{
  "best_metric": 0.338022381067276,
  "best_model_checkpoint": "/scratch/lmbanr001/HYBRID_20M_dropout_little/checkpoint-244000",
  "epoch": 9.99979669424848,
  "eval_steps": 2000,
  "global_step": 245930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 19.19866943359375,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.6875,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 12.13292121887207,
      "learning_rate": 2.5e-06,
      "loss": 6.8465,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 2.8739559650421143,
      "learning_rate": 5e-06,
      "loss": 3.4741,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 1.7225137948989868,
      "learning_rate": 7.5e-06,
      "loss": 1.7682,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 1.7597638368606567,
      "learning_rate": 1e-05,
      "loss": 1.2238,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 1.6617368459701538,
      "learning_rate": 1.25e-05,
      "loss": 1.0318,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 2.252094030380249,
      "learning_rate": 1.5e-05,
      "loss": 0.9176,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 2.1158359050750732,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.8546,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 2.873997688293457,
      "learning_rate": 2e-05,
      "loss": 0.8014,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 2.3957674503326416,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.7595,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 2.376518726348877,
      "learning_rate": 2.5e-05,
      "loss": 0.7339,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 2.803375720977783,
      "learning_rate": 2.75e-05,
      "loss": 0.7005,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 2.417477607727051,
      "learning_rate": 3e-05,
      "loss": 0.6733,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 2.283579111099243,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.6476,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 2.8959336280822754,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.6246,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 2.3752663135528564,
      "learning_rate": 3.75e-05,
      "loss": 0.6081,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 2.726912498474121,
      "learning_rate": 4e-05,
      "loss": 0.5932,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 2.5396568775177,
      "learning_rate": 4.25e-05,
      "loss": 0.582,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 2.4336535930633545,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.5677,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 2.0494120121002197,
      "learning_rate": 4.75e-05,
      "loss": 0.5537,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 2.2614734172821045,
      "learning_rate": 5e-05,
      "loss": 0.5474,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.5482079982757568,
      "eval_runtime": 117.183,
      "eval_samples_per_second": 1492.555,
      "eval_steps_per_second": 46.645,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 2.246554136276245,
      "learning_rate": 5.25e-05,
      "loss": 0.5407,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 2.118764638900757,
      "learning_rate": 5.5e-05,
      "loss": 0.5345,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 1.9059430360794067,
      "learning_rate": 5.75e-05,
      "loss": 0.5249,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 2.045391082763672,
      "learning_rate": 6e-05,
      "loss": 0.5228,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 2.137944221496582,
      "learning_rate": 6.25e-05,
      "loss": 0.518,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 1.5491400957107544,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.5123,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 1.629331111907959,
      "learning_rate": 6.75e-05,
      "loss": 0.5053,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 1.6942254304885864,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.5039,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 1.6294188499450684,
      "learning_rate": 7.25e-05,
      "loss": 0.5006,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 1.772447943687439,
      "learning_rate": 7.5e-05,
      "loss": 0.4983,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 1.5958832502365112,
      "learning_rate": 7.75e-05,
      "loss": 0.4963,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 1.5411961078643799,
      "learning_rate": 8e-05,
      "loss": 0.4922,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 1.6799098253250122,
      "learning_rate": 8.25e-05,
      "loss": 0.4889,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 1.3748542070388794,
      "learning_rate": 8.5e-05,
      "loss": 0.4852,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 1.4081141948699951,
      "learning_rate": 8.75e-05,
      "loss": 0.4876,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 1.268296480178833,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.4817,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 1.3497891426086426,
      "learning_rate": 9.25e-05,
      "loss": 0.4783,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 1.294649362564087,
      "learning_rate": 9.5e-05,
      "loss": 0.4756,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 1.3724735975265503,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.476,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 1.1237599849700928,
      "learning_rate": 0.0001,
      "loss": 0.4734,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.4811069071292877,
      "eval_runtime": 113.4137,
      "eval_samples_per_second": 1542.16,
      "eval_steps_per_second": 48.195,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 1.0453609228134155,
      "learning_rate": 0.0001025,
      "loss": 0.4693,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 1.1564948558807373,
      "learning_rate": 0.000105,
      "loss": 0.4701,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 1.2086702585220337,
      "learning_rate": 0.0001075,
      "loss": 0.4688,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 1.1010878086090088,
      "learning_rate": 0.00011,
      "loss": 0.4666,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 1.0885088443756104,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.4658,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 1.1625884771347046,
      "learning_rate": 0.000115,
      "loss": 0.4616,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 0.9988698959350586,
      "learning_rate": 0.0001175,
      "loss": 0.458,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 1.1554920673370361,
      "learning_rate": 0.00012,
      "loss": 0.4605,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 1.0871093273162842,
      "learning_rate": 0.0001225,
      "loss": 0.4604,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.8956074714660645,
      "learning_rate": 0.000125,
      "loss": 0.4605,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 0.9329069256782532,
      "learning_rate": 0.0001275,
      "loss": 0.4563,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 0.8724404573440552,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.4546,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 1.0196311473846436,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.4511,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.8539234399795532,
      "learning_rate": 0.000135,
      "loss": 0.451,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.8674988746643066,
      "learning_rate": 0.0001375,
      "loss": 0.4519,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.8306674361228943,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4498,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.8495289087295532,
      "learning_rate": 0.0001425,
      "loss": 0.4499,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.8446574211120605,
      "learning_rate": 0.000145,
      "loss": 0.4499,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.81836998462677,
      "learning_rate": 0.0001475,
      "loss": 0.4456,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.9913063645362854,
      "learning_rate": 0.00015,
      "loss": 0.4458,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.4554382264614105,
      "eval_runtime": 116.3528,
      "eval_samples_per_second": 1503.205,
      "eval_steps_per_second": 46.978,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 1.3064969778060913,
      "learning_rate": 0.0001525,
      "loss": 0.4452,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.8016210198402405,
      "learning_rate": 0.000155,
      "loss": 0.4462,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.7252851128578186,
      "learning_rate": 0.0001575,
      "loss": 0.4435,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 1.0114085674285889,
      "learning_rate": 0.00016,
      "loss": 0.4441,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.702377200126648,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.4444,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.6802545189857483,
      "learning_rate": 0.000165,
      "loss": 0.4457,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.7568301558494568,
      "learning_rate": 0.0001675,
      "loss": 0.4392,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.7755659222602844,
      "learning_rate": 0.00017,
      "loss": 0.44,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.7302706241607666,
      "learning_rate": 0.0001725,
      "loss": 0.439,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.6753720641136169,
      "learning_rate": 0.000175,
      "loss": 0.4395,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.6482388377189636,
      "learning_rate": 0.0001775,
      "loss": 0.4404,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.6246986389160156,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4384,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6719756126403809,
      "learning_rate": 0.0001825,
      "loss": 0.437,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.6382322907447815,
      "learning_rate": 0.000185,
      "loss": 0.4379,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.6730486750602722,
      "learning_rate": 0.0001875,
      "loss": 0.4361,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.5816685557365417,
      "learning_rate": 0.00019,
      "loss": 0.4357,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.6810534596443176,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4339,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.6697846055030823,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.4355,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.6841056942939758,
      "learning_rate": 0.0001975,
      "loss": 0.435,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.6225461363792419,
      "learning_rate": 0.0002,
      "loss": 0.4362,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.44267383217811584,
      "eval_runtime": 113.5299,
      "eval_samples_per_second": 1540.581,
      "eval_steps_per_second": 48.146,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.6706862449645996,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4363,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.5949196219444275,
      "learning_rate": 0.000205,
      "loss": 0.4364,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.6444986462593079,
      "learning_rate": 0.0002075,
      "loss": 0.4312,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.5849249958992004,
      "learning_rate": 0.00021,
      "loss": 0.4328,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.6075851917266846,
      "learning_rate": 0.0002125,
      "loss": 0.4305,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.6047567129135132,
      "learning_rate": 0.000215,
      "loss": 0.43,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.6945921182632446,
      "learning_rate": 0.0002175,
      "loss": 0.431,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.5679594874382019,
      "learning_rate": 0.00022,
      "loss": 0.4303,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.5652326941490173,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4285,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.6002563238143921,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.4273,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.5655284523963928,
      "learning_rate": 0.0002275,
      "loss": 0.4308,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.5232728719711304,
      "learning_rate": 0.00023,
      "loss": 0.4285,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.5316242575645447,
      "learning_rate": 0.0002325,
      "loss": 0.429,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.5193639397621155,
      "learning_rate": 0.000235,
      "loss": 0.4273,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.4951588809490204,
      "learning_rate": 0.0002375,
      "loss": 0.4244,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.5531091690063477,
      "learning_rate": 0.00024,
      "loss": 0.427,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.5796665549278259,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4253,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.4911940097808838,
      "learning_rate": 0.000245,
      "loss": 0.4241,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.46279847621917725,
      "learning_rate": 0.0002475,
      "loss": 0.4298,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.5195596814155579,
      "learning_rate": 0.00025,
      "loss": 0.4261,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.4363501965999603,
      "eval_runtime": 115.2809,
      "eval_samples_per_second": 1517.181,
      "eval_steps_per_second": 47.415,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.48841235041618347,
      "learning_rate": 0.0002525,
      "loss": 0.4268,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.47321978211402893,
      "learning_rate": 0.000255,
      "loss": 0.4279,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.5054214596748352,
      "learning_rate": 0.0002575,
      "loss": 0.4278,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.4955134987831116,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4243,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.44302624464035034,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4254,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.4998611807823181,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4254,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.51778244972229,
      "learning_rate": 0.0002675,
      "loss": 0.4253,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.4094427525997162,
      "learning_rate": 0.00027,
      "loss": 0.4233,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.41962045431137085,
      "learning_rate": 0.0002725,
      "loss": 0.4236,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.48351752758026123,
      "learning_rate": 0.000275,
      "loss": 0.4241,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.46708443760871887,
      "learning_rate": 0.0002775,
      "loss": 0.4207,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.39572736620903015,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4259,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.45534375309944153,
      "learning_rate": 0.0002825,
      "loss": 0.4234,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.41306501626968384,
      "learning_rate": 0.000285,
      "loss": 0.4208,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.42431244254112244,
      "learning_rate": 0.0002875,
      "loss": 0.4225,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.3664616048336029,
      "learning_rate": 0.00029,
      "loss": 0.4184,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.4255388677120209,
      "learning_rate": 0.0002925,
      "loss": 0.4207,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.4183686375617981,
      "learning_rate": 0.000295,
      "loss": 0.4189,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.40841978788375854,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4197,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.3898501992225647,
      "learning_rate": 0.0003,
      "loss": 0.4192,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.42937275767326355,
      "eval_runtime": 113.062,
      "eval_samples_per_second": 1546.957,
      "eval_steps_per_second": 48.345,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.3788551688194275,
      "learning_rate": 0.0003025,
      "loss": 0.419,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.3436335623264313,
      "learning_rate": 0.000305,
      "loss": 0.4152,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.37444204092025757,
      "learning_rate": 0.0003075,
      "loss": 0.4202,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.3905453383922577,
      "learning_rate": 0.00031,
      "loss": 0.4193,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.4151317775249481,
      "learning_rate": 0.0003125,
      "loss": 0.4197,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.4157867431640625,
      "learning_rate": 0.000315,
      "loss": 0.4192,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.35861706733703613,
      "learning_rate": 0.0003175,
      "loss": 0.4182,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.3969738185405731,
      "learning_rate": 0.00032,
      "loss": 0.4197,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.38542959094047546,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4186,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.3713223934173584,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4188,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.3842394948005676,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4188,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.38686588406562805,
      "learning_rate": 0.00033,
      "loss": 0.4167,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.33568674325942993,
      "learning_rate": 0.0003325,
      "loss": 0.4155,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.39265233278274536,
      "learning_rate": 0.000335,
      "loss": 0.4174,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.37611445784568787,
      "learning_rate": 0.0003375,
      "loss": 0.4159,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.3478836715221405,
      "learning_rate": 0.00034,
      "loss": 0.4156,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.34017878770828247,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.4167,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.3394051790237427,
      "learning_rate": 0.000345,
      "loss": 0.4175,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.3580530285835266,
      "learning_rate": 0.0003475,
      "loss": 0.4164,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.3234293758869171,
      "learning_rate": 0.00035,
      "loss": 0.418,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.4258577227592468,
      "eval_runtime": 114.7929,
      "eval_samples_per_second": 1523.631,
      "eval_steps_per_second": 47.616,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.3409923315048218,
      "learning_rate": 0.0003525,
      "loss": 0.4168,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.35392075777053833,
      "learning_rate": 0.000355,
      "loss": 0.4166,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.30403921008110046,
      "learning_rate": 0.0003575,
      "loss": 0.4159,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.32068681716918945,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4161,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.3100404143333435,
      "learning_rate": 0.0003625,
      "loss": 0.4137,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.3518546521663666,
      "learning_rate": 0.000365,
      "loss": 0.4158,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.33212828636169434,
      "learning_rate": 0.0003675,
      "loss": 0.417,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.3112615942955017,
      "learning_rate": 0.00037,
      "loss": 0.4122,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.31232208013534546,
      "learning_rate": 0.0003725,
      "loss": 0.4116,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.31029805541038513,
      "learning_rate": 0.000375,
      "loss": 0.4145,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.4216174781322479,
      "learning_rate": 0.0003775,
      "loss": 0.4128,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.3451187312602997,
      "learning_rate": 0.00038,
      "loss": 0.4131,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.3237797021865845,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4154,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.30964043736457825,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4111,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.30863702297210693,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4116,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.3343653678894043,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4116,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.4035443365573883,
      "learning_rate": 0.0003925,
      "loss": 0.4099,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.30214357376098633,
      "learning_rate": 0.000395,
      "loss": 0.412,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.31440356373786926,
      "learning_rate": 0.0003975,
      "loss": 0.4116,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.36322924494743347,
      "learning_rate": 0.0004,
      "loss": 0.4119,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.42167773842811584,
      "eval_runtime": 113.0318,
      "eval_samples_per_second": 1547.37,
      "eval_steps_per_second": 48.358,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.3689691126346588,
      "learning_rate": 0.0004025,
      "loss": 0.4138,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.29033008217811584,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4128,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.31487661600112915,
      "learning_rate": 0.0004075,
      "loss": 0.4128,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.3059391677379608,
      "learning_rate": 0.00041,
      "loss": 0.4114,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.28332626819610596,
      "learning_rate": 0.0004125,
      "loss": 0.412,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.27526384592056274,
      "learning_rate": 0.000415,
      "loss": 0.4117,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.30140557885169983,
      "learning_rate": 0.0004175,
      "loss": 0.4103,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.27625608444213867,
      "learning_rate": 0.00042,
      "loss": 0.4101,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.2752005159854889,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4107,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.3374031186103821,
      "learning_rate": 0.000425,
      "loss": 0.4104,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.27182379364967346,
      "learning_rate": 0.0004275,
      "loss": 0.4134,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.2872958183288574,
      "learning_rate": 0.00043,
      "loss": 0.4132,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.2859392464160919,
      "learning_rate": 0.0004325,
      "loss": 0.412,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.2892158627510071,
      "learning_rate": 0.000435,
      "loss": 0.4111,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.29659998416900635,
      "learning_rate": 0.0004375,
      "loss": 0.408,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.28916874527931213,
      "learning_rate": 0.00044,
      "loss": 0.4104,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.2731623649597168,
      "learning_rate": 0.0004425,
      "loss": 0.4075,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.2854125499725342,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4117,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.32965463399887085,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4095,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.2558073103427887,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4095,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.41651761531829834,
      "eval_runtime": 114.5698,
      "eval_samples_per_second": 1526.597,
      "eval_steps_per_second": 47.709,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.28299713134765625,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4069,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.2618330419063568,
      "learning_rate": 0.000455,
      "loss": 0.4092,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.2503061294555664,
      "learning_rate": 0.0004575,
      "loss": 0.4084,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.251765638589859,
      "learning_rate": 0.00046,
      "loss": 0.4092,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.23418934643268585,
      "learning_rate": 0.0004625,
      "loss": 0.4067,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.2849258780479431,
      "learning_rate": 0.000465,
      "loss": 0.4079,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.2369031459093094,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4091,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.23247648775577545,
      "learning_rate": 0.00047,
      "loss": 0.409,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.22940170764923096,
      "learning_rate": 0.0004725,
      "loss": 0.4081,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.23548568785190582,
      "learning_rate": 0.000475,
      "loss": 0.405,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.2503395974636078,
      "learning_rate": 0.0004775,
      "loss": 0.4073,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.2869364321231842,
      "learning_rate": 0.00048,
      "loss": 0.4078,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.23796120285987854,
      "learning_rate": 0.0004825,
      "loss": 0.41,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.26474159955978394,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.4074,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.21313387155532837,
      "learning_rate": 0.0004875,
      "loss": 0.4049,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.2726617753505707,
      "learning_rate": 0.00049,
      "loss": 0.4068,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.28507429361343384,
      "learning_rate": 0.0004925,
      "loss": 0.4046,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.21871639788150787,
      "learning_rate": 0.000495,
      "loss": 0.406,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.24475924670696259,
      "learning_rate": 0.0004975,
      "loss": 0.4072,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.2419770359992981,
      "learning_rate": 0.0005,
      "loss": 0.4064,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.4152769446372986,
      "eval_runtime": 112.6787,
      "eval_samples_per_second": 1552.219,
      "eval_steps_per_second": 48.51,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.22460462152957916,
      "learning_rate": 0.0004997786925153809,
      "loss": 0.4073,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.2572689354419708,
      "learning_rate": 0.0004995573850307618,
      "loss": 0.407,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.22954776883125305,
      "learning_rate": 0.0004993360775461426,
      "loss": 0.4018,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.19956085085868835,
      "learning_rate": 0.0004991147700615235,
      "loss": 0.4053,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.22466683387756348,
      "learning_rate": 0.0004988934625769043,
      "loss": 0.4036,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.21352823078632355,
      "learning_rate": 0.0004986721550922853,
      "loss": 0.4037,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.24356263875961304,
      "learning_rate": 0.0004984508476076661,
      "loss": 0.4056,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.1917089819908142,
      "learning_rate": 0.000498229540123047,
      "loss": 0.4051,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.22835934162139893,
      "learning_rate": 0.0004980082326384278,
      "loss": 0.4042,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.19794951379299164,
      "learning_rate": 0.0004977869251538087,
      "loss": 0.4029,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.22698864340782166,
      "learning_rate": 0.0004975656176691896,
      "loss": 0.4036,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.21834591031074524,
      "learning_rate": 0.0004973443101845705,
      "loss": 0.4009,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.20324131846427917,
      "learning_rate": 0.0004971230026999513,
      "loss": 0.4004,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.2151910364627838,
      "learning_rate": 0.0004969016952153321,
      "loss": 0.4032,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.22600950300693512,
      "learning_rate": 0.0004966803877307131,
      "loss": 0.4017,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.20749495923519135,
      "learning_rate": 0.0004964590802460939,
      "loss": 0.4017,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.20968110859394073,
      "learning_rate": 0.0004962377727614748,
      "loss": 0.4009,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.2335851490497589,
      "learning_rate": 0.0004960164652768557,
      "loss": 0.4,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.205797478556633,
      "learning_rate": 0.0004957951577922366,
      "loss": 0.4008,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.20664098858833313,
      "learning_rate": 0.0004955738503076174,
      "loss": 0.3997,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.4110566973686218,
      "eval_runtime": 113.631,
      "eval_samples_per_second": 1539.211,
      "eval_steps_per_second": 48.103,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.2018515169620514,
      "learning_rate": 0.0004953525428229983,
      "loss": 0.399,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.23595505952835083,
      "learning_rate": 0.0004951312353383792,
      "loss": 0.4033,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.18670879304409027,
      "learning_rate": 0.00049490992785376,
      "loss": 0.4004,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.2254958301782608,
      "learning_rate": 0.0004946886203691409,
      "loss": 0.3998,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.22962062060832977,
      "learning_rate": 0.0004944673128845217,
      "loss": 0.4024,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.2097329944372177,
      "learning_rate": 0.0004942460053999026,
      "loss": 0.3999,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.19802537560462952,
      "learning_rate": 0.0004940246979152835,
      "loss": 0.3985,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.2229231894016266,
      "learning_rate": 0.0004938033904306644,
      "loss": 0.4004,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.21323879063129425,
      "learning_rate": 0.0004935820829460452,
      "loss": 0.3987,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.2459859997034073,
      "learning_rate": 0.0004933607754614261,
      "loss": 0.3973,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.22427158057689667,
      "learning_rate": 0.000493139467976807,
      "loss": 0.3975,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.2081664651632309,
      "learning_rate": 0.0004929181604921879,
      "loss": 0.3989,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.21543467044830322,
      "learning_rate": 0.0004926968530075687,
      "loss": 0.3992,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.2069026529788971,
      "learning_rate": 0.0004924755455229495,
      "loss": 0.3969,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.19503509998321533,
      "learning_rate": 0.0004922542380383305,
      "loss": 0.3968,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.21266381442546844,
      "learning_rate": 0.0004920329305537113,
      "loss": 0.3965,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.1907777339220047,
      "learning_rate": 0.0004918116230690922,
      "loss": 0.399,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.19418209791183472,
      "learning_rate": 0.0004915903155844731,
      "loss": 0.3978,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.20434805750846863,
      "learning_rate": 0.000491369008099854,
      "loss": 0.3955,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.1968695968389511,
      "learning_rate": 0.0004911477006152348,
      "loss": 0.3956,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.4052344858646393,
      "eval_runtime": 112.8948,
      "eval_samples_per_second": 1549.248,
      "eval_steps_per_second": 48.417,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.19050166010856628,
      "learning_rate": 0.0004909263931306157,
      "loss": 0.3974,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.20424680411815643,
      "learning_rate": 0.0004907050856459966,
      "loss": 0.3956,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.17521126568317413,
      "learning_rate": 0.0004904837781613775,
      "loss": 0.3978,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.19525861740112305,
      "learning_rate": 0.0004902624706767583,
      "loss": 0.3956,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.18289127945899963,
      "learning_rate": 0.0004900411631921391,
      "loss": 0.3961,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.20396029949188232,
      "learning_rate": 0.00048981985570752,
      "loss": 0.3928,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.20592914521694183,
      "learning_rate": 0.0004895985482229009,
      "loss": 0.3928,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.2275443971157074,
      "learning_rate": 0.0004893772407382818,
      "loss": 0.396,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.21737994253635406,
      "learning_rate": 0.0004891559332536626,
      "loss": 0.3919,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.20750263333320618,
      "learning_rate": 0.0004889346257690435,
      "loss": 0.3962,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.20099470019340515,
      "learning_rate": 0.0004887133182844244,
      "loss": 0.3911,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.2061374932527542,
      "learning_rate": 0.0004884920107998053,
      "loss": 0.3962,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.20756009221076965,
      "learning_rate": 0.00048827070331518616,
      "loss": 0.3934,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.23219406604766846,
      "learning_rate": 0.000488049395830567,
      "loss": 0.3927,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.19916439056396484,
      "learning_rate": 0.0004878280883459479,
      "loss": 0.3934,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.19949255883693695,
      "learning_rate": 0.00048760678086132874,
      "loss": 0.3947,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.18925979733467102,
      "learning_rate": 0.00048738547337670964,
      "loss": 0.3926,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.18482789397239685,
      "learning_rate": 0.0004871641658920905,
      "loss": 0.3903,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.2011263221502304,
      "learning_rate": 0.0004869428584074714,
      "loss": 0.3931,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.20726656913757324,
      "learning_rate": 0.00048672155092285217,
      "loss": 0.3927,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.4021971523761749,
      "eval_runtime": 113.9765,
      "eval_samples_per_second": 1534.545,
      "eval_steps_per_second": 47.957,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.1694554090499878,
      "learning_rate": 0.00048650024343823307,
      "loss": 0.392,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.18519337475299835,
      "learning_rate": 0.00048627893595361396,
      "loss": 0.3907,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.19401589035987854,
      "learning_rate": 0.0004860576284689948,
      "loss": 0.3917,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.192395880818367,
      "learning_rate": 0.0004858363209843757,
      "loss": 0.3913,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.20259593427181244,
      "learning_rate": 0.00048561501349975655,
      "loss": 0.3908,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.210861936211586,
      "learning_rate": 0.00048539370601513744,
      "loss": 0.389,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.18901337683200836,
      "learning_rate": 0.0004851723985305183,
      "loss": 0.3911,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.17975665628910065,
      "learning_rate": 0.0004849510910458992,
      "loss": 0.3894,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.2199794501066208,
      "learning_rate": 0.0004847297835612801,
      "loss": 0.3914,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.1817806214094162,
      "learning_rate": 0.0004845084760766609,
      "loss": 0.3898,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.18405060470104218,
      "learning_rate": 0.0004842871685920418,
      "loss": 0.3909,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.1947610080242157,
      "learning_rate": 0.00048406586110742267,
      "loss": 0.3902,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.1836412400007248,
      "learning_rate": 0.00048384455362280356,
      "loss": 0.3929,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.17224815487861633,
      "learning_rate": 0.0004836232461381844,
      "loss": 0.3893,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.17317262291908264,
      "learning_rate": 0.0004834019386535653,
      "loss": 0.3876,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.20437870919704437,
      "learning_rate": 0.0004831806311689461,
      "loss": 0.3881,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.17922545969486237,
      "learning_rate": 0.000482959323684327,
      "loss": 0.3905,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.20159606635570526,
      "learning_rate": 0.0004827380161997079,
      "loss": 0.3913,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.20845769345760345,
      "learning_rate": 0.00048251670871508873,
      "loss": 0.3886,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.16973236203193665,
      "learning_rate": 0.00048229540123046963,
      "loss": 0.3903,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.39935052394866943,
      "eval_runtime": 113.7184,
      "eval_samples_per_second": 1538.027,
      "eval_steps_per_second": 48.066,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.19762884080410004,
      "learning_rate": 0.00048207409374585047,
      "loss": 0.3893,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.18635804951190948,
      "learning_rate": 0.00048185278626123137,
      "loss": 0.3905,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.195398211479187,
      "learning_rate": 0.0004816314787766122,
      "loss": 0.3871,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.16447505354881287,
      "learning_rate": 0.0004814101712919931,
      "loss": 0.3898,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.18749891221523285,
      "learning_rate": 0.00048118886380737395,
      "loss": 0.3877,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.1744668185710907,
      "learning_rate": 0.00048096755632275485,
      "loss": 0.3899,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.16778166592121124,
      "learning_rate": 0.00048074624883813575,
      "loss": 0.3869,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.19052107632160187,
      "learning_rate": 0.0004805249413535166,
      "loss": 0.3882,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.15995976328849792,
      "learning_rate": 0.0004803036338688975,
      "loss": 0.3898,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.16804274916648865,
      "learning_rate": 0.00048008232638427833,
      "loss": 0.3881,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.20163403451442719,
      "learning_rate": 0.00047986101889965923,
      "loss": 0.3908,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.17838969826698303,
      "learning_rate": 0.00047963971141504007,
      "loss": 0.3874,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.18075808882713318,
      "learning_rate": 0.0004794184039304209,
      "loss": 0.3895,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.17722053825855255,
      "learning_rate": 0.00047919709644580176,
      "loss": 0.3886,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.1852400004863739,
      "learning_rate": 0.00047897578896118265,
      "loss": 0.3895,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.17505207657814026,
      "learning_rate": 0.00047875448147656355,
      "loss": 0.3882,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.17860019207000732,
      "learning_rate": 0.0004785331739919444,
      "loss": 0.3862,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.20551538467407227,
      "learning_rate": 0.0004783118665073253,
      "loss": 0.3875,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.1767166256904602,
      "learning_rate": 0.00047809055902270614,
      "loss": 0.3888,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.1725575178861618,
      "learning_rate": 0.00047786925153808703,
      "loss": 0.3866,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.3966103196144104,
      "eval_runtime": 113.9196,
      "eval_samples_per_second": 1535.311,
      "eval_steps_per_second": 47.981,
      "step": 30000
    },
    {
      "epoch": 1.2239006241486572,
      "grad_norm": 0.1800871640443802,
      "learning_rate": 0.0004776479440534679,
      "loss": 0.386,
      "step": 30100
    },
    {
      "epoch": 1.2279667391790514,
      "grad_norm": 0.18151059746742249,
      "learning_rate": 0.0004774266365688488,
      "loss": 0.387,
      "step": 30200
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.18437543511390686,
      "learning_rate": 0.00047720532908422967,
      "loss": 0.3844,
      "step": 30300
    },
    {
      "epoch": 1.2360989692398399,
      "grad_norm": 0.1640896499156952,
      "learning_rate": 0.0004769840215996105,
      "loss": 0.3897,
      "step": 30400
    },
    {
      "epoch": 1.240165084270234,
      "grad_norm": 0.16402661800384521,
      "learning_rate": 0.0004767627141149914,
      "loss": 0.3864,
      "step": 30500
    },
    {
      "epoch": 1.2442311993006283,
      "grad_norm": 0.1916639357805252,
      "learning_rate": 0.00047654140663037225,
      "loss": 0.3866,
      "step": 30600
    },
    {
      "epoch": 1.2482973143310225,
      "grad_norm": 0.18788543343544006,
      "learning_rate": 0.00047632009914575315,
      "loss": 0.3854,
      "step": 30700
    },
    {
      "epoch": 1.2523634293614165,
      "grad_norm": 0.19616948068141937,
      "learning_rate": 0.000476098791661134,
      "loss": 0.3884,
      "step": 30800
    },
    {
      "epoch": 1.256429544391811,
      "grad_norm": 0.17281615734100342,
      "learning_rate": 0.0004758774841765149,
      "loss": 0.3878,
      "step": 30900
    },
    {
      "epoch": 1.260495659422205,
      "grad_norm": 0.16075120866298676,
      "learning_rate": 0.0004756561766918957,
      "loss": 0.385,
      "step": 31000
    },
    {
      "epoch": 1.2645617744525992,
      "grad_norm": 0.16225197911262512,
      "learning_rate": 0.0004754348692072766,
      "loss": 0.3866,
      "step": 31100
    },
    {
      "epoch": 1.2686278894829934,
      "grad_norm": 0.17589953541755676,
      "learning_rate": 0.0004752135617226575,
      "loss": 0.3851,
      "step": 31200
    },
    {
      "epoch": 1.2726940045133877,
      "grad_norm": 0.17587290704250336,
      "learning_rate": 0.0004749922542380383,
      "loss": 0.3845,
      "step": 31300
    },
    {
      "epoch": 1.2767601195437819,
      "grad_norm": 0.1725231111049652,
      "learning_rate": 0.0004747709467534192,
      "loss": 0.3877,
      "step": 31400
    },
    {
      "epoch": 1.280826234574176,
      "grad_norm": 0.16132576763629913,
      "learning_rate": 0.00047454963926880006,
      "loss": 0.383,
      "step": 31500
    },
    {
      "epoch": 1.2848923496045703,
      "grad_norm": 0.16721293330192566,
      "learning_rate": 0.00047432833178418096,
      "loss": 0.386,
      "step": 31600
    },
    {
      "epoch": 1.2889584646349646,
      "grad_norm": 0.1656702309846878,
      "learning_rate": 0.0004741070242995618,
      "loss": 0.3852,
      "step": 31700
    },
    {
      "epoch": 1.2930245796653588,
      "grad_norm": 0.19016002118587494,
      "learning_rate": 0.0004738857168149427,
      "loss": 0.3828,
      "step": 31800
    },
    {
      "epoch": 1.297090694695753,
      "grad_norm": 0.19160844385623932,
      "learning_rate": 0.00047366440933032354,
      "loss": 0.3871,
      "step": 31900
    },
    {
      "epoch": 1.3011568097261472,
      "grad_norm": 0.19736959040164948,
      "learning_rate": 0.00047344310184570444,
      "loss": 0.3854,
      "step": 32000
    },
    {
      "epoch": 1.3011568097261472,
      "eval_loss": 0.39563480019569397,
      "eval_runtime": 115.1674,
      "eval_samples_per_second": 1518.677,
      "eval_steps_per_second": 47.461,
      "step": 32000
    },
    {
      "epoch": 1.3052229247565412,
      "grad_norm": 0.18206870555877686,
      "learning_rate": 0.00047322179436108533,
      "loss": 0.385,
      "step": 32100
    },
    {
      "epoch": 1.3092890397869357,
      "grad_norm": 0.16891883313655853,
      "learning_rate": 0.0004730004868764662,
      "loss": 0.385,
      "step": 32200
    },
    {
      "epoch": 1.3133551548173297,
      "grad_norm": 0.17392556369304657,
      "learning_rate": 0.0004727791793918471,
      "loss": 0.387,
      "step": 32300
    },
    {
      "epoch": 1.3174212698477241,
      "grad_norm": 0.18975409865379333,
      "learning_rate": 0.0004725578719072279,
      "loss": 0.3852,
      "step": 32400
    },
    {
      "epoch": 1.3214873848781181,
      "grad_norm": 0.1676308959722519,
      "learning_rate": 0.0004723365644226088,
      "loss": 0.3827,
      "step": 32500
    },
    {
      "epoch": 1.3255534999085123,
      "grad_norm": 0.1837567538022995,
      "learning_rate": 0.00047211525693798966,
      "loss": 0.384,
      "step": 32600
    },
    {
      "epoch": 1.3296196149389066,
      "grad_norm": 0.16621018946170807,
      "learning_rate": 0.0004718939494533705,
      "loss": 0.3831,
      "step": 32700
    },
    {
      "epoch": 1.3336857299693008,
      "grad_norm": 0.16650208830833435,
      "learning_rate": 0.00047167264196875134,
      "loss": 0.3836,
      "step": 32800
    },
    {
      "epoch": 1.337751844999695,
      "grad_norm": 0.18742838501930237,
      "learning_rate": 0.00047145133448413224,
      "loss": 0.3845,
      "step": 32900
    },
    {
      "epoch": 1.3418179600300892,
      "grad_norm": 0.2044418752193451,
      "learning_rate": 0.00047123002699951314,
      "loss": 0.3855,
      "step": 33000
    },
    {
      "epoch": 1.3458840750604835,
      "grad_norm": 0.20261746644973755,
      "learning_rate": 0.000471008719514894,
      "loss": 0.3852,
      "step": 33100
    },
    {
      "epoch": 1.3499501900908777,
      "grad_norm": 0.15474367141723633,
      "learning_rate": 0.0004707874120302749,
      "loss": 0.3867,
      "step": 33200
    },
    {
      "epoch": 1.354016305121272,
      "grad_norm": 0.17736701667308807,
      "learning_rate": 0.0004705661045456557,
      "loss": 0.3818,
      "step": 33300
    },
    {
      "epoch": 1.3580824201516661,
      "grad_norm": 0.18523406982421875,
      "learning_rate": 0.0004703447970610366,
      "loss": 0.3857,
      "step": 33400
    },
    {
      "epoch": 1.3621485351820604,
      "grad_norm": 0.16811461746692657,
      "learning_rate": 0.00047012348957641746,
      "loss": 0.3813,
      "step": 33500
    },
    {
      "epoch": 1.3662146502124546,
      "grad_norm": 0.18600907921791077,
      "learning_rate": 0.00046990218209179836,
      "loss": 0.3857,
      "step": 33600
    },
    {
      "epoch": 1.3702807652428488,
      "grad_norm": 0.17724362015724182,
      "learning_rate": 0.00046968087460717926,
      "loss": 0.3831,
      "step": 33700
    },
    {
      "epoch": 1.3743468802732428,
      "grad_norm": 0.17528526484966278,
      "learning_rate": 0.0004694595671225601,
      "loss": 0.3839,
      "step": 33800
    },
    {
      "epoch": 1.3784129953036373,
      "grad_norm": 0.19247564673423767,
      "learning_rate": 0.000469238259637941,
      "loss": 0.3817,
      "step": 33900
    },
    {
      "epoch": 1.3824791103340313,
      "grad_norm": 0.17127622663974762,
      "learning_rate": 0.00046901695215332184,
      "loss": 0.3848,
      "step": 34000
    },
    {
      "epoch": 1.3824791103340313,
      "eval_loss": 0.39297738671302795,
      "eval_runtime": 113.5684,
      "eval_samples_per_second": 1540.058,
      "eval_steps_per_second": 48.13,
      "step": 34000
    },
    {
      "epoch": 1.3865452253644255,
      "grad_norm": 0.17616915702819824,
      "learning_rate": 0.00046879564466870274,
      "loss": 0.3837,
      "step": 34100
    },
    {
      "epoch": 1.3906113403948197,
      "grad_norm": 0.18032026290893555,
      "learning_rate": 0.0004685743371840836,
      "loss": 0.382,
      "step": 34200
    },
    {
      "epoch": 1.394677455425214,
      "grad_norm": 0.17847569286823273,
      "learning_rate": 0.0004683530296994645,
      "loss": 0.3837,
      "step": 34300
    },
    {
      "epoch": 1.3987435704556082,
      "grad_norm": 0.19275003671646118,
      "learning_rate": 0.00046813172221484527,
      "loss": 0.3844,
      "step": 34400
    },
    {
      "epoch": 1.4028096854860024,
      "grad_norm": 0.18048757314682007,
      "learning_rate": 0.00046791041473022617,
      "loss": 0.3837,
      "step": 34500
    },
    {
      "epoch": 1.4068758005163966,
      "grad_norm": 0.156645268201828,
      "learning_rate": 0.00046768910724560706,
      "loss": 0.3811,
      "step": 34600
    },
    {
      "epoch": 1.4109419155467908,
      "grad_norm": 0.1677723377943039,
      "learning_rate": 0.0004674677997609879,
      "loss": 0.381,
      "step": 34700
    },
    {
      "epoch": 1.415008030577185,
      "grad_norm": 0.16322830319404602,
      "learning_rate": 0.0004672464922763688,
      "loss": 0.3827,
      "step": 34800
    },
    {
      "epoch": 1.4190741456075793,
      "grad_norm": 0.2032032608985901,
      "learning_rate": 0.00046702518479174965,
      "loss": 0.382,
      "step": 34900
    },
    {
      "epoch": 1.4231402606379735,
      "grad_norm": 0.18388642370700836,
      "learning_rate": 0.00046680387730713054,
      "loss": 0.3833,
      "step": 35000
    },
    {
      "epoch": 1.4272063756683677,
      "grad_norm": 0.19130639731884003,
      "learning_rate": 0.0004665825698225114,
      "loss": 0.3833,
      "step": 35100
    },
    {
      "epoch": 1.431272490698762,
      "grad_norm": 0.17551212012767792,
      "learning_rate": 0.0004663612623378923,
      "loss": 0.3839,
      "step": 35200
    },
    {
      "epoch": 1.435338605729156,
      "grad_norm": 0.15671198070049286,
      "learning_rate": 0.0004661399548532731,
      "loss": 0.3825,
      "step": 35300
    },
    {
      "epoch": 1.4394047207595504,
      "grad_norm": 0.16682447493076324,
      "learning_rate": 0.000465918647368654,
      "loss": 0.3833,
      "step": 35400
    },
    {
      "epoch": 1.4434708357899444,
      "grad_norm": 0.20789647102355957,
      "learning_rate": 0.0004656973398840349,
      "loss": 0.3803,
      "step": 35500
    },
    {
      "epoch": 1.4475369508203388,
      "grad_norm": 0.1745135337114334,
      "learning_rate": 0.00046547603239941576,
      "loss": 0.3834,
      "step": 35600
    },
    {
      "epoch": 1.4516030658507328,
      "grad_norm": 0.1510237157344818,
      "learning_rate": 0.00046525472491479666,
      "loss": 0.3837,
      "step": 35700
    },
    {
      "epoch": 1.455669180881127,
      "grad_norm": 0.17791813611984253,
      "learning_rate": 0.0004650334174301775,
      "loss": 0.3825,
      "step": 35800
    },
    {
      "epoch": 1.4597352959115213,
      "grad_norm": 0.16635198891162872,
      "learning_rate": 0.0004648121099455584,
      "loss": 0.3826,
      "step": 35900
    },
    {
      "epoch": 1.4638014109419155,
      "grad_norm": 0.18779800832271576,
      "learning_rate": 0.00046459080246093925,
      "loss": 0.3835,
      "step": 36000
    },
    {
      "epoch": 1.4638014109419155,
      "eval_loss": 0.3906225562095642,
      "eval_runtime": 115.4572,
      "eval_samples_per_second": 1514.865,
      "eval_steps_per_second": 47.342,
      "step": 36000
    },
    {
      "epoch": 1.4678675259723097,
      "grad_norm": 0.1681162267923355,
      "learning_rate": 0.0004643694949763201,
      "loss": 0.3855,
      "step": 36100
    },
    {
      "epoch": 1.471933641002704,
      "grad_norm": 0.1901409775018692,
      "learning_rate": 0.00046414818749170093,
      "loss": 0.382,
      "step": 36200
    },
    {
      "epoch": 1.4759997560330982,
      "grad_norm": 0.1552066206932068,
      "learning_rate": 0.00046392688000708183,
      "loss": 0.3823,
      "step": 36300
    },
    {
      "epoch": 1.4800658710634924,
      "grad_norm": 0.16744616627693176,
      "learning_rate": 0.0004637055725224627,
      "loss": 0.3824,
      "step": 36400
    },
    {
      "epoch": 1.4841319860938866,
      "grad_norm": 0.16409829258918762,
      "learning_rate": 0.00046348426503784357,
      "loss": 0.3821,
      "step": 36500
    },
    {
      "epoch": 1.4881981011242809,
      "grad_norm": 0.17231197655200958,
      "learning_rate": 0.00046326295755322447,
      "loss": 0.3839,
      "step": 36600
    },
    {
      "epoch": 1.492264216154675,
      "grad_norm": 0.17430150508880615,
      "learning_rate": 0.0004630416500686053,
      "loss": 0.3799,
      "step": 36700
    },
    {
      "epoch": 1.4963303311850693,
      "grad_norm": 0.16603927314281464,
      "learning_rate": 0.0004628203425839862,
      "loss": 0.3839,
      "step": 36800
    },
    {
      "epoch": 1.5003964462154635,
      "grad_norm": 0.16799165308475494,
      "learning_rate": 0.00046259903509936705,
      "loss": 0.3834,
      "step": 36900
    },
    {
      "epoch": 1.5044625612458575,
      "grad_norm": 0.15833307802677155,
      "learning_rate": 0.00046237772761474795,
      "loss": 0.3821,
      "step": 37000
    },
    {
      "epoch": 1.508528676276252,
      "grad_norm": 0.16027219593524933,
      "learning_rate": 0.00046215642013012885,
      "loss": 0.3805,
      "step": 37100
    },
    {
      "epoch": 1.512594791306646,
      "grad_norm": 0.17796063423156738,
      "learning_rate": 0.0004619351126455097,
      "loss": 0.3817,
      "step": 37200
    },
    {
      "epoch": 1.5166609063370404,
      "grad_norm": 0.17315366864204407,
      "learning_rate": 0.0004617138051608906,
      "loss": 0.3811,
      "step": 37300
    },
    {
      "epoch": 1.5207270213674344,
      "grad_norm": 0.18731972575187683,
      "learning_rate": 0.00046149249767627143,
      "loss": 0.3807,
      "step": 37400
    },
    {
      "epoch": 1.5247931363978287,
      "grad_norm": 0.16696585714817047,
      "learning_rate": 0.0004612711901916523,
      "loss": 0.3805,
      "step": 37500
    },
    {
      "epoch": 1.5288592514282229,
      "grad_norm": 0.15880048274993896,
      "learning_rate": 0.00046104988270703317,
      "loss": 0.3803,
      "step": 37600
    },
    {
      "epoch": 1.532925366458617,
      "grad_norm": 0.1739608496427536,
      "learning_rate": 0.00046082857522241407,
      "loss": 0.3794,
      "step": 37700
    },
    {
      "epoch": 1.5369914814890113,
      "grad_norm": 0.18329066038131714,
      "learning_rate": 0.00046060726773779486,
      "loss": 0.3795,
      "step": 37800
    },
    {
      "epoch": 1.5410575965194055,
      "grad_norm": 0.173944354057312,
      "learning_rate": 0.00046038596025317575,
      "loss": 0.3791,
      "step": 37900
    },
    {
      "epoch": 1.5451237115497998,
      "grad_norm": 0.17036794126033783,
      "learning_rate": 0.00046016465276855665,
      "loss": 0.3817,
      "step": 38000
    },
    {
      "epoch": 1.5451237115497998,
      "eval_loss": 0.3907565772533417,
      "eval_runtime": 113.3401,
      "eval_samples_per_second": 1543.161,
      "eval_steps_per_second": 48.227,
      "step": 38000
    },
    {
      "epoch": 1.549189826580194,
      "grad_norm": 0.1739972084760666,
      "learning_rate": 0.0004599433452839375,
      "loss": 0.3827,
      "step": 38100
    },
    {
      "epoch": 1.5532559416105882,
      "grad_norm": 0.17620299756526947,
      "learning_rate": 0.0004597220377993184,
      "loss": 0.3815,
      "step": 38200
    },
    {
      "epoch": 1.5573220566409822,
      "grad_norm": 0.17868433892726898,
      "learning_rate": 0.00045950073031469923,
      "loss": 0.3798,
      "step": 38300
    },
    {
      "epoch": 1.5613881716713767,
      "grad_norm": 0.17522738873958588,
      "learning_rate": 0.00045927942283008013,
      "loss": 0.3793,
      "step": 38400
    },
    {
      "epoch": 1.5654542867017707,
      "grad_norm": 0.17666460573673248,
      "learning_rate": 0.000459058115345461,
      "loss": 0.3774,
      "step": 38500
    },
    {
      "epoch": 1.5695204017321651,
      "grad_norm": 0.18762627243995667,
      "learning_rate": 0.00045883680786084187,
      "loss": 0.3803,
      "step": 38600
    },
    {
      "epoch": 1.5735865167625591,
      "grad_norm": 0.18126454949378967,
      "learning_rate": 0.0004586155003762227,
      "loss": 0.3787,
      "step": 38700
    },
    {
      "epoch": 1.5776526317929536,
      "grad_norm": 0.17398881912231445,
      "learning_rate": 0.0004583941928916036,
      "loss": 0.3818,
      "step": 38800
    },
    {
      "epoch": 1.5817187468233476,
      "grad_norm": 0.17507821321487427,
      "learning_rate": 0.0004581728854069845,
      "loss": 0.3796,
      "step": 38900
    },
    {
      "epoch": 1.5857848618537418,
      "grad_norm": 0.16799084842205048,
      "learning_rate": 0.00045795157792236535,
      "loss": 0.382,
      "step": 39000
    },
    {
      "epoch": 1.589850976884136,
      "grad_norm": 0.17808642983436584,
      "learning_rate": 0.00045773027043774625,
      "loss": 0.3801,
      "step": 39100
    },
    {
      "epoch": 1.5939170919145302,
      "grad_norm": 0.1653461754322052,
      "learning_rate": 0.0004575089629531271,
      "loss": 0.3818,
      "step": 39200
    },
    {
      "epoch": 1.5979832069449245,
      "grad_norm": 0.17711785435676575,
      "learning_rate": 0.000457287655468508,
      "loss": 0.3787,
      "step": 39300
    },
    {
      "epoch": 1.6020493219753187,
      "grad_norm": 0.18112558126449585,
      "learning_rate": 0.0004570663479838888,
      "loss": 0.3789,
      "step": 39400
    },
    {
      "epoch": 1.606115437005713,
      "grad_norm": 0.17601653933525085,
      "learning_rate": 0.0004568450404992697,
      "loss": 0.3792,
      "step": 39500
    },
    {
      "epoch": 1.6101815520361071,
      "grad_norm": 0.19440490007400513,
      "learning_rate": 0.0004566237330146505,
      "loss": 0.3774,
      "step": 39600
    },
    {
      "epoch": 1.6142476670665014,
      "grad_norm": 0.16987577080726624,
      "learning_rate": 0.0004564024255300314,
      "loss": 0.3803,
      "step": 39700
    },
    {
      "epoch": 1.6183137820968954,
      "grad_norm": 0.1712784767150879,
      "learning_rate": 0.0004561811180454123,
      "loss": 0.3777,
      "step": 39800
    },
    {
      "epoch": 1.6223798971272898,
      "grad_norm": 0.1538977473974228,
      "learning_rate": 0.00045595981056079316,
      "loss": 0.3806,
      "step": 39900
    },
    {
      "epoch": 1.6264460121576838,
      "grad_norm": 0.18391680717468262,
      "learning_rate": 0.00045573850307617405,
      "loss": 0.3799,
      "step": 40000
    },
    {
      "epoch": 1.6264460121576838,
      "eval_loss": 0.3882843554019928,
      "eval_runtime": 115.9204,
      "eval_samples_per_second": 1508.811,
      "eval_steps_per_second": 47.153,
      "step": 40000
    },
    {
      "epoch": 1.6305121271880783,
      "grad_norm": 0.16308248043060303,
      "learning_rate": 0.0004555171955915549,
      "loss": 0.3823,
      "step": 40100
    },
    {
      "epoch": 1.6345782422184723,
      "grad_norm": 0.18829911947250366,
      "learning_rate": 0.0004552958881069358,
      "loss": 0.3768,
      "step": 40200
    },
    {
      "epoch": 1.6386443572488667,
      "grad_norm": 0.16715404391288757,
      "learning_rate": 0.00045507458062231664,
      "loss": 0.3824,
      "step": 40300
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.1840304136276245,
      "learning_rate": 0.00045485327313769754,
      "loss": 0.3795,
      "step": 40400
    },
    {
      "epoch": 1.6467765873096551,
      "grad_norm": 0.17058983445167542,
      "learning_rate": 0.0004546319656530784,
      "loss": 0.3812,
      "step": 40500
    },
    {
      "epoch": 1.6508427023400492,
      "grad_norm": 0.17685461044311523,
      "learning_rate": 0.0004544106581684593,
      "loss": 0.3765,
      "step": 40600
    },
    {
      "epoch": 1.6549088173704434,
      "grad_norm": 0.17264309525489807,
      "learning_rate": 0.0004541893506838402,
      "loss": 0.3801,
      "step": 40700
    },
    {
      "epoch": 1.6589749324008376,
      "grad_norm": 0.20904192328453064,
      "learning_rate": 0.000453968043199221,
      "loss": 0.3774,
      "step": 40800
    },
    {
      "epoch": 1.6630410474312318,
      "grad_norm": 0.16939011216163635,
      "learning_rate": 0.0004537467357146019,
      "loss": 0.3783,
      "step": 40900
    },
    {
      "epoch": 1.667107162461626,
      "grad_norm": 0.16174721717834473,
      "learning_rate": 0.00045352542822998276,
      "loss": 0.3784,
      "step": 41000
    },
    {
      "epoch": 1.6711732774920203,
      "grad_norm": 0.18607285618782043,
      "learning_rate": 0.0004533041207453636,
      "loss": 0.3785,
      "step": 41100
    },
    {
      "epoch": 1.6752393925224145,
      "grad_norm": 0.16814939677715302,
      "learning_rate": 0.00045308281326074444,
      "loss": 0.3799,
      "step": 41200
    },
    {
      "epoch": 1.6793055075528087,
      "grad_norm": 0.21646788716316223,
      "learning_rate": 0.00045286150577612534,
      "loss": 0.3794,
      "step": 41300
    },
    {
      "epoch": 1.683371622583203,
      "grad_norm": 0.18352879583835602,
      "learning_rate": 0.00045264019829150624,
      "loss": 0.3799,
      "step": 41400
    },
    {
      "epoch": 1.687437737613597,
      "grad_norm": 0.17621372640132904,
      "learning_rate": 0.0004524188908068871,
      "loss": 0.3802,
      "step": 41500
    },
    {
      "epoch": 1.6915038526439914,
      "grad_norm": 0.15675601363182068,
      "learning_rate": 0.000452197583322268,
      "loss": 0.3805,
      "step": 41600
    },
    {
      "epoch": 1.6955699676743854,
      "grad_norm": 0.18506422638893127,
      "learning_rate": 0.0004519762758376488,
      "loss": 0.3791,
      "step": 41700
    },
    {
      "epoch": 1.6996360827047798,
      "grad_norm": 0.17462992668151855,
      "learning_rate": 0.0004517549683530297,
      "loss": 0.3778,
      "step": 41800
    },
    {
      "epoch": 1.7037021977351738,
      "grad_norm": 0.15757010877132416,
      "learning_rate": 0.00045153366086841056,
      "loss": 0.3788,
      "step": 41900
    },
    {
      "epoch": 1.7077683127655683,
      "grad_norm": 0.17744949460029602,
      "learning_rate": 0.00045131235338379146,
      "loss": 0.3771,
      "step": 42000
    },
    {
      "epoch": 1.7077683127655683,
      "eval_loss": 0.3875572085380554,
      "eval_runtime": 113.035,
      "eval_samples_per_second": 1547.327,
      "eval_steps_per_second": 48.357,
      "step": 42000
    },
    {
      "epoch": 1.7118344277959623,
      "grad_norm": 0.18383952975273132,
      "learning_rate": 0.0004510910458991723,
      "loss": 0.3763,
      "step": 42100
    },
    {
      "epoch": 1.7159005428263565,
      "grad_norm": 0.17908994853496552,
      "learning_rate": 0.0004508697384145532,
      "loss": 0.3765,
      "step": 42200
    },
    {
      "epoch": 1.7199666578567507,
      "grad_norm": 0.18430426716804504,
      "learning_rate": 0.0004506484309299341,
      "loss": 0.3798,
      "step": 42300
    },
    {
      "epoch": 1.724032772887145,
      "grad_norm": 0.1865130066871643,
      "learning_rate": 0.00045042712344531494,
      "loss": 0.3758,
      "step": 42400
    },
    {
      "epoch": 1.7280988879175392,
      "grad_norm": 0.18926575779914856,
      "learning_rate": 0.00045020581596069584,
      "loss": 0.3782,
      "step": 42500
    },
    {
      "epoch": 1.7321650029479334,
      "grad_norm": 0.17101334035396576,
      "learning_rate": 0.0004499845084760767,
      "loss": 0.3795,
      "step": 42600
    },
    {
      "epoch": 1.7362311179783276,
      "grad_norm": 0.15968357026576996,
      "learning_rate": 0.0004497632009914576,
      "loss": 0.3771,
      "step": 42700
    },
    {
      "epoch": 1.7402972330087219,
      "grad_norm": 0.16717593371868134,
      "learning_rate": 0.00044954189350683837,
      "loss": 0.3769,
      "step": 42800
    },
    {
      "epoch": 1.744363348039116,
      "grad_norm": 0.1725948601961136,
      "learning_rate": 0.00044932058602221926,
      "loss": 0.38,
      "step": 42900
    },
    {
      "epoch": 1.74842946306951,
      "grad_norm": 0.1635267436504364,
      "learning_rate": 0.0004490992785376001,
      "loss": 0.3789,
      "step": 43000
    },
    {
      "epoch": 1.7524955780999045,
      "grad_norm": 0.16992886364459991,
      "learning_rate": 0.000448877971052981,
      "loss": 0.3763,
      "step": 43100
    },
    {
      "epoch": 1.7565616931302985,
      "grad_norm": 0.19718270003795624,
      "learning_rate": 0.0004486566635683619,
      "loss": 0.3756,
      "step": 43200
    },
    {
      "epoch": 1.760627808160693,
      "grad_norm": 0.14831635355949402,
      "learning_rate": 0.00044843535608374274,
      "loss": 0.3775,
      "step": 43300
    },
    {
      "epoch": 1.764693923191087,
      "grad_norm": 0.1659458726644516,
      "learning_rate": 0.00044821404859912364,
      "loss": 0.376,
      "step": 43400
    },
    {
      "epoch": 1.7687600382214814,
      "grad_norm": 0.17832119762897491,
      "learning_rate": 0.0004479927411145045,
      "loss": 0.3759,
      "step": 43500
    },
    {
      "epoch": 1.7728261532518754,
      "grad_norm": 0.1706501543521881,
      "learning_rate": 0.0004477714336298854,
      "loss": 0.3798,
      "step": 43600
    },
    {
      "epoch": 1.7768922682822699,
      "grad_norm": 0.1888316124677658,
      "learning_rate": 0.0004475501261452662,
      "loss": 0.3788,
      "step": 43700
    },
    {
      "epoch": 1.7809583833126639,
      "grad_norm": 0.1872972697019577,
      "learning_rate": 0.0004473288186606471,
      "loss": 0.378,
      "step": 43800
    },
    {
      "epoch": 1.785024498343058,
      "grad_norm": 0.20133088529109955,
      "learning_rate": 0.00044710751117602797,
      "loss": 0.3768,
      "step": 43900
    },
    {
      "epoch": 1.7890906133734523,
      "grad_norm": 0.1738308072090149,
      "learning_rate": 0.00044688620369140886,
      "loss": 0.378,
      "step": 44000
    },
    {
      "epoch": 1.7890906133734523,
      "eval_loss": 0.38726794719696045,
      "eval_runtime": 114.6349,
      "eval_samples_per_second": 1525.73,
      "eval_steps_per_second": 47.682,
      "step": 44000
    },
    {
      "epoch": 1.7931567284038465,
      "grad_norm": 0.1692916750907898,
      "learning_rate": 0.00044666489620678976,
      "loss": 0.3788,
      "step": 44100
    },
    {
      "epoch": 1.7972228434342408,
      "grad_norm": 0.15900000929832458,
      "learning_rate": 0.0004464435887221706,
      "loss": 0.3778,
      "step": 44200
    },
    {
      "epoch": 1.801288958464635,
      "grad_norm": 0.16875480115413666,
      "learning_rate": 0.0004462222812375515,
      "loss": 0.3765,
      "step": 44300
    },
    {
      "epoch": 1.8053550734950292,
      "grad_norm": 0.19019408524036407,
      "learning_rate": 0.00044600097375293234,
      "loss": 0.3767,
      "step": 44400
    },
    {
      "epoch": 1.8094211885254232,
      "grad_norm": 0.19075684249401093,
      "learning_rate": 0.0004457796662683132,
      "loss": 0.377,
      "step": 44500
    },
    {
      "epoch": 1.8134873035558177,
      "grad_norm": 0.17026638984680176,
      "learning_rate": 0.00044555835878369403,
      "loss": 0.377,
      "step": 44600
    },
    {
      "epoch": 1.8175534185862117,
      "grad_norm": 0.18913710117340088,
      "learning_rate": 0.00044533705129907493,
      "loss": 0.3765,
      "step": 44700
    },
    {
      "epoch": 1.8216195336166061,
      "grad_norm": 0.17886747419834137,
      "learning_rate": 0.00044511574381445577,
      "loss": 0.378,
      "step": 44800
    },
    {
      "epoch": 1.8256856486470001,
      "grad_norm": 0.19342878460884094,
      "learning_rate": 0.00044489443632983667,
      "loss": 0.3756,
      "step": 44900
    },
    {
      "epoch": 1.8297517636773946,
      "grad_norm": 0.1822517067193985,
      "learning_rate": 0.00044467312884521757,
      "loss": 0.3776,
      "step": 45000
    },
    {
      "epoch": 1.8338178787077886,
      "grad_norm": 0.17194832861423492,
      "learning_rate": 0.0004444518213605984,
      "loss": 0.3754,
      "step": 45100
    },
    {
      "epoch": 1.837883993738183,
      "grad_norm": 0.16913817822933197,
      "learning_rate": 0.0004442305138759793,
      "loss": 0.3777,
      "step": 45200
    },
    {
      "epoch": 1.841950108768577,
      "grad_norm": 0.2042103409767151,
      "learning_rate": 0.00044400920639136015,
      "loss": 0.3765,
      "step": 45300
    },
    {
      "epoch": 1.8460162237989712,
      "grad_norm": 0.2138860523700714,
      "learning_rate": 0.00044378789890674105,
      "loss": 0.3742,
      "step": 45400
    },
    {
      "epoch": 1.8500823388293655,
      "grad_norm": 0.18239939212799072,
      "learning_rate": 0.0004435665914221219,
      "loss": 0.3787,
      "step": 45500
    },
    {
      "epoch": 1.8541484538597597,
      "grad_norm": 0.15709859132766724,
      "learning_rate": 0.0004433452839375028,
      "loss": 0.3751,
      "step": 45600
    },
    {
      "epoch": 1.858214568890154,
      "grad_norm": 0.1589701622724533,
      "learning_rate": 0.0004431239764528837,
      "loss": 0.3775,
      "step": 45700
    },
    {
      "epoch": 1.8622806839205481,
      "grad_norm": 0.17945784330368042,
      "learning_rate": 0.00044290266896826453,
      "loss": 0.3762,
      "step": 45800
    },
    {
      "epoch": 1.8663467989509424,
      "grad_norm": 0.18726523220539093,
      "learning_rate": 0.0004426813614836454,
      "loss": 0.3788,
      "step": 45900
    },
    {
      "epoch": 1.8704129139813366,
      "grad_norm": 0.18503068387508392,
      "learning_rate": 0.00044246005399902627,
      "loss": 0.3743,
      "step": 46000
    },
    {
      "epoch": 1.8704129139813366,
      "eval_loss": 0.3854781985282898,
      "eval_runtime": 113.0723,
      "eval_samples_per_second": 1546.816,
      "eval_steps_per_second": 48.341,
      "step": 46000
    },
    {
      "epoch": 1.8744790290117308,
      "grad_norm": 0.16752640902996063,
      "learning_rate": 0.00044223874651440717,
      "loss": 0.3775,
      "step": 46100
    },
    {
      "epoch": 1.8785451440421248,
      "grad_norm": 0.17582270503044128,
      "learning_rate": 0.00044201743902978795,
      "loss": 0.3761,
      "step": 46200
    },
    {
      "epoch": 1.8826112590725192,
      "grad_norm": 0.1814824938774109,
      "learning_rate": 0.00044179613154516885,
      "loss": 0.3776,
      "step": 46300
    },
    {
      "epoch": 1.8866773741029133,
      "grad_norm": 0.18077796697616577,
      "learning_rate": 0.0004415748240605497,
      "loss": 0.3766,
      "step": 46400
    },
    {
      "epoch": 1.8907434891333077,
      "grad_norm": 0.19124667346477509,
      "learning_rate": 0.0004413535165759306,
      "loss": 0.3749,
      "step": 46500
    },
    {
      "epoch": 1.8948096041637017,
      "grad_norm": 0.21159997582435608,
      "learning_rate": 0.0004411322090913115,
      "loss": 0.3759,
      "step": 46600
    },
    {
      "epoch": 1.8988757191940961,
      "grad_norm": 0.17277833819389343,
      "learning_rate": 0.00044091090160669233,
      "loss": 0.3774,
      "step": 46700
    },
    {
      "epoch": 1.9029418342244901,
      "grad_norm": 0.18045209348201752,
      "learning_rate": 0.00044068959412207323,
      "loss": 0.3762,
      "step": 46800
    },
    {
      "epoch": 1.9070079492548844,
      "grad_norm": 0.18333400785923004,
      "learning_rate": 0.00044046828663745407,
      "loss": 0.3763,
      "step": 46900
    },
    {
      "epoch": 1.9110740642852786,
      "grad_norm": 0.19060052931308746,
      "learning_rate": 0.00044024697915283497,
      "loss": 0.3783,
      "step": 47000
    },
    {
      "epoch": 1.9151401793156728,
      "grad_norm": 0.17822855710983276,
      "learning_rate": 0.0004400256716682158,
      "loss": 0.3781,
      "step": 47100
    },
    {
      "epoch": 1.919206294346067,
      "grad_norm": 0.17875495553016663,
      "learning_rate": 0.0004398043641835967,
      "loss": 0.3775,
      "step": 47200
    },
    {
      "epoch": 1.9232724093764613,
      "grad_norm": 0.20363342761993408,
      "learning_rate": 0.00043958305669897755,
      "loss": 0.3763,
      "step": 47300
    },
    {
      "epoch": 1.9273385244068555,
      "grad_norm": 0.16742663085460663,
      "learning_rate": 0.00043936174921435845,
      "loss": 0.3767,
      "step": 47400
    },
    {
      "epoch": 1.9314046394372497,
      "grad_norm": 0.18832941353321075,
      "learning_rate": 0.00043914044172973935,
      "loss": 0.3792,
      "step": 47500
    },
    {
      "epoch": 1.935470754467644,
      "grad_norm": 0.17431262135505676,
      "learning_rate": 0.0004389191342451202,
      "loss": 0.3748,
      "step": 47600
    },
    {
      "epoch": 1.939536869498038,
      "grad_norm": 0.18641801178455353,
      "learning_rate": 0.0004386978267605011,
      "loss": 0.3747,
      "step": 47700
    },
    {
      "epoch": 1.9436029845284324,
      "grad_norm": 0.18447141349315643,
      "learning_rate": 0.00043847651927588193,
      "loss": 0.377,
      "step": 47800
    },
    {
      "epoch": 1.9476690995588264,
      "grad_norm": 0.213841050863266,
      "learning_rate": 0.0004382552117912628,
      "loss": 0.3786,
      "step": 47900
    },
    {
      "epoch": 1.9517352145892208,
      "grad_norm": 0.2009289711713791,
      "learning_rate": 0.0004380339043066436,
      "loss": 0.3751,
      "step": 48000
    },
    {
      "epoch": 1.9517352145892208,
      "eval_loss": 0.38423219323158264,
      "eval_runtime": 115.0815,
      "eval_samples_per_second": 1519.81,
      "eval_steps_per_second": 47.497,
      "step": 48000
    },
    {
      "epoch": 1.9558013296196148,
      "grad_norm": 0.18802237510681152,
      "learning_rate": 0.0004378125968220245,
      "loss": 0.3748,
      "step": 48100
    },
    {
      "epoch": 1.9598674446500093,
      "grad_norm": 0.17042042315006256,
      "learning_rate": 0.00043759128933740536,
      "loss": 0.3772,
      "step": 48200
    },
    {
      "epoch": 1.9639335596804033,
      "grad_norm": 0.1680605709552765,
      "learning_rate": 0.00043736998185278626,
      "loss": 0.3749,
      "step": 48300
    },
    {
      "epoch": 1.9679996747107977,
      "grad_norm": 0.18208782374858856,
      "learning_rate": 0.00043714867436816715,
      "loss": 0.3742,
      "step": 48400
    },
    {
      "epoch": 1.9720657897411917,
      "grad_norm": 0.21357716619968414,
      "learning_rate": 0.000436927366883548,
      "loss": 0.3753,
      "step": 48500
    },
    {
      "epoch": 1.976131904771586,
      "grad_norm": 0.17894908785820007,
      "learning_rate": 0.0004367060593989289,
      "loss": 0.3776,
      "step": 48600
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 0.178484708070755,
      "learning_rate": 0.00043648475191430974,
      "loss": 0.3761,
      "step": 48700
    },
    {
      "epoch": 1.9842641348323744,
      "grad_norm": 0.20862650871276855,
      "learning_rate": 0.00043626344442969063,
      "loss": 0.3765,
      "step": 48800
    },
    {
      "epoch": 1.9883302498627686,
      "grad_norm": 0.2058945894241333,
      "learning_rate": 0.0004360421369450715,
      "loss": 0.3723,
      "step": 48900
    },
    {
      "epoch": 1.9923963648931629,
      "grad_norm": 0.20067435503005981,
      "learning_rate": 0.0004358208294604524,
      "loss": 0.377,
      "step": 49000
    },
    {
      "epoch": 1.996462479923557,
      "grad_norm": 0.199122354388237,
      "learning_rate": 0.00043559952197583327,
      "loss": 0.3732,
      "step": 49100
    },
    {
      "epoch": 2.000528594953951,
      "grad_norm": 0.1995275914669037,
      "learning_rate": 0.0004353782144912141,
      "loss": 0.373,
      "step": 49200
    },
    {
      "epoch": 2.0045947099843455,
      "grad_norm": 0.17948248982429504,
      "learning_rate": 0.000435156907006595,
      "loss": 0.3733,
      "step": 49300
    },
    {
      "epoch": 2.0086608250147395,
      "grad_norm": 0.1957191377878189,
      "learning_rate": 0.00043493559952197586,
      "loss": 0.3709,
      "step": 49400
    },
    {
      "epoch": 2.012726940045134,
      "grad_norm": 0.19660334289073944,
      "learning_rate": 0.00043471429203735675,
      "loss": 0.3716,
      "step": 49500
    },
    {
      "epoch": 2.016793055075528,
      "grad_norm": 0.16370391845703125,
      "learning_rate": 0.00043449298455273754,
      "loss": 0.3693,
      "step": 49600
    },
    {
      "epoch": 2.0208591701059224,
      "grad_norm": 0.1828155219554901,
      "learning_rate": 0.00043427167706811844,
      "loss": 0.3725,
      "step": 49700
    },
    {
      "epoch": 2.0249252851363164,
      "grad_norm": 0.1958947330713272,
      "learning_rate": 0.0004340503695834993,
      "loss": 0.371,
      "step": 49800
    },
    {
      "epoch": 2.028991400166711,
      "grad_norm": 0.18437258899211884,
      "learning_rate": 0.0004338290620988802,
      "loss": 0.3711,
      "step": 49900
    },
    {
      "epoch": 2.033057515197105,
      "grad_norm": 0.2092764526605606,
      "learning_rate": 0.0004336077546142611,
      "loss": 0.3727,
      "step": 50000
    },
    {
      "epoch": 2.033057515197105,
      "eval_loss": 0.384213924407959,
      "eval_runtime": 113.5291,
      "eval_samples_per_second": 1540.591,
      "eval_steps_per_second": 48.146,
      "step": 50000
    },
    {
      "epoch": 2.0371236302274993,
      "grad_norm": 0.19729681313037872,
      "learning_rate": 0.0004333864471296419,
      "loss": 0.3745,
      "step": 50100
    },
    {
      "epoch": 2.0411897452578933,
      "grad_norm": 0.18202975392341614,
      "learning_rate": 0.0004331651396450228,
      "loss": 0.3709,
      "step": 50200
    },
    {
      "epoch": 2.0452558602882878,
      "grad_norm": 0.17813633382320404,
      "learning_rate": 0.00043294383216040366,
      "loss": 0.3723,
      "step": 50300
    },
    {
      "epoch": 2.0493219753186818,
      "grad_norm": 0.18467634916305542,
      "learning_rate": 0.00043272252467578456,
      "loss": 0.3705,
      "step": 50400
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.2009410411119461,
      "learning_rate": 0.0004325012171911654,
      "loss": 0.374,
      "step": 50500
    },
    {
      "epoch": 2.05745420537947,
      "grad_norm": 0.18469078838825226,
      "learning_rate": 0.0004322799097065463,
      "loss": 0.3715,
      "step": 50600
    },
    {
      "epoch": 2.061520320409864,
      "grad_norm": 0.20841620862483978,
      "learning_rate": 0.00043205860222192714,
      "loss": 0.3709,
      "step": 50700
    },
    {
      "epoch": 2.0655864354402587,
      "grad_norm": 0.1796644777059555,
      "learning_rate": 0.00043183729473730804,
      "loss": 0.3699,
      "step": 50800
    },
    {
      "epoch": 2.0696525504706527,
      "grad_norm": 0.20301389694213867,
      "learning_rate": 0.00043161598725268894,
      "loss": 0.3734,
      "step": 50900
    },
    {
      "epoch": 2.073718665501047,
      "grad_norm": 0.2078922986984253,
      "learning_rate": 0.0004313946797680698,
      "loss": 0.3714,
      "step": 51000
    },
    {
      "epoch": 2.077784780531441,
      "grad_norm": 0.17616811394691467,
      "learning_rate": 0.0004311733722834507,
      "loss": 0.371,
      "step": 51100
    },
    {
      "epoch": 2.0818508955618356,
      "grad_norm": 0.18923735618591309,
      "learning_rate": 0.00043095206479883147,
      "loss": 0.3721,
      "step": 51200
    },
    {
      "epoch": 2.0859170105922296,
      "grad_norm": 0.19244883954524994,
      "learning_rate": 0.00043073075731421236,
      "loss": 0.3713,
      "step": 51300
    },
    {
      "epoch": 2.089983125622624,
      "grad_norm": 0.19190743565559387,
      "learning_rate": 0.0004305094498295932,
      "loss": 0.3726,
      "step": 51400
    },
    {
      "epoch": 2.094049240653018,
      "grad_norm": 0.19833697378635406,
      "learning_rate": 0.0004302881423449741,
      "loss": 0.3722,
      "step": 51500
    },
    {
      "epoch": 2.0981153556834125,
      "grad_norm": 0.18784038722515106,
      "learning_rate": 0.00043006683486035495,
      "loss": 0.3719,
      "step": 51600
    },
    {
      "epoch": 2.1021814707138065,
      "grad_norm": 0.2234254628419876,
      "learning_rate": 0.00042984552737573584,
      "loss": 0.3722,
      "step": 51700
    },
    {
      "epoch": 2.106247585744201,
      "grad_norm": 0.1656022071838379,
      "learning_rate": 0.00042962421989111674,
      "loss": 0.3698,
      "step": 51800
    },
    {
      "epoch": 2.110313700774595,
      "grad_norm": 0.20709586143493652,
      "learning_rate": 0.0004294029124064976,
      "loss": 0.3727,
      "step": 51900
    },
    {
      "epoch": 2.1143798158049893,
      "grad_norm": 0.1989307552576065,
      "learning_rate": 0.0004291816049218785,
      "loss": 0.3721,
      "step": 52000
    },
    {
      "epoch": 2.1143798158049893,
      "eval_loss": 0.3826480805873871,
      "eval_runtime": 114.3715,
      "eval_samples_per_second": 1529.245,
      "eval_steps_per_second": 47.792,
      "step": 52000
    },
    {
      "epoch": 2.1184459308353834,
      "grad_norm": 0.19823655486106873,
      "learning_rate": 0.0004289602974372593,
      "loss": 0.3713,
      "step": 52100
    },
    {
      "epoch": 2.1225120458657774,
      "grad_norm": 0.21237647533416748,
      "learning_rate": 0.0004287389899526402,
      "loss": 0.3734,
      "step": 52200
    },
    {
      "epoch": 2.126578160896172,
      "grad_norm": 0.17838868498802185,
      "learning_rate": 0.00042851768246802106,
      "loss": 0.3739,
      "step": 52300
    },
    {
      "epoch": 2.130644275926566,
      "grad_norm": 0.19418978691101074,
      "learning_rate": 0.00042829637498340196,
      "loss": 0.3713,
      "step": 52400
    },
    {
      "epoch": 2.1347103909569602,
      "grad_norm": 0.20627819001674652,
      "learning_rate": 0.00042807506749878286,
      "loss": 0.371,
      "step": 52500
    },
    {
      "epoch": 2.1387765059873542,
      "grad_norm": 0.1956416815519333,
      "learning_rate": 0.0004278537600141637,
      "loss": 0.3724,
      "step": 52600
    },
    {
      "epoch": 2.1428426210177487,
      "grad_norm": 0.1885937601327896,
      "learning_rate": 0.0004276324525295446,
      "loss": 0.3723,
      "step": 52700
    },
    {
      "epoch": 2.1469087360481427,
      "grad_norm": 0.212808758020401,
      "learning_rate": 0.00042741114504492544,
      "loss": 0.3692,
      "step": 52800
    },
    {
      "epoch": 2.150974851078537,
      "grad_norm": 0.19156891107559204,
      "learning_rate": 0.0004271898375603063,
      "loss": 0.3732,
      "step": 52900
    },
    {
      "epoch": 2.155040966108931,
      "grad_norm": 0.17900413274765015,
      "learning_rate": 0.00042696853007568713,
      "loss": 0.373,
      "step": 53000
    },
    {
      "epoch": 2.1591070811393256,
      "grad_norm": 0.20868214964866638,
      "learning_rate": 0.000426747222591068,
      "loss": 0.3701,
      "step": 53100
    },
    {
      "epoch": 2.1631731961697196,
      "grad_norm": 0.17715956270694733,
      "learning_rate": 0.00042652591510644887,
      "loss": 0.3684,
      "step": 53200
    },
    {
      "epoch": 2.167239311200114,
      "grad_norm": 0.19446802139282227,
      "learning_rate": 0.00042630460762182977,
      "loss": 0.3722,
      "step": 53300
    },
    {
      "epoch": 2.171305426230508,
      "grad_norm": 0.18044063448905945,
      "learning_rate": 0.00042608330013721066,
      "loss": 0.3731,
      "step": 53400
    },
    {
      "epoch": 2.175371541260902,
      "grad_norm": 0.1767200082540512,
      "learning_rate": 0.0004258619926525915,
      "loss": 0.3705,
      "step": 53500
    },
    {
      "epoch": 2.1794376562912965,
      "grad_norm": 0.22077631950378418,
      "learning_rate": 0.0004256406851679724,
      "loss": 0.3705,
      "step": 53600
    },
    {
      "epoch": 2.1835037713216905,
      "grad_norm": 0.19100937247276306,
      "learning_rate": 0.00042541937768335325,
      "loss": 0.3699,
      "step": 53700
    },
    {
      "epoch": 2.187569886352085,
      "grad_norm": 0.17393676936626434,
      "learning_rate": 0.00042519807019873415,
      "loss": 0.3715,
      "step": 53800
    },
    {
      "epoch": 2.191636001382479,
      "grad_norm": 0.19367703795433044,
      "learning_rate": 0.000424976762714115,
      "loss": 0.373,
      "step": 53900
    },
    {
      "epoch": 2.1957021164128734,
      "grad_norm": 0.182527557015419,
      "learning_rate": 0.0004247554552294959,
      "loss": 0.3727,
      "step": 54000
    },
    {
      "epoch": 2.1957021164128734,
      "eval_loss": 0.381755530834198,
      "eval_runtime": 112.9866,
      "eval_samples_per_second": 1547.988,
      "eval_steps_per_second": 48.377,
      "step": 54000
    },
    {
      "epoch": 2.1997682314432674,
      "grad_norm": 0.17665278911590576,
      "learning_rate": 0.00042453414774487673,
      "loss": 0.3706,
      "step": 54100
    },
    {
      "epoch": 2.203834346473662,
      "grad_norm": 0.18198361992835999,
      "learning_rate": 0.0004243128402602576,
      "loss": 0.3714,
      "step": 54200
    },
    {
      "epoch": 2.207900461504056,
      "grad_norm": 0.18604382872581482,
      "learning_rate": 0.0004240915327756385,
      "loss": 0.3717,
      "step": 54300
    },
    {
      "epoch": 2.2119665765344503,
      "grad_norm": 0.18278905749320984,
      "learning_rate": 0.00042387022529101937,
      "loss": 0.3697,
      "step": 54400
    },
    {
      "epoch": 2.2160326915648443,
      "grad_norm": 0.18995873630046844,
      "learning_rate": 0.00042364891780640026,
      "loss": 0.3713,
      "step": 54500
    },
    {
      "epoch": 2.2200988065952387,
      "grad_norm": 0.17587193846702576,
      "learning_rate": 0.00042342761032178105,
      "loss": 0.3718,
      "step": 54600
    },
    {
      "epoch": 2.2241649216256327,
      "grad_norm": 0.19497990608215332,
      "learning_rate": 0.00042320630283716195,
      "loss": 0.3731,
      "step": 54700
    },
    {
      "epoch": 2.228231036656027,
      "grad_norm": 0.2010386437177658,
      "learning_rate": 0.0004229849953525428,
      "loss": 0.3705,
      "step": 54800
    },
    {
      "epoch": 2.232297151686421,
      "grad_norm": 0.1806144267320633,
      "learning_rate": 0.0004227636878679237,
      "loss": 0.3736,
      "step": 54900
    },
    {
      "epoch": 2.2363632667168156,
      "grad_norm": 0.18330201506614685,
      "learning_rate": 0.00042254238038330453,
      "loss": 0.373,
      "step": 55000
    },
    {
      "epoch": 2.2404293817472096,
      "grad_norm": 0.19386571645736694,
      "learning_rate": 0.00042232107289868543,
      "loss": 0.37,
      "step": 55100
    },
    {
      "epoch": 2.2444954967776036,
      "grad_norm": 0.195358544588089,
      "learning_rate": 0.00042209976541406633,
      "loss": 0.3697,
      "step": 55200
    },
    {
      "epoch": 2.248561611807998,
      "grad_norm": 0.18936221301555634,
      "learning_rate": 0.00042187845792944717,
      "loss": 0.3689,
      "step": 55300
    },
    {
      "epoch": 2.252627726838392,
      "grad_norm": 0.18405774235725403,
      "learning_rate": 0.00042165715044482807,
      "loss": 0.3713,
      "step": 55400
    },
    {
      "epoch": 2.2566938418687865,
      "grad_norm": 0.20388196408748627,
      "learning_rate": 0.0004214358429602089,
      "loss": 0.3717,
      "step": 55500
    },
    {
      "epoch": 2.2607599568991805,
      "grad_norm": 0.1995549499988556,
      "learning_rate": 0.0004212145354755898,
      "loss": 0.3706,
      "step": 55600
    },
    {
      "epoch": 2.264826071929575,
      "grad_norm": 0.20946004986763,
      "learning_rate": 0.00042099322799097065,
      "loss": 0.3714,
      "step": 55700
    },
    {
      "epoch": 2.268892186959969,
      "grad_norm": 0.17722423374652863,
      "learning_rate": 0.00042077192050635155,
      "loss": 0.3724,
      "step": 55800
    },
    {
      "epoch": 2.2729583019903634,
      "grad_norm": 0.18977169692516327,
      "learning_rate": 0.00042055061302173245,
      "loss": 0.3718,
      "step": 55900
    },
    {
      "epoch": 2.2770244170207574,
      "grad_norm": 0.20935505628585815,
      "learning_rate": 0.0004203293055371133,
      "loss": 0.3727,
      "step": 56000
    },
    {
      "epoch": 2.2770244170207574,
      "eval_loss": 0.3818925619125366,
      "eval_runtime": 114.9283,
      "eval_samples_per_second": 1521.836,
      "eval_steps_per_second": 47.56,
      "step": 56000
    },
    {
      "epoch": 2.281090532051152,
      "grad_norm": 0.2070288509130478,
      "learning_rate": 0.0004201079980524942,
      "loss": 0.3723,
      "step": 56100
    },
    {
      "epoch": 2.285156647081546,
      "grad_norm": 0.2399698942899704,
      "learning_rate": 0.00041988669056787503,
      "loss": 0.3708,
      "step": 56200
    },
    {
      "epoch": 2.2892227621119403,
      "grad_norm": 0.19702087342739105,
      "learning_rate": 0.0004196653830832559,
      "loss": 0.3699,
      "step": 56300
    },
    {
      "epoch": 2.2932888771423343,
      "grad_norm": 0.21237413585186005,
      "learning_rate": 0.0004194440755986367,
      "loss": 0.3708,
      "step": 56400
    },
    {
      "epoch": 2.2973549921727288,
      "grad_norm": 0.2084265798330307,
      "learning_rate": 0.0004192227681140176,
      "loss": 0.3725,
      "step": 56500
    },
    {
      "epoch": 2.3014211072031228,
      "grad_norm": 0.23095393180847168,
      "learning_rate": 0.00041900146062939846,
      "loss": 0.373,
      "step": 56600
    },
    {
      "epoch": 2.305487222233517,
      "grad_norm": 0.19662393629550934,
      "learning_rate": 0.00041878015314477935,
      "loss": 0.3716,
      "step": 56700
    },
    {
      "epoch": 2.309553337263911,
      "grad_norm": 0.21547643840312958,
      "learning_rate": 0.00041855884566016025,
      "loss": 0.3703,
      "step": 56800
    },
    {
      "epoch": 2.313619452294305,
      "grad_norm": 0.18810293078422546,
      "learning_rate": 0.0004183375381755411,
      "loss": 0.3708,
      "step": 56900
    },
    {
      "epoch": 2.3176855673246997,
      "grad_norm": 0.19643478095531464,
      "learning_rate": 0.000418116230690922,
      "loss": 0.3732,
      "step": 57000
    },
    {
      "epoch": 2.3217516823550937,
      "grad_norm": 0.19446660578250885,
      "learning_rate": 0.00041789492320630284,
      "loss": 0.3713,
      "step": 57100
    },
    {
      "epoch": 2.325817797385488,
      "grad_norm": 0.21520297229290009,
      "learning_rate": 0.00041767361572168373,
      "loss": 0.3721,
      "step": 57200
    },
    {
      "epoch": 2.329883912415882,
      "grad_norm": 0.20638494193553925,
      "learning_rate": 0.0004174523082370646,
      "loss": 0.3737,
      "step": 57300
    },
    {
      "epoch": 2.3339500274462766,
      "grad_norm": 0.18633513152599335,
      "learning_rate": 0.0004172310007524455,
      "loss": 0.3681,
      "step": 57400
    },
    {
      "epoch": 2.3380161424766706,
      "grad_norm": 0.19425822794437408,
      "learning_rate": 0.0004170096932678263,
      "loss": 0.3723,
      "step": 57500
    },
    {
      "epoch": 2.342082257507065,
      "grad_norm": 0.22287875413894653,
      "learning_rate": 0.0004167883857832072,
      "loss": 0.3718,
      "step": 57600
    },
    {
      "epoch": 2.346148372537459,
      "grad_norm": 0.2119961529970169,
      "learning_rate": 0.0004165670782985881,
      "loss": 0.3711,
      "step": 57700
    },
    {
      "epoch": 2.3502144875678534,
      "grad_norm": 0.1918611079454422,
      "learning_rate": 0.00041634577081396895,
      "loss": 0.372,
      "step": 57800
    },
    {
      "epoch": 2.3542806025982475,
      "grad_norm": 0.195176899433136,
      "learning_rate": 0.00041612446332934985,
      "loss": 0.3682,
      "step": 57900
    },
    {
      "epoch": 2.358346717628642,
      "grad_norm": 0.1998368203639984,
      "learning_rate": 0.00041590315584473064,
      "loss": 0.3688,
      "step": 58000
    },
    {
      "epoch": 2.358346717628642,
      "eval_loss": 0.3804132044315338,
      "eval_runtime": 113.1337,
      "eval_samples_per_second": 1545.977,
      "eval_steps_per_second": 48.315,
      "step": 58000
    },
    {
      "epoch": 2.362412832659036,
      "grad_norm": 0.19274412095546722,
      "learning_rate": 0.00041568184836011154,
      "loss": 0.3728,
      "step": 58100
    },
    {
      "epoch": 2.36647894768943,
      "grad_norm": 0.21713212132453918,
      "learning_rate": 0.0004154605408754924,
      "loss": 0.3694,
      "step": 58200
    },
    {
      "epoch": 2.3705450627198243,
      "grad_norm": 0.1817326843738556,
      "learning_rate": 0.0004152392333908733,
      "loss": 0.372,
      "step": 58300
    },
    {
      "epoch": 2.374611177750219,
      "grad_norm": 0.17583997547626495,
      "learning_rate": 0.0004150179259062541,
      "loss": 0.3695,
      "step": 58400
    },
    {
      "epoch": 2.378677292780613,
      "grad_norm": 0.2076844722032547,
      "learning_rate": 0.000414796618421635,
      "loss": 0.3736,
      "step": 58500
    },
    {
      "epoch": 2.382743407811007,
      "grad_norm": 0.20806926488876343,
      "learning_rate": 0.0004145753109370159,
      "loss": 0.3722,
      "step": 58600
    },
    {
      "epoch": 2.3868095228414012,
      "grad_norm": 0.21107393503189087,
      "learning_rate": 0.00041435400345239676,
      "loss": 0.3668,
      "step": 58700
    },
    {
      "epoch": 2.3908756378717952,
      "grad_norm": 0.1923091560602188,
      "learning_rate": 0.00041413269596777766,
      "loss": 0.3737,
      "step": 58800
    },
    {
      "epoch": 2.3949417529021897,
      "grad_norm": 0.230495423078537,
      "learning_rate": 0.0004139113884831585,
      "loss": 0.3708,
      "step": 58900
    },
    {
      "epoch": 2.3990078679325837,
      "grad_norm": 0.18940655887126923,
      "learning_rate": 0.0004136900809985394,
      "loss": 0.3706,
      "step": 59000
    },
    {
      "epoch": 2.403073982962978,
      "grad_norm": 0.19727860391139984,
      "learning_rate": 0.00041346877351392024,
      "loss": 0.3693,
      "step": 59100
    },
    {
      "epoch": 2.407140097993372,
      "grad_norm": 0.20932823419570923,
      "learning_rate": 0.00041324746602930114,
      "loss": 0.3718,
      "step": 59200
    },
    {
      "epoch": 2.4112062130237666,
      "grad_norm": 0.21638841927051544,
      "learning_rate": 0.000413026158544682,
      "loss": 0.3706,
      "step": 59300
    },
    {
      "epoch": 2.4152723280541606,
      "grad_norm": 0.20623622834682465,
      "learning_rate": 0.0004128048510600629,
      "loss": 0.3704,
      "step": 59400
    },
    {
      "epoch": 2.419338443084555,
      "grad_norm": 0.17957612872123718,
      "learning_rate": 0.0004125835435754438,
      "loss": 0.3701,
      "step": 59500
    },
    {
      "epoch": 2.423404558114949,
      "grad_norm": 0.1919318437576294,
      "learning_rate": 0.0004123622360908246,
      "loss": 0.3718,
      "step": 59600
    },
    {
      "epoch": 2.4274706731453435,
      "grad_norm": 0.19173017144203186,
      "learning_rate": 0.00041214092860620546,
      "loss": 0.3703,
      "step": 59700
    },
    {
      "epoch": 2.4315367881757375,
      "grad_norm": 0.2057790458202362,
      "learning_rate": 0.0004119196211215863,
      "loss": 0.3693,
      "step": 59800
    },
    {
      "epoch": 2.4356029032061315,
      "grad_norm": 0.19554775953292847,
      "learning_rate": 0.0004116983136369672,
      "loss": 0.3699,
      "step": 59900
    },
    {
      "epoch": 2.439669018236526,
      "grad_norm": 0.19533585011959076,
      "learning_rate": 0.00041147700615234804,
      "loss": 0.3702,
      "step": 60000
    },
    {
      "epoch": 2.439669018236526,
      "eval_loss": 0.38036754727363586,
      "eval_runtime": 113.0667,
      "eval_samples_per_second": 1546.892,
      "eval_steps_per_second": 48.343,
      "step": 60000
    },
    {
      "epoch": 2.44373513326692,
      "grad_norm": 0.20428356528282166,
      "learning_rate": 0.00041125569866772894,
      "loss": 0.3688,
      "step": 60100
    },
    {
      "epoch": 2.4478012482973144,
      "grad_norm": 0.21108375489711761,
      "learning_rate": 0.00041103439118310984,
      "loss": 0.3726,
      "step": 60200
    },
    {
      "epoch": 2.4518673633277084,
      "grad_norm": 0.1916787326335907,
      "learning_rate": 0.0004108130836984907,
      "loss": 0.3687,
      "step": 60300
    },
    {
      "epoch": 2.455933478358103,
      "grad_norm": 0.22268512845039368,
      "learning_rate": 0.0004105917762138716,
      "loss": 0.3694,
      "step": 60400
    },
    {
      "epoch": 2.459999593388497,
      "grad_norm": 0.24069646000862122,
      "learning_rate": 0.0004103704687292524,
      "loss": 0.3695,
      "step": 60500
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 0.20643742382526398,
      "learning_rate": 0.0004101491612446333,
      "loss": 0.3709,
      "step": 60600
    },
    {
      "epoch": 2.4681318234492853,
      "grad_norm": 0.19741280376911163,
      "learning_rate": 0.00040992785376001416,
      "loss": 0.3695,
      "step": 60700
    },
    {
      "epoch": 2.4721979384796797,
      "grad_norm": 0.21784335374832153,
      "learning_rate": 0.00040970654627539506,
      "loss": 0.3693,
      "step": 60800
    },
    {
      "epoch": 2.4762640535100737,
      "grad_norm": 0.21541687846183777,
      "learning_rate": 0.0004094852387907759,
      "loss": 0.3699,
      "step": 60900
    },
    {
      "epoch": 2.480330168540468,
      "grad_norm": 0.22053195536136627,
      "learning_rate": 0.0004092639313061568,
      "loss": 0.3684,
      "step": 61000
    },
    {
      "epoch": 2.484396283570862,
      "grad_norm": 0.22067196667194366,
      "learning_rate": 0.0004090426238215377,
      "loss": 0.3715,
      "step": 61100
    },
    {
      "epoch": 2.4884623986012566,
      "grad_norm": 0.19580237567424774,
      "learning_rate": 0.00040882131633691854,
      "loss": 0.3701,
      "step": 61200
    },
    {
      "epoch": 2.4925285136316506,
      "grad_norm": 0.22343391180038452,
      "learning_rate": 0.00040860000885229944,
      "loss": 0.3705,
      "step": 61300
    },
    {
      "epoch": 2.496594628662045,
      "grad_norm": 0.1889372169971466,
      "learning_rate": 0.00040837870136768023,
      "loss": 0.37,
      "step": 61400
    },
    {
      "epoch": 2.500660743692439,
      "grad_norm": 0.21402320265769958,
      "learning_rate": 0.0004081573938830611,
      "loss": 0.3689,
      "step": 61500
    },
    {
      "epoch": 2.504726858722833,
      "grad_norm": 0.2184494435787201,
      "learning_rate": 0.00040793608639844197,
      "loss": 0.3707,
      "step": 61600
    },
    {
      "epoch": 2.5087929737532275,
      "grad_norm": 0.18112356960773468,
      "learning_rate": 0.00040771477891382287,
      "loss": 0.3693,
      "step": 61700
    },
    {
      "epoch": 2.512859088783622,
      "grad_norm": 0.18786178529262543,
      "learning_rate": 0.0004074934714292037,
      "loss": 0.3694,
      "step": 61800
    },
    {
      "epoch": 2.516925203814016,
      "grad_norm": 0.2170681208372116,
      "learning_rate": 0.0004072721639445846,
      "loss": 0.3688,
      "step": 61900
    },
    {
      "epoch": 2.52099131884441,
      "grad_norm": 0.2257929891347885,
      "learning_rate": 0.0004070508564599655,
      "loss": 0.3697,
      "step": 62000
    },
    {
      "epoch": 2.52099131884441,
      "eval_loss": 0.3793625235557556,
      "eval_runtime": 113.3658,
      "eval_samples_per_second": 1542.811,
      "eval_steps_per_second": 48.216,
      "step": 62000
    },
    {
      "epoch": 2.5250574338748044,
      "grad_norm": 0.17627790570259094,
      "learning_rate": 0.00040682954897534635,
      "loss": 0.3705,
      "step": 62100
    },
    {
      "epoch": 2.5291235489051984,
      "grad_norm": 0.19965514540672302,
      "learning_rate": 0.00040660824149072724,
      "loss": 0.3688,
      "step": 62200
    },
    {
      "epoch": 2.533189663935593,
      "grad_norm": 0.20229530334472656,
      "learning_rate": 0.0004063869340061081,
      "loss": 0.3699,
      "step": 62300
    },
    {
      "epoch": 2.537255778965987,
      "grad_norm": 0.1980466991662979,
      "learning_rate": 0.000406165626521489,
      "loss": 0.3725,
      "step": 62400
    },
    {
      "epoch": 2.5413218939963813,
      "grad_norm": 0.21112623810768127,
      "learning_rate": 0.00040594431903686983,
      "loss": 0.3696,
      "step": 62500
    },
    {
      "epoch": 2.5453880090267753,
      "grad_norm": 0.21149572730064392,
      "learning_rate": 0.0004057230115522507,
      "loss": 0.3693,
      "step": 62600
    },
    {
      "epoch": 2.5494541240571698,
      "grad_norm": 0.20750200748443604,
      "learning_rate": 0.00040550170406763157,
      "loss": 0.3699,
      "step": 62700
    },
    {
      "epoch": 2.5535202390875638,
      "grad_norm": 0.17512211203575134,
      "learning_rate": 0.00040528039658301246,
      "loss": 0.3706,
      "step": 62800
    },
    {
      "epoch": 2.5575863541179578,
      "grad_norm": 0.22345274686813354,
      "learning_rate": 0.00040505908909839336,
      "loss": 0.3703,
      "step": 62900
    },
    {
      "epoch": 2.561652469148352,
      "grad_norm": 0.20513208210468292,
      "learning_rate": 0.00040483778161377415,
      "loss": 0.3708,
      "step": 63000
    },
    {
      "epoch": 2.5657185841787467,
      "grad_norm": 0.2223934382200241,
      "learning_rate": 0.00040461647412915505,
      "loss": 0.3682,
      "step": 63100
    },
    {
      "epoch": 2.5697846992091407,
      "grad_norm": 0.18683555722236633,
      "learning_rate": 0.0004043951666445359,
      "loss": 0.3693,
      "step": 63200
    },
    {
      "epoch": 2.5738508142395347,
      "grad_norm": 0.19622817635536194,
      "learning_rate": 0.0004041738591599168,
      "loss": 0.3688,
      "step": 63300
    },
    {
      "epoch": 2.577916929269929,
      "grad_norm": 0.2093624323606491,
      "learning_rate": 0.00040395255167529763,
      "loss": 0.3706,
      "step": 63400
    },
    {
      "epoch": 2.581983044300323,
      "grad_norm": 0.1950322836637497,
      "learning_rate": 0.00040373124419067853,
      "loss": 0.3691,
      "step": 63500
    },
    {
      "epoch": 2.5860491593307176,
      "grad_norm": 0.20656178891658783,
      "learning_rate": 0.00040350993670605937,
      "loss": 0.3702,
      "step": 63600
    },
    {
      "epoch": 2.5901152743611116,
      "grad_norm": 0.19746530055999756,
      "learning_rate": 0.00040328862922144027,
      "loss": 0.3687,
      "step": 63700
    },
    {
      "epoch": 2.594181389391506,
      "grad_norm": 0.1895180493593216,
      "learning_rate": 0.00040306732173682117,
      "loss": 0.371,
      "step": 63800
    },
    {
      "epoch": 2.5982475044219,
      "grad_norm": 0.20080116391181946,
      "learning_rate": 0.000402846014252202,
      "loss": 0.3714,
      "step": 63900
    },
    {
      "epoch": 2.6023136194522944,
      "grad_norm": 0.171073317527771,
      "learning_rate": 0.0004026247067675829,
      "loss": 0.3682,
      "step": 64000
    },
    {
      "epoch": 2.6023136194522944,
      "eval_loss": 0.37898433208465576,
      "eval_runtime": 113.3743,
      "eval_samples_per_second": 1542.696,
      "eval_steps_per_second": 48.212,
      "step": 64000
    },
    {
      "epoch": 2.6063797344826884,
      "grad_norm": 0.23026685416698456,
      "learning_rate": 0.00040240339928296375,
      "loss": 0.3694,
      "step": 64100
    },
    {
      "epoch": 2.6104458495130825,
      "grad_norm": 0.1923265904188156,
      "learning_rate": 0.00040218209179834465,
      "loss": 0.3699,
      "step": 64200
    },
    {
      "epoch": 2.614511964543477,
      "grad_norm": 0.19449368119239807,
      "learning_rate": 0.0004019607843137255,
      "loss": 0.3696,
      "step": 64300
    },
    {
      "epoch": 2.6185780795738713,
      "grad_norm": 0.20637965202331543,
      "learning_rate": 0.0004017394768291064,
      "loss": 0.3696,
      "step": 64400
    },
    {
      "epoch": 2.6226441946042653,
      "grad_norm": 0.19333648681640625,
      "learning_rate": 0.0004015181693444873,
      "loss": 0.3704,
      "step": 64500
    },
    {
      "epoch": 2.6267103096346593,
      "grad_norm": 0.21410633623600006,
      "learning_rate": 0.00040129686185986813,
      "loss": 0.3698,
      "step": 64600
    },
    {
      "epoch": 2.630776424665054,
      "grad_norm": 0.20277202129364014,
      "learning_rate": 0.00040107555437524897,
      "loss": 0.3713,
      "step": 64700
    },
    {
      "epoch": 2.6348425396954482,
      "grad_norm": 0.21644817292690277,
      "learning_rate": 0.0004008542468906298,
      "loss": 0.367,
      "step": 64800
    },
    {
      "epoch": 2.6389086547258422,
      "grad_norm": 0.18942472338676453,
      "learning_rate": 0.0004006329394060107,
      "loss": 0.3667,
      "step": 64900
    },
    {
      "epoch": 2.6429747697562362,
      "grad_norm": 0.21844638884067535,
      "learning_rate": 0.00040041163192139156,
      "loss": 0.3696,
      "step": 65000
    },
    {
      "epoch": 2.6470408847866307,
      "grad_norm": 0.205843985080719,
      "learning_rate": 0.00040019032443677245,
      "loss": 0.3695,
      "step": 65100
    },
    {
      "epoch": 2.6511069998170247,
      "grad_norm": 0.22281908988952637,
      "learning_rate": 0.0003999690169521533,
      "loss": 0.3698,
      "step": 65200
    },
    {
      "epoch": 2.655173114847419,
      "grad_norm": 0.20819321274757385,
      "learning_rate": 0.0003997477094675342,
      "loss": 0.37,
      "step": 65300
    },
    {
      "epoch": 2.659239229877813,
      "grad_norm": 0.21232318878173828,
      "learning_rate": 0.0003995264019829151,
      "loss": 0.37,
      "step": 65400
    },
    {
      "epoch": 2.6633053449082076,
      "grad_norm": 0.19263407588005066,
      "learning_rate": 0.00039930509449829593,
      "loss": 0.3703,
      "step": 65500
    },
    {
      "epoch": 2.6673714599386016,
      "grad_norm": 0.19186903536319733,
      "learning_rate": 0.00039908378701367683,
      "loss": 0.3679,
      "step": 65600
    },
    {
      "epoch": 2.671437574968996,
      "grad_norm": 0.223171204328537,
      "learning_rate": 0.0003988624795290577,
      "loss": 0.3681,
      "step": 65700
    },
    {
      "epoch": 2.67550368999939,
      "grad_norm": 0.21140259504318237,
      "learning_rate": 0.00039864117204443857,
      "loss": 0.3714,
      "step": 65800
    },
    {
      "epoch": 2.679569805029784,
      "grad_norm": 0.1920744627714157,
      "learning_rate": 0.0003984198645598194,
      "loss": 0.3674,
      "step": 65900
    },
    {
      "epoch": 2.6836359200601785,
      "grad_norm": 0.20200876891613007,
      "learning_rate": 0.0003981985570752003,
      "loss": 0.3702,
      "step": 66000
    },
    {
      "epoch": 2.6836359200601785,
      "eval_loss": 0.37832656502723694,
      "eval_runtime": 113.898,
      "eval_samples_per_second": 1535.602,
      "eval_steps_per_second": 47.99,
      "step": 66000
    },
    {
      "epoch": 2.687702035090573,
      "grad_norm": 0.19877219200134277,
      "learning_rate": 0.00039797724959058116,
      "loss": 0.3691,
      "step": 66100
    },
    {
      "epoch": 2.691768150120967,
      "grad_norm": 0.21537615358829498,
      "learning_rate": 0.00039775594210596205,
      "loss": 0.3702,
      "step": 66200
    },
    {
      "epoch": 2.695834265151361,
      "grad_norm": 0.19561436772346497,
      "learning_rate": 0.00039753463462134295,
      "loss": 0.3672,
      "step": 66300
    },
    {
      "epoch": 2.6999003801817554,
      "grad_norm": 0.20860697329044342,
      "learning_rate": 0.00039731332713672374,
      "loss": 0.3686,
      "step": 66400
    },
    {
      "epoch": 2.70396649521215,
      "grad_norm": 0.20868441462516785,
      "learning_rate": 0.00039709201965210464,
      "loss": 0.3697,
      "step": 66500
    },
    {
      "epoch": 2.708032610242544,
      "grad_norm": 0.20754121243953705,
      "learning_rate": 0.0003968707121674855,
      "loss": 0.3679,
      "step": 66600
    },
    {
      "epoch": 2.712098725272938,
      "grad_norm": 0.2012416571378708,
      "learning_rate": 0.0003966494046828664,
      "loss": 0.3684,
      "step": 66700
    },
    {
      "epoch": 2.7161648403033323,
      "grad_norm": 0.19646427035331726,
      "learning_rate": 0.0003964280971982472,
      "loss": 0.3689,
      "step": 66800
    },
    {
      "epoch": 2.7202309553337263,
      "grad_norm": 0.20145146548748016,
      "learning_rate": 0.0003962067897136281,
      "loss": 0.3695,
      "step": 66900
    },
    {
      "epoch": 2.7242970703641207,
      "grad_norm": 0.2083619236946106,
      "learning_rate": 0.00039598548222900896,
      "loss": 0.3691,
      "step": 67000
    },
    {
      "epoch": 2.7283631853945147,
      "grad_norm": 0.22253236174583435,
      "learning_rate": 0.00039576417474438986,
      "loss": 0.3678,
      "step": 67100
    },
    {
      "epoch": 2.732429300424909,
      "grad_norm": 0.20101694762706757,
      "learning_rate": 0.00039554286725977075,
      "loss": 0.3687,
      "step": 67200
    },
    {
      "epoch": 2.736495415455303,
      "grad_norm": 0.21736669540405273,
      "learning_rate": 0.0003953215597751516,
      "loss": 0.3689,
      "step": 67300
    },
    {
      "epoch": 2.7405615304856976,
      "grad_norm": 0.241350457072258,
      "learning_rate": 0.0003951002522905325,
      "loss": 0.3693,
      "step": 67400
    },
    {
      "epoch": 2.7446276455160916,
      "grad_norm": 0.21437367796897888,
      "learning_rate": 0.00039487894480591334,
      "loss": 0.3704,
      "step": 67500
    },
    {
      "epoch": 2.7486937605464856,
      "grad_norm": 0.20825143158435822,
      "learning_rate": 0.00039465763732129424,
      "loss": 0.3707,
      "step": 67600
    },
    {
      "epoch": 2.75275987557688,
      "grad_norm": 0.2044900357723236,
      "learning_rate": 0.0003944363298366751,
      "loss": 0.3685,
      "step": 67700
    },
    {
      "epoch": 2.7568259906072745,
      "grad_norm": 0.21657349169254303,
      "learning_rate": 0.000394215022352056,
      "loss": 0.3688,
      "step": 67800
    },
    {
      "epoch": 2.7608921056376685,
      "grad_norm": 0.23238375782966614,
      "learning_rate": 0.0003939937148674369,
      "loss": 0.3682,
      "step": 67900
    },
    {
      "epoch": 2.7649582206680625,
      "grad_norm": 0.2308778315782547,
      "learning_rate": 0.0003937724073828177,
      "loss": 0.3698,
      "step": 68000
    },
    {
      "epoch": 2.7649582206680625,
      "eval_loss": 0.37860721349716187,
      "eval_runtime": 113.6445,
      "eval_samples_per_second": 1539.028,
      "eval_steps_per_second": 48.097,
      "step": 68000
    },
    {
      "epoch": 2.769024335698457,
      "grad_norm": 0.19481121003627777,
      "learning_rate": 0.00039355109989819856,
      "loss": 0.3687,
      "step": 68100
    },
    {
      "epoch": 2.773090450728851,
      "grad_norm": 0.2218111753463745,
      "learning_rate": 0.0003933297924135794,
      "loss": 0.3697,
      "step": 68200
    },
    {
      "epoch": 2.7771565657592454,
      "grad_norm": 0.20530696213245392,
      "learning_rate": 0.0003931084849289603,
      "loss": 0.3661,
      "step": 68300
    },
    {
      "epoch": 2.7812226807896394,
      "grad_norm": 0.18982282280921936,
      "learning_rate": 0.00039288717744434114,
      "loss": 0.3678,
      "step": 68400
    },
    {
      "epoch": 2.785288795820034,
      "grad_norm": 0.2217826247215271,
      "learning_rate": 0.00039266586995972204,
      "loss": 0.3685,
      "step": 68500
    },
    {
      "epoch": 2.789354910850428,
      "grad_norm": 0.23023128509521484,
      "learning_rate": 0.0003924445624751029,
      "loss": 0.3705,
      "step": 68600
    },
    {
      "epoch": 2.7934210258808223,
      "grad_norm": 0.22178985178470612,
      "learning_rate": 0.0003922232549904838,
      "loss": 0.3686,
      "step": 68700
    },
    {
      "epoch": 2.7974871409112163,
      "grad_norm": 0.18226148188114166,
      "learning_rate": 0.0003920019475058647,
      "loss": 0.3689,
      "step": 68800
    },
    {
      "epoch": 2.8015532559416108,
      "grad_norm": 0.20779137313365936,
      "learning_rate": 0.0003917806400212455,
      "loss": 0.3696,
      "step": 68900
    },
    {
      "epoch": 2.8056193709720048,
      "grad_norm": 0.21058854460716248,
      "learning_rate": 0.0003915593325366264,
      "loss": 0.369,
      "step": 69000
    },
    {
      "epoch": 2.809685486002399,
      "grad_norm": 0.20524470508098602,
      "learning_rate": 0.00039133802505200726,
      "loss": 0.3685,
      "step": 69100
    },
    {
      "epoch": 2.813751601032793,
      "grad_norm": 0.22228704392910004,
      "learning_rate": 0.00039111671756738816,
      "loss": 0.3694,
      "step": 69200
    },
    {
      "epoch": 2.817817716063187,
      "grad_norm": 0.21044962108135223,
      "learning_rate": 0.000390895410082769,
      "loss": 0.3696,
      "step": 69300
    },
    {
      "epoch": 2.8218838310935817,
      "grad_norm": 0.22367534041404724,
      "learning_rate": 0.0003906741025981499,
      "loss": 0.3671,
      "step": 69400
    },
    {
      "epoch": 2.825949946123976,
      "grad_norm": 0.226939395070076,
      "learning_rate": 0.00039045279511353074,
      "loss": 0.3671,
      "step": 69500
    },
    {
      "epoch": 2.83001606115437,
      "grad_norm": 0.21960793435573578,
      "learning_rate": 0.00039023148762891164,
      "loss": 0.3672,
      "step": 69600
    },
    {
      "epoch": 2.834082176184764,
      "grad_norm": 0.2324380874633789,
      "learning_rate": 0.00039001018014429254,
      "loss": 0.3692,
      "step": 69700
    },
    {
      "epoch": 2.8381482912151585,
      "grad_norm": 0.21502996981143951,
      "learning_rate": 0.0003897888726596733,
      "loss": 0.368,
      "step": 69800
    },
    {
      "epoch": 2.8422144062455525,
      "grad_norm": 0.21483738720417023,
      "learning_rate": 0.0003895675651750542,
      "loss": 0.3686,
      "step": 69900
    },
    {
      "epoch": 2.846280521275947,
      "grad_norm": 0.20395790040493011,
      "learning_rate": 0.00038934625769043507,
      "loss": 0.3667,
      "step": 70000
    },
    {
      "epoch": 2.846280521275947,
      "eval_loss": 0.37762799859046936,
      "eval_runtime": 115.4805,
      "eval_samples_per_second": 1514.559,
      "eval_steps_per_second": 47.333,
      "step": 70000
    },
    {
      "epoch": 2.850346636306341,
      "grad_norm": 0.2073802649974823,
      "learning_rate": 0.00038912495020581596,
      "loss": 0.3705,
      "step": 70100
    },
    {
      "epoch": 2.8544127513367354,
      "grad_norm": 0.20674926042556763,
      "learning_rate": 0.0003889036427211968,
      "loss": 0.368,
      "step": 70200
    },
    {
      "epoch": 2.8584788663671294,
      "grad_norm": 0.21856892108917236,
      "learning_rate": 0.0003886823352365777,
      "loss": 0.368,
      "step": 70300
    },
    {
      "epoch": 2.862544981397524,
      "grad_norm": 0.2100791186094284,
      "learning_rate": 0.00038846102775195855,
      "loss": 0.3675,
      "step": 70400
    },
    {
      "epoch": 2.866611096427918,
      "grad_norm": 0.21210981905460358,
      "learning_rate": 0.00038823972026733944,
      "loss": 0.3684,
      "step": 70500
    },
    {
      "epoch": 2.870677211458312,
      "grad_norm": 0.21681077778339386,
      "learning_rate": 0.00038801841278272034,
      "loss": 0.3703,
      "step": 70600
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 0.22197185456752777,
      "learning_rate": 0.0003877971052981012,
      "loss": 0.3684,
      "step": 70700
    },
    {
      "epoch": 2.878809441519101,
      "grad_norm": 0.2148130238056183,
      "learning_rate": 0.0003875757978134821,
      "loss": 0.3697,
      "step": 70800
    },
    {
      "epoch": 2.882875556549495,
      "grad_norm": 0.22621871531009674,
      "learning_rate": 0.0003873544903288629,
      "loss": 0.3676,
      "step": 70900
    },
    {
      "epoch": 2.886941671579889,
      "grad_norm": 0.21813061833381653,
      "learning_rate": 0.0003871331828442438,
      "loss": 0.3699,
      "step": 71000
    },
    {
      "epoch": 2.8910077866102832,
      "grad_norm": 0.2194276750087738,
      "learning_rate": 0.00038691187535962467,
      "loss": 0.3663,
      "step": 71100
    },
    {
      "epoch": 2.8950739016406777,
      "grad_norm": 0.20677869021892548,
      "learning_rate": 0.00038669056787500556,
      "loss": 0.3678,
      "step": 71200
    },
    {
      "epoch": 2.8991400166710717,
      "grad_norm": 0.23064269125461578,
      "learning_rate": 0.00038646926039038646,
      "loss": 0.3686,
      "step": 71300
    },
    {
      "epoch": 2.9032061317014657,
      "grad_norm": 0.2430489957332611,
      "learning_rate": 0.0003862479529057673,
      "loss": 0.367,
      "step": 71400
    },
    {
      "epoch": 2.90727224673186,
      "grad_norm": 0.25174790620803833,
      "learning_rate": 0.00038602664542114815,
      "loss": 0.3695,
      "step": 71500
    },
    {
      "epoch": 2.911338361762254,
      "grad_norm": 0.22741156816482544,
      "learning_rate": 0.000385805337936529,
      "loss": 0.3689,
      "step": 71600
    },
    {
      "epoch": 2.9154044767926486,
      "grad_norm": 0.19789251685142517,
      "learning_rate": 0.0003855840304519099,
      "loss": 0.3665,
      "step": 71700
    },
    {
      "epoch": 2.9194705918230426,
      "grad_norm": 0.21792860329151154,
      "learning_rate": 0.00038536272296729073,
      "loss": 0.3672,
      "step": 71800
    },
    {
      "epoch": 2.923536706853437,
      "grad_norm": 0.23608335852622986,
      "learning_rate": 0.00038514141548267163,
      "loss": 0.3674,
      "step": 71900
    },
    {
      "epoch": 2.927602821883831,
      "grad_norm": 0.22070491313934326,
      "learning_rate": 0.00038492010799805247,
      "loss": 0.3679,
      "step": 72000
    },
    {
      "epoch": 2.927602821883831,
      "eval_loss": 0.37641826272010803,
      "eval_runtime": 113.5619,
      "eval_samples_per_second": 1540.147,
      "eval_steps_per_second": 48.132,
      "step": 72000
    },
    {
      "epoch": 2.9316689369142255,
      "grad_norm": 0.2431478351354599,
      "learning_rate": 0.00038469880051343337,
      "loss": 0.3658,
      "step": 72100
    },
    {
      "epoch": 2.9357350519446195,
      "grad_norm": 0.21024899184703827,
      "learning_rate": 0.00038447749302881427,
      "loss": 0.3673,
      "step": 72200
    },
    {
      "epoch": 2.9398011669750135,
      "grad_norm": 0.22182950377464294,
      "learning_rate": 0.0003842561855441951,
      "loss": 0.3671,
      "step": 72300
    },
    {
      "epoch": 2.943867282005408,
      "grad_norm": 0.2139863818883896,
      "learning_rate": 0.000384034878059576,
      "loss": 0.3684,
      "step": 72400
    },
    {
      "epoch": 2.9479333970358024,
      "grad_norm": 0.24841172993183136,
      "learning_rate": 0.00038381357057495685,
      "loss": 0.3655,
      "step": 72500
    },
    {
      "epoch": 2.9519995120661964,
      "grad_norm": 0.2080947458744049,
      "learning_rate": 0.00038359226309033775,
      "loss": 0.367,
      "step": 72600
    },
    {
      "epoch": 2.9560656270965904,
      "grad_norm": 0.19960899651050568,
      "learning_rate": 0.0003833709556057186,
      "loss": 0.3673,
      "step": 72700
    },
    {
      "epoch": 2.960131742126985,
      "grad_norm": 0.2463008463382721,
      "learning_rate": 0.0003831496481210995,
      "loss": 0.3678,
      "step": 72800
    },
    {
      "epoch": 2.964197857157379,
      "grad_norm": 0.2179805487394333,
      "learning_rate": 0.00038292834063648033,
      "loss": 0.3669,
      "step": 72900
    },
    {
      "epoch": 2.9682639721877733,
      "grad_norm": 0.21731188893318176,
      "learning_rate": 0.00038270703315186123,
      "loss": 0.3677,
      "step": 73000
    },
    {
      "epoch": 2.9723300872181673,
      "grad_norm": 0.2494715005159378,
      "learning_rate": 0.0003824857256672421,
      "loss": 0.3675,
      "step": 73100
    },
    {
      "epoch": 2.9763962022485617,
      "grad_norm": 0.1997949481010437,
      "learning_rate": 0.0003822644181826229,
      "loss": 0.3658,
      "step": 73200
    },
    {
      "epoch": 2.9804623172789557,
      "grad_norm": 0.22874385118484497,
      "learning_rate": 0.0003820431106980038,
      "loss": 0.3668,
      "step": 73300
    },
    {
      "epoch": 2.98452843230935,
      "grad_norm": 0.2056456059217453,
      "learning_rate": 0.00038182180321338465,
      "loss": 0.3681,
      "step": 73400
    },
    {
      "epoch": 2.988594547339744,
      "grad_norm": 0.22057102620601654,
      "learning_rate": 0.00038160049572876555,
      "loss": 0.3669,
      "step": 73500
    },
    {
      "epoch": 2.9926606623701386,
      "grad_norm": 0.21346813440322876,
      "learning_rate": 0.0003813791882441464,
      "loss": 0.3673,
      "step": 73600
    },
    {
      "epoch": 2.9967267774005326,
      "grad_norm": 0.2134305238723755,
      "learning_rate": 0.0003811578807595273,
      "loss": 0.3657,
      "step": 73700
    },
    {
      "epoch": 3.000792892430927,
      "grad_norm": 0.2350054681301117,
      "learning_rate": 0.00038093657327490813,
      "loss": 0.368,
      "step": 73800
    },
    {
      "epoch": 3.004859007461321,
      "grad_norm": 0.227524071931839,
      "learning_rate": 0.00038071526579028903,
      "loss": 0.3629,
      "step": 73900
    },
    {
      "epoch": 3.0089251224917155,
      "grad_norm": 0.21519970893859863,
      "learning_rate": 0.00038049395830566993,
      "loss": 0.3621,
      "step": 74000
    },
    {
      "epoch": 3.0089251224917155,
      "eval_loss": 0.3764563202857971,
      "eval_runtime": 117.152,
      "eval_samples_per_second": 1492.949,
      "eval_steps_per_second": 46.657,
      "step": 74000
    },
    {
      "epoch": 3.0129912375221095,
      "grad_norm": 0.2178466022014618,
      "learning_rate": 0.00038027265082105077,
      "loss": 0.364,
      "step": 74100
    },
    {
      "epoch": 3.0170573525525035,
      "grad_norm": 0.24678027629852295,
      "learning_rate": 0.00038005134333643167,
      "loss": 0.3648,
      "step": 74200
    },
    {
      "epoch": 3.021123467582898,
      "grad_norm": 0.23198240995407104,
      "learning_rate": 0.0003798300358518125,
      "loss": 0.363,
      "step": 74300
    },
    {
      "epoch": 3.025189582613292,
      "grad_norm": 0.2110670506954193,
      "learning_rate": 0.0003796087283671934,
      "loss": 0.3634,
      "step": 74400
    },
    {
      "epoch": 3.0292556976436864,
      "grad_norm": 0.20869728922843933,
      "learning_rate": 0.00037938742088257425,
      "loss": 0.363,
      "step": 74500
    },
    {
      "epoch": 3.0333218126740804,
      "grad_norm": 0.21939483284950256,
      "learning_rate": 0.00037916611339795515,
      "loss": 0.363,
      "step": 74600
    },
    {
      "epoch": 3.037387927704475,
      "grad_norm": 0.25552698969841003,
      "learning_rate": 0.00037894480591333605,
      "loss": 0.3644,
      "step": 74700
    },
    {
      "epoch": 3.041454042734869,
      "grad_norm": 0.24958957731723785,
      "learning_rate": 0.00037872349842871684,
      "loss": 0.3621,
      "step": 74800
    },
    {
      "epoch": 3.0455201577652633,
      "grad_norm": 0.24743805825710297,
      "learning_rate": 0.00037850219094409773,
      "loss": 0.3648,
      "step": 74900
    },
    {
      "epoch": 3.0495862727956573,
      "grad_norm": 0.20606563985347748,
      "learning_rate": 0.0003782808834594786,
      "loss": 0.3634,
      "step": 75000
    },
    {
      "epoch": 3.0536523878260518,
      "grad_norm": 0.23493057489395142,
      "learning_rate": 0.0003780595759748595,
      "loss": 0.3618,
      "step": 75100
    },
    {
      "epoch": 3.0577185028564458,
      "grad_norm": 0.23337361216545105,
      "learning_rate": 0.0003778382684902403,
      "loss": 0.3637,
      "step": 75200
    },
    {
      "epoch": 3.06178461788684,
      "grad_norm": 0.20379818975925446,
      "learning_rate": 0.0003776169610056212,
      "loss": 0.3647,
      "step": 75300
    },
    {
      "epoch": 3.065850732917234,
      "grad_norm": 0.2287321537733078,
      "learning_rate": 0.00037739565352100206,
      "loss": 0.3622,
      "step": 75400
    },
    {
      "epoch": 3.0699168479476286,
      "grad_norm": 0.2091902792453766,
      "learning_rate": 0.00037717434603638296,
      "loss": 0.3635,
      "step": 75500
    },
    {
      "epoch": 3.0739829629780226,
      "grad_norm": 0.23779474198818207,
      "learning_rate": 0.00037695303855176385,
      "loss": 0.3623,
      "step": 75600
    },
    {
      "epoch": 3.0780490780084167,
      "grad_norm": 0.22022688388824463,
      "learning_rate": 0.0003767317310671447,
      "loss": 0.3644,
      "step": 75700
    },
    {
      "epoch": 3.082115193038811,
      "grad_norm": 0.23517249524593353,
      "learning_rate": 0.0003765104235825256,
      "loss": 0.3637,
      "step": 75800
    },
    {
      "epoch": 3.086181308069205,
      "grad_norm": 0.22540543973445892,
      "learning_rate": 0.00037628911609790644,
      "loss": 0.3634,
      "step": 75900
    },
    {
      "epoch": 3.0902474230995995,
      "grad_norm": 0.2578202486038208,
      "learning_rate": 0.00037606780861328733,
      "loss": 0.3661,
      "step": 76000
    },
    {
      "epoch": 3.0902474230995995,
      "eval_loss": 0.37564438581466675,
      "eval_runtime": 113.2074,
      "eval_samples_per_second": 1544.97,
      "eval_steps_per_second": 48.283,
      "step": 76000
    },
    {
      "epoch": 3.0943135381299935,
      "grad_norm": 0.21673065423965454,
      "learning_rate": 0.0003758465011286682,
      "loss": 0.3619,
      "step": 76100
    },
    {
      "epoch": 3.098379653160388,
      "grad_norm": 0.22257350385189056,
      "learning_rate": 0.0003756251936440491,
      "loss": 0.3645,
      "step": 76200
    },
    {
      "epoch": 3.102445768190782,
      "grad_norm": 0.24058417975902557,
      "learning_rate": 0.0003754038861594299,
      "loss": 0.3632,
      "step": 76300
    },
    {
      "epoch": 3.1065118832211764,
      "grad_norm": 0.20885518193244934,
      "learning_rate": 0.0003751825786748108,
      "loss": 0.3653,
      "step": 76400
    },
    {
      "epoch": 3.1105779982515704,
      "grad_norm": 0.2514180541038513,
      "learning_rate": 0.00037496127119019166,
      "loss": 0.3638,
      "step": 76500
    },
    {
      "epoch": 3.114644113281965,
      "grad_norm": 0.22285096347332,
      "learning_rate": 0.0003747399637055725,
      "loss": 0.3644,
      "step": 76600
    },
    {
      "epoch": 3.118710228312359,
      "grad_norm": 0.2388875037431717,
      "learning_rate": 0.0003745186562209534,
      "loss": 0.3632,
      "step": 76700
    },
    {
      "epoch": 3.1227763433427533,
      "grad_norm": 0.21564938127994537,
      "learning_rate": 0.00037429734873633424,
      "loss": 0.3652,
      "step": 76800
    },
    {
      "epoch": 3.1268424583731473,
      "grad_norm": 0.2133714109659195,
      "learning_rate": 0.00037407604125171514,
      "loss": 0.3649,
      "step": 76900
    },
    {
      "epoch": 3.130908573403542,
      "grad_norm": 0.22516638040542603,
      "learning_rate": 0.000373854733767096,
      "loss": 0.366,
      "step": 77000
    },
    {
      "epoch": 3.134974688433936,
      "grad_norm": 0.20429816842079163,
      "learning_rate": 0.0003736334262824769,
      "loss": 0.3647,
      "step": 77100
    },
    {
      "epoch": 3.1390408034643302,
      "grad_norm": 0.23547667264938354,
      "learning_rate": 0.0003734121187978577,
      "loss": 0.3657,
      "step": 77200
    },
    {
      "epoch": 3.1431069184947242,
      "grad_norm": 0.22917018830776215,
      "learning_rate": 0.0003731908113132386,
      "loss": 0.3634,
      "step": 77300
    },
    {
      "epoch": 3.1471730335251182,
      "grad_norm": 0.20167547464370728,
      "learning_rate": 0.0003729695038286195,
      "loss": 0.3642,
      "step": 77400
    },
    {
      "epoch": 3.1512391485555127,
      "grad_norm": 0.2576839327812195,
      "learning_rate": 0.00037274819634400036,
      "loss": 0.3647,
      "step": 77500
    },
    {
      "epoch": 3.1553052635859067,
      "grad_norm": 0.233429417014122,
      "learning_rate": 0.00037252688885938126,
      "loss": 0.3625,
      "step": 77600
    },
    {
      "epoch": 3.159371378616301,
      "grad_norm": 0.22292305529117584,
      "learning_rate": 0.0003723055813747621,
      "loss": 0.3653,
      "step": 77700
    },
    {
      "epoch": 3.163437493646695,
      "grad_norm": 0.21974489092826843,
      "learning_rate": 0.000372084273890143,
      "loss": 0.3636,
      "step": 77800
    },
    {
      "epoch": 3.1675036086770896,
      "grad_norm": 0.25744950771331787,
      "learning_rate": 0.00037186296640552384,
      "loss": 0.3666,
      "step": 77900
    },
    {
      "epoch": 3.1715697237074836,
      "grad_norm": 0.2040918469429016,
      "learning_rate": 0.00037164165892090474,
      "loss": 0.364,
      "step": 78000
    },
    {
      "epoch": 3.1715697237074836,
      "eval_loss": 0.3754308521747589,
      "eval_runtime": 114.5058,
      "eval_samples_per_second": 1527.451,
      "eval_steps_per_second": 47.736,
      "step": 78000
    },
    {
      "epoch": 3.175635838737878,
      "grad_norm": 0.20542867481708527,
      "learning_rate": 0.0003714203514362856,
      "loss": 0.3654,
      "step": 78100
    },
    {
      "epoch": 3.179701953768272,
      "grad_norm": 0.23669379949569702,
      "learning_rate": 0.0003711990439516664,
      "loss": 0.3655,
      "step": 78200
    },
    {
      "epoch": 3.1837680687986665,
      "grad_norm": 0.23206615447998047,
      "learning_rate": 0.0003709777364670473,
      "loss": 0.3649,
      "step": 78300
    },
    {
      "epoch": 3.1878341838290605,
      "grad_norm": 0.2177012860774994,
      "learning_rate": 0.00037075642898242817,
      "loss": 0.365,
      "step": 78400
    },
    {
      "epoch": 3.191900298859455,
      "grad_norm": 0.21589195728302002,
      "learning_rate": 0.00037053512149780906,
      "loss": 0.3621,
      "step": 78500
    },
    {
      "epoch": 3.195966413889849,
      "grad_norm": 0.24312971532344818,
      "learning_rate": 0.0003703138140131899,
      "loss": 0.3653,
      "step": 78600
    },
    {
      "epoch": 3.200032528920243,
      "grad_norm": 0.23088622093200684,
      "learning_rate": 0.0003700925065285708,
      "loss": 0.3632,
      "step": 78700
    },
    {
      "epoch": 3.2040986439506374,
      "grad_norm": 0.24425330758094788,
      "learning_rate": 0.00036987119904395165,
      "loss": 0.3626,
      "step": 78800
    },
    {
      "epoch": 3.2081647589810314,
      "grad_norm": 0.23379890620708466,
      "learning_rate": 0.00036964989155933254,
      "loss": 0.3648,
      "step": 78900
    },
    {
      "epoch": 3.212230874011426,
      "grad_norm": 0.2174876481294632,
      "learning_rate": 0.00036942858407471344,
      "loss": 0.3649,
      "step": 79000
    },
    {
      "epoch": 3.21629698904182,
      "grad_norm": 0.2810266315937042,
      "learning_rate": 0.0003692072765900943,
      "loss": 0.3643,
      "step": 79100
    },
    {
      "epoch": 3.2203631040722143,
      "grad_norm": 0.24074967205524445,
      "learning_rate": 0.0003689859691054752,
      "loss": 0.3634,
      "step": 79200
    },
    {
      "epoch": 3.2244292191026083,
      "grad_norm": 0.21738781034946442,
      "learning_rate": 0.000368764661620856,
      "loss": 0.3633,
      "step": 79300
    },
    {
      "epoch": 3.2284953341330027,
      "grad_norm": 0.21775266528129578,
      "learning_rate": 0.0003685433541362369,
      "loss": 0.3631,
      "step": 79400
    },
    {
      "epoch": 3.2325614491633967,
      "grad_norm": 0.23879249393939972,
      "learning_rate": 0.00036832204665161776,
      "loss": 0.3642,
      "step": 79500
    },
    {
      "epoch": 3.236627564193791,
      "grad_norm": 0.20695430040359497,
      "learning_rate": 0.00036810073916699866,
      "loss": 0.3645,
      "step": 79600
    },
    {
      "epoch": 3.240693679224185,
      "grad_norm": 0.22739899158477783,
      "learning_rate": 0.0003678794316823795,
      "loss": 0.3628,
      "step": 79700
    },
    {
      "epoch": 3.2447597942545796,
      "grad_norm": 0.19031091034412384,
      "learning_rate": 0.0003676581241977604,
      "loss": 0.3631,
      "step": 79800
    },
    {
      "epoch": 3.2488259092849736,
      "grad_norm": 0.22998571395874023,
      "learning_rate": 0.00036743681671314125,
      "loss": 0.3649,
      "step": 79900
    },
    {
      "epoch": 3.252892024315368,
      "grad_norm": 0.23702986538410187,
      "learning_rate": 0.0003672155092285221,
      "loss": 0.3635,
      "step": 80000
    },
    {
      "epoch": 3.252892024315368,
      "eval_loss": 0.37520989775657654,
      "eval_runtime": 113.2021,
      "eval_samples_per_second": 1545.043,
      "eval_steps_per_second": 48.285,
      "step": 80000
    },
    {
      "epoch": 3.256958139345762,
      "grad_norm": 0.23169749975204468,
      "learning_rate": 0.000366994201743903,
      "loss": 0.3628,
      "step": 80100
    },
    {
      "epoch": 3.2610242543761565,
      "grad_norm": 0.2506673336029053,
      "learning_rate": 0.00036677289425928383,
      "loss": 0.3638,
      "step": 80200
    },
    {
      "epoch": 3.2650903694065505,
      "grad_norm": 0.22794581949710846,
      "learning_rate": 0.0003665515867746647,
      "loss": 0.363,
      "step": 80300
    },
    {
      "epoch": 3.2691564844369445,
      "grad_norm": 0.22943459451198578,
      "learning_rate": 0.00036633027929004557,
      "loss": 0.366,
      "step": 80400
    },
    {
      "epoch": 3.273222599467339,
      "grad_norm": 0.2497629076242447,
      "learning_rate": 0.00036610897180542647,
      "loss": 0.3645,
      "step": 80500
    },
    {
      "epoch": 3.277288714497733,
      "grad_norm": 0.2962869703769684,
      "learning_rate": 0.0003658876643208073,
      "loss": 0.3641,
      "step": 80600
    },
    {
      "epoch": 3.2813548295281274,
      "grad_norm": 0.272297203540802,
      "learning_rate": 0.0003656663568361882,
      "loss": 0.3647,
      "step": 80700
    },
    {
      "epoch": 3.2854209445585214,
      "grad_norm": 0.21337704360485077,
      "learning_rate": 0.0003654450493515691,
      "loss": 0.3646,
      "step": 80800
    },
    {
      "epoch": 3.289487059588916,
      "grad_norm": 0.20327919721603394,
      "learning_rate": 0.00036522374186694995,
      "loss": 0.364,
      "step": 80900
    },
    {
      "epoch": 3.29355317461931,
      "grad_norm": 0.22675472497940063,
      "learning_rate": 0.00036500243438233085,
      "loss": 0.3662,
      "step": 81000
    },
    {
      "epoch": 3.2976192896497043,
      "grad_norm": 0.22970733046531677,
      "learning_rate": 0.0003647811268977117,
      "loss": 0.3641,
      "step": 81100
    },
    {
      "epoch": 3.3016854046800983,
      "grad_norm": 0.25484699010849,
      "learning_rate": 0.0003645598194130926,
      "loss": 0.3667,
      "step": 81200
    },
    {
      "epoch": 3.3057515197104927,
      "grad_norm": 0.21870535612106323,
      "learning_rate": 0.00036433851192847343,
      "loss": 0.3629,
      "step": 81300
    },
    {
      "epoch": 3.3098176347408867,
      "grad_norm": 0.2291286736726761,
      "learning_rate": 0.0003641172044438543,
      "loss": 0.3669,
      "step": 81400
    },
    {
      "epoch": 3.313883749771281,
      "grad_norm": 0.2305360734462738,
      "learning_rate": 0.00036389589695923517,
      "loss": 0.3631,
      "step": 81500
    },
    {
      "epoch": 3.317949864801675,
      "grad_norm": 0.3042367398738861,
      "learning_rate": 0.000363674589474616,
      "loss": 0.3641,
      "step": 81600
    },
    {
      "epoch": 3.3220159798320696,
      "grad_norm": 0.27432742714881897,
      "learning_rate": 0.0003634532819899969,
      "loss": 0.3639,
      "step": 81700
    },
    {
      "epoch": 3.3260820948624636,
      "grad_norm": 0.2529038190841675,
      "learning_rate": 0.00036323197450537775,
      "loss": 0.3642,
      "step": 81800
    },
    {
      "epoch": 3.330148209892858,
      "grad_norm": 0.22282284498214722,
      "learning_rate": 0.00036301066702075865,
      "loss": 0.3647,
      "step": 81900
    },
    {
      "epoch": 3.334214324923252,
      "grad_norm": 0.20337586104869843,
      "learning_rate": 0.0003627893595361395,
      "loss": 0.3629,
      "step": 82000
    },
    {
      "epoch": 3.334214324923252,
      "eval_loss": 0.37488582730293274,
      "eval_runtime": 117.9993,
      "eval_samples_per_second": 1482.229,
      "eval_steps_per_second": 46.322,
      "step": 82000
    },
    {
      "epoch": 3.338280439953646,
      "grad_norm": 0.23338288068771362,
      "learning_rate": 0.0003625680520515204,
      "loss": 0.3648,
      "step": 82100
    },
    {
      "epoch": 3.3423465549840405,
      "grad_norm": 0.24409109354019165,
      "learning_rate": 0.00036234674456690123,
      "loss": 0.3618,
      "step": 82200
    },
    {
      "epoch": 3.3464126700144345,
      "grad_norm": 0.25758853554725647,
      "learning_rate": 0.00036212543708228213,
      "loss": 0.3634,
      "step": 82300
    },
    {
      "epoch": 3.350478785044829,
      "grad_norm": 0.22613012790679932,
      "learning_rate": 0.000361904129597663,
      "loss": 0.3655,
      "step": 82400
    },
    {
      "epoch": 3.354544900075223,
      "grad_norm": 0.24825499951839447,
      "learning_rate": 0.00036168282211304387,
      "loss": 0.3631,
      "step": 82500
    },
    {
      "epoch": 3.3586110151056174,
      "grad_norm": 0.2607724368572235,
      "learning_rate": 0.00036146151462842477,
      "loss": 0.3641,
      "step": 82600
    },
    {
      "epoch": 3.3626771301360114,
      "grad_norm": 0.27074986696243286,
      "learning_rate": 0.0003612402071438056,
      "loss": 0.3656,
      "step": 82700
    },
    {
      "epoch": 3.366743245166406,
      "grad_norm": 0.26898154616355896,
      "learning_rate": 0.0003610188996591865,
      "loss": 0.3631,
      "step": 82800
    },
    {
      "epoch": 3.3708093601968,
      "grad_norm": 0.26554372906684875,
      "learning_rate": 0.00036079759217456735,
      "loss": 0.3649,
      "step": 82900
    },
    {
      "epoch": 3.3748754752271943,
      "grad_norm": 0.2565418779850006,
      "learning_rate": 0.00036057628468994825,
      "loss": 0.3654,
      "step": 83000
    },
    {
      "epoch": 3.3789415902575883,
      "grad_norm": 0.2146764099597931,
      "learning_rate": 0.0003603549772053291,
      "loss": 0.3644,
      "step": 83100
    },
    {
      "epoch": 3.383007705287983,
      "grad_norm": 0.21060021221637726,
      "learning_rate": 0.00036013366972071,
      "loss": 0.362,
      "step": 83200
    },
    {
      "epoch": 3.387073820318377,
      "grad_norm": 0.22548522055149078,
      "learning_rate": 0.00035991236223609083,
      "loss": 0.3638,
      "step": 83300
    },
    {
      "epoch": 3.391139935348771,
      "grad_norm": 0.259178102016449,
      "learning_rate": 0.0003596910547514717,
      "loss": 0.3625,
      "step": 83400
    },
    {
      "epoch": 3.3952060503791652,
      "grad_norm": 0.2624461054801941,
      "learning_rate": 0.0003594697472668526,
      "loss": 0.3642,
      "step": 83500
    },
    {
      "epoch": 3.3992721654095597,
      "grad_norm": 0.22651204466819763,
      "learning_rate": 0.0003592484397822334,
      "loss": 0.3625,
      "step": 83600
    },
    {
      "epoch": 3.4033382804399537,
      "grad_norm": 0.23989976942539215,
      "learning_rate": 0.0003590271322976143,
      "loss": 0.3632,
      "step": 83700
    },
    {
      "epoch": 3.4074043954703477,
      "grad_norm": 0.24842359125614166,
      "learning_rate": 0.00035880582481299516,
      "loss": 0.3645,
      "step": 83800
    },
    {
      "epoch": 3.411470510500742,
      "grad_norm": 0.23729351162910461,
      "learning_rate": 0.00035858451732837605,
      "loss": 0.3627,
      "step": 83900
    },
    {
      "epoch": 3.415536625531136,
      "grad_norm": 0.2464863806962967,
      "learning_rate": 0.0003583632098437569,
      "loss": 0.3641,
      "step": 84000
    },
    {
      "epoch": 3.415536625531136,
      "eval_loss": 0.3753586709499359,
      "eval_runtime": 113.0738,
      "eval_samples_per_second": 1546.795,
      "eval_steps_per_second": 48.34,
      "step": 84000
    },
    {
      "epoch": 3.4196027405615306,
      "grad_norm": 0.22159914672374725,
      "learning_rate": 0.0003581419023591378,
      "loss": 0.3629,
      "step": 84100
    },
    {
      "epoch": 3.4236688555919246,
      "grad_norm": 0.2493719607591629,
      "learning_rate": 0.0003579205948745187,
      "loss": 0.3617,
      "step": 84200
    },
    {
      "epoch": 3.427734970622319,
      "grad_norm": 0.2409263402223587,
      "learning_rate": 0.00035769928738989954,
      "loss": 0.3637,
      "step": 84300
    },
    {
      "epoch": 3.431801085652713,
      "grad_norm": 0.25679323077201843,
      "learning_rate": 0.00035747797990528043,
      "loss": 0.3622,
      "step": 84400
    },
    {
      "epoch": 3.4358672006831075,
      "grad_norm": 0.21945320069789886,
      "learning_rate": 0.0003572566724206613,
      "loss": 0.362,
      "step": 84500
    },
    {
      "epoch": 3.4399333157135015,
      "grad_norm": 0.2234710156917572,
      "learning_rate": 0.0003570353649360422,
      "loss": 0.364,
      "step": 84600
    },
    {
      "epoch": 3.443999430743896,
      "grad_norm": 0.2301575392484665,
      "learning_rate": 0.000356814057451423,
      "loss": 0.3629,
      "step": 84700
    },
    {
      "epoch": 3.44806554577429,
      "grad_norm": 0.23387984931468964,
      "learning_rate": 0.0003565927499668039,
      "loss": 0.3633,
      "step": 84800
    },
    {
      "epoch": 3.4521316608046844,
      "grad_norm": 0.23348283767700195,
      "learning_rate": 0.00035637144248218476,
      "loss": 0.3608,
      "step": 84900
    },
    {
      "epoch": 3.4561977758350784,
      "grad_norm": 0.2596232295036316,
      "learning_rate": 0.0003561501349975656,
      "loss": 0.3649,
      "step": 85000
    },
    {
      "epoch": 3.4602638908654724,
      "grad_norm": 0.22078785300254822,
      "learning_rate": 0.0003559288275129465,
      "loss": 0.3627,
      "step": 85100
    },
    {
      "epoch": 3.464330005895867,
      "grad_norm": 0.25897130370140076,
      "learning_rate": 0.00035570752002832734,
      "loss": 0.3639,
      "step": 85200
    },
    {
      "epoch": 3.468396120926261,
      "grad_norm": 0.2297523468732834,
      "learning_rate": 0.00035548621254370824,
      "loss": 0.3626,
      "step": 85300
    },
    {
      "epoch": 3.4724622359566553,
      "grad_norm": 0.23028752207756042,
      "learning_rate": 0.0003552649050590891,
      "loss": 0.3624,
      "step": 85400
    },
    {
      "epoch": 3.4765283509870493,
      "grad_norm": 0.22614413499832153,
      "learning_rate": 0.00035504359757447,
      "loss": 0.3643,
      "step": 85500
    },
    {
      "epoch": 3.4805944660174437,
      "grad_norm": 0.23549498617649078,
      "learning_rate": 0.0003548222900898508,
      "loss": 0.3664,
      "step": 85600
    },
    {
      "epoch": 3.4846605810478377,
      "grad_norm": 0.22996175289154053,
      "learning_rate": 0.0003546009826052317,
      "loss": 0.3647,
      "step": 85700
    },
    {
      "epoch": 3.488726696078232,
      "grad_norm": 0.2773725688457489,
      "learning_rate": 0.00035437967512061256,
      "loss": 0.3612,
      "step": 85800
    },
    {
      "epoch": 3.492792811108626,
      "grad_norm": 0.2563452422618866,
      "learning_rate": 0.00035415836763599346,
      "loss": 0.3646,
      "step": 85900
    },
    {
      "epoch": 3.4968589261390206,
      "grad_norm": 0.26427093148231506,
      "learning_rate": 0.00035393706015137436,
      "loss": 0.3624,
      "step": 86000
    },
    {
      "epoch": 3.4968589261390206,
      "eval_loss": 0.37403687834739685,
      "eval_runtime": 114.1171,
      "eval_samples_per_second": 1532.653,
      "eval_steps_per_second": 47.898,
      "step": 86000
    },
    {
      "epoch": 3.5009250411694146,
      "grad_norm": 0.28190696239471436,
      "learning_rate": 0.0003537157526667552,
      "loss": 0.364,
      "step": 86100
    },
    {
      "epoch": 3.504991156199809,
      "grad_norm": 0.2208004891872406,
      "learning_rate": 0.0003534944451821361,
      "loss": 0.3628,
      "step": 86200
    },
    {
      "epoch": 3.509057271230203,
      "grad_norm": 0.22026285529136658,
      "learning_rate": 0.00035327313769751694,
      "loss": 0.3626,
      "step": 86300
    },
    {
      "epoch": 3.513123386260597,
      "grad_norm": 0.23020677268505096,
      "learning_rate": 0.00035305183021289784,
      "loss": 0.3665,
      "step": 86400
    },
    {
      "epoch": 3.5171895012909915,
      "grad_norm": 0.2702242434024811,
      "learning_rate": 0.0003528305227282787,
      "loss": 0.3646,
      "step": 86500
    },
    {
      "epoch": 3.521255616321386,
      "grad_norm": 0.2366846352815628,
      "learning_rate": 0.0003526092152436595,
      "loss": 0.365,
      "step": 86600
    },
    {
      "epoch": 3.52532173135178,
      "grad_norm": 0.27168700098991394,
      "learning_rate": 0.0003523879077590404,
      "loss": 0.3661,
      "step": 86700
    },
    {
      "epoch": 3.529387846382174,
      "grad_norm": 0.22401942312717438,
      "learning_rate": 0.00035216660027442126,
      "loss": 0.3649,
      "step": 86800
    },
    {
      "epoch": 3.5334539614125684,
      "grad_norm": 0.24899733066558838,
      "learning_rate": 0.00035194529278980216,
      "loss": 0.3603,
      "step": 86900
    },
    {
      "epoch": 3.537520076442963,
      "grad_norm": 0.2292839139699936,
      "learning_rate": 0.000351723985305183,
      "loss": 0.3638,
      "step": 87000
    },
    {
      "epoch": 3.541586191473357,
      "grad_norm": 0.26873478293418884,
      "learning_rate": 0.0003515026778205639,
      "loss": 0.363,
      "step": 87100
    },
    {
      "epoch": 3.545652306503751,
      "grad_norm": 0.24801145493984222,
      "learning_rate": 0.00035128137033594474,
      "loss": 0.3635,
      "step": 87200
    },
    {
      "epoch": 3.5497184215341453,
      "grad_norm": 0.2576127052307129,
      "learning_rate": 0.00035106006285132564,
      "loss": 0.3626,
      "step": 87300
    },
    {
      "epoch": 3.5537845365645393,
      "grad_norm": 0.2623577415943146,
      "learning_rate": 0.0003508387553667065,
      "loss": 0.3629,
      "step": 87400
    },
    {
      "epoch": 3.5578506515949337,
      "grad_norm": 0.23356930911540985,
      "learning_rate": 0.0003506174478820874,
      "loss": 0.3633,
      "step": 87500
    },
    {
      "epoch": 3.5619167666253277,
      "grad_norm": 0.22201043367385864,
      "learning_rate": 0.0003503961403974683,
      "loss": 0.3638,
      "step": 87600
    },
    {
      "epoch": 3.565982881655722,
      "grad_norm": 0.2270423173904419,
      "learning_rate": 0.0003501748329128491,
      "loss": 0.3639,
      "step": 87700
    },
    {
      "epoch": 3.570048996686116,
      "grad_norm": 0.24354808032512665,
      "learning_rate": 0.00034995352542823,
      "loss": 0.3627,
      "step": 87800
    },
    {
      "epoch": 3.5741151117165106,
      "grad_norm": 0.23644927144050598,
      "learning_rate": 0.00034973221794361086,
      "loss": 0.3633,
      "step": 87900
    },
    {
      "epoch": 3.5781812267469046,
      "grad_norm": 0.21106906235218048,
      "learning_rate": 0.00034951091045899176,
      "loss": 0.3634,
      "step": 88000
    },
    {
      "epoch": 3.5781812267469046,
      "eval_loss": 0.37290841341018677,
      "eval_runtime": 112.7805,
      "eval_samples_per_second": 1550.818,
      "eval_steps_per_second": 48.466,
      "step": 88000
    },
    {
      "epoch": 3.5822473417772986,
      "grad_norm": 0.2544475495815277,
      "learning_rate": 0.0003492896029743726,
      "loss": 0.3639,
      "step": 88100
    },
    {
      "epoch": 3.586313456807693,
      "grad_norm": 0.24406395852565765,
      "learning_rate": 0.0003490682954897535,
      "loss": 0.3627,
      "step": 88200
    },
    {
      "epoch": 3.5903795718380875,
      "grad_norm": 0.26587262749671936,
      "learning_rate": 0.0003488469880051343,
      "loss": 0.3645,
      "step": 88300
    },
    {
      "epoch": 3.5944456868684815,
      "grad_norm": 0.2540838420391083,
      "learning_rate": 0.0003486256805205152,
      "loss": 0.3649,
      "step": 88400
    },
    {
      "epoch": 3.5985118018988755,
      "grad_norm": 0.21694961190223694,
      "learning_rate": 0.0003484043730358961,
      "loss": 0.3628,
      "step": 88500
    },
    {
      "epoch": 3.60257791692927,
      "grad_norm": 0.26712527871131897,
      "learning_rate": 0.00034818306555127693,
      "loss": 0.3646,
      "step": 88600
    },
    {
      "epoch": 3.606644031959664,
      "grad_norm": 0.2585977613925934,
      "learning_rate": 0.0003479617580666578,
      "loss": 0.3647,
      "step": 88700
    },
    {
      "epoch": 3.6107101469900584,
      "grad_norm": 0.2369707226753235,
      "learning_rate": 0.00034774045058203867,
      "loss": 0.3631,
      "step": 88800
    },
    {
      "epoch": 3.6147762620204524,
      "grad_norm": 0.23671992123126984,
      "learning_rate": 0.00034751914309741957,
      "loss": 0.3616,
      "step": 88900
    },
    {
      "epoch": 3.618842377050847,
      "grad_norm": 0.23771193623542786,
      "learning_rate": 0.0003472978356128004,
      "loss": 0.364,
      "step": 89000
    },
    {
      "epoch": 3.622908492081241,
      "grad_norm": 0.2593914270401001,
      "learning_rate": 0.0003470765281281813,
      "loss": 0.3652,
      "step": 89100
    },
    {
      "epoch": 3.6269746071116353,
      "grad_norm": 0.2579791843891144,
      "learning_rate": 0.00034685522064356215,
      "loss": 0.3623,
      "step": 89200
    },
    {
      "epoch": 3.6310407221420293,
      "grad_norm": 0.22333310544490814,
      "learning_rate": 0.00034663391315894305,
      "loss": 0.3631,
      "step": 89300
    },
    {
      "epoch": 3.6351068371724233,
      "grad_norm": 0.24404843151569366,
      "learning_rate": 0.00034641260567432394,
      "loss": 0.3634,
      "step": 89400
    },
    {
      "epoch": 3.639172952202818,
      "grad_norm": 0.20203174650669098,
      "learning_rate": 0.0003461912981897048,
      "loss": 0.364,
      "step": 89500
    },
    {
      "epoch": 3.6432390672332122,
      "grad_norm": 0.23498016595840454,
      "learning_rate": 0.0003459699907050857,
      "loss": 0.3621,
      "step": 89600
    },
    {
      "epoch": 3.6473051822636062,
      "grad_norm": 0.2399650514125824,
      "learning_rate": 0.00034574868322046653,
      "loss": 0.3608,
      "step": 89700
    },
    {
      "epoch": 3.6513712972940002,
      "grad_norm": 0.26688894629478455,
      "learning_rate": 0.0003455273757358474,
      "loss": 0.3637,
      "step": 89800
    },
    {
      "epoch": 3.6554374123243947,
      "grad_norm": 0.26263970136642456,
      "learning_rate": 0.00034530606825122827,
      "loss": 0.3632,
      "step": 89900
    },
    {
      "epoch": 3.659503527354789,
      "grad_norm": 0.2583300471305847,
      "learning_rate": 0.0003450847607666091,
      "loss": 0.3617,
      "step": 90000
    },
    {
      "epoch": 3.659503527354789,
      "eval_loss": 0.37341955304145813,
      "eval_runtime": 114.1508,
      "eval_samples_per_second": 1532.202,
      "eval_steps_per_second": 47.884,
      "step": 90000
    },
    {
      "epoch": 3.663569642385183,
      "grad_norm": 0.20794427394866943,
      "learning_rate": 0.00034486345328198995,
      "loss": 0.3614,
      "step": 90100
    },
    {
      "epoch": 3.667635757415577,
      "grad_norm": 0.2354350984096527,
      "learning_rate": 0.00034464214579737085,
      "loss": 0.3669,
      "step": 90200
    },
    {
      "epoch": 3.6717018724459716,
      "grad_norm": 0.2661339044570923,
      "learning_rate": 0.00034442083831275175,
      "loss": 0.362,
      "step": 90300
    },
    {
      "epoch": 3.6757679874763656,
      "grad_norm": 0.2350468635559082,
      "learning_rate": 0.0003441995308281326,
      "loss": 0.3619,
      "step": 90400
    },
    {
      "epoch": 3.67983410250676,
      "grad_norm": 0.23419007658958435,
      "learning_rate": 0.0003439782233435135,
      "loss": 0.3627,
      "step": 90500
    },
    {
      "epoch": 3.683900217537154,
      "grad_norm": 0.24179336428642273,
      "learning_rate": 0.00034375691585889433,
      "loss": 0.3634,
      "step": 90600
    },
    {
      "epoch": 3.6879663325675485,
      "grad_norm": 0.2562888264656067,
      "learning_rate": 0.00034353560837427523,
      "loss": 0.3624,
      "step": 90700
    },
    {
      "epoch": 3.6920324475979425,
      "grad_norm": 0.2696792185306549,
      "learning_rate": 0.00034331430088965607,
      "loss": 0.3623,
      "step": 90800
    },
    {
      "epoch": 3.696098562628337,
      "grad_norm": 0.23639728128910065,
      "learning_rate": 0.00034309299340503697,
      "loss": 0.3643,
      "step": 90900
    },
    {
      "epoch": 3.700164677658731,
      "grad_norm": 0.20337407290935516,
      "learning_rate": 0.00034287168592041787,
      "loss": 0.3619,
      "step": 91000
    },
    {
      "epoch": 3.704230792689125,
      "grad_norm": 0.2645091414451599,
      "learning_rate": 0.0003426503784357987,
      "loss": 0.3617,
      "step": 91100
    },
    {
      "epoch": 3.7082969077195194,
      "grad_norm": 0.2331513911485672,
      "learning_rate": 0.0003424290709511796,
      "loss": 0.3616,
      "step": 91200
    },
    {
      "epoch": 3.712363022749914,
      "grad_norm": 0.23895610868930817,
      "learning_rate": 0.00034220776346656045,
      "loss": 0.3622,
      "step": 91300
    },
    {
      "epoch": 3.716429137780308,
      "grad_norm": 0.2720319330692291,
      "learning_rate": 0.00034198645598194135,
      "loss": 0.3651,
      "step": 91400
    },
    {
      "epoch": 3.720495252810702,
      "grad_norm": 0.25461944937705994,
      "learning_rate": 0.0003417651484973222,
      "loss": 0.3623,
      "step": 91500
    },
    {
      "epoch": 3.7245613678410963,
      "grad_norm": 0.25444403290748596,
      "learning_rate": 0.0003415438410127031,
      "loss": 0.3646,
      "step": 91600
    },
    {
      "epoch": 3.7286274828714907,
      "grad_norm": 0.2159511297941208,
      "learning_rate": 0.0003413225335280839,
      "loss": 0.3617,
      "step": 91700
    },
    {
      "epoch": 3.7326935979018847,
      "grad_norm": 0.28540122509002686,
      "learning_rate": 0.0003411012260434648,
      "loss": 0.364,
      "step": 91800
    },
    {
      "epoch": 3.7367597129322787,
      "grad_norm": 0.2305125743150711,
      "learning_rate": 0.00034087991855884567,
      "loss": 0.3622,
      "step": 91900
    },
    {
      "epoch": 3.740825827962673,
      "grad_norm": 0.23431479930877686,
      "learning_rate": 0.0003406586110742265,
      "loss": 0.3642,
      "step": 92000
    },
    {
      "epoch": 3.740825827962673,
      "eval_loss": 0.37263190746307373,
      "eval_runtime": 113.353,
      "eval_samples_per_second": 1542.985,
      "eval_steps_per_second": 48.221,
      "step": 92000
    },
    {
      "epoch": 3.744891942993067,
      "grad_norm": 0.243440642952919,
      "learning_rate": 0.0003404373035896074,
      "loss": 0.3624,
      "step": 92100
    },
    {
      "epoch": 3.7489580580234616,
      "grad_norm": 0.24967437982559204,
      "learning_rate": 0.00034021599610498826,
      "loss": 0.3622,
      "step": 92200
    },
    {
      "epoch": 3.7530241730538556,
      "grad_norm": 0.22858725488185883,
      "learning_rate": 0.00033999468862036915,
      "loss": 0.363,
      "step": 92300
    },
    {
      "epoch": 3.75709028808425,
      "grad_norm": 0.266730934381485,
      "learning_rate": 0.00033977338113575,
      "loss": 0.3633,
      "step": 92400
    },
    {
      "epoch": 3.761156403114644,
      "grad_norm": 0.22117812931537628,
      "learning_rate": 0.0003395520736511309,
      "loss": 0.3624,
      "step": 92500
    },
    {
      "epoch": 3.7652225181450385,
      "grad_norm": 0.23683752119541168,
      "learning_rate": 0.00033933076616651174,
      "loss": 0.3611,
      "step": 92600
    },
    {
      "epoch": 3.7692886331754325,
      "grad_norm": 0.2621278762817383,
      "learning_rate": 0.00033910945868189263,
      "loss": 0.3642,
      "step": 92700
    },
    {
      "epoch": 3.7733547482058265,
      "grad_norm": 0.21830545365810394,
      "learning_rate": 0.00033888815119727353,
      "loss": 0.3638,
      "step": 92800
    },
    {
      "epoch": 3.777420863236221,
      "grad_norm": 0.29267439246177673,
      "learning_rate": 0.0003386668437126544,
      "loss": 0.362,
      "step": 92900
    },
    {
      "epoch": 3.7814869782666154,
      "grad_norm": 0.2536149322986603,
      "learning_rate": 0.00033844553622803527,
      "loss": 0.3623,
      "step": 93000
    },
    {
      "epoch": 3.7855530932970094,
      "grad_norm": 0.2270154356956482,
      "learning_rate": 0.0003382242287434161,
      "loss": 0.3617,
      "step": 93100
    },
    {
      "epoch": 3.7896192083274034,
      "grad_norm": 0.27547213435173035,
      "learning_rate": 0.000338002921258797,
      "loss": 0.3647,
      "step": 93200
    },
    {
      "epoch": 3.793685323357798,
      "grad_norm": 0.2698025405406952,
      "learning_rate": 0.00033778161377417786,
      "loss": 0.3631,
      "step": 93300
    },
    {
      "epoch": 3.797751438388192,
      "grad_norm": 0.30019888281822205,
      "learning_rate": 0.0003375603062895587,
      "loss": 0.3623,
      "step": 93400
    },
    {
      "epoch": 3.8018175534185863,
      "grad_norm": 0.2764021158218384,
      "learning_rate": 0.00033733899880493954,
      "loss": 0.3623,
      "step": 93500
    },
    {
      "epoch": 3.8058836684489803,
      "grad_norm": 0.2280447632074356,
      "learning_rate": 0.00033711769132032044,
      "loss": 0.3634,
      "step": 93600
    },
    {
      "epoch": 3.8099497834793747,
      "grad_norm": 0.24326208233833313,
      "learning_rate": 0.00033689638383570134,
      "loss": 0.3608,
      "step": 93700
    },
    {
      "epoch": 3.8140158985097687,
      "grad_norm": 0.24674567580223083,
      "learning_rate": 0.0003366750763510822,
      "loss": 0.3627,
      "step": 93800
    },
    {
      "epoch": 3.818082013540163,
      "grad_norm": 0.24819901585578918,
      "learning_rate": 0.0003364537688664631,
      "loss": 0.3639,
      "step": 93900
    },
    {
      "epoch": 3.822148128570557,
      "grad_norm": 0.23009143769741058,
      "learning_rate": 0.0003362324613818439,
      "loss": 0.3613,
      "step": 94000
    },
    {
      "epoch": 3.822148128570557,
      "eval_loss": 0.3712649643421173,
      "eval_runtime": 113.8048,
      "eval_samples_per_second": 1536.86,
      "eval_steps_per_second": 48.03,
      "step": 94000
    },
    {
      "epoch": 3.8262142436009516,
      "grad_norm": 0.2368212640285492,
      "learning_rate": 0.0003360111538972248,
      "loss": 0.3635,
      "step": 94100
    },
    {
      "epoch": 3.8302803586313456,
      "grad_norm": 0.2514120042324066,
      "learning_rate": 0.00033578984641260566,
      "loss": 0.3622,
      "step": 94200
    },
    {
      "epoch": 3.83434647366174,
      "grad_norm": 0.26469749212265015,
      "learning_rate": 0.00033556853892798656,
      "loss": 0.361,
      "step": 94300
    },
    {
      "epoch": 3.838412588692134,
      "grad_norm": 0.23738786578178406,
      "learning_rate": 0.00033534723144336745,
      "loss": 0.3593,
      "step": 94400
    },
    {
      "epoch": 3.842478703722528,
      "grad_norm": 0.21982073783874512,
      "learning_rate": 0.0003351259239587483,
      "loss": 0.3632,
      "step": 94500
    },
    {
      "epoch": 3.8465448187529225,
      "grad_norm": 0.24978917837142944,
      "learning_rate": 0.0003349046164741292,
      "loss": 0.3612,
      "step": 94600
    },
    {
      "epoch": 3.850610933783317,
      "grad_norm": 0.26291751861572266,
      "learning_rate": 0.00033468330898951004,
      "loss": 0.3658,
      "step": 94700
    },
    {
      "epoch": 3.854677048813711,
      "grad_norm": 0.27796098589897156,
      "learning_rate": 0.00033446200150489094,
      "loss": 0.3601,
      "step": 94800
    },
    {
      "epoch": 3.858743163844105,
      "grad_norm": 0.2664223611354828,
      "learning_rate": 0.0003342406940202718,
      "loss": 0.3615,
      "step": 94900
    },
    {
      "epoch": 3.8628092788744994,
      "grad_norm": 0.28841328620910645,
      "learning_rate": 0.0003340193865356527,
      "loss": 0.362,
      "step": 95000
    },
    {
      "epoch": 3.8668753939048934,
      "grad_norm": 0.23071089386940002,
      "learning_rate": 0.00033379807905103346,
      "loss": 0.3632,
      "step": 95100
    },
    {
      "epoch": 3.870941508935288,
      "grad_norm": 0.24935604631900787,
      "learning_rate": 0.00033357677156641436,
      "loss": 0.3601,
      "step": 95200
    },
    {
      "epoch": 3.875007623965682,
      "grad_norm": 0.2441386878490448,
      "learning_rate": 0.00033335546408179526,
      "loss": 0.3601,
      "step": 95300
    },
    {
      "epoch": 3.8790737389960763,
      "grad_norm": 0.22039386630058289,
      "learning_rate": 0.0003331341565971761,
      "loss": 0.3595,
      "step": 95400
    },
    {
      "epoch": 3.8831398540264703,
      "grad_norm": 0.24845488369464874,
      "learning_rate": 0.000332912849112557,
      "loss": 0.3625,
      "step": 95500
    },
    {
      "epoch": 3.8872059690568648,
      "grad_norm": 0.2285066694021225,
      "learning_rate": 0.00033269154162793784,
      "loss": 0.3614,
      "step": 95600
    },
    {
      "epoch": 3.8912720840872588,
      "grad_norm": 0.2525082230567932,
      "learning_rate": 0.00033247023414331874,
      "loss": 0.3614,
      "step": 95700
    },
    {
      "epoch": 3.8953381991176528,
      "grad_norm": 0.21116790175437927,
      "learning_rate": 0.0003322489266586996,
      "loss": 0.3617,
      "step": 95800
    },
    {
      "epoch": 3.8994043141480472,
      "grad_norm": 0.2713410556316376,
      "learning_rate": 0.0003320276191740805,
      "loss": 0.3602,
      "step": 95900
    },
    {
      "epoch": 3.9034704291784417,
      "grad_norm": 0.2828059196472168,
      "learning_rate": 0.0003318063116894613,
      "loss": 0.3619,
      "step": 96000
    },
    {
      "epoch": 3.9034704291784417,
      "eval_loss": 0.3716493546962738,
      "eval_runtime": 112.7529,
      "eval_samples_per_second": 1551.197,
      "eval_steps_per_second": 48.478,
      "step": 96000
    },
    {
      "epoch": 3.9075365442088357,
      "grad_norm": 0.25669199228286743,
      "learning_rate": 0.0003315850042048422,
      "loss": 0.361,
      "step": 96100
    },
    {
      "epoch": 3.9116026592392297,
      "grad_norm": 0.28855323791503906,
      "learning_rate": 0.0003313636967202231,
      "loss": 0.3619,
      "step": 96200
    },
    {
      "epoch": 3.915668774269624,
      "grad_norm": 0.28530269861221313,
      "learning_rate": 0.00033114238923560396,
      "loss": 0.3592,
      "step": 96300
    },
    {
      "epoch": 3.9197348893000186,
      "grad_norm": 0.2529078423976898,
      "learning_rate": 0.00033092108175098486,
      "loss": 0.3615,
      "step": 96400
    },
    {
      "epoch": 3.9238010043304126,
      "grad_norm": 0.24697299301624298,
      "learning_rate": 0.0003306997742663657,
      "loss": 0.3624,
      "step": 96500
    },
    {
      "epoch": 3.9278671193608066,
      "grad_norm": 0.2358590066432953,
      "learning_rate": 0.0003304784667817466,
      "loss": 0.3612,
      "step": 96600
    },
    {
      "epoch": 3.931933234391201,
      "grad_norm": 0.24213609099388123,
      "learning_rate": 0.00033025715929712744,
      "loss": 0.3611,
      "step": 96700
    },
    {
      "epoch": 3.935999349421595,
      "grad_norm": 0.23129667341709137,
      "learning_rate": 0.0003300358518125083,
      "loss": 0.3609,
      "step": 96800
    },
    {
      "epoch": 3.9400654644519895,
      "grad_norm": 0.24444881081581116,
      "learning_rate": 0.00032981454432788913,
      "loss": 0.3621,
      "step": 96900
    },
    {
      "epoch": 3.9441315794823835,
      "grad_norm": 0.24609747529029846,
      "learning_rate": 0.00032959323684327,
      "loss": 0.3585,
      "step": 97000
    },
    {
      "epoch": 3.948197694512778,
      "grad_norm": 0.2477635145187378,
      "learning_rate": 0.0003293719293586509,
      "loss": 0.3619,
      "step": 97100
    },
    {
      "epoch": 3.952263809543172,
      "grad_norm": 0.2562827467918396,
      "learning_rate": 0.00032915062187403177,
      "loss": 0.3638,
      "step": 97200
    },
    {
      "epoch": 3.9563299245735664,
      "grad_norm": 0.25429779291152954,
      "learning_rate": 0.00032892931438941266,
      "loss": 0.3632,
      "step": 97300
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 0.27374160289764404,
      "learning_rate": 0.0003287080069047935,
      "loss": 0.3619,
      "step": 97400
    },
    {
      "epoch": 3.9644621546343544,
      "grad_norm": 0.22466762363910675,
      "learning_rate": 0.0003284866994201744,
      "loss": 0.3614,
      "step": 97500
    },
    {
      "epoch": 3.968528269664749,
      "grad_norm": 0.294486939907074,
      "learning_rate": 0.00032826539193555525,
      "loss": 0.363,
      "step": 97600
    },
    {
      "epoch": 3.9725943846951433,
      "grad_norm": 0.25811871886253357,
      "learning_rate": 0.00032804408445093614,
      "loss": 0.363,
      "step": 97700
    },
    {
      "epoch": 3.9766604997255373,
      "grad_norm": 0.2522861957550049,
      "learning_rate": 0.00032782277696631704,
      "loss": 0.3612,
      "step": 97800
    },
    {
      "epoch": 3.9807266147559313,
      "grad_norm": 0.22970835864543915,
      "learning_rate": 0.0003276014694816979,
      "loss": 0.3607,
      "step": 97900
    },
    {
      "epoch": 3.9847927297863257,
      "grad_norm": 0.21642518043518066,
      "learning_rate": 0.0003273801619970788,
      "loss": 0.3622,
      "step": 98000
    },
    {
      "epoch": 3.9847927297863257,
      "eval_loss": 0.3714452087879181,
      "eval_runtime": 113.5469,
      "eval_samples_per_second": 1540.35,
      "eval_steps_per_second": 48.139,
      "step": 98000
    },
    {
      "epoch": 3.9888588448167197,
      "grad_norm": 0.2511906027793884,
      "learning_rate": 0.0003271588545124596,
      "loss": 0.3617,
      "step": 98100
    },
    {
      "epoch": 3.992924959847114,
      "grad_norm": 0.24142104387283325,
      "learning_rate": 0.0003269375470278405,
      "loss": 0.3612,
      "step": 98200
    },
    {
      "epoch": 3.996991074877508,
      "grad_norm": 0.22065432369709015,
      "learning_rate": 0.00032671623954322137,
      "loss": 0.3609,
      "step": 98300
    },
    {
      "epoch": 4.001057189907902,
      "grad_norm": 0.27173781394958496,
      "learning_rate": 0.00032649493205860226,
      "loss": 0.3608,
      "step": 98400
    },
    {
      "epoch": 4.005123304938297,
      "grad_norm": 0.25548428297042847,
      "learning_rate": 0.00032627362457398305,
      "loss": 0.3582,
      "step": 98500
    },
    {
      "epoch": 4.009189419968691,
      "grad_norm": 0.27049627900123596,
      "learning_rate": 0.00032605231708936395,
      "loss": 0.3572,
      "step": 98600
    },
    {
      "epoch": 4.013255534999085,
      "grad_norm": 0.259294331073761,
      "learning_rate": 0.00032583100960474485,
      "loss": 0.3561,
      "step": 98700
    },
    {
      "epoch": 4.017321650029479,
      "grad_norm": 0.25625380873680115,
      "learning_rate": 0.0003256097021201257,
      "loss": 0.3615,
      "step": 98800
    },
    {
      "epoch": 4.021387765059874,
      "grad_norm": 0.272797167301178,
      "learning_rate": 0.0003253883946355066,
      "loss": 0.3572,
      "step": 98900
    },
    {
      "epoch": 4.025453880090268,
      "grad_norm": 0.22896935045719147,
      "learning_rate": 0.00032516708715088743,
      "loss": 0.3558,
      "step": 99000
    },
    {
      "epoch": 4.029519995120662,
      "grad_norm": 0.2552487850189209,
      "learning_rate": 0.00032494577966626833,
      "loss": 0.3592,
      "step": 99100
    },
    {
      "epoch": 4.033586110151056,
      "grad_norm": 0.23805828392505646,
      "learning_rate": 0.00032472447218164917,
      "loss": 0.3577,
      "step": 99200
    },
    {
      "epoch": 4.03765222518145,
      "grad_norm": 0.2739441692829132,
      "learning_rate": 0.00032450316469703007,
      "loss": 0.3561,
      "step": 99300
    },
    {
      "epoch": 4.041718340211845,
      "grad_norm": 0.2478051334619522,
      "learning_rate": 0.0003242818572124109,
      "loss": 0.3608,
      "step": 99400
    },
    {
      "epoch": 4.045784455242239,
      "grad_norm": 0.2632409632205963,
      "learning_rate": 0.0003240605497277918,
      "loss": 0.36,
      "step": 99500
    },
    {
      "epoch": 4.049850570272633,
      "grad_norm": 0.29724687337875366,
      "learning_rate": 0.0003238392422431727,
      "loss": 0.3572,
      "step": 99600
    },
    {
      "epoch": 4.053916685303027,
      "grad_norm": 0.24510057270526886,
      "learning_rate": 0.00032361793475855355,
      "loss": 0.3602,
      "step": 99700
    },
    {
      "epoch": 4.057982800333422,
      "grad_norm": 0.26744168996810913,
      "learning_rate": 0.00032339662727393445,
      "loss": 0.3574,
      "step": 99800
    },
    {
      "epoch": 4.062048915363816,
      "grad_norm": 0.21878306567668915,
      "learning_rate": 0.0003231753197893153,
      "loss": 0.3595,
      "step": 99900
    },
    {
      "epoch": 4.06611503039421,
      "grad_norm": 0.27490708231925964,
      "learning_rate": 0.0003229540123046962,
      "loss": 0.3593,
      "step": 100000
    },
    {
      "epoch": 4.06611503039421,
      "eval_loss": 0.3714216649532318,
      "eval_runtime": 113.1416,
      "eval_samples_per_second": 1545.868,
      "eval_steps_per_second": 48.311,
      "step": 100000
    },
    {
      "epoch": 4.070181145424604,
      "grad_norm": 0.2721678912639618,
      "learning_rate": 0.000322732704820077,
      "loss": 0.3573,
      "step": 100100
    },
    {
      "epoch": 4.074247260454999,
      "grad_norm": 0.2628021836280823,
      "learning_rate": 0.0003225113973354579,
      "loss": 0.3569,
      "step": 100200
    },
    {
      "epoch": 4.078313375485393,
      "grad_norm": 0.21529683470726013,
      "learning_rate": 0.0003222900898508387,
      "loss": 0.3589,
      "step": 100300
    },
    {
      "epoch": 4.082379490515787,
      "grad_norm": 0.23459909856319427,
      "learning_rate": 0.0003220687823662196,
      "loss": 0.361,
      "step": 100400
    },
    {
      "epoch": 4.086445605546181,
      "grad_norm": 0.26062601804733276,
      "learning_rate": 0.0003218474748816005,
      "loss": 0.359,
      "step": 100500
    },
    {
      "epoch": 4.0905117205765755,
      "grad_norm": 0.26631999015808105,
      "learning_rate": 0.00032162616739698135,
      "loss": 0.3583,
      "step": 100600
    },
    {
      "epoch": 4.0945778356069695,
      "grad_norm": 0.2575848400592804,
      "learning_rate": 0.00032140485991236225,
      "loss": 0.3592,
      "step": 100700
    },
    {
      "epoch": 4.0986439506373635,
      "grad_norm": 0.26711785793304443,
      "learning_rate": 0.0003211835524277431,
      "loss": 0.3577,
      "step": 100800
    },
    {
      "epoch": 4.1027100656677575,
      "grad_norm": 0.2027970403432846,
      "learning_rate": 0.000320962244943124,
      "loss": 0.3568,
      "step": 100900
    },
    {
      "epoch": 4.1067761806981515,
      "grad_norm": 0.2752786874771118,
      "learning_rate": 0.00032074093745850484,
      "loss": 0.3591,
      "step": 101000
    },
    {
      "epoch": 4.110842295728546,
      "grad_norm": 0.2994707226753235,
      "learning_rate": 0.00032051962997388573,
      "loss": 0.3602,
      "step": 101100
    },
    {
      "epoch": 4.11490841075894,
      "grad_norm": 0.26352378726005554,
      "learning_rate": 0.0003202983224892666,
      "loss": 0.3568,
      "step": 101200
    },
    {
      "epoch": 4.118974525789334,
      "grad_norm": 0.2525896430015564,
      "learning_rate": 0.00032007701500464747,
      "loss": 0.3579,
      "step": 101300
    },
    {
      "epoch": 4.123040640819728,
      "grad_norm": 0.245535209774971,
      "learning_rate": 0.00031985570752002837,
      "loss": 0.3587,
      "step": 101400
    },
    {
      "epoch": 4.127106755850123,
      "grad_norm": 0.26798662543296814,
      "learning_rate": 0.0003196344000354092,
      "loss": 0.3592,
      "step": 101500
    },
    {
      "epoch": 4.131172870880517,
      "grad_norm": 0.26851290464401245,
      "learning_rate": 0.0003194130925507901,
      "loss": 0.3584,
      "step": 101600
    },
    {
      "epoch": 4.135238985910911,
      "grad_norm": 0.22737367451190948,
      "learning_rate": 0.00031919178506617095,
      "loss": 0.3576,
      "step": 101700
    },
    {
      "epoch": 4.139305100941305,
      "grad_norm": 0.26366913318634033,
      "learning_rate": 0.0003189704775815518,
      "loss": 0.3606,
      "step": 101800
    },
    {
      "epoch": 4.1433712159717,
      "grad_norm": 0.23182834684848785,
      "learning_rate": 0.00031874917009693264,
      "loss": 0.359,
      "step": 101900
    },
    {
      "epoch": 4.147437331002094,
      "grad_norm": 0.22263377904891968,
      "learning_rate": 0.00031852786261231354,
      "loss": 0.357,
      "step": 102000
    },
    {
      "epoch": 4.147437331002094,
      "eval_loss": 0.37030383944511414,
      "eval_runtime": 114.0385,
      "eval_samples_per_second": 1533.71,
      "eval_steps_per_second": 47.931,
      "step": 102000
    },
    {
      "epoch": 4.151503446032488,
      "grad_norm": 0.26913002133369446,
      "learning_rate": 0.00031830655512769443,
      "loss": 0.3591,
      "step": 102100
    },
    {
      "epoch": 4.155569561062882,
      "grad_norm": 0.26355525851249695,
      "learning_rate": 0.0003180852476430753,
      "loss": 0.3595,
      "step": 102200
    },
    {
      "epoch": 4.159635676093277,
      "grad_norm": 0.263887494802475,
      "learning_rate": 0.0003178639401584562,
      "loss": 0.3578,
      "step": 102300
    },
    {
      "epoch": 4.163701791123671,
      "grad_norm": 0.2590482532978058,
      "learning_rate": 0.000317642632673837,
      "loss": 0.3572,
      "step": 102400
    },
    {
      "epoch": 4.167767906154065,
      "grad_norm": 0.2344169318675995,
      "learning_rate": 0.0003174213251892179,
      "loss": 0.3571,
      "step": 102500
    },
    {
      "epoch": 4.171834021184459,
      "grad_norm": 0.2615201771259308,
      "learning_rate": 0.00031720001770459876,
      "loss": 0.3566,
      "step": 102600
    },
    {
      "epoch": 4.175900136214853,
      "grad_norm": 0.2447270303964615,
      "learning_rate": 0.00031697871021997966,
      "loss": 0.3576,
      "step": 102700
    },
    {
      "epoch": 4.179966251245248,
      "grad_norm": 0.25871193408966064,
      "learning_rate": 0.0003167574027353605,
      "loss": 0.3576,
      "step": 102800
    },
    {
      "epoch": 4.184032366275642,
      "grad_norm": 0.24452292919158936,
      "learning_rate": 0.0003165360952507414,
      "loss": 0.3597,
      "step": 102900
    },
    {
      "epoch": 4.188098481306036,
      "grad_norm": 0.2515713572502136,
      "learning_rate": 0.0003163147877661223,
      "loss": 0.3571,
      "step": 103000
    },
    {
      "epoch": 4.19216459633643,
      "grad_norm": 0.2594355344772339,
      "learning_rate": 0.00031609348028150314,
      "loss": 0.3603,
      "step": 103100
    },
    {
      "epoch": 4.196230711366825,
      "grad_norm": 0.24378061294555664,
      "learning_rate": 0.00031587217279688403,
      "loss": 0.3593,
      "step": 103200
    },
    {
      "epoch": 4.200296826397219,
      "grad_norm": 0.2661110758781433,
      "learning_rate": 0.0003156508653122649,
      "loss": 0.3556,
      "step": 103300
    },
    {
      "epoch": 4.204362941427613,
      "grad_norm": 0.24766306579113007,
      "learning_rate": 0.0003154295578276458,
      "loss": 0.357,
      "step": 103400
    },
    {
      "epoch": 4.208429056458007,
      "grad_norm": 0.2288781702518463,
      "learning_rate": 0.00031520825034302656,
      "loss": 0.3574,
      "step": 103500
    },
    {
      "epoch": 4.212495171488402,
      "grad_norm": 0.25890371203422546,
      "learning_rate": 0.00031498694285840746,
      "loss": 0.3569,
      "step": 103600
    },
    {
      "epoch": 4.216561286518796,
      "grad_norm": 0.2434816211462021,
      "learning_rate": 0.0003147656353737883,
      "loss": 0.3569,
      "step": 103700
    },
    {
      "epoch": 4.22062740154919,
      "grad_norm": 0.2597056031227112,
      "learning_rate": 0.0003145443278891692,
      "loss": 0.3584,
      "step": 103800
    },
    {
      "epoch": 4.224693516579584,
      "grad_norm": 0.26739662885665894,
      "learning_rate": 0.0003143230204045501,
      "loss": 0.36,
      "step": 103900
    },
    {
      "epoch": 4.228759631609979,
      "grad_norm": 0.27504590153694153,
      "learning_rate": 0.00031410171291993094,
      "loss": 0.3599,
      "step": 104000
    },
    {
      "epoch": 4.228759631609979,
      "eval_loss": 0.3694014847278595,
      "eval_runtime": 114.2835,
      "eval_samples_per_second": 1530.422,
      "eval_steps_per_second": 47.828,
      "step": 104000
    },
    {
      "epoch": 4.232825746640373,
      "grad_norm": 0.2604079246520996,
      "learning_rate": 0.00031388040543531184,
      "loss": 0.3585,
      "step": 104100
    },
    {
      "epoch": 4.236891861670767,
      "grad_norm": 0.2731584310531616,
      "learning_rate": 0.0003136590979506927,
      "loss": 0.3598,
      "step": 104200
    },
    {
      "epoch": 4.240957976701161,
      "grad_norm": 0.2544620633125305,
      "learning_rate": 0.0003134377904660736,
      "loss": 0.3601,
      "step": 104300
    },
    {
      "epoch": 4.245024091731555,
      "grad_norm": 0.2555258274078369,
      "learning_rate": 0.0003132164829814544,
      "loss": 0.3588,
      "step": 104400
    },
    {
      "epoch": 4.24909020676195,
      "grad_norm": 0.2712520658969879,
      "learning_rate": 0.0003129951754968353,
      "loss": 0.3584,
      "step": 104500
    },
    {
      "epoch": 4.253156321792344,
      "grad_norm": 0.2809957265853882,
      "learning_rate": 0.00031277386801221616,
      "loss": 0.3597,
      "step": 104600
    },
    {
      "epoch": 4.257222436822738,
      "grad_norm": 0.2633373439311981,
      "learning_rate": 0.00031255256052759706,
      "loss": 0.3587,
      "step": 104700
    },
    {
      "epoch": 4.261288551853132,
      "grad_norm": 0.27035319805145264,
      "learning_rate": 0.00031233125304297796,
      "loss": 0.3563,
      "step": 104800
    },
    {
      "epoch": 4.2653546668835265,
      "grad_norm": 0.26699790358543396,
      "learning_rate": 0.0003121099455583588,
      "loss": 0.358,
      "step": 104900
    },
    {
      "epoch": 4.2694207819139205,
      "grad_norm": 0.26788026094436646,
      "learning_rate": 0.0003118886380737397,
      "loss": 0.3599,
      "step": 105000
    },
    {
      "epoch": 4.2734868969443145,
      "grad_norm": 0.2662062644958496,
      "learning_rate": 0.00031166733058912054,
      "loss": 0.3589,
      "step": 105100
    },
    {
      "epoch": 4.2775530119747085,
      "grad_norm": 0.2905649244785309,
      "learning_rate": 0.0003114460231045014,
      "loss": 0.3577,
      "step": 105200
    },
    {
      "epoch": 4.281619127005103,
      "grad_norm": 0.27681058645248413,
      "learning_rate": 0.00031122471561988223,
      "loss": 0.3585,
      "step": 105300
    },
    {
      "epoch": 4.285685242035497,
      "grad_norm": 0.3088572025299072,
      "learning_rate": 0.0003110034081352631,
      "loss": 0.357,
      "step": 105400
    },
    {
      "epoch": 4.289751357065891,
      "grad_norm": 0.24015918374061584,
      "learning_rate": 0.000310782100650644,
      "loss": 0.3561,
      "step": 105500
    },
    {
      "epoch": 4.293817472096285,
      "grad_norm": 0.2876666188240051,
      "learning_rate": 0.00031056079316602487,
      "loss": 0.3575,
      "step": 105600
    },
    {
      "epoch": 4.29788358712668,
      "grad_norm": 0.25922390818595886,
      "learning_rate": 0.00031033948568140576,
      "loss": 0.358,
      "step": 105700
    },
    {
      "epoch": 4.301949702157074,
      "grad_norm": 0.260194331407547,
      "learning_rate": 0.0003101181781967866,
      "loss": 0.3588,
      "step": 105800
    },
    {
      "epoch": 4.306015817187468,
      "grad_norm": 0.2749936580657959,
      "learning_rate": 0.0003098968707121675,
      "loss": 0.3594,
      "step": 105900
    },
    {
      "epoch": 4.310081932217862,
      "grad_norm": 0.2764592468738556,
      "learning_rate": 0.00030967556322754835,
      "loss": 0.36,
      "step": 106000
    },
    {
      "epoch": 4.310081932217862,
      "eval_loss": 0.36957934498786926,
      "eval_runtime": 114.6394,
      "eval_samples_per_second": 1525.671,
      "eval_steps_per_second": 47.68,
      "step": 106000
    },
    {
      "epoch": 4.314148047248256,
      "grad_norm": 0.2583886682987213,
      "learning_rate": 0.00030945425574292924,
      "loss": 0.3593,
      "step": 106100
    },
    {
      "epoch": 4.318214162278651,
      "grad_norm": 0.2743639647960663,
      "learning_rate": 0.0003092329482583101,
      "loss": 0.3589,
      "step": 106200
    },
    {
      "epoch": 4.322280277309045,
      "grad_norm": 0.24636316299438477,
      "learning_rate": 0.000309011640773691,
      "loss": 0.356,
      "step": 106300
    },
    {
      "epoch": 4.326346392339439,
      "grad_norm": 0.29073360562324524,
      "learning_rate": 0.0003087903332890719,
      "loss": 0.3553,
      "step": 106400
    },
    {
      "epoch": 4.330412507369833,
      "grad_norm": 0.27553972601890564,
      "learning_rate": 0.0003085690258044527,
      "loss": 0.3571,
      "step": 106500
    },
    {
      "epoch": 4.334478622400228,
      "grad_norm": 0.26193007826805115,
      "learning_rate": 0.0003083477183198336,
      "loss": 0.3563,
      "step": 106600
    },
    {
      "epoch": 4.338544737430622,
      "grad_norm": 0.29973530769348145,
      "learning_rate": 0.00030812641083521446,
      "loss": 0.3605,
      "step": 106700
    },
    {
      "epoch": 4.342610852461016,
      "grad_norm": 0.26817867159843445,
      "learning_rate": 0.00030790510335059536,
      "loss": 0.3591,
      "step": 106800
    },
    {
      "epoch": 4.34667696749141,
      "grad_norm": 0.26453277468681335,
      "learning_rate": 0.00030768379586597615,
      "loss": 0.3607,
      "step": 106900
    },
    {
      "epoch": 4.350743082521804,
      "grad_norm": 0.2799331545829773,
      "learning_rate": 0.00030746248838135705,
      "loss": 0.3594,
      "step": 107000
    },
    {
      "epoch": 4.354809197552199,
      "grad_norm": 0.26708292961120605,
      "learning_rate": 0.0003072411808967379,
      "loss": 0.3607,
      "step": 107100
    },
    {
      "epoch": 4.358875312582593,
      "grad_norm": 0.25430747866630554,
      "learning_rate": 0.0003070198734121188,
      "loss": 0.3586,
      "step": 107200
    },
    {
      "epoch": 4.362941427612987,
      "grad_norm": 0.329574316740036,
      "learning_rate": 0.0003067985659274997,
      "loss": 0.3583,
      "step": 107300
    },
    {
      "epoch": 4.367007542643381,
      "grad_norm": 0.28005385398864746,
      "learning_rate": 0.00030657725844288053,
      "loss": 0.3599,
      "step": 107400
    },
    {
      "epoch": 4.371073657673776,
      "grad_norm": 0.2482161521911621,
      "learning_rate": 0.0003063559509582614,
      "loss": 0.3612,
      "step": 107500
    },
    {
      "epoch": 4.37513977270417,
      "grad_norm": 0.2757086157798767,
      "learning_rate": 0.00030613464347364227,
      "loss": 0.3588,
      "step": 107600
    },
    {
      "epoch": 4.379205887734564,
      "grad_norm": 0.2796420753002167,
      "learning_rate": 0.00030591333598902317,
      "loss": 0.3562,
      "step": 107700
    },
    {
      "epoch": 4.383272002764958,
      "grad_norm": 0.2599547505378723,
      "learning_rate": 0.000305692028504404,
      "loss": 0.358,
      "step": 107800
    },
    {
      "epoch": 4.387338117795353,
      "grad_norm": 0.25044339895248413,
      "learning_rate": 0.0003054707210197849,
      "loss": 0.359,
      "step": 107900
    },
    {
      "epoch": 4.391404232825747,
      "grad_norm": 0.24726592004299164,
      "learning_rate": 0.00030524941353516575,
      "loss": 0.3574,
      "step": 108000
    },
    {
      "epoch": 4.391404232825747,
      "eval_loss": 0.36901670694351196,
      "eval_runtime": 114.5745,
      "eval_samples_per_second": 1526.535,
      "eval_steps_per_second": 47.707,
      "step": 108000
    },
    {
      "epoch": 4.395470347856141,
      "grad_norm": 0.2721192240715027,
      "learning_rate": 0.00030502810605054665,
      "loss": 0.3584,
      "step": 108100
    },
    {
      "epoch": 4.399536462886535,
      "grad_norm": 0.2560894787311554,
      "learning_rate": 0.00030480679856592755,
      "loss": 0.3591,
      "step": 108200
    },
    {
      "epoch": 4.40360257791693,
      "grad_norm": 0.28631460666656494,
      "learning_rate": 0.0003045854910813084,
      "loss": 0.3583,
      "step": 108300
    },
    {
      "epoch": 4.407668692947324,
      "grad_norm": 0.27935001254081726,
      "learning_rate": 0.0003043641835966893,
      "loss": 0.3588,
      "step": 108400
    },
    {
      "epoch": 4.411734807977718,
      "grad_norm": 0.24592366814613342,
      "learning_rate": 0.00030414287611207013,
      "loss": 0.3591,
      "step": 108500
    },
    {
      "epoch": 4.415800923008112,
      "grad_norm": 0.285506010055542,
      "learning_rate": 0.00030392156862745097,
      "loss": 0.3571,
      "step": 108600
    },
    {
      "epoch": 4.419867038038506,
      "grad_norm": 0.25003781914711,
      "learning_rate": 0.0003037002611428318,
      "loss": 0.3584,
      "step": 108700
    },
    {
      "epoch": 4.423933153068901,
      "grad_norm": 0.2910414934158325,
      "learning_rate": 0.0003034789536582127,
      "loss": 0.3591,
      "step": 108800
    },
    {
      "epoch": 4.427999268099295,
      "grad_norm": 0.28658178448677063,
      "learning_rate": 0.00030325764617359356,
      "loss": 0.3583,
      "step": 108900
    },
    {
      "epoch": 4.432065383129689,
      "grad_norm": 0.2224659025669098,
      "learning_rate": 0.00030303633868897445,
      "loss": 0.3592,
      "step": 109000
    },
    {
      "epoch": 4.436131498160083,
      "grad_norm": 0.2647169530391693,
      "learning_rate": 0.00030281503120435535,
      "loss": 0.3616,
      "step": 109100
    },
    {
      "epoch": 4.4401976131904775,
      "grad_norm": 0.27512532472610474,
      "learning_rate": 0.0003025937237197362,
      "loss": 0.3582,
      "step": 109200
    },
    {
      "epoch": 4.4442637282208715,
      "grad_norm": 0.3428255319595337,
      "learning_rate": 0.0003023724162351171,
      "loss": 0.3588,
      "step": 109300
    },
    {
      "epoch": 4.4483298432512655,
      "grad_norm": 0.2556435465812683,
      "learning_rate": 0.00030215110875049793,
      "loss": 0.3573,
      "step": 109400
    },
    {
      "epoch": 4.4523959582816595,
      "grad_norm": 0.2918087840080261,
      "learning_rate": 0.00030192980126587883,
      "loss": 0.3564,
      "step": 109500
    },
    {
      "epoch": 4.456462073312054,
      "grad_norm": 0.2432025521993637,
      "learning_rate": 0.0003017084937812597,
      "loss": 0.3582,
      "step": 109600
    },
    {
      "epoch": 4.460528188342448,
      "grad_norm": 0.27152150869369507,
      "learning_rate": 0.00030148718629664057,
      "loss": 0.3571,
      "step": 109700
    },
    {
      "epoch": 4.464594303372842,
      "grad_norm": 0.25922659039497375,
      "learning_rate": 0.00030126587881202147,
      "loss": 0.3564,
      "step": 109800
    },
    {
      "epoch": 4.468660418403236,
      "grad_norm": 0.24187104403972626,
      "learning_rate": 0.0003010445713274023,
      "loss": 0.3573,
      "step": 109900
    },
    {
      "epoch": 4.472726533433631,
      "grad_norm": 0.2692602574825287,
      "learning_rate": 0.0003008232638427832,
      "loss": 0.3584,
      "step": 110000
    },
    {
      "epoch": 4.472726533433631,
      "eval_loss": 0.3683944046497345,
      "eval_runtime": 114.552,
      "eval_samples_per_second": 1526.835,
      "eval_steps_per_second": 47.716,
      "step": 110000
    },
    {
      "epoch": 4.476792648464025,
      "grad_norm": 0.3186574876308441,
      "learning_rate": 0.00030060195635816405,
      "loss": 0.3577,
      "step": 110100
    },
    {
      "epoch": 4.480858763494419,
      "grad_norm": 0.2677055597305298,
      "learning_rate": 0.00030038064887354495,
      "loss": 0.3613,
      "step": 110200
    },
    {
      "epoch": 4.484924878524813,
      "grad_norm": 0.24090133607387543,
      "learning_rate": 0.00030015934138892574,
      "loss": 0.359,
      "step": 110300
    },
    {
      "epoch": 4.488990993555207,
      "grad_norm": 0.27916577458381653,
      "learning_rate": 0.00029993803390430664,
      "loss": 0.3576,
      "step": 110400
    },
    {
      "epoch": 4.493057108585602,
      "grad_norm": 0.27805614471435547,
      "learning_rate": 0.0002997167264196875,
      "loss": 0.3594,
      "step": 110500
    },
    {
      "epoch": 4.497123223615996,
      "grad_norm": 0.27501189708709717,
      "learning_rate": 0.0002994954189350684,
      "loss": 0.3583,
      "step": 110600
    },
    {
      "epoch": 4.50118933864639,
      "grad_norm": 0.3642600476741791,
      "learning_rate": 0.0002992741114504493,
      "loss": 0.3594,
      "step": 110700
    },
    {
      "epoch": 4.505255453676784,
      "grad_norm": 0.2723526060581207,
      "learning_rate": 0.0002990528039658301,
      "loss": 0.3557,
      "step": 110800
    },
    {
      "epoch": 4.509321568707179,
      "grad_norm": 0.24906501173973083,
      "learning_rate": 0.000298831496481211,
      "loss": 0.3571,
      "step": 110900
    },
    {
      "epoch": 4.513387683737573,
      "grad_norm": 0.2993667423725128,
      "learning_rate": 0.00029861018899659186,
      "loss": 0.3581,
      "step": 111000
    },
    {
      "epoch": 4.517453798767967,
      "grad_norm": 0.3300936222076416,
      "learning_rate": 0.00029838888151197275,
      "loss": 0.3581,
      "step": 111100
    },
    {
      "epoch": 4.521519913798361,
      "grad_norm": 0.2931194007396698,
      "learning_rate": 0.0002981675740273536,
      "loss": 0.3571,
      "step": 111200
    },
    {
      "epoch": 4.525586028828756,
      "grad_norm": 0.27035337686538696,
      "learning_rate": 0.0002979462665427345,
      "loss": 0.3588,
      "step": 111300
    },
    {
      "epoch": 4.52965214385915,
      "grad_norm": 0.24127908051013947,
      "learning_rate": 0.00029772495905811534,
      "loss": 0.3565,
      "step": 111400
    },
    {
      "epoch": 4.533718258889544,
      "grad_norm": 0.29642876982688904,
      "learning_rate": 0.00029750365157349624,
      "loss": 0.3587,
      "step": 111500
    },
    {
      "epoch": 4.537784373919938,
      "grad_norm": 0.2558536231517792,
      "learning_rate": 0.00029728234408887713,
      "loss": 0.3573,
      "step": 111600
    },
    {
      "epoch": 4.541850488950333,
      "grad_norm": 0.28011706471443176,
      "learning_rate": 0.000297061036604258,
      "loss": 0.359,
      "step": 111700
    },
    {
      "epoch": 4.545916603980727,
      "grad_norm": 0.318739652633667,
      "learning_rate": 0.0002968397291196389,
      "loss": 0.3571,
      "step": 111800
    },
    {
      "epoch": 4.549982719011121,
      "grad_norm": 0.24115106463432312,
      "learning_rate": 0.00029661842163501966,
      "loss": 0.3578,
      "step": 111900
    },
    {
      "epoch": 4.554048834041515,
      "grad_norm": 0.30597132444381714,
      "learning_rate": 0.00029639711415040056,
      "loss": 0.3562,
      "step": 112000
    },
    {
      "epoch": 4.554048834041515,
      "eval_loss": 0.36828580498695374,
      "eval_runtime": 116.3047,
      "eval_samples_per_second": 1503.825,
      "eval_steps_per_second": 46.997,
      "step": 112000
    },
    {
      "epoch": 4.558114949071909,
      "grad_norm": 0.29627326130867004,
      "learning_rate": 0.0002961758066657814,
      "loss": 0.3589,
      "step": 112100
    },
    {
      "epoch": 4.562181064102304,
      "grad_norm": 0.2751227617263794,
      "learning_rate": 0.0002959544991811623,
      "loss": 0.3585,
      "step": 112200
    },
    {
      "epoch": 4.566247179132698,
      "grad_norm": 0.2757367491722107,
      "learning_rate": 0.00029573319169654314,
      "loss": 0.3597,
      "step": 112300
    },
    {
      "epoch": 4.570313294163092,
      "grad_norm": 0.22802479565143585,
      "learning_rate": 0.00029551188421192404,
      "loss": 0.3542,
      "step": 112400
    },
    {
      "epoch": 4.574379409193486,
      "grad_norm": 0.2874675989151001,
      "learning_rate": 0.00029529057672730494,
      "loss": 0.3553,
      "step": 112500
    },
    {
      "epoch": 4.578445524223881,
      "grad_norm": 0.2583809792995453,
      "learning_rate": 0.0002950692692426858,
      "loss": 0.3578,
      "step": 112600
    },
    {
      "epoch": 4.582511639254275,
      "grad_norm": 0.2396027147769928,
      "learning_rate": 0.0002948479617580667,
      "loss": 0.3592,
      "step": 112700
    },
    {
      "epoch": 4.586577754284669,
      "grad_norm": 0.26868852972984314,
      "learning_rate": 0.0002946266542734475,
      "loss": 0.3584,
      "step": 112800
    },
    {
      "epoch": 4.590643869315063,
      "grad_norm": 0.2652552127838135,
      "learning_rate": 0.0002944053467888284,
      "loss": 0.358,
      "step": 112900
    },
    {
      "epoch": 4.5947099843454575,
      "grad_norm": 0.2859591543674469,
      "learning_rate": 0.00029418403930420926,
      "loss": 0.3578,
      "step": 113000
    },
    {
      "epoch": 4.5987760993758515,
      "grad_norm": 0.2826969623565674,
      "learning_rate": 0.00029396273181959016,
      "loss": 0.3573,
      "step": 113100
    },
    {
      "epoch": 4.6028422144062455,
      "grad_norm": 0.26187536120414734,
      "learning_rate": 0.00029374142433497106,
      "loss": 0.3569,
      "step": 113200
    },
    {
      "epoch": 4.6069083294366395,
      "grad_norm": 0.3529934883117676,
      "learning_rate": 0.0002935201168503519,
      "loss": 0.3575,
      "step": 113300
    },
    {
      "epoch": 4.610974444467034,
      "grad_norm": 0.286196231842041,
      "learning_rate": 0.0002932988093657328,
      "loss": 0.3562,
      "step": 113400
    },
    {
      "epoch": 4.615040559497428,
      "grad_norm": 0.23516502976417542,
      "learning_rate": 0.00029307750188111364,
      "loss": 0.358,
      "step": 113500
    },
    {
      "epoch": 4.619106674527822,
      "grad_norm": 0.26889723539352417,
      "learning_rate": 0.0002928561943964945,
      "loss": 0.3594,
      "step": 113600
    },
    {
      "epoch": 4.623172789558216,
      "grad_norm": 0.2629387080669403,
      "learning_rate": 0.0002926348869118753,
      "loss": 0.3588,
      "step": 113700
    },
    {
      "epoch": 4.62723890458861,
      "grad_norm": 0.2808358669281006,
      "learning_rate": 0.0002924135794272562,
      "loss": 0.3569,
      "step": 113800
    },
    {
      "epoch": 4.631305019619005,
      "grad_norm": 0.2753750681877136,
      "learning_rate": 0.00029219227194263707,
      "loss": 0.3577,
      "step": 113900
    },
    {
      "epoch": 4.635371134649399,
      "grad_norm": 0.3185809254646301,
      "learning_rate": 0.00029197096445801796,
      "loss": 0.3586,
      "step": 114000
    },
    {
      "epoch": 4.635371134649399,
      "eval_loss": 0.3683858811855316,
      "eval_runtime": 113.9801,
      "eval_samples_per_second": 1534.495,
      "eval_steps_per_second": 47.956,
      "step": 114000
    },
    {
      "epoch": 4.639437249679793,
      "grad_norm": 0.24351681768894196,
      "learning_rate": 0.00029174965697339886,
      "loss": 0.3571,
      "step": 114100
    },
    {
      "epoch": 4.643503364710187,
      "grad_norm": 0.24002626538276672,
      "learning_rate": 0.0002915283494887797,
      "loss": 0.3585,
      "step": 114200
    },
    {
      "epoch": 4.647569479740582,
      "grad_norm": 0.2553402781486511,
      "learning_rate": 0.0002913070420041606,
      "loss": 0.3576,
      "step": 114300
    },
    {
      "epoch": 4.651635594770976,
      "grad_norm": 0.2913469076156616,
      "learning_rate": 0.00029108573451954144,
      "loss": 0.3585,
      "step": 114400
    },
    {
      "epoch": 4.65570170980137,
      "grad_norm": 0.29377487301826477,
      "learning_rate": 0.00029086442703492234,
      "loss": 0.3569,
      "step": 114500
    },
    {
      "epoch": 4.659767824831764,
      "grad_norm": 0.2551237642765045,
      "learning_rate": 0.0002906431195503032,
      "loss": 0.3569,
      "step": 114600
    },
    {
      "epoch": 4.663833939862158,
      "grad_norm": 0.252288818359375,
      "learning_rate": 0.0002904218120656841,
      "loss": 0.3554,
      "step": 114700
    },
    {
      "epoch": 4.667900054892553,
      "grad_norm": 0.23820532858371735,
      "learning_rate": 0.0002902005045810649,
      "loss": 0.3587,
      "step": 114800
    },
    {
      "epoch": 4.671966169922947,
      "grad_norm": 0.28317588567733765,
      "learning_rate": 0.0002899791970964458,
      "loss": 0.3566,
      "step": 114900
    },
    {
      "epoch": 4.676032284953341,
      "grad_norm": 0.2799343466758728,
      "learning_rate": 0.0002897578896118267,
      "loss": 0.3566,
      "step": 115000
    },
    {
      "epoch": 4.680098399983736,
      "grad_norm": 0.24706880748271942,
      "learning_rate": 0.00028953658212720756,
      "loss": 0.3537,
      "step": 115100
    },
    {
      "epoch": 4.68416451501413,
      "grad_norm": 0.2474113255739212,
      "learning_rate": 0.00028931527464258846,
      "loss": 0.3574,
      "step": 115200
    },
    {
      "epoch": 4.688230630044524,
      "grad_norm": 0.28143036365509033,
      "learning_rate": 0.00028909396715796925,
      "loss": 0.3568,
      "step": 115300
    },
    {
      "epoch": 4.692296745074918,
      "grad_norm": 0.27421489357948303,
      "learning_rate": 0.00028887265967335015,
      "loss": 0.3581,
      "step": 115400
    },
    {
      "epoch": 4.696362860105312,
      "grad_norm": 0.30384936928749084,
      "learning_rate": 0.000288651352188731,
      "loss": 0.3571,
      "step": 115500
    },
    {
      "epoch": 4.700428975135707,
      "grad_norm": 0.2552129626274109,
      "learning_rate": 0.0002884300447041119,
      "loss": 0.3583,
      "step": 115600
    },
    {
      "epoch": 4.704495090166101,
      "grad_norm": 0.26996728777885437,
      "learning_rate": 0.00028820873721949273,
      "loss": 0.3563,
      "step": 115700
    },
    {
      "epoch": 4.708561205196495,
      "grad_norm": 0.2771793305873871,
      "learning_rate": 0.00028798742973487363,
      "loss": 0.3563,
      "step": 115800
    },
    {
      "epoch": 4.712627320226889,
      "grad_norm": 0.2930358052253723,
      "learning_rate": 0.0002877661222502545,
      "loss": 0.3569,
      "step": 115900
    },
    {
      "epoch": 4.716693435257284,
      "grad_norm": 0.29926052689552307,
      "learning_rate": 0.00028754481476563537,
      "loss": 0.3587,
      "step": 116000
    },
    {
      "epoch": 4.716693435257284,
      "eval_loss": 0.3686261773109436,
      "eval_runtime": 116.4728,
      "eval_samples_per_second": 1501.655,
      "eval_steps_per_second": 46.929,
      "step": 116000
    },
    {
      "epoch": 4.720759550287678,
      "grad_norm": 0.29963091015815735,
      "learning_rate": 0.00028732350728101627,
      "loss": 0.3573,
      "step": 116100
    },
    {
      "epoch": 4.724825665318072,
      "grad_norm": 0.2436000257730484,
      "learning_rate": 0.0002871021997963971,
      "loss": 0.3556,
      "step": 116200
    },
    {
      "epoch": 4.728891780348466,
      "grad_norm": 0.26237407326698303,
      "learning_rate": 0.000286880892311778,
      "loss": 0.3558,
      "step": 116300
    },
    {
      "epoch": 4.73295789537886,
      "grad_norm": 0.2856149673461914,
      "learning_rate": 0.00028665958482715885,
      "loss": 0.3581,
      "step": 116400
    },
    {
      "epoch": 4.737024010409255,
      "grad_norm": 0.2760984003543854,
      "learning_rate": 0.00028643827734253975,
      "loss": 0.3564,
      "step": 116500
    },
    {
      "epoch": 4.741090125439649,
      "grad_norm": 0.2998141050338745,
      "learning_rate": 0.00028621696985792064,
      "loss": 0.3579,
      "step": 116600
    },
    {
      "epoch": 4.745156240470043,
      "grad_norm": 0.27283021807670593,
      "learning_rate": 0.0002859956623733015,
      "loss": 0.3566,
      "step": 116700
    },
    {
      "epoch": 4.749222355500438,
      "grad_norm": 0.2492537945508957,
      "learning_rate": 0.0002857743548886824,
      "loss": 0.3594,
      "step": 116800
    },
    {
      "epoch": 4.753288470530832,
      "grad_norm": 0.30464598536491394,
      "learning_rate": 0.00028555304740406323,
      "loss": 0.3559,
      "step": 116900
    },
    {
      "epoch": 4.757354585561226,
      "grad_norm": 0.2583514451980591,
      "learning_rate": 0.00028533173991944407,
      "loss": 0.3581,
      "step": 117000
    },
    {
      "epoch": 4.76142070059162,
      "grad_norm": 0.2699941098690033,
      "learning_rate": 0.0002851104324348249,
      "loss": 0.3584,
      "step": 117100
    },
    {
      "epoch": 4.765486815622014,
      "grad_norm": 0.2684329152107239,
      "learning_rate": 0.0002848891249502058,
      "loss": 0.3565,
      "step": 117200
    },
    {
      "epoch": 4.7695529306524085,
      "grad_norm": 0.28536099195480347,
      "learning_rate": 0.00028466781746558665,
      "loss": 0.3563,
      "step": 117300
    },
    {
      "epoch": 4.7736190456828025,
      "grad_norm": 0.2979646921157837,
      "learning_rate": 0.00028444650998096755,
      "loss": 0.3576,
      "step": 117400
    },
    {
      "epoch": 4.7776851607131965,
      "grad_norm": 0.2886320650577545,
      "learning_rate": 0.00028422520249634845,
      "loss": 0.357,
      "step": 117500
    },
    {
      "epoch": 4.7817512757435905,
      "grad_norm": 0.294342964887619,
      "learning_rate": 0.0002840038950117293,
      "loss": 0.3571,
      "step": 117600
    },
    {
      "epoch": 4.785817390773985,
      "grad_norm": 0.29775694012641907,
      "learning_rate": 0.0002837825875271102,
      "loss": 0.3569,
      "step": 117700
    },
    {
      "epoch": 4.789883505804379,
      "grad_norm": 0.2807530462741852,
      "learning_rate": 0.00028356128004249103,
      "loss": 0.3561,
      "step": 117800
    },
    {
      "epoch": 4.793949620834773,
      "grad_norm": 0.28744804859161377,
      "learning_rate": 0.00028333997255787193,
      "loss": 0.3564,
      "step": 117900
    },
    {
      "epoch": 4.798015735865167,
      "grad_norm": 0.2923423647880554,
      "learning_rate": 0.00028311866507325277,
      "loss": 0.3596,
      "step": 118000
    },
    {
      "epoch": 4.798015735865167,
      "eval_loss": 0.3672460913658142,
      "eval_runtime": 113.9182,
      "eval_samples_per_second": 1535.33,
      "eval_steps_per_second": 47.982,
      "step": 118000
    },
    {
      "epoch": 4.802081850895561,
      "grad_norm": 0.285200297832489,
      "learning_rate": 0.00028289735758863367,
      "loss": 0.3595,
      "step": 118100
    },
    {
      "epoch": 4.806147965925956,
      "grad_norm": 0.2855869233608246,
      "learning_rate": 0.0002826760501040145,
      "loss": 0.3574,
      "step": 118200
    },
    {
      "epoch": 4.81021408095635,
      "grad_norm": 0.26352980732917786,
      "learning_rate": 0.0002824547426193954,
      "loss": 0.3565,
      "step": 118300
    },
    {
      "epoch": 4.814280195986744,
      "grad_norm": 0.26786288619041443,
      "learning_rate": 0.0002822334351347763,
      "loss": 0.3567,
      "step": 118400
    },
    {
      "epoch": 4.818346311017139,
      "grad_norm": 0.2769320607185364,
      "learning_rate": 0.00028201212765015715,
      "loss": 0.3545,
      "step": 118500
    },
    {
      "epoch": 4.822412426047533,
      "grad_norm": 0.2869698405265808,
      "learning_rate": 0.00028179082016553805,
      "loss": 0.3556,
      "step": 118600
    },
    {
      "epoch": 4.826478541077927,
      "grad_norm": 0.29435932636260986,
      "learning_rate": 0.00028156951268091884,
      "loss": 0.3563,
      "step": 118700
    },
    {
      "epoch": 4.830544656108321,
      "grad_norm": 0.2844902276992798,
      "learning_rate": 0.00028134820519629973,
      "loss": 0.3567,
      "step": 118800
    },
    {
      "epoch": 4.834610771138715,
      "grad_norm": 0.2843534052371979,
      "learning_rate": 0.0002811268977116806,
      "loss": 0.3578,
      "step": 118900
    },
    {
      "epoch": 4.83867688616911,
      "grad_norm": 0.325648695230484,
      "learning_rate": 0.0002809055902270615,
      "loss": 0.357,
      "step": 119000
    },
    {
      "epoch": 4.842743001199504,
      "grad_norm": 0.2988381087779999,
      "learning_rate": 0.0002806842827424423,
      "loss": 0.3554,
      "step": 119100
    },
    {
      "epoch": 4.846809116229898,
      "grad_norm": 0.2774618864059448,
      "learning_rate": 0.0002804629752578232,
      "loss": 0.3567,
      "step": 119200
    },
    {
      "epoch": 4.850875231260292,
      "grad_norm": 0.2994065284729004,
      "learning_rate": 0.0002802416677732041,
      "loss": 0.3558,
      "step": 119300
    },
    {
      "epoch": 4.854941346290687,
      "grad_norm": 0.25919434428215027,
      "learning_rate": 0.00028002036028858496,
      "loss": 0.3554,
      "step": 119400
    },
    {
      "epoch": 4.859007461321081,
      "grad_norm": 0.27242404222488403,
      "learning_rate": 0.00027979905280396585,
      "loss": 0.3569,
      "step": 119500
    },
    {
      "epoch": 4.863073576351475,
      "grad_norm": 0.29870516061782837,
      "learning_rate": 0.0002795777453193467,
      "loss": 0.3586,
      "step": 119600
    },
    {
      "epoch": 4.867139691381869,
      "grad_norm": 0.2911908030509949,
      "learning_rate": 0.0002793564378347276,
      "loss": 0.356,
      "step": 119700
    },
    {
      "epoch": 4.871205806412263,
      "grad_norm": 0.30292782187461853,
      "learning_rate": 0.00027913513035010844,
      "loss": 0.3559,
      "step": 119800
    },
    {
      "epoch": 4.875271921442658,
      "grad_norm": 0.2632213532924652,
      "learning_rate": 0.00027891382286548933,
      "loss": 0.3577,
      "step": 119900
    },
    {
      "epoch": 4.879338036473052,
      "grad_norm": 0.3054044246673584,
      "learning_rate": 0.0002786925153808702,
      "loss": 0.3558,
      "step": 120000
    },
    {
      "epoch": 4.879338036473052,
      "eval_loss": 0.36661332845687866,
      "eval_runtime": 115.4742,
      "eval_samples_per_second": 1514.641,
      "eval_steps_per_second": 47.335,
      "step": 120000
    },
    {
      "epoch": 4.883404151503446,
      "grad_norm": 0.313997745513916,
      "learning_rate": 0.0002784712078962511,
      "loss": 0.3583,
      "step": 120100
    },
    {
      "epoch": 4.88747026653384,
      "grad_norm": 0.29723215103149414,
      "learning_rate": 0.00027824990041163197,
      "loss": 0.3565,
      "step": 120200
    },
    {
      "epoch": 4.891536381564235,
      "grad_norm": 0.32813191413879395,
      "learning_rate": 0.0002780285929270128,
      "loss": 0.3561,
      "step": 120300
    },
    {
      "epoch": 4.895602496594629,
      "grad_norm": 0.28050634264945984,
      "learning_rate": 0.00027780728544239366,
      "loss": 0.3562,
      "step": 120400
    },
    {
      "epoch": 4.899668611625023,
      "grad_norm": 0.28726527094841003,
      "learning_rate": 0.0002775859779577745,
      "loss": 0.3573,
      "step": 120500
    },
    {
      "epoch": 4.903734726655417,
      "grad_norm": 0.2766326069831848,
      "learning_rate": 0.0002773646704731554,
      "loss": 0.3563,
      "step": 120600
    },
    {
      "epoch": 4.907800841685812,
      "grad_norm": 0.2747782766819,
      "learning_rate": 0.00027714336298853624,
      "loss": 0.3569,
      "step": 120700
    },
    {
      "epoch": 4.911866956716206,
      "grad_norm": 0.2831798493862152,
      "learning_rate": 0.00027692205550391714,
      "loss": 0.3593,
      "step": 120800
    },
    {
      "epoch": 4.9159330717466,
      "grad_norm": 0.2733260691165924,
      "learning_rate": 0.00027670074801929804,
      "loss": 0.3576,
      "step": 120900
    },
    {
      "epoch": 4.919999186776994,
      "grad_norm": 0.2550794184207916,
      "learning_rate": 0.0002764794405346789,
      "loss": 0.3546,
      "step": 121000
    },
    {
      "epoch": 4.9240653018073886,
      "grad_norm": 0.2881534993648529,
      "learning_rate": 0.0002762581330500598,
      "loss": 0.3584,
      "step": 121100
    },
    {
      "epoch": 4.9281314168377826,
      "grad_norm": 0.30873507261276245,
      "learning_rate": 0.0002760368255654406,
      "loss": 0.3538,
      "step": 121200
    },
    {
      "epoch": 4.9321975318681766,
      "grad_norm": 0.29368856549263,
      "learning_rate": 0.0002758155180808215,
      "loss": 0.3597,
      "step": 121300
    },
    {
      "epoch": 4.936263646898571,
      "grad_norm": 0.29866814613342285,
      "learning_rate": 0.00027559421059620236,
      "loss": 0.3556,
      "step": 121400
    },
    {
      "epoch": 4.940329761928965,
      "grad_norm": 0.26786860823631287,
      "learning_rate": 0.00027537290311158326,
      "loss": 0.3557,
      "step": 121500
    },
    {
      "epoch": 4.9443958769593594,
      "grad_norm": 0.26021939516067505,
      "learning_rate": 0.0002751515956269641,
      "loss": 0.3577,
      "step": 121600
    },
    {
      "epoch": 4.9484619919897535,
      "grad_norm": 0.2716139554977417,
      "learning_rate": 0.000274930288142345,
      "loss": 0.355,
      "step": 121700
    },
    {
      "epoch": 4.9525281070201475,
      "grad_norm": 0.2610626816749573,
      "learning_rate": 0.0002747089806577259,
      "loss": 0.3541,
      "step": 121800
    },
    {
      "epoch": 4.9565942220505415,
      "grad_norm": 0.26301249861717224,
      "learning_rate": 0.00027448767317310674,
      "loss": 0.3567,
      "step": 121900
    },
    {
      "epoch": 4.960660337080936,
      "grad_norm": 0.28714942932128906,
      "learning_rate": 0.00027426636568848764,
      "loss": 0.3562,
      "step": 122000
    },
    {
      "epoch": 4.960660337080936,
      "eval_loss": 0.36633557081222534,
      "eval_runtime": 112.9411,
      "eval_samples_per_second": 1548.612,
      "eval_steps_per_second": 48.397,
      "step": 122000
    },
    {
      "epoch": 4.96472645211133,
      "grad_norm": 0.2903277575969696,
      "learning_rate": 0.0002740450582038684,
      "loss": 0.3575,
      "step": 122100
    },
    {
      "epoch": 4.968792567141724,
      "grad_norm": 0.28074121475219727,
      "learning_rate": 0.0002738237507192493,
      "loss": 0.3583,
      "step": 122200
    },
    {
      "epoch": 4.972858682172118,
      "grad_norm": 0.2354891449213028,
      "learning_rate": 0.00027360244323463016,
      "loss": 0.3575,
      "step": 122300
    },
    {
      "epoch": 4.976924797202513,
      "grad_norm": 0.2998500466346741,
      "learning_rate": 0.00027338113575001106,
      "loss": 0.3562,
      "step": 122400
    },
    {
      "epoch": 4.980990912232907,
      "grad_norm": 0.27724340558052063,
      "learning_rate": 0.0002731598282653919,
      "loss": 0.3569,
      "step": 122500
    },
    {
      "epoch": 4.985057027263301,
      "grad_norm": 0.27924519777297974,
      "learning_rate": 0.0002729385207807728,
      "loss": 0.3567,
      "step": 122600
    },
    {
      "epoch": 4.989123142293695,
      "grad_norm": 0.3048509955406189,
      "learning_rate": 0.0002727172132961537,
      "loss": 0.3565,
      "step": 122700
    },
    {
      "epoch": 4.99318925732409,
      "grad_norm": 0.3285200595855713,
      "learning_rate": 0.00027249590581153454,
      "loss": 0.3561,
      "step": 122800
    },
    {
      "epoch": 4.997255372354484,
      "grad_norm": 0.27067187428474426,
      "learning_rate": 0.00027227459832691544,
      "loss": 0.3566,
      "step": 122900
    },
    {
      "epoch": 5.001321487384878,
      "grad_norm": 0.25470441579818726,
      "learning_rate": 0.0002720532908422963,
      "loss": 0.3551,
      "step": 123000
    },
    {
      "epoch": 5.005387602415272,
      "grad_norm": 0.27326932549476624,
      "learning_rate": 0.0002718319833576772,
      "loss": 0.3536,
      "step": 123100
    },
    {
      "epoch": 5.009453717445666,
      "grad_norm": 0.265625536441803,
      "learning_rate": 0.000271610675873058,
      "loss": 0.3504,
      "step": 123200
    },
    {
      "epoch": 5.013519832476061,
      "grad_norm": 0.2804862856864929,
      "learning_rate": 0.0002713893683884389,
      "loss": 0.3519,
      "step": 123300
    },
    {
      "epoch": 5.017585947506455,
      "grad_norm": 0.31174615025520325,
      "learning_rate": 0.00027116806090381976,
      "loss": 0.3533,
      "step": 123400
    },
    {
      "epoch": 5.021652062536849,
      "grad_norm": 0.27702200412750244,
      "learning_rate": 0.00027094675341920066,
      "loss": 0.3527,
      "step": 123500
    },
    {
      "epoch": 5.025718177567243,
      "grad_norm": 0.3195948600769043,
      "learning_rate": 0.00027072544593458156,
      "loss": 0.3524,
      "step": 123600
    },
    {
      "epoch": 5.029784292597638,
      "grad_norm": 0.31226974725723267,
      "learning_rate": 0.00027050413844996235,
      "loss": 0.3506,
      "step": 123700
    },
    {
      "epoch": 5.033850407628032,
      "grad_norm": 0.29679936170578003,
      "learning_rate": 0.00027028283096534325,
      "loss": 0.3532,
      "step": 123800
    },
    {
      "epoch": 5.037916522658426,
      "grad_norm": 0.32586050033569336,
      "learning_rate": 0.0002700615234807241,
      "loss": 0.3514,
      "step": 123900
    },
    {
      "epoch": 5.04198263768882,
      "grad_norm": 0.28293681144714355,
      "learning_rate": 0.000269840215996105,
      "loss": 0.3514,
      "step": 124000
    },
    {
      "epoch": 5.04198263768882,
      "eval_loss": 0.3671781122684479,
      "eval_runtime": 114.9222,
      "eval_samples_per_second": 1521.917,
      "eval_steps_per_second": 47.563,
      "step": 124000
    },
    {
      "epoch": 5.046048752719215,
      "grad_norm": 0.31971001625061035,
      "learning_rate": 0.00026961890851148583,
      "loss": 0.3542,
      "step": 124100
    },
    {
      "epoch": 5.050114867749609,
      "grad_norm": 0.28915485739707947,
      "learning_rate": 0.0002693976010268667,
      "loss": 0.3505,
      "step": 124200
    },
    {
      "epoch": 5.054180982780003,
      "grad_norm": 0.2811259925365448,
      "learning_rate": 0.0002691762935422476,
      "loss": 0.3515,
      "step": 124300
    },
    {
      "epoch": 5.058247097810397,
      "grad_norm": 0.2960687279701233,
      "learning_rate": 0.00026895498605762847,
      "loss": 0.353,
      "step": 124400
    },
    {
      "epoch": 5.062313212840791,
      "grad_norm": 0.313001811504364,
      "learning_rate": 0.00026873367857300936,
      "loss": 0.3513,
      "step": 124500
    },
    {
      "epoch": 5.066379327871186,
      "grad_norm": 0.3100533187389374,
      "learning_rate": 0.0002685123710883902,
      "loss": 0.3525,
      "step": 124600
    },
    {
      "epoch": 5.07044544290158,
      "grad_norm": 0.27641841769218445,
      "learning_rate": 0.0002682910636037711,
      "loss": 0.3547,
      "step": 124700
    },
    {
      "epoch": 5.074511557931974,
      "grad_norm": 0.28843408823013306,
      "learning_rate": 0.00026806975611915195,
      "loss": 0.3522,
      "step": 124800
    },
    {
      "epoch": 5.078577672962368,
      "grad_norm": 0.28428491950035095,
      "learning_rate": 0.00026784844863453284,
      "loss": 0.3528,
      "step": 124900
    },
    {
      "epoch": 5.082643787992763,
      "grad_norm": 0.2832513749599457,
      "learning_rate": 0.0002676271411499137,
      "loss": 0.3528,
      "step": 125000
    },
    {
      "epoch": 5.086709903023157,
      "grad_norm": 0.27518218755722046,
      "learning_rate": 0.0002674058336652946,
      "loss": 0.3541,
      "step": 125100
    },
    {
      "epoch": 5.090776018053551,
      "grad_norm": 0.34912699460983276,
      "learning_rate": 0.0002671845261806755,
      "loss": 0.3511,
      "step": 125200
    },
    {
      "epoch": 5.094842133083945,
      "grad_norm": 0.2986677885055542,
      "learning_rate": 0.0002669632186960563,
      "loss": 0.3527,
      "step": 125300
    },
    {
      "epoch": 5.0989082481143395,
      "grad_norm": 0.29027995467185974,
      "learning_rate": 0.00026674191121143717,
      "loss": 0.352,
      "step": 125400
    },
    {
      "epoch": 5.1029743631447335,
      "grad_norm": 0.27485471963882446,
      "learning_rate": 0.000266520603726818,
      "loss": 0.3525,
      "step": 125500
    },
    {
      "epoch": 5.1070404781751275,
      "grad_norm": 0.2968764007091522,
      "learning_rate": 0.0002662992962421989,
      "loss": 0.3526,
      "step": 125600
    },
    {
      "epoch": 5.1111065932055215,
      "grad_norm": 0.3290901184082031,
      "learning_rate": 0.00026607798875757975,
      "loss": 0.3505,
      "step": 125700
    },
    {
      "epoch": 5.115172708235916,
      "grad_norm": 0.27858948707580566,
      "learning_rate": 0.00026585668127296065,
      "loss": 0.3527,
      "step": 125800
    },
    {
      "epoch": 5.11923882326631,
      "grad_norm": 0.2790107727050781,
      "learning_rate": 0.0002656353737883415,
      "loss": 0.3518,
      "step": 125900
    },
    {
      "epoch": 5.123304938296704,
      "grad_norm": 0.26836639642715454,
      "learning_rate": 0.0002654140663037224,
      "loss": 0.3546,
      "step": 126000
    },
    {
      "epoch": 5.123304938296704,
      "eval_loss": 0.36512935161590576,
      "eval_runtime": 113.3896,
      "eval_samples_per_second": 1542.487,
      "eval_steps_per_second": 48.205,
      "step": 126000
    },
    {
      "epoch": 5.127371053327098,
      "grad_norm": 0.2924719750881195,
      "learning_rate": 0.0002651927588191033,
      "loss": 0.3521,
      "step": 126100
    },
    {
      "epoch": 5.131437168357492,
      "grad_norm": 0.3002028167247772,
      "learning_rate": 0.00026497145133448413,
      "loss": 0.3515,
      "step": 126200
    },
    {
      "epoch": 5.135503283387887,
      "grad_norm": 0.2810944616794586,
      "learning_rate": 0.00026475014384986503,
      "loss": 0.353,
      "step": 126300
    },
    {
      "epoch": 5.139569398418281,
      "grad_norm": 0.2920650839805603,
      "learning_rate": 0.00026452883636524587,
      "loss": 0.3538,
      "step": 126400
    },
    {
      "epoch": 5.143635513448675,
      "grad_norm": 0.2821171283721924,
      "learning_rate": 0.00026430752888062677,
      "loss": 0.3564,
      "step": 126500
    },
    {
      "epoch": 5.147701628479069,
      "grad_norm": 0.3283518850803375,
      "learning_rate": 0.0002640862213960076,
      "loss": 0.3531,
      "step": 126600
    },
    {
      "epoch": 5.151767743509464,
      "grad_norm": 0.29712074995040894,
      "learning_rate": 0.0002638649139113885,
      "loss": 0.3536,
      "step": 126700
    },
    {
      "epoch": 5.155833858539858,
      "grad_norm": 0.3126862943172455,
      "learning_rate": 0.00026364360642676935,
      "loss": 0.3518,
      "step": 126800
    },
    {
      "epoch": 5.159899973570252,
      "grad_norm": 0.31335029006004333,
      "learning_rate": 0.00026342229894215025,
      "loss": 0.3543,
      "step": 126900
    },
    {
      "epoch": 5.163966088600646,
      "grad_norm": 0.28500911593437195,
      "learning_rate": 0.00026320099145753115,
      "loss": 0.3543,
      "step": 127000
    },
    {
      "epoch": 5.168032203631041,
      "grad_norm": 0.2995319068431854,
      "learning_rate": 0.00026297968397291194,
      "loss": 0.353,
      "step": 127100
    },
    {
      "epoch": 5.172098318661435,
      "grad_norm": 0.31283241510391235,
      "learning_rate": 0.00026275837648829283,
      "loss": 0.3523,
      "step": 127200
    },
    {
      "epoch": 5.176164433691829,
      "grad_norm": 0.2886488735675812,
      "learning_rate": 0.0002625370690036737,
      "loss": 0.3536,
      "step": 127300
    },
    {
      "epoch": 5.180230548722223,
      "grad_norm": 0.27761566638946533,
      "learning_rate": 0.0002623157615190546,
      "loss": 0.3527,
      "step": 127400
    },
    {
      "epoch": 5.184296663752617,
      "grad_norm": 0.2423592060804367,
      "learning_rate": 0.0002620944540344354,
      "loss": 0.3515,
      "step": 127500
    },
    {
      "epoch": 5.188362778783012,
      "grad_norm": 0.2940182089805603,
      "learning_rate": 0.0002618731465498163,
      "loss": 0.3531,
      "step": 127600
    },
    {
      "epoch": 5.192428893813406,
      "grad_norm": 0.27346739172935486,
      "learning_rate": 0.00026165183906519716,
      "loss": 0.3508,
      "step": 127700
    },
    {
      "epoch": 5.1964950088438,
      "grad_norm": 0.30887237191200256,
      "learning_rate": 0.00026143053158057805,
      "loss": 0.3532,
      "step": 127800
    },
    {
      "epoch": 5.200561123874194,
      "grad_norm": 0.3273679316043854,
      "learning_rate": 0.00026120922409595895,
      "loss": 0.3544,
      "step": 127900
    },
    {
      "epoch": 5.204627238904589,
      "grad_norm": 0.31655099987983704,
      "learning_rate": 0.0002609879166113398,
      "loss": 0.354,
      "step": 128000
    },
    {
      "epoch": 5.204627238904589,
      "eval_loss": 0.3653300106525421,
      "eval_runtime": 114.3824,
      "eval_samples_per_second": 1529.099,
      "eval_steps_per_second": 47.787,
      "step": 128000
    },
    {
      "epoch": 5.208693353934983,
      "grad_norm": 0.2767501771450043,
      "learning_rate": 0.0002607666091267207,
      "loss": 0.3546,
      "step": 128100
    },
    {
      "epoch": 5.212759468965377,
      "grad_norm": 0.33251622319221497,
      "learning_rate": 0.00026054530164210154,
      "loss": 0.3509,
      "step": 128200
    },
    {
      "epoch": 5.216825583995771,
      "grad_norm": 0.3026396632194519,
      "learning_rate": 0.00026032399415748243,
      "loss": 0.3515,
      "step": 128300
    },
    {
      "epoch": 5.220891699026166,
      "grad_norm": 0.29046431183815,
      "learning_rate": 0.0002601026866728633,
      "loss": 0.355,
      "step": 128400
    },
    {
      "epoch": 5.22495781405656,
      "grad_norm": 0.30549243092536926,
      "learning_rate": 0.00025988137918824417,
      "loss": 0.3518,
      "step": 128500
    },
    {
      "epoch": 5.229023929086954,
      "grad_norm": 0.3279916048049927,
      "learning_rate": 0.00025966007170362507,
      "loss": 0.3523,
      "step": 128600
    },
    {
      "epoch": 5.233090044117348,
      "grad_norm": 0.2901688814163208,
      "learning_rate": 0.0002594387642190059,
      "loss": 0.3516,
      "step": 128700
    },
    {
      "epoch": 5.237156159147743,
      "grad_norm": 0.2976987063884735,
      "learning_rate": 0.00025921745673438676,
      "loss": 0.3533,
      "step": 128800
    },
    {
      "epoch": 5.241222274178137,
      "grad_norm": 0.3477770686149597,
      "learning_rate": 0.0002589961492497676,
      "loss": 0.3526,
      "step": 128900
    },
    {
      "epoch": 5.245288389208531,
      "grad_norm": 0.29000911116600037,
      "learning_rate": 0.0002587748417651485,
      "loss": 0.3521,
      "step": 129000
    },
    {
      "epoch": 5.249354504238925,
      "grad_norm": 0.29520484805107117,
      "learning_rate": 0.00025855353428052934,
      "loss": 0.3557,
      "step": 129100
    },
    {
      "epoch": 5.253420619269319,
      "grad_norm": 0.30027681589126587,
      "learning_rate": 0.00025833222679591024,
      "loss": 0.3518,
      "step": 129200
    },
    {
      "epoch": 5.257486734299714,
      "grad_norm": 0.32017815113067627,
      "learning_rate": 0.0002581109193112911,
      "loss": 0.3507,
      "step": 129300
    },
    {
      "epoch": 5.261552849330108,
      "grad_norm": 0.2942878007888794,
      "learning_rate": 0.000257889611826672,
      "loss": 0.3528,
      "step": 129400
    },
    {
      "epoch": 5.265618964360502,
      "grad_norm": 0.38239213824272156,
      "learning_rate": 0.0002576683043420529,
      "loss": 0.3533,
      "step": 129500
    },
    {
      "epoch": 5.269685079390896,
      "grad_norm": 0.30422836542129517,
      "learning_rate": 0.0002574469968574337,
      "loss": 0.3535,
      "step": 129600
    },
    {
      "epoch": 5.2737511944212905,
      "grad_norm": 0.30296748876571655,
      "learning_rate": 0.0002572256893728146,
      "loss": 0.3531,
      "step": 129700
    },
    {
      "epoch": 5.2778173094516845,
      "grad_norm": 0.3191644549369812,
      "learning_rate": 0.00025700438188819546,
      "loss": 0.3537,
      "step": 129800
    },
    {
      "epoch": 5.2818834244820785,
      "grad_norm": 0.3095398545265198,
      "learning_rate": 0.00025678307440357636,
      "loss": 0.3496,
      "step": 129900
    },
    {
      "epoch": 5.2859495395124725,
      "grad_norm": 0.32107487320899963,
      "learning_rate": 0.0002565617669189572,
      "loss": 0.3526,
      "step": 130000
    },
    {
      "epoch": 5.2859495395124725,
      "eval_loss": 0.36485588550567627,
      "eval_runtime": 112.9269,
      "eval_samples_per_second": 1548.807,
      "eval_steps_per_second": 48.403,
      "step": 130000
    },
    {
      "epoch": 5.290015654542867,
      "grad_norm": 0.26972031593322754,
      "learning_rate": 0.0002563404594343381,
      "loss": 0.3557,
      "step": 130100
    },
    {
      "epoch": 5.294081769573261,
      "grad_norm": 0.2632525563240051,
      "learning_rate": 0.00025611915194971894,
      "loss": 0.354,
      "step": 130200
    },
    {
      "epoch": 5.298147884603655,
      "grad_norm": 0.29008570313453674,
      "learning_rate": 0.00025589784446509984,
      "loss": 0.3532,
      "step": 130300
    },
    {
      "epoch": 5.302213999634049,
      "grad_norm": 0.29655879735946655,
      "learning_rate": 0.00025567653698048073,
      "loss": 0.3531,
      "step": 130400
    },
    {
      "epoch": 5.306280114664444,
      "grad_norm": 0.3349362313747406,
      "learning_rate": 0.0002554552294958615,
      "loss": 0.3531,
      "step": 130500
    },
    {
      "epoch": 5.310346229694838,
      "grad_norm": 0.2950611710548401,
      "learning_rate": 0.0002552339220112424,
      "loss": 0.3555,
      "step": 130600
    },
    {
      "epoch": 5.314412344725232,
      "grad_norm": 0.3059972822666168,
      "learning_rate": 0.00025501261452662326,
      "loss": 0.3521,
      "step": 130700
    },
    {
      "epoch": 5.318478459755626,
      "grad_norm": 0.306648313999176,
      "learning_rate": 0.00025479130704200416,
      "loss": 0.3516,
      "step": 130800
    },
    {
      "epoch": 5.32254457478602,
      "grad_norm": 0.31651774048805237,
      "learning_rate": 0.000254569999557385,
      "loss": 0.3547,
      "step": 130900
    },
    {
      "epoch": 5.326610689816415,
      "grad_norm": 0.28154462575912476,
      "learning_rate": 0.0002543486920727659,
      "loss": 0.3526,
      "step": 131000
    },
    {
      "epoch": 5.330676804846809,
      "grad_norm": 0.29941773414611816,
      "learning_rate": 0.00025412738458814674,
      "loss": 0.3513,
      "step": 131100
    },
    {
      "epoch": 5.334742919877203,
      "grad_norm": 0.3847063183784485,
      "learning_rate": 0.00025390607710352764,
      "loss": 0.3523,
      "step": 131200
    },
    {
      "epoch": 5.338809034907597,
      "grad_norm": 0.29785075783729553,
      "learning_rate": 0.00025368476961890854,
      "loss": 0.3539,
      "step": 131300
    },
    {
      "epoch": 5.342875149937992,
      "grad_norm": 0.3444138765335083,
      "learning_rate": 0.0002534634621342894,
      "loss": 0.3533,
      "step": 131400
    },
    {
      "epoch": 5.346941264968386,
      "grad_norm": 0.28301066160202026,
      "learning_rate": 0.0002532421546496703,
      "loss": 0.3535,
      "step": 131500
    },
    {
      "epoch": 5.35100737999878,
      "grad_norm": 0.296247661113739,
      "learning_rate": 0.0002530208471650511,
      "loss": 0.3541,
      "step": 131600
    },
    {
      "epoch": 5.355073495029174,
      "grad_norm": 0.32568463683128357,
      "learning_rate": 0.000252799539680432,
      "loss": 0.3513,
      "step": 131700
    },
    {
      "epoch": 5.359139610059569,
      "grad_norm": 0.3384125828742981,
      "learning_rate": 0.00025257823219581286,
      "loss": 0.3522,
      "step": 131800
    },
    {
      "epoch": 5.363205725089963,
      "grad_norm": 0.3175564110279083,
      "learning_rate": 0.00025235692471119376,
      "loss": 0.3546,
      "step": 131900
    },
    {
      "epoch": 5.367271840120357,
      "grad_norm": 0.28533992171287537,
      "learning_rate": 0.00025213561722657466,
      "loss": 0.3528,
      "step": 132000
    },
    {
      "epoch": 5.367271840120357,
      "eval_loss": 0.36455798149108887,
      "eval_runtime": 113.8298,
      "eval_samples_per_second": 1536.522,
      "eval_steps_per_second": 48.019,
      "step": 132000
    },
    {
      "epoch": 5.371337955150751,
      "grad_norm": 0.28151822090148926,
      "learning_rate": 0.0002519143097419555,
      "loss": 0.3529,
      "step": 132100
    },
    {
      "epoch": 5.375404070181146,
      "grad_norm": 0.2870617210865021,
      "learning_rate": 0.00025169300225733634,
      "loss": 0.3517,
      "step": 132200
    },
    {
      "epoch": 5.37947018521154,
      "grad_norm": 0.3225957751274109,
      "learning_rate": 0.0002514716947727172,
      "loss": 0.3509,
      "step": 132300
    },
    {
      "epoch": 5.383536300241934,
      "grad_norm": 0.3293258547782898,
      "learning_rate": 0.0002512503872880981,
      "loss": 0.3531,
      "step": 132400
    },
    {
      "epoch": 5.387602415272328,
      "grad_norm": 0.28547966480255127,
      "learning_rate": 0.00025102907980347893,
      "loss": 0.3515,
      "step": 132500
    },
    {
      "epoch": 5.391668530302722,
      "grad_norm": 0.33559858798980713,
      "learning_rate": 0.0002508077723188598,
      "loss": 0.3556,
      "step": 132600
    },
    {
      "epoch": 5.395734645333117,
      "grad_norm": 0.3058214485645294,
      "learning_rate": 0.00025058646483424067,
      "loss": 0.3554,
      "step": 132700
    },
    {
      "epoch": 5.399800760363511,
      "grad_norm": 0.3012019097805023,
      "learning_rate": 0.00025036515734962157,
      "loss": 0.3503,
      "step": 132800
    },
    {
      "epoch": 5.403866875393905,
      "grad_norm": 0.25158050656318665,
      "learning_rate": 0.00025014384986500246,
      "loss": 0.3527,
      "step": 132900
    },
    {
      "epoch": 5.407932990424299,
      "grad_norm": 0.28927960991859436,
      "learning_rate": 0.0002499225423803833,
      "loss": 0.3537,
      "step": 133000
    },
    {
      "epoch": 5.411999105454694,
      "grad_norm": 0.3025294542312622,
      "learning_rate": 0.0002497012348957642,
      "loss": 0.3525,
      "step": 133100
    },
    {
      "epoch": 5.416065220485088,
      "grad_norm": 0.32875365018844604,
      "learning_rate": 0.00024947992741114505,
      "loss": 0.3536,
      "step": 133200
    },
    {
      "epoch": 5.420131335515482,
      "grad_norm": 0.29355841875076294,
      "learning_rate": 0.00024925861992652594,
      "loss": 0.356,
      "step": 133300
    },
    {
      "epoch": 5.424197450545876,
      "grad_norm": 0.3505948483943939,
      "learning_rate": 0.0002490373124419068,
      "loss": 0.3532,
      "step": 133400
    },
    {
      "epoch": 5.4282635655762705,
      "grad_norm": 0.31278958916664124,
      "learning_rate": 0.00024881600495728763,
      "loss": 0.3521,
      "step": 133500
    },
    {
      "epoch": 5.4323296806066645,
      "grad_norm": 0.28952279686927795,
      "learning_rate": 0.0002485946974726685,
      "loss": 0.3543,
      "step": 133600
    },
    {
      "epoch": 5.4363957956370585,
      "grad_norm": 0.34992972016334534,
      "learning_rate": 0.0002483733899880494,
      "loss": 0.3525,
      "step": 133700
    },
    {
      "epoch": 5.4404619106674525,
      "grad_norm": 0.27024519443511963,
      "learning_rate": 0.00024815208250343027,
      "loss": 0.3534,
      "step": 133800
    },
    {
      "epoch": 5.444528025697847,
      "grad_norm": 0.2881180942058563,
      "learning_rate": 0.00024793077501881116,
      "loss": 0.3537,
      "step": 133900
    },
    {
      "epoch": 5.448594140728241,
      "grad_norm": 0.28178340196609497,
      "learning_rate": 0.000247709467534192,
      "loss": 0.351,
      "step": 134000
    },
    {
      "epoch": 5.448594140728241,
      "eval_loss": 0.3640677034854889,
      "eval_runtime": 112.7898,
      "eval_samples_per_second": 1550.69,
      "eval_steps_per_second": 48.462,
      "step": 134000
    },
    {
      "epoch": 5.452660255758635,
      "grad_norm": 0.316988468170166,
      "learning_rate": 0.0002474881600495729,
      "loss": 0.3517,
      "step": 134100
    },
    {
      "epoch": 5.4567263707890294,
      "grad_norm": 0.2942807972431183,
      "learning_rate": 0.00024726685256495375,
      "loss": 0.3526,
      "step": 134200
    },
    {
      "epoch": 5.4607924858194234,
      "grad_norm": 0.2812322676181793,
      "learning_rate": 0.0002470455450803346,
      "loss": 0.3502,
      "step": 134300
    },
    {
      "epoch": 5.464858600849818,
      "grad_norm": 0.2919638752937317,
      "learning_rate": 0.0002468242375957155,
      "loss": 0.3524,
      "step": 134400
    },
    {
      "epoch": 5.468924715880212,
      "grad_norm": 0.3021235167980194,
      "learning_rate": 0.00024660293011109633,
      "loss": 0.3516,
      "step": 134500
    },
    {
      "epoch": 5.472990830910606,
      "grad_norm": 0.28958213329315186,
      "learning_rate": 0.00024638162262647723,
      "loss": 0.3522,
      "step": 134600
    },
    {
      "epoch": 5.477056945941,
      "grad_norm": 0.2818427085876465,
      "learning_rate": 0.0002461603151418581,
      "loss": 0.3521,
      "step": 134700
    },
    {
      "epoch": 5.481123060971395,
      "grad_norm": 0.2944636940956116,
      "learning_rate": 0.00024593900765723897,
      "loss": 0.3532,
      "step": 134800
    },
    {
      "epoch": 5.485189176001789,
      "grad_norm": 0.2704330384731293,
      "learning_rate": 0.00024571770017261987,
      "loss": 0.3493,
      "step": 134900
    },
    {
      "epoch": 5.489255291032183,
      "grad_norm": 0.2704840898513794,
      "learning_rate": 0.0002454963926880007,
      "loss": 0.3514,
      "step": 135000
    },
    {
      "epoch": 5.493321406062577,
      "grad_norm": 0.2939203679561615,
      "learning_rate": 0.00024527508520338155,
      "loss": 0.3533,
      "step": 135100
    },
    {
      "epoch": 5.497387521092972,
      "grad_norm": 0.2715097665786743,
      "learning_rate": 0.00024505377771876245,
      "loss": 0.3529,
      "step": 135200
    },
    {
      "epoch": 5.501453636123366,
      "grad_norm": 0.31056323647499084,
      "learning_rate": 0.0002448324702341433,
      "loss": 0.3512,
      "step": 135300
    },
    {
      "epoch": 5.50551975115376,
      "grad_norm": 0.2823503911495209,
      "learning_rate": 0.0002446111627495242,
      "loss": 0.3535,
      "step": 135400
    },
    {
      "epoch": 5.509585866184154,
      "grad_norm": 0.2667537033557892,
      "learning_rate": 0.0002443898552649051,
      "loss": 0.3522,
      "step": 135500
    },
    {
      "epoch": 5.513651981214549,
      "grad_norm": 0.318879634141922,
      "learning_rate": 0.00024416854778028593,
      "loss": 0.3543,
      "step": 135600
    },
    {
      "epoch": 5.517718096244943,
      "grad_norm": 0.32473817467689514,
      "learning_rate": 0.0002439472402956668,
      "loss": 0.3526,
      "step": 135700
    },
    {
      "epoch": 5.521784211275337,
      "grad_norm": 0.3722643256187439,
      "learning_rate": 0.00024372593281104767,
      "loss": 0.3502,
      "step": 135800
    },
    {
      "epoch": 5.525850326305731,
      "grad_norm": 0.31318917870521545,
      "learning_rate": 0.00024350462532642857,
      "loss": 0.3509,
      "step": 135900
    },
    {
      "epoch": 5.529916441336125,
      "grad_norm": 0.3247288763523102,
      "learning_rate": 0.0002432833178418094,
      "loss": 0.3517,
      "step": 136000
    },
    {
      "epoch": 5.529916441336125,
      "eval_loss": 0.3638935387134552,
      "eval_runtime": 113.461,
      "eval_samples_per_second": 1541.517,
      "eval_steps_per_second": 48.175,
      "step": 136000
    },
    {
      "epoch": 5.53398255636652,
      "grad_norm": 0.3760218322277069,
      "learning_rate": 0.00024306201035719028,
      "loss": 0.3524,
      "step": 136100
    },
    {
      "epoch": 5.538048671396914,
      "grad_norm": 0.27644434571266174,
      "learning_rate": 0.00024284070287257115,
      "loss": 0.3512,
      "step": 136200
    },
    {
      "epoch": 5.542114786427308,
      "grad_norm": 0.3035142123699188,
      "learning_rate": 0.00024261939538795202,
      "loss": 0.353,
      "step": 136300
    },
    {
      "epoch": 5.546180901457702,
      "grad_norm": 0.28534963726997375,
      "learning_rate": 0.0002423980879033329,
      "loss": 0.3535,
      "step": 136400
    },
    {
      "epoch": 5.550247016488097,
      "grad_norm": 0.2798626124858856,
      "learning_rate": 0.00024217678041871376,
      "loss": 0.3532,
      "step": 136500
    },
    {
      "epoch": 5.554313131518491,
      "grad_norm": 0.30969855189323425,
      "learning_rate": 0.00024195547293409463,
      "loss": 0.3522,
      "step": 136600
    },
    {
      "epoch": 5.558379246548885,
      "grad_norm": 0.3295227289199829,
      "learning_rate": 0.00024173416544947553,
      "loss": 0.3519,
      "step": 136700
    },
    {
      "epoch": 5.562445361579279,
      "grad_norm": 0.3409738838672638,
      "learning_rate": 0.00024151285796485637,
      "loss": 0.3501,
      "step": 136800
    },
    {
      "epoch": 5.566511476609673,
      "grad_norm": 0.2824256718158722,
      "learning_rate": 0.00024129155048023724,
      "loss": 0.3514,
      "step": 136900
    },
    {
      "epoch": 5.570577591640068,
      "grad_norm": 0.29631155729293823,
      "learning_rate": 0.00024107024299561811,
      "loss": 0.3538,
      "step": 137000
    },
    {
      "epoch": 5.574643706670462,
      "grad_norm": 0.30877095460891724,
      "learning_rate": 0.00024084893551099898,
      "loss": 0.3525,
      "step": 137100
    },
    {
      "epoch": 5.578709821700856,
      "grad_norm": 0.2564268112182617,
      "learning_rate": 0.00024062762802637985,
      "loss": 0.3533,
      "step": 137200
    },
    {
      "epoch": 5.582775936731251,
      "grad_norm": 0.33625349402427673,
      "learning_rate": 0.00024040632054176073,
      "loss": 0.3513,
      "step": 137300
    },
    {
      "epoch": 5.586842051761645,
      "grad_norm": 0.31423482298851013,
      "learning_rate": 0.0002401850130571416,
      "loss": 0.3502,
      "step": 137400
    },
    {
      "epoch": 5.590908166792039,
      "grad_norm": 0.32515498995780945,
      "learning_rate": 0.00023996370557252247,
      "loss": 0.3504,
      "step": 137500
    },
    {
      "epoch": 5.594974281822433,
      "grad_norm": 0.2883802056312561,
      "learning_rate": 0.00023974239808790336,
      "loss": 0.3525,
      "step": 137600
    },
    {
      "epoch": 5.599040396852827,
      "grad_norm": 0.3132669925689697,
      "learning_rate": 0.0002395210906032842,
      "loss": 0.3514,
      "step": 137700
    },
    {
      "epoch": 5.6031065118832215,
      "grad_norm": 0.3366889953613281,
      "learning_rate": 0.00023929978311866508,
      "loss": 0.3542,
      "step": 137800
    },
    {
      "epoch": 5.6071726269136155,
      "grad_norm": 0.30607330799102783,
      "learning_rate": 0.00023907847563404595,
      "loss": 0.3516,
      "step": 137900
    },
    {
      "epoch": 5.6112387419440095,
      "grad_norm": 0.31843554973602295,
      "learning_rate": 0.00023885716814942682,
      "loss": 0.3534,
      "step": 138000
    },
    {
      "epoch": 5.6112387419440095,
      "eval_loss": 0.36338573694229126,
      "eval_runtime": 113.1834,
      "eval_samples_per_second": 1545.297,
      "eval_steps_per_second": 48.293,
      "step": 138000
    },
    {
      "epoch": 5.6153048569744035,
      "grad_norm": 0.2983645796775818,
      "learning_rate": 0.0002386358606648077,
      "loss": 0.3497,
      "step": 138100
    },
    {
      "epoch": 5.619370972004798,
      "grad_norm": 0.3053540885448456,
      "learning_rate": 0.00023841455318018856,
      "loss": 0.3524,
      "step": 138200
    },
    {
      "epoch": 5.623437087035192,
      "grad_norm": 0.29474082589149475,
      "learning_rate": 0.00023819324569556943,
      "loss": 0.3518,
      "step": 138300
    },
    {
      "epoch": 5.627503202065586,
      "grad_norm": 0.3153473138809204,
      "learning_rate": 0.00023797193821095032,
      "loss": 0.3531,
      "step": 138400
    },
    {
      "epoch": 5.63156931709598,
      "grad_norm": 0.3514719009399414,
      "learning_rate": 0.00023775063072633117,
      "loss": 0.3536,
      "step": 138500
    },
    {
      "epoch": 5.635635432126374,
      "grad_norm": 0.3422471582889557,
      "learning_rate": 0.00023752932324171204,
      "loss": 0.3532,
      "step": 138600
    },
    {
      "epoch": 5.639701547156769,
      "grad_norm": 0.3133574426174164,
      "learning_rate": 0.0002373080157570929,
      "loss": 0.3528,
      "step": 138700
    },
    {
      "epoch": 5.643767662187163,
      "grad_norm": 0.29749274253845215,
      "learning_rate": 0.00023708670827247378,
      "loss": 0.3503,
      "step": 138800
    },
    {
      "epoch": 5.647833777217557,
      "grad_norm": 0.3257756233215332,
      "learning_rate": 0.00023686540078785465,
      "loss": 0.3533,
      "step": 138900
    },
    {
      "epoch": 5.651899892247951,
      "grad_norm": 0.28439804911613464,
      "learning_rate": 0.00023664409330323552,
      "loss": 0.3522,
      "step": 139000
    },
    {
      "epoch": 5.655966007278346,
      "grad_norm": 0.32400140166282654,
      "learning_rate": 0.0002364227858186164,
      "loss": 0.3523,
      "step": 139100
    },
    {
      "epoch": 5.66003212230874,
      "grad_norm": 0.29480138421058655,
      "learning_rate": 0.00023620147833399726,
      "loss": 0.3532,
      "step": 139200
    },
    {
      "epoch": 5.664098237339134,
      "grad_norm": 0.3277897238731384,
      "learning_rate": 0.00023598017084937813,
      "loss": 0.3523,
      "step": 139300
    },
    {
      "epoch": 5.668164352369528,
      "grad_norm": 0.34421876072883606,
      "learning_rate": 0.000235758863364759,
      "loss": 0.3534,
      "step": 139400
    },
    {
      "epoch": 5.672230467399923,
      "grad_norm": 0.3177073001861572,
      "learning_rate": 0.00023553755588013987,
      "loss": 0.3526,
      "step": 139500
    },
    {
      "epoch": 5.676296582430317,
      "grad_norm": 0.3154994547367096,
      "learning_rate": 0.00023531624839552074,
      "loss": 0.3511,
      "step": 139600
    },
    {
      "epoch": 5.680362697460711,
      "grad_norm": 0.2997877895832062,
      "learning_rate": 0.0002350949409109016,
      "loss": 0.3521,
      "step": 139700
    },
    {
      "epoch": 5.684428812491105,
      "grad_norm": 0.3071001470088959,
      "learning_rate": 0.00023487363342628248,
      "loss": 0.3517,
      "step": 139800
    },
    {
      "epoch": 5.6884949275215,
      "grad_norm": 0.30394819378852844,
      "learning_rate": 0.00023465232594166335,
      "loss": 0.3514,
      "step": 139900
    },
    {
      "epoch": 5.692561042551894,
      "grad_norm": 0.29189231991767883,
      "learning_rate": 0.00023443101845704422,
      "loss": 0.35,
      "step": 140000
    },
    {
      "epoch": 5.692561042551894,
      "eval_loss": 0.3628189265727997,
      "eval_runtime": 114.3395,
      "eval_samples_per_second": 1529.673,
      "eval_steps_per_second": 47.805,
      "step": 140000
    },
    {
      "epoch": 5.696627157582288,
      "grad_norm": 0.2769259810447693,
      "learning_rate": 0.00023420971097242512,
      "loss": 0.3526,
      "step": 140100
    },
    {
      "epoch": 5.700693272612682,
      "grad_norm": 0.28585192561149597,
      "learning_rate": 0.00023398840348780596,
      "loss": 0.3507,
      "step": 140200
    },
    {
      "epoch": 5.704759387643076,
      "grad_norm": 0.4051508605480194,
      "learning_rate": 0.00023376709600318683,
      "loss": 0.349,
      "step": 140300
    },
    {
      "epoch": 5.708825502673471,
      "grad_norm": 0.2659914195537567,
      "learning_rate": 0.0002335457885185677,
      "loss": 0.3509,
      "step": 140400
    },
    {
      "epoch": 5.712891617703865,
      "grad_norm": 0.29279735684394836,
      "learning_rate": 0.00023332448103394857,
      "loss": 0.3525,
      "step": 140500
    },
    {
      "epoch": 5.716957732734259,
      "grad_norm": 0.3113420903682709,
      "learning_rate": 0.00023310317354932944,
      "loss": 0.3513,
      "step": 140600
    },
    {
      "epoch": 5.721023847764653,
      "grad_norm": 0.3272020220756531,
      "learning_rate": 0.0002328818660647103,
      "loss": 0.3531,
      "step": 140700
    },
    {
      "epoch": 5.725089962795048,
      "grad_norm": 0.3230070173740387,
      "learning_rate": 0.00023266055858009118,
      "loss": 0.3515,
      "step": 140800
    },
    {
      "epoch": 5.729156077825442,
      "grad_norm": 0.28368306159973145,
      "learning_rate": 0.00023243925109547205,
      "loss": 0.3509,
      "step": 140900
    },
    {
      "epoch": 5.733222192855836,
      "grad_norm": 0.3191545009613037,
      "learning_rate": 0.00023221794361085292,
      "loss": 0.3519,
      "step": 141000
    },
    {
      "epoch": 5.73728830788623,
      "grad_norm": 0.3195772171020508,
      "learning_rate": 0.0002319966361262338,
      "loss": 0.3504,
      "step": 141100
    },
    {
      "epoch": 5.741354422916625,
      "grad_norm": 0.3780323565006256,
      "learning_rate": 0.00023177532864161466,
      "loss": 0.3522,
      "step": 141200
    },
    {
      "epoch": 5.745420537947019,
      "grad_norm": 0.30588090419769287,
      "learning_rate": 0.00023155402115699553,
      "loss": 0.3547,
      "step": 141300
    },
    {
      "epoch": 5.749486652977413,
      "grad_norm": 0.3033711910247803,
      "learning_rate": 0.0002313327136723764,
      "loss": 0.3527,
      "step": 141400
    },
    {
      "epoch": 5.753552768007807,
      "grad_norm": 0.2897011935710907,
      "learning_rate": 0.00023111140618775727,
      "loss": 0.3523,
      "step": 141500
    },
    {
      "epoch": 5.757618883038202,
      "grad_norm": 0.36519908905029297,
      "learning_rate": 0.00023089009870313814,
      "loss": 0.3502,
      "step": 141600
    },
    {
      "epoch": 5.761684998068596,
      "grad_norm": 0.28363513946533203,
      "learning_rate": 0.00023066879121851901,
      "loss": 0.3554,
      "step": 141700
    },
    {
      "epoch": 5.76575111309899,
      "grad_norm": 0.3449331521987915,
      "learning_rate": 0.00023044748373389989,
      "loss": 0.3534,
      "step": 141800
    },
    {
      "epoch": 5.769817228129384,
      "grad_norm": 0.3080247938632965,
      "learning_rate": 0.00023022617624928076,
      "loss": 0.3516,
      "step": 141900
    },
    {
      "epoch": 5.773883343159778,
      "grad_norm": 0.3155336380004883,
      "learning_rate": 0.00023000486876466163,
      "loss": 0.3526,
      "step": 142000
    },
    {
      "epoch": 5.773883343159778,
      "eval_loss": 0.36191150546073914,
      "eval_runtime": 113.1545,
      "eval_samples_per_second": 1545.692,
      "eval_steps_per_second": 48.306,
      "step": 142000
    },
    {
      "epoch": 5.7779494581901725,
      "grad_norm": 0.3191286325454712,
      "learning_rate": 0.0002297835612800425,
      "loss": 0.3514,
      "step": 142100
    },
    {
      "epoch": 5.7820155732205665,
      "grad_norm": 0.3169316351413727,
      "learning_rate": 0.00022956225379542337,
      "loss": 0.3522,
      "step": 142200
    },
    {
      "epoch": 5.7860816882509605,
      "grad_norm": 0.312283992767334,
      "learning_rate": 0.00022934094631080424,
      "loss": 0.3537,
      "step": 142300
    },
    {
      "epoch": 5.7901478032813545,
      "grad_norm": 0.26732689142227173,
      "learning_rate": 0.0002291196388261851,
      "loss": 0.3516,
      "step": 142400
    },
    {
      "epoch": 5.794213918311749,
      "grad_norm": 0.34569409489631653,
      "learning_rate": 0.00022889833134156598,
      "loss": 0.3505,
      "step": 142500
    },
    {
      "epoch": 5.798280033342143,
      "grad_norm": 0.32962965965270996,
      "learning_rate": 0.00022867702385694685,
      "loss": 0.3518,
      "step": 142600
    },
    {
      "epoch": 5.802346148372537,
      "grad_norm": 0.2917628586292267,
      "learning_rate": 0.00022845571637232772,
      "loss": 0.3523,
      "step": 142700
    },
    {
      "epoch": 5.806412263402931,
      "grad_norm": 0.3246837854385376,
      "learning_rate": 0.0002282344088877086,
      "loss": 0.3509,
      "step": 142800
    },
    {
      "epoch": 5.810478378433326,
      "grad_norm": 0.3282139301300049,
      "learning_rate": 0.00022801310140308946,
      "loss": 0.3534,
      "step": 142900
    },
    {
      "epoch": 5.81454449346372,
      "grad_norm": 0.32276973128318787,
      "learning_rate": 0.00022779179391847033,
      "loss": 0.352,
      "step": 143000
    },
    {
      "epoch": 5.818610608494114,
      "grad_norm": 0.3032063841819763,
      "learning_rate": 0.0002275704864338512,
      "loss": 0.352,
      "step": 143100
    },
    {
      "epoch": 5.822676723524508,
      "grad_norm": 0.3556362986564636,
      "learning_rate": 0.00022734917894923207,
      "loss": 0.3516,
      "step": 143200
    },
    {
      "epoch": 5.826742838554903,
      "grad_norm": 0.32250818610191345,
      "learning_rate": 0.00022712787146461294,
      "loss": 0.3501,
      "step": 143300
    },
    {
      "epoch": 5.830808953585297,
      "grad_norm": 0.34952378273010254,
      "learning_rate": 0.0002269065639799938,
      "loss": 0.3516,
      "step": 143400
    },
    {
      "epoch": 5.834875068615691,
      "grad_norm": 0.27773046493530273,
      "learning_rate": 0.00022668525649537468,
      "loss": 0.3514,
      "step": 143500
    },
    {
      "epoch": 5.838941183646085,
      "grad_norm": 0.2994896173477173,
      "learning_rate": 0.00022646394901075555,
      "loss": 0.3513,
      "step": 143600
    },
    {
      "epoch": 5.843007298676479,
      "grad_norm": 0.2830149233341217,
      "learning_rate": 0.00022624264152613642,
      "loss": 0.353,
      "step": 143700
    },
    {
      "epoch": 5.847073413706874,
      "grad_norm": 0.3118404150009155,
      "learning_rate": 0.0002260213340415173,
      "loss": 0.3493,
      "step": 143800
    },
    {
      "epoch": 5.851139528737268,
      "grad_norm": 0.34615573287010193,
      "learning_rate": 0.00022580002655689816,
      "loss": 0.3527,
      "step": 143900
    },
    {
      "epoch": 5.855205643767662,
      "grad_norm": 0.35345715284347534,
      "learning_rate": 0.00022557871907227903,
      "loss": 0.3521,
      "step": 144000
    },
    {
      "epoch": 5.855205643767662,
      "eval_loss": 0.362051397562027,
      "eval_runtime": 113.7676,
      "eval_samples_per_second": 1537.362,
      "eval_steps_per_second": 48.045,
      "step": 144000
    },
    {
      "epoch": 5.859271758798056,
      "grad_norm": 0.303019255399704,
      "learning_rate": 0.0002253574115876599,
      "loss": 0.3492,
      "step": 144100
    },
    {
      "epoch": 5.863337873828451,
      "grad_norm": 0.3438606560230255,
      "learning_rate": 0.00022513610410304077,
      "loss": 0.3511,
      "step": 144200
    },
    {
      "epoch": 5.867403988858845,
      "grad_norm": 0.3155519962310791,
      "learning_rate": 0.00022491479661842164,
      "loss": 0.3539,
      "step": 144300
    },
    {
      "epoch": 5.871470103889239,
      "grad_norm": 0.33324575424194336,
      "learning_rate": 0.0002246934891338025,
      "loss": 0.3511,
      "step": 144400
    },
    {
      "epoch": 5.875536218919633,
      "grad_norm": 0.3100385069847107,
      "learning_rate": 0.00022447218164918338,
      "loss": 0.3499,
      "step": 144500
    },
    {
      "epoch": 5.879602333950027,
      "grad_norm": 0.3194282054901123,
      "learning_rate": 0.00022425087416456425,
      "loss": 0.3517,
      "step": 144600
    },
    {
      "epoch": 5.883668448980422,
      "grad_norm": 0.32451701164245605,
      "learning_rate": 0.00022402956667994512,
      "loss": 0.3504,
      "step": 144700
    },
    {
      "epoch": 5.887734564010816,
      "grad_norm": 0.2887103855609894,
      "learning_rate": 0.000223808259195326,
      "loss": 0.351,
      "step": 144800
    },
    {
      "epoch": 5.89180067904121,
      "grad_norm": 0.30505919456481934,
      "learning_rate": 0.00022358695171070686,
      "loss": 0.3497,
      "step": 144900
    },
    {
      "epoch": 5.895866794071605,
      "grad_norm": 0.3358396589756012,
      "learning_rate": 0.00022336564422608773,
      "loss": 0.3526,
      "step": 145000
    },
    {
      "epoch": 5.899932909101999,
      "grad_norm": 0.29761385917663574,
      "learning_rate": 0.0002231443367414686,
      "loss": 0.3516,
      "step": 145100
    },
    {
      "epoch": 5.903999024132393,
      "grad_norm": 0.3473001718521118,
      "learning_rate": 0.00022292302925684945,
      "loss": 0.3516,
      "step": 145200
    },
    {
      "epoch": 5.908065139162787,
      "grad_norm": 0.32233762741088867,
      "learning_rate": 0.00022270172177223034,
      "loss": 0.3525,
      "step": 145300
    },
    {
      "epoch": 5.912131254193181,
      "grad_norm": 0.31128302216529846,
      "learning_rate": 0.0002224804142876112,
      "loss": 0.3516,
      "step": 145400
    },
    {
      "epoch": 5.916197369223576,
      "grad_norm": 0.3011903464794159,
      "learning_rate": 0.00022225910680299208,
      "loss": 0.3509,
      "step": 145500
    },
    {
      "epoch": 5.92026348425397,
      "grad_norm": 0.31081342697143555,
      "learning_rate": 0.00022203779931837295,
      "loss": 0.3517,
      "step": 145600
    },
    {
      "epoch": 5.924329599284364,
      "grad_norm": 0.30660825967788696,
      "learning_rate": 0.00022181649183375382,
      "loss": 0.3519,
      "step": 145700
    },
    {
      "epoch": 5.928395714314758,
      "grad_norm": 0.31889447569847107,
      "learning_rate": 0.0002215951843491347,
      "loss": 0.3513,
      "step": 145800
    },
    {
      "epoch": 5.9324618293451525,
      "grad_norm": 0.29811447858810425,
      "learning_rate": 0.00022137387686451556,
      "loss": 0.3516,
      "step": 145900
    },
    {
      "epoch": 5.9365279443755465,
      "grad_norm": 0.3096832036972046,
      "learning_rate": 0.00022115256937989643,
      "loss": 0.3529,
      "step": 146000
    },
    {
      "epoch": 5.9365279443755465,
      "eval_loss": 0.36136558651924133,
      "eval_runtime": 114.1569,
      "eval_samples_per_second": 1532.119,
      "eval_steps_per_second": 47.881,
      "step": 146000
    },
    {
      "epoch": 5.9405940594059405,
      "grad_norm": 0.3167386054992676,
      "learning_rate": 0.0002209312618952773,
      "loss": 0.35,
      "step": 146100
    },
    {
      "epoch": 5.9446601744363345,
      "grad_norm": 0.34132274985313416,
      "learning_rate": 0.00022070995441065817,
      "loss": 0.3511,
      "step": 146200
    },
    {
      "epoch": 5.9487262894667285,
      "grad_norm": 0.29880690574645996,
      "learning_rate": 0.00022048864692603905,
      "loss": 0.3525,
      "step": 146300
    },
    {
      "epoch": 5.952792404497123,
      "grad_norm": 0.28197181224823,
      "learning_rate": 0.00022026733944141992,
      "loss": 0.3517,
      "step": 146400
    },
    {
      "epoch": 5.956858519527517,
      "grad_norm": 0.2869912087917328,
      "learning_rate": 0.00022004603195680079,
      "loss": 0.3496,
      "step": 146500
    },
    {
      "epoch": 5.960924634557911,
      "grad_norm": 0.31986677646636963,
      "learning_rate": 0.00021982472447218166,
      "loss": 0.351,
      "step": 146600
    },
    {
      "epoch": 5.964990749588306,
      "grad_norm": 0.3172973692417145,
      "learning_rate": 0.00021960341698756253,
      "loss": 0.3523,
      "step": 146700
    },
    {
      "epoch": 5.9690568646187,
      "grad_norm": 0.3093222677707672,
      "learning_rate": 0.0002193821095029434,
      "loss": 0.3518,
      "step": 146800
    },
    {
      "epoch": 5.973122979649094,
      "grad_norm": 0.3204258382320404,
      "learning_rate": 0.00021916080201832424,
      "loss": 0.3519,
      "step": 146900
    },
    {
      "epoch": 5.977189094679488,
      "grad_norm": 0.30083706974983215,
      "learning_rate": 0.00021893949453370514,
      "loss": 0.3529,
      "step": 147000
    },
    {
      "epoch": 5.981255209709882,
      "grad_norm": 0.31026652455329895,
      "learning_rate": 0.000218718187049086,
      "loss": 0.351,
      "step": 147100
    },
    {
      "epoch": 5.985321324740277,
      "grad_norm": 0.2866972088813782,
      "learning_rate": 0.00021849687956446688,
      "loss": 0.3527,
      "step": 147200
    },
    {
      "epoch": 5.989387439770671,
      "grad_norm": 0.41276246309280396,
      "learning_rate": 0.00021827557207984775,
      "loss": 0.3508,
      "step": 147300
    },
    {
      "epoch": 5.993453554801065,
      "grad_norm": 0.32814764976501465,
      "learning_rate": 0.00021805426459522862,
      "loss": 0.3516,
      "step": 147400
    },
    {
      "epoch": 5.997519669831459,
      "grad_norm": 0.37105339765548706,
      "learning_rate": 0.0002178329571106095,
      "loss": 0.3526,
      "step": 147500
    },
    {
      "epoch": 6.001585784861854,
      "grad_norm": 0.33364516496658325,
      "learning_rate": 0.00021761164962599036,
      "loss": 0.3483,
      "step": 147600
    },
    {
      "epoch": 6.005651899892248,
      "grad_norm": 0.2731606960296631,
      "learning_rate": 0.00021739034214137123,
      "loss": 0.3454,
      "step": 147700
    },
    {
      "epoch": 6.009718014922642,
      "grad_norm": 0.31633058190345764,
      "learning_rate": 0.00021716903465675207,
      "loss": 0.3469,
      "step": 147800
    },
    {
      "epoch": 6.013784129953036,
      "grad_norm": 0.37350690364837646,
      "learning_rate": 0.00021694772717213297,
      "loss": 0.3459,
      "step": 147900
    },
    {
      "epoch": 6.017850244983431,
      "grad_norm": 0.2803104519844055,
      "learning_rate": 0.00021672641968751384,
      "loss": 0.3453,
      "step": 148000
    },
    {
      "epoch": 6.017850244983431,
      "eval_loss": 0.3614100217819214,
      "eval_runtime": 113.3776,
      "eval_samples_per_second": 1542.65,
      "eval_steps_per_second": 48.211,
      "step": 148000
    },
    {
      "epoch": 6.021916360013825,
      "grad_norm": 0.3124711513519287,
      "learning_rate": 0.0002165051122028947,
      "loss": 0.3463,
      "step": 148100
    },
    {
      "epoch": 6.025982475044219,
      "grad_norm": 0.2939090430736542,
      "learning_rate": 0.00021628380471827558,
      "loss": 0.3467,
      "step": 148200
    },
    {
      "epoch": 6.030048590074613,
      "grad_norm": 0.3078528940677643,
      "learning_rate": 0.00021606249723365645,
      "loss": 0.3475,
      "step": 148300
    },
    {
      "epoch": 6.034114705105007,
      "grad_norm": 0.3384416401386261,
      "learning_rate": 0.00021584118974903732,
      "loss": 0.3458,
      "step": 148400
    },
    {
      "epoch": 6.038180820135402,
      "grad_norm": 0.33040159940719604,
      "learning_rate": 0.0002156198822644182,
      "loss": 0.345,
      "step": 148500
    },
    {
      "epoch": 6.042246935165796,
      "grad_norm": 0.3848971724510193,
      "learning_rate": 0.00021539857477979903,
      "loss": 0.346,
      "step": 148600
    },
    {
      "epoch": 6.04631305019619,
      "grad_norm": 0.31860631704330444,
      "learning_rate": 0.00021517726729517993,
      "loss": 0.3469,
      "step": 148700
    },
    {
      "epoch": 6.050379165226584,
      "grad_norm": 0.2888185679912567,
      "learning_rate": 0.0002149559598105608,
      "loss": 0.3448,
      "step": 148800
    },
    {
      "epoch": 6.054445280256979,
      "grad_norm": 0.3461361229419708,
      "learning_rate": 0.00021473465232594167,
      "loss": 0.3466,
      "step": 148900
    },
    {
      "epoch": 6.058511395287373,
      "grad_norm": 0.31519585847854614,
      "learning_rate": 0.00021451334484132254,
      "loss": 0.3481,
      "step": 149000
    },
    {
      "epoch": 6.062577510317767,
      "grad_norm": 0.3611266613006592,
      "learning_rate": 0.0002142920373567034,
      "loss": 0.348,
      "step": 149100
    },
    {
      "epoch": 6.066643625348161,
      "grad_norm": 0.31535807251930237,
      "learning_rate": 0.00021407072987208428,
      "loss": 0.3473,
      "step": 149200
    },
    {
      "epoch": 6.070709740378556,
      "grad_norm": 0.2828834056854248,
      "learning_rate": 0.00021384942238746515,
      "loss": 0.3469,
      "step": 149300
    },
    {
      "epoch": 6.07477585540895,
      "grad_norm": 0.3224584758281708,
      "learning_rate": 0.00021362811490284602,
      "loss": 0.3493,
      "step": 149400
    },
    {
      "epoch": 6.078841970439344,
      "grad_norm": 0.31600692868232727,
      "learning_rate": 0.00021340680741822687,
      "loss": 0.347,
      "step": 149500
    },
    {
      "epoch": 6.082908085469738,
      "grad_norm": 0.3430725038051605,
      "learning_rate": 0.00021318549993360776,
      "loss": 0.3452,
      "step": 149600
    },
    {
      "epoch": 6.086974200500132,
      "grad_norm": 0.31511572003364563,
      "learning_rate": 0.00021296419244898863,
      "loss": 0.3459,
      "step": 149700
    },
    {
      "epoch": 6.091040315530527,
      "grad_norm": 0.3132360875606537,
      "learning_rate": 0.0002127428849643695,
      "loss": 0.346,
      "step": 149800
    },
    {
      "epoch": 6.095106430560921,
      "grad_norm": 0.34257930517196655,
      "learning_rate": 0.00021252157747975037,
      "loss": 0.3455,
      "step": 149900
    },
    {
      "epoch": 6.099172545591315,
      "grad_norm": 0.3202229142189026,
      "learning_rate": 0.00021230026999513124,
      "loss": 0.3483,
      "step": 150000
    },
    {
      "epoch": 6.099172545591315,
      "eval_loss": 0.3614620566368103,
      "eval_runtime": 114.4401,
      "eval_samples_per_second": 1528.328,
      "eval_steps_per_second": 47.763,
      "step": 150000
    },
    {
      "epoch": 6.103238660621709,
      "grad_norm": 0.3825511932373047,
      "learning_rate": 0.0002120789625105121,
      "loss": 0.3481,
      "step": 150100
    },
    {
      "epoch": 6.1073047756521035,
      "grad_norm": 0.33544018864631653,
      "learning_rate": 0.00021185765502589298,
      "loss": 0.3475,
      "step": 150200
    },
    {
      "epoch": 6.1113708906824975,
      "grad_norm": 0.3621169328689575,
      "learning_rate": 0.00021163634754127383,
      "loss": 0.3472,
      "step": 150300
    },
    {
      "epoch": 6.1154370057128915,
      "grad_norm": 0.33049219846725464,
      "learning_rate": 0.00021141504005665472,
      "loss": 0.3477,
      "step": 150400
    },
    {
      "epoch": 6.1195031207432855,
      "grad_norm": 0.33381181955337524,
      "learning_rate": 0.0002111937325720356,
      "loss": 0.3453,
      "step": 150500
    },
    {
      "epoch": 6.12356923577368,
      "grad_norm": 0.30205172300338745,
      "learning_rate": 0.00021097242508741646,
      "loss": 0.3468,
      "step": 150600
    },
    {
      "epoch": 6.127635350804074,
      "grad_norm": 0.3205864429473877,
      "learning_rate": 0.00021075111760279733,
      "loss": 0.3469,
      "step": 150700
    },
    {
      "epoch": 6.131701465834468,
      "grad_norm": 0.29866841435432434,
      "learning_rate": 0.0002105298101181782,
      "loss": 0.3459,
      "step": 150800
    },
    {
      "epoch": 6.135767580864862,
      "grad_norm": 0.31567344069480896,
      "learning_rate": 0.00021030850263355908,
      "loss": 0.3468,
      "step": 150900
    },
    {
      "epoch": 6.139833695895257,
      "grad_norm": 0.329782634973526,
      "learning_rate": 0.00021008719514893995,
      "loss": 0.346,
      "step": 151000
    },
    {
      "epoch": 6.143899810925651,
      "grad_norm": 0.3398694694042206,
      "learning_rate": 0.0002098658876643208,
      "loss": 0.3472,
      "step": 151100
    },
    {
      "epoch": 6.147965925956045,
      "grad_norm": 0.31257063150405884,
      "learning_rate": 0.00020964458017970166,
      "loss": 0.3453,
      "step": 151200
    },
    {
      "epoch": 6.152032040986439,
      "grad_norm": 0.36034446954727173,
      "learning_rate": 0.00020942327269508256,
      "loss": 0.3482,
      "step": 151300
    },
    {
      "epoch": 6.156098156016833,
      "grad_norm": 0.31559449434280396,
      "learning_rate": 0.00020920196521046343,
      "loss": 0.3484,
      "step": 151400
    },
    {
      "epoch": 6.160164271047228,
      "grad_norm": 0.3134192228317261,
      "learning_rate": 0.0002089806577258443,
      "loss": 0.348,
      "step": 151500
    },
    {
      "epoch": 6.164230386077622,
      "grad_norm": 0.3439837396144867,
      "learning_rate": 0.00020875935024122517,
      "loss": 0.3473,
      "step": 151600
    },
    {
      "epoch": 6.168296501108016,
      "grad_norm": 0.3062111735343933,
      "learning_rate": 0.00020853804275660604,
      "loss": 0.3462,
      "step": 151700
    },
    {
      "epoch": 6.17236261613841,
      "grad_norm": 0.345112681388855,
      "learning_rate": 0.0002083167352719869,
      "loss": 0.3461,
      "step": 151800
    },
    {
      "epoch": 6.176428731168805,
      "grad_norm": 0.3265635371208191,
      "learning_rate": 0.00020809542778736778,
      "loss": 0.3458,
      "step": 151900
    },
    {
      "epoch": 6.180494846199199,
      "grad_norm": 0.3375372886657715,
      "learning_rate": 0.00020787412030274862,
      "loss": 0.3479,
      "step": 152000
    },
    {
      "epoch": 6.180494846199199,
      "eval_loss": 0.36054015159606934,
      "eval_runtime": 113.1981,
      "eval_samples_per_second": 1545.097,
      "eval_steps_per_second": 48.287,
      "step": 152000
    },
    {
      "epoch": 6.184560961229593,
      "grad_norm": 0.4061778783798218,
      "learning_rate": 0.00020765281281812952,
      "loss": 0.3494,
      "step": 152100
    },
    {
      "epoch": 6.188627076259987,
      "grad_norm": 0.3719034790992737,
      "learning_rate": 0.0002074315053335104,
      "loss": 0.347,
      "step": 152200
    },
    {
      "epoch": 6.192693191290382,
      "grad_norm": 0.3303864300251007,
      "learning_rate": 0.00020721019784889126,
      "loss": 0.3477,
      "step": 152300
    },
    {
      "epoch": 6.196759306320776,
      "grad_norm": 0.3506227433681488,
      "learning_rate": 0.00020698889036427213,
      "loss": 0.348,
      "step": 152400
    },
    {
      "epoch": 6.20082542135117,
      "grad_norm": 0.35550445318222046,
      "learning_rate": 0.000206767582879653,
      "loss": 0.3488,
      "step": 152500
    },
    {
      "epoch": 6.204891536381564,
      "grad_norm": 0.3360181152820587,
      "learning_rate": 0.00020654627539503387,
      "loss": 0.3463,
      "step": 152600
    },
    {
      "epoch": 6.208957651411959,
      "grad_norm": 0.3429238200187683,
      "learning_rate": 0.00020632496791041474,
      "loss": 0.3477,
      "step": 152700
    },
    {
      "epoch": 6.213023766442353,
      "grad_norm": 0.34203040599823,
      "learning_rate": 0.00020610366042579558,
      "loss": 0.3482,
      "step": 152800
    },
    {
      "epoch": 6.217089881472747,
      "grad_norm": 0.2928410768508911,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.3483,
      "step": 152900
    },
    {
      "epoch": 6.221155996503141,
      "grad_norm": 0.3492538034915924,
      "learning_rate": 0.00020566104545655735,
      "loss": 0.3481,
      "step": 153000
    },
    {
      "epoch": 6.225222111533535,
      "grad_norm": 0.32930833101272583,
      "learning_rate": 0.00020543973797193822,
      "loss": 0.3497,
      "step": 153100
    },
    {
      "epoch": 6.22928822656393,
      "grad_norm": 0.3857024610042572,
      "learning_rate": 0.0002052184304873191,
      "loss": 0.346,
      "step": 153200
    },
    {
      "epoch": 6.233354341594324,
      "grad_norm": 0.3017338216304779,
      "learning_rate": 0.00020499712300269996,
      "loss": 0.3454,
      "step": 153300
    },
    {
      "epoch": 6.237420456624718,
      "grad_norm": 0.31446921825408936,
      "learning_rate": 0.00020477581551808083,
      "loss": 0.3485,
      "step": 153400
    },
    {
      "epoch": 6.241486571655112,
      "grad_norm": 0.3406992554664612,
      "learning_rate": 0.0002045545080334617,
      "loss": 0.3473,
      "step": 153500
    },
    {
      "epoch": 6.245552686685507,
      "grad_norm": 0.3588021397590637,
      "learning_rate": 0.00020433320054884257,
      "loss": 0.3482,
      "step": 153600
    },
    {
      "epoch": 6.249618801715901,
      "grad_norm": 0.3170750141143799,
      "learning_rate": 0.00020411189306422341,
      "loss": 0.3464,
      "step": 153700
    },
    {
      "epoch": 6.253684916746295,
      "grad_norm": 0.3438548147678375,
      "learning_rate": 0.0002038905855796043,
      "loss": 0.3487,
      "step": 153800
    },
    {
      "epoch": 6.257751031776689,
      "grad_norm": 0.3911469876766205,
      "learning_rate": 0.00020366927809498518,
      "loss": 0.3486,
      "step": 153900
    },
    {
      "epoch": 6.261817146807084,
      "grad_norm": 0.34131139516830444,
      "learning_rate": 0.00020344797061036605,
      "loss": 0.3474,
      "step": 154000
    },
    {
      "epoch": 6.261817146807084,
      "eval_loss": 0.36022523045539856,
      "eval_runtime": 114.3669,
      "eval_samples_per_second": 1529.306,
      "eval_steps_per_second": 47.794,
      "step": 154000
    },
    {
      "epoch": 6.265883261837478,
      "grad_norm": 0.3403485417366028,
      "learning_rate": 0.00020322666312574692,
      "loss": 0.3439,
      "step": 154100
    },
    {
      "epoch": 6.269949376867872,
      "grad_norm": 0.312252014875412,
      "learning_rate": 0.0002030053556411278,
      "loss": 0.3459,
      "step": 154200
    },
    {
      "epoch": 6.274015491898266,
      "grad_norm": 0.33023330569267273,
      "learning_rate": 0.00020278404815650866,
      "loss": 0.3466,
      "step": 154300
    },
    {
      "epoch": 6.2780816069286605,
      "grad_norm": 0.34439125657081604,
      "learning_rate": 0.00020256274067188953,
      "loss": 0.3474,
      "step": 154400
    },
    {
      "epoch": 6.2821477219590545,
      "grad_norm": 0.3439648151397705,
      "learning_rate": 0.00020234143318727038,
      "loss": 0.3465,
      "step": 154500
    },
    {
      "epoch": 6.2862138369894485,
      "grad_norm": 0.33578890562057495,
      "learning_rate": 0.00020212012570265125,
      "loss": 0.3468,
      "step": 154600
    },
    {
      "epoch": 6.2902799520198425,
      "grad_norm": 0.34245193004608154,
      "learning_rate": 0.00020189881821803214,
      "loss": 0.3491,
      "step": 154700
    },
    {
      "epoch": 6.2943460670502365,
      "grad_norm": 0.3356388807296753,
      "learning_rate": 0.00020167751073341301,
      "loss": 0.344,
      "step": 154800
    },
    {
      "epoch": 6.298412182080631,
      "grad_norm": 0.37665855884552,
      "learning_rate": 0.00020145620324879388,
      "loss": 0.3452,
      "step": 154900
    },
    {
      "epoch": 6.302478297111025,
      "grad_norm": 0.32854512333869934,
      "learning_rate": 0.00020123489576417475,
      "loss": 0.3474,
      "step": 155000
    },
    {
      "epoch": 6.306544412141419,
      "grad_norm": 0.34695419669151306,
      "learning_rate": 0.00020101358827955562,
      "loss": 0.3479,
      "step": 155100
    },
    {
      "epoch": 6.310610527171813,
      "grad_norm": 0.357416570186615,
      "learning_rate": 0.0002007922807949365,
      "loss": 0.3479,
      "step": 155200
    },
    {
      "epoch": 6.314676642202208,
      "grad_norm": 0.30853140354156494,
      "learning_rate": 0.00020057097331031736,
      "loss": 0.3471,
      "step": 155300
    },
    {
      "epoch": 6.318742757232602,
      "grad_norm": 0.32966935634613037,
      "learning_rate": 0.0002003496658256982,
      "loss": 0.3493,
      "step": 155400
    },
    {
      "epoch": 6.322808872262996,
      "grad_norm": 0.3300763964653015,
      "learning_rate": 0.0002001283583410791,
      "loss": 0.3475,
      "step": 155500
    },
    {
      "epoch": 6.32687498729339,
      "grad_norm": 0.346346914768219,
      "learning_rate": 0.00019990705085645998,
      "loss": 0.3486,
      "step": 155600
    },
    {
      "epoch": 6.330941102323785,
      "grad_norm": 0.3249291479587555,
      "learning_rate": 0.00019968574337184085,
      "loss": 0.3456,
      "step": 155700
    },
    {
      "epoch": 6.335007217354179,
      "grad_norm": 0.30918148159980774,
      "learning_rate": 0.00019946443588722172,
      "loss": 0.3472,
      "step": 155800
    },
    {
      "epoch": 6.339073332384573,
      "grad_norm": 0.3599909543991089,
      "learning_rate": 0.00019924312840260259,
      "loss": 0.3462,
      "step": 155900
    },
    {
      "epoch": 6.343139447414967,
      "grad_norm": 0.34323152899742126,
      "learning_rate": 0.00019902182091798346,
      "loss": 0.3464,
      "step": 156000
    },
    {
      "epoch": 6.343139447414967,
      "eval_loss": 0.35976308584213257,
      "eval_runtime": 112.5735,
      "eval_samples_per_second": 1553.669,
      "eval_steps_per_second": 48.555,
      "step": 156000
    },
    {
      "epoch": 6.347205562445362,
      "grad_norm": 0.3253155052661896,
      "learning_rate": 0.00019880051343336433,
      "loss": 0.347,
      "step": 156100
    },
    {
      "epoch": 6.351271677475756,
      "grad_norm": 0.32884451746940613,
      "learning_rate": 0.00019857920594874517,
      "loss": 0.3466,
      "step": 156200
    },
    {
      "epoch": 6.35533779250615,
      "grad_norm": 0.3268170952796936,
      "learning_rate": 0.00019835789846412604,
      "loss": 0.3454,
      "step": 156300
    },
    {
      "epoch": 6.359403907536544,
      "grad_norm": 0.3684828579425812,
      "learning_rate": 0.00019813659097950694,
      "loss": 0.3472,
      "step": 156400
    },
    {
      "epoch": 6.363470022566938,
      "grad_norm": 0.3044537305831909,
      "learning_rate": 0.0001979152834948878,
      "loss": 0.348,
      "step": 156500
    },
    {
      "epoch": 6.367536137597333,
      "grad_norm": 0.3050459921360016,
      "learning_rate": 0.00019769397601026868,
      "loss": 0.3463,
      "step": 156600
    },
    {
      "epoch": 6.371602252627727,
      "grad_norm": 0.3494182527065277,
      "learning_rate": 0.00019747266852564955,
      "loss": 0.3473,
      "step": 156700
    },
    {
      "epoch": 6.375668367658121,
      "grad_norm": 0.35326725244522095,
      "learning_rate": 0.00019725136104103042,
      "loss": 0.3476,
      "step": 156800
    },
    {
      "epoch": 6.379734482688515,
      "grad_norm": 0.3169017732143402,
      "learning_rate": 0.0001970300535564113,
      "loss": 0.3478,
      "step": 156900
    },
    {
      "epoch": 6.38380059771891,
      "grad_norm": 0.32850709557533264,
      "learning_rate": 0.00019680874607179213,
      "loss": 0.345,
      "step": 157000
    },
    {
      "epoch": 6.387866712749304,
      "grad_norm": 0.37066882848739624,
      "learning_rate": 0.000196587438587173,
      "loss": 0.3476,
      "step": 157100
    },
    {
      "epoch": 6.391932827779698,
      "grad_norm": 0.2751624286174774,
      "learning_rate": 0.00019636613110255387,
      "loss": 0.3441,
      "step": 157200
    },
    {
      "epoch": 6.395998942810092,
      "grad_norm": 0.3638080060482025,
      "learning_rate": 0.00019614482361793477,
      "loss": 0.3467,
      "step": 157300
    },
    {
      "epoch": 6.400065057840486,
      "grad_norm": 0.37044188380241394,
      "learning_rate": 0.00019592351613331564,
      "loss": 0.347,
      "step": 157400
    },
    {
      "epoch": 6.404131172870881,
      "grad_norm": 0.3451574146747589,
      "learning_rate": 0.0001957022086486965,
      "loss": 0.3482,
      "step": 157500
    },
    {
      "epoch": 6.408197287901275,
      "grad_norm": 0.34766823053359985,
      "learning_rate": 0.00019548090116407738,
      "loss": 0.3463,
      "step": 157600
    },
    {
      "epoch": 6.412263402931669,
      "grad_norm": 0.3284590244293213,
      "learning_rate": 0.00019525959367945825,
      "loss": 0.3467,
      "step": 157700
    },
    {
      "epoch": 6.416329517962063,
      "grad_norm": 0.35248884558677673,
      "learning_rate": 0.00019503828619483912,
      "loss": 0.3487,
      "step": 157800
    },
    {
      "epoch": 6.420395632992458,
      "grad_norm": 0.31959858536720276,
      "learning_rate": 0.00019481697871021996,
      "loss": 0.3463,
      "step": 157900
    },
    {
      "epoch": 6.424461748022852,
      "grad_norm": 0.3411852717399597,
      "learning_rate": 0.00019459567122560083,
      "loss": 0.3464,
      "step": 158000
    },
    {
      "epoch": 6.424461748022852,
      "eval_loss": 0.3594829738140106,
      "eval_runtime": 116.9572,
      "eval_samples_per_second": 1495.436,
      "eval_steps_per_second": 46.735,
      "step": 158000
    },
    {
      "epoch": 6.428527863053246,
      "grad_norm": 0.3214612603187561,
      "learning_rate": 0.00019437436374098173,
      "loss": 0.3486,
      "step": 158100
    },
    {
      "epoch": 6.43259397808364,
      "grad_norm": 0.34233126044273376,
      "learning_rate": 0.0001941530562563626,
      "loss": 0.3473,
      "step": 158200
    },
    {
      "epoch": 6.4366600931140345,
      "grad_norm": 0.34951722621917725,
      "learning_rate": 0.00019393174877174347,
      "loss": 0.3468,
      "step": 158300
    },
    {
      "epoch": 6.4407262081444285,
      "grad_norm": 0.38395848870277405,
      "learning_rate": 0.00019371044128712434,
      "loss": 0.3491,
      "step": 158400
    },
    {
      "epoch": 6.4447923231748225,
      "grad_norm": 0.31363871693611145,
      "learning_rate": 0.0001934891338025052,
      "loss": 0.3466,
      "step": 158500
    },
    {
      "epoch": 6.4488584382052165,
      "grad_norm": 0.30831095576286316,
      "learning_rate": 0.00019326782631788608,
      "loss": 0.3468,
      "step": 158600
    },
    {
      "epoch": 6.452924553235611,
      "grad_norm": 0.3426505923271179,
      "learning_rate": 0.00019304651883326693,
      "loss": 0.3453,
      "step": 158700
    },
    {
      "epoch": 6.456990668266005,
      "grad_norm": 0.3189431428909302,
      "learning_rate": 0.0001928252113486478,
      "loss": 0.3479,
      "step": 158800
    },
    {
      "epoch": 6.461056783296399,
      "grad_norm": 0.33746904134750366,
      "learning_rate": 0.00019260390386402867,
      "loss": 0.3455,
      "step": 158900
    },
    {
      "epoch": 6.465122898326793,
      "grad_norm": 0.3336672782897949,
      "learning_rate": 0.00019238259637940956,
      "loss": 0.3458,
      "step": 159000
    },
    {
      "epoch": 6.469189013357187,
      "grad_norm": 0.32554441690444946,
      "learning_rate": 0.00019216128889479043,
      "loss": 0.3485,
      "step": 159100
    },
    {
      "epoch": 6.473255128387582,
      "grad_norm": 0.3779742121696472,
      "learning_rate": 0.0001919399814101713,
      "loss": 0.3473,
      "step": 159200
    },
    {
      "epoch": 6.477321243417976,
      "grad_norm": 0.35917410254478455,
      "learning_rate": 0.00019171867392555217,
      "loss": 0.3479,
      "step": 159300
    },
    {
      "epoch": 6.48138735844837,
      "grad_norm": 0.35927850008010864,
      "learning_rate": 0.00019149736644093304,
      "loss": 0.3445,
      "step": 159400
    },
    {
      "epoch": 6.485453473478764,
      "grad_norm": 0.3568032681941986,
      "learning_rate": 0.00019127605895631391,
      "loss": 0.3476,
      "step": 159500
    },
    {
      "epoch": 6.489519588509159,
      "grad_norm": 0.49861377477645874,
      "learning_rate": 0.00019105475147169476,
      "loss": 0.3485,
      "step": 159600
    },
    {
      "epoch": 6.493585703539553,
      "grad_norm": 0.3367135524749756,
      "learning_rate": 0.00019083344398707563,
      "loss": 0.3486,
      "step": 159700
    },
    {
      "epoch": 6.497651818569947,
      "grad_norm": 0.33213385939598083,
      "learning_rate": 0.00019061213650245652,
      "loss": 0.3441,
      "step": 159800
    },
    {
      "epoch": 6.501717933600341,
      "grad_norm": 0.33853983879089355,
      "learning_rate": 0.0001903908290178374,
      "loss": 0.3467,
      "step": 159900
    },
    {
      "epoch": 6.505784048630736,
      "grad_norm": 0.33616453409194946,
      "learning_rate": 0.00019016952153321827,
      "loss": 0.3487,
      "step": 160000
    },
    {
      "epoch": 6.505784048630736,
      "eval_loss": 0.358594685792923,
      "eval_runtime": 113.3508,
      "eval_samples_per_second": 1543.015,
      "eval_steps_per_second": 48.222,
      "step": 160000
    },
    {
      "epoch": 6.50985016366113,
      "grad_norm": 0.3556594252586365,
      "learning_rate": 0.00018994821404859914,
      "loss": 0.3478,
      "step": 160100
    },
    {
      "epoch": 6.513916278691524,
      "grad_norm": 0.3822998106479645,
      "learning_rate": 0.00018972690656398,
      "loss": 0.3456,
      "step": 160200
    },
    {
      "epoch": 6.517982393721918,
      "grad_norm": 0.3244073688983917,
      "learning_rate": 0.00018950559907936088,
      "loss": 0.3468,
      "step": 160300
    },
    {
      "epoch": 6.522048508752313,
      "grad_norm": 0.30526214838027954,
      "learning_rate": 0.00018928429159474172,
      "loss": 0.3476,
      "step": 160400
    },
    {
      "epoch": 6.526114623782707,
      "grad_norm": 0.32817694544792175,
      "learning_rate": 0.0001890629841101226,
      "loss": 0.3464,
      "step": 160500
    },
    {
      "epoch": 6.530180738813101,
      "grad_norm": 0.3781973421573639,
      "learning_rate": 0.00018884167662550346,
      "loss": 0.3482,
      "step": 160600
    },
    {
      "epoch": 6.534246853843495,
      "grad_norm": 0.3625836670398712,
      "learning_rate": 0.00018862036914088436,
      "loss": 0.3459,
      "step": 160700
    },
    {
      "epoch": 6.538312968873889,
      "grad_norm": 0.34507447481155396,
      "learning_rate": 0.00018839906165626523,
      "loss": 0.3494,
      "step": 160800
    },
    {
      "epoch": 6.542379083904284,
      "grad_norm": 0.3688727617263794,
      "learning_rate": 0.0001881777541716461,
      "loss": 0.3465,
      "step": 160900
    },
    {
      "epoch": 6.546445198934678,
      "grad_norm": 0.34748443961143494,
      "learning_rate": 0.00018795644668702697,
      "loss": 0.3467,
      "step": 161000
    },
    {
      "epoch": 6.550511313965072,
      "grad_norm": 0.37049394845962524,
      "learning_rate": 0.00018773513920240784,
      "loss": 0.3456,
      "step": 161100
    },
    {
      "epoch": 6.554577428995466,
      "grad_norm": 0.39466387033462524,
      "learning_rate": 0.0001875138317177887,
      "loss": 0.3442,
      "step": 161200
    },
    {
      "epoch": 6.558643544025861,
      "grad_norm": 0.41405346989631653,
      "learning_rate": 0.00018729252423316955,
      "loss": 0.3479,
      "step": 161300
    },
    {
      "epoch": 6.562709659056255,
      "grad_norm": 0.35441723465919495,
      "learning_rate": 0.00018707121674855042,
      "loss": 0.3465,
      "step": 161400
    },
    {
      "epoch": 6.566775774086649,
      "grad_norm": 0.32640329003334045,
      "learning_rate": 0.00018684990926393132,
      "loss": 0.3464,
      "step": 161500
    },
    {
      "epoch": 6.570841889117043,
      "grad_norm": 0.3398837447166443,
      "learning_rate": 0.0001866286017793122,
      "loss": 0.3471,
      "step": 161600
    },
    {
      "epoch": 6.574908004147438,
      "grad_norm": 0.32630014419555664,
      "learning_rate": 0.00018640729429469306,
      "loss": 0.3466,
      "step": 161700
    },
    {
      "epoch": 6.578974119177832,
      "grad_norm": 0.34092870354652405,
      "learning_rate": 0.00018618598681007393,
      "loss": 0.3473,
      "step": 161800
    },
    {
      "epoch": 6.583040234208226,
      "grad_norm": 0.3784117102622986,
      "learning_rate": 0.0001859646793254548,
      "loss": 0.3465,
      "step": 161900
    },
    {
      "epoch": 6.58710634923862,
      "grad_norm": 0.37197446823120117,
      "learning_rate": 0.00018574337184083567,
      "loss": 0.3477,
      "step": 162000
    },
    {
      "epoch": 6.58710634923862,
      "eval_loss": 0.3580290377140045,
      "eval_runtime": 115.6556,
      "eval_samples_per_second": 1512.266,
      "eval_steps_per_second": 47.261,
      "step": 162000
    },
    {
      "epoch": 6.591172464269015,
      "grad_norm": 0.37658998370170593,
      "learning_rate": 0.0001855220643562165,
      "loss": 0.3466,
      "step": 162100
    },
    {
      "epoch": 6.595238579299409,
      "grad_norm": 0.33716896176338196,
      "learning_rate": 0.00018530075687159738,
      "loss": 0.3462,
      "step": 162200
    },
    {
      "epoch": 6.599304694329803,
      "grad_norm": 0.41510772705078125,
      "learning_rate": 0.00018507944938697825,
      "loss": 0.3458,
      "step": 162300
    },
    {
      "epoch": 6.603370809360197,
      "grad_norm": 0.3263041377067566,
      "learning_rate": 0.00018485814190235915,
      "loss": 0.3461,
      "step": 162400
    },
    {
      "epoch": 6.607436924390591,
      "grad_norm": 0.36649829149246216,
      "learning_rate": 0.00018463683441774002,
      "loss": 0.3443,
      "step": 162500
    },
    {
      "epoch": 6.6115030394209855,
      "grad_norm": 0.35046282410621643,
      "learning_rate": 0.0001844155269331209,
      "loss": 0.3494,
      "step": 162600
    },
    {
      "epoch": 6.6155691544513795,
      "grad_norm": 0.33694788813591003,
      "learning_rate": 0.00018419421944850176,
      "loss": 0.3423,
      "step": 162700
    },
    {
      "epoch": 6.6196352694817735,
      "grad_norm": 0.34464359283447266,
      "learning_rate": 0.00018397291196388263,
      "loss": 0.3472,
      "step": 162800
    },
    {
      "epoch": 6.6237013845121675,
      "grad_norm": 0.3715142607688904,
      "learning_rate": 0.00018375160447926347,
      "loss": 0.3491,
      "step": 162900
    },
    {
      "epoch": 6.627767499542562,
      "grad_norm": 0.3181164264678955,
      "learning_rate": 0.00018353029699464434,
      "loss": 0.3461,
      "step": 163000
    },
    {
      "epoch": 6.631833614572956,
      "grad_norm": 0.37946176528930664,
      "learning_rate": 0.00018330898951002522,
      "loss": 0.3465,
      "step": 163100
    },
    {
      "epoch": 6.63589972960335,
      "grad_norm": 0.3195836842060089,
      "learning_rate": 0.0001830876820254061,
      "loss": 0.3473,
      "step": 163200
    },
    {
      "epoch": 6.639965844633744,
      "grad_norm": 0.34841859340667725,
      "learning_rate": 0.00018286637454078698,
      "loss": 0.3451,
      "step": 163300
    },
    {
      "epoch": 6.644031959664139,
      "grad_norm": 0.3966429531574249,
      "learning_rate": 0.00018264506705616785,
      "loss": 0.3447,
      "step": 163400
    },
    {
      "epoch": 6.648098074694533,
      "grad_norm": 0.38894012570381165,
      "learning_rate": 0.00018242375957154872,
      "loss": 0.3473,
      "step": 163500
    },
    {
      "epoch": 6.652164189724927,
      "grad_norm": 0.3104332983493805,
      "learning_rate": 0.0001822024520869296,
      "loss": 0.3466,
      "step": 163600
    },
    {
      "epoch": 6.656230304755321,
      "grad_norm": 0.3529554009437561,
      "learning_rate": 0.00018198114460231046,
      "loss": 0.3464,
      "step": 163700
    },
    {
      "epoch": 6.660296419785716,
      "grad_norm": 0.35376596450805664,
      "learning_rate": 0.0001817598371176913,
      "loss": 0.3453,
      "step": 163800
    },
    {
      "epoch": 6.66436253481611,
      "grad_norm": 0.33723539113998413,
      "learning_rate": 0.00018153852963307218,
      "loss": 0.3467,
      "step": 163900
    },
    {
      "epoch": 6.668428649846504,
      "grad_norm": 0.37490057945251465,
      "learning_rate": 0.00018131722214845305,
      "loss": 0.346,
      "step": 164000
    },
    {
      "epoch": 6.668428649846504,
      "eval_loss": 0.3579947054386139,
      "eval_runtime": 113.2227,
      "eval_samples_per_second": 1544.761,
      "eval_steps_per_second": 48.277,
      "step": 164000
    },
    {
      "epoch": 6.672494764876898,
      "grad_norm": 0.34495630860328674,
      "learning_rate": 0.00018109591466383394,
      "loss": 0.3475,
      "step": 164100
    },
    {
      "epoch": 6.676560879907292,
      "grad_norm": 0.34418562054634094,
      "learning_rate": 0.00018087460717921481,
      "loss": 0.3466,
      "step": 164200
    },
    {
      "epoch": 6.680626994937687,
      "grad_norm": 0.32920193672180176,
      "learning_rate": 0.00018065329969459568,
      "loss": 0.3476,
      "step": 164300
    },
    {
      "epoch": 6.684693109968081,
      "grad_norm": 0.3581230938434601,
      "learning_rate": 0.00018043199220997656,
      "loss": 0.3467,
      "step": 164400
    },
    {
      "epoch": 6.688759224998475,
      "grad_norm": 0.35499492287635803,
      "learning_rate": 0.00018021068472535743,
      "loss": 0.3448,
      "step": 164500
    },
    {
      "epoch": 6.692825340028869,
      "grad_norm": 0.3265804350376129,
      "learning_rate": 0.00017998937724073827,
      "loss": 0.3474,
      "step": 164600
    },
    {
      "epoch": 6.696891455059264,
      "grad_norm": 0.39224955439567566,
      "learning_rate": 0.00017976806975611914,
      "loss": 0.3471,
      "step": 164700
    },
    {
      "epoch": 6.700957570089658,
      "grad_norm": 0.3670389950275421,
      "learning_rate": 0.0001795467622715,
      "loss": 0.3467,
      "step": 164800
    },
    {
      "epoch": 6.705023685120052,
      "grad_norm": 0.3864099681377411,
      "learning_rate": 0.0001793254547868809,
      "loss": 0.3451,
      "step": 164900
    },
    {
      "epoch": 6.709089800150446,
      "grad_norm": 0.37744519114494324,
      "learning_rate": 0.00017910414730226178,
      "loss": 0.3458,
      "step": 165000
    },
    {
      "epoch": 6.71315591518084,
      "grad_norm": 0.37000033259391785,
      "learning_rate": 0.00017888283981764265,
      "loss": 0.3466,
      "step": 165100
    },
    {
      "epoch": 6.717222030211235,
      "grad_norm": 0.32615864276885986,
      "learning_rate": 0.00017866153233302352,
      "loss": 0.3478,
      "step": 165200
    },
    {
      "epoch": 6.721288145241629,
      "grad_norm": 0.343313992023468,
      "learning_rate": 0.0001784402248484044,
      "loss": 0.3446,
      "step": 165300
    },
    {
      "epoch": 6.725354260272023,
      "grad_norm": 0.3420589566230774,
      "learning_rate": 0.00017821891736378526,
      "loss": 0.3474,
      "step": 165400
    },
    {
      "epoch": 6.729420375302418,
      "grad_norm": 0.366382360458374,
      "learning_rate": 0.0001779976098791661,
      "loss": 0.3465,
      "step": 165500
    },
    {
      "epoch": 6.733486490332812,
      "grad_norm": 0.37223076820373535,
      "learning_rate": 0.00017777630239454697,
      "loss": 0.3455,
      "step": 165600
    },
    {
      "epoch": 6.737552605363206,
      "grad_norm": 0.34894949197769165,
      "learning_rate": 0.00017755499490992784,
      "loss": 0.3445,
      "step": 165700
    },
    {
      "epoch": 6.7416187203936,
      "grad_norm": 0.3505933880805969,
      "learning_rate": 0.00017733368742530874,
      "loss": 0.3453,
      "step": 165800
    },
    {
      "epoch": 6.745684835423994,
      "grad_norm": 0.31639039516448975,
      "learning_rate": 0.0001771123799406896,
      "loss": 0.3451,
      "step": 165900
    },
    {
      "epoch": 6.749750950454389,
      "grad_norm": 0.37136709690093994,
      "learning_rate": 0.00017689107245607048,
      "loss": 0.3454,
      "step": 166000
    },
    {
      "epoch": 6.749750950454389,
      "eval_loss": 0.35753175616264343,
      "eval_runtime": 116.0387,
      "eval_samples_per_second": 1507.273,
      "eval_steps_per_second": 47.105,
      "step": 166000
    },
    {
      "epoch": 6.753817065484783,
      "grad_norm": 0.30822688341140747,
      "learning_rate": 0.00017666976497145135,
      "loss": 0.3468,
      "step": 166100
    },
    {
      "epoch": 6.757883180515177,
      "grad_norm": 0.38394251465797424,
      "learning_rate": 0.00017644845748683222,
      "loss": 0.3461,
      "step": 166200
    },
    {
      "epoch": 6.761949295545571,
      "grad_norm": 0.34334853291511536,
      "learning_rate": 0.00017622715000221306,
      "loss": 0.3468,
      "step": 166300
    },
    {
      "epoch": 6.766015410575966,
      "grad_norm": 0.3227348029613495,
      "learning_rate": 0.00017600584251759393,
      "loss": 0.3468,
      "step": 166400
    },
    {
      "epoch": 6.77008152560636,
      "grad_norm": 0.3543226420879364,
      "learning_rate": 0.0001757845350329748,
      "loss": 0.3473,
      "step": 166500
    },
    {
      "epoch": 6.774147640636754,
      "grad_norm": 0.3585384488105774,
      "learning_rate": 0.00017556322754835567,
      "loss": 0.3467,
      "step": 166600
    },
    {
      "epoch": 6.778213755667148,
      "grad_norm": 0.3531606197357178,
      "learning_rate": 0.00017534192006373657,
      "loss": 0.3465,
      "step": 166700
    },
    {
      "epoch": 6.782279870697542,
      "grad_norm": 0.36885538697242737,
      "learning_rate": 0.00017512061257911744,
      "loss": 0.3471,
      "step": 166800
    },
    {
      "epoch": 6.7863459857279365,
      "grad_norm": 0.34933391213417053,
      "learning_rate": 0.0001748993050944983,
      "loss": 0.3465,
      "step": 166900
    },
    {
      "epoch": 6.7904121007583305,
      "grad_norm": 0.3579033613204956,
      "learning_rate": 0.00017467799760987918,
      "loss": 0.3435,
      "step": 167000
    },
    {
      "epoch": 6.7944782157887245,
      "grad_norm": 0.3645714521408081,
      "learning_rate": 0.00017445669012526005,
      "loss": 0.3458,
      "step": 167100
    },
    {
      "epoch": 6.798544330819119,
      "grad_norm": 0.34058478474617004,
      "learning_rate": 0.0001742353826406409,
      "loss": 0.3445,
      "step": 167200
    },
    {
      "epoch": 6.802610445849513,
      "grad_norm": 0.37901946902275085,
      "learning_rate": 0.00017401407515602176,
      "loss": 0.3433,
      "step": 167300
    },
    {
      "epoch": 6.806676560879907,
      "grad_norm": 0.37162429094314575,
      "learning_rate": 0.00017379276767140263,
      "loss": 0.3471,
      "step": 167400
    },
    {
      "epoch": 6.810742675910301,
      "grad_norm": 0.33973824977874756,
      "learning_rate": 0.00017357146018678353,
      "loss": 0.3456,
      "step": 167500
    },
    {
      "epoch": 6.814808790940695,
      "grad_norm": 0.3712146282196045,
      "learning_rate": 0.0001733501527021644,
      "loss": 0.3451,
      "step": 167600
    },
    {
      "epoch": 6.81887490597109,
      "grad_norm": 0.39301246404647827,
      "learning_rate": 0.00017312884521754527,
      "loss": 0.348,
      "step": 167700
    },
    {
      "epoch": 6.822941021001484,
      "grad_norm": 0.3133317530155182,
      "learning_rate": 0.00017290753773292614,
      "loss": 0.3459,
      "step": 167800
    },
    {
      "epoch": 6.827007136031878,
      "grad_norm": 0.32538464665412903,
      "learning_rate": 0.000172686230248307,
      "loss": 0.3455,
      "step": 167900
    },
    {
      "epoch": 6.831073251062272,
      "grad_norm": 0.4015251398086548,
      "learning_rate": 0.00017246492276368786,
      "loss": 0.3458,
      "step": 168000
    },
    {
      "epoch": 6.831073251062272,
      "eval_loss": 0.3572689890861511,
      "eval_runtime": 112.35,
      "eval_samples_per_second": 1556.76,
      "eval_steps_per_second": 48.652,
      "step": 168000
    },
    {
      "epoch": 6.835139366092667,
      "grad_norm": 0.31408533453941345,
      "learning_rate": 0.00017224361527906873,
      "loss": 0.3478,
      "step": 168100
    },
    {
      "epoch": 6.839205481123061,
      "grad_norm": 0.3508036732673645,
      "learning_rate": 0.0001720223077944496,
      "loss": 0.3477,
      "step": 168200
    },
    {
      "epoch": 6.843271596153455,
      "grad_norm": 0.32434406876564026,
      "learning_rate": 0.00017180100030983047,
      "loss": 0.3447,
      "step": 168300
    },
    {
      "epoch": 6.847337711183849,
      "grad_norm": 0.33517688512802124,
      "learning_rate": 0.00017157969282521136,
      "loss": 0.3456,
      "step": 168400
    },
    {
      "epoch": 6.851403826214243,
      "grad_norm": 0.346518337726593,
      "learning_rate": 0.00017135838534059223,
      "loss": 0.3456,
      "step": 168500
    },
    {
      "epoch": 6.855469941244638,
      "grad_norm": 0.3711214065551758,
      "learning_rate": 0.0001711370778559731,
      "loss": 0.3453,
      "step": 168600
    },
    {
      "epoch": 6.859536056275032,
      "grad_norm": 0.37086063623428345,
      "learning_rate": 0.00017091577037135397,
      "loss": 0.3463,
      "step": 168700
    },
    {
      "epoch": 6.863602171305426,
      "grad_norm": 0.3649854063987732,
      "learning_rate": 0.00017069446288673482,
      "loss": 0.3439,
      "step": 168800
    },
    {
      "epoch": 6.867668286335821,
      "grad_norm": 0.37352505326271057,
      "learning_rate": 0.0001704731554021157,
      "loss": 0.3457,
      "step": 168900
    },
    {
      "epoch": 6.871734401366215,
      "grad_norm": 0.3093854784965515,
      "learning_rate": 0.00017025184791749656,
      "loss": 0.3447,
      "step": 169000
    },
    {
      "epoch": 6.875800516396609,
      "grad_norm": 0.4162505269050598,
      "learning_rate": 0.00017003054043287743,
      "loss": 0.3483,
      "step": 169100
    },
    {
      "epoch": 6.879866631427003,
      "grad_norm": 0.3506956994533539,
      "learning_rate": 0.00016980923294825833,
      "loss": 0.3447,
      "step": 169200
    },
    {
      "epoch": 6.883932746457397,
      "grad_norm": 0.3238446116447449,
      "learning_rate": 0.0001695879254636392,
      "loss": 0.346,
      "step": 169300
    },
    {
      "epoch": 6.887998861487792,
      "grad_norm": 0.3495928645133972,
      "learning_rate": 0.00016936661797902007,
      "loss": 0.3462,
      "step": 169400
    },
    {
      "epoch": 6.892064976518186,
      "grad_norm": 0.29988402128219604,
      "learning_rate": 0.00016914531049440094,
      "loss": 0.3431,
      "step": 169500
    },
    {
      "epoch": 6.89613109154858,
      "grad_norm": 0.38272303342819214,
      "learning_rate": 0.0001689240030097818,
      "loss": 0.348,
      "step": 169600
    },
    {
      "epoch": 6.900197206578974,
      "grad_norm": 0.3556659519672394,
      "learning_rate": 0.00016870269552516265,
      "loss": 0.3465,
      "step": 169700
    },
    {
      "epoch": 6.904263321609369,
      "grad_norm": 0.35239237546920776,
      "learning_rate": 0.00016848138804054352,
      "loss": 0.3451,
      "step": 169800
    },
    {
      "epoch": 6.908329436639763,
      "grad_norm": 0.3579283356666565,
      "learning_rate": 0.0001682600805559244,
      "loss": 0.3454,
      "step": 169900
    },
    {
      "epoch": 6.912395551670157,
      "grad_norm": 0.35863932967185974,
      "learning_rate": 0.00016803877307130526,
      "loss": 0.3478,
      "step": 170000
    },
    {
      "epoch": 6.912395551670157,
      "eval_loss": 0.3568115532398224,
      "eval_runtime": 115.1609,
      "eval_samples_per_second": 1518.762,
      "eval_steps_per_second": 47.464,
      "step": 170000
    },
    {
      "epoch": 6.916461666700551,
      "grad_norm": 0.3460004925727844,
      "learning_rate": 0.00016781746558668616,
      "loss": 0.3468,
      "step": 170100
    },
    {
      "epoch": 6.920527781730945,
      "grad_norm": 0.31544962525367737,
      "learning_rate": 0.00016759615810206703,
      "loss": 0.3455,
      "step": 170200
    },
    {
      "epoch": 6.92459389676134,
      "grad_norm": 0.3609919250011444,
      "learning_rate": 0.0001673748506174479,
      "loss": 0.3462,
      "step": 170300
    },
    {
      "epoch": 6.928660011791734,
      "grad_norm": 0.34648236632347107,
      "learning_rate": 0.00016715354313282877,
      "loss": 0.347,
      "step": 170400
    },
    {
      "epoch": 6.932726126822128,
      "grad_norm": 0.3564571142196655,
      "learning_rate": 0.0001669322356482096,
      "loss": 0.3446,
      "step": 170500
    },
    {
      "epoch": 6.936792241852522,
      "grad_norm": 0.3405625522136688,
      "learning_rate": 0.00016671092816359048,
      "loss": 0.3453,
      "step": 170600
    },
    {
      "epoch": 6.9408583568829165,
      "grad_norm": 0.30706214904785156,
      "learning_rate": 0.00016648962067897135,
      "loss": 0.3463,
      "step": 170700
    },
    {
      "epoch": 6.9449244719133105,
      "grad_norm": 0.37657788395881653,
      "learning_rate": 0.00016626831319435222,
      "loss": 0.3433,
      "step": 170800
    },
    {
      "epoch": 6.9489905869437045,
      "grad_norm": 0.36234620213508606,
      "learning_rate": 0.00016604700570973312,
      "loss": 0.3463,
      "step": 170900
    },
    {
      "epoch": 6.9530567019740985,
      "grad_norm": 0.33497193455696106,
      "learning_rate": 0.000165825698225114,
      "loss": 0.3431,
      "step": 171000
    },
    {
      "epoch": 6.957122817004493,
      "grad_norm": 0.32629474997520447,
      "learning_rate": 0.00016560439074049486,
      "loss": 0.3457,
      "step": 171100
    },
    {
      "epoch": 6.961188932034887,
      "grad_norm": 0.32180631160736084,
      "learning_rate": 0.00016538308325587573,
      "loss": 0.3429,
      "step": 171200
    },
    {
      "epoch": 6.965255047065281,
      "grad_norm": 0.32292333245277405,
      "learning_rate": 0.0001651617757712566,
      "loss": 0.3452,
      "step": 171300
    },
    {
      "epoch": 6.969321162095675,
      "grad_norm": 0.32426413893699646,
      "learning_rate": 0.00016494046828663744,
      "loss": 0.3461,
      "step": 171400
    },
    {
      "epoch": 6.97338727712607,
      "grad_norm": 0.3225485384464264,
      "learning_rate": 0.00016471916080201831,
      "loss": 0.3486,
      "step": 171500
    },
    {
      "epoch": 6.977453392156464,
      "grad_norm": 0.399931937456131,
      "learning_rate": 0.00016449785331739918,
      "loss": 0.3442,
      "step": 171600
    },
    {
      "epoch": 6.981519507186858,
      "grad_norm": 0.36714357137680054,
      "learning_rate": 0.00016427654583278005,
      "loss": 0.3456,
      "step": 171700
    },
    {
      "epoch": 6.985585622217252,
      "grad_norm": 0.3931470215320587,
      "learning_rate": 0.00016405523834816095,
      "loss": 0.3458,
      "step": 171800
    },
    {
      "epoch": 6.989651737247646,
      "grad_norm": 0.39005008339881897,
      "learning_rate": 0.00016383393086354182,
      "loss": 0.3462,
      "step": 171900
    },
    {
      "epoch": 6.993717852278041,
      "grad_norm": 0.4211643636226654,
      "learning_rate": 0.0001636126233789227,
      "loss": 0.3464,
      "step": 172000
    },
    {
      "epoch": 6.993717852278041,
      "eval_loss": 0.35659462213516235,
      "eval_runtime": 114.029,
      "eval_samples_per_second": 1533.837,
      "eval_steps_per_second": 47.935,
      "step": 172000
    },
    {
      "epoch": 6.997783967308435,
      "grad_norm": 0.3518284857273102,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3447,
      "step": 172100
    },
    {
      "epoch": 7.001850082338829,
      "grad_norm": 0.3661775588989258,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3442,
      "step": 172200
    },
    {
      "epoch": 7.005916197369223,
      "grad_norm": 0.3431282341480255,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.3402,
      "step": 172300
    },
    {
      "epoch": 7.009982312399618,
      "grad_norm": 0.44671252369880676,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3399,
      "step": 172400
    },
    {
      "epoch": 7.014048427430012,
      "grad_norm": 0.3442181646823883,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3409,
      "step": 172500
    },
    {
      "epoch": 7.018114542460406,
      "grad_norm": 0.34800201654434204,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.34,
      "step": 172600
    },
    {
      "epoch": 7.0221806574908,
      "grad_norm": 0.37038615345954895,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.341,
      "step": 172700
    },
    {
      "epoch": 7.026246772521195,
      "grad_norm": 0.40036430954933167,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.34,
      "step": 172800
    },
    {
      "epoch": 7.030312887551589,
      "grad_norm": 0.39871856570243835,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.3406,
      "step": 172900
    },
    {
      "epoch": 7.034379002581983,
      "grad_norm": 0.4346846640110016,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3403,
      "step": 173000
    },
    {
      "epoch": 7.038445117612377,
      "grad_norm": 0.35936981439590454,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3403,
      "step": 173100
    },
    {
      "epoch": 7.042511232642772,
      "grad_norm": 0.34441104531288147,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3397,
      "step": 173200
    },
    {
      "epoch": 7.046577347673166,
      "grad_norm": 0.34105539321899414,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.3396,
      "step": 173300
    },
    {
      "epoch": 7.05064346270356,
      "grad_norm": 0.35737237334251404,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3382,
      "step": 173400
    },
    {
      "epoch": 7.054709577733954,
      "grad_norm": 0.4065210819244385,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3418,
      "step": 173500
    },
    {
      "epoch": 7.058775692764348,
      "grad_norm": 0.34048962593078613,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3397,
      "step": 173600
    },
    {
      "epoch": 7.062841807794743,
      "grad_norm": 0.35585471987724304,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.3394,
      "step": 173700
    },
    {
      "epoch": 7.066907922825137,
      "grad_norm": 0.36319977045059204,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3408,
      "step": 173800
    },
    {
      "epoch": 7.070974037855531,
      "grad_norm": 0.34003040194511414,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.3397,
      "step": 173900
    },
    {
      "epoch": 7.075040152885925,
      "grad_norm": 0.35668155550956726,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3395,
      "step": 174000
    },
    {
      "epoch": 7.075040152885925,
      "eval_loss": 0.35658836364746094,
      "eval_runtime": 113.8117,
      "eval_samples_per_second": 1536.766,
      "eval_steps_per_second": 48.027,
      "step": 174000
    },
    {
      "epoch": 7.07910626791632,
      "grad_norm": 0.4055803418159485,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.34,
      "step": 174100
    },
    {
      "epoch": 7.083172382946714,
      "grad_norm": 0.3672468364238739,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.3402,
      "step": 174200
    },
    {
      "epoch": 7.087238497977108,
      "grad_norm": 0.3344961404800415,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.341,
      "step": 174300
    },
    {
      "epoch": 7.091304613007502,
      "grad_norm": 0.3644004464149475,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.3405,
      "step": 174400
    },
    {
      "epoch": 7.095370728037897,
      "grad_norm": 0.3329348564147949,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3399,
      "step": 174500
    },
    {
      "epoch": 7.099436843068291,
      "grad_norm": 0.3876628577709198,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.3413,
      "step": 174600
    },
    {
      "epoch": 7.103502958098685,
      "grad_norm": 0.43067196011543274,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3426,
      "step": 174700
    },
    {
      "epoch": 7.107569073129079,
      "grad_norm": 0.38699397444725037,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.342,
      "step": 174800
    },
    {
      "epoch": 7.111635188159473,
      "grad_norm": 0.3683598041534424,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3401,
      "step": 174900
    },
    {
      "epoch": 7.1157013031898675,
      "grad_norm": 0.4683420956134796,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3413,
      "step": 175000
    },
    {
      "epoch": 7.1197674182202615,
      "grad_norm": 0.38617104291915894,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.3397,
      "step": 175100
    },
    {
      "epoch": 7.1238335332506555,
      "grad_norm": 0.3614724576473236,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.3412,
      "step": 175200
    },
    {
      "epoch": 7.1278996482810495,
      "grad_norm": 0.40193402767181396,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3415,
      "step": 175300
    },
    {
      "epoch": 7.131965763311444,
      "grad_norm": 0.38947874307632446,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3409,
      "step": 175400
    },
    {
      "epoch": 7.136031878341838,
      "grad_norm": 0.34622541069984436,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3409,
      "step": 175500
    },
    {
      "epoch": 7.140097993372232,
      "grad_norm": 0.39472174644470215,
      "learning_rate": 0.000155645553932634,
      "loss": 0.3403,
      "step": 175600
    },
    {
      "epoch": 7.144164108402626,
      "grad_norm": 0.398670494556427,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3382,
      "step": 175700
    },
    {
      "epoch": 7.148230223433021,
      "grad_norm": 0.38067105412483215,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3409,
      "step": 175800
    },
    {
      "epoch": 7.152296338463415,
      "grad_norm": 0.39497238397598267,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3405,
      "step": 175900
    },
    {
      "epoch": 7.156362453493809,
      "grad_norm": 0.3525525629520416,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.3421,
      "step": 176000
    },
    {
      "epoch": 7.156362453493809,
      "eval_loss": 0.355363667011261,
      "eval_runtime": 113.8193,
      "eval_samples_per_second": 1536.663,
      "eval_steps_per_second": 48.023,
      "step": 176000
    },
    {
      "epoch": 7.160428568524203,
      "grad_norm": 0.4190342128276825,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.3425,
      "step": 176100
    },
    {
      "epoch": 7.164494683554598,
      "grad_norm": 0.35342222452163696,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3405,
      "step": 176200
    },
    {
      "epoch": 7.168560798584992,
      "grad_norm": 0.39953047037124634,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.3408,
      "step": 176300
    },
    {
      "epoch": 7.172626913615386,
      "grad_norm": 0.4065215587615967,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3416,
      "step": 176400
    },
    {
      "epoch": 7.17669302864578,
      "grad_norm": 0.33137449622154236,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3411,
      "step": 176500
    },
    {
      "epoch": 7.180759143676174,
      "grad_norm": 0.3944922983646393,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3385,
      "step": 176600
    },
    {
      "epoch": 7.184825258706569,
      "grad_norm": 0.3828778862953186,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.3389,
      "step": 176700
    },
    {
      "epoch": 7.188891373736963,
      "grad_norm": 0.46211254596710205,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3422,
      "step": 176800
    },
    {
      "epoch": 7.192957488767357,
      "grad_norm": 0.38315480947494507,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3403,
      "step": 176900
    },
    {
      "epoch": 7.197023603797751,
      "grad_norm": 0.3692014515399933,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3412,
      "step": 177000
    },
    {
      "epoch": 7.201089718828146,
      "grad_norm": 0.37148040533065796,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3414,
      "step": 177100
    },
    {
      "epoch": 7.20515583385854,
      "grad_norm": 0.342160701751709,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3403,
      "step": 177200
    },
    {
      "epoch": 7.209221948888934,
      "grad_norm": 0.35901495814323425,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.3398,
      "step": 177300
    },
    {
      "epoch": 7.213288063919328,
      "grad_norm": 0.38219425082206726,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.3418,
      "step": 177400
    },
    {
      "epoch": 7.217354178949723,
      "grad_norm": 0.44311630725860596,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.3413,
      "step": 177500
    },
    {
      "epoch": 7.221420293980117,
      "grad_norm": 0.37677302956581116,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3401,
      "step": 177600
    },
    {
      "epoch": 7.225486409010511,
      "grad_norm": 0.4114495515823364,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3401,
      "step": 177700
    },
    {
      "epoch": 7.229552524040905,
      "grad_norm": 0.4350253939628601,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.3423,
      "step": 177800
    },
    {
      "epoch": 7.233618639071299,
      "grad_norm": 0.40423092246055603,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3415,
      "step": 177900
    },
    {
      "epoch": 7.237684754101694,
      "grad_norm": 0.3627640902996063,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.3386,
      "step": 178000
    },
    {
      "epoch": 7.237684754101694,
      "eval_loss": 0.35548165440559387,
      "eval_runtime": 116.0189,
      "eval_samples_per_second": 1507.53,
      "eval_steps_per_second": 47.113,
      "step": 178000
    },
    {
      "epoch": 7.241750869132088,
      "grad_norm": 0.3700180649757385,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3399,
      "step": 178100
    },
    {
      "epoch": 7.245816984162482,
      "grad_norm": 0.3795447051525116,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3408,
      "step": 178200
    },
    {
      "epoch": 7.249883099192876,
      "grad_norm": 0.3965418040752411,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3407,
      "step": 178300
    },
    {
      "epoch": 7.253949214223271,
      "grad_norm": 0.3836786448955536,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.3403,
      "step": 178400
    },
    {
      "epoch": 7.258015329253665,
      "grad_norm": 0.3652729392051697,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3403,
      "step": 178500
    },
    {
      "epoch": 7.262081444284059,
      "grad_norm": 0.4393422305583954,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3402,
      "step": 178600
    },
    {
      "epoch": 7.266147559314453,
      "grad_norm": 0.3732547163963318,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3404,
      "step": 178700
    },
    {
      "epoch": 7.2702136743448476,
      "grad_norm": 0.46049413084983826,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3404,
      "step": 178800
    },
    {
      "epoch": 7.274279789375242,
      "grad_norm": 0.4035322070121765,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3403,
      "step": 178900
    },
    {
      "epoch": 7.278345904405636,
      "grad_norm": 0.42853987216949463,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3389,
      "step": 179000
    },
    {
      "epoch": 7.28241201943603,
      "grad_norm": 0.45574483275413513,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.34,
      "step": 179100
    },
    {
      "epoch": 7.2864781344664245,
      "grad_norm": 0.3733452260494232,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3398,
      "step": 179200
    },
    {
      "epoch": 7.2905442494968185,
      "grad_norm": 0.3652682304382324,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.3397,
      "step": 179300
    },
    {
      "epoch": 7.2946103645272125,
      "grad_norm": 0.381817489862442,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3403,
      "step": 179400
    },
    {
      "epoch": 7.2986764795576065,
      "grad_norm": 0.3673219382762909,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3424,
      "step": 179500
    },
    {
      "epoch": 7.3027425945880005,
      "grad_norm": 0.34079355001449585,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3425,
      "step": 179600
    },
    {
      "epoch": 7.306808709618395,
      "grad_norm": 0.40425947308540344,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.3397,
      "step": 179700
    },
    {
      "epoch": 7.310874824648789,
      "grad_norm": 0.46253809332847595,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.3401,
      "step": 179800
    },
    {
      "epoch": 7.314940939679183,
      "grad_norm": 0.3981817662715912,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3403,
      "step": 179900
    },
    {
      "epoch": 7.319007054709577,
      "grad_norm": 0.4247349500656128,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3409,
      "step": 180000
    },
    {
      "epoch": 7.319007054709577,
      "eval_loss": 0.3550485670566559,
      "eval_runtime": 113.3521,
      "eval_samples_per_second": 1542.998,
      "eval_steps_per_second": 48.221,
      "step": 180000
    },
    {
      "epoch": 7.323073169739972,
      "grad_norm": 0.37809598445892334,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3407,
      "step": 180100
    },
    {
      "epoch": 7.327139284770366,
      "grad_norm": 0.3549582064151764,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.3394,
      "step": 180200
    },
    {
      "epoch": 7.33120539980076,
      "grad_norm": 0.45690515637397766,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3398,
      "step": 180300
    },
    {
      "epoch": 7.335271514831154,
      "grad_norm": 0.3981710970401764,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.34,
      "step": 180400
    },
    {
      "epoch": 7.339337629861549,
      "grad_norm": 0.322075754404068,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3398,
      "step": 180500
    },
    {
      "epoch": 7.343403744891943,
      "grad_norm": 0.3866617679595947,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.3385,
      "step": 180600
    },
    {
      "epoch": 7.347469859922337,
      "grad_norm": 0.3764309287071228,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3422,
      "step": 180700
    },
    {
      "epoch": 7.351535974952731,
      "grad_norm": 0.4168277680873871,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.3398,
      "step": 180800
    },
    {
      "epoch": 7.355602089983126,
      "grad_norm": 0.42484039068222046,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3394,
      "step": 180900
    },
    {
      "epoch": 7.35966820501352,
      "grad_norm": 0.3228091895580292,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3407,
      "step": 181000
    },
    {
      "epoch": 7.363734320043914,
      "grad_norm": 0.38164234161376953,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3408,
      "step": 181100
    },
    {
      "epoch": 7.367800435074308,
      "grad_norm": 0.43466630578041077,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3396,
      "step": 181200
    },
    {
      "epoch": 7.371866550104702,
      "grad_norm": 0.378665953874588,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3409,
      "step": 181300
    },
    {
      "epoch": 7.375932665135097,
      "grad_norm": 0.4464696943759918,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3407,
      "step": 181400
    },
    {
      "epoch": 7.379998780165491,
      "grad_norm": 0.38530224561691284,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.3396,
      "step": 181500
    },
    {
      "epoch": 7.384064895195885,
      "grad_norm": 0.3514145314693451,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3396,
      "step": 181600
    },
    {
      "epoch": 7.388131010226279,
      "grad_norm": 0.3477829396724701,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.3385,
      "step": 181700
    },
    {
      "epoch": 7.392197125256674,
      "grad_norm": 0.4325415790081024,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3411,
      "step": 181800
    },
    {
      "epoch": 7.396263240287068,
      "grad_norm": 0.4068966209888458,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3407,
      "step": 181900
    },
    {
      "epoch": 7.400329355317462,
      "grad_norm": 0.36481305956840515,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3398,
      "step": 182000
    },
    {
      "epoch": 7.400329355317462,
      "eval_loss": 0.35471126437187195,
      "eval_runtime": 114.1149,
      "eval_samples_per_second": 1532.683,
      "eval_steps_per_second": 47.899,
      "step": 182000
    },
    {
      "epoch": 7.404395470347856,
      "grad_norm": 0.36901551485061646,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3403,
      "step": 182100
    },
    {
      "epoch": 7.408461585378251,
      "grad_norm": 0.3543088436126709,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.341,
      "step": 182200
    },
    {
      "epoch": 7.412527700408645,
      "grad_norm": 0.3519361615180969,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.34,
      "step": 182300
    },
    {
      "epoch": 7.416593815439039,
      "grad_norm": 0.36020627617836,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3424,
      "step": 182400
    },
    {
      "epoch": 7.420659930469433,
      "grad_norm": 0.3666872978210449,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3432,
      "step": 182500
    },
    {
      "epoch": 7.424726045499828,
      "grad_norm": 0.39161401987075806,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.34,
      "step": 182600
    },
    {
      "epoch": 7.428792160530222,
      "grad_norm": 0.3733379542827606,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3427,
      "step": 182700
    },
    {
      "epoch": 7.432858275560616,
      "grad_norm": 0.41268041729927063,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3414,
      "step": 182800
    },
    {
      "epoch": 7.43692439059101,
      "grad_norm": 0.3794424533843994,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.3402,
      "step": 182900
    },
    {
      "epoch": 7.440990505621404,
      "grad_norm": 0.37504738569259644,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3402,
      "step": 183000
    },
    {
      "epoch": 7.4450566206517985,
      "grad_norm": 0.401725709438324,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3407,
      "step": 183100
    },
    {
      "epoch": 7.4491227356821925,
      "grad_norm": 0.39502617716789246,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.339,
      "step": 183200
    },
    {
      "epoch": 7.4531888507125865,
      "grad_norm": 0.4060048758983612,
      "learning_rate": 0.000138604877616961,
      "loss": 0.341,
      "step": 183300
    },
    {
      "epoch": 7.4572549657429805,
      "grad_norm": 0.36300384998321533,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.3391,
      "step": 183400
    },
    {
      "epoch": 7.461321080773375,
      "grad_norm": 0.39888137578964233,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3403,
      "step": 183500
    },
    {
      "epoch": 7.465387195803769,
      "grad_norm": 0.3578644096851349,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.3403,
      "step": 183600
    },
    {
      "epoch": 7.469453310834163,
      "grad_norm": 0.42471420764923096,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3404,
      "step": 183700
    },
    {
      "epoch": 7.473519425864557,
      "grad_norm": 0.40946394205093384,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.3414,
      "step": 183800
    },
    {
      "epoch": 7.477585540894952,
      "grad_norm": 0.3901958763599396,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3384,
      "step": 183900
    },
    {
      "epoch": 7.481651655925346,
      "grad_norm": 0.384164959192276,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.3415,
      "step": 184000
    },
    {
      "epoch": 7.481651655925346,
      "eval_loss": 0.3537675440311432,
      "eval_runtime": 115.5995,
      "eval_samples_per_second": 1513.0,
      "eval_steps_per_second": 47.284,
      "step": 184000
    },
    {
      "epoch": 7.48571777095574,
      "grad_norm": 0.37059667706489563,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3407,
      "step": 184100
    },
    {
      "epoch": 7.489783885986134,
      "grad_norm": 0.3651699721813202,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.3421,
      "step": 184200
    },
    {
      "epoch": 7.493850001016529,
      "grad_norm": 0.39351677894592285,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.3396,
      "step": 184300
    },
    {
      "epoch": 7.497916116046923,
      "grad_norm": 0.44847843050956726,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3394,
      "step": 184400
    },
    {
      "epoch": 7.501982231077317,
      "grad_norm": 0.4521331489086151,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3409,
      "step": 184500
    },
    {
      "epoch": 7.506048346107711,
      "grad_norm": 0.4092594385147095,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.3388,
      "step": 184600
    },
    {
      "epoch": 7.510114461138105,
      "grad_norm": 0.3649623692035675,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3402,
      "step": 184700
    },
    {
      "epoch": 7.5141805761685,
      "grad_norm": 0.36794015765190125,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.3388,
      "step": 184800
    },
    {
      "epoch": 7.518246691198894,
      "grad_norm": 0.3866054117679596,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.3416,
      "step": 184900
    },
    {
      "epoch": 7.522312806229288,
      "grad_norm": 0.3862244486808777,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3407,
      "step": 185000
    },
    {
      "epoch": 7.526378921259682,
      "grad_norm": 0.3713497817516327,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3395,
      "step": 185100
    },
    {
      "epoch": 7.530445036290077,
      "grad_norm": 0.385021448135376,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3415,
      "step": 185200
    },
    {
      "epoch": 7.534511151320471,
      "grad_norm": 0.3985573947429657,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3395,
      "step": 185300
    },
    {
      "epoch": 7.538577266350865,
      "grad_norm": 0.4105500280857086,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.3412,
      "step": 185400
    },
    {
      "epoch": 7.542643381381259,
      "grad_norm": 0.40257635712623596,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.3387,
      "step": 185500
    },
    {
      "epoch": 7.546709496411653,
      "grad_norm": 0.4238576292991638,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.3411,
      "step": 185600
    },
    {
      "epoch": 7.550775611442048,
      "grad_norm": 0.3952423632144928,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3404,
      "step": 185700
    },
    {
      "epoch": 7.554841726472442,
      "grad_norm": 0.41084590554237366,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3395,
      "step": 185800
    },
    {
      "epoch": 7.558907841502836,
      "grad_norm": 0.4078845977783203,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.3395,
      "step": 185900
    },
    {
      "epoch": 7.562973956533231,
      "grad_norm": 0.3935788869857788,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.341,
      "step": 186000
    },
    {
      "epoch": 7.562973956533231,
      "eval_loss": 0.35307249426841736,
      "eval_runtime": 113.6677,
      "eval_samples_per_second": 1538.714,
      "eval_steps_per_second": 48.088,
      "step": 186000
    },
    {
      "epoch": 7.567040071563625,
      "grad_norm": 0.41178789734840393,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3401,
      "step": 186100
    },
    {
      "epoch": 7.571106186594019,
      "grad_norm": 0.4097227156162262,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.3404,
      "step": 186200
    },
    {
      "epoch": 7.575172301624413,
      "grad_norm": 0.4055987298488617,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3401,
      "step": 186300
    },
    {
      "epoch": 7.579238416654807,
      "grad_norm": 0.3781619966030121,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3398,
      "step": 186400
    },
    {
      "epoch": 7.583304531685202,
      "grad_norm": 0.36026132106781006,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.3382,
      "step": 186500
    },
    {
      "epoch": 7.587370646715596,
      "grad_norm": 0.45113322138786316,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3391,
      "step": 186600
    },
    {
      "epoch": 7.59143676174599,
      "grad_norm": 0.4058276414871216,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.3403,
      "step": 186700
    },
    {
      "epoch": 7.595502876776384,
      "grad_norm": 0.3887793719768524,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3394,
      "step": 186800
    },
    {
      "epoch": 7.599568991806779,
      "grad_norm": 0.4115165174007416,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.3415,
      "step": 186900
    },
    {
      "epoch": 7.603635106837173,
      "grad_norm": 0.42667317390441895,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3396,
      "step": 187000
    },
    {
      "epoch": 7.607701221867567,
      "grad_norm": 0.4407403767108917,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3391,
      "step": 187100
    },
    {
      "epoch": 7.611767336897961,
      "grad_norm": 0.46941256523132324,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.34,
      "step": 187200
    },
    {
      "epoch": 7.615833451928355,
      "grad_norm": 0.4337743818759918,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.3395,
      "step": 187300
    },
    {
      "epoch": 7.6198995669587495,
      "grad_norm": 0.39772242307662964,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.3407,
      "step": 187400
    },
    {
      "epoch": 7.6239656819891435,
      "grad_norm": 0.4390134811401367,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.34,
      "step": 187500
    },
    {
      "epoch": 7.6280317970195375,
      "grad_norm": 0.426373153924942,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.3393,
      "step": 187600
    },
    {
      "epoch": 7.632097912049932,
      "grad_norm": 0.44893139600753784,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3384,
      "step": 187700
    },
    {
      "epoch": 7.636164027080326,
      "grad_norm": 0.4200107455253601,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3406,
      "step": 187800
    },
    {
      "epoch": 7.64023014211072,
      "grad_norm": 0.3727629780769348,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3383,
      "step": 187900
    },
    {
      "epoch": 7.644296257141114,
      "grad_norm": 0.3944259285926819,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.3391,
      "step": 188000
    },
    {
      "epoch": 7.644296257141114,
      "eval_loss": 0.35334455966949463,
      "eval_runtime": 113.362,
      "eval_samples_per_second": 1542.863,
      "eval_steps_per_second": 48.217,
      "step": 188000
    },
    {
      "epoch": 7.648362372171508,
      "grad_norm": 0.3793439269065857,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.3379,
      "step": 188100
    },
    {
      "epoch": 7.652428487201903,
      "grad_norm": 0.40887561440467834,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3388,
      "step": 188200
    },
    {
      "epoch": 7.656494602232297,
      "grad_norm": 0.3864304721355438,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3392,
      "step": 188300
    },
    {
      "epoch": 7.660560717262691,
      "grad_norm": 0.40938565135002136,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3393,
      "step": 188400
    },
    {
      "epoch": 7.664626832293085,
      "grad_norm": 0.4045906364917755,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3424,
      "step": 188500
    },
    {
      "epoch": 7.66869294732348,
      "grad_norm": 0.40434643626213074,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.3394,
      "step": 188600
    },
    {
      "epoch": 7.672759062353874,
      "grad_norm": 0.41011059284210205,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3383,
      "step": 188700
    },
    {
      "epoch": 7.676825177384268,
      "grad_norm": 0.3535047173500061,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.341,
      "step": 188800
    },
    {
      "epoch": 7.680891292414662,
      "grad_norm": 0.3765082359313965,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.3395,
      "step": 188900
    },
    {
      "epoch": 7.684957407445056,
      "grad_norm": 0.40259867906570435,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3399,
      "step": 189000
    },
    {
      "epoch": 7.689023522475451,
      "grad_norm": 0.4111781120300293,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.3402,
      "step": 189100
    },
    {
      "epoch": 7.693089637505845,
      "grad_norm": 0.39001211524009705,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.3378,
      "step": 189200
    },
    {
      "epoch": 7.697155752536239,
      "grad_norm": 0.4816180467605591,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.3397,
      "step": 189300
    },
    {
      "epoch": 7.701221867566633,
      "grad_norm": 0.3943420648574829,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.3393,
      "step": 189400
    },
    {
      "epoch": 7.705287982597028,
      "grad_norm": 0.40615928173065186,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3393,
      "step": 189500
    },
    {
      "epoch": 7.709354097627422,
      "grad_norm": 0.3979175090789795,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.341,
      "step": 189600
    },
    {
      "epoch": 7.713420212657816,
      "grad_norm": 0.4677955210208893,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3395,
      "step": 189700
    },
    {
      "epoch": 7.71748632768821,
      "grad_norm": 0.3852996230125427,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.3391,
      "step": 189800
    },
    {
      "epoch": 7.721552442718605,
      "grad_norm": 0.3399600088596344,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3414,
      "step": 189900
    },
    {
      "epoch": 7.725618557748999,
      "grad_norm": 0.35978084802627563,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.34,
      "step": 190000
    },
    {
      "epoch": 7.725618557748999,
      "eval_loss": 0.35254839062690735,
      "eval_runtime": 114.2562,
      "eval_samples_per_second": 1530.787,
      "eval_steps_per_second": 47.84,
      "step": 190000
    },
    {
      "epoch": 7.729684672779393,
      "grad_norm": 0.47717878222465515,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3388,
      "step": 190100
    },
    {
      "epoch": 7.733750787809787,
      "grad_norm": 0.47899672389030457,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3398,
      "step": 190200
    },
    {
      "epoch": 7.737816902840182,
      "grad_norm": 0.3520458936691284,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.3398,
      "step": 190300
    },
    {
      "epoch": 7.741883017870576,
      "grad_norm": 0.41995498538017273,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.3382,
      "step": 190400
    },
    {
      "epoch": 7.74594913290097,
      "grad_norm": 0.4337732195854187,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3397,
      "step": 190500
    },
    {
      "epoch": 7.750015247931364,
      "grad_norm": 0.39870670437812805,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.3394,
      "step": 190600
    },
    {
      "epoch": 7.754081362961758,
      "grad_norm": 0.41484391689300537,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3369,
      "step": 190700
    },
    {
      "epoch": 7.758147477992153,
      "grad_norm": 0.39245572686195374,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3396,
      "step": 190800
    },
    {
      "epoch": 7.762213593022547,
      "grad_norm": 0.36758530139923096,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.3403,
      "step": 190900
    },
    {
      "epoch": 7.766279708052941,
      "grad_norm": 0.40506136417388916,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3376,
      "step": 191000
    },
    {
      "epoch": 7.770345823083335,
      "grad_norm": 0.3927048146724701,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3391,
      "step": 191100
    },
    {
      "epoch": 7.7744119381137295,
      "grad_norm": 0.3526896834373474,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3395,
      "step": 191200
    },
    {
      "epoch": 7.7784780531441235,
      "grad_norm": 0.38757458329200745,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3391,
      "step": 191300
    },
    {
      "epoch": 7.7825441681745176,
      "grad_norm": 0.36509692668914795,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.34,
      "step": 191400
    },
    {
      "epoch": 7.7866102832049116,
      "grad_norm": 0.4187738001346588,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3398,
      "step": 191500
    },
    {
      "epoch": 7.790676398235306,
      "grad_norm": 0.3634190857410431,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3395,
      "step": 191600
    },
    {
      "epoch": 7.7947425132657004,
      "grad_norm": 0.453151136636734,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3384,
      "step": 191700
    },
    {
      "epoch": 7.7988086282960944,
      "grad_norm": 0.39937353134155273,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.3388,
      "step": 191800
    },
    {
      "epoch": 7.8028747433264884,
      "grad_norm": 0.3970136046409607,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3377,
      "step": 191900
    },
    {
      "epoch": 7.806940858356883,
      "grad_norm": 0.37919148802757263,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3389,
      "step": 192000
    },
    {
      "epoch": 7.806940858356883,
      "eval_loss": 0.35197535157203674,
      "eval_runtime": 114.2363,
      "eval_samples_per_second": 1531.055,
      "eval_steps_per_second": 47.848,
      "step": 192000
    },
    {
      "epoch": 7.811006973387277,
      "grad_norm": 0.43510353565216064,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.3413,
      "step": 192100
    },
    {
      "epoch": 7.815073088417671,
      "grad_norm": 0.3773916959762573,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.339,
      "step": 192200
    },
    {
      "epoch": 7.819139203448065,
      "grad_norm": 0.4370597302913666,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3383,
      "step": 192300
    },
    {
      "epoch": 7.823205318478459,
      "grad_norm": 0.41450533270835876,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.3375,
      "step": 192400
    },
    {
      "epoch": 7.827271433508854,
      "grad_norm": 0.41616693139076233,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.3379,
      "step": 192500
    },
    {
      "epoch": 7.831337548539248,
      "grad_norm": 0.4352757930755615,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.3401,
      "step": 192600
    },
    {
      "epoch": 7.835403663569642,
      "grad_norm": 0.41465091705322266,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3398,
      "step": 192700
    },
    {
      "epoch": 7.839469778600036,
      "grad_norm": 0.36590248346328735,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.339,
      "step": 192800
    },
    {
      "epoch": 7.843535893630431,
      "grad_norm": 0.44654542207717896,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.3378,
      "step": 192900
    },
    {
      "epoch": 7.847602008660825,
      "grad_norm": 0.419980525970459,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.3372,
      "step": 193000
    },
    {
      "epoch": 7.851668123691219,
      "grad_norm": 0.39875996112823486,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.3394,
      "step": 193100
    },
    {
      "epoch": 7.855734238721613,
      "grad_norm": 0.4157177209854126,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3398,
      "step": 193200
    },
    {
      "epoch": 7.859800353752008,
      "grad_norm": 0.3800748586654663,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.3394,
      "step": 193300
    },
    {
      "epoch": 7.863866468782402,
      "grad_norm": 0.44137123227119446,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.3384,
      "step": 193400
    },
    {
      "epoch": 7.867932583812796,
      "grad_norm": 0.4150856137275696,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3394,
      "step": 193500
    },
    {
      "epoch": 7.87199869884319,
      "grad_norm": 0.4626256823539734,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3388,
      "step": 193600
    },
    {
      "epoch": 7.876064813873585,
      "grad_norm": 0.4010581076145172,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3374,
      "step": 193700
    },
    {
      "epoch": 7.880130928903979,
      "grad_norm": 0.4549606442451477,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3398,
      "step": 193800
    },
    {
      "epoch": 7.884197043934373,
      "grad_norm": 0.42414185404777527,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3382,
      "step": 193900
    },
    {
      "epoch": 7.888263158964767,
      "grad_norm": 0.48630160093307495,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3389,
      "step": 194000
    },
    {
      "epoch": 7.888263158964767,
      "eval_loss": 0.3510095477104187,
      "eval_runtime": 113.356,
      "eval_samples_per_second": 1542.945,
      "eval_steps_per_second": 48.22,
      "step": 194000
    },
    {
      "epoch": 7.892329273995161,
      "grad_norm": 0.40474748611450195,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3387,
      "step": 194100
    },
    {
      "epoch": 7.896395389025556,
      "grad_norm": 0.38483282923698425,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.3375,
      "step": 194200
    },
    {
      "epoch": 7.90046150405595,
      "grad_norm": 0.43703749775886536,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3363,
      "step": 194300
    },
    {
      "epoch": 7.904527619086344,
      "grad_norm": 0.4411885440349579,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3391,
      "step": 194400
    },
    {
      "epoch": 7.908593734116738,
      "grad_norm": 0.5187091827392578,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3392,
      "step": 194500
    },
    {
      "epoch": 7.912659849147133,
      "grad_norm": 0.42936813831329346,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.3386,
      "step": 194600
    },
    {
      "epoch": 7.916725964177527,
      "grad_norm": 0.44165468215942383,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.3374,
      "step": 194700
    },
    {
      "epoch": 7.920792079207921,
      "grad_norm": 0.4271797239780426,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3395,
      "step": 194800
    },
    {
      "epoch": 7.924858194238315,
      "grad_norm": 0.4237120747566223,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3392,
      "step": 194900
    },
    {
      "epoch": 7.928924309268709,
      "grad_norm": 0.40776535868644714,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.3411,
      "step": 195000
    },
    {
      "epoch": 7.932990424299104,
      "grad_norm": 0.44721388816833496,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.3374,
      "step": 195100
    },
    {
      "epoch": 7.937056539329498,
      "grad_norm": 0.46491581201553345,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.3385,
      "step": 195200
    },
    {
      "epoch": 7.941122654359892,
      "grad_norm": 0.4498997628688812,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.336,
      "step": 195300
    },
    {
      "epoch": 7.9451887693902865,
      "grad_norm": 0.3952142000198364,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3386,
      "step": 195400
    },
    {
      "epoch": 7.9492548844206805,
      "grad_norm": 0.3746815621852875,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3405,
      "step": 195500
    },
    {
      "epoch": 7.9533209994510745,
      "grad_norm": 0.48208087682724,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.3399,
      "step": 195600
    },
    {
      "epoch": 7.9573871144814685,
      "grad_norm": 0.470551997423172,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.3366,
      "step": 195700
    },
    {
      "epoch": 7.9614532295118625,
      "grad_norm": 0.45510196685791016,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.3375,
      "step": 195800
    },
    {
      "epoch": 7.965519344542257,
      "grad_norm": 0.4003337025642395,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.3372,
      "step": 195900
    },
    {
      "epoch": 7.969585459572651,
      "grad_norm": 0.44919371604919434,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3404,
      "step": 196000
    },
    {
      "epoch": 7.969585459572651,
      "eval_loss": 0.3502306044101715,
      "eval_runtime": 116.5439,
      "eval_samples_per_second": 1500.739,
      "eval_steps_per_second": 46.901,
      "step": 196000
    },
    {
      "epoch": 7.973651574603045,
      "grad_norm": 0.4094510078430176,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.3378,
      "step": 196100
    },
    {
      "epoch": 7.977717689633439,
      "grad_norm": 0.4514084756374359,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3384,
      "step": 196200
    },
    {
      "epoch": 7.981783804663834,
      "grad_norm": 0.4222410023212433,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3382,
      "step": 196300
    },
    {
      "epoch": 7.985849919694228,
      "grad_norm": 0.3707692325115204,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3382,
      "step": 196400
    },
    {
      "epoch": 7.989916034724622,
      "grad_norm": 0.4523765444755554,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3406,
      "step": 196500
    },
    {
      "epoch": 7.993982149755016,
      "grad_norm": 0.4148561954498291,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.338,
      "step": 196600
    },
    {
      "epoch": 7.99804826478541,
      "grad_norm": 0.3844693601131439,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.3358,
      "step": 196700
    },
    {
      "epoch": 8.002114379815804,
      "grad_norm": 0.36021390557289124,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3349,
      "step": 196800
    },
    {
      "epoch": 8.006180494846198,
      "grad_norm": 0.4143591821193695,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.3309,
      "step": 196900
    },
    {
      "epoch": 8.010246609876594,
      "grad_norm": 0.45772871375083923,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3321,
      "step": 197000
    },
    {
      "epoch": 8.014312724906988,
      "grad_norm": 0.40135568380355835,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3301,
      "step": 197100
    },
    {
      "epoch": 8.018378839937382,
      "grad_norm": 0.4334768056869507,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.3313,
      "step": 197200
    },
    {
      "epoch": 8.022444954967776,
      "grad_norm": 0.5061126947402954,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.3326,
      "step": 197300
    },
    {
      "epoch": 8.02651106999817,
      "grad_norm": 0.3927174210548401,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.332,
      "step": 197400
    },
    {
      "epoch": 8.030577185028564,
      "grad_norm": 0.45359566807746887,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3334,
      "step": 197500
    },
    {
      "epoch": 8.034643300058958,
      "grad_norm": 0.3799779415130615,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.3307,
      "step": 197600
    },
    {
      "epoch": 8.038709415089352,
      "grad_norm": 0.39246246218681335,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.3337,
      "step": 197700
    },
    {
      "epoch": 8.042775530119748,
      "grad_norm": 0.5223683714866638,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.333,
      "step": 197800
    },
    {
      "epoch": 8.046841645150142,
      "grad_norm": 0.4515877962112427,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3329,
      "step": 197900
    },
    {
      "epoch": 8.050907760180536,
      "grad_norm": 0.5167526006698608,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3319,
      "step": 198000
    },
    {
      "epoch": 8.050907760180536,
      "eval_loss": 0.35098689794540405,
      "eval_runtime": 113.6219,
      "eval_samples_per_second": 1539.333,
      "eval_steps_per_second": 48.107,
      "step": 198000
    },
    {
      "epoch": 8.05497387521093,
      "grad_norm": 0.4312033951282501,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3322,
      "step": 198100
    },
    {
      "epoch": 8.059039990241324,
      "grad_norm": 0.4135337769985199,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3313,
      "step": 198200
    },
    {
      "epoch": 8.063106105271718,
      "grad_norm": 0.41365018486976624,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.3325,
      "step": 198300
    },
    {
      "epoch": 8.067172220302112,
      "grad_norm": 0.4921477735042572,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3313,
      "step": 198400
    },
    {
      "epoch": 8.071238335332506,
      "grad_norm": 0.42639070749282837,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.332,
      "step": 198500
    },
    {
      "epoch": 8.0753044503629,
      "grad_norm": 0.467833012342453,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3302,
      "step": 198600
    },
    {
      "epoch": 8.079370565393296,
      "grad_norm": 0.40098944306373596,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3323,
      "step": 198700
    },
    {
      "epoch": 8.08343668042369,
      "grad_norm": 0.3993559777736664,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3347,
      "step": 198800
    },
    {
      "epoch": 8.087502795454084,
      "grad_norm": 0.42282313108444214,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.3322,
      "step": 198900
    },
    {
      "epoch": 8.091568910484478,
      "grad_norm": 0.4433400332927704,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3323,
      "step": 199000
    },
    {
      "epoch": 8.095635025514872,
      "grad_norm": 0.43449825048446655,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3338,
      "step": 199100
    },
    {
      "epoch": 8.099701140545266,
      "grad_norm": 0.41915643215179443,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.3338,
      "step": 199200
    },
    {
      "epoch": 8.10376725557566,
      "grad_norm": 0.44464394450187683,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.3321,
      "step": 199300
    },
    {
      "epoch": 8.107833370606054,
      "grad_norm": 0.44360166788101196,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3321,
      "step": 199400
    },
    {
      "epoch": 8.11189948563645,
      "grad_norm": 0.3922421336174011,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3332,
      "step": 199500
    },
    {
      "epoch": 8.115965600666843,
      "grad_norm": 0.42053505778312683,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.333,
      "step": 199600
    },
    {
      "epoch": 8.120031715697237,
      "grad_norm": 0.4683084189891815,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3326,
      "step": 199700
    },
    {
      "epoch": 8.124097830727631,
      "grad_norm": 0.42274633049964905,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.3303,
      "step": 199800
    },
    {
      "epoch": 8.128163945758025,
      "grad_norm": 0.4134623408317566,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3334,
      "step": 199900
    },
    {
      "epoch": 8.13223006078842,
      "grad_norm": 0.4935184717178345,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3334,
      "step": 200000
    },
    {
      "epoch": 8.13223006078842,
      "eval_loss": 0.35017824172973633,
      "eval_runtime": 115.412,
      "eval_samples_per_second": 1515.457,
      "eval_steps_per_second": 47.361,
      "step": 200000
    },
    {
      "epoch": 8.136296175818813,
      "grad_norm": 0.4211396872997284,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.3327,
      "step": 200100
    },
    {
      "epoch": 8.140362290849207,
      "grad_norm": 0.4140316843986511,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.333,
      "step": 200200
    },
    {
      "epoch": 8.144428405879601,
      "grad_norm": 0.4402022659778595,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.3319,
      "step": 200300
    },
    {
      "epoch": 8.148494520909997,
      "grad_norm": 0.4545607566833496,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.3343,
      "step": 200400
    },
    {
      "epoch": 8.152560635940391,
      "grad_norm": 0.5186834931373596,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3333,
      "step": 200500
    },
    {
      "epoch": 8.156626750970785,
      "grad_norm": 0.4269963800907135,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3335,
      "step": 200600
    },
    {
      "epoch": 8.16069286600118,
      "grad_norm": 0.4874025583267212,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3318,
      "step": 200700
    },
    {
      "epoch": 8.164758981031573,
      "grad_norm": 0.45605072379112244,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.3325,
      "step": 200800
    },
    {
      "epoch": 8.168825096061967,
      "grad_norm": 0.4986891746520996,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.332,
      "step": 200900
    },
    {
      "epoch": 8.172891211092361,
      "grad_norm": 0.4432726800441742,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3335,
      "step": 201000
    },
    {
      "epoch": 8.176957326122755,
      "grad_norm": 0.5118234157562256,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3336,
      "step": 201100
    },
    {
      "epoch": 8.181023441153151,
      "grad_norm": 0.46071189641952515,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.3302,
      "step": 201200
    },
    {
      "epoch": 8.185089556183545,
      "grad_norm": 0.4389697313308716,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3321,
      "step": 201300
    },
    {
      "epoch": 8.189155671213939,
      "grad_norm": 0.45987263321876526,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3308,
      "step": 201400
    },
    {
      "epoch": 8.193221786244333,
      "grad_norm": 0.4418928325176239,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.335,
      "step": 201500
    },
    {
      "epoch": 8.197287901274727,
      "grad_norm": 0.43917977809906006,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.3338,
      "step": 201600
    },
    {
      "epoch": 8.201354016305121,
      "grad_norm": 0.47209781408309937,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3326,
      "step": 201700
    },
    {
      "epoch": 8.205420131335515,
      "grad_norm": 0.42372235655784607,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.3335,
      "step": 201800
    },
    {
      "epoch": 8.209486246365909,
      "grad_norm": 0.4701290428638458,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3335,
      "step": 201900
    },
    {
      "epoch": 8.213552361396303,
      "grad_norm": 0.44659939408302307,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3325,
      "step": 202000
    },
    {
      "epoch": 8.213552361396303,
      "eval_loss": 0.3497600853443146,
      "eval_runtime": 113.9097,
      "eval_samples_per_second": 1535.444,
      "eval_steps_per_second": 47.985,
      "step": 202000
    },
    {
      "epoch": 8.217618476426699,
      "grad_norm": 0.41285425424575806,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.3314,
      "step": 202100
    },
    {
      "epoch": 8.221684591457093,
      "grad_norm": 0.5023473501205444,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3327,
      "step": 202200
    },
    {
      "epoch": 8.225750706487487,
      "grad_norm": 0.4187217652797699,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.3329,
      "step": 202300
    },
    {
      "epoch": 8.22981682151788,
      "grad_norm": 0.4537120759487152,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.3331,
      "step": 202400
    },
    {
      "epoch": 8.233882936548275,
      "grad_norm": 0.45369014143943787,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3335,
      "step": 202500
    },
    {
      "epoch": 8.237949051578669,
      "grad_norm": 0.4174356460571289,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3324,
      "step": 202600
    },
    {
      "epoch": 8.242015166609063,
      "grad_norm": 0.5234178304672241,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.3332,
      "step": 202700
    },
    {
      "epoch": 8.246081281639457,
      "grad_norm": 0.44375142455101013,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3318,
      "step": 202800
    },
    {
      "epoch": 8.250147396669853,
      "grad_norm": 0.4084849953651428,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3343,
      "step": 202900
    },
    {
      "epoch": 8.254213511700247,
      "grad_norm": 0.4511752426624298,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3342,
      "step": 203000
    },
    {
      "epoch": 8.25827962673064,
      "grad_norm": 0.4887228310108185,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3321,
      "step": 203100
    },
    {
      "epoch": 8.262345741761035,
      "grad_norm": 0.4205678403377533,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.332,
      "step": 203200
    },
    {
      "epoch": 8.266411856791429,
      "grad_norm": 0.4670083224773407,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3339,
      "step": 203300
    },
    {
      "epoch": 8.270477971821823,
      "grad_norm": 0.48236846923828125,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.3315,
      "step": 203400
    },
    {
      "epoch": 8.274544086852217,
      "grad_norm": 0.49317631125450134,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.3348,
      "step": 203500
    },
    {
      "epoch": 8.27861020188261,
      "grad_norm": 0.5259438157081604,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.3331,
      "step": 203600
    },
    {
      "epoch": 8.282676316913005,
      "grad_norm": 0.4909302592277527,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3318,
      "step": 203700
    },
    {
      "epoch": 8.2867424319434,
      "grad_norm": 0.40018782019615173,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.3323,
      "step": 203800
    },
    {
      "epoch": 8.290808546973794,
      "grad_norm": 0.5031529664993286,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.3315,
      "step": 203900
    },
    {
      "epoch": 8.294874662004188,
      "grad_norm": 0.46044695377349854,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3327,
      "step": 204000
    },
    {
      "epoch": 8.294874662004188,
      "eval_loss": 0.34900370240211487,
      "eval_runtime": 116.5234,
      "eval_samples_per_second": 1501.004,
      "eval_steps_per_second": 46.909,
      "step": 204000
    },
    {
      "epoch": 8.298940777034582,
      "grad_norm": 0.4891470670700073,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.3328,
      "step": 204100
    },
    {
      "epoch": 8.303006892064976,
      "grad_norm": 0.47109413146972656,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.333,
      "step": 204200
    },
    {
      "epoch": 8.30707300709537,
      "grad_norm": 0.4390909671783447,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.3334,
      "step": 204300
    },
    {
      "epoch": 8.311139122125764,
      "grad_norm": 0.5462839007377625,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3333,
      "step": 204400
    },
    {
      "epoch": 8.315205237156158,
      "grad_norm": 0.45757266879081726,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.3325,
      "step": 204500
    },
    {
      "epoch": 8.319271352186554,
      "grad_norm": 0.4712487459182739,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.3333,
      "step": 204600
    },
    {
      "epoch": 8.323337467216948,
      "grad_norm": 0.4612795412540436,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.3337,
      "step": 204700
    },
    {
      "epoch": 8.327403582247342,
      "grad_norm": 0.4343055784702301,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3322,
      "step": 204800
    },
    {
      "epoch": 8.331469697277736,
      "grad_norm": 0.4213527739048004,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.3314,
      "step": 204900
    },
    {
      "epoch": 8.33553581230813,
      "grad_norm": 0.45044609904289246,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.3318,
      "step": 205000
    },
    {
      "epoch": 8.339601927338524,
      "grad_norm": 0.45456403493881226,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.333,
      "step": 205100
    },
    {
      "epoch": 8.343668042368918,
      "grad_norm": 0.4379892647266388,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.3316,
      "step": 205200
    },
    {
      "epoch": 8.347734157399312,
      "grad_norm": 0.4411364495754242,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3327,
      "step": 205300
    },
    {
      "epoch": 8.351800272429706,
      "grad_norm": 0.41220957040786743,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3325,
      "step": 205400
    },
    {
      "epoch": 8.355866387460102,
      "grad_norm": 0.4060971140861511,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.3322,
      "step": 205500
    },
    {
      "epoch": 8.359932502490496,
      "grad_norm": 0.4527360200881958,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3337,
      "step": 205600
    },
    {
      "epoch": 8.36399861752089,
      "grad_norm": 0.5177602767944336,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3325,
      "step": 205700
    },
    {
      "epoch": 8.368064732551284,
      "grad_norm": 0.47891056537628174,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3333,
      "step": 205800
    },
    {
      "epoch": 8.372130847581678,
      "grad_norm": 0.421983003616333,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3322,
      "step": 205900
    },
    {
      "epoch": 8.376196962612072,
      "grad_norm": 0.48695340752601624,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3328,
      "step": 206000
    },
    {
      "epoch": 8.376196962612072,
      "eval_loss": 0.3485606014728546,
      "eval_runtime": 112.6555,
      "eval_samples_per_second": 1552.539,
      "eval_steps_per_second": 48.52,
      "step": 206000
    },
    {
      "epoch": 8.380263077642466,
      "grad_norm": 0.42034435272216797,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3331,
      "step": 206100
    },
    {
      "epoch": 8.38432919267286,
      "grad_norm": 0.4211652874946594,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.3333,
      "step": 206200
    },
    {
      "epoch": 8.388395307703256,
      "grad_norm": 0.5143337845802307,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.3331,
      "step": 206300
    },
    {
      "epoch": 8.39246142273365,
      "grad_norm": 0.4927788972854614,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.335,
      "step": 206400
    },
    {
      "epoch": 8.396527537764044,
      "grad_norm": 0.42683374881744385,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3325,
      "step": 206500
    },
    {
      "epoch": 8.400593652794438,
      "grad_norm": 0.4635467827320099,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.332,
      "step": 206600
    },
    {
      "epoch": 8.404659767824832,
      "grad_norm": 0.4476068913936615,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.3342,
      "step": 206700
    },
    {
      "epoch": 8.408725882855226,
      "grad_norm": 0.43283411860466003,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.333,
      "step": 206800
    },
    {
      "epoch": 8.41279199788562,
      "grad_norm": 0.48092132806777954,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.3328,
      "step": 206900
    },
    {
      "epoch": 8.416858112916014,
      "grad_norm": 0.49238327145576477,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3322,
      "step": 207000
    },
    {
      "epoch": 8.420924227946408,
      "grad_norm": 0.5419068336486816,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3292,
      "step": 207100
    },
    {
      "epoch": 8.424990342976804,
      "grad_norm": 0.48831236362457275,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3321,
      "step": 207200
    },
    {
      "epoch": 8.429056458007198,
      "grad_norm": 0.46833086013793945,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3322,
      "step": 207300
    },
    {
      "epoch": 8.433122573037592,
      "grad_norm": 0.4450080692768097,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3331,
      "step": 207400
    },
    {
      "epoch": 8.437188688067986,
      "grad_norm": 0.42157214879989624,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3326,
      "step": 207500
    },
    {
      "epoch": 8.44125480309838,
      "grad_norm": 0.4385477900505066,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3308,
      "step": 207600
    },
    {
      "epoch": 8.445320918128774,
      "grad_norm": 0.4922090172767639,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3325,
      "step": 207700
    },
    {
      "epoch": 8.449387033159168,
      "grad_norm": 0.44666221737861633,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3297,
      "step": 207800
    },
    {
      "epoch": 8.453453148189562,
      "grad_norm": 0.5110483765602112,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3308,
      "step": 207900
    },
    {
      "epoch": 8.457519263219957,
      "grad_norm": 0.49050477147102356,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.3326,
      "step": 208000
    },
    {
      "epoch": 8.457519263219957,
      "eval_loss": 0.3481128215789795,
      "eval_runtime": 115.0491,
      "eval_samples_per_second": 1520.238,
      "eval_steps_per_second": 47.51,
      "step": 208000
    },
    {
      "epoch": 8.461585378250351,
      "grad_norm": 0.4887962341308594,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.3313,
      "step": 208100
    },
    {
      "epoch": 8.465651493280745,
      "grad_norm": 0.46838605403900146,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.3323,
      "step": 208200
    },
    {
      "epoch": 8.46971760831114,
      "grad_norm": 0.5703259706497192,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.3304,
      "step": 208300
    },
    {
      "epoch": 8.473783723341533,
      "grad_norm": 0.44332319498062134,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3322,
      "step": 208400
    },
    {
      "epoch": 8.477849838371927,
      "grad_norm": 0.512758195400238,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.3329,
      "step": 208500
    },
    {
      "epoch": 8.481915953402321,
      "grad_norm": 0.45878443121910095,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.3327,
      "step": 208600
    },
    {
      "epoch": 8.485982068432715,
      "grad_norm": 0.4441918432712555,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3318,
      "step": 208700
    },
    {
      "epoch": 8.49004818346311,
      "grad_norm": 0.4317062795162201,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.3312,
      "step": 208800
    },
    {
      "epoch": 8.494114298493505,
      "grad_norm": 0.4574061334133148,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.3314,
      "step": 208900
    },
    {
      "epoch": 8.4981804135239,
      "grad_norm": 0.46174225211143494,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3297,
      "step": 209000
    },
    {
      "epoch": 8.502246528554293,
      "grad_norm": 0.46612459421157837,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.3305,
      "step": 209100
    },
    {
      "epoch": 8.506312643584687,
      "grad_norm": 0.48876190185546875,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.3336,
      "step": 209200
    },
    {
      "epoch": 8.510378758615081,
      "grad_norm": 0.5175159573554993,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.332,
      "step": 209300
    },
    {
      "epoch": 8.514444873645475,
      "grad_norm": 0.45589178800582886,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.332,
      "step": 209400
    },
    {
      "epoch": 8.51851098867587,
      "grad_norm": 0.45008307695388794,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.3335,
      "step": 209500
    },
    {
      "epoch": 8.522577103706263,
      "grad_norm": 0.43956661224365234,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.3304,
      "step": 209600
    },
    {
      "epoch": 8.526643218736659,
      "grad_norm": 0.5022574663162231,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.3315,
      "step": 209700
    },
    {
      "epoch": 8.530709333767053,
      "grad_norm": 0.4774561822414398,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.3311,
      "step": 209800
    },
    {
      "epoch": 8.534775448797447,
      "grad_norm": 0.4555564820766449,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3311,
      "step": 209900
    },
    {
      "epoch": 8.538841563827841,
      "grad_norm": 0.47760209441185,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3327,
      "step": 210000
    },
    {
      "epoch": 8.538841563827841,
      "eval_loss": 0.3475326597690582,
      "eval_runtime": 115.0927,
      "eval_samples_per_second": 1519.663,
      "eval_steps_per_second": 47.492,
      "step": 210000
    },
    {
      "epoch": 8.542907678858235,
      "grad_norm": 0.5931859612464905,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.333,
      "step": 210100
    },
    {
      "epoch": 8.546973793888629,
      "grad_norm": 0.5407696962356567,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.3332,
      "step": 210200
    },
    {
      "epoch": 8.551039908919023,
      "grad_norm": 0.5444524884223938,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.3328,
      "step": 210300
    },
    {
      "epoch": 8.555106023949417,
      "grad_norm": 0.5602301359176636,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3335,
      "step": 210400
    },
    {
      "epoch": 8.559172138979811,
      "grad_norm": 0.4563109874725342,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3313,
      "step": 210500
    },
    {
      "epoch": 8.563238254010207,
      "grad_norm": 0.4468441903591156,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.332,
      "step": 210600
    },
    {
      "epoch": 8.5673043690406,
      "grad_norm": 0.45055726170539856,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3317,
      "step": 210700
    },
    {
      "epoch": 8.571370484070995,
      "grad_norm": 0.47270721197128296,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.3318,
      "step": 210800
    },
    {
      "epoch": 8.575436599101389,
      "grad_norm": 0.5666952729225159,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3324,
      "step": 210900
    },
    {
      "epoch": 8.579502714131783,
      "grad_norm": 0.46317723393440247,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.3331,
      "step": 211000
    },
    {
      "epoch": 8.583568829162177,
      "grad_norm": 0.4087761640548706,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3323,
      "step": 211100
    },
    {
      "epoch": 8.58763494419257,
      "grad_norm": 0.4340234696865082,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3293,
      "step": 211200
    },
    {
      "epoch": 8.591701059222965,
      "grad_norm": 0.48815906047821045,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3312,
      "step": 211300
    },
    {
      "epoch": 8.59576717425336,
      "grad_norm": 0.4674460291862488,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3328,
      "step": 211400
    },
    {
      "epoch": 8.599833289283755,
      "grad_norm": 0.504608154296875,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3324,
      "step": 211500
    },
    {
      "epoch": 8.603899404314149,
      "grad_norm": 0.4998331665992737,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.3328,
      "step": 211600
    },
    {
      "epoch": 8.607965519344543,
      "grad_norm": 0.49562719464302063,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.3322,
      "step": 211700
    },
    {
      "epoch": 8.612031634374937,
      "grad_norm": 0.45715704560279846,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3307,
      "step": 211800
    },
    {
      "epoch": 8.61609774940533,
      "grad_norm": 0.5128810405731201,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.3304,
      "step": 211900
    },
    {
      "epoch": 8.620163864435725,
      "grad_norm": 0.4502624273300171,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3304,
      "step": 212000
    },
    {
      "epoch": 8.620163864435725,
      "eval_loss": 0.346698522567749,
      "eval_runtime": 113.824,
      "eval_samples_per_second": 1536.6,
      "eval_steps_per_second": 48.021,
      "step": 212000
    },
    {
      "epoch": 8.624229979466119,
      "grad_norm": 0.49918726086616516,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3319,
      "step": 212100
    },
    {
      "epoch": 8.628296094496513,
      "grad_norm": 0.452612966299057,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.3298,
      "step": 212200
    },
    {
      "epoch": 8.632362209526907,
      "grad_norm": 0.4988589286804199,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3302,
      "step": 212300
    },
    {
      "epoch": 8.636428324557302,
      "grad_norm": 0.4106651544570923,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.3322,
      "step": 212400
    },
    {
      "epoch": 8.640494439587696,
      "grad_norm": 0.5035689473152161,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3332,
      "step": 212500
    },
    {
      "epoch": 8.64456055461809,
      "grad_norm": 0.47852957248687744,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.3309,
      "step": 212600
    },
    {
      "epoch": 8.648626669648484,
      "grad_norm": 0.43794772028923035,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3315,
      "step": 212700
    },
    {
      "epoch": 8.652692784678878,
      "grad_norm": 0.48530247807502747,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.3315,
      "step": 212800
    },
    {
      "epoch": 8.656758899709272,
      "grad_norm": 0.5058887004852295,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3315,
      "step": 212900
    },
    {
      "epoch": 8.660825014739666,
      "grad_norm": 0.4828556180000305,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.33,
      "step": 213000
    },
    {
      "epoch": 8.66489112977006,
      "grad_norm": 0.5871242880821228,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3291,
      "step": 213100
    },
    {
      "epoch": 8.668957244800456,
      "grad_norm": 0.5211130976676941,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.3302,
      "step": 213200
    },
    {
      "epoch": 8.67302335983085,
      "grad_norm": 0.42502713203430176,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.33,
      "step": 213300
    },
    {
      "epoch": 8.677089474861244,
      "grad_norm": 0.43707600235939026,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.3307,
      "step": 213400
    },
    {
      "epoch": 8.681155589891638,
      "grad_norm": 0.5076389312744141,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3312,
      "step": 213500
    },
    {
      "epoch": 8.685221704922032,
      "grad_norm": 0.5452377796173096,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3338,
      "step": 213600
    },
    {
      "epoch": 8.689287819952426,
      "grad_norm": 0.4792498052120209,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3285,
      "step": 213700
    },
    {
      "epoch": 8.69335393498282,
      "grad_norm": 0.4928702116012573,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3299,
      "step": 213800
    },
    {
      "epoch": 8.697420050013214,
      "grad_norm": 0.42425960302352905,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.3312,
      "step": 213900
    },
    {
      "epoch": 8.701486165043608,
      "grad_norm": 0.49454954266548157,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.3306,
      "step": 214000
    },
    {
      "epoch": 8.701486165043608,
      "eval_loss": 0.3460189998149872,
      "eval_runtime": 113.4957,
      "eval_samples_per_second": 1541.045,
      "eval_steps_per_second": 48.16,
      "step": 214000
    },
    {
      "epoch": 8.705552280074004,
      "grad_norm": 0.5134318470954895,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.3292,
      "step": 214100
    },
    {
      "epoch": 8.709618395104398,
      "grad_norm": 0.49676045775413513,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.3299,
      "step": 214200
    },
    {
      "epoch": 8.713684510134792,
      "grad_norm": 0.4382164478302002,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.3301,
      "step": 214300
    },
    {
      "epoch": 8.717750625165186,
      "grad_norm": 0.4659508466720581,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3306,
      "step": 214400
    },
    {
      "epoch": 8.72181674019558,
      "grad_norm": 0.5234275460243225,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3289,
      "step": 214500
    },
    {
      "epoch": 8.725882855225974,
      "grad_norm": 0.5282741189002991,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.3307,
      "step": 214600
    },
    {
      "epoch": 8.729948970256368,
      "grad_norm": 0.48133614659309387,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.3298,
      "step": 214700
    },
    {
      "epoch": 8.734015085286762,
      "grad_norm": 0.4813266694545746,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3311,
      "step": 214800
    },
    {
      "epoch": 8.738081200317158,
      "grad_norm": 0.4696248173713684,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.3322,
      "step": 214900
    },
    {
      "epoch": 8.742147315347552,
      "grad_norm": 0.5427998900413513,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3303,
      "step": 215000
    },
    {
      "epoch": 8.746213430377946,
      "grad_norm": 0.4995080530643463,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.3313,
      "step": 215100
    },
    {
      "epoch": 8.75027954540834,
      "grad_norm": 0.424922913312912,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.334,
      "step": 215200
    },
    {
      "epoch": 8.754345660438734,
      "grad_norm": 0.5559487342834473,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3296,
      "step": 215300
    },
    {
      "epoch": 8.758411775469128,
      "grad_norm": 0.4698154926300049,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.3311,
      "step": 215400
    },
    {
      "epoch": 8.762477890499522,
      "grad_norm": 0.4882919192314148,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3287,
      "step": 215500
    },
    {
      "epoch": 8.766544005529916,
      "grad_norm": 0.492505818605423,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.3316,
      "step": 215600
    },
    {
      "epoch": 8.77061012056031,
      "grad_norm": 0.4551078975200653,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3297,
      "step": 215700
    },
    {
      "epoch": 8.774676235590706,
      "grad_norm": 0.4772174656391144,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3312,
      "step": 215800
    },
    {
      "epoch": 8.7787423506211,
      "grad_norm": 0.4752908945083618,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.3308,
      "step": 215900
    },
    {
      "epoch": 8.782808465651494,
      "grad_norm": 0.44458428025245667,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.33,
      "step": 216000
    },
    {
      "epoch": 8.782808465651494,
      "eval_loss": 0.3456088900566101,
      "eval_runtime": 114.899,
      "eval_samples_per_second": 1522.224,
      "eval_steps_per_second": 47.572,
      "step": 216000
    },
    {
      "epoch": 8.786874580681888,
      "grad_norm": 0.4900815486907959,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3301,
      "step": 216100
    },
    {
      "epoch": 8.790940695712282,
      "grad_norm": 0.4749928414821625,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.3303,
      "step": 216200
    },
    {
      "epoch": 8.795006810742676,
      "grad_norm": 0.6005041003227234,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.33,
      "step": 216300
    },
    {
      "epoch": 8.79907292577307,
      "grad_norm": 0.5414323806762695,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.329,
      "step": 216400
    },
    {
      "epoch": 8.803139040803464,
      "grad_norm": 0.4850828945636749,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.3312,
      "step": 216500
    },
    {
      "epoch": 8.80720515583386,
      "grad_norm": 0.48333391547203064,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3295,
      "step": 216600
    },
    {
      "epoch": 8.811271270864253,
      "grad_norm": 0.525225818157196,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.3308,
      "step": 216700
    },
    {
      "epoch": 8.815337385894647,
      "grad_norm": 0.4865993559360504,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.3286,
      "step": 216800
    },
    {
      "epoch": 8.819403500925041,
      "grad_norm": 0.4458755850791931,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3311,
      "step": 216900
    },
    {
      "epoch": 8.823469615955435,
      "grad_norm": 0.4919563829898834,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.331,
      "step": 217000
    },
    {
      "epoch": 8.82753573098583,
      "grad_norm": 0.5558649897575378,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3305,
      "step": 217100
    },
    {
      "epoch": 8.831601846016223,
      "grad_norm": 0.49132323265075684,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.3301,
      "step": 217200
    },
    {
      "epoch": 8.835667961046617,
      "grad_norm": 0.4557260274887085,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3305,
      "step": 217300
    },
    {
      "epoch": 8.839734076077011,
      "grad_norm": 0.512704074382782,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.3319,
      "step": 217400
    },
    {
      "epoch": 8.843800191107407,
      "grad_norm": 0.48832476139068604,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3293,
      "step": 217500
    },
    {
      "epoch": 8.847866306137801,
      "grad_norm": 0.5246978998184204,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3298,
      "step": 217600
    },
    {
      "epoch": 8.851932421168195,
      "grad_norm": 0.49189576506614685,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3304,
      "step": 217700
    },
    {
      "epoch": 8.85599853619859,
      "grad_norm": 0.4795088469982147,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.3297,
      "step": 217800
    },
    {
      "epoch": 8.860064651228983,
      "grad_norm": 0.5509976148605347,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3291,
      "step": 217900
    },
    {
      "epoch": 8.864130766259377,
      "grad_norm": 0.49090057611465454,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3298,
      "step": 218000
    },
    {
      "epoch": 8.864130766259377,
      "eval_loss": 0.34478121995925903,
      "eval_runtime": 112.4477,
      "eval_samples_per_second": 1555.408,
      "eval_steps_per_second": 48.609,
      "step": 218000
    },
    {
      "epoch": 8.868196881289771,
      "grad_norm": 0.5052531361579895,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.3294,
      "step": 218100
    },
    {
      "epoch": 8.872262996320165,
      "grad_norm": 0.5037828683853149,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.3294,
      "step": 218200
    },
    {
      "epoch": 8.876329111350561,
      "grad_norm": 0.5510346293449402,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3304,
      "step": 218300
    },
    {
      "epoch": 8.880395226380955,
      "grad_norm": 0.5295710563659668,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3303,
      "step": 218400
    },
    {
      "epoch": 8.884461341411349,
      "grad_norm": 0.5202428698539734,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.3298,
      "step": 218500
    },
    {
      "epoch": 8.888527456441743,
      "grad_norm": 0.5447074770927429,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3297,
      "step": 218600
    },
    {
      "epoch": 8.892593571472137,
      "grad_norm": 0.517903208732605,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3292,
      "step": 218700
    },
    {
      "epoch": 8.896659686502531,
      "grad_norm": 0.5809631943702698,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3292,
      "step": 218800
    },
    {
      "epoch": 8.900725801532925,
      "grad_norm": 0.6055744886398315,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3278,
      "step": 218900
    },
    {
      "epoch": 8.904791916563319,
      "grad_norm": 0.47248271107673645,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3288,
      "step": 219000
    },
    {
      "epoch": 8.908858031593713,
      "grad_norm": 0.6018940806388855,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3298,
      "step": 219100
    },
    {
      "epoch": 8.912924146624109,
      "grad_norm": 0.5436387062072754,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3298,
      "step": 219200
    },
    {
      "epoch": 8.916990261654503,
      "grad_norm": 0.4807443916797638,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3304,
      "step": 219300
    },
    {
      "epoch": 8.921056376684897,
      "grad_norm": 0.4678191840648651,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3281,
      "step": 219400
    },
    {
      "epoch": 8.92512249171529,
      "grad_norm": 0.5316670536994934,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3295,
      "step": 219500
    },
    {
      "epoch": 8.929188606745685,
      "grad_norm": 0.5362815856933594,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.3289,
      "step": 219600
    },
    {
      "epoch": 8.933254721776079,
      "grad_norm": 0.5106082558631897,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.3283,
      "step": 219700
    },
    {
      "epoch": 8.937320836806473,
      "grad_norm": 0.5824035406112671,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.3293,
      "step": 219800
    },
    {
      "epoch": 8.941386951836867,
      "grad_norm": 0.47510072588920593,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.3303,
      "step": 219900
    },
    {
      "epoch": 8.945453066867262,
      "grad_norm": 0.5567203760147095,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.329,
      "step": 220000
    },
    {
      "epoch": 8.945453066867262,
      "eval_loss": 0.3441701829433441,
      "eval_runtime": 113.2216,
      "eval_samples_per_second": 1544.776,
      "eval_steps_per_second": 48.277,
      "step": 220000
    },
    {
      "epoch": 8.949519181897656,
      "grad_norm": 0.4580724239349365,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3299,
      "step": 220100
    },
    {
      "epoch": 8.95358529692805,
      "grad_norm": 0.4937454164028168,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.329,
      "step": 220200
    },
    {
      "epoch": 8.957651411958444,
      "grad_norm": 0.4918269217014313,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.3295,
      "step": 220300
    },
    {
      "epoch": 8.961717526988839,
      "grad_norm": 0.509760856628418,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.3275,
      "step": 220400
    },
    {
      "epoch": 8.965783642019233,
      "grad_norm": 0.456704318523407,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.329,
      "step": 220500
    },
    {
      "epoch": 8.969849757049627,
      "grad_norm": 0.4743137061595917,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.3289,
      "step": 220600
    },
    {
      "epoch": 8.97391587208002,
      "grad_norm": 0.5802095532417297,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.329,
      "step": 220700
    },
    {
      "epoch": 8.977981987110415,
      "grad_norm": 0.5017684698104858,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.3291,
      "step": 220800
    },
    {
      "epoch": 8.98204810214081,
      "grad_norm": 0.5275439620018005,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3292,
      "step": 220900
    },
    {
      "epoch": 8.986114217171204,
      "grad_norm": 0.6044138669967651,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.3278,
      "step": 221000
    },
    {
      "epoch": 8.990180332201598,
      "grad_norm": 0.47128674387931824,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.3296,
      "step": 221100
    },
    {
      "epoch": 8.994246447231992,
      "grad_norm": 0.47208285331726074,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3313,
      "step": 221200
    },
    {
      "epoch": 8.998312562262386,
      "grad_norm": 0.45188382267951965,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.3286,
      "step": 221300
    },
    {
      "epoch": 9.00237867729278,
      "grad_norm": 0.484615296125412,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3246,
      "step": 221400
    },
    {
      "epoch": 9.006444792323174,
      "grad_norm": 0.5101736783981323,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.324,
      "step": 221500
    },
    {
      "epoch": 9.010510907353568,
      "grad_norm": 0.49992430210113525,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3225,
      "step": 221600
    },
    {
      "epoch": 9.014577022383964,
      "grad_norm": 0.5282307863235474,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3208,
      "step": 221700
    },
    {
      "epoch": 9.018643137414358,
      "grad_norm": 0.4892978370189667,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.3219,
      "step": 221800
    },
    {
      "epoch": 9.022709252444752,
      "grad_norm": 0.562655508518219,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.3219,
      "step": 221900
    },
    {
      "epoch": 9.026775367475146,
      "grad_norm": 0.5043216943740845,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3224,
      "step": 222000
    },
    {
      "epoch": 9.026775367475146,
      "eval_loss": 0.3443264067173004,
      "eval_runtime": 114.1386,
      "eval_samples_per_second": 1532.365,
      "eval_steps_per_second": 47.889,
      "step": 222000
    },
    {
      "epoch": 9.03084148250554,
      "grad_norm": 0.5134115219116211,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3233,
      "step": 222100
    },
    {
      "epoch": 9.034907597535934,
      "grad_norm": 0.5663789510726929,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.3237,
      "step": 222200
    },
    {
      "epoch": 9.038973712566328,
      "grad_norm": 0.5428726077079773,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3234,
      "step": 222300
    },
    {
      "epoch": 9.043039827596722,
      "grad_norm": 0.5858665704727173,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3234,
      "step": 222400
    },
    {
      "epoch": 9.047105942627116,
      "grad_norm": 0.5633158683776855,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.3222,
      "step": 222500
    },
    {
      "epoch": 9.051172057657512,
      "grad_norm": 0.5478840470314026,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.3222,
      "step": 222600
    },
    {
      "epoch": 9.055238172687906,
      "grad_norm": 0.534796953201294,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.321,
      "step": 222700
    },
    {
      "epoch": 9.0593042877183,
      "grad_norm": 0.5058072805404663,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.3215,
      "step": 222800
    },
    {
      "epoch": 9.063370402748694,
      "grad_norm": 0.5079018473625183,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3223,
      "step": 222900
    },
    {
      "epoch": 9.067436517779088,
      "grad_norm": 0.5189049243927002,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.3209,
      "step": 223000
    },
    {
      "epoch": 9.071502632809482,
      "grad_norm": 0.5237976908683777,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.3233,
      "step": 223100
    },
    {
      "epoch": 9.075568747839876,
      "grad_norm": 0.5656964778900146,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3218,
      "step": 223200
    },
    {
      "epoch": 9.07963486287027,
      "grad_norm": 0.5216886401176453,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.3207,
      "step": 223300
    },
    {
      "epoch": 9.083700977900666,
      "grad_norm": 0.5708197951316833,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.3218,
      "step": 223400
    },
    {
      "epoch": 9.08776709293106,
      "grad_norm": 0.6216362714767456,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3233,
      "step": 223500
    },
    {
      "epoch": 9.091833207961454,
      "grad_norm": 0.510292112827301,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.3232,
      "step": 223600
    },
    {
      "epoch": 9.095899322991848,
      "grad_norm": 0.6003064513206482,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.323,
      "step": 223700
    },
    {
      "epoch": 9.099965438022242,
      "grad_norm": 0.5724294781684875,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3226,
      "step": 223800
    },
    {
      "epoch": 9.104031553052636,
      "grad_norm": 0.5023618340492249,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.3236,
      "step": 223900
    },
    {
      "epoch": 9.10809766808303,
      "grad_norm": 0.5257349610328674,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.3205,
      "step": 224000
    },
    {
      "epoch": 9.10809766808303,
      "eval_loss": 0.3438757061958313,
      "eval_runtime": 113.1354,
      "eval_samples_per_second": 1545.952,
      "eval_steps_per_second": 48.314,
      "step": 224000
    },
    {
      "epoch": 9.112163783113424,
      "grad_norm": 0.5567121505737305,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.3237,
      "step": 224100
    },
    {
      "epoch": 9.116229898143818,
      "grad_norm": 0.540395975112915,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.3226,
      "step": 224200
    },
    {
      "epoch": 9.120296013174213,
      "grad_norm": 0.6450220942497253,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.3231,
      "step": 224300
    },
    {
      "epoch": 9.124362128204607,
      "grad_norm": 0.5102683901786804,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.3243,
      "step": 224400
    },
    {
      "epoch": 9.128428243235001,
      "grad_norm": 0.5283673405647278,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3212,
      "step": 224500
    },
    {
      "epoch": 9.132494358265395,
      "grad_norm": 0.5403662919998169,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3214,
      "step": 224600
    },
    {
      "epoch": 9.13656047329579,
      "grad_norm": 0.541144609451294,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3244,
      "step": 224700
    },
    {
      "epoch": 9.140626588326183,
      "grad_norm": 0.526767909526825,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3222,
      "step": 224800
    },
    {
      "epoch": 9.144692703356577,
      "grad_norm": 0.5670379996299744,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3218,
      "step": 224900
    },
    {
      "epoch": 9.148758818386971,
      "grad_norm": 0.6043624877929688,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3232,
      "step": 225000
    },
    {
      "epoch": 9.152824933417367,
      "grad_norm": 0.5463181734085083,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3215,
      "step": 225100
    },
    {
      "epoch": 9.156891048447761,
      "grad_norm": 0.5852166414260864,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.3233,
      "step": 225200
    },
    {
      "epoch": 9.160957163478155,
      "grad_norm": 0.5205663442611694,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.3223,
      "step": 225300
    },
    {
      "epoch": 9.16502327850855,
      "grad_norm": 0.6934521198272705,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3237,
      "step": 225400
    },
    {
      "epoch": 9.169089393538943,
      "grad_norm": 0.5724356770515442,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3222,
      "step": 225500
    },
    {
      "epoch": 9.173155508569337,
      "grad_norm": 0.616680383682251,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3231,
      "step": 225600
    },
    {
      "epoch": 9.177221623599731,
      "grad_norm": 0.576004683971405,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.3218,
      "step": 225700
    },
    {
      "epoch": 9.181287738630125,
      "grad_norm": 0.6046187877655029,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3228,
      "step": 225800
    },
    {
      "epoch": 9.18535385366052,
      "grad_norm": 0.5157796740531921,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3215,
      "step": 225900
    },
    {
      "epoch": 9.189419968690915,
      "grad_norm": 0.4911075234413147,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3214,
      "step": 226000
    },
    {
      "epoch": 9.189419968690915,
      "eval_loss": 0.34320268034935,
      "eval_runtime": 112.8782,
      "eval_samples_per_second": 1549.475,
      "eval_steps_per_second": 48.424,
      "step": 226000
    },
    {
      "epoch": 9.193486083721309,
      "grad_norm": 0.6066705584526062,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.3222,
      "step": 226100
    },
    {
      "epoch": 9.197552198751703,
      "grad_norm": 0.5431363582611084,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3217,
      "step": 226200
    },
    {
      "epoch": 9.201618313782097,
      "grad_norm": 0.5871829986572266,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3227,
      "step": 226300
    },
    {
      "epoch": 9.205684428812491,
      "grad_norm": 0.5298857092857361,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3223,
      "step": 226400
    },
    {
      "epoch": 9.209750543842885,
      "grad_norm": 0.5392560958862305,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.3237,
      "step": 226500
    },
    {
      "epoch": 9.213816658873279,
      "grad_norm": 0.6085472106933594,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.324,
      "step": 226600
    },
    {
      "epoch": 9.217882773903673,
      "grad_norm": 0.5808648467063904,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3232,
      "step": 226700
    },
    {
      "epoch": 9.221948888934069,
      "grad_norm": 0.6111124157905579,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3229,
      "step": 226800
    },
    {
      "epoch": 9.226015003964463,
      "grad_norm": 0.5253227949142456,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3213,
      "step": 226900
    },
    {
      "epoch": 9.230081118994857,
      "grad_norm": 0.5433210134506226,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3221,
      "step": 227000
    },
    {
      "epoch": 9.23414723402525,
      "grad_norm": 0.5693141222000122,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3228,
      "step": 227100
    },
    {
      "epoch": 9.238213349055645,
      "grad_norm": 0.599463164806366,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.3208,
      "step": 227200
    },
    {
      "epoch": 9.242279464086039,
      "grad_norm": 0.5731222033500671,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3217,
      "step": 227300
    },
    {
      "epoch": 9.246345579116433,
      "grad_norm": 0.6940189003944397,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3218,
      "step": 227400
    },
    {
      "epoch": 9.250411694146827,
      "grad_norm": 0.5885212421417236,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3207,
      "step": 227500
    },
    {
      "epoch": 9.25447780917722,
      "grad_norm": 0.5331254005432129,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3202,
      "step": 227600
    },
    {
      "epoch": 9.258543924207617,
      "grad_norm": 0.5610257387161255,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.3201,
      "step": 227700
    },
    {
      "epoch": 9.26261003923801,
      "grad_norm": 0.5152887105941772,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.3215,
      "step": 227800
    },
    {
      "epoch": 9.266676154268405,
      "grad_norm": 0.5010618567466736,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.3221,
      "step": 227900
    },
    {
      "epoch": 9.270742269298799,
      "grad_norm": 0.6501156091690063,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3212,
      "step": 228000
    },
    {
      "epoch": 9.270742269298799,
      "eval_loss": 0.3426581919193268,
      "eval_runtime": 114.8678,
      "eval_samples_per_second": 1522.637,
      "eval_steps_per_second": 47.585,
      "step": 228000
    },
    {
      "epoch": 9.274808384329193,
      "grad_norm": 0.4867497980594635,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.3211,
      "step": 228100
    },
    {
      "epoch": 9.278874499359587,
      "grad_norm": 0.6207961440086365,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.3203,
      "step": 228200
    },
    {
      "epoch": 9.28294061438998,
      "grad_norm": 0.5574356317520142,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3222,
      "step": 228300
    },
    {
      "epoch": 9.287006729420375,
      "grad_norm": 0.5327698588371277,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3219,
      "step": 228400
    },
    {
      "epoch": 9.29107284445077,
      "grad_norm": 0.5517969131469727,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3225,
      "step": 228500
    },
    {
      "epoch": 9.295138959481164,
      "grad_norm": 0.6730816960334778,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.3236,
      "step": 228600
    },
    {
      "epoch": 9.299205074511558,
      "grad_norm": 0.49792179465293884,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.321,
      "step": 228700
    },
    {
      "epoch": 9.303271189541952,
      "grad_norm": 0.5394736528396606,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3208,
      "step": 228800
    },
    {
      "epoch": 9.307337304572346,
      "grad_norm": 0.558163583278656,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3218,
      "step": 228900
    },
    {
      "epoch": 9.31140341960274,
      "grad_norm": 0.562934935092926,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3207,
      "step": 229000
    },
    {
      "epoch": 9.315469534633134,
      "grad_norm": 0.5747961401939392,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.3219,
      "step": 229100
    },
    {
      "epoch": 9.319535649663528,
      "grad_norm": 0.5303084254264832,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3215,
      "step": 229200
    },
    {
      "epoch": 9.323601764693922,
      "grad_norm": 0.568591296672821,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3216,
      "step": 229300
    },
    {
      "epoch": 9.327667879724318,
      "grad_norm": 0.5680117011070251,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3207,
      "step": 229400
    },
    {
      "epoch": 9.331733994754712,
      "grad_norm": 0.564372181892395,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3216,
      "step": 229500
    },
    {
      "epoch": 9.335800109785106,
      "grad_norm": 0.5679556727409363,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.3218,
      "step": 229600
    },
    {
      "epoch": 9.3398662248155,
      "grad_norm": 0.5735393762588501,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3208,
      "step": 229700
    },
    {
      "epoch": 9.343932339845894,
      "grad_norm": 0.6329615116119385,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3226,
      "step": 229800
    },
    {
      "epoch": 9.347998454876288,
      "grad_norm": 0.6674889922142029,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3226,
      "step": 229900
    },
    {
      "epoch": 9.352064569906682,
      "grad_norm": 0.5481969714164734,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.3208,
      "step": 230000
    },
    {
      "epoch": 9.352064569906682,
      "eval_loss": 0.34208136796951294,
      "eval_runtime": 114.9538,
      "eval_samples_per_second": 1521.498,
      "eval_steps_per_second": 47.55,
      "step": 230000
    },
    {
      "epoch": 9.356130684937076,
      "grad_norm": 0.5661762356758118,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.322,
      "step": 230100
    },
    {
      "epoch": 9.36019679996747,
      "grad_norm": 0.5627914667129517,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.3233,
      "step": 230200
    },
    {
      "epoch": 9.364262914997866,
      "grad_norm": 0.5494740009307861,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.3223,
      "step": 230300
    },
    {
      "epoch": 9.36832903002826,
      "grad_norm": 0.5460007190704346,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.321,
      "step": 230400
    },
    {
      "epoch": 9.372395145058654,
      "grad_norm": 0.6530137658119202,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3219,
      "step": 230500
    },
    {
      "epoch": 9.376461260089048,
      "grad_norm": 0.6018294095993042,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3207,
      "step": 230600
    },
    {
      "epoch": 9.380527375119442,
      "grad_norm": 0.5753752589225769,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.324,
      "step": 230700
    },
    {
      "epoch": 9.384593490149836,
      "grad_norm": 0.5344887375831604,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.3232,
      "step": 230800
    },
    {
      "epoch": 9.38865960518023,
      "grad_norm": 0.5460650324821472,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.3212,
      "step": 230900
    },
    {
      "epoch": 9.392725720210624,
      "grad_norm": 0.6230508685112,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.3207,
      "step": 231000
    },
    {
      "epoch": 9.39679183524102,
      "grad_norm": 0.5826669931411743,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3226,
      "step": 231100
    },
    {
      "epoch": 9.400857950271414,
      "grad_norm": 0.5218126773834229,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3199,
      "step": 231200
    },
    {
      "epoch": 9.404924065301808,
      "grad_norm": 0.5300588607788086,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3238,
      "step": 231300
    },
    {
      "epoch": 9.408990180332202,
      "grad_norm": 0.6004026532173157,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3238,
      "step": 231400
    },
    {
      "epoch": 9.413056295362596,
      "grad_norm": 0.6100056171417236,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3219,
      "step": 231500
    },
    {
      "epoch": 9.41712241039299,
      "grad_norm": 0.551182210445404,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3222,
      "step": 231600
    },
    {
      "epoch": 9.421188525423384,
      "grad_norm": 0.5407038331031799,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.3219,
      "step": 231700
    },
    {
      "epoch": 9.425254640453778,
      "grad_norm": 0.5810732841491699,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.3226,
      "step": 231800
    },
    {
      "epoch": 9.429320755484172,
      "grad_norm": 0.6202370524406433,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3212,
      "step": 231900
    },
    {
      "epoch": 9.433386870514568,
      "grad_norm": 0.6264575123786926,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.3222,
      "step": 232000
    },
    {
      "epoch": 9.433386870514568,
      "eval_loss": 0.34153831005096436,
      "eval_runtime": 113.4696,
      "eval_samples_per_second": 1541.4,
      "eval_steps_per_second": 48.171,
      "step": 232000
    },
    {
      "epoch": 9.437452985544962,
      "grad_norm": 0.6124215722084045,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3224,
      "step": 232100
    },
    {
      "epoch": 9.441519100575356,
      "grad_norm": 0.6221628189086914,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3196,
      "step": 232200
    },
    {
      "epoch": 9.44558521560575,
      "grad_norm": 0.5687023997306824,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3218,
      "step": 232300
    },
    {
      "epoch": 9.449651330636144,
      "grad_norm": 0.5215346217155457,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.32,
      "step": 232400
    },
    {
      "epoch": 9.453717445666538,
      "grad_norm": 0.6019988059997559,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.3213,
      "step": 232500
    },
    {
      "epoch": 9.457783560696932,
      "grad_norm": 0.650492250919342,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3208,
      "step": 232600
    },
    {
      "epoch": 9.461849675727326,
      "grad_norm": 0.6358209252357483,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3207,
      "step": 232700
    },
    {
      "epoch": 9.465915790757721,
      "grad_norm": 0.6677630543708801,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.3199,
      "step": 232800
    },
    {
      "epoch": 9.469981905788115,
      "grad_norm": 0.5998205542564392,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3212,
      "step": 232900
    },
    {
      "epoch": 9.47404802081851,
      "grad_norm": 0.5718259215354919,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3218,
      "step": 233000
    },
    {
      "epoch": 9.478114135848903,
      "grad_norm": 0.5275886058807373,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.3219,
      "step": 233100
    },
    {
      "epoch": 9.482180250879297,
      "grad_norm": 0.5590533018112183,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.3213,
      "step": 233200
    },
    {
      "epoch": 9.486246365909691,
      "grad_norm": 0.630616307258606,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.3198,
      "step": 233300
    },
    {
      "epoch": 9.490312480940085,
      "grad_norm": 0.5787443518638611,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3212,
      "step": 233400
    },
    {
      "epoch": 9.49437859597048,
      "grad_norm": 0.5793952941894531,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3208,
      "step": 233500
    },
    {
      "epoch": 9.498444711000873,
      "grad_norm": 0.6815775632858276,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3214,
      "step": 233600
    },
    {
      "epoch": 9.50251082603127,
      "grad_norm": 0.639225423336029,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.3206,
      "step": 233700
    },
    {
      "epoch": 9.506576941061663,
      "grad_norm": 0.6063714623451233,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3203,
      "step": 233800
    },
    {
      "epoch": 9.510643056092057,
      "grad_norm": 0.6185179948806763,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3214,
      "step": 233900
    },
    {
      "epoch": 9.514709171122451,
      "grad_norm": 0.6102057695388794,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.3203,
      "step": 234000
    },
    {
      "epoch": 9.514709171122451,
      "eval_loss": 0.34093090891838074,
      "eval_runtime": 116.1053,
      "eval_samples_per_second": 1506.409,
      "eval_steps_per_second": 47.078,
      "step": 234000
    },
    {
      "epoch": 9.518775286152845,
      "grad_norm": 0.5509513020515442,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.3196,
      "step": 234100
    },
    {
      "epoch": 9.52284140118324,
      "grad_norm": 0.6172807216644287,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.3216,
      "step": 234200
    },
    {
      "epoch": 9.526907516213633,
      "grad_norm": 0.570794403553009,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3197,
      "step": 234300
    },
    {
      "epoch": 9.530973631244027,
      "grad_norm": 0.5980387926101685,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3199,
      "step": 234400
    },
    {
      "epoch": 9.535039746274421,
      "grad_norm": 0.5382639169692993,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3219,
      "step": 234500
    },
    {
      "epoch": 9.539105861304817,
      "grad_norm": 0.5982204675674438,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3223,
      "step": 234600
    },
    {
      "epoch": 9.543171976335211,
      "grad_norm": 0.590280294418335,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3216,
      "step": 234700
    },
    {
      "epoch": 9.547238091365605,
      "grad_norm": 0.5881667733192444,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.318,
      "step": 234800
    },
    {
      "epoch": 9.551304206395999,
      "grad_norm": 0.6202654242515564,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.323,
      "step": 234900
    },
    {
      "epoch": 9.555370321426393,
      "grad_norm": 0.5309077501296997,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.3201,
      "step": 235000
    },
    {
      "epoch": 9.559436436456787,
      "grad_norm": 0.57015061378479,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3187,
      "step": 235100
    },
    {
      "epoch": 9.563502551487181,
      "grad_norm": 0.6221541166305542,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3195,
      "step": 235200
    },
    {
      "epoch": 9.567568666517575,
      "grad_norm": 0.6048243641853333,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3205,
      "step": 235300
    },
    {
      "epoch": 9.57163478154797,
      "grad_norm": 0.6412408351898193,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3216,
      "step": 235400
    },
    {
      "epoch": 9.575700896578365,
      "grad_norm": 0.6056469678878784,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.3205,
      "step": 235500
    },
    {
      "epoch": 9.579767011608759,
      "grad_norm": 0.5496545433998108,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3221,
      "step": 235600
    },
    {
      "epoch": 9.583833126639153,
      "grad_norm": 0.6410097479820251,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.321,
      "step": 235700
    },
    {
      "epoch": 9.587899241669547,
      "grad_norm": 0.5876380205154419,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.3221,
      "step": 235800
    },
    {
      "epoch": 9.59196535669994,
      "grad_norm": 0.588086724281311,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.32,
      "step": 235900
    },
    {
      "epoch": 9.596031471730335,
      "grad_norm": 0.6076818108558655,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.3196,
      "step": 236000
    },
    {
      "epoch": 9.596031471730335,
      "eval_loss": 0.3402647376060486,
      "eval_runtime": 114.4109,
      "eval_samples_per_second": 1528.718,
      "eval_steps_per_second": 47.775,
      "step": 236000
    },
    {
      "epoch": 9.600097586760729,
      "grad_norm": 0.6174798607826233,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3205,
      "step": 236100
    },
    {
      "epoch": 9.604163701791123,
      "grad_norm": 0.6199722290039062,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3189,
      "step": 236200
    },
    {
      "epoch": 9.608229816821519,
      "grad_norm": 0.6111768484115601,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.3199,
      "step": 236300
    },
    {
      "epoch": 9.612295931851913,
      "grad_norm": 0.6877264976501465,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3222,
      "step": 236400
    },
    {
      "epoch": 9.616362046882307,
      "grad_norm": 0.5772040486335754,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.3203,
      "step": 236500
    },
    {
      "epoch": 9.6204281619127,
      "grad_norm": 0.6945359706878662,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3194,
      "step": 236600
    },
    {
      "epoch": 9.624494276943095,
      "grad_norm": 0.6137568354606628,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3196,
      "step": 236700
    },
    {
      "epoch": 9.628560391973489,
      "grad_norm": 0.6199758052825928,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.319,
      "step": 236800
    },
    {
      "epoch": 9.632626507003883,
      "grad_norm": 0.637482762336731,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3193,
      "step": 236900
    },
    {
      "epoch": 9.636692622034277,
      "grad_norm": 0.5293148756027222,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.3211,
      "step": 237000
    },
    {
      "epoch": 9.640758737064672,
      "grad_norm": 0.6085631251335144,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3195,
      "step": 237100
    },
    {
      "epoch": 9.644824852095066,
      "grad_norm": 0.5812593698501587,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.319,
      "step": 237200
    },
    {
      "epoch": 9.64889096712546,
      "grad_norm": 0.6508277058601379,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3206,
      "step": 237300
    },
    {
      "epoch": 9.652957082155854,
      "grad_norm": 0.6480844616889954,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.32,
      "step": 237400
    },
    {
      "epoch": 9.657023197186248,
      "grad_norm": 0.547767698764801,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.3208,
      "step": 237500
    },
    {
      "epoch": 9.661089312216642,
      "grad_norm": 0.6375157237052917,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3217,
      "step": 237600
    },
    {
      "epoch": 9.665155427247036,
      "grad_norm": 0.6773266792297363,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.3209,
      "step": 237700
    },
    {
      "epoch": 9.66922154227743,
      "grad_norm": 0.6447089910507202,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.3208,
      "step": 237800
    },
    {
      "epoch": 9.673287657307824,
      "grad_norm": 0.6196219325065613,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3215,
      "step": 237900
    },
    {
      "epoch": 9.67735377233822,
      "grad_norm": 0.5959182381629944,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3198,
      "step": 238000
    },
    {
      "epoch": 9.67735377233822,
      "eval_loss": 0.33974695205688477,
      "eval_runtime": 115.6505,
      "eval_samples_per_second": 1512.333,
      "eval_steps_per_second": 47.263,
      "step": 238000
    },
    {
      "epoch": 9.681419887368614,
      "grad_norm": 0.5738450288772583,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.32,
      "step": 238100
    },
    {
      "epoch": 9.685486002399008,
      "grad_norm": 0.5425533056259155,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3187,
      "step": 238200
    },
    {
      "epoch": 9.689552117429402,
      "grad_norm": 0.6157065033912659,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3182,
      "step": 238300
    },
    {
      "epoch": 9.693618232459796,
      "grad_norm": 0.6020839214324951,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.3209,
      "step": 238400
    },
    {
      "epoch": 9.69768434749019,
      "grad_norm": 0.5821365118026733,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3188,
      "step": 238500
    },
    {
      "epoch": 9.701750462520584,
      "grad_norm": 0.6027969717979431,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.3205,
      "step": 238600
    },
    {
      "epoch": 9.705816577550978,
      "grad_norm": 0.6058735847473145,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3194,
      "step": 238700
    },
    {
      "epoch": 9.709882692581374,
      "grad_norm": 0.5955514907836914,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3193,
      "step": 238800
    },
    {
      "epoch": 9.713948807611768,
      "grad_norm": 0.5694769024848938,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3178,
      "step": 238900
    },
    {
      "epoch": 9.718014922642162,
      "grad_norm": 0.6094651818275452,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.3187,
      "step": 239000
    },
    {
      "epoch": 9.722081037672556,
      "grad_norm": 0.6180406808853149,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.319,
      "step": 239100
    },
    {
      "epoch": 9.72614715270295,
      "grad_norm": 0.5974807739257812,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3172,
      "step": 239200
    },
    {
      "epoch": 9.730213267733344,
      "grad_norm": 0.6134299635887146,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3195,
      "step": 239300
    },
    {
      "epoch": 9.734279382763738,
      "grad_norm": 0.6509073972702026,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.3197,
      "step": 239400
    },
    {
      "epoch": 9.738345497794132,
      "grad_norm": 0.5894322991371155,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3189,
      "step": 239500
    },
    {
      "epoch": 9.742411612824526,
      "grad_norm": 0.5996589064598083,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3198,
      "step": 239600
    },
    {
      "epoch": 9.746477727854922,
      "grad_norm": 0.517117977142334,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3189,
      "step": 239700
    },
    {
      "epoch": 9.750543842885316,
      "grad_norm": 0.659879744052887,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3198,
      "step": 239800
    },
    {
      "epoch": 9.75460995791571,
      "grad_norm": 0.5434019565582275,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.3176,
      "step": 239900
    },
    {
      "epoch": 9.758676072946104,
      "grad_norm": 0.5985574126243591,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3185,
      "step": 240000
    },
    {
      "epoch": 9.758676072946104,
      "eval_loss": 0.3390839397907257,
      "eval_runtime": 113.3421,
      "eval_samples_per_second": 1543.133,
      "eval_steps_per_second": 48.226,
      "step": 240000
    },
    {
      "epoch": 9.762742187976498,
      "grad_norm": 0.627892792224884,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.3199,
      "step": 240100
    },
    {
      "epoch": 9.766808303006892,
      "grad_norm": 0.6423552632331848,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.3199,
      "step": 240200
    },
    {
      "epoch": 9.770874418037286,
      "grad_norm": 0.6264569759368896,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.3213,
      "step": 240300
    },
    {
      "epoch": 9.77494053306768,
      "grad_norm": 0.6301575899124146,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.3184,
      "step": 240400
    },
    {
      "epoch": 9.779006648098076,
      "grad_norm": 0.6689466834068298,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.318,
      "step": 240500
    },
    {
      "epoch": 9.78307276312847,
      "grad_norm": 0.628376305103302,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3186,
      "step": 240600
    },
    {
      "epoch": 9.787138878158864,
      "grad_norm": 0.6546834111213684,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3196,
      "step": 240700
    },
    {
      "epoch": 9.791204993189258,
      "grad_norm": 0.5880551338195801,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3197,
      "step": 240800
    },
    {
      "epoch": 9.795271108219652,
      "grad_norm": 0.6521701216697693,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.3181,
      "step": 240900
    },
    {
      "epoch": 9.799337223250046,
      "grad_norm": 0.5778535008430481,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3188,
      "step": 241000
    },
    {
      "epoch": 9.80340333828044,
      "grad_norm": 0.6432666182518005,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3203,
      "step": 241100
    },
    {
      "epoch": 9.807469453310834,
      "grad_norm": 0.6106082201004028,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3188,
      "step": 241200
    },
    {
      "epoch": 9.811535568341228,
      "grad_norm": 0.6113417744636536,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.3209,
      "step": 241300
    },
    {
      "epoch": 9.815601683371623,
      "grad_norm": 0.6155768632888794,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.321,
      "step": 241400
    },
    {
      "epoch": 9.819667798402017,
      "grad_norm": 0.6487017869949341,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3178,
      "step": 241500
    },
    {
      "epoch": 9.823733913432411,
      "grad_norm": 0.5995577573776245,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.3198,
      "step": 241600
    },
    {
      "epoch": 9.827800028462805,
      "grad_norm": 0.5728811621665955,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3187,
      "step": 241700
    },
    {
      "epoch": 9.8318661434932,
      "grad_norm": 0.6181831359863281,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3173,
      "step": 241800
    },
    {
      "epoch": 9.835932258523593,
      "grad_norm": 0.6365871429443359,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.3169,
      "step": 241900
    },
    {
      "epoch": 9.839998373553987,
      "grad_norm": 0.5633066296577454,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3163,
      "step": 242000
    },
    {
      "epoch": 9.839998373553987,
      "eval_loss": 0.3385098874568939,
      "eval_runtime": 116.467,
      "eval_samples_per_second": 1501.73,
      "eval_steps_per_second": 46.932,
      "step": 242000
    },
    {
      "epoch": 9.844064488584381,
      "grad_norm": 0.5842506885528564,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3176,
      "step": 242100
    },
    {
      "epoch": 9.848130603614777,
      "grad_norm": 0.5702678561210632,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3205,
      "step": 242200
    },
    {
      "epoch": 9.852196718645171,
      "grad_norm": 0.5663641095161438,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.3191,
      "step": 242300
    },
    {
      "epoch": 9.856262833675565,
      "grad_norm": 0.6087449193000793,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.3183,
      "step": 242400
    },
    {
      "epoch": 9.860328948705959,
      "grad_norm": 0.6295434236526489,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.3181,
      "step": 242500
    },
    {
      "epoch": 9.864395063736353,
      "grad_norm": 0.6040306091308594,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3193,
      "step": 242600
    },
    {
      "epoch": 9.868461178766747,
      "grad_norm": 0.6400340795516968,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3178,
      "step": 242700
    },
    {
      "epoch": 9.872527293797141,
      "grad_norm": 0.6301876902580261,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3194,
      "step": 242800
    },
    {
      "epoch": 9.876593408827535,
      "grad_norm": 0.5561107397079468,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.3175,
      "step": 242900
    },
    {
      "epoch": 9.88065952385793,
      "grad_norm": 0.6344679594039917,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3171,
      "step": 243000
    },
    {
      "epoch": 9.884725638888325,
      "grad_norm": 0.6530554294586182,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.3176,
      "step": 243100
    },
    {
      "epoch": 9.888791753918719,
      "grad_norm": 0.5670358538627625,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.3181,
      "step": 243200
    },
    {
      "epoch": 9.892857868949113,
      "grad_norm": 0.6022915840148926,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3199,
      "step": 243300
    },
    {
      "epoch": 9.896923983979507,
      "grad_norm": 0.573248028755188,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3177,
      "step": 243400
    },
    {
      "epoch": 9.900990099009901,
      "grad_norm": 0.6672959923744202,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.318,
      "step": 243500
    },
    {
      "epoch": 9.905056214040295,
      "grad_norm": 0.5954417586326599,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.318,
      "step": 243600
    },
    {
      "epoch": 9.909122329070689,
      "grad_norm": 0.5814417004585266,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3174,
      "step": 243700
    },
    {
      "epoch": 9.913188444101083,
      "grad_norm": 0.788123369216919,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3174,
      "step": 243800
    },
    {
      "epoch": 9.917254559131479,
      "grad_norm": 0.6395183205604553,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3171,
      "step": 243900
    },
    {
      "epoch": 9.921320674161873,
      "grad_norm": 0.7187450528144836,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3167,
      "step": 244000
    },
    {
      "epoch": 9.921320674161873,
      "eval_loss": 0.338022381067276,
      "eval_runtime": 112.6346,
      "eval_samples_per_second": 1552.826,
      "eval_steps_per_second": 48.529,
      "step": 244000
    },
    {
      "epoch": 9.925386789192267,
      "grad_norm": 0.5678550601005554,
      "learning_rate": 4.049926968530075e-06,
      "loss": 0.3184,
      "step": 244100
    },
    {
      "epoch": 9.92945290422266,
      "grad_norm": 0.6077285408973694,
      "learning_rate": 3.8286194839109455e-06,
      "loss": 0.3183,
      "step": 244200
    },
    {
      "epoch": 9.933519019253055,
      "grad_norm": 0.6520390510559082,
      "learning_rate": 3.607311999291816e-06,
      "loss": 0.3178,
      "step": 244300
    },
    {
      "epoch": 9.937585134283449,
      "grad_norm": 0.6017028093338013,
      "learning_rate": 3.3860045146726864e-06,
      "loss": 0.3195,
      "step": 244400
    },
    {
      "epoch": 9.941651249313843,
      "grad_norm": 0.6157605648040771,
      "learning_rate": 3.1646970300535566e-06,
      "loss": 0.3195,
      "step": 244500
    },
    {
      "epoch": 9.945717364344237,
      "grad_norm": 0.5772256255149841,
      "learning_rate": 2.943389545434427e-06,
      "loss": 0.3162,
      "step": 244600
    },
    {
      "epoch": 9.94978347937463,
      "grad_norm": 0.6505815982818604,
      "learning_rate": 2.7220820608152966e-06,
      "loss": 0.3171,
      "step": 244700
    },
    {
      "epoch": 9.953849594405026,
      "grad_norm": 0.5842097401618958,
      "learning_rate": 2.5007745761961673e-06,
      "loss": 0.3189,
      "step": 244800
    },
    {
      "epoch": 9.95791570943542,
      "grad_norm": 0.6236952543258667,
      "learning_rate": 2.279467091577037e-06,
      "loss": 0.3173,
      "step": 244900
    },
    {
      "epoch": 9.961981824465814,
      "grad_norm": 0.6631197333335876,
      "learning_rate": 2.0581596069579077e-06,
      "loss": 0.3179,
      "step": 245000
    },
    {
      "epoch": 9.966047939496208,
      "grad_norm": 0.6576110124588013,
      "learning_rate": 1.8368521223387775e-06,
      "loss": 0.3176,
      "step": 245100
    },
    {
      "epoch": 9.970114054526602,
      "grad_norm": 0.6312286853790283,
      "learning_rate": 1.6155446377196477e-06,
      "loss": 0.3188,
      "step": 245200
    },
    {
      "epoch": 9.974180169556996,
      "grad_norm": 0.6673591136932373,
      "learning_rate": 1.394237153100518e-06,
      "loss": 0.319,
      "step": 245300
    },
    {
      "epoch": 9.97824628458739,
      "grad_norm": 0.6660640835762024,
      "learning_rate": 1.172929668481388e-06,
      "loss": 0.3184,
      "step": 245400
    },
    {
      "epoch": 9.982312399617784,
      "grad_norm": 0.6377920508384705,
      "learning_rate": 9.516221838622583e-07,
      "loss": 0.3159,
      "step": 245500
    },
    {
      "epoch": 9.98637851464818,
      "grad_norm": 0.5950188636779785,
      "learning_rate": 7.303146992431284e-07,
      "loss": 0.3181,
      "step": 245600
    },
    {
      "epoch": 9.990444629678574,
      "grad_norm": 0.6207943558692932,
      "learning_rate": 5.090072146239986e-07,
      "loss": 0.3171,
      "step": 245700
    },
    {
      "epoch": 9.994510744708968,
      "grad_norm": 0.5868164300918579,
      "learning_rate": 2.876997300048688e-07,
      "loss": 0.3168,
      "step": 245800
    },
    {
      "epoch": 9.998576859739362,
      "grad_norm": 0.6037117838859558,
      "learning_rate": 6.639224538573895e-08,
      "loss": 0.3187,
      "step": 245900
    },
    {
      "epoch": 9.99979669424848,
      "step": 245930,
      "total_flos": 0.0,
      "train_loss": 0.3655714443485836,
      "train_runtime": 40417.9753,
      "train_samples_per_second": 389.426,
      "train_steps_per_second": 6.085
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
