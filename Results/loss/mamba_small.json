{
  "best_metric": 0.33303168416023254,
  "best_model_checkpoint": "/scratch/lmbanr001/SSM_20M_little_dropout/checkpoint-244000",
  "epoch": 9.99979669424848,
  "eval_steps": 2000,
  "global_step": 245930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 20.148107528686523,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.7939,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 10.745707511901855,
      "learning_rate": 2.5e-06,
      "loss": 6.8568,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 2.6882011890411377,
      "learning_rate": 5e-06,
      "loss": 3.3725,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 1.743302583694458,
      "learning_rate": 7.5e-06,
      "loss": 1.6827,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 2.473194122314453,
      "learning_rate": 1e-05,
      "loss": 1.2138,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 2.330338716506958,
      "learning_rate": 1.25e-05,
      "loss": 1.037,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 3.0660300254821777,
      "learning_rate": 1.5e-05,
      "loss": 0.9275,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 3.076815605163574,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.8643,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 2.2557713985443115,
      "learning_rate": 2e-05,
      "loss": 0.8139,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 2.7602486610412598,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.7741,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 3.0668160915374756,
      "learning_rate": 2.5e-05,
      "loss": 0.7482,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 2.9060890674591064,
      "learning_rate": 2.75e-05,
      "loss": 0.7152,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 3.011538028717041,
      "learning_rate": 3e-05,
      "loss": 0.6867,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 2.590341567993164,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.6638,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 3.1233229637145996,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.6414,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 2.6470508575439453,
      "learning_rate": 3.75e-05,
      "loss": 0.6278,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 2.288689136505127,
      "learning_rate": 4e-05,
      "loss": 0.6146,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 2.8817291259765625,
      "learning_rate": 4.25e-05,
      "loss": 0.6025,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 2.4728827476501465,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.5881,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 3.8963170051574707,
      "learning_rate": 4.75e-05,
      "loss": 0.5743,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 2.27463698387146,
      "learning_rate": 5e-05,
      "loss": 0.5668,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.5662501454353333,
      "eval_runtime": 128.2654,
      "eval_samples_per_second": 1363.594,
      "eval_steps_per_second": 42.615,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 2.694491386413574,
      "learning_rate": 5.25e-05,
      "loss": 0.559,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 2.6851768493652344,
      "learning_rate": 5.5e-05,
      "loss": 0.5519,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 2.770070791244507,
      "learning_rate": 5.75e-05,
      "loss": 0.5426,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 2.1497585773468018,
      "learning_rate": 6e-05,
      "loss": 0.5391,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 2.2294013500213623,
      "learning_rate": 6.25e-05,
      "loss": 0.5324,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 1.7778452634811401,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.5254,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 2.307335615158081,
      "learning_rate": 6.75e-05,
      "loss": 0.5179,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 2.048177480697632,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.5153,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 1.8078279495239258,
      "learning_rate": 7.25e-05,
      "loss": 0.5104,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 2.655454158782959,
      "learning_rate": 7.5e-05,
      "loss": 0.5072,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 1.784195899963379,
      "learning_rate": 7.75e-05,
      "loss": 0.5046,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 1.7012428045272827,
      "learning_rate": 8e-05,
      "loss": 0.5007,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 2.189152956008911,
      "learning_rate": 8.25e-05,
      "loss": 0.4951,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 1.871216058731079,
      "learning_rate": 8.5e-05,
      "loss": 0.4908,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 1.4764865636825562,
      "learning_rate": 8.75e-05,
      "loss": 0.4928,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 1.3756862878799438,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.4863,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 1.5512586832046509,
      "learning_rate": 9.25e-05,
      "loss": 0.4827,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 1.4638348817825317,
      "learning_rate": 9.5e-05,
      "loss": 0.4792,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 1.366010308265686,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.4792,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 1.3581585884094238,
      "learning_rate": 0.0001,
      "loss": 0.4757,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.4845903515815735,
      "eval_runtime": 127.5932,
      "eval_samples_per_second": 1370.779,
      "eval_steps_per_second": 42.839,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 1.2038344144821167,
      "learning_rate": 0.0001025,
      "loss": 0.4718,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 1.2851535081863403,
      "learning_rate": 0.000105,
      "loss": 0.4709,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 1.360494613647461,
      "learning_rate": 0.0001075,
      "loss": 0.4704,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 1.1572504043579102,
      "learning_rate": 0.00011,
      "loss": 0.4673,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 1.1887558698654175,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.4664,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 1.0697282552719116,
      "learning_rate": 0.000115,
      "loss": 0.4619,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 1.0288609266281128,
      "learning_rate": 0.0001175,
      "loss": 0.4594,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 1.1036756038665771,
      "learning_rate": 0.00012,
      "loss": 0.4604,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 0.9932342767715454,
      "learning_rate": 0.0001225,
      "loss": 0.4591,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.9003431797027588,
      "learning_rate": 0.000125,
      "loss": 0.4588,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 1.077178716659546,
      "learning_rate": 0.0001275,
      "loss": 0.4556,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 1.0004884004592896,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.4536,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 0.9369518756866455,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.4495,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.8516722321510315,
      "learning_rate": 0.000135,
      "loss": 0.4494,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.8391764760017395,
      "learning_rate": 0.0001375,
      "loss": 0.4506,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.8828625082969666,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4481,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.9156238436698914,
      "learning_rate": 0.0001425,
      "loss": 0.4475,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.815686047077179,
      "learning_rate": 0.000145,
      "loss": 0.4478,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.8414824604988098,
      "learning_rate": 0.0001475,
      "loss": 0.4428,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.8032627105712891,
      "learning_rate": 0.00015,
      "loss": 0.4438,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.45034924149513245,
      "eval_runtime": 128.3268,
      "eval_samples_per_second": 1362.942,
      "eval_steps_per_second": 42.594,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 0.9153229594230652,
      "learning_rate": 0.0001525,
      "loss": 0.4417,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.8642535209655762,
      "learning_rate": 0.000155,
      "loss": 0.4437,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.7590948343276978,
      "learning_rate": 0.0001575,
      "loss": 0.4393,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 0.8186560273170471,
      "learning_rate": 0.00016,
      "loss": 0.4404,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.6985359787940979,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.4401,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.682876706123352,
      "learning_rate": 0.000165,
      "loss": 0.4417,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.6880430579185486,
      "learning_rate": 0.0001675,
      "loss": 0.4344,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.7641327977180481,
      "learning_rate": 0.00017,
      "loss": 0.4339,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.7183297872543335,
      "learning_rate": 0.0001725,
      "loss": 0.4345,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.6784125566482544,
      "learning_rate": 0.000175,
      "loss": 0.4353,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.6981005072593689,
      "learning_rate": 0.0001775,
      "loss": 0.4354,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.7113904356956482,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4338,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6716073751449585,
      "learning_rate": 0.0001825,
      "loss": 0.4315,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.6432834267616272,
      "learning_rate": 0.000185,
      "loss": 0.4334,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.6342195868492126,
      "learning_rate": 0.0001875,
      "loss": 0.4297,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.6242103576660156,
      "learning_rate": 0.00019,
      "loss": 0.4301,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.5983924269676208,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4282,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.6189877986907959,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.428,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.6788188219070435,
      "learning_rate": 0.0001975,
      "loss": 0.4296,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.6451650261878967,
      "learning_rate": 0.0002,
      "loss": 0.43,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.43703004717826843,
      "eval_runtime": 127.7717,
      "eval_samples_per_second": 1368.863,
      "eval_steps_per_second": 42.779,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.687504231929779,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4302,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.614637553691864,
      "learning_rate": 0.000205,
      "loss": 0.431,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.6516600251197815,
      "learning_rate": 0.0002075,
      "loss": 0.4264,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.6155157089233398,
      "learning_rate": 0.00021,
      "loss": 0.4267,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.5717310905456543,
      "learning_rate": 0.0002125,
      "loss": 0.4241,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.6067683100700378,
      "learning_rate": 0.000215,
      "loss": 0.4235,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.5835137367248535,
      "learning_rate": 0.0002175,
      "loss": 0.4244,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.6227883100509644,
      "learning_rate": 0.00022,
      "loss": 0.4238,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.5542848110198975,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4226,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.6659951210021973,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.4208,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.5891121029853821,
      "learning_rate": 0.0002275,
      "loss": 0.4238,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.48979833722114563,
      "learning_rate": 0.00023,
      "loss": 0.4227,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.5041999220848083,
      "learning_rate": 0.0002325,
      "loss": 0.4224,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.5409729480743408,
      "learning_rate": 0.000235,
      "loss": 0.421,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.5442303419113159,
      "learning_rate": 0.0002375,
      "loss": 0.4179,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.5089928507804871,
      "learning_rate": 0.00024,
      "loss": 0.4203,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.566397488117218,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4179,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.5158553719520569,
      "learning_rate": 0.000245,
      "loss": 0.4176,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.5127894878387451,
      "learning_rate": 0.0002475,
      "loss": 0.4216,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.4810131788253784,
      "learning_rate": 0.00025,
      "loss": 0.4201,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.42769232392311096,
      "eval_runtime": 127.5933,
      "eval_samples_per_second": 1370.778,
      "eval_steps_per_second": 42.839,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.49476757645606995,
      "learning_rate": 0.0002525,
      "loss": 0.4192,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.46896520256996155,
      "learning_rate": 0.000255,
      "loss": 0.4214,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.5133504271507263,
      "learning_rate": 0.0002575,
      "loss": 0.4213,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.4863104522228241,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4172,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.4296129047870636,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4174,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.4673713147640228,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4182,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.5180169939994812,
      "learning_rate": 0.0002675,
      "loss": 0.4171,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.473730206489563,
      "learning_rate": 0.00027,
      "loss": 0.4163,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.4105440378189087,
      "learning_rate": 0.0002725,
      "loss": 0.4167,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.44013556838035583,
      "learning_rate": 0.000275,
      "loss": 0.4174,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.4338752329349518,
      "learning_rate": 0.0002775,
      "loss": 0.4132,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.40242800116539,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4184,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.4544924795627594,
      "learning_rate": 0.0002825,
      "loss": 0.4169,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.41062334179878235,
      "learning_rate": 0.000285,
      "loss": 0.4135,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.4302169978618622,
      "learning_rate": 0.0002875,
      "loss": 0.415,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.40651267766952515,
      "learning_rate": 0.00029,
      "loss": 0.4113,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.46576327085494995,
      "learning_rate": 0.0002925,
      "loss": 0.413,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.4515947997570038,
      "learning_rate": 0.000295,
      "loss": 0.4125,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.4475499093532562,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4121,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.39682668447494507,
      "learning_rate": 0.0003,
      "loss": 0.4117,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.42247724533081055,
      "eval_runtime": 128.4254,
      "eval_samples_per_second": 1361.895,
      "eval_steps_per_second": 42.562,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.4079892039299011,
      "learning_rate": 0.0003025,
      "loss": 0.4126,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.3714994490146637,
      "learning_rate": 0.000305,
      "loss": 0.4084,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.38495996594429016,
      "learning_rate": 0.0003075,
      "loss": 0.413,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.3864521086215973,
      "learning_rate": 0.00031,
      "loss": 0.4123,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.4287468194961548,
      "learning_rate": 0.0003125,
      "loss": 0.4128,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.41169071197509766,
      "learning_rate": 0.000315,
      "loss": 0.4114,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.37177619338035583,
      "learning_rate": 0.0003175,
      "loss": 0.4105,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.3789044916629791,
      "learning_rate": 0.00032,
      "loss": 0.4122,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.3886801600456238,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4118,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.4554375112056732,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4112,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.4088115692138672,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4108,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.3988354206085205,
      "learning_rate": 0.00033,
      "loss": 0.4094,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.35223984718322754,
      "learning_rate": 0.0003325,
      "loss": 0.4084,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.3701562285423279,
      "learning_rate": 0.000335,
      "loss": 0.4106,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.37816402316093445,
      "learning_rate": 0.0003375,
      "loss": 0.4087,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.33429810404777527,
      "learning_rate": 0.00034,
      "loss": 0.4085,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.33960697054862976,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.4098,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.3532212972640991,
      "learning_rate": 0.000345,
      "loss": 0.4098,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.35113635659217834,
      "learning_rate": 0.0003475,
      "loss": 0.4094,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.3354688286781311,
      "learning_rate": 0.00035,
      "loss": 0.4112,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.4178485870361328,
      "eval_runtime": 128.1442,
      "eval_samples_per_second": 1364.884,
      "eval_steps_per_second": 42.655,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.3619513511657715,
      "learning_rate": 0.0003525,
      "loss": 0.4104,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.36713719367980957,
      "learning_rate": 0.000355,
      "loss": 0.4094,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.2829880118370056,
      "learning_rate": 0.0003575,
      "loss": 0.4081,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.3215958774089813,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4089,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.323804646730423,
      "learning_rate": 0.0003625,
      "loss": 0.4072,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.3829142451286316,
      "learning_rate": 0.000365,
      "loss": 0.4085,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.3747681975364685,
      "learning_rate": 0.0003675,
      "loss": 0.4089,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.3211413621902466,
      "learning_rate": 0.00037,
      "loss": 0.4056,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.3246191442012787,
      "learning_rate": 0.0003725,
      "loss": 0.405,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.3019808828830719,
      "learning_rate": 0.000375,
      "loss": 0.4073,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.32854804396629333,
      "learning_rate": 0.0003775,
      "loss": 0.405,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.3259241580963135,
      "learning_rate": 0.00038,
      "loss": 0.4058,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.35623645782470703,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4084,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.3266441226005554,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4046,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.3051733672618866,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4049,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.3208968937397003,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4047,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.353022038936615,
      "learning_rate": 0.0003925,
      "loss": 0.4027,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.2860640585422516,
      "learning_rate": 0.000395,
      "loss": 0.405,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.31235194206237793,
      "learning_rate": 0.0003975,
      "loss": 0.4048,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.34121859073638916,
      "learning_rate": 0.0004,
      "loss": 0.4038,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.4152246117591858,
      "eval_runtime": 128.1206,
      "eval_samples_per_second": 1365.136,
      "eval_steps_per_second": 42.663,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.2825157642364502,
      "learning_rate": 0.0004025,
      "loss": 0.4067,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.257425993680954,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4057,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.3052492141723633,
      "learning_rate": 0.0004075,
      "loss": 0.4058,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.29256877303123474,
      "learning_rate": 0.00041,
      "loss": 0.4051,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.2617708444595337,
      "learning_rate": 0.0004125,
      "loss": 0.4051,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.2921912670135498,
      "learning_rate": 0.000415,
      "loss": 0.4042,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.29396605491638184,
      "learning_rate": 0.0004175,
      "loss": 0.4039,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.2666808068752289,
      "learning_rate": 0.00042,
      "loss": 0.4038,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.263476699590683,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4036,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.28925621509552,
      "learning_rate": 0.000425,
      "loss": 0.4031,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.2637810707092285,
      "learning_rate": 0.0004275,
      "loss": 0.4049,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.29627665877342224,
      "learning_rate": 0.00043,
      "loss": 0.4052,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.2950856685638428,
      "learning_rate": 0.0004325,
      "loss": 0.4045,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.28676825761795044,
      "learning_rate": 0.000435,
      "loss": 0.4034,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.29473328590393066,
      "learning_rate": 0.0004375,
      "loss": 0.4011,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.28707239031791687,
      "learning_rate": 0.00044,
      "loss": 0.4032,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.27066338062286377,
      "learning_rate": 0.0004425,
      "loss": 0.4001,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.2802712917327881,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4038,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.28655338287353516,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4022,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.2798442840576172,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4012,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.4103682339191437,
      "eval_runtime": 127.8235,
      "eval_samples_per_second": 1368.309,
      "eval_steps_per_second": 42.762,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.27841243147850037,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4005,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.25380632281303406,
      "learning_rate": 0.000455,
      "loss": 0.4026,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.2267945408821106,
      "learning_rate": 0.0004575,
      "loss": 0.4006,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.25612515211105347,
      "learning_rate": 0.00046,
      "loss": 0.4025,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.23758424818515778,
      "learning_rate": 0.0004625,
      "loss": 0.3995,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.25380784273147583,
      "learning_rate": 0.000465,
      "loss": 0.4006,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.26471370458602905,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4021,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.23814404010772705,
      "learning_rate": 0.00047,
      "loss": 0.4021,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.27048978209495544,
      "learning_rate": 0.0004725,
      "loss": 0.4003,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.2604040205478668,
      "learning_rate": 0.000475,
      "loss": 0.3984,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.23643194139003754,
      "learning_rate": 0.0004775,
      "loss": 0.4001,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.3036671578884125,
      "learning_rate": 0.00048,
      "loss": 0.4003,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.23844346404075623,
      "learning_rate": 0.0004825,
      "loss": 0.4021,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.2555045485496521,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.4014,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.23769859969615936,
      "learning_rate": 0.0004875,
      "loss": 0.3976,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.26888468861579895,
      "learning_rate": 0.00049,
      "loss": 0.3994,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.2710023522377014,
      "learning_rate": 0.0004925,
      "loss": 0.3973,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.24903295934200287,
      "learning_rate": 0.000495,
      "loss": 0.3997,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.2515420913696289,
      "learning_rate": 0.0004975,
      "loss": 0.3994,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.24606788158416748,
      "learning_rate": 0.0005,
      "loss": 0.3996,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.4084397554397583,
      "eval_runtime": 127.8731,
      "eval_samples_per_second": 1367.778,
      "eval_steps_per_second": 42.746,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.23193001747131348,
      "learning_rate": 0.0004997786925153809,
      "loss": 0.3998,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.2441045343875885,
      "learning_rate": 0.0004995573850307618,
      "loss": 0.4005,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.2302526831626892,
      "learning_rate": 0.0004993360775461426,
      "loss": 0.3955,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.20205581188201904,
      "learning_rate": 0.0004991147700615235,
      "loss": 0.3977,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.24443717300891876,
      "learning_rate": 0.0004988934625769043,
      "loss": 0.397,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.21676939725875854,
      "learning_rate": 0.0004986721550922853,
      "loss": 0.3964,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.22261087596416473,
      "learning_rate": 0.0004984508476076661,
      "loss": 0.3987,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.21132944524288177,
      "learning_rate": 0.000498229540123047,
      "loss": 0.3989,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.22930951416492462,
      "learning_rate": 0.0004980082326384278,
      "loss": 0.397,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.19940753281116486,
      "learning_rate": 0.0004977869251538087,
      "loss": 0.3958,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.2312743216753006,
      "learning_rate": 0.0004975656176691896,
      "loss": 0.3957,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.2256244570016861,
      "learning_rate": 0.0004973443101845705,
      "loss": 0.3945,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.20705293118953705,
      "learning_rate": 0.0004971230026999513,
      "loss": 0.3929,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.22585506737232208,
      "learning_rate": 0.0004969016952153321,
      "loss": 0.3966,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.23688872158527374,
      "learning_rate": 0.0004966803877307131,
      "loss": 0.3949,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.2168969213962555,
      "learning_rate": 0.0004964590802460939,
      "loss": 0.3953,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.22501732409000397,
      "learning_rate": 0.0004962377727614748,
      "loss": 0.3939,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.20069263875484467,
      "learning_rate": 0.0004960164652768557,
      "loss": 0.3931,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.2263277918100357,
      "learning_rate": 0.0004957951577922366,
      "loss": 0.3948,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.22034548223018646,
      "learning_rate": 0.0004955738503076174,
      "loss": 0.393,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.4037014842033386,
      "eval_runtime": 128.1481,
      "eval_samples_per_second": 1364.842,
      "eval_steps_per_second": 42.654,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.23047639429569244,
      "learning_rate": 0.0004953525428229983,
      "loss": 0.3932,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.21573340892791748,
      "learning_rate": 0.0004951312353383792,
      "loss": 0.3962,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.20124098658561707,
      "learning_rate": 0.00049490992785376,
      "loss": 0.3927,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.2128549963235855,
      "learning_rate": 0.0004946886203691409,
      "loss": 0.3933,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.21605820953845978,
      "learning_rate": 0.0004944673128845217,
      "loss": 0.3955,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.2173287272453308,
      "learning_rate": 0.0004942460053999026,
      "loss": 0.3931,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.2051798552274704,
      "learning_rate": 0.0004940246979152835,
      "loss": 0.3926,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.2123619019985199,
      "learning_rate": 0.0004938033904306644,
      "loss": 0.3936,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.20386479794979095,
      "learning_rate": 0.0004935820829460452,
      "loss": 0.3921,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.22133581340312958,
      "learning_rate": 0.0004933607754614261,
      "loss": 0.3907,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.20241990685462952,
      "learning_rate": 0.000493139467976807,
      "loss": 0.3907,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.22867727279663086,
      "learning_rate": 0.0004929181604921879,
      "loss": 0.3926,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.2082095593214035,
      "learning_rate": 0.0004926968530075687,
      "loss": 0.3923,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.21672311425209045,
      "learning_rate": 0.0004924755455229495,
      "loss": 0.39,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.18381841480731964,
      "learning_rate": 0.0004922542380383305,
      "loss": 0.3903,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.18471013009548187,
      "learning_rate": 0.0004920329305537113,
      "loss": 0.3899,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.20817142724990845,
      "learning_rate": 0.0004918116230690922,
      "loss": 0.3924,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.19019871950149536,
      "learning_rate": 0.0004915903155844731,
      "loss": 0.3907,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.20394323766231537,
      "learning_rate": 0.000491369008099854,
      "loss": 0.3887,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.18631413578987122,
      "learning_rate": 0.0004911477006152348,
      "loss": 0.3885,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.3988412618637085,
      "eval_runtime": 127.6353,
      "eval_samples_per_second": 1370.327,
      "eval_steps_per_second": 42.825,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.19875973463058472,
      "learning_rate": 0.0004909263931306157,
      "loss": 0.391,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.2042475938796997,
      "learning_rate": 0.0004907050856459966,
      "loss": 0.3894,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.17920894920825958,
      "learning_rate": 0.0004904837781613775,
      "loss": 0.3905,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.19074657559394836,
      "learning_rate": 0.0004902624706767583,
      "loss": 0.3876,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.16656680405139923,
      "learning_rate": 0.0004900411631921391,
      "loss": 0.39,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.20586633682250977,
      "learning_rate": 0.00048981985570752,
      "loss": 0.3867,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.19586430490016937,
      "learning_rate": 0.0004895985482229009,
      "loss": 0.3861,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.20591911673545837,
      "learning_rate": 0.0004893772407382818,
      "loss": 0.388,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.19660668075084686,
      "learning_rate": 0.0004891559332536626,
      "loss": 0.3855,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.19853533804416656,
      "learning_rate": 0.0004889346257690435,
      "loss": 0.3889,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.21073491871356964,
      "learning_rate": 0.0004887133182844244,
      "loss": 0.3842,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.19493705034255981,
      "learning_rate": 0.0004884920107998053,
      "loss": 0.3893,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.20267756283283234,
      "learning_rate": 0.00048827070331518616,
      "loss": 0.386,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.23342052102088928,
      "learning_rate": 0.000488049395830567,
      "loss": 0.3863,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.2048649787902832,
      "learning_rate": 0.0004878280883459479,
      "loss": 0.3861,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.19726499915122986,
      "learning_rate": 0.00048760678086132874,
      "loss": 0.3877,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.1905156821012497,
      "learning_rate": 0.00048738547337670964,
      "loss": 0.3855,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.1816689670085907,
      "learning_rate": 0.0004871641658920905,
      "loss": 0.3836,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.19897837936878204,
      "learning_rate": 0.0004869428584074714,
      "loss": 0.3855,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.1895296722650528,
      "learning_rate": 0.00048672155092285217,
      "loss": 0.3862,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.3948618471622467,
      "eval_runtime": 127.6106,
      "eval_samples_per_second": 1370.591,
      "eval_steps_per_second": 42.833,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.17084814608097076,
      "learning_rate": 0.00048650024343823307,
      "loss": 0.3855,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.1727423071861267,
      "learning_rate": 0.00048627893595361396,
      "loss": 0.3846,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.18666799366474152,
      "learning_rate": 0.0004860576284689948,
      "loss": 0.3853,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.20298105478286743,
      "learning_rate": 0.0004858363209843757,
      "loss": 0.3841,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.2038402110338211,
      "learning_rate": 0.00048561501349975655,
      "loss": 0.3834,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.1935742050409317,
      "learning_rate": 0.00048539370601513744,
      "loss": 0.3826,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.19426335394382477,
      "learning_rate": 0.0004851723985305183,
      "loss": 0.3841,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.16839323937892914,
      "learning_rate": 0.0004849510910458992,
      "loss": 0.3824,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.17240078747272491,
      "learning_rate": 0.0004847297835612801,
      "loss": 0.3846,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.1892363429069519,
      "learning_rate": 0.0004845084760766609,
      "loss": 0.3832,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.19069986045360565,
      "learning_rate": 0.0004842871685920418,
      "loss": 0.3847,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.19578279554843903,
      "learning_rate": 0.00048406586110742267,
      "loss": 0.3831,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.18232181668281555,
      "learning_rate": 0.00048384455362280356,
      "loss": 0.3859,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.18378932774066925,
      "learning_rate": 0.0004836232461381844,
      "loss": 0.3823,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.1931367963552475,
      "learning_rate": 0.0004834019386535653,
      "loss": 0.3816,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.19997821748256683,
      "learning_rate": 0.0004831806311689461,
      "loss": 0.3811,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.18733474612236023,
      "learning_rate": 0.000482959323684327,
      "loss": 0.3836,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.18752743303775787,
      "learning_rate": 0.0004827380161997079,
      "loss": 0.3844,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.2026272714138031,
      "learning_rate": 0.00048251670871508873,
      "loss": 0.3824,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.17838479578495026,
      "learning_rate": 0.00048229540123046963,
      "loss": 0.3829,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.3918657898902893,
      "eval_runtime": 127.5374,
      "eval_samples_per_second": 1371.378,
      "eval_steps_per_second": 42.858,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.2015528380870819,
      "learning_rate": 0.00048207409374585047,
      "loss": 0.3817,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.1934596300125122,
      "learning_rate": 0.00048185278626123137,
      "loss": 0.3839,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.19467231631278992,
      "learning_rate": 0.0004816314787766122,
      "loss": 0.38,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.1734662801027298,
      "learning_rate": 0.0004814101712919931,
      "loss": 0.383,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.17939379811286926,
      "learning_rate": 0.00048118886380737395,
      "loss": 0.3812,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.17628733813762665,
      "learning_rate": 0.00048096755632275485,
      "loss": 0.3831,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.17077875137329102,
      "learning_rate": 0.00048074624883813575,
      "loss": 0.381,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.18000702559947968,
      "learning_rate": 0.0004805249413535166,
      "loss": 0.3813,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.16518619656562805,
      "learning_rate": 0.0004803036338688975,
      "loss": 0.383,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.1728534698486328,
      "learning_rate": 0.00048008232638427833,
      "loss": 0.3809,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.21997717022895813,
      "learning_rate": 0.00047986101889965923,
      "loss": 0.384,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.19518372416496277,
      "learning_rate": 0.00047963971141504007,
      "loss": 0.3804,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.17409375309944153,
      "learning_rate": 0.0004794184039304209,
      "loss": 0.382,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.18760907649993896,
      "learning_rate": 0.00047919709644580176,
      "loss": 0.3823,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.18635359406471252,
      "learning_rate": 0.00047897578896118265,
      "loss": 0.3823,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.1669413447380066,
      "learning_rate": 0.00047875448147656355,
      "loss": 0.381,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.19926102459430695,
      "learning_rate": 0.0004785331739919444,
      "loss": 0.3793,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.21281960606575012,
      "learning_rate": 0.0004783118665073253,
      "loss": 0.3814,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.17595675587654114,
      "learning_rate": 0.00047809055902270614,
      "loss": 0.3822,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.1821969598531723,
      "learning_rate": 0.00047786925153808703,
      "loss": 0.3791,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.3899502456188202,
      "eval_runtime": 127.1364,
      "eval_samples_per_second": 1375.704,
      "eval_steps_per_second": 42.993,
      "step": 30000
    },
    {
      "epoch": 1.2239006241486572,
      "grad_norm": 0.19614757597446442,
      "learning_rate": 0.0004776479440534679,
      "loss": 0.3793,
      "step": 30100
    },
    {
      "epoch": 1.2279667391790514,
      "grad_norm": 0.1829359531402588,
      "learning_rate": 0.0004774266365688488,
      "loss": 0.3805,
      "step": 30200
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.17871156334877014,
      "learning_rate": 0.00047720532908422967,
      "loss": 0.3778,
      "step": 30300
    },
    {
      "epoch": 1.2360989692398399,
      "grad_norm": 0.16627086699008942,
      "learning_rate": 0.0004769840215996105,
      "loss": 0.3826,
      "step": 30400
    },
    {
      "epoch": 1.240165084270234,
      "grad_norm": 0.16688333451747894,
      "learning_rate": 0.0004767627141149914,
      "loss": 0.3795,
      "step": 30500
    },
    {
      "epoch": 1.2442311993006283,
      "grad_norm": 0.19514888525009155,
      "learning_rate": 0.00047654140663037225,
      "loss": 0.3794,
      "step": 30600
    },
    {
      "epoch": 1.2482973143310225,
      "grad_norm": 0.17610755562782288,
      "learning_rate": 0.00047632009914575315,
      "loss": 0.3782,
      "step": 30700
    },
    {
      "epoch": 1.2523634293614165,
      "grad_norm": 0.1794574111700058,
      "learning_rate": 0.000476098791661134,
      "loss": 0.3821,
      "step": 30800
    },
    {
      "epoch": 1.256429544391811,
      "grad_norm": 0.1803928017616272,
      "learning_rate": 0.0004758774841765149,
      "loss": 0.3811,
      "step": 30900
    },
    {
      "epoch": 1.260495659422205,
      "grad_norm": 0.1712465137243271,
      "learning_rate": 0.0004756561766918957,
      "loss": 0.3783,
      "step": 31000
    },
    {
      "epoch": 1.2645617744525992,
      "grad_norm": 0.17814449965953827,
      "learning_rate": 0.0004754348692072766,
      "loss": 0.3805,
      "step": 31100
    },
    {
      "epoch": 1.2686278894829934,
      "grad_norm": 0.18483866751194,
      "learning_rate": 0.0004752135617226575,
      "loss": 0.3791,
      "step": 31200
    },
    {
      "epoch": 1.2726940045133877,
      "grad_norm": 0.17289350926876068,
      "learning_rate": 0.0004749922542380383,
      "loss": 0.3776,
      "step": 31300
    },
    {
      "epoch": 1.2767601195437819,
      "grad_norm": 0.16458654403686523,
      "learning_rate": 0.0004747709467534192,
      "loss": 0.3805,
      "step": 31400
    },
    {
      "epoch": 1.280826234574176,
      "grad_norm": 0.15949304401874542,
      "learning_rate": 0.00047454963926880006,
      "loss": 0.3777,
      "step": 31500
    },
    {
      "epoch": 1.2848923496045703,
      "grad_norm": 0.17788292467594147,
      "learning_rate": 0.00047432833178418096,
      "loss": 0.3785,
      "step": 31600
    },
    {
      "epoch": 1.2889584646349646,
      "grad_norm": 0.1653790920972824,
      "learning_rate": 0.0004741070242995618,
      "loss": 0.3784,
      "step": 31700
    },
    {
      "epoch": 1.2930245796653588,
      "grad_norm": 0.1894567757844925,
      "learning_rate": 0.0004738857168149427,
      "loss": 0.3758,
      "step": 31800
    },
    {
      "epoch": 1.297090694695753,
      "grad_norm": 0.19105525314807892,
      "learning_rate": 0.00047366440933032354,
      "loss": 0.3803,
      "step": 31900
    },
    {
      "epoch": 1.3011568097261472,
      "grad_norm": 0.18661445379257202,
      "learning_rate": 0.00047344310184570444,
      "loss": 0.3794,
      "step": 32000
    },
    {
      "epoch": 1.3011568097261472,
      "eval_loss": 0.38850337266921997,
      "eval_runtime": 127.4814,
      "eval_samples_per_second": 1371.98,
      "eval_steps_per_second": 42.877,
      "step": 32000
    },
    {
      "epoch": 1.3052229247565412,
      "grad_norm": 0.18517974019050598,
      "learning_rate": 0.00047322179436108533,
      "loss": 0.3782,
      "step": 32100
    },
    {
      "epoch": 1.3092890397869357,
      "grad_norm": 0.17290665209293365,
      "learning_rate": 0.0004730004868764662,
      "loss": 0.3777,
      "step": 32200
    },
    {
      "epoch": 1.3133551548173297,
      "grad_norm": 0.18478140234947205,
      "learning_rate": 0.0004727791793918471,
      "loss": 0.3805,
      "step": 32300
    },
    {
      "epoch": 1.3174212698477241,
      "grad_norm": 0.18493874371051788,
      "learning_rate": 0.0004725578719072279,
      "loss": 0.3783,
      "step": 32400
    },
    {
      "epoch": 1.3214873848781181,
      "grad_norm": 0.17466729879379272,
      "learning_rate": 0.0004723365644226088,
      "loss": 0.3763,
      "step": 32500
    },
    {
      "epoch": 1.3255534999085123,
      "grad_norm": 0.1706957221031189,
      "learning_rate": 0.00047211525693798966,
      "loss": 0.377,
      "step": 32600
    },
    {
      "epoch": 1.3296196149389066,
      "grad_norm": 0.16547732055187225,
      "learning_rate": 0.0004718939494533705,
      "loss": 0.3765,
      "step": 32700
    },
    {
      "epoch": 1.3336857299693008,
      "grad_norm": 0.17236511409282684,
      "learning_rate": 0.00047167264196875134,
      "loss": 0.3764,
      "step": 32800
    },
    {
      "epoch": 1.337751844999695,
      "grad_norm": 0.18015728890895844,
      "learning_rate": 0.00047145133448413224,
      "loss": 0.3775,
      "step": 32900
    },
    {
      "epoch": 1.3418179600300892,
      "grad_norm": 0.2175292819738388,
      "learning_rate": 0.00047123002699951314,
      "loss": 0.3789,
      "step": 33000
    },
    {
      "epoch": 1.3458840750604835,
      "grad_norm": 0.1697661578655243,
      "learning_rate": 0.000471008719514894,
      "loss": 0.3786,
      "step": 33100
    },
    {
      "epoch": 1.3499501900908777,
      "grad_norm": 0.16261319816112518,
      "learning_rate": 0.0004707874120302749,
      "loss": 0.3803,
      "step": 33200
    },
    {
      "epoch": 1.354016305121272,
      "grad_norm": 0.16961264610290527,
      "learning_rate": 0.0004705661045456557,
      "loss": 0.3756,
      "step": 33300
    },
    {
      "epoch": 1.3580824201516661,
      "grad_norm": 0.1757083386182785,
      "learning_rate": 0.0004703447970610366,
      "loss": 0.3787,
      "step": 33400
    },
    {
      "epoch": 1.3621485351820604,
      "grad_norm": 0.1775626540184021,
      "learning_rate": 0.00047012348957641746,
      "loss": 0.3751,
      "step": 33500
    },
    {
      "epoch": 1.3662146502124546,
      "grad_norm": 0.17083577811717987,
      "learning_rate": 0.00046990218209179836,
      "loss": 0.3795,
      "step": 33600
    },
    {
      "epoch": 1.3702807652428488,
      "grad_norm": 0.17872963845729828,
      "learning_rate": 0.00046968087460717926,
      "loss": 0.3757,
      "step": 33700
    },
    {
      "epoch": 1.3743468802732428,
      "grad_norm": 0.1863061934709549,
      "learning_rate": 0.0004694595671225601,
      "loss": 0.3774,
      "step": 33800
    },
    {
      "epoch": 1.3784129953036373,
      "grad_norm": 0.20334675908088684,
      "learning_rate": 0.000469238259637941,
      "loss": 0.3758,
      "step": 33900
    },
    {
      "epoch": 1.3824791103340313,
      "grad_norm": 0.17429697513580322,
      "learning_rate": 0.00046901695215332184,
      "loss": 0.3779,
      "step": 34000
    },
    {
      "epoch": 1.3824791103340313,
      "eval_loss": 0.38604822754859924,
      "eval_runtime": 127.3783,
      "eval_samples_per_second": 1373.091,
      "eval_steps_per_second": 42.912,
      "step": 34000
    },
    {
      "epoch": 1.3865452253644255,
      "grad_norm": 0.18188224732875824,
      "learning_rate": 0.00046879564466870274,
      "loss": 0.3767,
      "step": 34100
    },
    {
      "epoch": 1.3906113403948197,
      "grad_norm": 0.19538792967796326,
      "learning_rate": 0.0004685743371840836,
      "loss": 0.3758,
      "step": 34200
    },
    {
      "epoch": 1.394677455425214,
      "grad_norm": 0.17356017231941223,
      "learning_rate": 0.0004683530296994645,
      "loss": 0.3775,
      "step": 34300
    },
    {
      "epoch": 1.3987435704556082,
      "grad_norm": 0.19519691169261932,
      "learning_rate": 0.00046813172221484527,
      "loss": 0.378,
      "step": 34400
    },
    {
      "epoch": 1.4028096854860024,
      "grad_norm": 0.1736382246017456,
      "learning_rate": 0.00046791041473022617,
      "loss": 0.3769,
      "step": 34500
    },
    {
      "epoch": 1.4068758005163966,
      "grad_norm": 0.1742245852947235,
      "learning_rate": 0.00046768910724560706,
      "loss": 0.374,
      "step": 34600
    },
    {
      "epoch": 1.4109419155467908,
      "grad_norm": 0.1757364422082901,
      "learning_rate": 0.0004674677997609879,
      "loss": 0.3755,
      "step": 34700
    },
    {
      "epoch": 1.415008030577185,
      "grad_norm": 0.16188444197177887,
      "learning_rate": 0.0004672464922763688,
      "loss": 0.3763,
      "step": 34800
    },
    {
      "epoch": 1.4190741456075793,
      "grad_norm": 0.15675023198127747,
      "learning_rate": 0.00046702518479174965,
      "loss": 0.3759,
      "step": 34900
    },
    {
      "epoch": 1.4231402606379735,
      "grad_norm": 0.1934361308813095,
      "learning_rate": 0.00046680387730713054,
      "loss": 0.3772,
      "step": 35000
    },
    {
      "epoch": 1.4272063756683677,
      "grad_norm": 0.16472847759723663,
      "learning_rate": 0.0004665825698225114,
      "loss": 0.3773,
      "step": 35100
    },
    {
      "epoch": 1.431272490698762,
      "grad_norm": 0.17189021408557892,
      "learning_rate": 0.0004663612623378923,
      "loss": 0.3767,
      "step": 35200
    },
    {
      "epoch": 1.435338605729156,
      "grad_norm": 0.16161766648292542,
      "learning_rate": 0.0004661399548532731,
      "loss": 0.3756,
      "step": 35300
    },
    {
      "epoch": 1.4394047207595504,
      "grad_norm": 0.16324743628501892,
      "learning_rate": 0.000465918647368654,
      "loss": 0.3769,
      "step": 35400
    },
    {
      "epoch": 1.4434708357899444,
      "grad_norm": 0.2061259150505066,
      "learning_rate": 0.0004656973398840349,
      "loss": 0.3742,
      "step": 35500
    },
    {
      "epoch": 1.4475369508203388,
      "grad_norm": 0.18658854067325592,
      "learning_rate": 0.00046547603239941576,
      "loss": 0.3768,
      "step": 35600
    },
    {
      "epoch": 1.4516030658507328,
      "grad_norm": 0.15421302616596222,
      "learning_rate": 0.00046525472491479666,
      "loss": 0.3767,
      "step": 35700
    },
    {
      "epoch": 1.455669180881127,
      "grad_norm": 0.17620107531547546,
      "learning_rate": 0.0004650334174301775,
      "loss": 0.3762,
      "step": 35800
    },
    {
      "epoch": 1.4597352959115213,
      "grad_norm": 0.17057767510414124,
      "learning_rate": 0.0004648121099455584,
      "loss": 0.376,
      "step": 35900
    },
    {
      "epoch": 1.4638014109419155,
      "grad_norm": 0.19414949417114258,
      "learning_rate": 0.00046459080246093925,
      "loss": 0.3772,
      "step": 36000
    },
    {
      "epoch": 1.4638014109419155,
      "eval_loss": 0.3854040503501892,
      "eval_runtime": 125.7834,
      "eval_samples_per_second": 1390.501,
      "eval_steps_per_second": 43.456,
      "step": 36000
    },
    {
      "epoch": 1.4678675259723097,
      "grad_norm": 0.1672116070985794,
      "learning_rate": 0.0004643694949763201,
      "loss": 0.379,
      "step": 36100
    },
    {
      "epoch": 1.471933641002704,
      "grad_norm": 0.17331549525260925,
      "learning_rate": 0.00046414818749170093,
      "loss": 0.3752,
      "step": 36200
    },
    {
      "epoch": 1.4759997560330982,
      "grad_norm": 0.15714649856090546,
      "learning_rate": 0.00046392688000708183,
      "loss": 0.376,
      "step": 36300
    },
    {
      "epoch": 1.4800658710634924,
      "grad_norm": 0.17593128979206085,
      "learning_rate": 0.0004637055725224627,
      "loss": 0.3757,
      "step": 36400
    },
    {
      "epoch": 1.4841319860938866,
      "grad_norm": 0.15309225022792816,
      "learning_rate": 0.00046348426503784357,
      "loss": 0.3758,
      "step": 36500
    },
    {
      "epoch": 1.4881981011242809,
      "grad_norm": 0.1567295342683792,
      "learning_rate": 0.00046326295755322447,
      "loss": 0.377,
      "step": 36600
    },
    {
      "epoch": 1.492264216154675,
      "grad_norm": 0.17265932261943817,
      "learning_rate": 0.0004630416500686053,
      "loss": 0.3733,
      "step": 36700
    },
    {
      "epoch": 1.4963303311850693,
      "grad_norm": 0.1630750149488449,
      "learning_rate": 0.0004628203425839862,
      "loss": 0.3769,
      "step": 36800
    },
    {
      "epoch": 1.5003964462154635,
      "grad_norm": 0.17310357093811035,
      "learning_rate": 0.00046259903509936705,
      "loss": 0.3767,
      "step": 36900
    },
    {
      "epoch": 1.5044625612458575,
      "grad_norm": 0.16592207551002502,
      "learning_rate": 0.00046237772761474795,
      "loss": 0.3754,
      "step": 37000
    },
    {
      "epoch": 1.508528676276252,
      "grad_norm": 0.16503210365772247,
      "learning_rate": 0.00046215642013012885,
      "loss": 0.3739,
      "step": 37100
    },
    {
      "epoch": 1.512594791306646,
      "grad_norm": 0.1913350224494934,
      "learning_rate": 0.0004619351126455097,
      "loss": 0.3754,
      "step": 37200
    },
    {
      "epoch": 1.5166609063370404,
      "grad_norm": 0.1732999086380005,
      "learning_rate": 0.0004617138051608906,
      "loss": 0.3744,
      "step": 37300
    },
    {
      "epoch": 1.5207270213674344,
      "grad_norm": 0.17487916350364685,
      "learning_rate": 0.00046149249767627143,
      "loss": 0.3749,
      "step": 37400
    },
    {
      "epoch": 1.5247931363978287,
      "grad_norm": 0.1690748631954193,
      "learning_rate": 0.0004612711901916523,
      "loss": 0.3736,
      "step": 37500
    },
    {
      "epoch": 1.5288592514282229,
      "grad_norm": 0.1398518681526184,
      "learning_rate": 0.00046104988270703317,
      "loss": 0.3744,
      "step": 37600
    },
    {
      "epoch": 1.532925366458617,
      "grad_norm": 0.1722736805677414,
      "learning_rate": 0.00046082857522241407,
      "loss": 0.3733,
      "step": 37700
    },
    {
      "epoch": 1.5369914814890113,
      "grad_norm": 0.1928071826696396,
      "learning_rate": 0.00046060726773779486,
      "loss": 0.3721,
      "step": 37800
    },
    {
      "epoch": 1.5410575965194055,
      "grad_norm": 0.2089661806821823,
      "learning_rate": 0.00046038596025317575,
      "loss": 0.3728,
      "step": 37900
    },
    {
      "epoch": 1.5451237115497998,
      "grad_norm": 0.1676872968673706,
      "learning_rate": 0.00046016465276855665,
      "loss": 0.375,
      "step": 38000
    },
    {
      "epoch": 1.5451237115497998,
      "eval_loss": 0.3831368386745453,
      "eval_runtime": 125.9244,
      "eval_samples_per_second": 1388.945,
      "eval_steps_per_second": 43.407,
      "step": 38000
    },
    {
      "epoch": 1.549189826580194,
      "grad_norm": 0.1823248267173767,
      "learning_rate": 0.0004599433452839375,
      "loss": 0.3751,
      "step": 38100
    },
    {
      "epoch": 1.5532559416105882,
      "grad_norm": 0.18947510421276093,
      "learning_rate": 0.0004597220377993184,
      "loss": 0.3746,
      "step": 38200
    },
    {
      "epoch": 1.5573220566409822,
      "grad_norm": 0.17336338758468628,
      "learning_rate": 0.00045950073031469923,
      "loss": 0.3733,
      "step": 38300
    },
    {
      "epoch": 1.5613881716713767,
      "grad_norm": 0.17431138455867767,
      "learning_rate": 0.00045927942283008013,
      "loss": 0.3723,
      "step": 38400
    },
    {
      "epoch": 1.5654542867017707,
      "grad_norm": 0.17988577485084534,
      "learning_rate": 0.000459058115345461,
      "loss": 0.3712,
      "step": 38500
    },
    {
      "epoch": 1.5695204017321651,
      "grad_norm": 0.17456242442131042,
      "learning_rate": 0.00045883680786084187,
      "loss": 0.3734,
      "step": 38600
    },
    {
      "epoch": 1.5735865167625591,
      "grad_norm": 0.18587161600589752,
      "learning_rate": 0.0004586155003762227,
      "loss": 0.3721,
      "step": 38700
    },
    {
      "epoch": 1.5776526317929536,
      "grad_norm": 0.16428890824317932,
      "learning_rate": 0.0004583941928916036,
      "loss": 0.3751,
      "step": 38800
    },
    {
      "epoch": 1.5817187468233476,
      "grad_norm": 0.16394223272800446,
      "learning_rate": 0.0004581728854069845,
      "loss": 0.3733,
      "step": 38900
    },
    {
      "epoch": 1.5857848618537418,
      "grad_norm": 0.16565845906734467,
      "learning_rate": 0.00045795157792236535,
      "loss": 0.3752,
      "step": 39000
    },
    {
      "epoch": 1.589850976884136,
      "grad_norm": 0.16254651546478271,
      "learning_rate": 0.00045773027043774625,
      "loss": 0.3737,
      "step": 39100
    },
    {
      "epoch": 1.5939170919145302,
      "grad_norm": 0.1750398576259613,
      "learning_rate": 0.0004575089629531271,
      "loss": 0.3757,
      "step": 39200
    },
    {
      "epoch": 1.5979832069449245,
      "grad_norm": 0.17189715802669525,
      "learning_rate": 0.000457287655468508,
      "loss": 0.372,
      "step": 39300
    },
    {
      "epoch": 1.6020493219753187,
      "grad_norm": 0.16337716579437256,
      "learning_rate": 0.0004570663479838888,
      "loss": 0.3721,
      "step": 39400
    },
    {
      "epoch": 1.606115437005713,
      "grad_norm": 0.1754106879234314,
      "learning_rate": 0.0004568450404992697,
      "loss": 0.3725,
      "step": 39500
    },
    {
      "epoch": 1.6101815520361071,
      "grad_norm": 0.20771925151348114,
      "learning_rate": 0.0004566237330146505,
      "loss": 0.3704,
      "step": 39600
    },
    {
      "epoch": 1.6142476670665014,
      "grad_norm": 0.18426458537578583,
      "learning_rate": 0.0004564024255300314,
      "loss": 0.3735,
      "step": 39700
    },
    {
      "epoch": 1.6183137820968954,
      "grad_norm": 0.18835139274597168,
      "learning_rate": 0.0004561811180454123,
      "loss": 0.3707,
      "step": 39800
    },
    {
      "epoch": 1.6223798971272898,
      "grad_norm": 0.17836672067642212,
      "learning_rate": 0.00045595981056079316,
      "loss": 0.3743,
      "step": 39900
    },
    {
      "epoch": 1.6264460121576838,
      "grad_norm": 0.17917685210704803,
      "learning_rate": 0.00045573850307617405,
      "loss": 0.3733,
      "step": 40000
    },
    {
      "epoch": 1.6264460121576838,
      "eval_loss": 0.3814237713813782,
      "eval_runtime": 126.0902,
      "eval_samples_per_second": 1387.118,
      "eval_steps_per_second": 43.35,
      "step": 40000
    },
    {
      "epoch": 1.6305121271880783,
      "grad_norm": 0.17443910241127014,
      "learning_rate": 0.0004555171955915549,
      "loss": 0.3758,
      "step": 40100
    },
    {
      "epoch": 1.6345782422184723,
      "grad_norm": 0.18495848774909973,
      "learning_rate": 0.0004552958881069358,
      "loss": 0.3702,
      "step": 40200
    },
    {
      "epoch": 1.6386443572488667,
      "grad_norm": 0.17090938985347748,
      "learning_rate": 0.00045507458062231664,
      "loss": 0.3752,
      "step": 40300
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.1773478388786316,
      "learning_rate": 0.00045485327313769754,
      "loss": 0.3726,
      "step": 40400
    },
    {
      "epoch": 1.6467765873096551,
      "grad_norm": 0.18886886537075043,
      "learning_rate": 0.0004546319656530784,
      "loss": 0.3748,
      "step": 40500
    },
    {
      "epoch": 1.6508427023400492,
      "grad_norm": 0.18253129720687866,
      "learning_rate": 0.0004544106581684593,
      "loss": 0.3707,
      "step": 40600
    },
    {
      "epoch": 1.6549088173704434,
      "grad_norm": 0.16899117827415466,
      "learning_rate": 0.0004541893506838402,
      "loss": 0.3739,
      "step": 40700
    },
    {
      "epoch": 1.6589749324008376,
      "grad_norm": 0.21663622558116913,
      "learning_rate": 0.000453968043199221,
      "loss": 0.3716,
      "step": 40800
    },
    {
      "epoch": 1.6630410474312318,
      "grad_norm": 0.19041720032691956,
      "learning_rate": 0.0004537467357146019,
      "loss": 0.3716,
      "step": 40900
    },
    {
      "epoch": 1.667107162461626,
      "grad_norm": 0.17056743800640106,
      "learning_rate": 0.00045352542822998276,
      "loss": 0.3722,
      "step": 41000
    },
    {
      "epoch": 1.6711732774920203,
      "grad_norm": 0.18982043862342834,
      "learning_rate": 0.0004533041207453636,
      "loss": 0.3711,
      "step": 41100
    },
    {
      "epoch": 1.6752393925224145,
      "grad_norm": 0.16877861320972443,
      "learning_rate": 0.00045308281326074444,
      "loss": 0.3733,
      "step": 41200
    },
    {
      "epoch": 1.6793055075528087,
      "grad_norm": 0.1948210895061493,
      "learning_rate": 0.00045286150577612534,
      "loss": 0.3727,
      "step": 41300
    },
    {
      "epoch": 1.683371622583203,
      "grad_norm": 0.18009260296821594,
      "learning_rate": 0.00045264019829150624,
      "loss": 0.3733,
      "step": 41400
    },
    {
      "epoch": 1.687437737613597,
      "grad_norm": 0.18625250458717346,
      "learning_rate": 0.0004524188908068871,
      "loss": 0.373,
      "step": 41500
    },
    {
      "epoch": 1.6915038526439914,
      "grad_norm": 0.15615016222000122,
      "learning_rate": 0.000452197583322268,
      "loss": 0.3746,
      "step": 41600
    },
    {
      "epoch": 1.6955699676743854,
      "grad_norm": 0.19392438232898712,
      "learning_rate": 0.0004519762758376488,
      "loss": 0.3721,
      "step": 41700
    },
    {
      "epoch": 1.6996360827047798,
      "grad_norm": 0.17907142639160156,
      "learning_rate": 0.0004517549683530297,
      "loss": 0.3714,
      "step": 41800
    },
    {
      "epoch": 1.7037021977351738,
      "grad_norm": 0.1619904339313507,
      "learning_rate": 0.00045153366086841056,
      "loss": 0.3714,
      "step": 41900
    },
    {
      "epoch": 1.7077683127655683,
      "grad_norm": 0.1709003448486328,
      "learning_rate": 0.00045131235338379146,
      "loss": 0.3699,
      "step": 42000
    },
    {
      "epoch": 1.7077683127655683,
      "eval_loss": 0.3804800808429718,
      "eval_runtime": 125.652,
      "eval_samples_per_second": 1391.956,
      "eval_steps_per_second": 43.501,
      "step": 42000
    },
    {
      "epoch": 1.7118344277959623,
      "grad_norm": 0.17655260860919952,
      "learning_rate": 0.0004510910458991723,
      "loss": 0.3692,
      "step": 42100
    },
    {
      "epoch": 1.7159005428263565,
      "grad_norm": 0.1570090502500534,
      "learning_rate": 0.0004508697384145532,
      "loss": 0.3707,
      "step": 42200
    },
    {
      "epoch": 1.7199666578567507,
      "grad_norm": 0.18649208545684814,
      "learning_rate": 0.0004506484309299341,
      "loss": 0.3732,
      "step": 42300
    },
    {
      "epoch": 1.724032772887145,
      "grad_norm": 0.18493753671646118,
      "learning_rate": 0.00045042712344531494,
      "loss": 0.3691,
      "step": 42400
    },
    {
      "epoch": 1.7280988879175392,
      "grad_norm": 0.1912442445755005,
      "learning_rate": 0.00045020581596069584,
      "loss": 0.372,
      "step": 42500
    },
    {
      "epoch": 1.7321650029479334,
      "grad_norm": 0.15935018658638,
      "learning_rate": 0.0004499845084760767,
      "loss": 0.3729,
      "step": 42600
    },
    {
      "epoch": 1.7362311179783276,
      "grad_norm": 0.17030280828475952,
      "learning_rate": 0.0004497632009914576,
      "loss": 0.37,
      "step": 42700
    },
    {
      "epoch": 1.7402972330087219,
      "grad_norm": 0.1666862666606903,
      "learning_rate": 0.00044954189350683837,
      "loss": 0.3703,
      "step": 42800
    },
    {
      "epoch": 1.744363348039116,
      "grad_norm": 0.17482557892799377,
      "learning_rate": 0.00044932058602221926,
      "loss": 0.3731,
      "step": 42900
    },
    {
      "epoch": 1.74842946306951,
      "grad_norm": 0.1578214317560196,
      "learning_rate": 0.0004490992785376001,
      "loss": 0.3722,
      "step": 43000
    },
    {
      "epoch": 1.7524955780999045,
      "grad_norm": 0.16629891097545624,
      "learning_rate": 0.000448877971052981,
      "loss": 0.3704,
      "step": 43100
    },
    {
      "epoch": 1.7565616931302985,
      "grad_norm": 0.17895828187465668,
      "learning_rate": 0.0004486566635683619,
      "loss": 0.3694,
      "step": 43200
    },
    {
      "epoch": 1.760627808160693,
      "grad_norm": 0.155790776014328,
      "learning_rate": 0.00044843535608374274,
      "loss": 0.3713,
      "step": 43300
    },
    {
      "epoch": 1.764693923191087,
      "grad_norm": 0.17156007885932922,
      "learning_rate": 0.00044821404859912364,
      "loss": 0.3692,
      "step": 43400
    },
    {
      "epoch": 1.7687600382214814,
      "grad_norm": 0.18834742903709412,
      "learning_rate": 0.0004479927411145045,
      "loss": 0.3695,
      "step": 43500
    },
    {
      "epoch": 1.7728261532518754,
      "grad_norm": 0.18698211014270782,
      "learning_rate": 0.0004477714336298854,
      "loss": 0.3736,
      "step": 43600
    },
    {
      "epoch": 1.7768922682822699,
      "grad_norm": 0.17977577447891235,
      "learning_rate": 0.0004475501261452662,
      "loss": 0.3719,
      "step": 43700
    },
    {
      "epoch": 1.7809583833126639,
      "grad_norm": 0.16892267763614655,
      "learning_rate": 0.0004473288186606471,
      "loss": 0.3715,
      "step": 43800
    },
    {
      "epoch": 1.785024498343058,
      "grad_norm": 0.1901235282421112,
      "learning_rate": 0.00044710751117602797,
      "loss": 0.3705,
      "step": 43900
    },
    {
      "epoch": 1.7890906133734523,
      "grad_norm": 0.17739108204841614,
      "learning_rate": 0.00044688620369140886,
      "loss": 0.372,
      "step": 44000
    },
    {
      "epoch": 1.7890906133734523,
      "eval_loss": 0.3798080384731293,
      "eval_runtime": 125.5278,
      "eval_samples_per_second": 1393.332,
      "eval_steps_per_second": 43.544,
      "step": 44000
    },
    {
      "epoch": 1.7931567284038465,
      "grad_norm": 0.16857028007507324,
      "learning_rate": 0.00044666489620678976,
      "loss": 0.3716,
      "step": 44100
    },
    {
      "epoch": 1.7972228434342408,
      "grad_norm": 0.1638098508119583,
      "learning_rate": 0.0004464435887221706,
      "loss": 0.3721,
      "step": 44200
    },
    {
      "epoch": 1.801288958464635,
      "grad_norm": 0.16732460260391235,
      "learning_rate": 0.0004462222812375515,
      "loss": 0.3696,
      "step": 44300
    },
    {
      "epoch": 1.8053550734950292,
      "grad_norm": 0.18233218789100647,
      "learning_rate": 0.00044600097375293234,
      "loss": 0.3708,
      "step": 44400
    },
    {
      "epoch": 1.8094211885254232,
      "grad_norm": 0.208842933177948,
      "learning_rate": 0.0004457796662683132,
      "loss": 0.37,
      "step": 44500
    },
    {
      "epoch": 1.8134873035558177,
      "grad_norm": 0.16830939054489136,
      "learning_rate": 0.00044555835878369403,
      "loss": 0.3704,
      "step": 44600
    },
    {
      "epoch": 1.8175534185862117,
      "grad_norm": 0.1897367686033249,
      "learning_rate": 0.00044533705129907493,
      "loss": 0.37,
      "step": 44700
    },
    {
      "epoch": 1.8216195336166061,
      "grad_norm": 0.20131641626358032,
      "learning_rate": 0.00044511574381445577,
      "loss": 0.3712,
      "step": 44800
    },
    {
      "epoch": 1.8256856486470001,
      "grad_norm": 0.2006787359714508,
      "learning_rate": 0.00044489443632983667,
      "loss": 0.3689,
      "step": 44900
    },
    {
      "epoch": 1.8297517636773946,
      "grad_norm": 0.1637798398733139,
      "learning_rate": 0.00044467312884521757,
      "loss": 0.3708,
      "step": 45000
    },
    {
      "epoch": 1.8338178787077886,
      "grad_norm": 0.17544426023960114,
      "learning_rate": 0.0004444518213605984,
      "loss": 0.3692,
      "step": 45100
    },
    {
      "epoch": 1.837883993738183,
      "grad_norm": 0.17708748579025269,
      "learning_rate": 0.0004442305138759793,
      "loss": 0.3711,
      "step": 45200
    },
    {
      "epoch": 1.841950108768577,
      "grad_norm": 0.20885324478149414,
      "learning_rate": 0.00044400920639136015,
      "loss": 0.3693,
      "step": 45300
    },
    {
      "epoch": 1.8460162237989712,
      "grad_norm": 0.19389896094799042,
      "learning_rate": 0.00044378789890674105,
      "loss": 0.3679,
      "step": 45400
    },
    {
      "epoch": 1.8500823388293655,
      "grad_norm": 0.17411524057388306,
      "learning_rate": 0.0004435665914221219,
      "loss": 0.3716,
      "step": 45500
    },
    {
      "epoch": 1.8541484538597597,
      "grad_norm": 0.15537463128566742,
      "learning_rate": 0.0004433452839375028,
      "loss": 0.3689,
      "step": 45600
    },
    {
      "epoch": 1.858214568890154,
      "grad_norm": 0.16169284284114838,
      "learning_rate": 0.0004431239764528837,
      "loss": 0.3713,
      "step": 45700
    },
    {
      "epoch": 1.8622806839205481,
      "grad_norm": 0.15734682977199554,
      "learning_rate": 0.00044290266896826453,
      "loss": 0.3695,
      "step": 45800
    },
    {
      "epoch": 1.8663467989509424,
      "grad_norm": 0.1927379071712494,
      "learning_rate": 0.0004426813614836454,
      "loss": 0.3721,
      "step": 45900
    },
    {
      "epoch": 1.8704129139813366,
      "grad_norm": 0.18548856675624847,
      "learning_rate": 0.00044246005399902627,
      "loss": 0.3677,
      "step": 46000
    },
    {
      "epoch": 1.8704129139813366,
      "eval_loss": 0.3797515034675598,
      "eval_runtime": 125.96,
      "eval_samples_per_second": 1388.552,
      "eval_steps_per_second": 43.395,
      "step": 46000
    },
    {
      "epoch": 1.8744790290117308,
      "grad_norm": 0.1793985664844513,
      "learning_rate": 0.00044223874651440717,
      "loss": 0.371,
      "step": 46100
    },
    {
      "epoch": 1.8785451440421248,
      "grad_norm": 0.17218004167079926,
      "learning_rate": 0.00044201743902978795,
      "loss": 0.3691,
      "step": 46200
    },
    {
      "epoch": 1.8826112590725192,
      "grad_norm": 0.1912301629781723,
      "learning_rate": 0.00044179613154516885,
      "loss": 0.371,
      "step": 46300
    },
    {
      "epoch": 1.8866773741029133,
      "grad_norm": 0.1798275262117386,
      "learning_rate": 0.0004415748240605497,
      "loss": 0.3697,
      "step": 46400
    },
    {
      "epoch": 1.8907434891333077,
      "grad_norm": 0.1912059634923935,
      "learning_rate": 0.0004413535165759306,
      "loss": 0.3686,
      "step": 46500
    },
    {
      "epoch": 1.8948096041637017,
      "grad_norm": 0.2018793374300003,
      "learning_rate": 0.0004411322090913115,
      "loss": 0.3695,
      "step": 46600
    },
    {
      "epoch": 1.8988757191940961,
      "grad_norm": 0.20787711441516876,
      "learning_rate": 0.00044091090160669233,
      "loss": 0.3706,
      "step": 46700
    },
    {
      "epoch": 1.9029418342244901,
      "grad_norm": 0.17953358590602875,
      "learning_rate": 0.00044068959412207323,
      "loss": 0.3694,
      "step": 46800
    },
    {
      "epoch": 1.9070079492548844,
      "grad_norm": 0.20702657103538513,
      "learning_rate": 0.00044046828663745407,
      "loss": 0.3697,
      "step": 46900
    },
    {
      "epoch": 1.9110740642852786,
      "grad_norm": 0.20142462849617004,
      "learning_rate": 0.00044024697915283497,
      "loss": 0.3718,
      "step": 47000
    },
    {
      "epoch": 1.9151401793156728,
      "grad_norm": 0.18797799944877625,
      "learning_rate": 0.0004400256716682158,
      "loss": 0.3714,
      "step": 47100
    },
    {
      "epoch": 1.919206294346067,
      "grad_norm": 0.1821361929178238,
      "learning_rate": 0.0004398043641835967,
      "loss": 0.3705,
      "step": 47200
    },
    {
      "epoch": 1.9232724093764613,
      "grad_norm": 0.2267979234457016,
      "learning_rate": 0.00043958305669897755,
      "loss": 0.3695,
      "step": 47300
    },
    {
      "epoch": 1.9273385244068555,
      "grad_norm": 0.17354243993759155,
      "learning_rate": 0.00043936174921435845,
      "loss": 0.3702,
      "step": 47400
    },
    {
      "epoch": 1.9314046394372497,
      "grad_norm": 0.1834326982498169,
      "learning_rate": 0.00043914044172973935,
      "loss": 0.3721,
      "step": 47500
    },
    {
      "epoch": 1.935470754467644,
      "grad_norm": 0.1790933459997177,
      "learning_rate": 0.0004389191342451202,
      "loss": 0.3679,
      "step": 47600
    },
    {
      "epoch": 1.939536869498038,
      "grad_norm": 0.1908542960882187,
      "learning_rate": 0.0004386978267605011,
      "loss": 0.3682,
      "step": 47700
    },
    {
      "epoch": 1.9436029845284324,
      "grad_norm": 0.21218347549438477,
      "learning_rate": 0.00043847651927588193,
      "loss": 0.3704,
      "step": 47800
    },
    {
      "epoch": 1.9476690995588264,
      "grad_norm": 0.26049473881721497,
      "learning_rate": 0.0004382552117912628,
      "loss": 0.3722,
      "step": 47900
    },
    {
      "epoch": 1.9517352145892208,
      "grad_norm": 0.27107149362564087,
      "learning_rate": 0.0004380339043066436,
      "loss": 0.369,
      "step": 48000
    },
    {
      "epoch": 1.9517352145892208,
      "eval_loss": 0.37713977694511414,
      "eval_runtime": 126.1015,
      "eval_samples_per_second": 1386.994,
      "eval_steps_per_second": 43.346,
      "step": 48000
    },
    {
      "epoch": 1.9558013296196148,
      "grad_norm": 0.18643130362033844,
      "learning_rate": 0.0004378125968220245,
      "loss": 0.3677,
      "step": 48100
    },
    {
      "epoch": 1.9598674446500093,
      "grad_norm": 0.16140271723270416,
      "learning_rate": 0.00043759128933740536,
      "loss": 0.3707,
      "step": 48200
    },
    {
      "epoch": 1.9639335596804033,
      "grad_norm": 0.17952434718608856,
      "learning_rate": 0.00043736998185278626,
      "loss": 0.3685,
      "step": 48300
    },
    {
      "epoch": 1.9679996747107977,
      "grad_norm": 0.20737746357917786,
      "learning_rate": 0.00043714867436816715,
      "loss": 0.3673,
      "step": 48400
    },
    {
      "epoch": 1.9720657897411917,
      "grad_norm": 0.20537574589252472,
      "learning_rate": 0.000436927366883548,
      "loss": 0.3694,
      "step": 48500
    },
    {
      "epoch": 1.976131904771586,
      "grad_norm": 0.18756066262722015,
      "learning_rate": 0.0004367060593989289,
      "loss": 0.3704,
      "step": 48600
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 0.17357128858566284,
      "learning_rate": 0.00043648475191430974,
      "loss": 0.3692,
      "step": 48700
    },
    {
      "epoch": 1.9842641348323744,
      "grad_norm": 0.1992308795452118,
      "learning_rate": 0.00043626344442969063,
      "loss": 0.37,
      "step": 48800
    },
    {
      "epoch": 1.9883302498627686,
      "grad_norm": 0.18636910617351532,
      "learning_rate": 0.0004360421369450715,
      "loss": 0.366,
      "step": 48900
    },
    {
      "epoch": 1.9923963648931629,
      "grad_norm": 0.17809602618217468,
      "learning_rate": 0.0004358208294604524,
      "loss": 0.3703,
      "step": 49000
    },
    {
      "epoch": 1.996462479923557,
      "grad_norm": 0.21832527220249176,
      "learning_rate": 0.00043559952197583327,
      "loss": 0.3669,
      "step": 49100
    },
    {
      "epoch": 2.000528594953951,
      "grad_norm": 0.19474735856056213,
      "learning_rate": 0.0004353782144912141,
      "loss": 0.3665,
      "step": 49200
    },
    {
      "epoch": 2.0045947099843455,
      "grad_norm": 0.18258270621299744,
      "learning_rate": 0.000435156907006595,
      "loss": 0.3646,
      "step": 49300
    },
    {
      "epoch": 2.0086608250147395,
      "grad_norm": 0.2244921773672104,
      "learning_rate": 0.00043493559952197586,
      "loss": 0.3637,
      "step": 49400
    },
    {
      "epoch": 2.012726940045134,
      "grad_norm": 0.20326019823551178,
      "learning_rate": 0.00043471429203735675,
      "loss": 0.3644,
      "step": 49500
    },
    {
      "epoch": 2.016793055075528,
      "grad_norm": 0.17100873589515686,
      "learning_rate": 0.00043449298455273754,
      "loss": 0.3621,
      "step": 49600
    },
    {
      "epoch": 2.0208591701059224,
      "grad_norm": 0.18027542531490326,
      "learning_rate": 0.00043427167706811844,
      "loss": 0.3649,
      "step": 49700
    },
    {
      "epoch": 2.0249252851363164,
      "grad_norm": 0.19253534078598022,
      "learning_rate": 0.0004340503695834993,
      "loss": 0.3633,
      "step": 49800
    },
    {
      "epoch": 2.028991400166711,
      "grad_norm": 0.2049250602722168,
      "learning_rate": 0.0004338290620988802,
      "loss": 0.3643,
      "step": 49900
    },
    {
      "epoch": 2.033057515197105,
      "grad_norm": 0.1973336786031723,
      "learning_rate": 0.0004336077546142611,
      "loss": 0.3659,
      "step": 50000
    },
    {
      "epoch": 2.033057515197105,
      "eval_loss": 0.3772989511489868,
      "eval_runtime": 126.0267,
      "eval_samples_per_second": 1387.817,
      "eval_steps_per_second": 43.372,
      "step": 50000
    },
    {
      "epoch": 2.0371236302274993,
      "grad_norm": 0.21812637150287628,
      "learning_rate": 0.0004333864471296419,
      "loss": 0.3664,
      "step": 50100
    },
    {
      "epoch": 2.0411897452578933,
      "grad_norm": 0.19611699879169464,
      "learning_rate": 0.0004331651396450228,
      "loss": 0.3637,
      "step": 50200
    },
    {
      "epoch": 2.0452558602882878,
      "grad_norm": 0.18355010449886322,
      "learning_rate": 0.00043294383216040366,
      "loss": 0.3641,
      "step": 50300
    },
    {
      "epoch": 2.0493219753186818,
      "grad_norm": 0.18757832050323486,
      "learning_rate": 0.00043272252467578456,
      "loss": 0.3629,
      "step": 50400
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.21593788266181946,
      "learning_rate": 0.0004325012171911654,
      "loss": 0.3667,
      "step": 50500
    },
    {
      "epoch": 2.05745420537947,
      "grad_norm": 0.18823346495628357,
      "learning_rate": 0.0004322799097065463,
      "loss": 0.3653,
      "step": 50600
    },
    {
      "epoch": 2.061520320409864,
      "grad_norm": 0.2009376734495163,
      "learning_rate": 0.00043205860222192714,
      "loss": 0.3639,
      "step": 50700
    },
    {
      "epoch": 2.0655864354402587,
      "grad_norm": 0.17758575081825256,
      "learning_rate": 0.00043183729473730804,
      "loss": 0.3628,
      "step": 50800
    },
    {
      "epoch": 2.0696525504706527,
      "grad_norm": 0.19725622236728668,
      "learning_rate": 0.00043161598725268894,
      "loss": 0.3657,
      "step": 50900
    },
    {
      "epoch": 2.073718665501047,
      "grad_norm": 0.22755983471870422,
      "learning_rate": 0.0004313946797680698,
      "loss": 0.3643,
      "step": 51000
    },
    {
      "epoch": 2.077784780531441,
      "grad_norm": 0.197858527302742,
      "learning_rate": 0.0004311733722834507,
      "loss": 0.3642,
      "step": 51100
    },
    {
      "epoch": 2.0818508955618356,
      "grad_norm": 0.22340871393680573,
      "learning_rate": 0.00043095206479883147,
      "loss": 0.3644,
      "step": 51200
    },
    {
      "epoch": 2.0859170105922296,
      "grad_norm": 0.2137046456336975,
      "learning_rate": 0.00043073075731421236,
      "loss": 0.3647,
      "step": 51300
    },
    {
      "epoch": 2.089983125622624,
      "grad_norm": 0.1937422901391983,
      "learning_rate": 0.0004305094498295932,
      "loss": 0.3655,
      "step": 51400
    },
    {
      "epoch": 2.094049240653018,
      "grad_norm": 0.19254498183727264,
      "learning_rate": 0.0004302881423449741,
      "loss": 0.3657,
      "step": 51500
    },
    {
      "epoch": 2.0981153556834125,
      "grad_norm": 0.17434121668338776,
      "learning_rate": 0.00043006683486035495,
      "loss": 0.3653,
      "step": 51600
    },
    {
      "epoch": 2.1021814707138065,
      "grad_norm": 0.20164082944393158,
      "learning_rate": 0.00042984552737573584,
      "loss": 0.3657,
      "step": 51700
    },
    {
      "epoch": 2.106247585744201,
      "grad_norm": 0.1696152687072754,
      "learning_rate": 0.00042962421989111674,
      "loss": 0.3628,
      "step": 51800
    },
    {
      "epoch": 2.110313700774595,
      "grad_norm": 0.1932803839445114,
      "learning_rate": 0.0004294029124064976,
      "loss": 0.3652,
      "step": 51900
    },
    {
      "epoch": 2.1143798158049893,
      "grad_norm": 0.21943074464797974,
      "learning_rate": 0.0004291816049218785,
      "loss": 0.3649,
      "step": 52000
    },
    {
      "epoch": 2.1143798158049893,
      "eval_loss": 0.3763289153575897,
      "eval_runtime": 126.4951,
      "eval_samples_per_second": 1382.678,
      "eval_steps_per_second": 43.211,
      "step": 52000
    },
    {
      "epoch": 2.1184459308353834,
      "grad_norm": 0.1832038164138794,
      "learning_rate": 0.0004289602974372593,
      "loss": 0.3644,
      "step": 52100
    },
    {
      "epoch": 2.1225120458657774,
      "grad_norm": 0.22306913137435913,
      "learning_rate": 0.0004287389899526402,
      "loss": 0.3668,
      "step": 52200
    },
    {
      "epoch": 2.126578160896172,
      "grad_norm": 0.18069575726985931,
      "learning_rate": 0.00042851768246802106,
      "loss": 0.3669,
      "step": 52300
    },
    {
      "epoch": 2.130644275926566,
      "grad_norm": 0.19569031894207,
      "learning_rate": 0.00042829637498340196,
      "loss": 0.365,
      "step": 52400
    },
    {
      "epoch": 2.1347103909569602,
      "grad_norm": 0.19910715520381927,
      "learning_rate": 0.00042807506749878286,
      "loss": 0.3638,
      "step": 52500
    },
    {
      "epoch": 2.1387765059873542,
      "grad_norm": 0.22318494319915771,
      "learning_rate": 0.0004278537600141637,
      "loss": 0.3664,
      "step": 52600
    },
    {
      "epoch": 2.1428426210177487,
      "grad_norm": 0.20174464583396912,
      "learning_rate": 0.0004276324525295446,
      "loss": 0.3652,
      "step": 52700
    },
    {
      "epoch": 2.1469087360481427,
      "grad_norm": 0.22012129426002502,
      "learning_rate": 0.00042741114504492544,
      "loss": 0.3626,
      "step": 52800
    },
    {
      "epoch": 2.150974851078537,
      "grad_norm": 0.230416402220726,
      "learning_rate": 0.0004271898375603063,
      "loss": 0.3661,
      "step": 52900
    },
    {
      "epoch": 2.155040966108931,
      "grad_norm": 0.18417759239673615,
      "learning_rate": 0.00042696853007568713,
      "loss": 0.3659,
      "step": 53000
    },
    {
      "epoch": 2.1591070811393256,
      "grad_norm": 0.2107677310705185,
      "learning_rate": 0.000426747222591068,
      "loss": 0.363,
      "step": 53100
    },
    {
      "epoch": 2.1631731961697196,
      "grad_norm": 0.1865079700946808,
      "learning_rate": 0.00042652591510644887,
      "loss": 0.3616,
      "step": 53200
    },
    {
      "epoch": 2.167239311200114,
      "grad_norm": 0.21021558344364166,
      "learning_rate": 0.00042630460762182977,
      "loss": 0.3654,
      "step": 53300
    },
    {
      "epoch": 2.171305426230508,
      "grad_norm": 0.18095846474170685,
      "learning_rate": 0.00042608330013721066,
      "loss": 0.3657,
      "step": 53400
    },
    {
      "epoch": 2.175371541260902,
      "grad_norm": 0.18352608382701874,
      "learning_rate": 0.0004258619926525915,
      "loss": 0.3632,
      "step": 53500
    },
    {
      "epoch": 2.1794376562912965,
      "grad_norm": 0.2096283733844757,
      "learning_rate": 0.0004256406851679724,
      "loss": 0.3635,
      "step": 53600
    },
    {
      "epoch": 2.1835037713216905,
      "grad_norm": 0.21978971362113953,
      "learning_rate": 0.00042541937768335325,
      "loss": 0.3632,
      "step": 53700
    },
    {
      "epoch": 2.187569886352085,
      "grad_norm": 0.18203890323638916,
      "learning_rate": 0.00042519807019873415,
      "loss": 0.3641,
      "step": 53800
    },
    {
      "epoch": 2.191636001382479,
      "grad_norm": 0.18229009211063385,
      "learning_rate": 0.000424976762714115,
      "loss": 0.3665,
      "step": 53900
    },
    {
      "epoch": 2.1957021164128734,
      "grad_norm": 0.20217068493366241,
      "learning_rate": 0.0004247554552294959,
      "loss": 0.3658,
      "step": 54000
    },
    {
      "epoch": 2.1957021164128734,
      "eval_loss": 0.3750028610229492,
      "eval_runtime": 126.4908,
      "eval_samples_per_second": 1382.725,
      "eval_steps_per_second": 43.213,
      "step": 54000
    },
    {
      "epoch": 2.1997682314432674,
      "grad_norm": 0.1826411485671997,
      "learning_rate": 0.00042453414774487673,
      "loss": 0.3637,
      "step": 54100
    },
    {
      "epoch": 2.203834346473662,
      "grad_norm": 0.21290455758571625,
      "learning_rate": 0.0004243128402602576,
      "loss": 0.3649,
      "step": 54200
    },
    {
      "epoch": 2.207900461504056,
      "grad_norm": 0.2048984169960022,
      "learning_rate": 0.0004240915327756385,
      "loss": 0.3641,
      "step": 54300
    },
    {
      "epoch": 2.2119665765344503,
      "grad_norm": 0.21925151348114014,
      "learning_rate": 0.00042387022529101937,
      "loss": 0.3632,
      "step": 54400
    },
    {
      "epoch": 2.2160326915648443,
      "grad_norm": 0.18642261624336243,
      "learning_rate": 0.00042364891780640026,
      "loss": 0.3644,
      "step": 54500
    },
    {
      "epoch": 2.2200988065952387,
      "grad_norm": 0.18141548335552216,
      "learning_rate": 0.00042342761032178105,
      "loss": 0.3649,
      "step": 54600
    },
    {
      "epoch": 2.2241649216256327,
      "grad_norm": 0.2015015184879303,
      "learning_rate": 0.00042320630283716195,
      "loss": 0.366,
      "step": 54700
    },
    {
      "epoch": 2.228231036656027,
      "grad_norm": 0.21037447452545166,
      "learning_rate": 0.0004229849953525428,
      "loss": 0.3637,
      "step": 54800
    },
    {
      "epoch": 2.232297151686421,
      "grad_norm": 0.18016164004802704,
      "learning_rate": 0.0004227636878679237,
      "loss": 0.3666,
      "step": 54900
    },
    {
      "epoch": 2.2363632667168156,
      "grad_norm": 0.2232646346092224,
      "learning_rate": 0.00042254238038330453,
      "loss": 0.3659,
      "step": 55000
    },
    {
      "epoch": 2.2404293817472096,
      "grad_norm": 0.19609320163726807,
      "learning_rate": 0.00042232107289868543,
      "loss": 0.3637,
      "step": 55100
    },
    {
      "epoch": 2.2444954967776036,
      "grad_norm": 0.21319130063056946,
      "learning_rate": 0.00042209976541406633,
      "loss": 0.3626,
      "step": 55200
    },
    {
      "epoch": 2.248561611807998,
      "grad_norm": 0.17771537601947784,
      "learning_rate": 0.00042187845792944717,
      "loss": 0.3624,
      "step": 55300
    },
    {
      "epoch": 2.252627726838392,
      "grad_norm": 0.2080247700214386,
      "learning_rate": 0.00042165715044482807,
      "loss": 0.3651,
      "step": 55400
    },
    {
      "epoch": 2.2566938418687865,
      "grad_norm": 0.2506634593009949,
      "learning_rate": 0.0004214358429602089,
      "loss": 0.365,
      "step": 55500
    },
    {
      "epoch": 2.2607599568991805,
      "grad_norm": 0.19424982368946075,
      "learning_rate": 0.0004212145354755898,
      "loss": 0.3639,
      "step": 55600
    },
    {
      "epoch": 2.264826071929575,
      "grad_norm": 0.2091737538576126,
      "learning_rate": 0.00042099322799097065,
      "loss": 0.3644,
      "step": 55700
    },
    {
      "epoch": 2.268892186959969,
      "grad_norm": 0.1799652874469757,
      "learning_rate": 0.00042077192050635155,
      "loss": 0.3655,
      "step": 55800
    },
    {
      "epoch": 2.2729583019903634,
      "grad_norm": 0.19960670173168182,
      "learning_rate": 0.00042055061302173245,
      "loss": 0.3649,
      "step": 55900
    },
    {
      "epoch": 2.2770244170207574,
      "grad_norm": 0.20657753944396973,
      "learning_rate": 0.0004203293055371133,
      "loss": 0.3655,
      "step": 56000
    },
    {
      "epoch": 2.2770244170207574,
      "eval_loss": 0.3754572570323944,
      "eval_runtime": 126.1608,
      "eval_samples_per_second": 1386.342,
      "eval_steps_per_second": 43.326,
      "step": 56000
    },
    {
      "epoch": 2.281090532051152,
      "grad_norm": 0.22227729856967926,
      "learning_rate": 0.0004201079980524942,
      "loss": 0.3656,
      "step": 56100
    },
    {
      "epoch": 2.285156647081546,
      "grad_norm": 0.23162008821964264,
      "learning_rate": 0.00041988669056787503,
      "loss": 0.3638,
      "step": 56200
    },
    {
      "epoch": 2.2892227621119403,
      "grad_norm": 0.20652738213539124,
      "learning_rate": 0.0004196653830832559,
      "loss": 0.3628,
      "step": 56300
    },
    {
      "epoch": 2.2932888771423343,
      "grad_norm": 0.23423299193382263,
      "learning_rate": 0.0004194440755986367,
      "loss": 0.3636,
      "step": 56400
    },
    {
      "epoch": 2.2973549921727288,
      "grad_norm": 0.20432406663894653,
      "learning_rate": 0.0004192227681140176,
      "loss": 0.3655,
      "step": 56500
    },
    {
      "epoch": 2.3014211072031228,
      "grad_norm": 0.21241047978401184,
      "learning_rate": 0.00041900146062939846,
      "loss": 0.366,
      "step": 56600
    },
    {
      "epoch": 2.305487222233517,
      "grad_norm": 0.20812256634235382,
      "learning_rate": 0.00041878015314477935,
      "loss": 0.3642,
      "step": 56700
    },
    {
      "epoch": 2.309553337263911,
      "grad_norm": 0.22518333792686462,
      "learning_rate": 0.00041855884566016025,
      "loss": 0.3637,
      "step": 56800
    },
    {
      "epoch": 2.313619452294305,
      "grad_norm": 0.20498672127723694,
      "learning_rate": 0.0004183375381755411,
      "loss": 0.3641,
      "step": 56900
    },
    {
      "epoch": 2.3176855673246997,
      "grad_norm": 0.20365774631500244,
      "learning_rate": 0.000418116230690922,
      "loss": 0.3662,
      "step": 57000
    },
    {
      "epoch": 2.3217516823550937,
      "grad_norm": 0.18944407999515533,
      "learning_rate": 0.00041789492320630284,
      "loss": 0.3647,
      "step": 57100
    },
    {
      "epoch": 2.325817797385488,
      "grad_norm": 0.21926331520080566,
      "learning_rate": 0.00041767361572168373,
      "loss": 0.3652,
      "step": 57200
    },
    {
      "epoch": 2.329883912415882,
      "grad_norm": 0.20010621845722198,
      "learning_rate": 0.0004174523082370646,
      "loss": 0.3665,
      "step": 57300
    },
    {
      "epoch": 2.3339500274462766,
      "grad_norm": 0.1858905553817749,
      "learning_rate": 0.0004172310007524455,
      "loss": 0.3617,
      "step": 57400
    },
    {
      "epoch": 2.3380161424766706,
      "grad_norm": 0.22192241251468658,
      "learning_rate": 0.0004170096932678263,
      "loss": 0.3658,
      "step": 57500
    },
    {
      "epoch": 2.342082257507065,
      "grad_norm": 0.23407365381717682,
      "learning_rate": 0.0004167883857832072,
      "loss": 0.3657,
      "step": 57600
    },
    {
      "epoch": 2.346148372537459,
      "grad_norm": 0.2374803125858307,
      "learning_rate": 0.0004165670782985881,
      "loss": 0.3641,
      "step": 57700
    },
    {
      "epoch": 2.3502144875678534,
      "grad_norm": 0.2118815928697586,
      "learning_rate": 0.00041634577081396895,
      "loss": 0.3647,
      "step": 57800
    },
    {
      "epoch": 2.3542806025982475,
      "grad_norm": 0.18712963163852692,
      "learning_rate": 0.00041612446332934985,
      "loss": 0.3616,
      "step": 57900
    },
    {
      "epoch": 2.358346717628642,
      "grad_norm": 0.2088554948568344,
      "learning_rate": 0.00041590315584473064,
      "loss": 0.3621,
      "step": 58000
    },
    {
      "epoch": 2.358346717628642,
      "eval_loss": 0.3735469877719879,
      "eval_runtime": 126.6035,
      "eval_samples_per_second": 1381.494,
      "eval_steps_per_second": 43.174,
      "step": 58000
    },
    {
      "epoch": 2.362412832659036,
      "grad_norm": 0.20765085518360138,
      "learning_rate": 0.00041568184836011154,
      "loss": 0.3663,
      "step": 58100
    },
    {
      "epoch": 2.36647894768943,
      "grad_norm": 0.2150176614522934,
      "learning_rate": 0.0004154605408754924,
      "loss": 0.3622,
      "step": 58200
    },
    {
      "epoch": 2.3705450627198243,
      "grad_norm": 0.21117371320724487,
      "learning_rate": 0.0004152392333908733,
      "loss": 0.3651,
      "step": 58300
    },
    {
      "epoch": 2.374611177750219,
      "grad_norm": 0.20622457563877106,
      "learning_rate": 0.0004150179259062541,
      "loss": 0.3621,
      "step": 58400
    },
    {
      "epoch": 2.378677292780613,
      "grad_norm": 0.21640516817569733,
      "learning_rate": 0.000414796618421635,
      "loss": 0.3671,
      "step": 58500
    },
    {
      "epoch": 2.382743407811007,
      "grad_norm": 0.22378969192504883,
      "learning_rate": 0.0004145753109370159,
      "loss": 0.3646,
      "step": 58600
    },
    {
      "epoch": 2.3868095228414012,
      "grad_norm": 0.24320374429225922,
      "learning_rate": 0.00041435400345239676,
      "loss": 0.36,
      "step": 58700
    },
    {
      "epoch": 2.3908756378717952,
      "grad_norm": 0.21170321106910706,
      "learning_rate": 0.00041413269596777766,
      "loss": 0.3674,
      "step": 58800
    },
    {
      "epoch": 2.3949417529021897,
      "grad_norm": 0.2226417064666748,
      "learning_rate": 0.0004139113884831585,
      "loss": 0.3642,
      "step": 58900
    },
    {
      "epoch": 2.3990078679325837,
      "grad_norm": 0.20096974074840546,
      "learning_rate": 0.0004136900809985394,
      "loss": 0.3636,
      "step": 59000
    },
    {
      "epoch": 2.403073982962978,
      "grad_norm": 0.21537967026233673,
      "learning_rate": 0.00041346877351392024,
      "loss": 0.3629,
      "step": 59100
    },
    {
      "epoch": 2.407140097993372,
      "grad_norm": 0.20026442408561707,
      "learning_rate": 0.00041324746602930114,
      "loss": 0.3651,
      "step": 59200
    },
    {
      "epoch": 2.4112062130237666,
      "grad_norm": 0.20591184496879578,
      "learning_rate": 0.000413026158544682,
      "loss": 0.3636,
      "step": 59300
    },
    {
      "epoch": 2.4152723280541606,
      "grad_norm": 0.2104000300168991,
      "learning_rate": 0.0004128048510600629,
      "loss": 0.3634,
      "step": 59400
    },
    {
      "epoch": 2.419338443084555,
      "grad_norm": 0.20205022394657135,
      "learning_rate": 0.0004125835435754438,
      "loss": 0.3635,
      "step": 59500
    },
    {
      "epoch": 2.423404558114949,
      "grad_norm": 0.21537107229232788,
      "learning_rate": 0.0004123622360908246,
      "loss": 0.3646,
      "step": 59600
    },
    {
      "epoch": 2.4274706731453435,
      "grad_norm": 0.24804569780826569,
      "learning_rate": 0.00041214092860620546,
      "loss": 0.3634,
      "step": 59700
    },
    {
      "epoch": 2.4315367881757375,
      "grad_norm": 0.20438306033611298,
      "learning_rate": 0.0004119196211215863,
      "loss": 0.3625,
      "step": 59800
    },
    {
      "epoch": 2.4356029032061315,
      "grad_norm": 0.20246879756450653,
      "learning_rate": 0.0004116983136369672,
      "loss": 0.3628,
      "step": 59900
    },
    {
      "epoch": 2.439669018236526,
      "grad_norm": 0.27633243799209595,
      "learning_rate": 0.00041147700615234804,
      "loss": 0.3639,
      "step": 60000
    },
    {
      "epoch": 2.439669018236526,
      "eval_loss": 0.3731519877910614,
      "eval_runtime": 126.8595,
      "eval_samples_per_second": 1378.707,
      "eval_steps_per_second": 43.087,
      "step": 60000
    },
    {
      "epoch": 2.44373513326692,
      "grad_norm": 0.23765616118907928,
      "learning_rate": 0.00041125569866772894,
      "loss": 0.3617,
      "step": 60100
    },
    {
      "epoch": 2.4478012482973144,
      "grad_norm": 0.2220282256603241,
      "learning_rate": 0.00041103439118310984,
      "loss": 0.3658,
      "step": 60200
    },
    {
      "epoch": 2.4518673633277084,
      "grad_norm": 0.20390161871910095,
      "learning_rate": 0.0004108130836984907,
      "loss": 0.3618,
      "step": 60300
    },
    {
      "epoch": 2.455933478358103,
      "grad_norm": 0.23456931114196777,
      "learning_rate": 0.0004105917762138716,
      "loss": 0.3622,
      "step": 60400
    },
    {
      "epoch": 2.459999593388497,
      "grad_norm": 0.25006264448165894,
      "learning_rate": 0.0004103704687292524,
      "loss": 0.3629,
      "step": 60500
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 0.22942939400672913,
      "learning_rate": 0.0004101491612446333,
      "loss": 0.3636,
      "step": 60600
    },
    {
      "epoch": 2.4681318234492853,
      "grad_norm": 0.2027585357427597,
      "learning_rate": 0.00040992785376001416,
      "loss": 0.3627,
      "step": 60700
    },
    {
      "epoch": 2.4721979384796797,
      "grad_norm": 0.26068180799484253,
      "learning_rate": 0.00040970654627539506,
      "loss": 0.3629,
      "step": 60800
    },
    {
      "epoch": 2.4762640535100737,
      "grad_norm": 0.23776471614837646,
      "learning_rate": 0.0004094852387907759,
      "loss": 0.3634,
      "step": 60900
    },
    {
      "epoch": 2.480330168540468,
      "grad_norm": 0.328708291053772,
      "learning_rate": 0.0004092639313061568,
      "loss": 0.3622,
      "step": 61000
    },
    {
      "epoch": 2.484396283570862,
      "grad_norm": 0.23132994771003723,
      "learning_rate": 0.0004090426238215377,
      "loss": 0.3651,
      "step": 61100
    },
    {
      "epoch": 2.4884623986012566,
      "grad_norm": 0.23242521286010742,
      "learning_rate": 0.00040882131633691854,
      "loss": 0.3637,
      "step": 61200
    },
    {
      "epoch": 2.4925285136316506,
      "grad_norm": 0.21505649387836456,
      "learning_rate": 0.00040860000885229944,
      "loss": 0.3636,
      "step": 61300
    },
    {
      "epoch": 2.496594628662045,
      "grad_norm": 0.2035072147846222,
      "learning_rate": 0.00040837870136768023,
      "loss": 0.3628,
      "step": 61400
    },
    {
      "epoch": 2.500660743692439,
      "grad_norm": 0.2292376607656479,
      "learning_rate": 0.0004081573938830611,
      "loss": 0.3626,
      "step": 61500
    },
    {
      "epoch": 2.504726858722833,
      "grad_norm": 0.2153841108083725,
      "learning_rate": 0.00040793608639844197,
      "loss": 0.3641,
      "step": 61600
    },
    {
      "epoch": 2.5087929737532275,
      "grad_norm": 0.20469839870929718,
      "learning_rate": 0.00040771477891382287,
      "loss": 0.3626,
      "step": 61700
    },
    {
      "epoch": 2.512859088783622,
      "grad_norm": 0.18464213609695435,
      "learning_rate": 0.0004074934714292037,
      "loss": 0.3627,
      "step": 61800
    },
    {
      "epoch": 2.516925203814016,
      "grad_norm": 0.2044418752193451,
      "learning_rate": 0.0004072721639445846,
      "loss": 0.3625,
      "step": 61900
    },
    {
      "epoch": 2.52099131884441,
      "grad_norm": 0.2126132845878601,
      "learning_rate": 0.0004070508564599655,
      "loss": 0.3628,
      "step": 62000
    },
    {
      "epoch": 2.52099131884441,
      "eval_loss": 0.37268635630607605,
      "eval_runtime": 126.8029,
      "eval_samples_per_second": 1379.322,
      "eval_steps_per_second": 43.106,
      "step": 62000
    },
    {
      "epoch": 2.5250574338748044,
      "grad_norm": 0.21362362802028656,
      "learning_rate": 0.00040682954897534635,
      "loss": 0.3637,
      "step": 62100
    },
    {
      "epoch": 2.5291235489051984,
      "grad_norm": 0.2037048488855362,
      "learning_rate": 0.00040660824149072724,
      "loss": 0.3627,
      "step": 62200
    },
    {
      "epoch": 2.533189663935593,
      "grad_norm": 0.24935638904571533,
      "learning_rate": 0.0004063869340061081,
      "loss": 0.3626,
      "step": 62300
    },
    {
      "epoch": 2.537255778965987,
      "grad_norm": 0.23130282759666443,
      "learning_rate": 0.000406165626521489,
      "loss": 0.3653,
      "step": 62400
    },
    {
      "epoch": 2.5413218939963813,
      "grad_norm": 0.20008176565170288,
      "learning_rate": 0.00040594431903686983,
      "loss": 0.3633,
      "step": 62500
    },
    {
      "epoch": 2.5453880090267753,
      "grad_norm": 0.2060409039258957,
      "learning_rate": 0.0004057230115522507,
      "loss": 0.3623,
      "step": 62600
    },
    {
      "epoch": 2.5494541240571698,
      "grad_norm": 0.22174322605133057,
      "learning_rate": 0.00040550170406763157,
      "loss": 0.3631,
      "step": 62700
    },
    {
      "epoch": 2.5535202390875638,
      "grad_norm": 0.2047194540500641,
      "learning_rate": 0.00040528039658301246,
      "loss": 0.3632,
      "step": 62800
    },
    {
      "epoch": 2.5575863541179578,
      "grad_norm": 0.2365574687719345,
      "learning_rate": 0.00040505908909839336,
      "loss": 0.3636,
      "step": 62900
    },
    {
      "epoch": 2.561652469148352,
      "grad_norm": 0.19965817034244537,
      "learning_rate": 0.00040483778161377415,
      "loss": 0.3642,
      "step": 63000
    },
    {
      "epoch": 2.5657185841787467,
      "grad_norm": 0.23658692836761475,
      "learning_rate": 0.00040461647412915505,
      "loss": 0.3617,
      "step": 63100
    },
    {
      "epoch": 2.5697846992091407,
      "grad_norm": 0.23205512762069702,
      "learning_rate": 0.0004043951666445359,
      "loss": 0.363,
      "step": 63200
    },
    {
      "epoch": 2.5738508142395347,
      "grad_norm": 0.2681090533733368,
      "learning_rate": 0.0004041738591599168,
      "loss": 0.3624,
      "step": 63300
    },
    {
      "epoch": 2.577916929269929,
      "grad_norm": 0.21207311749458313,
      "learning_rate": 0.00040395255167529763,
      "loss": 0.3635,
      "step": 63400
    },
    {
      "epoch": 2.581983044300323,
      "grad_norm": 0.21043351292610168,
      "learning_rate": 0.00040373124419067853,
      "loss": 0.3626,
      "step": 63500
    },
    {
      "epoch": 2.5860491593307176,
      "grad_norm": 0.2348208725452423,
      "learning_rate": 0.00040350993670605937,
      "loss": 0.3629,
      "step": 63600
    },
    {
      "epoch": 2.5901152743611116,
      "grad_norm": 0.2240297943353653,
      "learning_rate": 0.00040328862922144027,
      "loss": 0.3618,
      "step": 63700
    },
    {
      "epoch": 2.594181389391506,
      "grad_norm": 0.2161559760570526,
      "learning_rate": 0.00040306732173682117,
      "loss": 0.3642,
      "step": 63800
    },
    {
      "epoch": 2.5982475044219,
      "grad_norm": 0.22969353199005127,
      "learning_rate": 0.000402846014252202,
      "loss": 0.364,
      "step": 63900
    },
    {
      "epoch": 2.6023136194522944,
      "grad_norm": 0.19417646527290344,
      "learning_rate": 0.0004026247067675829,
      "loss": 0.3619,
      "step": 64000
    },
    {
      "epoch": 2.6023136194522944,
      "eval_loss": 0.3723039925098419,
      "eval_runtime": 126.2072,
      "eval_samples_per_second": 1385.833,
      "eval_steps_per_second": 43.31,
      "step": 64000
    },
    {
      "epoch": 2.6063797344826884,
      "grad_norm": 0.23226740956306458,
      "learning_rate": 0.00040240339928296375,
      "loss": 0.3624,
      "step": 64100
    },
    {
      "epoch": 2.6104458495130825,
      "grad_norm": 0.2093822956085205,
      "learning_rate": 0.00040218209179834465,
      "loss": 0.3632,
      "step": 64200
    },
    {
      "epoch": 2.614511964543477,
      "grad_norm": 0.21730877459049225,
      "learning_rate": 0.0004019607843137255,
      "loss": 0.3628,
      "step": 64300
    },
    {
      "epoch": 2.6185780795738713,
      "grad_norm": 0.24048607051372528,
      "learning_rate": 0.0004017394768291064,
      "loss": 0.363,
      "step": 64400
    },
    {
      "epoch": 2.6226441946042653,
      "grad_norm": 0.19686481356620789,
      "learning_rate": 0.0004015181693444873,
      "loss": 0.3636,
      "step": 64500
    },
    {
      "epoch": 2.6267103096346593,
      "grad_norm": 0.25639423727989197,
      "learning_rate": 0.00040129686185986813,
      "loss": 0.3635,
      "step": 64600
    },
    {
      "epoch": 2.630776424665054,
      "grad_norm": 0.19706107676029205,
      "learning_rate": 0.00040107555437524897,
      "loss": 0.3641,
      "step": 64700
    },
    {
      "epoch": 2.6348425396954482,
      "grad_norm": 0.23326319456100464,
      "learning_rate": 0.0004008542468906298,
      "loss": 0.3606,
      "step": 64800
    },
    {
      "epoch": 2.6389086547258422,
      "grad_norm": 0.21795247495174408,
      "learning_rate": 0.0004006329394060107,
      "loss": 0.3602,
      "step": 64900
    },
    {
      "epoch": 2.6429747697562362,
      "grad_norm": 0.23332104086875916,
      "learning_rate": 0.00040041163192139156,
      "loss": 0.3626,
      "step": 65000
    },
    {
      "epoch": 2.6470408847866307,
      "grad_norm": 0.2253662645816803,
      "learning_rate": 0.00040019032443677245,
      "loss": 0.363,
      "step": 65100
    },
    {
      "epoch": 2.6511069998170247,
      "grad_norm": 0.28623202443122864,
      "learning_rate": 0.0003999690169521533,
      "loss": 0.3629,
      "step": 65200
    },
    {
      "epoch": 2.655173114847419,
      "grad_norm": 0.20080941915512085,
      "learning_rate": 0.0003997477094675342,
      "loss": 0.3629,
      "step": 65300
    },
    {
      "epoch": 2.659239229877813,
      "grad_norm": 0.21882875263690948,
      "learning_rate": 0.0003995264019829151,
      "loss": 0.363,
      "step": 65400
    },
    {
      "epoch": 2.6633053449082076,
      "grad_norm": 0.19934433698654175,
      "learning_rate": 0.00039930509449829593,
      "loss": 0.3637,
      "step": 65500
    },
    {
      "epoch": 2.6673714599386016,
      "grad_norm": 0.21095003187656403,
      "learning_rate": 0.00039908378701367683,
      "loss": 0.3614,
      "step": 65600
    },
    {
      "epoch": 2.671437574968996,
      "grad_norm": 0.2697962820529938,
      "learning_rate": 0.0003988624795290577,
      "loss": 0.3617,
      "step": 65700
    },
    {
      "epoch": 2.67550368999939,
      "grad_norm": 0.2425641119480133,
      "learning_rate": 0.00039864117204443857,
      "loss": 0.364,
      "step": 65800
    },
    {
      "epoch": 2.679569805029784,
      "grad_norm": 0.22229896485805511,
      "learning_rate": 0.0003984198645598194,
      "loss": 0.3608,
      "step": 65900
    },
    {
      "epoch": 2.6836359200601785,
      "grad_norm": 0.21967987716197968,
      "learning_rate": 0.0003981985570752003,
      "loss": 0.364,
      "step": 66000
    },
    {
      "epoch": 2.6836359200601785,
      "eval_loss": 0.3715237081050873,
      "eval_runtime": 126.5506,
      "eval_samples_per_second": 1382.071,
      "eval_steps_per_second": 43.192,
      "step": 66000
    },
    {
      "epoch": 2.687702035090573,
      "grad_norm": 0.21846839785575867,
      "learning_rate": 0.00039797724959058116,
      "loss": 0.3622,
      "step": 66100
    },
    {
      "epoch": 2.691768150120967,
      "grad_norm": 0.2415846437215805,
      "learning_rate": 0.00039775594210596205,
      "loss": 0.3632,
      "step": 66200
    },
    {
      "epoch": 2.695834265151361,
      "grad_norm": 0.20734752714633942,
      "learning_rate": 0.00039753463462134295,
      "loss": 0.3607,
      "step": 66300
    },
    {
      "epoch": 2.6999003801817554,
      "grad_norm": 0.23500032722949982,
      "learning_rate": 0.00039731332713672374,
      "loss": 0.362,
      "step": 66400
    },
    {
      "epoch": 2.70396649521215,
      "grad_norm": 0.24535854160785675,
      "learning_rate": 0.00039709201965210464,
      "loss": 0.3634,
      "step": 66500
    },
    {
      "epoch": 2.708032610242544,
      "grad_norm": 0.2371380627155304,
      "learning_rate": 0.0003968707121674855,
      "loss": 0.3617,
      "step": 66600
    },
    {
      "epoch": 2.712098725272938,
      "grad_norm": 0.21479801833629608,
      "learning_rate": 0.0003966494046828664,
      "loss": 0.3624,
      "step": 66700
    },
    {
      "epoch": 2.7161648403033323,
      "grad_norm": 0.23782828450202942,
      "learning_rate": 0.0003964280971982472,
      "loss": 0.362,
      "step": 66800
    },
    {
      "epoch": 2.7202309553337263,
      "grad_norm": 0.22610314190387726,
      "learning_rate": 0.0003962067897136281,
      "loss": 0.3626,
      "step": 66900
    },
    {
      "epoch": 2.7242970703641207,
      "grad_norm": 0.23050643503665924,
      "learning_rate": 0.00039598548222900896,
      "loss": 0.3624,
      "step": 67000
    },
    {
      "epoch": 2.7283631853945147,
      "grad_norm": 0.2216217964887619,
      "learning_rate": 0.00039576417474438986,
      "loss": 0.361,
      "step": 67100
    },
    {
      "epoch": 2.732429300424909,
      "grad_norm": 0.21712249517440796,
      "learning_rate": 0.00039554286725977075,
      "loss": 0.3622,
      "step": 67200
    },
    {
      "epoch": 2.736495415455303,
      "grad_norm": 0.2469506859779358,
      "learning_rate": 0.0003953215597751516,
      "loss": 0.3621,
      "step": 67300
    },
    {
      "epoch": 2.7405615304856976,
      "grad_norm": 0.31032946705818176,
      "learning_rate": 0.0003951002522905325,
      "loss": 0.3618,
      "step": 67400
    },
    {
      "epoch": 2.7446276455160916,
      "grad_norm": 0.24900928139686584,
      "learning_rate": 0.00039487894480591334,
      "loss": 0.3632,
      "step": 67500
    },
    {
      "epoch": 2.7486937605464856,
      "grad_norm": 0.24308879673480988,
      "learning_rate": 0.00039465763732129424,
      "loss": 0.364,
      "step": 67600
    },
    {
      "epoch": 2.75275987557688,
      "grad_norm": 0.2237519919872284,
      "learning_rate": 0.0003944363298366751,
      "loss": 0.3621,
      "step": 67700
    },
    {
      "epoch": 2.7568259906072745,
      "grad_norm": 0.26846620440483093,
      "learning_rate": 0.000394215022352056,
      "loss": 0.3626,
      "step": 67800
    },
    {
      "epoch": 2.7608921056376685,
      "grad_norm": 0.25207415223121643,
      "learning_rate": 0.0003939937148674369,
      "loss": 0.3618,
      "step": 67900
    },
    {
      "epoch": 2.7649582206680625,
      "grad_norm": 0.2680240273475647,
      "learning_rate": 0.0003937724073828177,
      "loss": 0.3631,
      "step": 68000
    },
    {
      "epoch": 2.7649582206680625,
      "eval_loss": 0.3714894950389862,
      "eval_runtime": 126.5241,
      "eval_samples_per_second": 1382.361,
      "eval_steps_per_second": 43.201,
      "step": 68000
    },
    {
      "epoch": 2.769024335698457,
      "grad_norm": 0.2193501591682434,
      "learning_rate": 0.00039355109989819856,
      "loss": 0.3619,
      "step": 68100
    },
    {
      "epoch": 2.773090450728851,
      "grad_norm": 0.26636233925819397,
      "learning_rate": 0.0003933297924135794,
      "loss": 0.3626,
      "step": 68200
    },
    {
      "epoch": 2.7771565657592454,
      "grad_norm": 0.24004150927066803,
      "learning_rate": 0.0003931084849289603,
      "loss": 0.3585,
      "step": 68300
    },
    {
      "epoch": 2.7812226807896394,
      "grad_norm": 0.31194165349006653,
      "learning_rate": 0.00039288717744434114,
      "loss": 0.3611,
      "step": 68400
    },
    {
      "epoch": 2.785288795820034,
      "grad_norm": 0.23379842936992645,
      "learning_rate": 0.00039266586995972204,
      "loss": 0.3623,
      "step": 68500
    },
    {
      "epoch": 2.789354910850428,
      "grad_norm": 0.27376630902290344,
      "learning_rate": 0.0003924445624751029,
      "loss": 0.3642,
      "step": 68600
    },
    {
      "epoch": 2.7934210258808223,
      "grad_norm": 0.24385902285575867,
      "learning_rate": 0.0003922232549904838,
      "loss": 0.3624,
      "step": 68700
    },
    {
      "epoch": 2.7974871409112163,
      "grad_norm": 0.21764369308948517,
      "learning_rate": 0.0003920019475058647,
      "loss": 0.3622,
      "step": 68800
    },
    {
      "epoch": 2.8015532559416108,
      "grad_norm": 0.24149756133556366,
      "learning_rate": 0.0003917806400212455,
      "loss": 0.3642,
      "step": 68900
    },
    {
      "epoch": 2.8056193709720048,
      "grad_norm": 0.2762143611907959,
      "learning_rate": 0.0003915593325366264,
      "loss": 0.3629,
      "step": 69000
    },
    {
      "epoch": 2.809685486002399,
      "grad_norm": 0.20721744000911713,
      "learning_rate": 0.00039133802505200726,
      "loss": 0.3613,
      "step": 69100
    },
    {
      "epoch": 2.813751601032793,
      "grad_norm": 0.2700294256210327,
      "learning_rate": 0.00039111671756738816,
      "loss": 0.3627,
      "step": 69200
    },
    {
      "epoch": 2.817817716063187,
      "grad_norm": 0.24805863201618195,
      "learning_rate": 0.000390895410082769,
      "loss": 0.363,
      "step": 69300
    },
    {
      "epoch": 2.8218838310935817,
      "grad_norm": 0.25742506980895996,
      "learning_rate": 0.0003906741025981499,
      "loss": 0.3619,
      "step": 69400
    },
    {
      "epoch": 2.825949946123976,
      "grad_norm": 0.24052217602729797,
      "learning_rate": 0.00039045279511353074,
      "loss": 0.3606,
      "step": 69500
    },
    {
      "epoch": 2.83001606115437,
      "grad_norm": 0.26452627778053284,
      "learning_rate": 0.00039023148762891164,
      "loss": 0.3605,
      "step": 69600
    },
    {
      "epoch": 2.834082176184764,
      "grad_norm": 0.27381572127342224,
      "learning_rate": 0.00039001018014429254,
      "loss": 0.3628,
      "step": 69700
    },
    {
      "epoch": 2.8381482912151585,
      "grad_norm": 0.23135879635810852,
      "learning_rate": 0.0003897888726596733,
      "loss": 0.3619,
      "step": 69800
    },
    {
      "epoch": 2.8422144062455525,
      "grad_norm": 0.23064342141151428,
      "learning_rate": 0.0003895675651750542,
      "loss": 0.362,
      "step": 69900
    },
    {
      "epoch": 2.846280521275947,
      "grad_norm": 0.23455679416656494,
      "learning_rate": 0.00038934625769043507,
      "loss": 0.3597,
      "step": 70000
    },
    {
      "epoch": 2.846280521275947,
      "eval_loss": 0.3708280026912689,
      "eval_runtime": 126.2317,
      "eval_samples_per_second": 1385.564,
      "eval_steps_per_second": 43.301,
      "step": 70000
    },
    {
      "epoch": 2.850346636306341,
      "grad_norm": 0.22285059094429016,
      "learning_rate": 0.00038912495020581596,
      "loss": 0.3638,
      "step": 70100
    },
    {
      "epoch": 2.8544127513367354,
      "grad_norm": 0.24282698333263397,
      "learning_rate": 0.0003889036427211968,
      "loss": 0.3613,
      "step": 70200
    },
    {
      "epoch": 2.8584788663671294,
      "grad_norm": 0.22561587393283844,
      "learning_rate": 0.0003886823352365777,
      "loss": 0.3622,
      "step": 70300
    },
    {
      "epoch": 2.862544981397524,
      "grad_norm": 0.24012184143066406,
      "learning_rate": 0.00038846102775195855,
      "loss": 0.3605,
      "step": 70400
    },
    {
      "epoch": 2.866611096427918,
      "grad_norm": 0.2256818264722824,
      "learning_rate": 0.00038823972026733944,
      "loss": 0.3614,
      "step": 70500
    },
    {
      "epoch": 2.870677211458312,
      "grad_norm": 0.23922783136367798,
      "learning_rate": 0.00038801841278272034,
      "loss": 0.3639,
      "step": 70600
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 0.2382987141609192,
      "learning_rate": 0.0003877971052981012,
      "loss": 0.3609,
      "step": 70700
    },
    {
      "epoch": 2.878809441519101,
      "grad_norm": 0.26683223247528076,
      "learning_rate": 0.0003875757978134821,
      "loss": 0.3634,
      "step": 70800
    },
    {
      "epoch": 2.882875556549495,
      "grad_norm": 0.2496267408132553,
      "learning_rate": 0.0003873544903288629,
      "loss": 0.3609,
      "step": 70900
    },
    {
      "epoch": 2.886941671579889,
      "grad_norm": 0.22403602302074432,
      "learning_rate": 0.0003871331828442438,
      "loss": 0.3635,
      "step": 71000
    },
    {
      "epoch": 2.8910077866102832,
      "grad_norm": 0.2430403232574463,
      "learning_rate": 0.00038691187535962467,
      "loss": 0.3604,
      "step": 71100
    },
    {
      "epoch": 2.8950739016406777,
      "grad_norm": 0.23293112218379974,
      "learning_rate": 0.00038669056787500556,
      "loss": 0.3617,
      "step": 71200
    },
    {
      "epoch": 2.8991400166710717,
      "grad_norm": 0.25271573662757874,
      "learning_rate": 0.00038646926039038646,
      "loss": 0.3617,
      "step": 71300
    },
    {
      "epoch": 2.9032061317014657,
      "grad_norm": 0.2737894654273987,
      "learning_rate": 0.0003862479529057673,
      "loss": 0.3604,
      "step": 71400
    },
    {
      "epoch": 2.90727224673186,
      "grad_norm": 0.29347869753837585,
      "learning_rate": 0.00038602664542114815,
      "loss": 0.3634,
      "step": 71500
    },
    {
      "epoch": 2.911338361762254,
      "grad_norm": 0.25347620248794556,
      "learning_rate": 0.000385805337936529,
      "loss": 0.3622,
      "step": 71600
    },
    {
      "epoch": 2.9154044767926486,
      "grad_norm": 0.21382726728916168,
      "learning_rate": 0.0003855840304519099,
      "loss": 0.3594,
      "step": 71700
    },
    {
      "epoch": 2.9194705918230426,
      "grad_norm": 0.24672164022922516,
      "learning_rate": 0.00038536272296729073,
      "loss": 0.3614,
      "step": 71800
    },
    {
      "epoch": 2.923536706853437,
      "grad_norm": 0.27122238278388977,
      "learning_rate": 0.00038514141548267163,
      "loss": 0.3606,
      "step": 71900
    },
    {
      "epoch": 2.927602821883831,
      "grad_norm": 0.24020227789878845,
      "learning_rate": 0.00038492010799805247,
      "loss": 0.3618,
      "step": 72000
    },
    {
      "epoch": 2.927602821883831,
      "eval_loss": 0.3702845573425293,
      "eval_runtime": 126.5519,
      "eval_samples_per_second": 1382.058,
      "eval_steps_per_second": 43.192,
      "step": 72000
    },
    {
      "epoch": 2.9316689369142255,
      "grad_norm": 0.28179097175598145,
      "learning_rate": 0.00038469880051343337,
      "loss": 0.3597,
      "step": 72100
    },
    {
      "epoch": 2.9357350519446195,
      "grad_norm": 0.22076064348220825,
      "learning_rate": 0.00038447749302881427,
      "loss": 0.3607,
      "step": 72200
    },
    {
      "epoch": 2.9398011669750135,
      "grad_norm": 0.26725637912750244,
      "learning_rate": 0.0003842561855441951,
      "loss": 0.36,
      "step": 72300
    },
    {
      "epoch": 2.943867282005408,
      "grad_norm": 0.24253930151462555,
      "learning_rate": 0.000384034878059576,
      "loss": 0.3614,
      "step": 72400
    },
    {
      "epoch": 2.9479333970358024,
      "grad_norm": 0.30798467993736267,
      "learning_rate": 0.00038381357057495685,
      "loss": 0.359,
      "step": 72500
    },
    {
      "epoch": 2.9519995120661964,
      "grad_norm": 0.28464728593826294,
      "learning_rate": 0.00038359226309033775,
      "loss": 0.3612,
      "step": 72600
    },
    {
      "epoch": 2.9560656270965904,
      "grad_norm": 0.22060935199260712,
      "learning_rate": 0.0003833709556057186,
      "loss": 0.3608,
      "step": 72700
    },
    {
      "epoch": 2.960131742126985,
      "grad_norm": 0.26290982961654663,
      "learning_rate": 0.0003831496481210995,
      "loss": 0.3614,
      "step": 72800
    },
    {
      "epoch": 2.964197857157379,
      "grad_norm": 0.2614065408706665,
      "learning_rate": 0.00038292834063648033,
      "loss": 0.3608,
      "step": 72900
    },
    {
      "epoch": 2.9682639721877733,
      "grad_norm": 0.25104060769081116,
      "learning_rate": 0.00038270703315186123,
      "loss": 0.361,
      "step": 73000
    },
    {
      "epoch": 2.9723300872181673,
      "grad_norm": 0.29064130783081055,
      "learning_rate": 0.0003824857256672421,
      "loss": 0.3611,
      "step": 73100
    },
    {
      "epoch": 2.9763962022485617,
      "grad_norm": 0.22736555337905884,
      "learning_rate": 0.0003822644181826229,
      "loss": 0.3597,
      "step": 73200
    },
    {
      "epoch": 2.9804623172789557,
      "grad_norm": 0.2498834729194641,
      "learning_rate": 0.0003820431106980038,
      "loss": 0.3605,
      "step": 73300
    },
    {
      "epoch": 2.98452843230935,
      "grad_norm": 0.2564079463481903,
      "learning_rate": 0.00038182180321338465,
      "loss": 0.3612,
      "step": 73400
    },
    {
      "epoch": 2.988594547339744,
      "grad_norm": 0.24314801394939423,
      "learning_rate": 0.00038160049572876555,
      "loss": 0.3604,
      "step": 73500
    },
    {
      "epoch": 2.9926606623701386,
      "grad_norm": 0.2327910214662552,
      "learning_rate": 0.0003813791882441464,
      "loss": 0.361,
      "step": 73600
    },
    {
      "epoch": 2.9967267774005326,
      "grad_norm": 0.24174173176288605,
      "learning_rate": 0.0003811578807595273,
      "loss": 0.3586,
      "step": 73700
    },
    {
      "epoch": 3.000792892430927,
      "grad_norm": 0.22831682860851288,
      "learning_rate": 0.00038093657327490813,
      "loss": 0.3612,
      "step": 73800
    },
    {
      "epoch": 3.004859007461321,
      "grad_norm": 0.271724134683609,
      "learning_rate": 0.00038071526579028903,
      "loss": 0.356,
      "step": 73900
    },
    {
      "epoch": 3.0089251224917155,
      "grad_norm": 0.24522291123867035,
      "learning_rate": 0.00038049395830566993,
      "loss": 0.355,
      "step": 74000
    },
    {
      "epoch": 3.0089251224917155,
      "eval_loss": 0.37003573775291443,
      "eval_runtime": 126.6594,
      "eval_samples_per_second": 1380.885,
      "eval_steps_per_second": 43.155,
      "step": 74000
    },
    {
      "epoch": 3.0129912375221095,
      "grad_norm": 0.23901520669460297,
      "learning_rate": 0.00038027265082105077,
      "loss": 0.3565,
      "step": 74100
    },
    {
      "epoch": 3.0170573525525035,
      "grad_norm": 0.3054526448249817,
      "learning_rate": 0.00038005134333643167,
      "loss": 0.358,
      "step": 74200
    },
    {
      "epoch": 3.021123467582898,
      "grad_norm": 0.2518264949321747,
      "learning_rate": 0.0003798300358518125,
      "loss": 0.3562,
      "step": 74300
    },
    {
      "epoch": 3.025189582613292,
      "grad_norm": 0.2395932376384735,
      "learning_rate": 0.0003796087283671934,
      "loss": 0.3558,
      "step": 74400
    },
    {
      "epoch": 3.0292556976436864,
      "grad_norm": 0.2289341390132904,
      "learning_rate": 0.00037938742088257425,
      "loss": 0.3556,
      "step": 74500
    },
    {
      "epoch": 3.0333218126740804,
      "grad_norm": 0.2701455056667328,
      "learning_rate": 0.00037916611339795515,
      "loss": 0.356,
      "step": 74600
    },
    {
      "epoch": 3.037387927704475,
      "grad_norm": 0.29631510376930237,
      "learning_rate": 0.00037894480591333605,
      "loss": 0.3565,
      "step": 74700
    },
    {
      "epoch": 3.041454042734869,
      "grad_norm": 0.2544999122619629,
      "learning_rate": 0.00037872349842871684,
      "loss": 0.3542,
      "step": 74800
    },
    {
      "epoch": 3.0455201577652633,
      "grad_norm": 0.25717493891716003,
      "learning_rate": 0.00037850219094409773,
      "loss": 0.3582,
      "step": 74900
    },
    {
      "epoch": 3.0495862727956573,
      "grad_norm": 0.30340781807899475,
      "learning_rate": 0.0003782808834594786,
      "loss": 0.3559,
      "step": 75000
    },
    {
      "epoch": 3.0536523878260518,
      "grad_norm": 0.2868975102901459,
      "learning_rate": 0.0003780595759748595,
      "loss": 0.355,
      "step": 75100
    },
    {
      "epoch": 3.0577185028564458,
      "grad_norm": 0.2880110442638397,
      "learning_rate": 0.0003778382684902403,
      "loss": 0.3566,
      "step": 75200
    },
    {
      "epoch": 3.06178461788684,
      "grad_norm": 0.22534604370594025,
      "learning_rate": 0.0003776169610056212,
      "loss": 0.3577,
      "step": 75300
    },
    {
      "epoch": 3.065850732917234,
      "grad_norm": 0.27942541241645813,
      "learning_rate": 0.00037739565352100206,
      "loss": 0.3548,
      "step": 75400
    },
    {
      "epoch": 3.0699168479476286,
      "grad_norm": 0.21553391218185425,
      "learning_rate": 0.00037717434603638296,
      "loss": 0.3566,
      "step": 75500
    },
    {
      "epoch": 3.0739829629780226,
      "grad_norm": 0.2398403435945511,
      "learning_rate": 0.00037695303855176385,
      "loss": 0.3552,
      "step": 75600
    },
    {
      "epoch": 3.0780490780084167,
      "grad_norm": 0.26943376660346985,
      "learning_rate": 0.0003767317310671447,
      "loss": 0.3575,
      "step": 75700
    },
    {
      "epoch": 3.082115193038811,
      "grad_norm": 0.2659090757369995,
      "learning_rate": 0.0003765104235825256,
      "loss": 0.3567,
      "step": 75800
    },
    {
      "epoch": 3.086181308069205,
      "grad_norm": 0.24306657910346985,
      "learning_rate": 0.00037628911609790644,
      "loss": 0.356,
      "step": 75900
    },
    {
      "epoch": 3.0902474230995995,
      "grad_norm": 0.2519662380218506,
      "learning_rate": 0.00037606780861328733,
      "loss": 0.3586,
      "step": 76000
    },
    {
      "epoch": 3.0902474230995995,
      "eval_loss": 0.3690563440322876,
      "eval_runtime": 126.8578,
      "eval_samples_per_second": 1378.725,
      "eval_steps_per_second": 43.088,
      "step": 76000
    },
    {
      "epoch": 3.0943135381299935,
      "grad_norm": 0.22221648693084717,
      "learning_rate": 0.0003758465011286682,
      "loss": 0.355,
      "step": 76100
    },
    {
      "epoch": 3.098379653160388,
      "grad_norm": 0.24574042856693268,
      "learning_rate": 0.0003756251936440491,
      "loss": 0.3571,
      "step": 76200
    },
    {
      "epoch": 3.102445768190782,
      "grad_norm": 0.2705998718738556,
      "learning_rate": 0.0003754038861594299,
      "loss": 0.3557,
      "step": 76300
    },
    {
      "epoch": 3.1065118832211764,
      "grad_norm": 0.2401195913553238,
      "learning_rate": 0.0003751825786748108,
      "loss": 0.3585,
      "step": 76400
    },
    {
      "epoch": 3.1105779982515704,
      "grad_norm": 0.28627336025238037,
      "learning_rate": 0.00037496127119019166,
      "loss": 0.3565,
      "step": 76500
    },
    {
      "epoch": 3.114644113281965,
      "grad_norm": 0.2539255619049072,
      "learning_rate": 0.0003747399637055725,
      "loss": 0.3575,
      "step": 76600
    },
    {
      "epoch": 3.118710228312359,
      "grad_norm": 0.31135791540145874,
      "learning_rate": 0.0003745186562209534,
      "loss": 0.3554,
      "step": 76700
    },
    {
      "epoch": 3.1227763433427533,
      "grad_norm": 0.25462502241134644,
      "learning_rate": 0.00037429734873633424,
      "loss": 0.3578,
      "step": 76800
    },
    {
      "epoch": 3.1268424583731473,
      "grad_norm": 0.23674793541431427,
      "learning_rate": 0.00037407604125171514,
      "loss": 0.3579,
      "step": 76900
    },
    {
      "epoch": 3.130908573403542,
      "grad_norm": 0.23674407601356506,
      "learning_rate": 0.000373854733767096,
      "loss": 0.3591,
      "step": 77000
    },
    {
      "epoch": 3.134974688433936,
      "grad_norm": 0.26448193192481995,
      "learning_rate": 0.0003736334262824769,
      "loss": 0.3566,
      "step": 77100
    },
    {
      "epoch": 3.1390408034643302,
      "grad_norm": 0.2568607032299042,
      "learning_rate": 0.0003734121187978577,
      "loss": 0.3591,
      "step": 77200
    },
    {
      "epoch": 3.1431069184947242,
      "grad_norm": 0.23703472316265106,
      "learning_rate": 0.0003731908113132386,
      "loss": 0.3564,
      "step": 77300
    },
    {
      "epoch": 3.1471730335251182,
      "grad_norm": 0.2850872278213501,
      "learning_rate": 0.0003729695038286195,
      "loss": 0.3575,
      "step": 77400
    },
    {
      "epoch": 3.1512391485555127,
      "grad_norm": 0.2990819811820984,
      "learning_rate": 0.00037274819634400036,
      "loss": 0.3578,
      "step": 77500
    },
    {
      "epoch": 3.1553052635859067,
      "grad_norm": 0.2778230905532837,
      "learning_rate": 0.00037252688885938126,
      "loss": 0.3562,
      "step": 77600
    },
    {
      "epoch": 3.159371378616301,
      "grad_norm": 0.2991732656955719,
      "learning_rate": 0.0003723055813747621,
      "loss": 0.3577,
      "step": 77700
    },
    {
      "epoch": 3.163437493646695,
      "grad_norm": 0.2443438470363617,
      "learning_rate": 0.000372084273890143,
      "loss": 0.3565,
      "step": 77800
    },
    {
      "epoch": 3.1675036086770896,
      "grad_norm": 0.30743399262428284,
      "learning_rate": 0.00037186296640552384,
      "loss": 0.3597,
      "step": 77900
    },
    {
      "epoch": 3.1715697237074836,
      "grad_norm": 0.24451108276844025,
      "learning_rate": 0.00037164165892090474,
      "loss": 0.358,
      "step": 78000
    },
    {
      "epoch": 3.1715697237074836,
      "eval_loss": 0.3687460720539093,
      "eval_runtime": 127.3866,
      "eval_samples_per_second": 1373.002,
      "eval_steps_per_second": 42.909,
      "step": 78000
    },
    {
      "epoch": 3.175635838737878,
      "grad_norm": 0.26030266284942627,
      "learning_rate": 0.0003714203514362856,
      "loss": 0.3587,
      "step": 78100
    },
    {
      "epoch": 3.179701953768272,
      "grad_norm": 0.3985116183757782,
      "learning_rate": 0.0003711990439516664,
      "loss": 0.3576,
      "step": 78200
    },
    {
      "epoch": 3.1837680687986665,
      "grad_norm": 0.26866498589515686,
      "learning_rate": 0.0003709777364670473,
      "loss": 0.3578,
      "step": 78300
    },
    {
      "epoch": 3.1878341838290605,
      "grad_norm": 0.28635719418525696,
      "learning_rate": 0.00037075642898242817,
      "loss": 0.3577,
      "step": 78400
    },
    {
      "epoch": 3.191900298859455,
      "grad_norm": 0.264919251203537,
      "learning_rate": 0.00037053512149780906,
      "loss": 0.3556,
      "step": 78500
    },
    {
      "epoch": 3.195966413889849,
      "grad_norm": 0.362281858921051,
      "learning_rate": 0.0003703138140131899,
      "loss": 0.358,
      "step": 78600
    },
    {
      "epoch": 3.200032528920243,
      "grad_norm": 0.2933387756347656,
      "learning_rate": 0.0003700925065285708,
      "loss": 0.3568,
      "step": 78700
    },
    {
      "epoch": 3.2040986439506374,
      "grad_norm": 0.29837214946746826,
      "learning_rate": 0.00036987119904395165,
      "loss": 0.3561,
      "step": 78800
    },
    {
      "epoch": 3.2081647589810314,
      "grad_norm": 0.24746255576610565,
      "learning_rate": 0.00036964989155933254,
      "loss": 0.3589,
      "step": 78900
    },
    {
      "epoch": 3.212230874011426,
      "grad_norm": 0.23116903007030487,
      "learning_rate": 0.00036942858407471344,
      "loss": 0.3583,
      "step": 79000
    },
    {
      "epoch": 3.21629698904182,
      "grad_norm": 0.2768169939517975,
      "learning_rate": 0.0003692072765900943,
      "loss": 0.3569,
      "step": 79100
    },
    {
      "epoch": 3.2203631040722143,
      "grad_norm": 0.30469438433647156,
      "learning_rate": 0.0003689859691054752,
      "loss": 0.3572,
      "step": 79200
    },
    {
      "epoch": 3.2244292191026083,
      "grad_norm": 0.2346591204404831,
      "learning_rate": 0.000368764661620856,
      "loss": 0.3568,
      "step": 79300
    },
    {
      "epoch": 3.2284953341330027,
      "grad_norm": 0.32399147748947144,
      "learning_rate": 0.0003685433541362369,
      "loss": 0.3564,
      "step": 79400
    },
    {
      "epoch": 3.2325614491633967,
      "grad_norm": 0.24156619608402252,
      "learning_rate": 0.00036832204665161776,
      "loss": 0.3566,
      "step": 79500
    },
    {
      "epoch": 3.236627564193791,
      "grad_norm": 0.23645614087581635,
      "learning_rate": 0.00036810073916699866,
      "loss": 0.3574,
      "step": 79600
    },
    {
      "epoch": 3.240693679224185,
      "grad_norm": 0.24328109622001648,
      "learning_rate": 0.0003678794316823795,
      "loss": 0.3563,
      "step": 79700
    },
    {
      "epoch": 3.2447597942545796,
      "grad_norm": 0.2367343157529831,
      "learning_rate": 0.0003676581241977604,
      "loss": 0.3561,
      "step": 79800
    },
    {
      "epoch": 3.2488259092849736,
      "grad_norm": 0.26978522539138794,
      "learning_rate": 0.00036743681671314125,
      "loss": 0.3582,
      "step": 79900
    },
    {
      "epoch": 3.252892024315368,
      "grad_norm": 0.2631480395793915,
      "learning_rate": 0.0003672155092285221,
      "loss": 0.3569,
      "step": 80000
    },
    {
      "epoch": 3.252892024315368,
      "eval_loss": 0.36788251996040344,
      "eval_runtime": 127.2434,
      "eval_samples_per_second": 1374.547,
      "eval_steps_per_second": 42.957,
      "step": 80000
    },
    {
      "epoch": 3.256958139345762,
      "grad_norm": 0.24725112318992615,
      "learning_rate": 0.000366994201743903,
      "loss": 0.3557,
      "step": 80100
    },
    {
      "epoch": 3.2610242543761565,
      "grad_norm": 0.25493812561035156,
      "learning_rate": 0.00036677289425928383,
      "loss": 0.3572,
      "step": 80200
    },
    {
      "epoch": 3.2650903694065505,
      "grad_norm": 0.3454594910144806,
      "learning_rate": 0.0003665515867746647,
      "loss": 0.3563,
      "step": 80300
    },
    {
      "epoch": 3.2691564844369445,
      "grad_norm": 0.2912629246711731,
      "learning_rate": 0.00036633027929004557,
      "loss": 0.3598,
      "step": 80400
    },
    {
      "epoch": 3.273222599467339,
      "grad_norm": 0.3211655020713806,
      "learning_rate": 0.00036610897180542647,
      "loss": 0.357,
      "step": 80500
    },
    {
      "epoch": 3.277288714497733,
      "grad_norm": 0.34359413385391235,
      "learning_rate": 0.0003658876643208073,
      "loss": 0.3565,
      "step": 80600
    },
    {
      "epoch": 3.2813548295281274,
      "grad_norm": 0.36807525157928467,
      "learning_rate": 0.0003656663568361882,
      "loss": 0.358,
      "step": 80700
    },
    {
      "epoch": 3.2854209445585214,
      "grad_norm": 0.21309544146060944,
      "learning_rate": 0.0003654450493515691,
      "loss": 0.3584,
      "step": 80800
    },
    {
      "epoch": 3.289487059588916,
      "grad_norm": 0.23481401801109314,
      "learning_rate": 0.00036522374186694995,
      "loss": 0.3572,
      "step": 80900
    },
    {
      "epoch": 3.29355317461931,
      "grad_norm": 0.28237202763557434,
      "learning_rate": 0.00036500243438233085,
      "loss": 0.3596,
      "step": 81000
    },
    {
      "epoch": 3.2976192896497043,
      "grad_norm": 0.27754801511764526,
      "learning_rate": 0.0003647811268977117,
      "loss": 0.3571,
      "step": 81100
    },
    {
      "epoch": 3.3016854046800983,
      "grad_norm": 0.2836766541004181,
      "learning_rate": 0.0003645598194130926,
      "loss": 0.3603,
      "step": 81200
    },
    {
      "epoch": 3.3057515197104927,
      "grad_norm": 0.26991042494773865,
      "learning_rate": 0.00036433851192847343,
      "loss": 0.3558,
      "step": 81300
    },
    {
      "epoch": 3.3098176347408867,
      "grad_norm": 0.2485324740409851,
      "learning_rate": 0.0003641172044438543,
      "loss": 0.3594,
      "step": 81400
    },
    {
      "epoch": 3.313883749771281,
      "grad_norm": 0.2790581285953522,
      "learning_rate": 0.00036389589695923517,
      "loss": 0.3567,
      "step": 81500
    },
    {
      "epoch": 3.317949864801675,
      "grad_norm": 0.4250200688838959,
      "learning_rate": 0.000363674589474616,
      "loss": 0.3574,
      "step": 81600
    },
    {
      "epoch": 3.3220159798320696,
      "grad_norm": 0.32643595337867737,
      "learning_rate": 0.0003634532819899969,
      "loss": 0.3571,
      "step": 81700
    },
    {
      "epoch": 3.3260820948624636,
      "grad_norm": 0.28752750158309937,
      "learning_rate": 0.00036323197450537775,
      "loss": 0.357,
      "step": 81800
    },
    {
      "epoch": 3.330148209892858,
      "grad_norm": 0.2298336923122406,
      "learning_rate": 0.00036301066702075865,
      "loss": 0.3573,
      "step": 81900
    },
    {
      "epoch": 3.334214324923252,
      "grad_norm": 0.31229081749916077,
      "learning_rate": 0.0003627893595361395,
      "loss": 0.3557,
      "step": 82000
    },
    {
      "epoch": 3.334214324923252,
      "eval_loss": 0.3677377998828888,
      "eval_runtime": 126.5934,
      "eval_samples_per_second": 1381.604,
      "eval_steps_per_second": 43.178,
      "step": 82000
    },
    {
      "epoch": 3.338280439953646,
      "grad_norm": 0.296750545501709,
      "learning_rate": 0.0003625680520515204,
      "loss": 0.3578,
      "step": 82100
    },
    {
      "epoch": 3.3423465549840405,
      "grad_norm": 0.3016667068004608,
      "learning_rate": 0.00036234674456690123,
      "loss": 0.3553,
      "step": 82200
    },
    {
      "epoch": 3.3464126700144345,
      "grad_norm": 0.3115386962890625,
      "learning_rate": 0.00036212543708228213,
      "loss": 0.3564,
      "step": 82300
    },
    {
      "epoch": 3.350478785044829,
      "grad_norm": 0.30530476570129395,
      "learning_rate": 0.000361904129597663,
      "loss": 0.358,
      "step": 82400
    },
    {
      "epoch": 3.354544900075223,
      "grad_norm": 0.2642119228839874,
      "learning_rate": 0.00036168282211304387,
      "loss": 0.3564,
      "step": 82500
    },
    {
      "epoch": 3.3586110151056174,
      "grad_norm": 0.2938896417617798,
      "learning_rate": 0.00036146151462842477,
      "loss": 0.3568,
      "step": 82600
    },
    {
      "epoch": 3.3626771301360114,
      "grad_norm": 0.371105432510376,
      "learning_rate": 0.0003612402071438056,
      "loss": 0.359,
      "step": 82700
    },
    {
      "epoch": 3.366743245166406,
      "grad_norm": 0.2809019088745117,
      "learning_rate": 0.0003610188996591865,
      "loss": 0.3564,
      "step": 82800
    },
    {
      "epoch": 3.3708093601968,
      "grad_norm": 0.30005693435668945,
      "learning_rate": 0.00036079759217456735,
      "loss": 0.3582,
      "step": 82900
    },
    {
      "epoch": 3.3748754752271943,
      "grad_norm": 0.28845468163490295,
      "learning_rate": 0.00036057628468994825,
      "loss": 0.3586,
      "step": 83000
    },
    {
      "epoch": 3.3789415902575883,
      "grad_norm": 0.24622687697410583,
      "learning_rate": 0.0003603549772053291,
      "loss": 0.3572,
      "step": 83100
    },
    {
      "epoch": 3.383007705287983,
      "grad_norm": 0.23772354423999786,
      "learning_rate": 0.00036013366972071,
      "loss": 0.3552,
      "step": 83200
    },
    {
      "epoch": 3.387073820318377,
      "grad_norm": 0.23869279026985168,
      "learning_rate": 0.00035991236223609083,
      "loss": 0.357,
      "step": 83300
    },
    {
      "epoch": 3.391139935348771,
      "grad_norm": 0.2620033323764801,
      "learning_rate": 0.0003596910547514717,
      "loss": 0.3558,
      "step": 83400
    },
    {
      "epoch": 3.3952060503791652,
      "grad_norm": 0.33015206456184387,
      "learning_rate": 0.0003594697472668526,
      "loss": 0.3573,
      "step": 83500
    },
    {
      "epoch": 3.3992721654095597,
      "grad_norm": 0.29495981335639954,
      "learning_rate": 0.0003592484397822334,
      "loss": 0.3553,
      "step": 83600
    },
    {
      "epoch": 3.4033382804399537,
      "grad_norm": 0.3681928515434265,
      "learning_rate": 0.0003590271322976143,
      "loss": 0.3567,
      "step": 83700
    },
    {
      "epoch": 3.4074043954703477,
      "grad_norm": 0.2881094217300415,
      "learning_rate": 0.00035880582481299516,
      "loss": 0.3578,
      "step": 83800
    },
    {
      "epoch": 3.411470510500742,
      "grad_norm": 0.2549063563346863,
      "learning_rate": 0.00035858451732837605,
      "loss": 0.3564,
      "step": 83900
    },
    {
      "epoch": 3.415536625531136,
      "grad_norm": 0.25615808367729187,
      "learning_rate": 0.0003583632098437569,
      "loss": 0.3575,
      "step": 84000
    },
    {
      "epoch": 3.415536625531136,
      "eval_loss": 0.3680776059627533,
      "eval_runtime": 126.5297,
      "eval_samples_per_second": 1382.3,
      "eval_steps_per_second": 43.199,
      "step": 84000
    },
    {
      "epoch": 3.4196027405615306,
      "grad_norm": 0.29497483372688293,
      "learning_rate": 0.0003581419023591378,
      "loss": 0.3561,
      "step": 84100
    },
    {
      "epoch": 3.4236688555919246,
      "grad_norm": 0.29824987053871155,
      "learning_rate": 0.0003579205948745187,
      "loss": 0.355,
      "step": 84200
    },
    {
      "epoch": 3.427734970622319,
      "grad_norm": 0.3096408545970917,
      "learning_rate": 0.00035769928738989954,
      "loss": 0.3568,
      "step": 84300
    },
    {
      "epoch": 3.431801085652713,
      "grad_norm": 0.2926022708415985,
      "learning_rate": 0.00035747797990528043,
      "loss": 0.3556,
      "step": 84400
    },
    {
      "epoch": 3.4358672006831075,
      "grad_norm": 0.26791298389434814,
      "learning_rate": 0.0003572566724206613,
      "loss": 0.3554,
      "step": 84500
    },
    {
      "epoch": 3.4399333157135015,
      "grad_norm": 0.2722628116607666,
      "learning_rate": 0.0003570353649360422,
      "loss": 0.3571,
      "step": 84600
    },
    {
      "epoch": 3.443999430743896,
      "grad_norm": 0.26936620473861694,
      "learning_rate": 0.000356814057451423,
      "loss": 0.356,
      "step": 84700
    },
    {
      "epoch": 3.44806554577429,
      "grad_norm": 0.2774656414985657,
      "learning_rate": 0.0003565927499668039,
      "loss": 0.3566,
      "step": 84800
    },
    {
      "epoch": 3.4521316608046844,
      "grad_norm": 0.23856940865516663,
      "learning_rate": 0.00035637144248218476,
      "loss": 0.3543,
      "step": 84900
    },
    {
      "epoch": 3.4561977758350784,
      "grad_norm": 0.319619357585907,
      "learning_rate": 0.0003561501349975656,
      "loss": 0.3576,
      "step": 85000
    },
    {
      "epoch": 3.4602638908654724,
      "grad_norm": 0.26027265191078186,
      "learning_rate": 0.0003559288275129465,
      "loss": 0.357,
      "step": 85100
    },
    {
      "epoch": 3.464330005895867,
      "grad_norm": 0.25137314200401306,
      "learning_rate": 0.00035570752002832734,
      "loss": 0.3568,
      "step": 85200
    },
    {
      "epoch": 3.468396120926261,
      "grad_norm": 0.24296678602695465,
      "learning_rate": 0.00035548621254370824,
      "loss": 0.356,
      "step": 85300
    },
    {
      "epoch": 3.4724622359566553,
      "grad_norm": 0.2657652497291565,
      "learning_rate": 0.0003552649050590891,
      "loss": 0.3557,
      "step": 85400
    },
    {
      "epoch": 3.4765283509870493,
      "grad_norm": 0.25796177983283997,
      "learning_rate": 0.00035504359757447,
      "loss": 0.3569,
      "step": 85500
    },
    {
      "epoch": 3.4805944660174437,
      "grad_norm": 0.27027496695518494,
      "learning_rate": 0.0003548222900898508,
      "loss": 0.3594,
      "step": 85600
    },
    {
      "epoch": 3.4846605810478377,
      "grad_norm": 0.30482304096221924,
      "learning_rate": 0.0003546009826052317,
      "loss": 0.3573,
      "step": 85700
    },
    {
      "epoch": 3.488726696078232,
      "grad_norm": 0.29002827405929565,
      "learning_rate": 0.00035437967512061256,
      "loss": 0.3542,
      "step": 85800
    },
    {
      "epoch": 3.492792811108626,
      "grad_norm": 0.3565302789211273,
      "learning_rate": 0.00035415836763599346,
      "loss": 0.3578,
      "step": 85900
    },
    {
      "epoch": 3.4968589261390206,
      "grad_norm": 0.332742303609848,
      "learning_rate": 0.00035393706015137436,
      "loss": 0.3555,
      "step": 86000
    },
    {
      "epoch": 3.4968589261390206,
      "eval_loss": 0.36752429604530334,
      "eval_runtime": 125.851,
      "eval_samples_per_second": 1389.755,
      "eval_steps_per_second": 43.432,
      "step": 86000
    },
    {
      "epoch": 3.5009250411694146,
      "grad_norm": 0.2847415804862976,
      "learning_rate": 0.0003537157526667552,
      "loss": 0.357,
      "step": 86100
    },
    {
      "epoch": 3.504991156199809,
      "grad_norm": 0.29462701082229614,
      "learning_rate": 0.0003534944451821361,
      "loss": 0.3565,
      "step": 86200
    },
    {
      "epoch": 3.509057271230203,
      "grad_norm": 0.26929980516433716,
      "learning_rate": 0.00035327313769751694,
      "loss": 0.3561,
      "step": 86300
    },
    {
      "epoch": 3.513123386260597,
      "grad_norm": 0.2743958532810211,
      "learning_rate": 0.00035305183021289784,
      "loss": 0.3596,
      "step": 86400
    },
    {
      "epoch": 3.5171895012909915,
      "grad_norm": 0.3448050916194916,
      "learning_rate": 0.0003528305227282787,
      "loss": 0.3581,
      "step": 86500
    },
    {
      "epoch": 3.521255616321386,
      "grad_norm": 0.2642330527305603,
      "learning_rate": 0.0003526092152436595,
      "loss": 0.3582,
      "step": 86600
    },
    {
      "epoch": 3.52532173135178,
      "grad_norm": 0.3168336749076843,
      "learning_rate": 0.0003523879077590404,
      "loss": 0.3592,
      "step": 86700
    },
    {
      "epoch": 3.529387846382174,
      "grad_norm": 0.2632909417152405,
      "learning_rate": 0.00035216660027442126,
      "loss": 0.3582,
      "step": 86800
    },
    {
      "epoch": 3.5334539614125684,
      "grad_norm": 0.3473524749279022,
      "learning_rate": 0.00035194529278980216,
      "loss": 0.354,
      "step": 86900
    },
    {
      "epoch": 3.537520076442963,
      "grad_norm": 0.2770124673843384,
      "learning_rate": 0.000351723985305183,
      "loss": 0.3566,
      "step": 87000
    },
    {
      "epoch": 3.541586191473357,
      "grad_norm": 0.2699003517627716,
      "learning_rate": 0.0003515026778205639,
      "loss": 0.3565,
      "step": 87100
    },
    {
      "epoch": 3.545652306503751,
      "grad_norm": 0.32454532384872437,
      "learning_rate": 0.00035128137033594474,
      "loss": 0.3568,
      "step": 87200
    },
    {
      "epoch": 3.5497184215341453,
      "grad_norm": 0.3177579939365387,
      "learning_rate": 0.00035106006285132564,
      "loss": 0.3562,
      "step": 87300
    },
    {
      "epoch": 3.5537845365645393,
      "grad_norm": 0.27616116404533386,
      "learning_rate": 0.0003508387553667065,
      "loss": 0.3568,
      "step": 87400
    },
    {
      "epoch": 3.5578506515949337,
      "grad_norm": 0.30156055092811584,
      "learning_rate": 0.0003506174478820874,
      "loss": 0.3567,
      "step": 87500
    },
    {
      "epoch": 3.5619167666253277,
      "grad_norm": 0.2665293514728546,
      "learning_rate": 0.0003503961403974683,
      "loss": 0.3572,
      "step": 87600
    },
    {
      "epoch": 3.565982881655722,
      "grad_norm": 0.28401097655296326,
      "learning_rate": 0.0003501748329128491,
      "loss": 0.3568,
      "step": 87700
    },
    {
      "epoch": 3.570048996686116,
      "grad_norm": 0.3395620286464691,
      "learning_rate": 0.00034995352542823,
      "loss": 0.3558,
      "step": 87800
    },
    {
      "epoch": 3.5741151117165106,
      "grad_norm": 0.26908957958221436,
      "learning_rate": 0.00034973221794361086,
      "loss": 0.3574,
      "step": 87900
    },
    {
      "epoch": 3.5781812267469046,
      "grad_norm": 0.2865769565105438,
      "learning_rate": 0.00034951091045899176,
      "loss": 0.3567,
      "step": 88000
    },
    {
      "epoch": 3.5781812267469046,
      "eval_loss": 0.36705610156059265,
      "eval_runtime": 128.6803,
      "eval_samples_per_second": 1359.198,
      "eval_steps_per_second": 42.477,
      "step": 88000
    },
    {
      "epoch": 3.5822473417772986,
      "grad_norm": 0.303302139043808,
      "learning_rate": 0.0003492896029743726,
      "loss": 0.3572,
      "step": 88100
    },
    {
      "epoch": 3.586313456807693,
      "grad_norm": 0.29535171389579773,
      "learning_rate": 0.0003490682954897535,
      "loss": 0.3561,
      "step": 88200
    },
    {
      "epoch": 3.5903795718380875,
      "grad_norm": 0.3224288523197174,
      "learning_rate": 0.0003488469880051343,
      "loss": 0.3579,
      "step": 88300
    },
    {
      "epoch": 3.5944456868684815,
      "grad_norm": 0.24264399707317352,
      "learning_rate": 0.0003486256805205152,
      "loss": 0.3583,
      "step": 88400
    },
    {
      "epoch": 3.5985118018988755,
      "grad_norm": 0.2665584683418274,
      "learning_rate": 0.0003484043730358961,
      "loss": 0.3565,
      "step": 88500
    },
    {
      "epoch": 3.60257791692927,
      "grad_norm": 0.35670995712280273,
      "learning_rate": 0.00034818306555127693,
      "loss": 0.3577,
      "step": 88600
    },
    {
      "epoch": 3.606644031959664,
      "grad_norm": 0.28035569190979004,
      "learning_rate": 0.0003479617580666578,
      "loss": 0.3581,
      "step": 88700
    },
    {
      "epoch": 3.6107101469900584,
      "grad_norm": 0.3234356939792633,
      "learning_rate": 0.00034774045058203867,
      "loss": 0.3569,
      "step": 88800
    },
    {
      "epoch": 3.6147762620204524,
      "grad_norm": 0.2213554084300995,
      "learning_rate": 0.00034751914309741957,
      "loss": 0.3545,
      "step": 88900
    },
    {
      "epoch": 3.618842377050847,
      "grad_norm": 0.29219356179237366,
      "learning_rate": 0.0003472978356128004,
      "loss": 0.3569,
      "step": 89000
    },
    {
      "epoch": 3.622908492081241,
      "grad_norm": 0.28556880354881287,
      "learning_rate": 0.0003470765281281813,
      "loss": 0.3586,
      "step": 89100
    },
    {
      "epoch": 3.6269746071116353,
      "grad_norm": 0.28216052055358887,
      "learning_rate": 0.00034685522064356215,
      "loss": 0.3559,
      "step": 89200
    },
    {
      "epoch": 3.6310407221420293,
      "grad_norm": 0.2664679288864136,
      "learning_rate": 0.00034663391315894305,
      "loss": 0.3561,
      "step": 89300
    },
    {
      "epoch": 3.6351068371724233,
      "grad_norm": 0.30828091502189636,
      "learning_rate": 0.00034641260567432394,
      "loss": 0.3568,
      "step": 89400
    },
    {
      "epoch": 3.639172952202818,
      "grad_norm": 0.2700086534023285,
      "learning_rate": 0.0003461912981897048,
      "loss": 0.3573,
      "step": 89500
    },
    {
      "epoch": 3.6432390672332122,
      "grad_norm": 0.27850142121315,
      "learning_rate": 0.0003459699907050857,
      "loss": 0.355,
      "step": 89600
    },
    {
      "epoch": 3.6473051822636062,
      "grad_norm": 0.2899370789527893,
      "learning_rate": 0.00034574868322046653,
      "loss": 0.3537,
      "step": 89700
    },
    {
      "epoch": 3.6513712972940002,
      "grad_norm": 0.30529654026031494,
      "learning_rate": 0.0003455273757358474,
      "loss": 0.3568,
      "step": 89800
    },
    {
      "epoch": 3.6554374123243947,
      "grad_norm": 0.3086210787296295,
      "learning_rate": 0.00034530606825122827,
      "loss": 0.3567,
      "step": 89900
    },
    {
      "epoch": 3.659503527354789,
      "grad_norm": 0.3419025242328644,
      "learning_rate": 0.0003450847607666091,
      "loss": 0.3552,
      "step": 90000
    },
    {
      "epoch": 3.659503527354789,
      "eval_loss": 0.3670406639575958,
      "eval_runtime": 125.7494,
      "eval_samples_per_second": 1390.877,
      "eval_steps_per_second": 43.467,
      "step": 90000
    },
    {
      "epoch": 3.663569642385183,
      "grad_norm": 0.27612853050231934,
      "learning_rate": 0.00034486345328198995,
      "loss": 0.3549,
      "step": 90100
    },
    {
      "epoch": 3.667635757415577,
      "grad_norm": 0.3303927779197693,
      "learning_rate": 0.00034464214579737085,
      "loss": 0.3598,
      "step": 90200
    },
    {
      "epoch": 3.6717018724459716,
      "grad_norm": 0.33225125074386597,
      "learning_rate": 0.00034442083831275175,
      "loss": 0.3557,
      "step": 90300
    },
    {
      "epoch": 3.6757679874763656,
      "grad_norm": 0.28035950660705566,
      "learning_rate": 0.0003441995308281326,
      "loss": 0.3552,
      "step": 90400
    },
    {
      "epoch": 3.67983410250676,
      "grad_norm": 0.2837212383747101,
      "learning_rate": 0.0003439782233435135,
      "loss": 0.3566,
      "step": 90500
    },
    {
      "epoch": 3.683900217537154,
      "grad_norm": 0.29828470945358276,
      "learning_rate": 0.00034375691585889433,
      "loss": 0.3575,
      "step": 90600
    },
    {
      "epoch": 3.6879663325675485,
      "grad_norm": 0.3298378884792328,
      "learning_rate": 0.00034353560837427523,
      "loss": 0.356,
      "step": 90700
    },
    {
      "epoch": 3.6920324475979425,
      "grad_norm": 0.2915197014808655,
      "learning_rate": 0.00034331430088965607,
      "loss": 0.3556,
      "step": 90800
    },
    {
      "epoch": 3.696098562628337,
      "grad_norm": 0.34466245770454407,
      "learning_rate": 0.00034309299340503697,
      "loss": 0.3584,
      "step": 90900
    },
    {
      "epoch": 3.700164677658731,
      "grad_norm": 0.2612724304199219,
      "learning_rate": 0.00034287168592041787,
      "loss": 0.3552,
      "step": 91000
    },
    {
      "epoch": 3.704230792689125,
      "grad_norm": 0.3372010886669159,
      "learning_rate": 0.0003426503784357987,
      "loss": 0.355,
      "step": 91100
    },
    {
      "epoch": 3.7082969077195194,
      "grad_norm": 0.29376158118247986,
      "learning_rate": 0.0003424290709511796,
      "loss": 0.3548,
      "step": 91200
    },
    {
      "epoch": 3.712363022749914,
      "grad_norm": 0.284155011177063,
      "learning_rate": 0.00034220776346656045,
      "loss": 0.3556,
      "step": 91300
    },
    {
      "epoch": 3.716429137780308,
      "grad_norm": 0.2879297733306885,
      "learning_rate": 0.00034198645598194135,
      "loss": 0.358,
      "step": 91400
    },
    {
      "epoch": 3.720495252810702,
      "grad_norm": 0.2875749170780182,
      "learning_rate": 0.0003417651484973222,
      "loss": 0.3557,
      "step": 91500
    },
    {
      "epoch": 3.7245613678410963,
      "grad_norm": 0.30363577604293823,
      "learning_rate": 0.0003415438410127031,
      "loss": 0.3574,
      "step": 91600
    },
    {
      "epoch": 3.7286274828714907,
      "grad_norm": 0.2718072533607483,
      "learning_rate": 0.0003413225335280839,
      "loss": 0.3543,
      "step": 91700
    },
    {
      "epoch": 3.7326935979018847,
      "grad_norm": 0.3223687708377838,
      "learning_rate": 0.0003411012260434648,
      "loss": 0.3573,
      "step": 91800
    },
    {
      "epoch": 3.7367597129322787,
      "grad_norm": 0.3212849199771881,
      "learning_rate": 0.00034087991855884567,
      "loss": 0.3557,
      "step": 91900
    },
    {
      "epoch": 3.740825827962673,
      "grad_norm": 0.2643912136554718,
      "learning_rate": 0.0003406586110742265,
      "loss": 0.3572,
      "step": 92000
    },
    {
      "epoch": 3.740825827962673,
      "eval_loss": 0.3660050928592682,
      "eval_runtime": 126.7656,
      "eval_samples_per_second": 1379.728,
      "eval_steps_per_second": 43.119,
      "step": 92000
    },
    {
      "epoch": 3.744891942993067,
      "grad_norm": 0.27611762285232544,
      "learning_rate": 0.0003404373035896074,
      "loss": 0.3562,
      "step": 92100
    },
    {
      "epoch": 3.7489580580234616,
      "grad_norm": 0.32932350039482117,
      "learning_rate": 0.00034021599610498826,
      "loss": 0.3555,
      "step": 92200
    },
    {
      "epoch": 3.7530241730538556,
      "grad_norm": 0.27718836069107056,
      "learning_rate": 0.00033999468862036915,
      "loss": 0.3561,
      "step": 92300
    },
    {
      "epoch": 3.75709028808425,
      "grad_norm": 0.31899362802505493,
      "learning_rate": 0.00033977338113575,
      "loss": 0.3566,
      "step": 92400
    },
    {
      "epoch": 3.761156403114644,
      "grad_norm": 0.2650110721588135,
      "learning_rate": 0.0003395520736511309,
      "loss": 0.3562,
      "step": 92500
    },
    {
      "epoch": 3.7652225181450385,
      "grad_norm": 0.33231544494628906,
      "learning_rate": 0.00033933076616651174,
      "loss": 0.3546,
      "step": 92600
    },
    {
      "epoch": 3.7692886331754325,
      "grad_norm": 0.32555168867111206,
      "learning_rate": 0.00033910945868189263,
      "loss": 0.3571,
      "step": 92700
    },
    {
      "epoch": 3.7733547482058265,
      "grad_norm": 0.3020782768726349,
      "learning_rate": 0.00033888815119727353,
      "loss": 0.3568,
      "step": 92800
    },
    {
      "epoch": 3.777420863236221,
      "grad_norm": 0.3107927739620209,
      "learning_rate": 0.0003386668437126544,
      "loss": 0.3552,
      "step": 92900
    },
    {
      "epoch": 3.7814869782666154,
      "grad_norm": 0.2920836806297302,
      "learning_rate": 0.00033844553622803527,
      "loss": 0.3554,
      "step": 93000
    },
    {
      "epoch": 3.7855530932970094,
      "grad_norm": 0.2815595269203186,
      "learning_rate": 0.0003382242287434161,
      "loss": 0.3564,
      "step": 93100
    },
    {
      "epoch": 3.7896192083274034,
      "grad_norm": 0.3181576728820801,
      "learning_rate": 0.000338002921258797,
      "loss": 0.3579,
      "step": 93200
    },
    {
      "epoch": 3.793685323357798,
      "grad_norm": 0.3107404112815857,
      "learning_rate": 0.00033778161377417786,
      "loss": 0.3567,
      "step": 93300
    },
    {
      "epoch": 3.797751438388192,
      "grad_norm": 0.3811590373516083,
      "learning_rate": 0.0003375603062895587,
      "loss": 0.3555,
      "step": 93400
    },
    {
      "epoch": 3.8018175534185863,
      "grad_norm": 0.30949702858924866,
      "learning_rate": 0.00033733899880493954,
      "loss": 0.3565,
      "step": 93500
    },
    {
      "epoch": 3.8058836684489803,
      "grad_norm": 0.3099547028541565,
      "learning_rate": 0.00033711769132032044,
      "loss": 0.3565,
      "step": 93600
    },
    {
      "epoch": 3.8099497834793747,
      "grad_norm": 0.27840283513069153,
      "learning_rate": 0.00033689638383570134,
      "loss": 0.3547,
      "step": 93700
    },
    {
      "epoch": 3.8140158985097687,
      "grad_norm": 0.3105253577232361,
      "learning_rate": 0.0003366750763510822,
      "loss": 0.3563,
      "step": 93800
    },
    {
      "epoch": 3.818082013540163,
      "grad_norm": 0.2789827585220337,
      "learning_rate": 0.0003364537688664631,
      "loss": 0.357,
      "step": 93900
    },
    {
      "epoch": 3.822148128570557,
      "grad_norm": 0.3139936029911041,
      "learning_rate": 0.0003362324613818439,
      "loss": 0.3542,
      "step": 94000
    },
    {
      "epoch": 3.822148128570557,
      "eval_loss": 0.3657626509666443,
      "eval_runtime": 126.8503,
      "eval_samples_per_second": 1378.807,
      "eval_steps_per_second": 43.09,
      "step": 94000
    },
    {
      "epoch": 3.8262142436009516,
      "grad_norm": 0.3009575605392456,
      "learning_rate": 0.0003360111538972248,
      "loss": 0.3573,
      "step": 94100
    },
    {
      "epoch": 3.8302803586313456,
      "grad_norm": 0.3185840845108032,
      "learning_rate": 0.00033578984641260566,
      "loss": 0.3556,
      "step": 94200
    },
    {
      "epoch": 3.83434647366174,
      "grad_norm": 0.35879236459732056,
      "learning_rate": 0.00033556853892798656,
      "loss": 0.3546,
      "step": 94300
    },
    {
      "epoch": 3.838412588692134,
      "grad_norm": 0.2723797857761383,
      "learning_rate": 0.00033534723144336745,
      "loss": 0.3526,
      "step": 94400
    },
    {
      "epoch": 3.842478703722528,
      "grad_norm": 0.2624358534812927,
      "learning_rate": 0.0003351259239587483,
      "loss": 0.3562,
      "step": 94500
    },
    {
      "epoch": 3.8465448187529225,
      "grad_norm": 0.3095846176147461,
      "learning_rate": 0.0003349046164741292,
      "loss": 0.3544,
      "step": 94600
    },
    {
      "epoch": 3.850610933783317,
      "grad_norm": 0.346645325422287,
      "learning_rate": 0.00033468330898951004,
      "loss": 0.3592,
      "step": 94700
    },
    {
      "epoch": 3.854677048813711,
      "grad_norm": 0.2835552394390106,
      "learning_rate": 0.00033446200150489094,
      "loss": 0.3533,
      "step": 94800
    },
    {
      "epoch": 3.858743163844105,
      "grad_norm": 0.301442950963974,
      "learning_rate": 0.0003342406940202718,
      "loss": 0.3547,
      "step": 94900
    },
    {
      "epoch": 3.8628092788744994,
      "grad_norm": 0.2888180911540985,
      "learning_rate": 0.0003340193865356527,
      "loss": 0.3557,
      "step": 95000
    },
    {
      "epoch": 3.8668753939048934,
      "grad_norm": 0.3246971666812897,
      "learning_rate": 0.00033379807905103346,
      "loss": 0.3568,
      "step": 95100
    },
    {
      "epoch": 3.870941508935288,
      "grad_norm": 0.2897001802921295,
      "learning_rate": 0.00033357677156641436,
      "loss": 0.3534,
      "step": 95200
    },
    {
      "epoch": 3.875007623965682,
      "grad_norm": 0.27786388993263245,
      "learning_rate": 0.00033335546408179526,
      "loss": 0.3536,
      "step": 95300
    },
    {
      "epoch": 3.8790737389960763,
      "grad_norm": 0.27511563897132874,
      "learning_rate": 0.0003331341565971761,
      "loss": 0.3528,
      "step": 95400
    },
    {
      "epoch": 3.8831398540264703,
      "grad_norm": 0.27650120854377747,
      "learning_rate": 0.000332912849112557,
      "loss": 0.356,
      "step": 95500
    },
    {
      "epoch": 3.8872059690568648,
      "grad_norm": 0.2631010413169861,
      "learning_rate": 0.00033269154162793784,
      "loss": 0.3547,
      "step": 95600
    },
    {
      "epoch": 3.8912720840872588,
      "grad_norm": 0.2654389441013336,
      "learning_rate": 0.00033247023414331874,
      "loss": 0.3552,
      "step": 95700
    },
    {
      "epoch": 3.8953381991176528,
      "grad_norm": 0.25446850061416626,
      "learning_rate": 0.0003322489266586996,
      "loss": 0.3544,
      "step": 95800
    },
    {
      "epoch": 3.8994043141480472,
      "grad_norm": 0.2966497838497162,
      "learning_rate": 0.0003320276191740805,
      "loss": 0.3535,
      "step": 95900
    },
    {
      "epoch": 3.9034704291784417,
      "grad_norm": 0.38460448384284973,
      "learning_rate": 0.0003318063116894613,
      "loss": 0.3555,
      "step": 96000
    },
    {
      "epoch": 3.9034704291784417,
      "eval_loss": 0.3655364513397217,
      "eval_runtime": 126.0018,
      "eval_samples_per_second": 1388.091,
      "eval_steps_per_second": 43.38,
      "step": 96000
    },
    {
      "epoch": 3.9075365442088357,
      "grad_norm": 0.3275093734264374,
      "learning_rate": 0.0003315850042048422,
      "loss": 0.3552,
      "step": 96100
    },
    {
      "epoch": 3.9116026592392297,
      "grad_norm": 0.3353326916694641,
      "learning_rate": 0.0003313636967202231,
      "loss": 0.3556,
      "step": 96200
    },
    {
      "epoch": 3.915668774269624,
      "grad_norm": 0.3738011121749878,
      "learning_rate": 0.00033114238923560396,
      "loss": 0.3522,
      "step": 96300
    },
    {
      "epoch": 3.9197348893000186,
      "grad_norm": 0.3554457724094391,
      "learning_rate": 0.00033092108175098486,
      "loss": 0.3546,
      "step": 96400
    },
    {
      "epoch": 3.9238010043304126,
      "grad_norm": 0.294436514377594,
      "learning_rate": 0.0003306997742663657,
      "loss": 0.3557,
      "step": 96500
    },
    {
      "epoch": 3.9278671193608066,
      "grad_norm": 0.29663845896720886,
      "learning_rate": 0.0003304784667817466,
      "loss": 0.3543,
      "step": 96600
    },
    {
      "epoch": 3.931933234391201,
      "grad_norm": 0.3223758637905121,
      "learning_rate": 0.00033025715929712744,
      "loss": 0.3545,
      "step": 96700
    },
    {
      "epoch": 3.935999349421595,
      "grad_norm": 0.266773521900177,
      "learning_rate": 0.0003300358518125083,
      "loss": 0.3543,
      "step": 96800
    },
    {
      "epoch": 3.9400654644519895,
      "grad_norm": 0.30695298314094543,
      "learning_rate": 0.00032981454432788913,
      "loss": 0.3551,
      "step": 96900
    },
    {
      "epoch": 3.9441315794823835,
      "grad_norm": 0.3128669261932373,
      "learning_rate": 0.00032959323684327,
      "loss": 0.3531,
      "step": 97000
    },
    {
      "epoch": 3.948197694512778,
      "grad_norm": 0.3325573205947876,
      "learning_rate": 0.0003293719293586509,
      "loss": 0.3555,
      "step": 97100
    },
    {
      "epoch": 3.952263809543172,
      "grad_norm": 0.268185019493103,
      "learning_rate": 0.00032915062187403177,
      "loss": 0.3572,
      "step": 97200
    },
    {
      "epoch": 3.9563299245735664,
      "grad_norm": 0.284152090549469,
      "learning_rate": 0.00032892931438941266,
      "loss": 0.356,
      "step": 97300
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 0.2907043397426605,
      "learning_rate": 0.0003287080069047935,
      "loss": 0.3553,
      "step": 97400
    },
    {
      "epoch": 3.9644621546343544,
      "grad_norm": 0.2913910746574402,
      "learning_rate": 0.0003284866994201744,
      "loss": 0.3545,
      "step": 97500
    },
    {
      "epoch": 3.968528269664749,
      "grad_norm": 0.3333434760570526,
      "learning_rate": 0.00032826539193555525,
      "loss": 0.3562,
      "step": 97600
    },
    {
      "epoch": 3.9725943846951433,
      "grad_norm": 0.2908276319503784,
      "learning_rate": 0.00032804408445093614,
      "loss": 0.3565,
      "step": 97700
    },
    {
      "epoch": 3.9766604997255373,
      "grad_norm": 0.3426842987537384,
      "learning_rate": 0.00032782277696631704,
      "loss": 0.3542,
      "step": 97800
    },
    {
      "epoch": 3.9807266147559313,
      "grad_norm": 0.2893645763397217,
      "learning_rate": 0.0003276014694816979,
      "loss": 0.3543,
      "step": 97900
    },
    {
      "epoch": 3.9847927297863257,
      "grad_norm": 0.25943058729171753,
      "learning_rate": 0.0003273801619970788,
      "loss": 0.3559,
      "step": 98000
    },
    {
      "epoch": 3.9847927297863257,
      "eval_loss": 0.3652743697166443,
      "eval_runtime": 127.1152,
      "eval_samples_per_second": 1375.933,
      "eval_steps_per_second": 43.0,
      "step": 98000
    },
    {
      "epoch": 3.9888588448167197,
      "grad_norm": 0.2781410217285156,
      "learning_rate": 0.0003271588545124596,
      "loss": 0.3549,
      "step": 98100
    },
    {
      "epoch": 3.992924959847114,
      "grad_norm": 0.28825080394744873,
      "learning_rate": 0.0003269375470278405,
      "loss": 0.3556,
      "step": 98200
    },
    {
      "epoch": 3.996991074877508,
      "grad_norm": 0.2501317262649536,
      "learning_rate": 0.00032671623954322137,
      "loss": 0.3549,
      "step": 98300
    },
    {
      "epoch": 4.001057189907902,
      "grad_norm": 0.34968066215515137,
      "learning_rate": 0.00032649493205860226,
      "loss": 0.3532,
      "step": 98400
    },
    {
      "epoch": 4.005123304938297,
      "grad_norm": 0.3087007701396942,
      "learning_rate": 0.00032627362457398305,
      "loss": 0.351,
      "step": 98500
    },
    {
      "epoch": 4.009189419968691,
      "grad_norm": 0.3380071520805359,
      "learning_rate": 0.00032605231708936395,
      "loss": 0.3494,
      "step": 98600
    },
    {
      "epoch": 4.013255534999085,
      "grad_norm": 0.29280269145965576,
      "learning_rate": 0.00032583100960474485,
      "loss": 0.349,
      "step": 98700
    },
    {
      "epoch": 4.017321650029479,
      "grad_norm": 0.32800400257110596,
      "learning_rate": 0.0003256097021201257,
      "loss": 0.3544,
      "step": 98800
    },
    {
      "epoch": 4.021387765059874,
      "grad_norm": 0.32644423842430115,
      "learning_rate": 0.0003253883946355066,
      "loss": 0.3496,
      "step": 98900
    },
    {
      "epoch": 4.025453880090268,
      "grad_norm": 0.2791571617126465,
      "learning_rate": 0.00032516708715088743,
      "loss": 0.3489,
      "step": 99000
    },
    {
      "epoch": 4.029519995120662,
      "grad_norm": 0.3678962290287018,
      "learning_rate": 0.00032494577966626833,
      "loss": 0.3518,
      "step": 99100
    },
    {
      "epoch": 4.033586110151056,
      "grad_norm": 0.2890080511569977,
      "learning_rate": 0.00032472447218164917,
      "loss": 0.3502,
      "step": 99200
    },
    {
      "epoch": 4.03765222518145,
      "grad_norm": 0.2958097457885742,
      "learning_rate": 0.00032450316469703007,
      "loss": 0.3498,
      "step": 99300
    },
    {
      "epoch": 4.041718340211845,
      "grad_norm": 0.2863911986351013,
      "learning_rate": 0.0003242818572124109,
      "loss": 0.3534,
      "step": 99400
    },
    {
      "epoch": 4.045784455242239,
      "grad_norm": 0.3052137494087219,
      "learning_rate": 0.0003240605497277918,
      "loss": 0.3521,
      "step": 99500
    },
    {
      "epoch": 4.049850570272633,
      "grad_norm": 0.3824704587459564,
      "learning_rate": 0.0003238392422431727,
      "loss": 0.3499,
      "step": 99600
    },
    {
      "epoch": 4.053916685303027,
      "grad_norm": 0.2895629107952118,
      "learning_rate": 0.00032361793475855355,
      "loss": 0.3532,
      "step": 99700
    },
    {
      "epoch": 4.057982800333422,
      "grad_norm": 0.2841006815433502,
      "learning_rate": 0.00032339662727393445,
      "loss": 0.3501,
      "step": 99800
    },
    {
      "epoch": 4.062048915363816,
      "grad_norm": 0.2644340991973877,
      "learning_rate": 0.0003231753197893153,
      "loss": 0.3522,
      "step": 99900
    },
    {
      "epoch": 4.06611503039421,
      "grad_norm": 0.3997701406478882,
      "learning_rate": 0.0003229540123046962,
      "loss": 0.3523,
      "step": 100000
    },
    {
      "epoch": 4.06611503039421,
      "eval_loss": 0.3642062246799469,
      "eval_runtime": 126.1905,
      "eval_samples_per_second": 1386.015,
      "eval_steps_per_second": 43.315,
      "step": 100000
    },
    {
      "epoch": 4.070181145424604,
      "grad_norm": 0.31585103273391724,
      "learning_rate": 0.000322732704820077,
      "loss": 0.3494,
      "step": 100100
    },
    {
      "epoch": 4.074247260454999,
      "grad_norm": 0.286985844373703,
      "learning_rate": 0.0003225113973354579,
      "loss": 0.3496,
      "step": 100200
    },
    {
      "epoch": 4.078313375485393,
      "grad_norm": 0.27744337916374207,
      "learning_rate": 0.0003222900898508387,
      "loss": 0.3519,
      "step": 100300
    },
    {
      "epoch": 4.082379490515787,
      "grad_norm": 0.2859601676464081,
      "learning_rate": 0.0003220687823662196,
      "loss": 0.3532,
      "step": 100400
    },
    {
      "epoch": 4.086445605546181,
      "grad_norm": 0.3319902718067169,
      "learning_rate": 0.0003218474748816005,
      "loss": 0.352,
      "step": 100500
    },
    {
      "epoch": 4.0905117205765755,
      "grad_norm": 0.30853524804115295,
      "learning_rate": 0.00032162616739698135,
      "loss": 0.3508,
      "step": 100600
    },
    {
      "epoch": 4.0945778356069695,
      "grad_norm": 0.29724085330963135,
      "learning_rate": 0.00032140485991236225,
      "loss": 0.3526,
      "step": 100700
    },
    {
      "epoch": 4.0986439506373635,
      "grad_norm": 0.31140851974487305,
      "learning_rate": 0.0003211835524277431,
      "loss": 0.3503,
      "step": 100800
    },
    {
      "epoch": 4.1027100656677575,
      "grad_norm": 0.2909235954284668,
      "learning_rate": 0.000320962244943124,
      "loss": 0.3496,
      "step": 100900
    },
    {
      "epoch": 4.1067761806981515,
      "grad_norm": 0.2924637496471405,
      "learning_rate": 0.00032074093745850484,
      "loss": 0.3519,
      "step": 101000
    },
    {
      "epoch": 4.110842295728546,
      "grad_norm": 0.3821958601474762,
      "learning_rate": 0.00032051962997388573,
      "loss": 0.3527,
      "step": 101100
    },
    {
      "epoch": 4.11490841075894,
      "grad_norm": 0.29547420144081116,
      "learning_rate": 0.0003202983224892666,
      "loss": 0.3498,
      "step": 101200
    },
    {
      "epoch": 4.118974525789334,
      "grad_norm": 0.2900371849536896,
      "learning_rate": 0.00032007701500464747,
      "loss": 0.3508,
      "step": 101300
    },
    {
      "epoch": 4.123040640819728,
      "grad_norm": 0.29576626420021057,
      "learning_rate": 0.00031985570752002837,
      "loss": 0.3509,
      "step": 101400
    },
    {
      "epoch": 4.127106755850123,
      "grad_norm": 0.36127325892448425,
      "learning_rate": 0.0003196344000354092,
      "loss": 0.3514,
      "step": 101500
    },
    {
      "epoch": 4.131172870880517,
      "grad_norm": 0.36601659655570984,
      "learning_rate": 0.0003194130925507901,
      "loss": 0.3508,
      "step": 101600
    },
    {
      "epoch": 4.135238985910911,
      "grad_norm": 0.33329132199287415,
      "learning_rate": 0.00031919178506617095,
      "loss": 0.3502,
      "step": 101700
    },
    {
      "epoch": 4.139305100941305,
      "grad_norm": 0.3347416818141937,
      "learning_rate": 0.0003189704775815518,
      "loss": 0.3532,
      "step": 101800
    },
    {
      "epoch": 4.1433712159717,
      "grad_norm": 0.25023433566093445,
      "learning_rate": 0.00031874917009693264,
      "loss": 0.3517,
      "step": 101900
    },
    {
      "epoch": 4.147437331002094,
      "grad_norm": 0.2843376696109772,
      "learning_rate": 0.00031852786261231354,
      "loss": 0.3497,
      "step": 102000
    },
    {
      "epoch": 4.147437331002094,
      "eval_loss": 0.363616406917572,
      "eval_runtime": 126.5476,
      "eval_samples_per_second": 1382.104,
      "eval_steps_per_second": 43.193,
      "step": 102000
    },
    {
      "epoch": 4.151503446032488,
      "grad_norm": 0.3208973705768585,
      "learning_rate": 0.00031830655512769443,
      "loss": 0.3521,
      "step": 102100
    },
    {
      "epoch": 4.155569561062882,
      "grad_norm": 0.3310740888118744,
      "learning_rate": 0.0003180852476430753,
      "loss": 0.3524,
      "step": 102200
    },
    {
      "epoch": 4.159635676093277,
      "grad_norm": 0.3182237148284912,
      "learning_rate": 0.0003178639401584562,
      "loss": 0.35,
      "step": 102300
    },
    {
      "epoch": 4.163701791123671,
      "grad_norm": 0.35226085782051086,
      "learning_rate": 0.000317642632673837,
      "loss": 0.3505,
      "step": 102400
    },
    {
      "epoch": 4.167767906154065,
      "grad_norm": 0.2514483630657196,
      "learning_rate": 0.0003174213251892179,
      "loss": 0.3502,
      "step": 102500
    },
    {
      "epoch": 4.171834021184459,
      "grad_norm": 0.28943610191345215,
      "learning_rate": 0.00031720001770459876,
      "loss": 0.3496,
      "step": 102600
    },
    {
      "epoch": 4.175900136214853,
      "grad_norm": 0.2928597033023834,
      "learning_rate": 0.00031697871021997966,
      "loss": 0.3504,
      "step": 102700
    },
    {
      "epoch": 4.179966251245248,
      "grad_norm": 0.3499153256416321,
      "learning_rate": 0.0003167574027353605,
      "loss": 0.3507,
      "step": 102800
    },
    {
      "epoch": 4.184032366275642,
      "grad_norm": 0.26632335782051086,
      "learning_rate": 0.0003165360952507414,
      "loss": 0.3525,
      "step": 102900
    },
    {
      "epoch": 4.188098481306036,
      "grad_norm": 0.3874906301498413,
      "learning_rate": 0.0003163147877661223,
      "loss": 0.3506,
      "step": 103000
    },
    {
      "epoch": 4.19216459633643,
      "grad_norm": 0.2993924021720886,
      "learning_rate": 0.00031609348028150314,
      "loss": 0.3533,
      "step": 103100
    },
    {
      "epoch": 4.196230711366825,
      "grad_norm": 0.3608728051185608,
      "learning_rate": 0.00031587217279688403,
      "loss": 0.3523,
      "step": 103200
    },
    {
      "epoch": 4.200296826397219,
      "grad_norm": 0.3282438814640045,
      "learning_rate": 0.0003156508653122649,
      "loss": 0.3489,
      "step": 103300
    },
    {
      "epoch": 4.204362941427613,
      "grad_norm": 0.4222852885723114,
      "learning_rate": 0.0003154295578276458,
      "loss": 0.3501,
      "step": 103400
    },
    {
      "epoch": 4.208429056458007,
      "grad_norm": 0.2682098150253296,
      "learning_rate": 0.00031520825034302656,
      "loss": 0.3509,
      "step": 103500
    },
    {
      "epoch": 4.212495171488402,
      "grad_norm": 0.30895763635635376,
      "learning_rate": 0.00031498694285840746,
      "loss": 0.35,
      "step": 103600
    },
    {
      "epoch": 4.216561286518796,
      "grad_norm": 0.35930925607681274,
      "learning_rate": 0.0003147656353737883,
      "loss": 0.3496,
      "step": 103700
    },
    {
      "epoch": 4.22062740154919,
      "grad_norm": 0.33234962821006775,
      "learning_rate": 0.0003145443278891692,
      "loss": 0.3512,
      "step": 103800
    },
    {
      "epoch": 4.224693516579584,
      "grad_norm": 0.310909241437912,
      "learning_rate": 0.0003143230204045501,
      "loss": 0.3527,
      "step": 103900
    },
    {
      "epoch": 4.228759631609979,
      "grad_norm": 0.3766334354877472,
      "learning_rate": 0.00031410171291993094,
      "loss": 0.3534,
      "step": 104000
    },
    {
      "epoch": 4.228759631609979,
      "eval_loss": 0.3632649779319763,
      "eval_runtime": 128.3899,
      "eval_samples_per_second": 1362.272,
      "eval_steps_per_second": 42.573,
      "step": 104000
    },
    {
      "epoch": 4.232825746640373,
      "grad_norm": 0.3310511112213135,
      "learning_rate": 0.00031388040543531184,
      "loss": 0.3514,
      "step": 104100
    },
    {
      "epoch": 4.236891861670767,
      "grad_norm": 0.3238520920276642,
      "learning_rate": 0.0003136590979506927,
      "loss": 0.3527,
      "step": 104200
    },
    {
      "epoch": 4.240957976701161,
      "grad_norm": 0.3140600025653839,
      "learning_rate": 0.0003134377904660736,
      "loss": 0.3522,
      "step": 104300
    },
    {
      "epoch": 4.245024091731555,
      "grad_norm": 0.3217984139919281,
      "learning_rate": 0.0003132164829814544,
      "loss": 0.3515,
      "step": 104400
    },
    {
      "epoch": 4.24909020676195,
      "grad_norm": 0.2744100093841553,
      "learning_rate": 0.0003129951754968353,
      "loss": 0.3509,
      "step": 104500
    },
    {
      "epoch": 4.253156321792344,
      "grad_norm": 0.325987845659256,
      "learning_rate": 0.00031277386801221616,
      "loss": 0.3531,
      "step": 104600
    },
    {
      "epoch": 4.257222436822738,
      "grad_norm": 0.3336884677410126,
      "learning_rate": 0.00031255256052759706,
      "loss": 0.3516,
      "step": 104700
    },
    {
      "epoch": 4.261288551853132,
      "grad_norm": 0.32095685601234436,
      "learning_rate": 0.00031233125304297796,
      "loss": 0.3497,
      "step": 104800
    },
    {
      "epoch": 4.2653546668835265,
      "grad_norm": 0.3451770842075348,
      "learning_rate": 0.0003121099455583588,
      "loss": 0.3507,
      "step": 104900
    },
    {
      "epoch": 4.2694207819139205,
      "grad_norm": 0.30488768219947815,
      "learning_rate": 0.0003118886380737397,
      "loss": 0.3528,
      "step": 105000
    },
    {
      "epoch": 4.2734868969443145,
      "grad_norm": 0.29475662112236023,
      "learning_rate": 0.00031166733058912054,
      "loss": 0.3519,
      "step": 105100
    },
    {
      "epoch": 4.2775530119747085,
      "grad_norm": 0.38839834928512573,
      "learning_rate": 0.0003114460231045014,
      "loss": 0.3511,
      "step": 105200
    },
    {
      "epoch": 4.281619127005103,
      "grad_norm": 0.2748733162879944,
      "learning_rate": 0.00031122471561988223,
      "loss": 0.3516,
      "step": 105300
    },
    {
      "epoch": 4.285685242035497,
      "grad_norm": 0.3911159932613373,
      "learning_rate": 0.0003110034081352631,
      "loss": 0.3495,
      "step": 105400
    },
    {
      "epoch": 4.289751357065891,
      "grad_norm": 0.3037012815475464,
      "learning_rate": 0.000310782100650644,
      "loss": 0.3492,
      "step": 105500
    },
    {
      "epoch": 4.293817472096285,
      "grad_norm": 0.3600950837135315,
      "learning_rate": 0.00031056079316602487,
      "loss": 0.3508,
      "step": 105600
    },
    {
      "epoch": 4.29788358712668,
      "grad_norm": 0.3167506456375122,
      "learning_rate": 0.00031033948568140576,
      "loss": 0.3504,
      "step": 105700
    },
    {
      "epoch": 4.301949702157074,
      "grad_norm": 0.33774229884147644,
      "learning_rate": 0.0003101181781967866,
      "loss": 0.3517,
      "step": 105800
    },
    {
      "epoch": 4.306015817187468,
      "grad_norm": 0.38811057806015015,
      "learning_rate": 0.0003098968707121675,
      "loss": 0.3534,
      "step": 105900
    },
    {
      "epoch": 4.310081932217862,
      "grad_norm": 0.304076611995697,
      "learning_rate": 0.00030967556322754835,
      "loss": 0.3528,
      "step": 106000
    },
    {
      "epoch": 4.310081932217862,
      "eval_loss": 0.3634294271469116,
      "eval_runtime": 125.8514,
      "eval_samples_per_second": 1389.75,
      "eval_steps_per_second": 43.432,
      "step": 106000
    },
    {
      "epoch": 4.314148047248256,
      "grad_norm": 0.34731829166412354,
      "learning_rate": 0.00030945425574292924,
      "loss": 0.3525,
      "step": 106100
    },
    {
      "epoch": 4.318214162278651,
      "grad_norm": 0.36355483531951904,
      "learning_rate": 0.0003092329482583101,
      "loss": 0.3516,
      "step": 106200
    },
    {
      "epoch": 4.322280277309045,
      "grad_norm": 0.3822862207889557,
      "learning_rate": 0.000309011640773691,
      "loss": 0.3491,
      "step": 106300
    },
    {
      "epoch": 4.326346392339439,
      "grad_norm": 0.34141555428504944,
      "learning_rate": 0.0003087903332890719,
      "loss": 0.3488,
      "step": 106400
    },
    {
      "epoch": 4.330412507369833,
      "grad_norm": 0.31276392936706543,
      "learning_rate": 0.0003085690258044527,
      "loss": 0.3505,
      "step": 106500
    },
    {
      "epoch": 4.334478622400228,
      "grad_norm": 0.32079094648361206,
      "learning_rate": 0.0003083477183198336,
      "loss": 0.3492,
      "step": 106600
    },
    {
      "epoch": 4.338544737430622,
      "grad_norm": 0.45807352662086487,
      "learning_rate": 0.00030812641083521446,
      "loss": 0.3532,
      "step": 106700
    },
    {
      "epoch": 4.342610852461016,
      "grad_norm": 0.32355108857154846,
      "learning_rate": 0.00030790510335059536,
      "loss": 0.3531,
      "step": 106800
    },
    {
      "epoch": 4.34667696749141,
      "grad_norm": 0.3022089898586273,
      "learning_rate": 0.00030768379586597615,
      "loss": 0.3541,
      "step": 106900
    },
    {
      "epoch": 4.350743082521804,
      "grad_norm": 0.3206276297569275,
      "learning_rate": 0.00030746248838135705,
      "loss": 0.3524,
      "step": 107000
    },
    {
      "epoch": 4.354809197552199,
      "grad_norm": 0.37854692339897156,
      "learning_rate": 0.0003072411808967379,
      "loss": 0.3538,
      "step": 107100
    },
    {
      "epoch": 4.358875312582593,
      "grad_norm": 0.30020052194595337,
      "learning_rate": 0.0003070198734121188,
      "loss": 0.3524,
      "step": 107200
    },
    {
      "epoch": 4.362941427612987,
      "grad_norm": 0.40808576345443726,
      "learning_rate": 0.0003067985659274997,
      "loss": 0.352,
      "step": 107300
    },
    {
      "epoch": 4.367007542643381,
      "grad_norm": 0.39599210023880005,
      "learning_rate": 0.00030657725844288053,
      "loss": 0.3534,
      "step": 107400
    },
    {
      "epoch": 4.371073657673776,
      "grad_norm": 0.3801738917827606,
      "learning_rate": 0.0003063559509582614,
      "loss": 0.3538,
      "step": 107500
    },
    {
      "epoch": 4.37513977270417,
      "grad_norm": 0.3275294005870819,
      "learning_rate": 0.00030613464347364227,
      "loss": 0.3519,
      "step": 107600
    },
    {
      "epoch": 4.379205887734564,
      "grad_norm": 0.33435818552970886,
      "learning_rate": 0.00030591333598902317,
      "loss": 0.3494,
      "step": 107700
    },
    {
      "epoch": 4.383272002764958,
      "grad_norm": 0.34233176708221436,
      "learning_rate": 0.000305692028504404,
      "loss": 0.3515,
      "step": 107800
    },
    {
      "epoch": 4.387338117795353,
      "grad_norm": 0.3096834421157837,
      "learning_rate": 0.0003054707210197849,
      "loss": 0.3519,
      "step": 107900
    },
    {
      "epoch": 4.391404232825747,
      "grad_norm": 0.30175623297691345,
      "learning_rate": 0.00030524941353516575,
      "loss": 0.3506,
      "step": 108000
    },
    {
      "epoch": 4.391404232825747,
      "eval_loss": 0.36294761300086975,
      "eval_runtime": 126.2819,
      "eval_samples_per_second": 1385.012,
      "eval_steps_per_second": 43.284,
      "step": 108000
    },
    {
      "epoch": 4.395470347856141,
      "grad_norm": 0.30722305178642273,
      "learning_rate": 0.00030502810605054665,
      "loss": 0.3508,
      "step": 108100
    },
    {
      "epoch": 4.399536462886535,
      "grad_norm": 0.2768442630767822,
      "learning_rate": 0.00030480679856592755,
      "loss": 0.3517,
      "step": 108200
    },
    {
      "epoch": 4.40360257791693,
      "grad_norm": 0.35521554946899414,
      "learning_rate": 0.0003045854910813084,
      "loss": 0.352,
      "step": 108300
    },
    {
      "epoch": 4.407668692947324,
      "grad_norm": 0.38899680972099304,
      "learning_rate": 0.0003043641835966893,
      "loss": 0.3516,
      "step": 108400
    },
    {
      "epoch": 4.411734807977718,
      "grad_norm": 0.3078356683254242,
      "learning_rate": 0.00030414287611207013,
      "loss": 0.3524,
      "step": 108500
    },
    {
      "epoch": 4.415800923008112,
      "grad_norm": 0.4021647870540619,
      "learning_rate": 0.00030392156862745097,
      "loss": 0.3507,
      "step": 108600
    },
    {
      "epoch": 4.419867038038506,
      "grad_norm": 0.508131742477417,
      "learning_rate": 0.0003037002611428318,
      "loss": 0.3512,
      "step": 108700
    },
    {
      "epoch": 4.423933153068901,
      "grad_norm": 0.4706050157546997,
      "learning_rate": 0.0003034789536582127,
      "loss": 0.3517,
      "step": 108800
    },
    {
      "epoch": 4.427999268099295,
      "grad_norm": 0.3143731355667114,
      "learning_rate": 0.00030325764617359356,
      "loss": 0.3511,
      "step": 108900
    },
    {
      "epoch": 4.432065383129689,
      "grad_norm": 0.3737376630306244,
      "learning_rate": 0.00030303633868897445,
      "loss": 0.3528,
      "step": 109000
    },
    {
      "epoch": 4.436131498160083,
      "grad_norm": 0.38138389587402344,
      "learning_rate": 0.00030281503120435535,
      "loss": 0.3543,
      "step": 109100
    },
    {
      "epoch": 4.4401976131904775,
      "grad_norm": 0.28654101490974426,
      "learning_rate": 0.0003025937237197362,
      "loss": 0.3509,
      "step": 109200
    },
    {
      "epoch": 4.4442637282208715,
      "grad_norm": 0.34448713064193726,
      "learning_rate": 0.0003023724162351171,
      "loss": 0.3517,
      "step": 109300
    },
    {
      "epoch": 4.4483298432512655,
      "grad_norm": 0.3030003309249878,
      "learning_rate": 0.00030215110875049793,
      "loss": 0.3495,
      "step": 109400
    },
    {
      "epoch": 4.4523959582816595,
      "grad_norm": 0.3039032518863678,
      "learning_rate": 0.00030192980126587883,
      "loss": 0.3492,
      "step": 109500
    },
    {
      "epoch": 4.456462073312054,
      "grad_norm": 0.3088277578353882,
      "learning_rate": 0.0003017084937812597,
      "loss": 0.3513,
      "step": 109600
    },
    {
      "epoch": 4.460528188342448,
      "grad_norm": 0.31107303500175476,
      "learning_rate": 0.00030148718629664057,
      "loss": 0.3499,
      "step": 109700
    },
    {
      "epoch": 4.464594303372842,
      "grad_norm": 0.3054758906364441,
      "learning_rate": 0.00030126587881202147,
      "loss": 0.3504,
      "step": 109800
    },
    {
      "epoch": 4.468660418403236,
      "grad_norm": 0.2844955623149872,
      "learning_rate": 0.0003010445713274023,
      "loss": 0.3502,
      "step": 109900
    },
    {
      "epoch": 4.472726533433631,
      "grad_norm": 0.3607885241508484,
      "learning_rate": 0.0003008232638427832,
      "loss": 0.3513,
      "step": 110000
    },
    {
      "epoch": 4.472726533433631,
      "eval_loss": 0.3623065650463104,
      "eval_runtime": 127.2646,
      "eval_samples_per_second": 1374.318,
      "eval_steps_per_second": 42.95,
      "step": 110000
    },
    {
      "epoch": 4.476792648464025,
      "grad_norm": 0.354002445936203,
      "learning_rate": 0.00030060195635816405,
      "loss": 0.3501,
      "step": 110100
    },
    {
      "epoch": 4.480858763494419,
      "grad_norm": 0.2924163043498993,
      "learning_rate": 0.00030038064887354495,
      "loss": 0.3534,
      "step": 110200
    },
    {
      "epoch": 4.484924878524813,
      "grad_norm": 0.3194727599620819,
      "learning_rate": 0.00030015934138892574,
      "loss": 0.352,
      "step": 110300
    },
    {
      "epoch": 4.488990993555207,
      "grad_norm": 0.3525697886943817,
      "learning_rate": 0.00029993803390430664,
      "loss": 0.351,
      "step": 110400
    },
    {
      "epoch": 4.493057108585602,
      "grad_norm": 0.43392306566238403,
      "learning_rate": 0.0002997167264196875,
      "loss": 0.3525,
      "step": 110500
    },
    {
      "epoch": 4.497123223615996,
      "grad_norm": 0.3721033036708832,
      "learning_rate": 0.0002994954189350684,
      "loss": 0.3512,
      "step": 110600
    },
    {
      "epoch": 4.50118933864639,
      "grad_norm": 0.47441431879997253,
      "learning_rate": 0.0002992741114504493,
      "loss": 0.3527,
      "step": 110700
    },
    {
      "epoch": 4.505255453676784,
      "grad_norm": 0.27866995334625244,
      "learning_rate": 0.0002990528039658301,
      "loss": 0.3491,
      "step": 110800
    },
    {
      "epoch": 4.509321568707179,
      "grad_norm": 0.316396027803421,
      "learning_rate": 0.000298831496481211,
      "loss": 0.3503,
      "step": 110900
    },
    {
      "epoch": 4.513387683737573,
      "grad_norm": 0.33339542150497437,
      "learning_rate": 0.00029861018899659186,
      "loss": 0.3509,
      "step": 111000
    },
    {
      "epoch": 4.517453798767967,
      "grad_norm": 0.3478710353374481,
      "learning_rate": 0.00029838888151197275,
      "loss": 0.3514,
      "step": 111100
    },
    {
      "epoch": 4.521519913798361,
      "grad_norm": 0.3646520674228668,
      "learning_rate": 0.0002981675740273536,
      "loss": 0.3498,
      "step": 111200
    },
    {
      "epoch": 4.525586028828756,
      "grad_norm": 0.3066771626472473,
      "learning_rate": 0.0002979462665427345,
      "loss": 0.3514,
      "step": 111300
    },
    {
      "epoch": 4.52965214385915,
      "grad_norm": 0.28938406705856323,
      "learning_rate": 0.00029772495905811534,
      "loss": 0.3498,
      "step": 111400
    },
    {
      "epoch": 4.533718258889544,
      "grad_norm": 0.4851302206516266,
      "learning_rate": 0.00029750365157349624,
      "loss": 0.3522,
      "step": 111500
    },
    {
      "epoch": 4.537784373919938,
      "grad_norm": 0.38765209913253784,
      "learning_rate": 0.00029728234408887713,
      "loss": 0.3506,
      "step": 111600
    },
    {
      "epoch": 4.541850488950333,
      "grad_norm": 0.34251075983047485,
      "learning_rate": 0.000297061036604258,
      "loss": 0.3517,
      "step": 111700
    },
    {
      "epoch": 4.545916603980727,
      "grad_norm": 0.40781062841415405,
      "learning_rate": 0.0002968397291196389,
      "loss": 0.3502,
      "step": 111800
    },
    {
      "epoch": 4.549982719011121,
      "grad_norm": 0.2830389440059662,
      "learning_rate": 0.00029661842163501966,
      "loss": 0.351,
      "step": 111900
    },
    {
      "epoch": 4.554048834041515,
      "grad_norm": 0.3174869418144226,
      "learning_rate": 0.00029639711415040056,
      "loss": 0.3502,
      "step": 112000
    },
    {
      "epoch": 4.554048834041515,
      "eval_loss": 0.36114323139190674,
      "eval_runtime": 125.8769,
      "eval_samples_per_second": 1389.469,
      "eval_steps_per_second": 43.423,
      "step": 112000
    },
    {
      "epoch": 4.558114949071909,
      "grad_norm": 0.31153300404548645,
      "learning_rate": 0.0002961758066657814,
      "loss": 0.3518,
      "step": 112100
    },
    {
      "epoch": 4.562181064102304,
      "grad_norm": 0.4037157893180847,
      "learning_rate": 0.0002959544991811623,
      "loss": 0.3519,
      "step": 112200
    },
    {
      "epoch": 4.566247179132698,
      "grad_norm": 0.3036736845970154,
      "learning_rate": 0.00029573319169654314,
      "loss": 0.3521,
      "step": 112300
    },
    {
      "epoch": 4.570313294163092,
      "grad_norm": 0.30684390664100647,
      "learning_rate": 0.00029551188421192404,
      "loss": 0.3478,
      "step": 112400
    },
    {
      "epoch": 4.574379409193486,
      "grad_norm": 0.3145487904548645,
      "learning_rate": 0.00029529057672730494,
      "loss": 0.3487,
      "step": 112500
    },
    {
      "epoch": 4.578445524223881,
      "grad_norm": 0.37036147713661194,
      "learning_rate": 0.0002950692692426858,
      "loss": 0.3511,
      "step": 112600
    },
    {
      "epoch": 4.582511639254275,
      "grad_norm": 0.2988993525505066,
      "learning_rate": 0.0002948479617580667,
      "loss": 0.3523,
      "step": 112700
    },
    {
      "epoch": 4.586577754284669,
      "grad_norm": 0.4028792977333069,
      "learning_rate": 0.0002946266542734475,
      "loss": 0.3518,
      "step": 112800
    },
    {
      "epoch": 4.590643869315063,
      "grad_norm": 0.46341973543167114,
      "learning_rate": 0.0002944053467888284,
      "loss": 0.3515,
      "step": 112900
    },
    {
      "epoch": 4.5947099843454575,
      "grad_norm": 0.30836203694343567,
      "learning_rate": 0.00029418403930420926,
      "loss": 0.3508,
      "step": 113000
    },
    {
      "epoch": 4.5987760993758515,
      "grad_norm": 0.2942692041397095,
      "learning_rate": 0.00029396273181959016,
      "loss": 0.3503,
      "step": 113100
    },
    {
      "epoch": 4.6028422144062455,
      "grad_norm": 0.3922101557254791,
      "learning_rate": 0.00029374142433497106,
      "loss": 0.3503,
      "step": 113200
    },
    {
      "epoch": 4.6069083294366395,
      "grad_norm": 0.4108639657497406,
      "learning_rate": 0.0002935201168503519,
      "loss": 0.3504,
      "step": 113300
    },
    {
      "epoch": 4.610974444467034,
      "grad_norm": 0.31312310695648193,
      "learning_rate": 0.0002932988093657328,
      "loss": 0.3499,
      "step": 113400
    },
    {
      "epoch": 4.615040559497428,
      "grad_norm": 0.2903859615325928,
      "learning_rate": 0.00029307750188111364,
      "loss": 0.3512,
      "step": 113500
    },
    {
      "epoch": 4.619106674527822,
      "grad_norm": 0.33566218614578247,
      "learning_rate": 0.0002928561943964945,
      "loss": 0.3521,
      "step": 113600
    },
    {
      "epoch": 4.623172789558216,
      "grad_norm": 0.32066622376441956,
      "learning_rate": 0.0002926348869118753,
      "loss": 0.3517,
      "step": 113700
    },
    {
      "epoch": 4.62723890458861,
      "grad_norm": 0.38949793577194214,
      "learning_rate": 0.0002924135794272562,
      "loss": 0.3497,
      "step": 113800
    },
    {
      "epoch": 4.631305019619005,
      "grad_norm": 0.3792153000831604,
      "learning_rate": 0.00029219227194263707,
      "loss": 0.3505,
      "step": 113900
    },
    {
      "epoch": 4.635371134649399,
      "grad_norm": 0.34536293148994446,
      "learning_rate": 0.00029197096445801796,
      "loss": 0.352,
      "step": 114000
    },
    {
      "epoch": 4.635371134649399,
      "eval_loss": 0.3617251217365265,
      "eval_runtime": 127.2617,
      "eval_samples_per_second": 1374.349,
      "eval_steps_per_second": 42.951,
      "step": 114000
    },
    {
      "epoch": 4.639437249679793,
      "grad_norm": 0.33094191551208496,
      "learning_rate": 0.00029174965697339886,
      "loss": 0.3501,
      "step": 114100
    },
    {
      "epoch": 4.643503364710187,
      "grad_norm": 0.3405892550945282,
      "learning_rate": 0.0002915283494887797,
      "loss": 0.3519,
      "step": 114200
    },
    {
      "epoch": 4.647569479740582,
      "grad_norm": 0.3515070676803589,
      "learning_rate": 0.0002913070420041606,
      "loss": 0.3503,
      "step": 114300
    },
    {
      "epoch": 4.651635594770976,
      "grad_norm": 0.40743377804756165,
      "learning_rate": 0.00029108573451954144,
      "loss": 0.3513,
      "step": 114400
    },
    {
      "epoch": 4.65570170980137,
      "grad_norm": 0.34630537033081055,
      "learning_rate": 0.00029086442703492234,
      "loss": 0.3492,
      "step": 114500
    },
    {
      "epoch": 4.659767824831764,
      "grad_norm": 0.352750301361084,
      "learning_rate": 0.0002906431195503032,
      "loss": 0.3505,
      "step": 114600
    },
    {
      "epoch": 4.663833939862158,
      "grad_norm": 0.3697996437549591,
      "learning_rate": 0.0002904218120656841,
      "loss": 0.3484,
      "step": 114700
    },
    {
      "epoch": 4.667900054892553,
      "grad_norm": 0.27545517683029175,
      "learning_rate": 0.0002902005045810649,
      "loss": 0.3526,
      "step": 114800
    },
    {
      "epoch": 4.671966169922947,
      "grad_norm": 0.47395867109298706,
      "learning_rate": 0.0002899791970964458,
      "loss": 0.3499,
      "step": 114900
    },
    {
      "epoch": 4.676032284953341,
      "grad_norm": 0.29928651452064514,
      "learning_rate": 0.0002897578896118267,
      "loss": 0.3499,
      "step": 115000
    },
    {
      "epoch": 4.680098399983736,
      "grad_norm": 0.32803580164909363,
      "learning_rate": 0.00028953658212720756,
      "loss": 0.3468,
      "step": 115100
    },
    {
      "epoch": 4.68416451501413,
      "grad_norm": 0.32039663195610046,
      "learning_rate": 0.00028931527464258846,
      "loss": 0.3504,
      "step": 115200
    },
    {
      "epoch": 4.688230630044524,
      "grad_norm": 0.3408956229686737,
      "learning_rate": 0.00028909396715796925,
      "loss": 0.3509,
      "step": 115300
    },
    {
      "epoch": 4.692296745074918,
      "grad_norm": 0.33068862557411194,
      "learning_rate": 0.00028887265967335015,
      "loss": 0.3513,
      "step": 115400
    },
    {
      "epoch": 4.696362860105312,
      "grad_norm": 0.40290072560310364,
      "learning_rate": 0.000288651352188731,
      "loss": 0.3509,
      "step": 115500
    },
    {
      "epoch": 4.700428975135707,
      "grad_norm": 0.3460973799228668,
      "learning_rate": 0.0002884300447041119,
      "loss": 0.3511,
      "step": 115600
    },
    {
      "epoch": 4.704495090166101,
      "grad_norm": 0.32572445273399353,
      "learning_rate": 0.00028820873721949273,
      "loss": 0.3495,
      "step": 115700
    },
    {
      "epoch": 4.708561205196495,
      "grad_norm": 0.33387330174446106,
      "learning_rate": 0.00028798742973487363,
      "loss": 0.3501,
      "step": 115800
    },
    {
      "epoch": 4.712627320226889,
      "grad_norm": 0.4155007600784302,
      "learning_rate": 0.0002877661222502545,
      "loss": 0.3501,
      "step": 115900
    },
    {
      "epoch": 4.716693435257284,
      "grad_norm": 0.3644959628582001,
      "learning_rate": 0.00028754481476563537,
      "loss": 0.3515,
      "step": 116000
    },
    {
      "epoch": 4.716693435257284,
      "eval_loss": 0.3614059090614319,
      "eval_runtime": 126.0239,
      "eval_samples_per_second": 1387.848,
      "eval_steps_per_second": 43.373,
      "step": 116000
    },
    {
      "epoch": 4.720759550287678,
      "grad_norm": 0.3511272370815277,
      "learning_rate": 0.00028732350728101627,
      "loss": 0.3506,
      "step": 116100
    },
    {
      "epoch": 4.724825665318072,
      "grad_norm": 0.3535180389881134,
      "learning_rate": 0.0002871021997963971,
      "loss": 0.3491,
      "step": 116200
    },
    {
      "epoch": 4.728891780348466,
      "grad_norm": 0.31838148832321167,
      "learning_rate": 0.000286880892311778,
      "loss": 0.3494,
      "step": 116300
    },
    {
      "epoch": 4.73295789537886,
      "grad_norm": 0.3509930968284607,
      "learning_rate": 0.00028665958482715885,
      "loss": 0.3515,
      "step": 116400
    },
    {
      "epoch": 4.737024010409255,
      "grad_norm": 0.31936565041542053,
      "learning_rate": 0.00028643827734253975,
      "loss": 0.3497,
      "step": 116500
    },
    {
      "epoch": 4.741090125439649,
      "grad_norm": 0.33182746171951294,
      "learning_rate": 0.00028621696985792064,
      "loss": 0.3509,
      "step": 116600
    },
    {
      "epoch": 4.745156240470043,
      "grad_norm": 0.29087528586387634,
      "learning_rate": 0.0002859956623733015,
      "loss": 0.3495,
      "step": 116700
    },
    {
      "epoch": 4.749222355500438,
      "grad_norm": 0.2945420742034912,
      "learning_rate": 0.0002857743548886824,
      "loss": 0.3523,
      "step": 116800
    },
    {
      "epoch": 4.753288470530832,
      "grad_norm": 0.3318482041358948,
      "learning_rate": 0.00028555304740406323,
      "loss": 0.3492,
      "step": 116900
    },
    {
      "epoch": 4.757354585561226,
      "grad_norm": 0.3160204589366913,
      "learning_rate": 0.00028533173991944407,
      "loss": 0.3509,
      "step": 117000
    },
    {
      "epoch": 4.76142070059162,
      "grad_norm": 0.3566751778125763,
      "learning_rate": 0.0002851104324348249,
      "loss": 0.3522,
      "step": 117100
    },
    {
      "epoch": 4.765486815622014,
      "grad_norm": 0.3041452467441559,
      "learning_rate": 0.0002848891249502058,
      "loss": 0.3493,
      "step": 117200
    },
    {
      "epoch": 4.7695529306524085,
      "grad_norm": 0.3280685842037201,
      "learning_rate": 0.00028466781746558665,
      "loss": 0.3498,
      "step": 117300
    },
    {
      "epoch": 4.7736190456828025,
      "grad_norm": 0.354697585105896,
      "learning_rate": 0.00028444650998096755,
      "loss": 0.3516,
      "step": 117400
    },
    {
      "epoch": 4.7776851607131965,
      "grad_norm": 0.38052013516426086,
      "learning_rate": 0.00028422520249634845,
      "loss": 0.3507,
      "step": 117500
    },
    {
      "epoch": 4.7817512757435905,
      "grad_norm": 0.32863467931747437,
      "learning_rate": 0.0002840038950117293,
      "loss": 0.3503,
      "step": 117600
    },
    {
      "epoch": 4.785817390773985,
      "grad_norm": 0.3183680474758148,
      "learning_rate": 0.0002837825875271102,
      "loss": 0.3511,
      "step": 117700
    },
    {
      "epoch": 4.789883505804379,
      "grad_norm": 0.35020196437835693,
      "learning_rate": 0.00028356128004249103,
      "loss": 0.3501,
      "step": 117800
    },
    {
      "epoch": 4.793949620834773,
      "grad_norm": 0.31234365701675415,
      "learning_rate": 0.00028333997255787193,
      "loss": 0.3494,
      "step": 117900
    },
    {
      "epoch": 4.798015735865167,
      "grad_norm": 0.3377286195755005,
      "learning_rate": 0.00028311866507325277,
      "loss": 0.3525,
      "step": 118000
    },
    {
      "epoch": 4.798015735865167,
      "eval_loss": 0.36077016592025757,
      "eval_runtime": 126.5796,
      "eval_samples_per_second": 1381.755,
      "eval_steps_per_second": 43.182,
      "step": 118000
    },
    {
      "epoch": 4.802081850895561,
      "grad_norm": 0.32359856367111206,
      "learning_rate": 0.00028289735758863367,
      "loss": 0.3525,
      "step": 118100
    },
    {
      "epoch": 4.806147965925956,
      "grad_norm": 0.36511993408203125,
      "learning_rate": 0.0002826760501040145,
      "loss": 0.3506,
      "step": 118200
    },
    {
      "epoch": 4.81021408095635,
      "grad_norm": 0.363569438457489,
      "learning_rate": 0.0002824547426193954,
      "loss": 0.3501,
      "step": 118300
    },
    {
      "epoch": 4.814280195986744,
      "grad_norm": 0.34361106157302856,
      "learning_rate": 0.0002822334351347763,
      "loss": 0.3503,
      "step": 118400
    },
    {
      "epoch": 4.818346311017139,
      "grad_norm": 0.38939934968948364,
      "learning_rate": 0.00028201212765015715,
      "loss": 0.3479,
      "step": 118500
    },
    {
      "epoch": 4.822412426047533,
      "grad_norm": 0.3417090177536011,
      "learning_rate": 0.00028179082016553805,
      "loss": 0.3495,
      "step": 118600
    },
    {
      "epoch": 4.826478541077927,
      "grad_norm": 0.36826494336128235,
      "learning_rate": 0.00028156951268091884,
      "loss": 0.3498,
      "step": 118700
    },
    {
      "epoch": 4.830544656108321,
      "grad_norm": 0.40997985005378723,
      "learning_rate": 0.00028134820519629973,
      "loss": 0.3502,
      "step": 118800
    },
    {
      "epoch": 4.834610771138715,
      "grad_norm": 0.3338482081890106,
      "learning_rate": 0.0002811268977116806,
      "loss": 0.3509,
      "step": 118900
    },
    {
      "epoch": 4.83867688616911,
      "grad_norm": 0.3207102417945862,
      "learning_rate": 0.0002809055902270615,
      "loss": 0.3503,
      "step": 119000
    },
    {
      "epoch": 4.842743001199504,
      "grad_norm": 0.36186233162879944,
      "learning_rate": 0.0002806842827424423,
      "loss": 0.3484,
      "step": 119100
    },
    {
      "epoch": 4.846809116229898,
      "grad_norm": 0.3599766790866852,
      "learning_rate": 0.0002804629752578232,
      "loss": 0.3503,
      "step": 119200
    },
    {
      "epoch": 4.850875231260292,
      "grad_norm": 0.3819277584552765,
      "learning_rate": 0.0002802416677732041,
      "loss": 0.3484,
      "step": 119300
    },
    {
      "epoch": 4.854941346290687,
      "grad_norm": 0.4308924973011017,
      "learning_rate": 0.00028002036028858496,
      "loss": 0.3489,
      "step": 119400
    },
    {
      "epoch": 4.859007461321081,
      "grad_norm": 0.34201154112815857,
      "learning_rate": 0.00027979905280396585,
      "loss": 0.35,
      "step": 119500
    },
    {
      "epoch": 4.863073576351475,
      "grad_norm": 0.40274113416671753,
      "learning_rate": 0.0002795777453193467,
      "loss": 0.3517,
      "step": 119600
    },
    {
      "epoch": 4.867139691381869,
      "grad_norm": 0.3858184516429901,
      "learning_rate": 0.0002793564378347276,
      "loss": 0.3493,
      "step": 119700
    },
    {
      "epoch": 4.871205806412263,
      "grad_norm": 0.3230181932449341,
      "learning_rate": 0.00027913513035010844,
      "loss": 0.3497,
      "step": 119800
    },
    {
      "epoch": 4.875271921442658,
      "grad_norm": 0.31791144609451294,
      "learning_rate": 0.00027891382286548933,
      "loss": 0.3515,
      "step": 119900
    },
    {
      "epoch": 4.879338036473052,
      "grad_norm": 0.3541773855686188,
      "learning_rate": 0.0002786925153808702,
      "loss": 0.3496,
      "step": 120000
    },
    {
      "epoch": 4.879338036473052,
      "eval_loss": 0.3604845404624939,
      "eval_runtime": 127.4286,
      "eval_samples_per_second": 1372.549,
      "eval_steps_per_second": 42.895,
      "step": 120000
    },
    {
      "epoch": 4.883404151503446,
      "grad_norm": 0.3615361750125885,
      "learning_rate": 0.0002784712078962511,
      "loss": 0.352,
      "step": 120100
    },
    {
      "epoch": 4.88747026653384,
      "grad_norm": 0.34712496399879456,
      "learning_rate": 0.00027824990041163197,
      "loss": 0.349,
      "step": 120200
    },
    {
      "epoch": 4.891536381564235,
      "grad_norm": 0.37317532300949097,
      "learning_rate": 0.0002780285929270128,
      "loss": 0.3499,
      "step": 120300
    },
    {
      "epoch": 4.895602496594629,
      "grad_norm": 0.3726099133491516,
      "learning_rate": 0.00027780728544239366,
      "loss": 0.3492,
      "step": 120400
    },
    {
      "epoch": 4.899668611625023,
      "grad_norm": 0.34437888860702515,
      "learning_rate": 0.0002775859779577745,
      "loss": 0.3495,
      "step": 120500
    },
    {
      "epoch": 4.903734726655417,
      "grad_norm": 0.4077475965023041,
      "learning_rate": 0.0002773646704731554,
      "loss": 0.3494,
      "step": 120600
    },
    {
      "epoch": 4.907800841685812,
      "grad_norm": 0.32358694076538086,
      "learning_rate": 0.00027714336298853624,
      "loss": 0.3502,
      "step": 120700
    },
    {
      "epoch": 4.911866956716206,
      "grad_norm": 0.317228227853775,
      "learning_rate": 0.00027692205550391714,
      "loss": 0.3518,
      "step": 120800
    },
    {
      "epoch": 4.9159330717466,
      "grad_norm": 0.44711506366729736,
      "learning_rate": 0.00027670074801929804,
      "loss": 0.3513,
      "step": 120900
    },
    {
      "epoch": 4.919999186776994,
      "grad_norm": 0.29577699303627014,
      "learning_rate": 0.0002764794405346789,
      "loss": 0.3482,
      "step": 121000
    },
    {
      "epoch": 4.9240653018073886,
      "grad_norm": 0.33339428901672363,
      "learning_rate": 0.0002762581330500598,
      "loss": 0.3522,
      "step": 121100
    },
    {
      "epoch": 4.9281314168377826,
      "grad_norm": 0.41667747497558594,
      "learning_rate": 0.0002760368255654406,
      "loss": 0.3475,
      "step": 121200
    },
    {
      "epoch": 4.9321975318681766,
      "grad_norm": 0.3423294126987457,
      "learning_rate": 0.0002758155180808215,
      "loss": 0.353,
      "step": 121300
    },
    {
      "epoch": 4.936263646898571,
      "grad_norm": 0.384678453207016,
      "learning_rate": 0.00027559421059620236,
      "loss": 0.3486,
      "step": 121400
    },
    {
      "epoch": 4.940329761928965,
      "grad_norm": 0.3587985634803772,
      "learning_rate": 0.00027537290311158326,
      "loss": 0.3489,
      "step": 121500
    },
    {
      "epoch": 4.9443958769593594,
      "grad_norm": 0.3594496548175812,
      "learning_rate": 0.0002751515956269641,
      "loss": 0.3503,
      "step": 121600
    },
    {
      "epoch": 4.9484619919897535,
      "grad_norm": 0.4638030230998993,
      "learning_rate": 0.000274930288142345,
      "loss": 0.3484,
      "step": 121700
    },
    {
      "epoch": 4.9525281070201475,
      "grad_norm": 0.35574737191200256,
      "learning_rate": 0.0002747089806577259,
      "loss": 0.348,
      "step": 121800
    },
    {
      "epoch": 4.9565942220505415,
      "grad_norm": 0.3343704044818878,
      "learning_rate": 0.00027448767317310674,
      "loss": 0.3495,
      "step": 121900
    },
    {
      "epoch": 4.960660337080936,
      "grad_norm": 0.3021767735481262,
      "learning_rate": 0.00027426636568848764,
      "loss": 0.3491,
      "step": 122000
    },
    {
      "epoch": 4.960660337080936,
      "eval_loss": 0.3598072826862335,
      "eval_runtime": 127.3161,
      "eval_samples_per_second": 1373.761,
      "eval_steps_per_second": 42.932,
      "step": 122000
    },
    {
      "epoch": 4.96472645211133,
      "grad_norm": 0.34794852137565613,
      "learning_rate": 0.0002740450582038684,
      "loss": 0.3506,
      "step": 122100
    },
    {
      "epoch": 4.968792567141724,
      "grad_norm": 0.33527401089668274,
      "learning_rate": 0.0002738237507192493,
      "loss": 0.3511,
      "step": 122200
    },
    {
      "epoch": 4.972858682172118,
      "grad_norm": 0.3577065169811249,
      "learning_rate": 0.00027360244323463016,
      "loss": 0.35,
      "step": 122300
    },
    {
      "epoch": 4.976924797202513,
      "grad_norm": 0.37479445338249207,
      "learning_rate": 0.00027338113575001106,
      "loss": 0.3502,
      "step": 122400
    },
    {
      "epoch": 4.980990912232907,
      "grad_norm": 0.3614955246448517,
      "learning_rate": 0.0002731598282653919,
      "loss": 0.3495,
      "step": 122500
    },
    {
      "epoch": 4.985057027263301,
      "grad_norm": 0.40253233909606934,
      "learning_rate": 0.0002729385207807728,
      "loss": 0.3497,
      "step": 122600
    },
    {
      "epoch": 4.989123142293695,
      "grad_norm": 0.36874181032180786,
      "learning_rate": 0.0002727172132961537,
      "loss": 0.3499,
      "step": 122700
    },
    {
      "epoch": 4.99318925732409,
      "grad_norm": 0.3509189486503601,
      "learning_rate": 0.00027249590581153454,
      "loss": 0.3497,
      "step": 122800
    },
    {
      "epoch": 4.997255372354484,
      "grad_norm": 0.45747286081314087,
      "learning_rate": 0.00027227459832691544,
      "loss": 0.3503,
      "step": 122900
    },
    {
      "epoch": 5.001321487384878,
      "grad_norm": 0.28074145317077637,
      "learning_rate": 0.0002720532908422963,
      "loss": 0.3482,
      "step": 123000
    },
    {
      "epoch": 5.005387602415272,
      "grad_norm": 0.33582282066345215,
      "learning_rate": 0.0002718319833576772,
      "loss": 0.3453,
      "step": 123100
    },
    {
      "epoch": 5.009453717445666,
      "grad_norm": 0.38441580533981323,
      "learning_rate": 0.000271610675873058,
      "loss": 0.3428,
      "step": 123200
    },
    {
      "epoch": 5.013519832476061,
      "grad_norm": 0.3445650637149811,
      "learning_rate": 0.0002713893683884389,
      "loss": 0.3452,
      "step": 123300
    },
    {
      "epoch": 5.017585947506455,
      "grad_norm": 0.4477256238460541,
      "learning_rate": 0.00027116806090381976,
      "loss": 0.3449,
      "step": 123400
    },
    {
      "epoch": 5.021652062536849,
      "grad_norm": 0.3348981738090515,
      "learning_rate": 0.00027094675341920066,
      "loss": 0.3445,
      "step": 123500
    },
    {
      "epoch": 5.025718177567243,
      "grad_norm": 0.4940996468067169,
      "learning_rate": 0.00027072544593458156,
      "loss": 0.3452,
      "step": 123600
    },
    {
      "epoch": 5.029784292597638,
      "grad_norm": 0.44154706597328186,
      "learning_rate": 0.00027050413844996235,
      "loss": 0.3426,
      "step": 123700
    },
    {
      "epoch": 5.033850407628032,
      "grad_norm": 0.3564061224460602,
      "learning_rate": 0.00027028283096534325,
      "loss": 0.3457,
      "step": 123800
    },
    {
      "epoch": 5.037916522658426,
      "grad_norm": 0.3489179313182831,
      "learning_rate": 0.0002700615234807241,
      "loss": 0.3441,
      "step": 123900
    },
    {
      "epoch": 5.04198263768882,
      "grad_norm": 0.37476930022239685,
      "learning_rate": 0.000269840215996105,
      "loss": 0.3436,
      "step": 124000
    },
    {
      "epoch": 5.04198263768882,
      "eval_loss": 0.3603629171848297,
      "eval_runtime": 126.6032,
      "eval_samples_per_second": 1381.497,
      "eval_steps_per_second": 43.174,
      "step": 124000
    },
    {
      "epoch": 5.046048752719215,
      "grad_norm": 0.3945677876472473,
      "learning_rate": 0.00026961890851148583,
      "loss": 0.3464,
      "step": 124100
    },
    {
      "epoch": 5.050114867749609,
      "grad_norm": 0.3510317802429199,
      "learning_rate": 0.0002693976010268667,
      "loss": 0.3439,
      "step": 124200
    },
    {
      "epoch": 5.054180982780003,
      "grad_norm": 0.3492114543914795,
      "learning_rate": 0.0002691762935422476,
      "loss": 0.3438,
      "step": 124300
    },
    {
      "epoch": 5.058247097810397,
      "grad_norm": 0.4669307470321655,
      "learning_rate": 0.00026895498605762847,
      "loss": 0.3456,
      "step": 124400
    },
    {
      "epoch": 5.062313212840791,
      "grad_norm": 0.448866605758667,
      "learning_rate": 0.00026873367857300936,
      "loss": 0.3439,
      "step": 124500
    },
    {
      "epoch": 5.066379327871186,
      "grad_norm": 0.3728223145008087,
      "learning_rate": 0.0002685123710883902,
      "loss": 0.3448,
      "step": 124600
    },
    {
      "epoch": 5.07044544290158,
      "grad_norm": 0.3108622431755066,
      "learning_rate": 0.0002682910636037711,
      "loss": 0.3471,
      "step": 124700
    },
    {
      "epoch": 5.074511557931974,
      "grad_norm": 0.5105547904968262,
      "learning_rate": 0.00026806975611915195,
      "loss": 0.3447,
      "step": 124800
    },
    {
      "epoch": 5.078577672962368,
      "grad_norm": 0.31888076663017273,
      "learning_rate": 0.00026784844863453284,
      "loss": 0.3461,
      "step": 124900
    },
    {
      "epoch": 5.082643787992763,
      "grad_norm": 0.37115299701690674,
      "learning_rate": 0.0002676271411499137,
      "loss": 0.3456,
      "step": 125000
    },
    {
      "epoch": 5.086709903023157,
      "grad_norm": 0.3107331395149231,
      "learning_rate": 0.0002674058336652946,
      "loss": 0.3468,
      "step": 125100
    },
    {
      "epoch": 5.090776018053551,
      "grad_norm": 0.38310447335243225,
      "learning_rate": 0.0002671845261806755,
      "loss": 0.3439,
      "step": 125200
    },
    {
      "epoch": 5.094842133083945,
      "grad_norm": 0.33348649740219116,
      "learning_rate": 0.0002669632186960563,
      "loss": 0.3455,
      "step": 125300
    },
    {
      "epoch": 5.0989082481143395,
      "grad_norm": 0.3317480683326721,
      "learning_rate": 0.00026674191121143717,
      "loss": 0.3443,
      "step": 125400
    },
    {
      "epoch": 5.1029743631447335,
      "grad_norm": 0.5342686176300049,
      "learning_rate": 0.000266520603726818,
      "loss": 0.3444,
      "step": 125500
    },
    {
      "epoch": 5.1070404781751275,
      "grad_norm": 0.3197856843471527,
      "learning_rate": 0.0002662992962421989,
      "loss": 0.3445,
      "step": 125600
    },
    {
      "epoch": 5.1111065932055215,
      "grad_norm": 0.3652482330799103,
      "learning_rate": 0.00026607798875757975,
      "loss": 0.3431,
      "step": 125700
    },
    {
      "epoch": 5.115172708235916,
      "grad_norm": 0.32566168904304504,
      "learning_rate": 0.00026585668127296065,
      "loss": 0.346,
      "step": 125800
    },
    {
      "epoch": 5.11923882326631,
      "grad_norm": 0.3594273328781128,
      "learning_rate": 0.0002656353737883415,
      "loss": 0.3442,
      "step": 125900
    },
    {
      "epoch": 5.123304938296704,
      "grad_norm": 0.34953340888023376,
      "learning_rate": 0.0002654140663037224,
      "loss": 0.3472,
      "step": 126000
    },
    {
      "epoch": 5.123304938296704,
      "eval_loss": 0.35926419496536255,
      "eval_runtime": 126.8812,
      "eval_samples_per_second": 1378.47,
      "eval_steps_per_second": 43.08,
      "step": 126000
    },
    {
      "epoch": 5.127371053327098,
      "grad_norm": 0.342284619808197,
      "learning_rate": 0.0002651927588191033,
      "loss": 0.3453,
      "step": 126100
    },
    {
      "epoch": 5.131437168357492,
      "grad_norm": 0.31440985202789307,
      "learning_rate": 0.00026497145133448413,
      "loss": 0.3441,
      "step": 126200
    },
    {
      "epoch": 5.135503283387887,
      "grad_norm": 0.3462204039096832,
      "learning_rate": 0.00026475014384986503,
      "loss": 0.3463,
      "step": 126300
    },
    {
      "epoch": 5.139569398418281,
      "grad_norm": 0.3809433579444885,
      "learning_rate": 0.00026452883636524587,
      "loss": 0.3465,
      "step": 126400
    },
    {
      "epoch": 5.143635513448675,
      "grad_norm": 0.3337632417678833,
      "learning_rate": 0.00026430752888062677,
      "loss": 0.3494,
      "step": 126500
    },
    {
      "epoch": 5.147701628479069,
      "grad_norm": 0.46148598194122314,
      "learning_rate": 0.0002640862213960076,
      "loss": 0.3451,
      "step": 126600
    },
    {
      "epoch": 5.151767743509464,
      "grad_norm": 0.35781392455101013,
      "learning_rate": 0.0002638649139113885,
      "loss": 0.3461,
      "step": 126700
    },
    {
      "epoch": 5.155833858539858,
      "grad_norm": 0.4103083610534668,
      "learning_rate": 0.00026364360642676935,
      "loss": 0.3447,
      "step": 126800
    },
    {
      "epoch": 5.159899973570252,
      "grad_norm": 0.38768643140792847,
      "learning_rate": 0.00026342229894215025,
      "loss": 0.3468,
      "step": 126900
    },
    {
      "epoch": 5.163966088600646,
      "grad_norm": 0.3513493239879608,
      "learning_rate": 0.00026320099145753115,
      "loss": 0.3466,
      "step": 127000
    },
    {
      "epoch": 5.168032203631041,
      "grad_norm": 0.40134042501449585,
      "learning_rate": 0.00026297968397291194,
      "loss": 0.3456,
      "step": 127100
    },
    {
      "epoch": 5.172098318661435,
      "grad_norm": 0.35659343004226685,
      "learning_rate": 0.00026275837648829283,
      "loss": 0.3452,
      "step": 127200
    },
    {
      "epoch": 5.176164433691829,
      "grad_norm": 0.4259348213672638,
      "learning_rate": 0.0002625370690036737,
      "loss": 0.3463,
      "step": 127300
    },
    {
      "epoch": 5.180230548722223,
      "grad_norm": 0.2971014678478241,
      "learning_rate": 0.0002623157615190546,
      "loss": 0.3452,
      "step": 127400
    },
    {
      "epoch": 5.184296663752617,
      "grad_norm": 0.38750746846199036,
      "learning_rate": 0.0002620944540344354,
      "loss": 0.3438,
      "step": 127500
    },
    {
      "epoch": 5.188362778783012,
      "grad_norm": 0.3004261553287506,
      "learning_rate": 0.0002618731465498163,
      "loss": 0.3458,
      "step": 127600
    },
    {
      "epoch": 5.192428893813406,
      "grad_norm": 0.3126216530799866,
      "learning_rate": 0.00026165183906519716,
      "loss": 0.3431,
      "step": 127700
    },
    {
      "epoch": 5.1964950088438,
      "grad_norm": 0.3732445538043976,
      "learning_rate": 0.00026143053158057805,
      "loss": 0.3463,
      "step": 127800
    },
    {
      "epoch": 5.200561123874194,
      "grad_norm": 0.36477431654930115,
      "learning_rate": 0.00026120922409595895,
      "loss": 0.3471,
      "step": 127900
    },
    {
      "epoch": 5.204627238904589,
      "grad_norm": 0.3759365379810333,
      "learning_rate": 0.0002609879166113398,
      "loss": 0.3474,
      "step": 128000
    },
    {
      "epoch": 5.204627238904589,
      "eval_loss": 0.35863372683525085,
      "eval_runtime": 125.8568,
      "eval_samples_per_second": 1389.691,
      "eval_steps_per_second": 43.43,
      "step": 128000
    },
    {
      "epoch": 5.208693353934983,
      "grad_norm": 0.35797351598739624,
      "learning_rate": 0.0002607666091267207,
      "loss": 0.3466,
      "step": 128100
    },
    {
      "epoch": 5.212759468965377,
      "grad_norm": 0.3664591908454895,
      "learning_rate": 0.00026054530164210154,
      "loss": 0.3436,
      "step": 128200
    },
    {
      "epoch": 5.216825583995771,
      "grad_norm": 0.3883223235607147,
      "learning_rate": 0.00026032399415748243,
      "loss": 0.3441,
      "step": 128300
    },
    {
      "epoch": 5.220891699026166,
      "grad_norm": 0.372930645942688,
      "learning_rate": 0.0002601026866728633,
      "loss": 0.347,
      "step": 128400
    },
    {
      "epoch": 5.22495781405656,
      "grad_norm": 0.3859964907169342,
      "learning_rate": 0.00025988137918824417,
      "loss": 0.3453,
      "step": 128500
    },
    {
      "epoch": 5.229023929086954,
      "grad_norm": 0.3670881986618042,
      "learning_rate": 0.00025966007170362507,
      "loss": 0.3446,
      "step": 128600
    },
    {
      "epoch": 5.233090044117348,
      "grad_norm": 0.3907679617404938,
      "learning_rate": 0.0002594387642190059,
      "loss": 0.3446,
      "step": 128700
    },
    {
      "epoch": 5.237156159147743,
      "grad_norm": 0.5339808464050293,
      "learning_rate": 0.00025921745673438676,
      "loss": 0.3458,
      "step": 128800
    },
    {
      "epoch": 5.241222274178137,
      "grad_norm": 0.3872831165790558,
      "learning_rate": 0.0002589961492497676,
      "loss": 0.346,
      "step": 128900
    },
    {
      "epoch": 5.245288389208531,
      "grad_norm": 0.33330217003822327,
      "learning_rate": 0.0002587748417651485,
      "loss": 0.3447,
      "step": 129000
    },
    {
      "epoch": 5.249354504238925,
      "grad_norm": 0.40265291929244995,
      "learning_rate": 0.00025855353428052934,
      "loss": 0.3484,
      "step": 129100
    },
    {
      "epoch": 5.253420619269319,
      "grad_norm": 0.3879311680793762,
      "learning_rate": 0.00025833222679591024,
      "loss": 0.3452,
      "step": 129200
    },
    {
      "epoch": 5.257486734299714,
      "grad_norm": 0.42522695660591125,
      "learning_rate": 0.0002581109193112911,
      "loss": 0.3438,
      "step": 129300
    },
    {
      "epoch": 5.261552849330108,
      "grad_norm": 0.40689265727996826,
      "learning_rate": 0.000257889611826672,
      "loss": 0.3455,
      "step": 129400
    },
    {
      "epoch": 5.265618964360502,
      "grad_norm": 0.42230740189552307,
      "learning_rate": 0.0002576683043420529,
      "loss": 0.3452,
      "step": 129500
    },
    {
      "epoch": 5.269685079390896,
      "grad_norm": 0.3617831766605377,
      "learning_rate": 0.0002574469968574337,
      "loss": 0.3462,
      "step": 129600
    },
    {
      "epoch": 5.2737511944212905,
      "grad_norm": 0.36692866683006287,
      "learning_rate": 0.0002572256893728146,
      "loss": 0.3458,
      "step": 129700
    },
    {
      "epoch": 5.2778173094516845,
      "grad_norm": 0.4524429738521576,
      "learning_rate": 0.00025700438188819546,
      "loss": 0.3467,
      "step": 129800
    },
    {
      "epoch": 5.2818834244820785,
      "grad_norm": 0.30405378341674805,
      "learning_rate": 0.00025678307440357636,
      "loss": 0.343,
      "step": 129900
    },
    {
      "epoch": 5.2859495395124725,
      "grad_norm": 0.4383062720298767,
      "learning_rate": 0.0002565617669189572,
      "loss": 0.3455,
      "step": 130000
    },
    {
      "epoch": 5.2859495395124725,
      "eval_loss": 0.35810863971710205,
      "eval_runtime": 128.1091,
      "eval_samples_per_second": 1365.259,
      "eval_steps_per_second": 42.667,
      "step": 130000
    },
    {
      "epoch": 5.290015654542867,
      "grad_norm": 0.32689282298088074,
      "learning_rate": 0.0002563404594343381,
      "loss": 0.3481,
      "step": 130100
    },
    {
      "epoch": 5.294081769573261,
      "grad_norm": 0.3658903241157532,
      "learning_rate": 0.00025611915194971894,
      "loss": 0.3461,
      "step": 130200
    },
    {
      "epoch": 5.298147884603655,
      "grad_norm": 0.33907562494277954,
      "learning_rate": 0.00025589784446509984,
      "loss": 0.3461,
      "step": 130300
    },
    {
      "epoch": 5.302213999634049,
      "grad_norm": 0.3144378066062927,
      "learning_rate": 0.00025567653698048073,
      "loss": 0.3461,
      "step": 130400
    },
    {
      "epoch": 5.306280114664444,
      "grad_norm": 0.42627429962158203,
      "learning_rate": 0.0002554552294958615,
      "loss": 0.3456,
      "step": 130500
    },
    {
      "epoch": 5.310346229694838,
      "grad_norm": 0.3468858003616333,
      "learning_rate": 0.0002552339220112424,
      "loss": 0.3484,
      "step": 130600
    },
    {
      "epoch": 5.314412344725232,
      "grad_norm": 0.345274418592453,
      "learning_rate": 0.00025501261452662326,
      "loss": 0.3452,
      "step": 130700
    },
    {
      "epoch": 5.318478459755626,
      "grad_norm": 0.3978603780269623,
      "learning_rate": 0.00025479130704200416,
      "loss": 0.3443,
      "step": 130800
    },
    {
      "epoch": 5.32254457478602,
      "grad_norm": 0.3808707296848297,
      "learning_rate": 0.000254569999557385,
      "loss": 0.3476,
      "step": 130900
    },
    {
      "epoch": 5.326610689816415,
      "grad_norm": 0.3587949573993683,
      "learning_rate": 0.0002543486920727659,
      "loss": 0.3458,
      "step": 131000
    },
    {
      "epoch": 5.330676804846809,
      "grad_norm": 0.3143173158168793,
      "learning_rate": 0.00025412738458814674,
      "loss": 0.3442,
      "step": 131100
    },
    {
      "epoch": 5.334742919877203,
      "grad_norm": 0.5403249263763428,
      "learning_rate": 0.00025390607710352764,
      "loss": 0.3452,
      "step": 131200
    },
    {
      "epoch": 5.338809034907597,
      "grad_norm": 0.43814513087272644,
      "learning_rate": 0.00025368476961890854,
      "loss": 0.3462,
      "step": 131300
    },
    {
      "epoch": 5.342875149937992,
      "grad_norm": 0.39729899168014526,
      "learning_rate": 0.0002534634621342894,
      "loss": 0.3466,
      "step": 131400
    },
    {
      "epoch": 5.346941264968386,
      "grad_norm": 0.33957648277282715,
      "learning_rate": 0.0002532421546496703,
      "loss": 0.3463,
      "step": 131500
    },
    {
      "epoch": 5.35100737999878,
      "grad_norm": 0.3871009647846222,
      "learning_rate": 0.0002530208471650511,
      "loss": 0.3469,
      "step": 131600
    },
    {
      "epoch": 5.355073495029174,
      "grad_norm": 0.4052446484565735,
      "learning_rate": 0.000252799539680432,
      "loss": 0.344,
      "step": 131700
    },
    {
      "epoch": 5.359139610059569,
      "grad_norm": 0.3466235399246216,
      "learning_rate": 0.00025257823219581286,
      "loss": 0.3453,
      "step": 131800
    },
    {
      "epoch": 5.363205725089963,
      "grad_norm": 0.4335393011569977,
      "learning_rate": 0.00025235692471119376,
      "loss": 0.3466,
      "step": 131900
    },
    {
      "epoch": 5.367271840120357,
      "grad_norm": 0.31061819195747375,
      "learning_rate": 0.00025213561722657466,
      "loss": 0.3451,
      "step": 132000
    },
    {
      "epoch": 5.367271840120357,
      "eval_loss": 0.3580148220062256,
      "eval_runtime": 125.5194,
      "eval_samples_per_second": 1393.426,
      "eval_steps_per_second": 43.547,
      "step": 132000
    },
    {
      "epoch": 5.371337955150751,
      "grad_norm": 0.31150200963020325,
      "learning_rate": 0.0002519143097419555,
      "loss": 0.3461,
      "step": 132100
    },
    {
      "epoch": 5.375404070181146,
      "grad_norm": 0.41716644167900085,
      "learning_rate": 0.00025169300225733634,
      "loss": 0.3452,
      "step": 132200
    },
    {
      "epoch": 5.37947018521154,
      "grad_norm": 0.3871137499809265,
      "learning_rate": 0.0002514716947727172,
      "loss": 0.3441,
      "step": 132300
    },
    {
      "epoch": 5.383536300241934,
      "grad_norm": 0.40312495827674866,
      "learning_rate": 0.0002512503872880981,
      "loss": 0.3458,
      "step": 132400
    },
    {
      "epoch": 5.387602415272328,
      "grad_norm": 0.35136139392852783,
      "learning_rate": 0.00025102907980347893,
      "loss": 0.3442,
      "step": 132500
    },
    {
      "epoch": 5.391668530302722,
      "grad_norm": 0.3522056043148041,
      "learning_rate": 0.0002508077723188598,
      "loss": 0.3479,
      "step": 132600
    },
    {
      "epoch": 5.395734645333117,
      "grad_norm": 0.49847546219825745,
      "learning_rate": 0.00025058646483424067,
      "loss": 0.3481,
      "step": 132700
    },
    {
      "epoch": 5.399800760363511,
      "grad_norm": 0.38158518075942993,
      "learning_rate": 0.00025036515734962157,
      "loss": 0.3437,
      "step": 132800
    },
    {
      "epoch": 5.403866875393905,
      "grad_norm": 0.4834710657596588,
      "learning_rate": 0.00025014384986500246,
      "loss": 0.3455,
      "step": 132900
    },
    {
      "epoch": 5.407932990424299,
      "grad_norm": 0.34477514028549194,
      "learning_rate": 0.0002499225423803833,
      "loss": 0.3463,
      "step": 133000
    },
    {
      "epoch": 5.411999105454694,
      "grad_norm": 0.34331583976745605,
      "learning_rate": 0.0002497012348957642,
      "loss": 0.3449,
      "step": 133100
    },
    {
      "epoch": 5.416065220485088,
      "grad_norm": 0.3994255065917969,
      "learning_rate": 0.00024947992741114505,
      "loss": 0.3473,
      "step": 133200
    },
    {
      "epoch": 5.420131335515482,
      "grad_norm": 0.36120331287384033,
      "learning_rate": 0.00024925861992652594,
      "loss": 0.3484,
      "step": 133300
    },
    {
      "epoch": 5.424197450545876,
      "grad_norm": 0.5595853328704834,
      "learning_rate": 0.0002490373124419068,
      "loss": 0.3459,
      "step": 133400
    },
    {
      "epoch": 5.4282635655762705,
      "grad_norm": 0.3359455466270447,
      "learning_rate": 0.00024881600495728763,
      "loss": 0.3449,
      "step": 133500
    },
    {
      "epoch": 5.4323296806066645,
      "grad_norm": 0.3197493255138397,
      "learning_rate": 0.0002485946974726685,
      "loss": 0.347,
      "step": 133600
    },
    {
      "epoch": 5.4363957956370585,
      "grad_norm": 0.4638388752937317,
      "learning_rate": 0.0002483733899880494,
      "loss": 0.346,
      "step": 133700
    },
    {
      "epoch": 5.4404619106674525,
      "grad_norm": 0.3345489501953125,
      "learning_rate": 0.00024815208250343027,
      "loss": 0.346,
      "step": 133800
    },
    {
      "epoch": 5.444528025697847,
      "grad_norm": 0.3720211684703827,
      "learning_rate": 0.00024793077501881116,
      "loss": 0.3469,
      "step": 133900
    },
    {
      "epoch": 5.448594140728241,
      "grad_norm": 0.3680307865142822,
      "learning_rate": 0.000247709467534192,
      "loss": 0.3437,
      "step": 134000
    },
    {
      "epoch": 5.448594140728241,
      "eval_loss": 0.35779067873954773,
      "eval_runtime": 126.5739,
      "eval_samples_per_second": 1381.817,
      "eval_steps_per_second": 43.184,
      "step": 134000
    },
    {
      "epoch": 5.452660255758635,
      "grad_norm": 0.3332575857639313,
      "learning_rate": 0.0002474881600495729,
      "loss": 0.3445,
      "step": 134100
    },
    {
      "epoch": 5.4567263707890294,
      "grad_norm": 0.37842419743537903,
      "learning_rate": 0.00024726685256495375,
      "loss": 0.3454,
      "step": 134200
    },
    {
      "epoch": 5.4607924858194234,
      "grad_norm": 0.35352084040641785,
      "learning_rate": 0.0002470455450803346,
      "loss": 0.3436,
      "step": 134300
    },
    {
      "epoch": 5.464858600849818,
      "grad_norm": 0.35389500856399536,
      "learning_rate": 0.0002468242375957155,
      "loss": 0.3455,
      "step": 134400
    },
    {
      "epoch": 5.468924715880212,
      "grad_norm": 0.3489046096801758,
      "learning_rate": 0.00024660293011109633,
      "loss": 0.3448,
      "step": 134500
    },
    {
      "epoch": 5.472990830910606,
      "grad_norm": 0.34077832102775574,
      "learning_rate": 0.00024638162262647723,
      "loss": 0.3451,
      "step": 134600
    },
    {
      "epoch": 5.477056945941,
      "grad_norm": 0.3491058349609375,
      "learning_rate": 0.0002461603151418581,
      "loss": 0.3456,
      "step": 134700
    },
    {
      "epoch": 5.481123060971395,
      "grad_norm": 0.33805206418037415,
      "learning_rate": 0.00024593900765723897,
      "loss": 0.3466,
      "step": 134800
    },
    {
      "epoch": 5.485189176001789,
      "grad_norm": 0.3446863889694214,
      "learning_rate": 0.00024571770017261987,
      "loss": 0.3418,
      "step": 134900
    },
    {
      "epoch": 5.489255291032183,
      "grad_norm": 0.4316142797470093,
      "learning_rate": 0.0002454963926880007,
      "loss": 0.3454,
      "step": 135000
    },
    {
      "epoch": 5.493321406062577,
      "grad_norm": 0.3938962519168854,
      "learning_rate": 0.00024527508520338155,
      "loss": 0.346,
      "step": 135100
    },
    {
      "epoch": 5.497387521092972,
      "grad_norm": 0.35311615467071533,
      "learning_rate": 0.00024505377771876245,
      "loss": 0.3456,
      "step": 135200
    },
    {
      "epoch": 5.501453636123366,
      "grad_norm": 0.34181568026542664,
      "learning_rate": 0.0002448324702341433,
      "loss": 0.3442,
      "step": 135300
    },
    {
      "epoch": 5.50551975115376,
      "grad_norm": 0.42392170429229736,
      "learning_rate": 0.0002446111627495242,
      "loss": 0.3461,
      "step": 135400
    },
    {
      "epoch": 5.509585866184154,
      "grad_norm": 0.3239271342754364,
      "learning_rate": 0.0002443898552649051,
      "loss": 0.3454,
      "step": 135500
    },
    {
      "epoch": 5.513651981214549,
      "grad_norm": 0.4527827501296997,
      "learning_rate": 0.00024416854778028593,
      "loss": 0.3476,
      "step": 135600
    },
    {
      "epoch": 5.517718096244943,
      "grad_norm": 0.40401437878608704,
      "learning_rate": 0.0002439472402956668,
      "loss": 0.3459,
      "step": 135700
    },
    {
      "epoch": 5.521784211275337,
      "grad_norm": 0.5074458122253418,
      "learning_rate": 0.00024372593281104767,
      "loss": 0.3431,
      "step": 135800
    },
    {
      "epoch": 5.525850326305731,
      "grad_norm": 0.4904493987560272,
      "learning_rate": 0.00024350462532642857,
      "loss": 0.3438,
      "step": 135900
    },
    {
      "epoch": 5.529916441336125,
      "grad_norm": 0.4427337050437927,
      "learning_rate": 0.0002432833178418094,
      "loss": 0.3453,
      "step": 136000
    },
    {
      "epoch": 5.529916441336125,
      "eval_loss": 0.3570307195186615,
      "eval_runtime": 128.938,
      "eval_samples_per_second": 1356.482,
      "eval_steps_per_second": 42.392,
      "step": 136000
    },
    {
      "epoch": 5.53398255636652,
      "grad_norm": 0.4284175932407379,
      "learning_rate": 0.00024306201035719028,
      "loss": 0.3453,
      "step": 136100
    },
    {
      "epoch": 5.538048671396914,
      "grad_norm": 0.3439369797706604,
      "learning_rate": 0.00024284070287257115,
      "loss": 0.3443,
      "step": 136200
    },
    {
      "epoch": 5.542114786427308,
      "grad_norm": 0.34777534008026123,
      "learning_rate": 0.00024261939538795202,
      "loss": 0.346,
      "step": 136300
    },
    {
      "epoch": 5.546180901457702,
      "grad_norm": 0.38353148102760315,
      "learning_rate": 0.0002423980879033329,
      "loss": 0.3466,
      "step": 136400
    },
    {
      "epoch": 5.550247016488097,
      "grad_norm": 0.36160382628440857,
      "learning_rate": 0.00024217678041871376,
      "loss": 0.3462,
      "step": 136500
    },
    {
      "epoch": 5.554313131518491,
      "grad_norm": 0.38412052392959595,
      "learning_rate": 0.00024195547293409463,
      "loss": 0.3444,
      "step": 136600
    },
    {
      "epoch": 5.558379246548885,
      "grad_norm": 0.3557940423488617,
      "learning_rate": 0.00024173416544947553,
      "loss": 0.3453,
      "step": 136700
    },
    {
      "epoch": 5.562445361579279,
      "grad_norm": 0.4065309166908264,
      "learning_rate": 0.00024151285796485637,
      "loss": 0.3435,
      "step": 136800
    },
    {
      "epoch": 5.566511476609673,
      "grad_norm": 0.3379630446434021,
      "learning_rate": 0.00024129155048023724,
      "loss": 0.3444,
      "step": 136900
    },
    {
      "epoch": 5.570577591640068,
      "grad_norm": 0.40158703923225403,
      "learning_rate": 0.00024107024299561811,
      "loss": 0.3468,
      "step": 137000
    },
    {
      "epoch": 5.574643706670462,
      "grad_norm": 0.36517593264579773,
      "learning_rate": 0.00024084893551099898,
      "loss": 0.346,
      "step": 137100
    },
    {
      "epoch": 5.578709821700856,
      "grad_norm": 0.2925408184528351,
      "learning_rate": 0.00024062762802637985,
      "loss": 0.3461,
      "step": 137200
    },
    {
      "epoch": 5.582775936731251,
      "grad_norm": 0.41642966866493225,
      "learning_rate": 0.00024040632054176073,
      "loss": 0.3446,
      "step": 137300
    },
    {
      "epoch": 5.586842051761645,
      "grad_norm": 0.3621041476726532,
      "learning_rate": 0.0002401850130571416,
      "loss": 0.3436,
      "step": 137400
    },
    {
      "epoch": 5.590908166792039,
      "grad_norm": 0.36237865686416626,
      "learning_rate": 0.00023996370557252247,
      "loss": 0.3442,
      "step": 137500
    },
    {
      "epoch": 5.594974281822433,
      "grad_norm": 0.3779563903808594,
      "learning_rate": 0.00023974239808790336,
      "loss": 0.3456,
      "step": 137600
    },
    {
      "epoch": 5.599040396852827,
      "grad_norm": 0.36022478342056274,
      "learning_rate": 0.0002395210906032842,
      "loss": 0.3436,
      "step": 137700
    },
    {
      "epoch": 5.6031065118832215,
      "grad_norm": 0.39708584547042847,
      "learning_rate": 0.00023929978311866508,
      "loss": 0.3469,
      "step": 137800
    },
    {
      "epoch": 5.6071726269136155,
      "grad_norm": 0.35583943128585815,
      "learning_rate": 0.00023907847563404595,
      "loss": 0.3449,
      "step": 137900
    },
    {
      "epoch": 5.6112387419440095,
      "grad_norm": 0.4072295129299164,
      "learning_rate": 0.00023885716814942682,
      "loss": 0.3465,
      "step": 138000
    },
    {
      "epoch": 5.6112387419440095,
      "eval_loss": 0.3568962812423706,
      "eval_runtime": 125.3648,
      "eval_samples_per_second": 1395.145,
      "eval_steps_per_second": 43.601,
      "step": 138000
    },
    {
      "epoch": 5.6153048569744035,
      "grad_norm": 0.34305325150489807,
      "learning_rate": 0.0002386358606648077,
      "loss": 0.343,
      "step": 138100
    },
    {
      "epoch": 5.619370972004798,
      "grad_norm": 0.3548097610473633,
      "learning_rate": 0.00023841455318018856,
      "loss": 0.3457,
      "step": 138200
    },
    {
      "epoch": 5.623437087035192,
      "grad_norm": 0.34461510181427,
      "learning_rate": 0.00023819324569556943,
      "loss": 0.3441,
      "step": 138300
    },
    {
      "epoch": 5.627503202065586,
      "grad_norm": 0.3678721487522125,
      "learning_rate": 0.00023797193821095032,
      "loss": 0.3452,
      "step": 138400
    },
    {
      "epoch": 5.63156931709598,
      "grad_norm": 0.43214207887649536,
      "learning_rate": 0.00023775063072633117,
      "loss": 0.3461,
      "step": 138500
    },
    {
      "epoch": 5.635635432126374,
      "grad_norm": 0.38168054819107056,
      "learning_rate": 0.00023752932324171204,
      "loss": 0.3468,
      "step": 138600
    },
    {
      "epoch": 5.639701547156769,
      "grad_norm": 0.3722652196884155,
      "learning_rate": 0.0002373080157570929,
      "loss": 0.3462,
      "step": 138700
    },
    {
      "epoch": 5.643767662187163,
      "grad_norm": 0.32294267416000366,
      "learning_rate": 0.00023708670827247378,
      "loss": 0.3438,
      "step": 138800
    },
    {
      "epoch": 5.647833777217557,
      "grad_norm": 0.4235398769378662,
      "learning_rate": 0.00023686540078785465,
      "loss": 0.3459,
      "step": 138900
    },
    {
      "epoch": 5.651899892247951,
      "grad_norm": 0.39756983518600464,
      "learning_rate": 0.00023664409330323552,
      "loss": 0.3445,
      "step": 139000
    },
    {
      "epoch": 5.655966007278346,
      "grad_norm": 0.4216724634170532,
      "learning_rate": 0.0002364227858186164,
      "loss": 0.3448,
      "step": 139100
    },
    {
      "epoch": 5.66003212230874,
      "grad_norm": 0.33199071884155273,
      "learning_rate": 0.00023620147833399726,
      "loss": 0.3466,
      "step": 139200
    },
    {
      "epoch": 5.664098237339134,
      "grad_norm": 0.4306231737136841,
      "learning_rate": 0.00023598017084937813,
      "loss": 0.3451,
      "step": 139300
    },
    {
      "epoch": 5.668164352369528,
      "grad_norm": 0.3715779781341553,
      "learning_rate": 0.000235758863364759,
      "loss": 0.346,
      "step": 139400
    },
    {
      "epoch": 5.672230467399923,
      "grad_norm": 0.38400810956954956,
      "learning_rate": 0.00023553755588013987,
      "loss": 0.3462,
      "step": 139500
    },
    {
      "epoch": 5.676296582430317,
      "grad_norm": 0.387100487947464,
      "learning_rate": 0.00023531624839552074,
      "loss": 0.3442,
      "step": 139600
    },
    {
      "epoch": 5.680362697460711,
      "grad_norm": 0.3702140152454376,
      "learning_rate": 0.0002350949409109016,
      "loss": 0.3452,
      "step": 139700
    },
    {
      "epoch": 5.684428812491105,
      "grad_norm": 0.4364209473133087,
      "learning_rate": 0.00023487363342628248,
      "loss": 0.3445,
      "step": 139800
    },
    {
      "epoch": 5.6884949275215,
      "grad_norm": 0.36829566955566406,
      "learning_rate": 0.00023465232594166335,
      "loss": 0.3442,
      "step": 139900
    },
    {
      "epoch": 5.692561042551894,
      "grad_norm": 0.31987741589546204,
      "learning_rate": 0.00023443101845704422,
      "loss": 0.3439,
      "step": 140000
    },
    {
      "epoch": 5.692561042551894,
      "eval_loss": 0.3565352261066437,
      "eval_runtime": 126.7019,
      "eval_samples_per_second": 1380.421,
      "eval_steps_per_second": 43.141,
      "step": 140000
    },
    {
      "epoch": 5.696627157582288,
      "grad_norm": 0.3753487467765808,
      "learning_rate": 0.00023420971097242512,
      "loss": 0.3451,
      "step": 140100
    },
    {
      "epoch": 5.700693272612682,
      "grad_norm": 0.5838750600814819,
      "learning_rate": 0.00023398840348780596,
      "loss": 0.3437,
      "step": 140200
    },
    {
      "epoch": 5.704759387643076,
      "grad_norm": 0.3877037763595581,
      "learning_rate": 0.00023376709600318683,
      "loss": 0.3423,
      "step": 140300
    },
    {
      "epoch": 5.708825502673471,
      "grad_norm": 0.35491058230400085,
      "learning_rate": 0.0002335457885185677,
      "loss": 0.3441,
      "step": 140400
    },
    {
      "epoch": 5.712891617703865,
      "grad_norm": 0.303885817527771,
      "learning_rate": 0.00023332448103394857,
      "loss": 0.346,
      "step": 140500
    },
    {
      "epoch": 5.716957732734259,
      "grad_norm": 0.3506106436252594,
      "learning_rate": 0.00023310317354932944,
      "loss": 0.3442,
      "step": 140600
    },
    {
      "epoch": 5.721023847764653,
      "grad_norm": 0.4424695074558258,
      "learning_rate": 0.0002328818660647103,
      "loss": 0.3466,
      "step": 140700
    },
    {
      "epoch": 5.725089962795048,
      "grad_norm": 0.35280388593673706,
      "learning_rate": 0.00023266055858009118,
      "loss": 0.3438,
      "step": 140800
    },
    {
      "epoch": 5.729156077825442,
      "grad_norm": 0.3862968683242798,
      "learning_rate": 0.00023243925109547205,
      "loss": 0.3442,
      "step": 140900
    },
    {
      "epoch": 5.733222192855836,
      "grad_norm": 0.44162559509277344,
      "learning_rate": 0.00023221794361085292,
      "loss": 0.3452,
      "step": 141000
    },
    {
      "epoch": 5.73728830788623,
      "grad_norm": 0.3817979395389557,
      "learning_rate": 0.0002319966361262338,
      "loss": 0.343,
      "step": 141100
    },
    {
      "epoch": 5.741354422916625,
      "grad_norm": 0.3687545657157898,
      "learning_rate": 0.00023177532864161466,
      "loss": 0.3455,
      "step": 141200
    },
    {
      "epoch": 5.745420537947019,
      "grad_norm": 0.4534936249256134,
      "learning_rate": 0.00023155402115699553,
      "loss": 0.3465,
      "step": 141300
    },
    {
      "epoch": 5.749486652977413,
      "grad_norm": 0.3694290220737457,
      "learning_rate": 0.0002313327136723764,
      "loss": 0.3462,
      "step": 141400
    },
    {
      "epoch": 5.753552768007807,
      "grad_norm": 0.36701053380966187,
      "learning_rate": 0.00023111140618775727,
      "loss": 0.3455,
      "step": 141500
    },
    {
      "epoch": 5.757618883038202,
      "grad_norm": 0.3562168478965759,
      "learning_rate": 0.00023089009870313814,
      "loss": 0.3429,
      "step": 141600
    },
    {
      "epoch": 5.761684998068596,
      "grad_norm": 0.39030423760414124,
      "learning_rate": 0.00023066879121851901,
      "loss": 0.3482,
      "step": 141700
    },
    {
      "epoch": 5.76575111309899,
      "grad_norm": 0.3928266167640686,
      "learning_rate": 0.00023044748373389989,
      "loss": 0.3466,
      "step": 141800
    },
    {
      "epoch": 5.769817228129384,
      "grad_norm": 0.355448454618454,
      "learning_rate": 0.00023022617624928076,
      "loss": 0.3451,
      "step": 141900
    },
    {
      "epoch": 5.773883343159778,
      "grad_norm": 0.36694756150245667,
      "learning_rate": 0.00023000486876466163,
      "loss": 0.3451,
      "step": 142000
    },
    {
      "epoch": 5.773883343159778,
      "eval_loss": 0.35542234778404236,
      "eval_runtime": 125.4904,
      "eval_samples_per_second": 1393.749,
      "eval_steps_per_second": 43.557,
      "step": 142000
    },
    {
      "epoch": 5.7779494581901725,
      "grad_norm": 0.4109613001346588,
      "learning_rate": 0.0002297835612800425,
      "loss": 0.344,
      "step": 142100
    },
    {
      "epoch": 5.7820155732205665,
      "grad_norm": 0.36390769481658936,
      "learning_rate": 0.00022956225379542337,
      "loss": 0.3453,
      "step": 142200
    },
    {
      "epoch": 5.7860816882509605,
      "grad_norm": 0.3828136920928955,
      "learning_rate": 0.00022934094631080424,
      "loss": 0.3468,
      "step": 142300
    },
    {
      "epoch": 5.7901478032813545,
      "grad_norm": 0.6077758073806763,
      "learning_rate": 0.0002291196388261851,
      "loss": 0.3441,
      "step": 142400
    },
    {
      "epoch": 5.794213918311749,
      "grad_norm": 0.3688114583492279,
      "learning_rate": 0.00022889833134156598,
      "loss": 0.3438,
      "step": 142500
    },
    {
      "epoch": 5.798280033342143,
      "grad_norm": 0.38821181654930115,
      "learning_rate": 0.00022867702385694685,
      "loss": 0.3445,
      "step": 142600
    },
    {
      "epoch": 5.802346148372537,
      "grad_norm": 0.3505077362060547,
      "learning_rate": 0.00022845571637232772,
      "loss": 0.345,
      "step": 142700
    },
    {
      "epoch": 5.806412263402931,
      "grad_norm": 0.4178163409233093,
      "learning_rate": 0.0002282344088877086,
      "loss": 0.3437,
      "step": 142800
    },
    {
      "epoch": 5.810478378433326,
      "grad_norm": 0.40123412013053894,
      "learning_rate": 0.00022801310140308946,
      "loss": 0.3462,
      "step": 142900
    },
    {
      "epoch": 5.81454449346372,
      "grad_norm": 0.39068499207496643,
      "learning_rate": 0.00022779179391847033,
      "loss": 0.3448,
      "step": 143000
    },
    {
      "epoch": 5.818610608494114,
      "grad_norm": 0.36839357018470764,
      "learning_rate": 0.0002275704864338512,
      "loss": 0.3451,
      "step": 143100
    },
    {
      "epoch": 5.822676723524508,
      "grad_norm": 0.461563378572464,
      "learning_rate": 0.00022734917894923207,
      "loss": 0.3446,
      "step": 143200
    },
    {
      "epoch": 5.826742838554903,
      "grad_norm": 0.4643090069293976,
      "learning_rate": 0.00022712787146461294,
      "loss": 0.3436,
      "step": 143300
    },
    {
      "epoch": 5.830808953585297,
      "grad_norm": 0.4011070132255554,
      "learning_rate": 0.0002269065639799938,
      "loss": 0.3447,
      "step": 143400
    },
    {
      "epoch": 5.834875068615691,
      "grad_norm": 0.37373802065849304,
      "learning_rate": 0.00022668525649537468,
      "loss": 0.3447,
      "step": 143500
    },
    {
      "epoch": 5.838941183646085,
      "grad_norm": 0.3390883207321167,
      "learning_rate": 0.00022646394901075555,
      "loss": 0.3448,
      "step": 143600
    },
    {
      "epoch": 5.843007298676479,
      "grad_norm": 0.4095540940761566,
      "learning_rate": 0.00022624264152613642,
      "loss": 0.3457,
      "step": 143700
    },
    {
      "epoch": 5.847073413706874,
      "grad_norm": 0.4034196436405182,
      "learning_rate": 0.0002260213340415173,
      "loss": 0.3428,
      "step": 143800
    },
    {
      "epoch": 5.851139528737268,
      "grad_norm": 0.3666723668575287,
      "learning_rate": 0.00022580002655689816,
      "loss": 0.3455,
      "step": 143900
    },
    {
      "epoch": 5.855205643767662,
      "grad_norm": 0.4166509807109833,
      "learning_rate": 0.00022557871907227903,
      "loss": 0.3452,
      "step": 144000
    },
    {
      "epoch": 5.855205643767662,
      "eval_loss": 0.3551976978778839,
      "eval_runtime": 125.7376,
      "eval_samples_per_second": 1391.008,
      "eval_steps_per_second": 43.471,
      "step": 144000
    },
    {
      "epoch": 5.859271758798056,
      "grad_norm": 0.3548521101474762,
      "learning_rate": 0.0002253574115876599,
      "loss": 0.3425,
      "step": 144100
    },
    {
      "epoch": 5.863337873828451,
      "grad_norm": 0.3429985046386719,
      "learning_rate": 0.00022513610410304077,
      "loss": 0.3438,
      "step": 144200
    },
    {
      "epoch": 5.867403988858845,
      "grad_norm": 0.3768866956233978,
      "learning_rate": 0.00022491479661842164,
      "loss": 0.3465,
      "step": 144300
    },
    {
      "epoch": 5.871470103889239,
      "grad_norm": 0.3564029932022095,
      "learning_rate": 0.0002246934891338025,
      "loss": 0.344,
      "step": 144400
    },
    {
      "epoch": 5.875536218919633,
      "grad_norm": 0.36334720253944397,
      "learning_rate": 0.00022447218164918338,
      "loss": 0.3434,
      "step": 144500
    },
    {
      "epoch": 5.879602333950027,
      "grad_norm": 0.39073067903518677,
      "learning_rate": 0.00022425087416456425,
      "loss": 0.3444,
      "step": 144600
    },
    {
      "epoch": 5.883668448980422,
      "grad_norm": 0.5118179321289062,
      "learning_rate": 0.00022402956667994512,
      "loss": 0.3435,
      "step": 144700
    },
    {
      "epoch": 5.887734564010816,
      "grad_norm": 0.41698288917541504,
      "learning_rate": 0.000223808259195326,
      "loss": 0.3443,
      "step": 144800
    },
    {
      "epoch": 5.89180067904121,
      "grad_norm": 0.3609921634197235,
      "learning_rate": 0.00022358695171070686,
      "loss": 0.3428,
      "step": 144900
    },
    {
      "epoch": 5.895866794071605,
      "grad_norm": 0.3452136218547821,
      "learning_rate": 0.00022336564422608773,
      "loss": 0.3455,
      "step": 145000
    },
    {
      "epoch": 5.899932909101999,
      "grad_norm": 0.3423950970172882,
      "learning_rate": 0.0002231443367414686,
      "loss": 0.3447,
      "step": 145100
    },
    {
      "epoch": 5.903999024132393,
      "grad_norm": 0.3955039978027344,
      "learning_rate": 0.00022292302925684945,
      "loss": 0.3449,
      "step": 145200
    },
    {
      "epoch": 5.908065139162787,
      "grad_norm": 0.4126318693161011,
      "learning_rate": 0.00022270172177223034,
      "loss": 0.3463,
      "step": 145300
    },
    {
      "epoch": 5.912131254193181,
      "grad_norm": 0.38464269042015076,
      "learning_rate": 0.0002224804142876112,
      "loss": 0.3439,
      "step": 145400
    },
    {
      "epoch": 5.916197369223576,
      "grad_norm": 0.37042170763015747,
      "learning_rate": 0.00022225910680299208,
      "loss": 0.3436,
      "step": 145500
    },
    {
      "epoch": 5.92026348425397,
      "grad_norm": 0.3903891146183014,
      "learning_rate": 0.00022203779931837295,
      "loss": 0.3453,
      "step": 145600
    },
    {
      "epoch": 5.924329599284364,
      "grad_norm": 0.5168448090553284,
      "learning_rate": 0.00022181649183375382,
      "loss": 0.3446,
      "step": 145700
    },
    {
      "epoch": 5.928395714314758,
      "grad_norm": 0.4396032691001892,
      "learning_rate": 0.0002215951843491347,
      "loss": 0.3448,
      "step": 145800
    },
    {
      "epoch": 5.9324618293451525,
      "grad_norm": 0.39340293407440186,
      "learning_rate": 0.00022137387686451556,
      "loss": 0.3451,
      "step": 145900
    },
    {
      "epoch": 5.9365279443755465,
      "grad_norm": 0.35064929723739624,
      "learning_rate": 0.00022115256937989643,
      "loss": 0.3457,
      "step": 146000
    },
    {
      "epoch": 5.9365279443755465,
      "eval_loss": 0.35472655296325684,
      "eval_runtime": 127.6456,
      "eval_samples_per_second": 1370.216,
      "eval_steps_per_second": 42.822,
      "step": 146000
    },
    {
      "epoch": 5.9405940594059405,
      "grad_norm": 0.39358997344970703,
      "learning_rate": 0.0002209312618952773,
      "loss": 0.3431,
      "step": 146100
    },
    {
      "epoch": 5.9446601744363345,
      "grad_norm": 0.3865622282028198,
      "learning_rate": 0.00022070995441065817,
      "loss": 0.3445,
      "step": 146200
    },
    {
      "epoch": 5.9487262894667285,
      "grad_norm": 0.4178062677383423,
      "learning_rate": 0.00022048864692603905,
      "loss": 0.3459,
      "step": 146300
    },
    {
      "epoch": 5.952792404497123,
      "grad_norm": 0.38569796085357666,
      "learning_rate": 0.00022026733944141992,
      "loss": 0.3452,
      "step": 146400
    },
    {
      "epoch": 5.956858519527517,
      "grad_norm": 0.37447357177734375,
      "learning_rate": 0.00022004603195680079,
      "loss": 0.3432,
      "step": 146500
    },
    {
      "epoch": 5.960924634557911,
      "grad_norm": 0.3604375720024109,
      "learning_rate": 0.00021982472447218166,
      "loss": 0.3439,
      "step": 146600
    },
    {
      "epoch": 5.964990749588306,
      "grad_norm": 0.364188551902771,
      "learning_rate": 0.00021960341698756253,
      "loss": 0.3449,
      "step": 146700
    },
    {
      "epoch": 5.9690568646187,
      "grad_norm": 0.4099085032939911,
      "learning_rate": 0.0002193821095029434,
      "loss": 0.3454,
      "step": 146800
    },
    {
      "epoch": 5.973122979649094,
      "grad_norm": 0.386089563369751,
      "learning_rate": 0.00021916080201832424,
      "loss": 0.3448,
      "step": 146900
    },
    {
      "epoch": 5.977189094679488,
      "grad_norm": 0.3433595597743988,
      "learning_rate": 0.00021893949453370514,
      "loss": 0.3457,
      "step": 147000
    },
    {
      "epoch": 5.981255209709882,
      "grad_norm": 0.3533459007740021,
      "learning_rate": 0.000218718187049086,
      "loss": 0.3434,
      "step": 147100
    },
    {
      "epoch": 5.985321324740277,
      "grad_norm": 0.37954941391944885,
      "learning_rate": 0.00021849687956446688,
      "loss": 0.3452,
      "step": 147200
    },
    {
      "epoch": 5.989387439770671,
      "grad_norm": 0.3445596396923065,
      "learning_rate": 0.00021827557207984775,
      "loss": 0.3438,
      "step": 147300
    },
    {
      "epoch": 5.993453554801065,
      "grad_norm": 0.36504682898521423,
      "learning_rate": 0.00021805426459522862,
      "loss": 0.345,
      "step": 147400
    },
    {
      "epoch": 5.997519669831459,
      "grad_norm": 0.39542001485824585,
      "learning_rate": 0.0002178329571106095,
      "loss": 0.3455,
      "step": 147500
    },
    {
      "epoch": 6.001585784861854,
      "grad_norm": 0.3952425718307495,
      "learning_rate": 0.00021761164962599036,
      "loss": 0.3404,
      "step": 147600
    },
    {
      "epoch": 6.005651899892248,
      "grad_norm": 0.40525326132774353,
      "learning_rate": 0.00021739034214137123,
      "loss": 0.3376,
      "step": 147700
    },
    {
      "epoch": 6.009718014922642,
      "grad_norm": 0.3425902724266052,
      "learning_rate": 0.00021716903465675207,
      "loss": 0.3378,
      "step": 147800
    },
    {
      "epoch": 6.013784129953036,
      "grad_norm": 0.34822481870651245,
      "learning_rate": 0.00021694772717213297,
      "loss": 0.3374,
      "step": 147900
    },
    {
      "epoch": 6.017850244983431,
      "grad_norm": 0.34406036138534546,
      "learning_rate": 0.00021672641968751384,
      "loss": 0.3375,
      "step": 148000
    },
    {
      "epoch": 6.017850244983431,
      "eval_loss": 0.3549405038356781,
      "eval_runtime": 125.4039,
      "eval_samples_per_second": 1394.709,
      "eval_steps_per_second": 43.587,
      "step": 148000
    },
    {
      "epoch": 6.021916360013825,
      "grad_norm": 0.3850550949573517,
      "learning_rate": 0.0002165051122028947,
      "loss": 0.3376,
      "step": 148100
    },
    {
      "epoch": 6.025982475044219,
      "grad_norm": 0.34986114501953125,
      "learning_rate": 0.00021628380471827558,
      "loss": 0.3388,
      "step": 148200
    },
    {
      "epoch": 6.030048590074613,
      "grad_norm": 0.371624618768692,
      "learning_rate": 0.00021606249723365645,
      "loss": 0.3397,
      "step": 148300
    },
    {
      "epoch": 6.034114705105007,
      "grad_norm": 0.3685043752193451,
      "learning_rate": 0.00021584118974903732,
      "loss": 0.3381,
      "step": 148400
    },
    {
      "epoch": 6.038180820135402,
      "grad_norm": 0.4369003474712372,
      "learning_rate": 0.0002156198822644182,
      "loss": 0.3372,
      "step": 148500
    },
    {
      "epoch": 6.042246935165796,
      "grad_norm": 0.4810328483581543,
      "learning_rate": 0.00021539857477979903,
      "loss": 0.3385,
      "step": 148600
    },
    {
      "epoch": 6.04631305019619,
      "grad_norm": 0.40282773971557617,
      "learning_rate": 0.00021517726729517993,
      "loss": 0.3393,
      "step": 148700
    },
    {
      "epoch": 6.050379165226584,
      "grad_norm": 0.39950037002563477,
      "learning_rate": 0.0002149559598105608,
      "loss": 0.3373,
      "step": 148800
    },
    {
      "epoch": 6.054445280256979,
      "grad_norm": 0.35332104563713074,
      "learning_rate": 0.00021473465232594167,
      "loss": 0.3386,
      "step": 148900
    },
    {
      "epoch": 6.058511395287373,
      "grad_norm": 0.39246538281440735,
      "learning_rate": 0.00021451334484132254,
      "loss": 0.3401,
      "step": 149000
    },
    {
      "epoch": 6.062577510317767,
      "grad_norm": 0.3919883668422699,
      "learning_rate": 0.0002142920373567034,
      "loss": 0.3399,
      "step": 149100
    },
    {
      "epoch": 6.066643625348161,
      "grad_norm": 0.4163389205932617,
      "learning_rate": 0.00021407072987208428,
      "loss": 0.3394,
      "step": 149200
    },
    {
      "epoch": 6.070709740378556,
      "grad_norm": 0.33362460136413574,
      "learning_rate": 0.00021384942238746515,
      "loss": 0.3394,
      "step": 149300
    },
    {
      "epoch": 6.07477585540895,
      "grad_norm": 0.40516602993011475,
      "learning_rate": 0.00021362811490284602,
      "loss": 0.3415,
      "step": 149400
    },
    {
      "epoch": 6.078841970439344,
      "grad_norm": 0.37606900930404663,
      "learning_rate": 0.00021340680741822687,
      "loss": 0.3385,
      "step": 149500
    },
    {
      "epoch": 6.082908085469738,
      "grad_norm": 0.46476662158966064,
      "learning_rate": 0.00021318549993360776,
      "loss": 0.338,
      "step": 149600
    },
    {
      "epoch": 6.086974200500132,
      "grad_norm": 0.38864997029304504,
      "learning_rate": 0.00021296419244898863,
      "loss": 0.3384,
      "step": 149700
    },
    {
      "epoch": 6.091040315530527,
      "grad_norm": 0.37898197770118713,
      "learning_rate": 0.0002127428849643695,
      "loss": 0.3381,
      "step": 149800
    },
    {
      "epoch": 6.095106430560921,
      "grad_norm": 0.3784061074256897,
      "learning_rate": 0.00021252157747975037,
      "loss": 0.3382,
      "step": 149900
    },
    {
      "epoch": 6.099172545591315,
      "grad_norm": 0.38133469223976135,
      "learning_rate": 0.00021230026999513124,
      "loss": 0.3401,
      "step": 150000
    },
    {
      "epoch": 6.099172545591315,
      "eval_loss": 0.3550108075141907,
      "eval_runtime": 127.7449,
      "eval_samples_per_second": 1369.151,
      "eval_steps_per_second": 42.788,
      "step": 150000
    },
    {
      "epoch": 6.103238660621709,
      "grad_norm": 0.42217084765434265,
      "learning_rate": 0.0002120789625105121,
      "loss": 0.3409,
      "step": 150100
    },
    {
      "epoch": 6.1073047756521035,
      "grad_norm": 0.4028378129005432,
      "learning_rate": 0.00021185765502589298,
      "loss": 0.3392,
      "step": 150200
    },
    {
      "epoch": 6.1113708906824975,
      "grad_norm": 0.35361790657043457,
      "learning_rate": 0.00021163634754127383,
      "loss": 0.3393,
      "step": 150300
    },
    {
      "epoch": 6.1154370057128915,
      "grad_norm": 0.3781755268573761,
      "learning_rate": 0.00021141504005665472,
      "loss": 0.3396,
      "step": 150400
    },
    {
      "epoch": 6.1195031207432855,
      "grad_norm": 0.4617578387260437,
      "learning_rate": 0.0002111937325720356,
      "loss": 0.3372,
      "step": 150500
    },
    {
      "epoch": 6.12356923577368,
      "grad_norm": 0.37623777985572815,
      "learning_rate": 0.00021097242508741646,
      "loss": 0.3393,
      "step": 150600
    },
    {
      "epoch": 6.127635350804074,
      "grad_norm": 0.3772676885128021,
      "learning_rate": 0.00021075111760279733,
      "loss": 0.3392,
      "step": 150700
    },
    {
      "epoch": 6.131701465834468,
      "grad_norm": 0.3509353995323181,
      "learning_rate": 0.0002105298101181782,
      "loss": 0.3381,
      "step": 150800
    },
    {
      "epoch": 6.135767580864862,
      "grad_norm": 0.5862932801246643,
      "learning_rate": 0.00021030850263355908,
      "loss": 0.3398,
      "step": 150900
    },
    {
      "epoch": 6.139833695895257,
      "grad_norm": 0.3437952399253845,
      "learning_rate": 0.00021008719514893995,
      "loss": 0.3384,
      "step": 151000
    },
    {
      "epoch": 6.143899810925651,
      "grad_norm": 0.4535669684410095,
      "learning_rate": 0.0002098658876643208,
      "loss": 0.3392,
      "step": 151100
    },
    {
      "epoch": 6.147965925956045,
      "grad_norm": 0.3482155203819275,
      "learning_rate": 0.00020964458017970166,
      "loss": 0.3377,
      "step": 151200
    },
    {
      "epoch": 6.152032040986439,
      "grad_norm": 0.41659921407699585,
      "learning_rate": 0.00020942327269508256,
      "loss": 0.3405,
      "step": 151300
    },
    {
      "epoch": 6.156098156016833,
      "grad_norm": 0.3477795124053955,
      "learning_rate": 0.00020920196521046343,
      "loss": 0.3404,
      "step": 151400
    },
    {
      "epoch": 6.160164271047228,
      "grad_norm": 0.3445335626602173,
      "learning_rate": 0.0002089806577258443,
      "loss": 0.3398,
      "step": 151500
    },
    {
      "epoch": 6.164230386077622,
      "grad_norm": 0.4255011975765228,
      "learning_rate": 0.00020875935024122517,
      "loss": 0.3394,
      "step": 151600
    },
    {
      "epoch": 6.168296501108016,
      "grad_norm": 0.4050922989845276,
      "learning_rate": 0.00020853804275660604,
      "loss": 0.3384,
      "step": 151700
    },
    {
      "epoch": 6.17236261613841,
      "grad_norm": 0.4003429412841797,
      "learning_rate": 0.0002083167352719869,
      "loss": 0.3391,
      "step": 151800
    },
    {
      "epoch": 6.176428731168805,
      "grad_norm": 0.41271042823791504,
      "learning_rate": 0.00020809542778736778,
      "loss": 0.3383,
      "step": 151900
    },
    {
      "epoch": 6.180494846199199,
      "grad_norm": 0.3725031614303589,
      "learning_rate": 0.00020787412030274862,
      "loss": 0.34,
      "step": 152000
    },
    {
      "epoch": 6.180494846199199,
      "eval_loss": 0.3542450964450836,
      "eval_runtime": 127.8854,
      "eval_samples_per_second": 1367.647,
      "eval_steps_per_second": 42.741,
      "step": 152000
    },
    {
      "epoch": 6.184560961229593,
      "grad_norm": 0.36991646885871887,
      "learning_rate": 0.00020765281281812952,
      "loss": 0.3421,
      "step": 152100
    },
    {
      "epoch": 6.188627076259987,
      "grad_norm": 0.45793798565864563,
      "learning_rate": 0.0002074315053335104,
      "loss": 0.3393,
      "step": 152200
    },
    {
      "epoch": 6.192693191290382,
      "grad_norm": 0.36598891019821167,
      "learning_rate": 0.00020721019784889126,
      "loss": 0.3406,
      "step": 152300
    },
    {
      "epoch": 6.196759306320776,
      "grad_norm": 0.425924688577652,
      "learning_rate": 0.00020698889036427213,
      "loss": 0.3399,
      "step": 152400
    },
    {
      "epoch": 6.20082542135117,
      "grad_norm": 0.4527857005596161,
      "learning_rate": 0.000206767582879653,
      "loss": 0.3414,
      "step": 152500
    },
    {
      "epoch": 6.204891536381564,
      "grad_norm": 0.4550947844982147,
      "learning_rate": 0.00020654627539503387,
      "loss": 0.3388,
      "step": 152600
    },
    {
      "epoch": 6.208957651411959,
      "grad_norm": 0.3821139931678772,
      "learning_rate": 0.00020632496791041474,
      "loss": 0.3401,
      "step": 152700
    },
    {
      "epoch": 6.213023766442353,
      "grad_norm": 0.4425135552883148,
      "learning_rate": 0.00020610366042579558,
      "loss": 0.3402,
      "step": 152800
    },
    {
      "epoch": 6.217089881472747,
      "grad_norm": 0.3228800892829895,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.3406,
      "step": 152900
    },
    {
      "epoch": 6.221155996503141,
      "grad_norm": 0.3867979645729065,
      "learning_rate": 0.00020566104545655735,
      "loss": 0.3406,
      "step": 153000
    },
    {
      "epoch": 6.225222111533535,
      "grad_norm": 0.37318119406700134,
      "learning_rate": 0.00020543973797193822,
      "loss": 0.3415,
      "step": 153100
    },
    {
      "epoch": 6.22928822656393,
      "grad_norm": 0.4371439218521118,
      "learning_rate": 0.0002052184304873191,
      "loss": 0.3386,
      "step": 153200
    },
    {
      "epoch": 6.233354341594324,
      "grad_norm": 0.406962513923645,
      "learning_rate": 0.00020499712300269996,
      "loss": 0.3383,
      "step": 153300
    },
    {
      "epoch": 6.237420456624718,
      "grad_norm": 0.3771875500679016,
      "learning_rate": 0.00020477581551808083,
      "loss": 0.3405,
      "step": 153400
    },
    {
      "epoch": 6.241486571655112,
      "grad_norm": 0.4623725116252899,
      "learning_rate": 0.0002045545080334617,
      "loss": 0.3392,
      "step": 153500
    },
    {
      "epoch": 6.245552686685507,
      "grad_norm": 0.4065934419631958,
      "learning_rate": 0.00020433320054884257,
      "loss": 0.3407,
      "step": 153600
    },
    {
      "epoch": 6.249618801715901,
      "grad_norm": 0.3790922164916992,
      "learning_rate": 0.00020411189306422341,
      "loss": 0.3398,
      "step": 153700
    },
    {
      "epoch": 6.253684916746295,
      "grad_norm": 0.44870880246162415,
      "learning_rate": 0.0002038905855796043,
      "loss": 0.3407,
      "step": 153800
    },
    {
      "epoch": 6.257751031776689,
      "grad_norm": 0.46016380190849304,
      "learning_rate": 0.00020366927809498518,
      "loss": 0.3408,
      "step": 153900
    },
    {
      "epoch": 6.261817146807084,
      "grad_norm": 0.4429125189781189,
      "learning_rate": 0.00020344797061036605,
      "loss": 0.3401,
      "step": 154000
    },
    {
      "epoch": 6.261817146807084,
      "eval_loss": 0.3534085154533386,
      "eval_runtime": 125.8593,
      "eval_samples_per_second": 1389.663,
      "eval_steps_per_second": 43.429,
      "step": 154000
    },
    {
      "epoch": 6.265883261837478,
      "grad_norm": 0.5759393572807312,
      "learning_rate": 0.00020322666312574692,
      "loss": 0.3363,
      "step": 154100
    },
    {
      "epoch": 6.269949376867872,
      "grad_norm": 0.4027653932571411,
      "learning_rate": 0.0002030053556411278,
      "loss": 0.339,
      "step": 154200
    },
    {
      "epoch": 6.274015491898266,
      "grad_norm": 0.4424551725387573,
      "learning_rate": 0.00020278404815650866,
      "loss": 0.3392,
      "step": 154300
    },
    {
      "epoch": 6.2780816069286605,
      "grad_norm": 0.4190210700035095,
      "learning_rate": 0.00020256274067188953,
      "loss": 0.34,
      "step": 154400
    },
    {
      "epoch": 6.2821477219590545,
      "grad_norm": 0.4568041265010834,
      "learning_rate": 0.00020234143318727038,
      "loss": 0.3394,
      "step": 154500
    },
    {
      "epoch": 6.2862138369894485,
      "grad_norm": 0.3613048493862152,
      "learning_rate": 0.00020212012570265125,
      "loss": 0.34,
      "step": 154600
    },
    {
      "epoch": 6.2902799520198425,
      "grad_norm": 0.42315858602523804,
      "learning_rate": 0.00020189881821803214,
      "loss": 0.3411,
      "step": 154700
    },
    {
      "epoch": 6.2943460670502365,
      "grad_norm": 0.36939355731010437,
      "learning_rate": 0.00020167751073341301,
      "loss": 0.3366,
      "step": 154800
    },
    {
      "epoch": 6.298412182080631,
      "grad_norm": 0.49399125576019287,
      "learning_rate": 0.00020145620324879388,
      "loss": 0.3371,
      "step": 154900
    },
    {
      "epoch": 6.302478297111025,
      "grad_norm": 0.4695162773132324,
      "learning_rate": 0.00020123489576417475,
      "loss": 0.3398,
      "step": 155000
    },
    {
      "epoch": 6.306544412141419,
      "grad_norm": 0.49007242918014526,
      "learning_rate": 0.00020101358827955562,
      "loss": 0.341,
      "step": 155100
    },
    {
      "epoch": 6.310610527171813,
      "grad_norm": 0.4349859654903412,
      "learning_rate": 0.0002007922807949365,
      "loss": 0.3408,
      "step": 155200
    },
    {
      "epoch": 6.314676642202208,
      "grad_norm": 0.3812903165817261,
      "learning_rate": 0.00020057097331031736,
      "loss": 0.3394,
      "step": 155300
    },
    {
      "epoch": 6.318742757232602,
      "grad_norm": 0.43224063515663147,
      "learning_rate": 0.0002003496658256982,
      "loss": 0.3421,
      "step": 155400
    },
    {
      "epoch": 6.322808872262996,
      "grad_norm": 0.48156672716140747,
      "learning_rate": 0.0002001283583410791,
      "loss": 0.3396,
      "step": 155500
    },
    {
      "epoch": 6.32687498729339,
      "grad_norm": 0.4239426851272583,
      "learning_rate": 0.00019990705085645998,
      "loss": 0.3409,
      "step": 155600
    },
    {
      "epoch": 6.330941102323785,
      "grad_norm": 0.3700541853904724,
      "learning_rate": 0.00019968574337184085,
      "loss": 0.3379,
      "step": 155700
    },
    {
      "epoch": 6.335007217354179,
      "grad_norm": 0.3769925832748413,
      "learning_rate": 0.00019946443588722172,
      "loss": 0.3395,
      "step": 155800
    },
    {
      "epoch": 6.339073332384573,
      "grad_norm": 0.3852536976337433,
      "learning_rate": 0.00019924312840260259,
      "loss": 0.3387,
      "step": 155900
    },
    {
      "epoch": 6.343139447414967,
      "grad_norm": 0.39979472756385803,
      "learning_rate": 0.00019902182091798346,
      "loss": 0.3393,
      "step": 156000
    },
    {
      "epoch": 6.343139447414967,
      "eval_loss": 0.35335367918014526,
      "eval_runtime": 126.6096,
      "eval_samples_per_second": 1381.428,
      "eval_steps_per_second": 43.172,
      "step": 156000
    },
    {
      "epoch": 6.347205562445362,
      "grad_norm": 0.39643487334251404,
      "learning_rate": 0.00019880051343336433,
      "loss": 0.3395,
      "step": 156100
    },
    {
      "epoch": 6.351271677475756,
      "grad_norm": 0.41663435101509094,
      "learning_rate": 0.00019857920594874517,
      "loss": 0.3396,
      "step": 156200
    },
    {
      "epoch": 6.35533779250615,
      "grad_norm": 0.3741549253463745,
      "learning_rate": 0.00019835789846412604,
      "loss": 0.3381,
      "step": 156300
    },
    {
      "epoch": 6.359403907536544,
      "grad_norm": 0.3925706744194031,
      "learning_rate": 0.00019813659097950694,
      "loss": 0.3395,
      "step": 156400
    },
    {
      "epoch": 6.363470022566938,
      "grad_norm": 0.3677079677581787,
      "learning_rate": 0.0001979152834948878,
      "loss": 0.3413,
      "step": 156500
    },
    {
      "epoch": 6.367536137597333,
      "grad_norm": 0.3378606140613556,
      "learning_rate": 0.00019769397601026868,
      "loss": 0.3386,
      "step": 156600
    },
    {
      "epoch": 6.371602252627727,
      "grad_norm": 0.40869709849357605,
      "learning_rate": 0.00019747266852564955,
      "loss": 0.3397,
      "step": 156700
    },
    {
      "epoch": 6.375668367658121,
      "grad_norm": 0.3663535416126251,
      "learning_rate": 0.00019725136104103042,
      "loss": 0.3404,
      "step": 156800
    },
    {
      "epoch": 6.379734482688515,
      "grad_norm": 0.46293842792510986,
      "learning_rate": 0.0001970300535564113,
      "loss": 0.3404,
      "step": 156900
    },
    {
      "epoch": 6.38380059771891,
      "grad_norm": 0.33924615383148193,
      "learning_rate": 0.00019680874607179213,
      "loss": 0.3378,
      "step": 157000
    },
    {
      "epoch": 6.387866712749304,
      "grad_norm": 0.40627896785736084,
      "learning_rate": 0.000196587438587173,
      "loss": 0.3403,
      "step": 157100
    },
    {
      "epoch": 6.391932827779698,
      "grad_norm": 0.3289397954940796,
      "learning_rate": 0.00019636613110255387,
      "loss": 0.3372,
      "step": 157200
    },
    {
      "epoch": 6.395998942810092,
      "grad_norm": 0.4010278284549713,
      "learning_rate": 0.00019614482361793477,
      "loss": 0.3394,
      "step": 157300
    },
    {
      "epoch": 6.400065057840486,
      "grad_norm": 0.5336008071899414,
      "learning_rate": 0.00019592351613331564,
      "loss": 0.3396,
      "step": 157400
    },
    {
      "epoch": 6.404131172870881,
      "grad_norm": 0.3478280007839203,
      "learning_rate": 0.0001957022086486965,
      "loss": 0.3412,
      "step": 157500
    },
    {
      "epoch": 6.408197287901275,
      "grad_norm": 0.4612228274345398,
      "learning_rate": 0.00019548090116407738,
      "loss": 0.3392,
      "step": 157600
    },
    {
      "epoch": 6.412263402931669,
      "grad_norm": 0.3758355975151062,
      "learning_rate": 0.00019525959367945825,
      "loss": 0.3395,
      "step": 157700
    },
    {
      "epoch": 6.416329517962063,
      "grad_norm": 0.4137314260005951,
      "learning_rate": 0.00019503828619483912,
      "loss": 0.341,
      "step": 157800
    },
    {
      "epoch": 6.420395632992458,
      "grad_norm": 0.37750232219696045,
      "learning_rate": 0.00019481697871021996,
      "loss": 0.3396,
      "step": 157900
    },
    {
      "epoch": 6.424461748022852,
      "grad_norm": 0.5409029722213745,
      "learning_rate": 0.00019459567122560083,
      "loss": 0.3391,
      "step": 158000
    },
    {
      "epoch": 6.424461748022852,
      "eval_loss": 0.3527228534221649,
      "eval_runtime": 126.4906,
      "eval_samples_per_second": 1382.727,
      "eval_steps_per_second": 43.213,
      "step": 158000
    },
    {
      "epoch": 6.428527863053246,
      "grad_norm": 0.3754025399684906,
      "learning_rate": 0.00019437436374098173,
      "loss": 0.3421,
      "step": 158100
    },
    {
      "epoch": 6.43259397808364,
      "grad_norm": 0.41043177247047424,
      "learning_rate": 0.0001941530562563626,
      "loss": 0.3393,
      "step": 158200
    },
    {
      "epoch": 6.4366600931140345,
      "grad_norm": 0.4833489656448364,
      "learning_rate": 0.00019393174877174347,
      "loss": 0.3393,
      "step": 158300
    },
    {
      "epoch": 6.4407262081444285,
      "grad_norm": 0.45431727170944214,
      "learning_rate": 0.00019371044128712434,
      "loss": 0.3418,
      "step": 158400
    },
    {
      "epoch": 6.4447923231748225,
      "grad_norm": 0.3076836168766022,
      "learning_rate": 0.0001934891338025052,
      "loss": 0.3394,
      "step": 158500
    },
    {
      "epoch": 6.4488584382052165,
      "grad_norm": 0.4241270422935486,
      "learning_rate": 0.00019326782631788608,
      "loss": 0.3393,
      "step": 158600
    },
    {
      "epoch": 6.452924553235611,
      "grad_norm": 0.582599937915802,
      "learning_rate": 0.00019304651883326693,
      "loss": 0.3383,
      "step": 158700
    },
    {
      "epoch": 6.456990668266005,
      "grad_norm": 0.4497411549091339,
      "learning_rate": 0.0001928252113486478,
      "loss": 0.3401,
      "step": 158800
    },
    {
      "epoch": 6.461056783296399,
      "grad_norm": 0.3970268666744232,
      "learning_rate": 0.00019260390386402867,
      "loss": 0.3384,
      "step": 158900
    },
    {
      "epoch": 6.465122898326793,
      "grad_norm": 0.3455342650413513,
      "learning_rate": 0.00019238259637940956,
      "loss": 0.3383,
      "step": 159000
    },
    {
      "epoch": 6.469189013357187,
      "grad_norm": 0.38016465306282043,
      "learning_rate": 0.00019216128889479043,
      "loss": 0.3412,
      "step": 159100
    },
    {
      "epoch": 6.473255128387582,
      "grad_norm": 0.4987487494945526,
      "learning_rate": 0.0001919399814101713,
      "loss": 0.3399,
      "step": 159200
    },
    {
      "epoch": 6.477321243417976,
      "grad_norm": 0.421306848526001,
      "learning_rate": 0.00019171867392555217,
      "loss": 0.3406,
      "step": 159300
    },
    {
      "epoch": 6.48138735844837,
      "grad_norm": 0.42967918515205383,
      "learning_rate": 0.00019149736644093304,
      "loss": 0.3374,
      "step": 159400
    },
    {
      "epoch": 6.485453473478764,
      "grad_norm": 0.3564209043979645,
      "learning_rate": 0.00019127605895631391,
      "loss": 0.3402,
      "step": 159500
    },
    {
      "epoch": 6.489519588509159,
      "grad_norm": 0.33076587319374084,
      "learning_rate": 0.00019105475147169476,
      "loss": 0.3411,
      "step": 159600
    },
    {
      "epoch": 6.493585703539553,
      "grad_norm": 0.4154367446899414,
      "learning_rate": 0.00019083344398707563,
      "loss": 0.3407,
      "step": 159700
    },
    {
      "epoch": 6.497651818569947,
      "grad_norm": 0.36436647176742554,
      "learning_rate": 0.00019061213650245652,
      "loss": 0.3373,
      "step": 159800
    },
    {
      "epoch": 6.501717933600341,
      "grad_norm": 0.3879109025001526,
      "learning_rate": 0.0001903908290178374,
      "loss": 0.339,
      "step": 159900
    },
    {
      "epoch": 6.505784048630736,
      "grad_norm": 0.39220932126045227,
      "learning_rate": 0.00019016952153321827,
      "loss": 0.3412,
      "step": 160000
    },
    {
      "epoch": 6.505784048630736,
      "eval_loss": 0.3524182438850403,
      "eval_runtime": 126.7407,
      "eval_samples_per_second": 1379.999,
      "eval_steps_per_second": 43.127,
      "step": 160000
    },
    {
      "epoch": 6.50985016366113,
      "grad_norm": 0.37837618589401245,
      "learning_rate": 0.00018994821404859914,
      "loss": 0.3408,
      "step": 160100
    },
    {
      "epoch": 6.513916278691524,
      "grad_norm": 0.39935970306396484,
      "learning_rate": 0.00018972690656398,
      "loss": 0.3385,
      "step": 160200
    },
    {
      "epoch": 6.517982393721918,
      "grad_norm": 0.4892711043357849,
      "learning_rate": 0.00018950559907936088,
      "loss": 0.3395,
      "step": 160300
    },
    {
      "epoch": 6.522048508752313,
      "grad_norm": 0.4113446772098541,
      "learning_rate": 0.00018928429159474172,
      "loss": 0.3399,
      "step": 160400
    },
    {
      "epoch": 6.526114623782707,
      "grad_norm": 0.46373751759529114,
      "learning_rate": 0.0001890629841101226,
      "loss": 0.3393,
      "step": 160500
    },
    {
      "epoch": 6.530180738813101,
      "grad_norm": 0.42401352524757385,
      "learning_rate": 0.00018884167662550346,
      "loss": 0.3405,
      "step": 160600
    },
    {
      "epoch": 6.534246853843495,
      "grad_norm": 0.37497198581695557,
      "learning_rate": 0.00018862036914088436,
      "loss": 0.339,
      "step": 160700
    },
    {
      "epoch": 6.538312968873889,
      "grad_norm": 0.37041711807250977,
      "learning_rate": 0.00018839906165626523,
      "loss": 0.3417,
      "step": 160800
    },
    {
      "epoch": 6.542379083904284,
      "grad_norm": 0.3811585307121277,
      "learning_rate": 0.0001881777541716461,
      "loss": 0.3387,
      "step": 160900
    },
    {
      "epoch": 6.546445198934678,
      "grad_norm": 0.530033528804779,
      "learning_rate": 0.00018795644668702697,
      "loss": 0.3395,
      "step": 161000
    },
    {
      "epoch": 6.550511313965072,
      "grad_norm": 0.3519658148288727,
      "learning_rate": 0.00018773513920240784,
      "loss": 0.3387,
      "step": 161100
    },
    {
      "epoch": 6.554577428995466,
      "grad_norm": 0.41432106494903564,
      "learning_rate": 0.0001875138317177887,
      "loss": 0.3372,
      "step": 161200
    },
    {
      "epoch": 6.558643544025861,
      "grad_norm": 0.43385154008865356,
      "learning_rate": 0.00018729252423316955,
      "loss": 0.3405,
      "step": 161300
    },
    {
      "epoch": 6.562709659056255,
      "grad_norm": 0.4039537012577057,
      "learning_rate": 0.00018707121674855042,
      "loss": 0.3392,
      "step": 161400
    },
    {
      "epoch": 6.566775774086649,
      "grad_norm": 0.4001179337501526,
      "learning_rate": 0.00018684990926393132,
      "loss": 0.3386,
      "step": 161500
    },
    {
      "epoch": 6.570841889117043,
      "grad_norm": 0.4158150851726532,
      "learning_rate": 0.0001866286017793122,
      "loss": 0.3402,
      "step": 161600
    },
    {
      "epoch": 6.574908004147438,
      "grad_norm": 0.3588518500328064,
      "learning_rate": 0.00018640729429469306,
      "loss": 0.339,
      "step": 161700
    },
    {
      "epoch": 6.578974119177832,
      "grad_norm": 0.3976643681526184,
      "learning_rate": 0.00018618598681007393,
      "loss": 0.3402,
      "step": 161800
    },
    {
      "epoch": 6.583040234208226,
      "grad_norm": 0.42995765805244446,
      "learning_rate": 0.0001859646793254548,
      "loss": 0.3394,
      "step": 161900
    },
    {
      "epoch": 6.58710634923862,
      "grad_norm": 0.458332896232605,
      "learning_rate": 0.00018574337184083567,
      "loss": 0.3406,
      "step": 162000
    },
    {
      "epoch": 6.58710634923862,
      "eval_loss": 0.351789265871048,
      "eval_runtime": 128.0852,
      "eval_samples_per_second": 1365.512,
      "eval_steps_per_second": 42.675,
      "step": 162000
    },
    {
      "epoch": 6.591172464269015,
      "grad_norm": 0.6283323168754578,
      "learning_rate": 0.0001855220643562165,
      "loss": 0.3394,
      "step": 162100
    },
    {
      "epoch": 6.595238579299409,
      "grad_norm": 0.41558021306991577,
      "learning_rate": 0.00018530075687159738,
      "loss": 0.3393,
      "step": 162200
    },
    {
      "epoch": 6.599304694329803,
      "grad_norm": 0.45757579803466797,
      "learning_rate": 0.00018507944938697825,
      "loss": 0.3384,
      "step": 162300
    },
    {
      "epoch": 6.603370809360197,
      "grad_norm": 0.45195797085762024,
      "learning_rate": 0.00018485814190235915,
      "loss": 0.3388,
      "step": 162400
    },
    {
      "epoch": 6.607436924390591,
      "grad_norm": 0.41840043663978577,
      "learning_rate": 0.00018463683441774002,
      "loss": 0.3377,
      "step": 162500
    },
    {
      "epoch": 6.6115030394209855,
      "grad_norm": 0.3923916220664978,
      "learning_rate": 0.0001844155269331209,
      "loss": 0.3413,
      "step": 162600
    },
    {
      "epoch": 6.6155691544513795,
      "grad_norm": 0.3997485041618347,
      "learning_rate": 0.00018419421944850176,
      "loss": 0.3354,
      "step": 162700
    },
    {
      "epoch": 6.6196352694817735,
      "grad_norm": 0.4366128742694855,
      "learning_rate": 0.00018397291196388263,
      "loss": 0.3399,
      "step": 162800
    },
    {
      "epoch": 6.6237013845121675,
      "grad_norm": 0.5064679980278015,
      "learning_rate": 0.00018375160447926347,
      "loss": 0.3419,
      "step": 162900
    },
    {
      "epoch": 6.627767499542562,
      "grad_norm": 0.4460974335670471,
      "learning_rate": 0.00018353029699464434,
      "loss": 0.3389,
      "step": 163000
    },
    {
      "epoch": 6.631833614572956,
      "grad_norm": 0.3581171929836273,
      "learning_rate": 0.00018330898951002522,
      "loss": 0.3393,
      "step": 163100
    },
    {
      "epoch": 6.63589972960335,
      "grad_norm": 0.4220479726791382,
      "learning_rate": 0.0001830876820254061,
      "loss": 0.3389,
      "step": 163200
    },
    {
      "epoch": 6.639965844633744,
      "grad_norm": 0.4325266182422638,
      "learning_rate": 0.00018286637454078698,
      "loss": 0.338,
      "step": 163300
    },
    {
      "epoch": 6.644031959664139,
      "grad_norm": 0.4390066862106323,
      "learning_rate": 0.00018264506705616785,
      "loss": 0.338,
      "step": 163400
    },
    {
      "epoch": 6.648098074694533,
      "grad_norm": 0.48202723264694214,
      "learning_rate": 0.00018242375957154872,
      "loss": 0.3399,
      "step": 163500
    },
    {
      "epoch": 6.652164189724927,
      "grad_norm": 0.33665165305137634,
      "learning_rate": 0.0001822024520869296,
      "loss": 0.3397,
      "step": 163600
    },
    {
      "epoch": 6.656230304755321,
      "grad_norm": 0.41818222403526306,
      "learning_rate": 0.00018198114460231046,
      "loss": 0.3391,
      "step": 163700
    },
    {
      "epoch": 6.660296419785716,
      "grad_norm": 0.3725346028804779,
      "learning_rate": 0.0001817598371176913,
      "loss": 0.3374,
      "step": 163800
    },
    {
      "epoch": 6.66436253481611,
      "grad_norm": 0.3870773911476135,
      "learning_rate": 0.00018153852963307218,
      "loss": 0.3392,
      "step": 163900
    },
    {
      "epoch": 6.668428649846504,
      "grad_norm": 0.5001316070556641,
      "learning_rate": 0.00018131722214845305,
      "loss": 0.339,
      "step": 164000
    },
    {
      "epoch": 6.668428649846504,
      "eval_loss": 0.3510933220386505,
      "eval_runtime": 125.7673,
      "eval_samples_per_second": 1390.679,
      "eval_steps_per_second": 43.461,
      "step": 164000
    },
    {
      "epoch": 6.672494764876898,
      "grad_norm": 0.38458216190338135,
      "learning_rate": 0.00018109591466383394,
      "loss": 0.3403,
      "step": 164100
    },
    {
      "epoch": 6.676560879907292,
      "grad_norm": 0.37791699171066284,
      "learning_rate": 0.00018087460717921481,
      "loss": 0.3387,
      "step": 164200
    },
    {
      "epoch": 6.680626994937687,
      "grad_norm": 0.4054788053035736,
      "learning_rate": 0.00018065329969459568,
      "loss": 0.3404,
      "step": 164300
    },
    {
      "epoch": 6.684693109968081,
      "grad_norm": 0.42405250668525696,
      "learning_rate": 0.00018043199220997656,
      "loss": 0.3397,
      "step": 164400
    },
    {
      "epoch": 6.688759224998475,
      "grad_norm": 0.44726794958114624,
      "learning_rate": 0.00018021068472535743,
      "loss": 0.3377,
      "step": 164500
    },
    {
      "epoch": 6.692825340028869,
      "grad_norm": 0.38774198293685913,
      "learning_rate": 0.00017998937724073827,
      "loss": 0.3405,
      "step": 164600
    },
    {
      "epoch": 6.696891455059264,
      "grad_norm": 0.44191181659698486,
      "learning_rate": 0.00017976806975611914,
      "loss": 0.3398,
      "step": 164700
    },
    {
      "epoch": 6.700957570089658,
      "grad_norm": 0.4308350682258606,
      "learning_rate": 0.0001795467622715,
      "loss": 0.3398,
      "step": 164800
    },
    {
      "epoch": 6.705023685120052,
      "grad_norm": 0.5093550682067871,
      "learning_rate": 0.0001793254547868809,
      "loss": 0.3377,
      "step": 164900
    },
    {
      "epoch": 6.709089800150446,
      "grad_norm": 0.39217525720596313,
      "learning_rate": 0.00017910414730226178,
      "loss": 0.3389,
      "step": 165000
    },
    {
      "epoch": 6.71315591518084,
      "grad_norm": 0.4686533808708191,
      "learning_rate": 0.00017888283981764265,
      "loss": 0.3394,
      "step": 165100
    },
    {
      "epoch": 6.717222030211235,
      "grad_norm": 0.4131370782852173,
      "learning_rate": 0.00017866153233302352,
      "loss": 0.3407,
      "step": 165200
    },
    {
      "epoch": 6.721288145241629,
      "grad_norm": 0.4165455102920532,
      "learning_rate": 0.0001784402248484044,
      "loss": 0.3381,
      "step": 165300
    },
    {
      "epoch": 6.725354260272023,
      "grad_norm": 0.5178784728050232,
      "learning_rate": 0.00017821891736378526,
      "loss": 0.3402,
      "step": 165400
    },
    {
      "epoch": 6.729420375302418,
      "grad_norm": 0.5464301109313965,
      "learning_rate": 0.0001779976098791661,
      "loss": 0.339,
      "step": 165500
    },
    {
      "epoch": 6.733486490332812,
      "grad_norm": 0.3884522616863251,
      "learning_rate": 0.00017777630239454697,
      "loss": 0.3389,
      "step": 165600
    },
    {
      "epoch": 6.737552605363206,
      "grad_norm": 0.4552499055862427,
      "learning_rate": 0.00017755499490992784,
      "loss": 0.3375,
      "step": 165700
    },
    {
      "epoch": 6.7416187203936,
      "grad_norm": 0.5277954936027527,
      "learning_rate": 0.00017733368742530874,
      "loss": 0.3378,
      "step": 165800
    },
    {
      "epoch": 6.745684835423994,
      "grad_norm": 0.45769575238227844,
      "learning_rate": 0.0001771123799406896,
      "loss": 0.3386,
      "step": 165900
    },
    {
      "epoch": 6.749750950454389,
      "grad_norm": 0.449521005153656,
      "learning_rate": 0.00017689107245607048,
      "loss": 0.3384,
      "step": 166000
    },
    {
      "epoch": 6.749750950454389,
      "eval_loss": 0.35142987966537476,
      "eval_runtime": 126.629,
      "eval_samples_per_second": 1381.216,
      "eval_steps_per_second": 43.165,
      "step": 166000
    },
    {
      "epoch": 6.753817065484783,
      "grad_norm": 0.486268013715744,
      "learning_rate": 0.00017666976497145135,
      "loss": 0.3393,
      "step": 166100
    },
    {
      "epoch": 6.757883180515177,
      "grad_norm": 0.4422664940357208,
      "learning_rate": 0.00017644845748683222,
      "loss": 0.3391,
      "step": 166200
    },
    {
      "epoch": 6.761949295545571,
      "grad_norm": 0.47140660881996155,
      "learning_rate": 0.00017622715000221306,
      "loss": 0.3389,
      "step": 166300
    },
    {
      "epoch": 6.766015410575966,
      "grad_norm": 0.40918901562690735,
      "learning_rate": 0.00017600584251759393,
      "loss": 0.3393,
      "step": 166400
    },
    {
      "epoch": 6.77008152560636,
      "grad_norm": 0.3965205252170563,
      "learning_rate": 0.0001757845350329748,
      "loss": 0.3394,
      "step": 166500
    },
    {
      "epoch": 6.774147640636754,
      "grad_norm": 0.3828276991844177,
      "learning_rate": 0.00017556322754835567,
      "loss": 0.34,
      "step": 166600
    },
    {
      "epoch": 6.778213755667148,
      "grad_norm": 0.365001380443573,
      "learning_rate": 0.00017534192006373657,
      "loss": 0.3398,
      "step": 166700
    },
    {
      "epoch": 6.782279870697542,
      "grad_norm": 0.4346447288990021,
      "learning_rate": 0.00017512061257911744,
      "loss": 0.3404,
      "step": 166800
    },
    {
      "epoch": 6.7863459857279365,
      "grad_norm": 0.41105660796165466,
      "learning_rate": 0.0001748993050944983,
      "loss": 0.3395,
      "step": 166900
    },
    {
      "epoch": 6.7904121007583305,
      "grad_norm": 0.42999449372291565,
      "learning_rate": 0.00017467799760987918,
      "loss": 0.3364,
      "step": 167000
    },
    {
      "epoch": 6.7944782157887245,
      "grad_norm": 0.4289700388908386,
      "learning_rate": 0.00017445669012526005,
      "loss": 0.3386,
      "step": 167100
    },
    {
      "epoch": 6.798544330819119,
      "grad_norm": 0.40332576632499695,
      "learning_rate": 0.0001742353826406409,
      "loss": 0.3378,
      "step": 167200
    },
    {
      "epoch": 6.802610445849513,
      "grad_norm": 0.41327524185180664,
      "learning_rate": 0.00017401407515602176,
      "loss": 0.3362,
      "step": 167300
    },
    {
      "epoch": 6.806676560879907,
      "grad_norm": 0.4517431855201721,
      "learning_rate": 0.00017379276767140263,
      "loss": 0.3395,
      "step": 167400
    },
    {
      "epoch": 6.810742675910301,
      "grad_norm": 0.3988397717475891,
      "learning_rate": 0.00017357146018678353,
      "loss": 0.3388,
      "step": 167500
    },
    {
      "epoch": 6.814808790940695,
      "grad_norm": 0.49104103446006775,
      "learning_rate": 0.0001733501527021644,
      "loss": 0.3377,
      "step": 167600
    },
    {
      "epoch": 6.81887490597109,
      "grad_norm": 0.4677295684814453,
      "learning_rate": 0.00017312884521754527,
      "loss": 0.3404,
      "step": 167700
    },
    {
      "epoch": 6.822941021001484,
      "grad_norm": 0.33738693594932556,
      "learning_rate": 0.00017290753773292614,
      "loss": 0.3385,
      "step": 167800
    },
    {
      "epoch": 6.827007136031878,
      "grad_norm": 0.4120621085166931,
      "learning_rate": 0.000172686230248307,
      "loss": 0.3381,
      "step": 167900
    },
    {
      "epoch": 6.831073251062272,
      "grad_norm": 0.45696234703063965,
      "learning_rate": 0.00017246492276368786,
      "loss": 0.3385,
      "step": 168000
    },
    {
      "epoch": 6.831073251062272,
      "eval_loss": 0.35107529163360596,
      "eval_runtime": 127.4767,
      "eval_samples_per_second": 1372.031,
      "eval_steps_per_second": 42.878,
      "step": 168000
    },
    {
      "epoch": 6.835139366092667,
      "grad_norm": 0.35937201976776123,
      "learning_rate": 0.00017224361527906873,
      "loss": 0.3404,
      "step": 168100
    },
    {
      "epoch": 6.839205481123061,
      "grad_norm": 0.4569317698478699,
      "learning_rate": 0.0001720223077944496,
      "loss": 0.34,
      "step": 168200
    },
    {
      "epoch": 6.843271596153455,
      "grad_norm": 0.45811671018600464,
      "learning_rate": 0.00017180100030983047,
      "loss": 0.3375,
      "step": 168300
    },
    {
      "epoch": 6.847337711183849,
      "grad_norm": 0.36730846762657166,
      "learning_rate": 0.00017157969282521136,
      "loss": 0.3385,
      "step": 168400
    },
    {
      "epoch": 6.851403826214243,
      "grad_norm": 0.4532783627510071,
      "learning_rate": 0.00017135838534059223,
      "loss": 0.3384,
      "step": 168500
    },
    {
      "epoch": 6.855469941244638,
      "grad_norm": 0.40666788816452026,
      "learning_rate": 0.0001711370778559731,
      "loss": 0.3381,
      "step": 168600
    },
    {
      "epoch": 6.859536056275032,
      "grad_norm": 0.5559688210487366,
      "learning_rate": 0.00017091577037135397,
      "loss": 0.3391,
      "step": 168700
    },
    {
      "epoch": 6.863602171305426,
      "grad_norm": 0.4357600808143616,
      "learning_rate": 0.00017069446288673482,
      "loss": 0.3364,
      "step": 168800
    },
    {
      "epoch": 6.867668286335821,
      "grad_norm": 0.5936310291290283,
      "learning_rate": 0.0001704731554021157,
      "loss": 0.3388,
      "step": 168900
    },
    {
      "epoch": 6.871734401366215,
      "grad_norm": 0.3927094340324402,
      "learning_rate": 0.00017025184791749656,
      "loss": 0.3379,
      "step": 169000
    },
    {
      "epoch": 6.875800516396609,
      "grad_norm": 0.48672589659690857,
      "learning_rate": 0.00017003054043287743,
      "loss": 0.3405,
      "step": 169100
    },
    {
      "epoch": 6.879866631427003,
      "grad_norm": 0.6497448682785034,
      "learning_rate": 0.00016980923294825833,
      "loss": 0.337,
      "step": 169200
    },
    {
      "epoch": 6.883932746457397,
      "grad_norm": 0.3634992241859436,
      "learning_rate": 0.0001695879254636392,
      "loss": 0.3385,
      "step": 169300
    },
    {
      "epoch": 6.887998861487792,
      "grad_norm": 0.4032268226146698,
      "learning_rate": 0.00016936661797902007,
      "loss": 0.3395,
      "step": 169400
    },
    {
      "epoch": 6.892064976518186,
      "grad_norm": 0.3967370390892029,
      "learning_rate": 0.00016914531049440094,
      "loss": 0.3358,
      "step": 169500
    },
    {
      "epoch": 6.89613109154858,
      "grad_norm": 0.45460185408592224,
      "learning_rate": 0.0001689240030097818,
      "loss": 0.3408,
      "step": 169600
    },
    {
      "epoch": 6.900197206578974,
      "grad_norm": 0.45982909202575684,
      "learning_rate": 0.00016870269552516265,
      "loss": 0.3394,
      "step": 169700
    },
    {
      "epoch": 6.904263321609369,
      "grad_norm": 0.4853367209434509,
      "learning_rate": 0.00016848138804054352,
      "loss": 0.3376,
      "step": 169800
    },
    {
      "epoch": 6.908329436639763,
      "grad_norm": 0.4391024112701416,
      "learning_rate": 0.0001682600805559244,
      "loss": 0.3384,
      "step": 169900
    },
    {
      "epoch": 6.912395551670157,
      "grad_norm": 0.46232151985168457,
      "learning_rate": 0.00016803877307130526,
      "loss": 0.3401,
      "step": 170000
    },
    {
      "epoch": 6.912395551670157,
      "eval_loss": 0.3503514528274536,
      "eval_runtime": 126.7124,
      "eval_samples_per_second": 1380.307,
      "eval_steps_per_second": 43.137,
      "step": 170000
    },
    {
      "epoch": 6.916461666700551,
      "grad_norm": 0.39522457122802734,
      "learning_rate": 0.00016781746558668616,
      "loss": 0.3399,
      "step": 170100
    },
    {
      "epoch": 6.920527781730945,
      "grad_norm": 0.3525104522705078,
      "learning_rate": 0.00016759615810206703,
      "loss": 0.3389,
      "step": 170200
    },
    {
      "epoch": 6.92459389676134,
      "grad_norm": 0.42472848296165466,
      "learning_rate": 0.0001673748506174479,
      "loss": 0.3387,
      "step": 170300
    },
    {
      "epoch": 6.928660011791734,
      "grad_norm": 0.4296814799308777,
      "learning_rate": 0.00016715354313282877,
      "loss": 0.3401,
      "step": 170400
    },
    {
      "epoch": 6.932726126822128,
      "grad_norm": 0.45231714844703674,
      "learning_rate": 0.0001669322356482096,
      "loss": 0.3373,
      "step": 170500
    },
    {
      "epoch": 6.936792241852522,
      "grad_norm": 0.44535884261131287,
      "learning_rate": 0.00016671092816359048,
      "loss": 0.3379,
      "step": 170600
    },
    {
      "epoch": 6.9408583568829165,
      "grad_norm": 0.3874354362487793,
      "learning_rate": 0.00016648962067897135,
      "loss": 0.3388,
      "step": 170700
    },
    {
      "epoch": 6.9449244719133105,
      "grad_norm": 0.5168071985244751,
      "learning_rate": 0.00016626831319435222,
      "loss": 0.3359,
      "step": 170800
    },
    {
      "epoch": 6.9489905869437045,
      "grad_norm": 0.42912158370018005,
      "learning_rate": 0.00016604700570973312,
      "loss": 0.3396,
      "step": 170900
    },
    {
      "epoch": 6.9530567019740985,
      "grad_norm": 0.39947399497032166,
      "learning_rate": 0.000165825698225114,
      "loss": 0.336,
      "step": 171000
    },
    {
      "epoch": 6.957122817004493,
      "grad_norm": 0.3906143605709076,
      "learning_rate": 0.00016560439074049486,
      "loss": 0.3385,
      "step": 171100
    },
    {
      "epoch": 6.961188932034887,
      "grad_norm": 0.4265006184577942,
      "learning_rate": 0.00016538308325587573,
      "loss": 0.3362,
      "step": 171200
    },
    {
      "epoch": 6.965255047065281,
      "grad_norm": 0.522555410861969,
      "learning_rate": 0.0001651617757712566,
      "loss": 0.3375,
      "step": 171300
    },
    {
      "epoch": 6.969321162095675,
      "grad_norm": 0.38510662317276,
      "learning_rate": 0.00016494046828663744,
      "loss": 0.339,
      "step": 171400
    },
    {
      "epoch": 6.97338727712607,
      "grad_norm": 0.37856119871139526,
      "learning_rate": 0.00016471916080201831,
      "loss": 0.3414,
      "step": 171500
    },
    {
      "epoch": 6.977453392156464,
      "grad_norm": 0.4704599380493164,
      "learning_rate": 0.00016449785331739918,
      "loss": 0.3375,
      "step": 171600
    },
    {
      "epoch": 6.981519507186858,
      "grad_norm": 0.38676896691322327,
      "learning_rate": 0.00016427654583278005,
      "loss": 0.3384,
      "step": 171700
    },
    {
      "epoch": 6.985585622217252,
      "grad_norm": 0.5690879225730896,
      "learning_rate": 0.00016405523834816095,
      "loss": 0.3388,
      "step": 171800
    },
    {
      "epoch": 6.989651737247646,
      "grad_norm": 0.4277673363685608,
      "learning_rate": 0.00016383393086354182,
      "loss": 0.3391,
      "step": 171900
    },
    {
      "epoch": 6.993717852278041,
      "grad_norm": 0.4499121606349945,
      "learning_rate": 0.0001636126233789227,
      "loss": 0.3389,
      "step": 172000
    },
    {
      "epoch": 6.993717852278041,
      "eval_loss": 0.35004499554634094,
      "eval_runtime": 126.0578,
      "eval_samples_per_second": 1387.475,
      "eval_steps_per_second": 43.361,
      "step": 172000
    },
    {
      "epoch": 6.997783967308435,
      "grad_norm": 0.4126049280166626,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3369,
      "step": 172100
    },
    {
      "epoch": 7.001850082338829,
      "grad_norm": 0.4388507306575775,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3363,
      "step": 172200
    },
    {
      "epoch": 7.005916197369223,
      "grad_norm": 0.38915345072746277,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.332,
      "step": 172300
    },
    {
      "epoch": 7.009982312399618,
      "grad_norm": 0.500696063041687,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3313,
      "step": 172400
    },
    {
      "epoch": 7.014048427430012,
      "grad_norm": 0.4523860514163971,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3326,
      "step": 172500
    },
    {
      "epoch": 7.018114542460406,
      "grad_norm": 0.549594521522522,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.3316,
      "step": 172600
    },
    {
      "epoch": 7.0221806574908,
      "grad_norm": 0.43620166182518005,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.3321,
      "step": 172700
    },
    {
      "epoch": 7.026246772521195,
      "grad_norm": 0.44333168864250183,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.3317,
      "step": 172800
    },
    {
      "epoch": 7.030312887551589,
      "grad_norm": 0.4472675323486328,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.332,
      "step": 172900
    },
    {
      "epoch": 7.034379002581983,
      "grad_norm": 0.4368543028831482,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3316,
      "step": 173000
    },
    {
      "epoch": 7.038445117612377,
      "grad_norm": 0.4399399757385254,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3316,
      "step": 173100
    },
    {
      "epoch": 7.042511232642772,
      "grad_norm": 0.48157021403312683,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3317,
      "step": 173200
    },
    {
      "epoch": 7.046577347673166,
      "grad_norm": 0.3792247474193573,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.332,
      "step": 173300
    },
    {
      "epoch": 7.05064346270356,
      "grad_norm": 0.42273908853530884,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3302,
      "step": 173400
    },
    {
      "epoch": 7.054709577733954,
      "grad_norm": 0.5146006941795349,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3333,
      "step": 173500
    },
    {
      "epoch": 7.058775692764348,
      "grad_norm": 0.45410406589508057,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3311,
      "step": 173600
    },
    {
      "epoch": 7.062841807794743,
      "grad_norm": 0.5593783259391785,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.331,
      "step": 173700
    },
    {
      "epoch": 7.066907922825137,
      "grad_norm": 0.4100622236728668,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3323,
      "step": 173800
    },
    {
      "epoch": 7.070974037855531,
      "grad_norm": 0.40047687292099,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.3321,
      "step": 173900
    },
    {
      "epoch": 7.075040152885925,
      "grad_norm": 0.46826425194740295,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3316,
      "step": 174000
    },
    {
      "epoch": 7.075040152885925,
      "eval_loss": 0.3499464988708496,
      "eval_runtime": 126.849,
      "eval_samples_per_second": 1378.821,
      "eval_steps_per_second": 43.091,
      "step": 174000
    },
    {
      "epoch": 7.07910626791632,
      "grad_norm": 0.5306036472320557,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.3321,
      "step": 174100
    },
    {
      "epoch": 7.083172382946714,
      "grad_norm": 0.492422878742218,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.3315,
      "step": 174200
    },
    {
      "epoch": 7.087238497977108,
      "grad_norm": 0.4508959949016571,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.3325,
      "step": 174300
    },
    {
      "epoch": 7.091304613007502,
      "grad_norm": 0.5280702114105225,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.332,
      "step": 174400
    },
    {
      "epoch": 7.095370728037897,
      "grad_norm": 0.40089720487594604,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3315,
      "step": 174500
    },
    {
      "epoch": 7.099436843068291,
      "grad_norm": 0.5712629556655884,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.3335,
      "step": 174600
    },
    {
      "epoch": 7.103502958098685,
      "grad_norm": 0.5345228910446167,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3339,
      "step": 174700
    },
    {
      "epoch": 7.107569073129079,
      "grad_norm": 0.4486744701862335,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.3342,
      "step": 174800
    },
    {
      "epoch": 7.111635188159473,
      "grad_norm": 0.42618486285209656,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3322,
      "step": 174900
    },
    {
      "epoch": 7.1157013031898675,
      "grad_norm": 0.48023009300231934,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3328,
      "step": 175000
    },
    {
      "epoch": 7.1197674182202615,
      "grad_norm": 0.40899333357810974,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.332,
      "step": 175100
    },
    {
      "epoch": 7.1238335332506555,
      "grad_norm": 0.44169822335243225,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.3333,
      "step": 175200
    },
    {
      "epoch": 7.1278996482810495,
      "grad_norm": 0.46005475521087646,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3329,
      "step": 175300
    },
    {
      "epoch": 7.131965763311444,
      "grad_norm": 0.42085814476013184,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3323,
      "step": 175400
    },
    {
      "epoch": 7.136031878341838,
      "grad_norm": 0.3960856795310974,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3328,
      "step": 175500
    },
    {
      "epoch": 7.140097993372232,
      "grad_norm": 0.46251940727233887,
      "learning_rate": 0.000155645553932634,
      "loss": 0.3322,
      "step": 175600
    },
    {
      "epoch": 7.144164108402626,
      "grad_norm": 0.42530491948127747,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3301,
      "step": 175700
    },
    {
      "epoch": 7.148230223433021,
      "grad_norm": 0.4292850196361542,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3326,
      "step": 175800
    },
    {
      "epoch": 7.152296338463415,
      "grad_norm": 0.43397098779678345,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3322,
      "step": 175900
    },
    {
      "epoch": 7.156362453493809,
      "grad_norm": 0.4093743562698364,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.3339,
      "step": 176000
    },
    {
      "epoch": 7.156362453493809,
      "eval_loss": 0.34914258122444153,
      "eval_runtime": 126.0658,
      "eval_samples_per_second": 1387.386,
      "eval_steps_per_second": 43.358,
      "step": 176000
    },
    {
      "epoch": 7.160428568524203,
      "grad_norm": 0.5157127380371094,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.3341,
      "step": 176100
    },
    {
      "epoch": 7.164494683554598,
      "grad_norm": 0.4371393024921417,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3328,
      "step": 176200
    },
    {
      "epoch": 7.168560798584992,
      "grad_norm": 0.5743579268455505,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.3326,
      "step": 176300
    },
    {
      "epoch": 7.172626913615386,
      "grad_norm": 0.4993985891342163,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3333,
      "step": 176400
    },
    {
      "epoch": 7.17669302864578,
      "grad_norm": 0.4288632273674011,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3332,
      "step": 176500
    },
    {
      "epoch": 7.180759143676174,
      "grad_norm": 0.41791608929634094,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3303,
      "step": 176600
    },
    {
      "epoch": 7.184825258706569,
      "grad_norm": 0.4396131634712219,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.3312,
      "step": 176700
    },
    {
      "epoch": 7.188891373736963,
      "grad_norm": 0.4497370719909668,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3338,
      "step": 176800
    },
    {
      "epoch": 7.192957488767357,
      "grad_norm": 0.43747904896736145,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3316,
      "step": 176900
    },
    {
      "epoch": 7.197023603797751,
      "grad_norm": 0.48047080636024475,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3332,
      "step": 177000
    },
    {
      "epoch": 7.201089718828146,
      "grad_norm": 0.41734737157821655,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3332,
      "step": 177100
    },
    {
      "epoch": 7.20515583385854,
      "grad_norm": 0.47578081488609314,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3324,
      "step": 177200
    },
    {
      "epoch": 7.209221948888934,
      "grad_norm": 0.39234688878059387,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.3314,
      "step": 177300
    },
    {
      "epoch": 7.213288063919328,
      "grad_norm": 0.4479012191295624,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.333,
      "step": 177400
    },
    {
      "epoch": 7.217354178949723,
      "grad_norm": 0.5456105470657349,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.3337,
      "step": 177500
    },
    {
      "epoch": 7.221420293980117,
      "grad_norm": 0.41027572751045227,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3325,
      "step": 177600
    },
    {
      "epoch": 7.225486409010511,
      "grad_norm": 0.5413044691085815,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3319,
      "step": 177700
    },
    {
      "epoch": 7.229552524040905,
      "grad_norm": 0.6496666669845581,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.3338,
      "step": 177800
    },
    {
      "epoch": 7.233618639071299,
      "grad_norm": 0.4464977979660034,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3337,
      "step": 177900
    },
    {
      "epoch": 7.237684754101694,
      "grad_norm": 0.4817837178707123,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.331,
      "step": 178000
    },
    {
      "epoch": 7.237684754101694,
      "eval_loss": 0.3491378724575043,
      "eval_runtime": 127.9383,
      "eval_samples_per_second": 1367.081,
      "eval_steps_per_second": 42.724,
      "step": 178000
    },
    {
      "epoch": 7.241750869132088,
      "grad_norm": 0.5312494039535522,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3322,
      "step": 178100
    },
    {
      "epoch": 7.245816984162482,
      "grad_norm": 0.44317978620529175,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3326,
      "step": 178200
    },
    {
      "epoch": 7.249883099192876,
      "grad_norm": 0.3843345046043396,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3328,
      "step": 178300
    },
    {
      "epoch": 7.253949214223271,
      "grad_norm": 0.3914985954761505,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.333,
      "step": 178400
    },
    {
      "epoch": 7.258015329253665,
      "grad_norm": 0.4176584780216217,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3327,
      "step": 178500
    },
    {
      "epoch": 7.262081444284059,
      "grad_norm": 0.4728696346282959,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3321,
      "step": 178600
    },
    {
      "epoch": 7.266147559314453,
      "grad_norm": 0.4352945387363434,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3324,
      "step": 178700
    },
    {
      "epoch": 7.2702136743448476,
      "grad_norm": 0.4635455310344696,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3324,
      "step": 178800
    },
    {
      "epoch": 7.274279789375242,
      "grad_norm": 0.4805721044540405,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3327,
      "step": 178900
    },
    {
      "epoch": 7.278345904405636,
      "grad_norm": 0.4993230402469635,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3314,
      "step": 179000
    },
    {
      "epoch": 7.28241201943603,
      "grad_norm": 0.48739707469940186,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.3321,
      "step": 179100
    },
    {
      "epoch": 7.2864781344664245,
      "grad_norm": 0.4209226965904236,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3317,
      "step": 179200
    },
    {
      "epoch": 7.2905442494968185,
      "grad_norm": 0.419851690530777,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.3314,
      "step": 179300
    },
    {
      "epoch": 7.2946103645272125,
      "grad_norm": 0.4099438488483429,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3324,
      "step": 179400
    },
    {
      "epoch": 7.2986764795576065,
      "grad_norm": 0.49053871631622314,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3339,
      "step": 179500
    },
    {
      "epoch": 7.3027425945880005,
      "grad_norm": 0.5350614786148071,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3346,
      "step": 179600
    },
    {
      "epoch": 7.306808709618395,
      "grad_norm": 0.5202147364616394,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.332,
      "step": 179700
    },
    {
      "epoch": 7.310874824648789,
      "grad_norm": 0.4880245327949524,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.3317,
      "step": 179800
    },
    {
      "epoch": 7.314940939679183,
      "grad_norm": 0.4677850604057312,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3325,
      "step": 179900
    },
    {
      "epoch": 7.319007054709577,
      "grad_norm": 0.4635712802410126,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3328,
      "step": 180000
    },
    {
      "epoch": 7.319007054709577,
      "eval_loss": 0.34897229075431824,
      "eval_runtime": 126.3192,
      "eval_samples_per_second": 1384.603,
      "eval_steps_per_second": 43.271,
      "step": 180000
    },
    {
      "epoch": 7.323073169739972,
      "grad_norm": 0.4612460136413574,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3329,
      "step": 180100
    },
    {
      "epoch": 7.327139284770366,
      "grad_norm": 0.4299032390117645,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.3317,
      "step": 180200
    },
    {
      "epoch": 7.33120539980076,
      "grad_norm": 0.5972719192504883,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3318,
      "step": 180300
    },
    {
      "epoch": 7.335271514831154,
      "grad_norm": 0.4131240248680115,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.3323,
      "step": 180400
    },
    {
      "epoch": 7.339337629861549,
      "grad_norm": 0.3729660212993622,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3318,
      "step": 180500
    },
    {
      "epoch": 7.343403744891943,
      "grad_norm": 0.44812315702438354,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.3308,
      "step": 180600
    },
    {
      "epoch": 7.347469859922337,
      "grad_norm": 0.5073750615119934,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3338,
      "step": 180700
    },
    {
      "epoch": 7.351535974952731,
      "grad_norm": 0.576614499092102,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.3316,
      "step": 180800
    },
    {
      "epoch": 7.355602089983126,
      "grad_norm": 0.463189959526062,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3318,
      "step": 180900
    },
    {
      "epoch": 7.35966820501352,
      "grad_norm": 0.3801020681858063,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3331,
      "step": 181000
    },
    {
      "epoch": 7.363734320043914,
      "grad_norm": 0.46762409806251526,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3328,
      "step": 181100
    },
    {
      "epoch": 7.367800435074308,
      "grad_norm": 0.5112208127975464,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3323,
      "step": 181200
    },
    {
      "epoch": 7.371866550104702,
      "grad_norm": 0.45042136311531067,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3332,
      "step": 181300
    },
    {
      "epoch": 7.375932665135097,
      "grad_norm": 0.5258458852767944,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3329,
      "step": 181400
    },
    {
      "epoch": 7.379998780165491,
      "grad_norm": 0.39498528838157654,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.3322,
      "step": 181500
    },
    {
      "epoch": 7.384064895195885,
      "grad_norm": 0.49392130970954895,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3312,
      "step": 181600
    },
    {
      "epoch": 7.388131010226279,
      "grad_norm": 0.44199562072753906,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.3306,
      "step": 181700
    },
    {
      "epoch": 7.392197125256674,
      "grad_norm": 0.5823972821235657,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3332,
      "step": 181800
    },
    {
      "epoch": 7.396263240287068,
      "grad_norm": 0.44744837284088135,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3329,
      "step": 181900
    },
    {
      "epoch": 7.400329355317462,
      "grad_norm": 0.6194844245910645,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3318,
      "step": 182000
    },
    {
      "epoch": 7.400329355317462,
      "eval_loss": 0.3482532501220703,
      "eval_runtime": 126.2374,
      "eval_samples_per_second": 1385.501,
      "eval_steps_per_second": 43.299,
      "step": 182000
    },
    {
      "epoch": 7.404395470347856,
      "grad_norm": 0.4269607365131378,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3321,
      "step": 182100
    },
    {
      "epoch": 7.408461585378251,
      "grad_norm": 0.394111305475235,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.3338,
      "step": 182200
    },
    {
      "epoch": 7.412527700408645,
      "grad_norm": 0.4308222830295563,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.3323,
      "step": 182300
    },
    {
      "epoch": 7.416593815439039,
      "grad_norm": 0.43723976612091064,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3345,
      "step": 182400
    },
    {
      "epoch": 7.420659930469433,
      "grad_norm": 0.4306730031967163,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3352,
      "step": 182500
    },
    {
      "epoch": 7.424726045499828,
      "grad_norm": 0.3899383246898651,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.3317,
      "step": 182600
    },
    {
      "epoch": 7.428792160530222,
      "grad_norm": 0.4927588403224945,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3346,
      "step": 182700
    },
    {
      "epoch": 7.432858275560616,
      "grad_norm": 0.5127007961273193,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3333,
      "step": 182800
    },
    {
      "epoch": 7.43692439059101,
      "grad_norm": 0.4296179413795471,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.3329,
      "step": 182900
    },
    {
      "epoch": 7.440990505621404,
      "grad_norm": 0.5094007849693298,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3324,
      "step": 183000
    },
    {
      "epoch": 7.4450566206517985,
      "grad_norm": 0.4707012176513672,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3332,
      "step": 183100
    },
    {
      "epoch": 7.4491227356821925,
      "grad_norm": 0.5031083822250366,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.3313,
      "step": 183200
    },
    {
      "epoch": 7.4531888507125865,
      "grad_norm": 0.4807642102241516,
      "learning_rate": 0.000138604877616961,
      "loss": 0.3334,
      "step": 183300
    },
    {
      "epoch": 7.4572549657429805,
      "grad_norm": 0.4534464478492737,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.331,
      "step": 183400
    },
    {
      "epoch": 7.461321080773375,
      "grad_norm": 0.4358145296573639,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3336,
      "step": 183500
    },
    {
      "epoch": 7.465387195803769,
      "grad_norm": 0.5938953161239624,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.3326,
      "step": 183600
    },
    {
      "epoch": 7.469453310834163,
      "grad_norm": 0.5134260654449463,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3323,
      "step": 183700
    },
    {
      "epoch": 7.473519425864557,
      "grad_norm": 0.4198363125324249,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.3334,
      "step": 183800
    },
    {
      "epoch": 7.477585540894952,
      "grad_norm": 0.5212036371231079,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3317,
      "step": 183900
    },
    {
      "epoch": 7.481651655925346,
      "grad_norm": 0.41884705424308777,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.333,
      "step": 184000
    },
    {
      "epoch": 7.481651655925346,
      "eval_loss": 0.3474758267402649,
      "eval_runtime": 129.3086,
      "eval_samples_per_second": 1352.594,
      "eval_steps_per_second": 42.271,
      "step": 184000
    },
    {
      "epoch": 7.48571777095574,
      "grad_norm": 0.4511714577674866,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3334,
      "step": 184100
    },
    {
      "epoch": 7.489783885986134,
      "grad_norm": 0.4540470242500305,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.3342,
      "step": 184200
    },
    {
      "epoch": 7.493850001016529,
      "grad_norm": 0.43198806047439575,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.333,
      "step": 184300
    },
    {
      "epoch": 7.497916116046923,
      "grad_norm": 0.47279092669487,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3318,
      "step": 184400
    },
    {
      "epoch": 7.501982231077317,
      "grad_norm": 0.652411699295044,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3332,
      "step": 184500
    },
    {
      "epoch": 7.506048346107711,
      "grad_norm": 0.4366593360900879,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.3316,
      "step": 184600
    },
    {
      "epoch": 7.510114461138105,
      "grad_norm": 0.5323725938796997,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3324,
      "step": 184700
    },
    {
      "epoch": 7.5141805761685,
      "grad_norm": 0.5465081334114075,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.3312,
      "step": 184800
    },
    {
      "epoch": 7.518246691198894,
      "grad_norm": 0.5474028587341309,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.3337,
      "step": 184900
    },
    {
      "epoch": 7.522312806229288,
      "grad_norm": 0.4725183844566345,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3329,
      "step": 185000
    },
    {
      "epoch": 7.526378921259682,
      "grad_norm": 0.4267992079257965,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3322,
      "step": 185100
    },
    {
      "epoch": 7.530445036290077,
      "grad_norm": 0.5127508640289307,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3336,
      "step": 185200
    },
    {
      "epoch": 7.534511151320471,
      "grad_norm": 0.503171980381012,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3321,
      "step": 185300
    },
    {
      "epoch": 7.538577266350865,
      "grad_norm": 0.5355773568153381,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.334,
      "step": 185400
    },
    {
      "epoch": 7.542643381381259,
      "grad_norm": 0.4612627923488617,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.331,
      "step": 185500
    },
    {
      "epoch": 7.546709496411653,
      "grad_norm": 0.43207886815071106,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.3332,
      "step": 185600
    },
    {
      "epoch": 7.550775611442048,
      "grad_norm": 0.44733670353889465,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3323,
      "step": 185700
    },
    {
      "epoch": 7.554841726472442,
      "grad_norm": 0.5029219388961792,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3316,
      "step": 185800
    },
    {
      "epoch": 7.558907841502836,
      "grad_norm": 0.4887675642967224,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.3323,
      "step": 185900
    },
    {
      "epoch": 7.562973956533231,
      "grad_norm": 0.4346778094768524,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.3328,
      "step": 186000
    },
    {
      "epoch": 7.562973956533231,
      "eval_loss": 0.34664657711982727,
      "eval_runtime": 125.6002,
      "eval_samples_per_second": 1392.53,
      "eval_steps_per_second": 43.519,
      "step": 186000
    },
    {
      "epoch": 7.567040071563625,
      "grad_norm": 0.5004862546920776,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3327,
      "step": 186100
    },
    {
      "epoch": 7.571106186594019,
      "grad_norm": 0.4635314345359802,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.3324,
      "step": 186200
    },
    {
      "epoch": 7.575172301624413,
      "grad_norm": 0.4181429445743561,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3321,
      "step": 186300
    },
    {
      "epoch": 7.579238416654807,
      "grad_norm": 0.5087658762931824,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3316,
      "step": 186400
    },
    {
      "epoch": 7.583304531685202,
      "grad_norm": 0.4102417230606079,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.331,
      "step": 186500
    },
    {
      "epoch": 7.587370646715596,
      "grad_norm": 0.5109541416168213,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3317,
      "step": 186600
    },
    {
      "epoch": 7.59143676174599,
      "grad_norm": 0.4801971912384033,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.333,
      "step": 186700
    },
    {
      "epoch": 7.595502876776384,
      "grad_norm": 0.4955512583255768,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3319,
      "step": 186800
    },
    {
      "epoch": 7.599568991806779,
      "grad_norm": 0.4268876016139984,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.334,
      "step": 186900
    },
    {
      "epoch": 7.603635106837173,
      "grad_norm": 0.47311946749687195,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3319,
      "step": 187000
    },
    {
      "epoch": 7.607701221867567,
      "grad_norm": 0.48146435618400574,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3312,
      "step": 187100
    },
    {
      "epoch": 7.611767336897961,
      "grad_norm": 0.636208176612854,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.3328,
      "step": 187200
    },
    {
      "epoch": 7.615833451928355,
      "grad_norm": 0.4577831029891968,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.3321,
      "step": 187300
    },
    {
      "epoch": 7.6198995669587495,
      "grad_norm": 0.47258734703063965,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.333,
      "step": 187400
    },
    {
      "epoch": 7.6239656819891435,
      "grad_norm": 0.5881123542785645,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.3324,
      "step": 187500
    },
    {
      "epoch": 7.6280317970195375,
      "grad_norm": 0.4671884775161743,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.3316,
      "step": 187600
    },
    {
      "epoch": 7.632097912049932,
      "grad_norm": 0.5144911408424377,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3307,
      "step": 187700
    },
    {
      "epoch": 7.636164027080326,
      "grad_norm": 0.5172939300537109,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3333,
      "step": 187800
    },
    {
      "epoch": 7.64023014211072,
      "grad_norm": 0.4531945586204529,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3304,
      "step": 187900
    },
    {
      "epoch": 7.644296257141114,
      "grad_norm": 0.5248866677284241,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.3311,
      "step": 188000
    },
    {
      "epoch": 7.644296257141114,
      "eval_loss": 0.3462468683719635,
      "eval_runtime": 126.5812,
      "eval_samples_per_second": 1381.737,
      "eval_steps_per_second": 43.182,
      "step": 188000
    },
    {
      "epoch": 7.648362372171508,
      "grad_norm": 0.4590246379375458,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.33,
      "step": 188100
    },
    {
      "epoch": 7.652428487201903,
      "grad_norm": 0.4382169246673584,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3313,
      "step": 188200
    },
    {
      "epoch": 7.656494602232297,
      "grad_norm": 0.6626006364822388,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3316,
      "step": 188300
    },
    {
      "epoch": 7.660560717262691,
      "grad_norm": 0.4366711974143982,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3323,
      "step": 188400
    },
    {
      "epoch": 7.664626832293085,
      "grad_norm": 0.45100390911102295,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3345,
      "step": 188500
    },
    {
      "epoch": 7.66869294732348,
      "grad_norm": 0.4494059979915619,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.3322,
      "step": 188600
    },
    {
      "epoch": 7.672759062353874,
      "grad_norm": 0.5082388520240784,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3305,
      "step": 188700
    },
    {
      "epoch": 7.676825177384268,
      "grad_norm": 0.41733694076538086,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.3333,
      "step": 188800
    },
    {
      "epoch": 7.680891292414662,
      "grad_norm": 0.47463977336883545,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.3317,
      "step": 188900
    },
    {
      "epoch": 7.684957407445056,
      "grad_norm": 0.5445945858955383,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3316,
      "step": 189000
    },
    {
      "epoch": 7.689023522475451,
      "grad_norm": 0.5531354546546936,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.3322,
      "step": 189100
    },
    {
      "epoch": 7.693089637505845,
      "grad_norm": 0.42900651693344116,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.3306,
      "step": 189200
    },
    {
      "epoch": 7.697155752536239,
      "grad_norm": 0.6034865975379944,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.332,
      "step": 189300
    },
    {
      "epoch": 7.701221867566633,
      "grad_norm": 0.5286409258842468,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.3315,
      "step": 189400
    },
    {
      "epoch": 7.705287982597028,
      "grad_norm": 0.5540450215339661,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3314,
      "step": 189500
    },
    {
      "epoch": 7.709354097627422,
      "grad_norm": 0.4740401804447174,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.3331,
      "step": 189600
    },
    {
      "epoch": 7.713420212657816,
      "grad_norm": 0.5583798885345459,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3316,
      "step": 189700
    },
    {
      "epoch": 7.71748632768821,
      "grad_norm": 0.45346590876579285,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.3313,
      "step": 189800
    },
    {
      "epoch": 7.721552442718605,
      "grad_norm": 0.5558958053588867,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3342,
      "step": 189900
    },
    {
      "epoch": 7.725618557748999,
      "grad_norm": 0.4342009723186493,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.3323,
      "step": 190000
    },
    {
      "epoch": 7.725618557748999,
      "eval_loss": 0.3462274968624115,
      "eval_runtime": 126.9235,
      "eval_samples_per_second": 1378.011,
      "eval_steps_per_second": 43.065,
      "step": 190000
    },
    {
      "epoch": 7.729684672779393,
      "grad_norm": 0.6597604155540466,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3319,
      "step": 190100
    },
    {
      "epoch": 7.733750787809787,
      "grad_norm": 0.4546343982219696,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3322,
      "step": 190200
    },
    {
      "epoch": 7.737816902840182,
      "grad_norm": 0.39609581232070923,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.3327,
      "step": 190300
    },
    {
      "epoch": 7.741883017870576,
      "grad_norm": 0.5270168781280518,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.3304,
      "step": 190400
    },
    {
      "epoch": 7.74594913290097,
      "grad_norm": 0.49734577536582947,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3327,
      "step": 190500
    },
    {
      "epoch": 7.750015247931364,
      "grad_norm": 0.5849572420120239,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.3314,
      "step": 190600
    },
    {
      "epoch": 7.754081362961758,
      "grad_norm": 0.46701696515083313,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3295,
      "step": 190700
    },
    {
      "epoch": 7.758147477992153,
      "grad_norm": 0.47124120593070984,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3317,
      "step": 190800
    },
    {
      "epoch": 7.762213593022547,
      "grad_norm": 0.4398636519908905,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.333,
      "step": 190900
    },
    {
      "epoch": 7.766279708052941,
      "grad_norm": 0.49932828545570374,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3295,
      "step": 191000
    },
    {
      "epoch": 7.770345823083335,
      "grad_norm": 0.5860006213188171,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3314,
      "step": 191100
    },
    {
      "epoch": 7.7744119381137295,
      "grad_norm": 0.40752092003822327,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3315,
      "step": 191200
    },
    {
      "epoch": 7.7784780531441235,
      "grad_norm": 0.5317969918251038,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3314,
      "step": 191300
    },
    {
      "epoch": 7.7825441681745176,
      "grad_norm": 0.5587937235832214,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.3325,
      "step": 191400
    },
    {
      "epoch": 7.7866102832049116,
      "grad_norm": 0.4442189931869507,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3323,
      "step": 191500
    },
    {
      "epoch": 7.790676398235306,
      "grad_norm": 0.46967846155166626,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3316,
      "step": 191600
    },
    {
      "epoch": 7.7947425132657004,
      "grad_norm": 0.507827639579773,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3312,
      "step": 191700
    },
    {
      "epoch": 7.7988086282960944,
      "grad_norm": 0.43720656633377075,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.331,
      "step": 191800
    },
    {
      "epoch": 7.8028747433264884,
      "grad_norm": 0.5070227980613708,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3309,
      "step": 191900
    },
    {
      "epoch": 7.806940858356883,
      "grad_norm": 0.5541260838508606,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3311,
      "step": 192000
    },
    {
      "epoch": 7.806940858356883,
      "eval_loss": 0.34517157077789307,
      "eval_runtime": 125.744,
      "eval_samples_per_second": 1390.937,
      "eval_steps_per_second": 43.469,
      "step": 192000
    },
    {
      "epoch": 7.811006973387277,
      "grad_norm": 0.5910822749137878,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.3337,
      "step": 192100
    },
    {
      "epoch": 7.815073088417671,
      "grad_norm": 0.4532199800014496,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.3316,
      "step": 192200
    },
    {
      "epoch": 7.819139203448065,
      "grad_norm": 0.47960367798805237,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3305,
      "step": 192300
    },
    {
      "epoch": 7.823205318478459,
      "grad_norm": 0.6025828123092651,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.3301,
      "step": 192400
    },
    {
      "epoch": 7.827271433508854,
      "grad_norm": 0.4876158833503723,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.33,
      "step": 192500
    },
    {
      "epoch": 7.831337548539248,
      "grad_norm": 0.571192741394043,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.3324,
      "step": 192600
    },
    {
      "epoch": 7.835403663569642,
      "grad_norm": 0.5213424563407898,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3321,
      "step": 192700
    },
    {
      "epoch": 7.839469778600036,
      "grad_norm": 0.4651244282722473,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.3319,
      "step": 192800
    },
    {
      "epoch": 7.843535893630431,
      "grad_norm": 0.4871074855327606,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.33,
      "step": 192900
    },
    {
      "epoch": 7.847602008660825,
      "grad_norm": 0.489012211561203,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.33,
      "step": 193000
    },
    {
      "epoch": 7.851668123691219,
      "grad_norm": 0.4816596210002899,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.3319,
      "step": 193100
    },
    {
      "epoch": 7.855734238721613,
      "grad_norm": 0.44820472598075867,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3323,
      "step": 193200
    },
    {
      "epoch": 7.859800353752008,
      "grad_norm": 0.542067289352417,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.332,
      "step": 193300
    },
    {
      "epoch": 7.863866468782402,
      "grad_norm": 0.48133519291877747,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.3309,
      "step": 193400
    },
    {
      "epoch": 7.867932583812796,
      "grad_norm": 0.4645625948905945,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3323,
      "step": 193500
    },
    {
      "epoch": 7.87199869884319,
      "grad_norm": 0.4652060866355896,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3308,
      "step": 193600
    },
    {
      "epoch": 7.876064813873585,
      "grad_norm": 0.46806663274765015,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3302,
      "step": 193700
    },
    {
      "epoch": 7.880130928903979,
      "grad_norm": 0.5190942883491516,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3321,
      "step": 193800
    },
    {
      "epoch": 7.884197043934373,
      "grad_norm": 0.4715535044670105,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3307,
      "step": 193900
    },
    {
      "epoch": 7.888263158964767,
      "grad_norm": 0.4961152970790863,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3312,
      "step": 194000
    },
    {
      "epoch": 7.888263158964767,
      "eval_loss": 0.3448585569858551,
      "eval_runtime": 128.591,
      "eval_samples_per_second": 1360.141,
      "eval_steps_per_second": 42.507,
      "step": 194000
    },
    {
      "epoch": 7.892329273995161,
      "grad_norm": 0.4592021107673645,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3312,
      "step": 194100
    },
    {
      "epoch": 7.896395389025556,
      "grad_norm": 0.4602803587913513,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.3301,
      "step": 194200
    },
    {
      "epoch": 7.90046150405595,
      "grad_norm": 0.5940374732017517,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3287,
      "step": 194300
    },
    {
      "epoch": 7.904527619086344,
      "grad_norm": 0.4700523614883423,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3314,
      "step": 194400
    },
    {
      "epoch": 7.908593734116738,
      "grad_norm": 0.5163679122924805,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3315,
      "step": 194500
    },
    {
      "epoch": 7.912659849147133,
      "grad_norm": 0.5775622129440308,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.3314,
      "step": 194600
    },
    {
      "epoch": 7.916725964177527,
      "grad_norm": 0.6399346590042114,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.3298,
      "step": 194700
    },
    {
      "epoch": 7.920792079207921,
      "grad_norm": 0.5119985938072205,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3315,
      "step": 194800
    },
    {
      "epoch": 7.924858194238315,
      "grad_norm": 0.4690154790878296,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3315,
      "step": 194900
    },
    {
      "epoch": 7.928924309268709,
      "grad_norm": 0.5284074544906616,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.3334,
      "step": 195000
    },
    {
      "epoch": 7.932990424299104,
      "grad_norm": 0.4555432200431824,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.33,
      "step": 195100
    },
    {
      "epoch": 7.937056539329498,
      "grad_norm": 0.6650736927986145,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.3311,
      "step": 195200
    },
    {
      "epoch": 7.941122654359892,
      "grad_norm": 0.567901074886322,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.329,
      "step": 195300
    },
    {
      "epoch": 7.9451887693902865,
      "grad_norm": 0.4444621205329895,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3312,
      "step": 195400
    },
    {
      "epoch": 7.9492548844206805,
      "grad_norm": 0.5043330192565918,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3322,
      "step": 195500
    },
    {
      "epoch": 7.9533209994510745,
      "grad_norm": 0.49941346049308777,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.3324,
      "step": 195600
    },
    {
      "epoch": 7.9573871144814685,
      "grad_norm": 0.4855363965034485,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.3294,
      "step": 195700
    },
    {
      "epoch": 7.9614532295118625,
      "grad_norm": 0.453308641910553,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.3303,
      "step": 195800
    },
    {
      "epoch": 7.965519344542257,
      "grad_norm": 0.4859676957130432,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.3301,
      "step": 195900
    },
    {
      "epoch": 7.969585459572651,
      "grad_norm": 0.46750590205192566,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3327,
      "step": 196000
    },
    {
      "epoch": 7.969585459572651,
      "eval_loss": 0.34430283308029175,
      "eval_runtime": 125.3283,
      "eval_samples_per_second": 1395.551,
      "eval_steps_per_second": 43.613,
      "step": 196000
    },
    {
      "epoch": 7.973651574603045,
      "grad_norm": 0.4736436605453491,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.3305,
      "step": 196100
    },
    {
      "epoch": 7.977717689633439,
      "grad_norm": 0.639643669128418,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3308,
      "step": 196200
    },
    {
      "epoch": 7.981783804663834,
      "grad_norm": 0.5167898535728455,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3309,
      "step": 196300
    },
    {
      "epoch": 7.985849919694228,
      "grad_norm": 0.43838730454444885,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3304,
      "step": 196400
    },
    {
      "epoch": 7.989916034724622,
      "grad_norm": 0.5592992901802063,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3326,
      "step": 196500
    },
    {
      "epoch": 7.993982149755016,
      "grad_norm": 0.4644511044025421,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.3313,
      "step": 196600
    },
    {
      "epoch": 7.99804826478541,
      "grad_norm": 0.5043948888778687,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.3285,
      "step": 196700
    },
    {
      "epoch": 8.002114379815804,
      "grad_norm": 0.5822567939758301,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3271,
      "step": 196800
    },
    {
      "epoch": 8.006180494846198,
      "grad_norm": 0.641531229019165,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.322,
      "step": 196900
    },
    {
      "epoch": 8.010246609876594,
      "grad_norm": 0.5406733155250549,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3228,
      "step": 197000
    },
    {
      "epoch": 8.014312724906988,
      "grad_norm": 0.42348241806030273,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3214,
      "step": 197100
    },
    {
      "epoch": 8.018378839937382,
      "grad_norm": 0.5036606192588806,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.3215,
      "step": 197200
    },
    {
      "epoch": 8.022444954967776,
      "grad_norm": 0.5064002275466919,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.3239,
      "step": 197300
    },
    {
      "epoch": 8.02651106999817,
      "grad_norm": 0.4686577320098877,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.323,
      "step": 197400
    },
    {
      "epoch": 8.030577185028564,
      "grad_norm": 0.568243145942688,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3239,
      "step": 197500
    },
    {
      "epoch": 8.034643300058958,
      "grad_norm": 0.5022513270378113,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.3214,
      "step": 197600
    },
    {
      "epoch": 8.038709415089352,
      "grad_norm": 0.5242998003959656,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.3245,
      "step": 197700
    },
    {
      "epoch": 8.042775530119748,
      "grad_norm": 0.4825512766838074,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.3243,
      "step": 197800
    },
    {
      "epoch": 8.046841645150142,
      "grad_norm": 0.5277466773986816,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3235,
      "step": 197900
    },
    {
      "epoch": 8.050907760180536,
      "grad_norm": 0.6380377411842346,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3227,
      "step": 198000
    },
    {
      "epoch": 8.050907760180536,
      "eval_loss": 0.3451690077781677,
      "eval_runtime": 126.1113,
      "eval_samples_per_second": 1386.886,
      "eval_steps_per_second": 43.343,
      "step": 198000
    },
    {
      "epoch": 8.05497387521093,
      "grad_norm": 0.5876474976539612,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3237,
      "step": 198100
    },
    {
      "epoch": 8.059039990241324,
      "grad_norm": 0.5644955039024353,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3225,
      "step": 198200
    },
    {
      "epoch": 8.063106105271718,
      "grad_norm": 0.5695533752441406,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.3238,
      "step": 198300
    },
    {
      "epoch": 8.067172220302112,
      "grad_norm": 0.5954486727714539,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3227,
      "step": 198400
    },
    {
      "epoch": 8.071238335332506,
      "grad_norm": 0.5599672198295593,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.3234,
      "step": 198500
    },
    {
      "epoch": 8.0753044503629,
      "grad_norm": 0.5707370638847351,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3219,
      "step": 198600
    },
    {
      "epoch": 8.079370565393296,
      "grad_norm": 0.43125393986701965,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3232,
      "step": 198700
    },
    {
      "epoch": 8.08343668042369,
      "grad_norm": 0.48935750126838684,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3258,
      "step": 198800
    },
    {
      "epoch": 8.087502795454084,
      "grad_norm": 0.520723819732666,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.323,
      "step": 198900
    },
    {
      "epoch": 8.091568910484478,
      "grad_norm": 0.521416425704956,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3228,
      "step": 199000
    },
    {
      "epoch": 8.095635025514872,
      "grad_norm": 0.4989069104194641,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3249,
      "step": 199100
    },
    {
      "epoch": 8.099701140545266,
      "grad_norm": 0.4841274917125702,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.3251,
      "step": 199200
    },
    {
      "epoch": 8.10376725557566,
      "grad_norm": 0.5093021392822266,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.3236,
      "step": 199300
    },
    {
      "epoch": 8.107833370606054,
      "grad_norm": 0.6069021224975586,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3227,
      "step": 199400
    },
    {
      "epoch": 8.11189948563645,
      "grad_norm": 0.5160966515541077,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3246,
      "step": 199500
    },
    {
      "epoch": 8.115965600666843,
      "grad_norm": 0.523231565952301,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.324,
      "step": 199600
    },
    {
      "epoch": 8.120031715697237,
      "grad_norm": 0.5086828470230103,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3235,
      "step": 199700
    },
    {
      "epoch": 8.124097830727631,
      "grad_norm": 0.5468272566795349,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.322,
      "step": 199800
    },
    {
      "epoch": 8.128163945758025,
      "grad_norm": 0.5245776772499084,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3248,
      "step": 199900
    },
    {
      "epoch": 8.13223006078842,
      "grad_norm": 0.6044970154762268,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3248,
      "step": 200000
    },
    {
      "epoch": 8.13223006078842,
      "eval_loss": 0.34396877884864807,
      "eval_runtime": 128.1216,
      "eval_samples_per_second": 1365.125,
      "eval_steps_per_second": 42.663,
      "step": 200000
    },
    {
      "epoch": 8.136296175818813,
      "grad_norm": 0.5178048014640808,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.324,
      "step": 200100
    },
    {
      "epoch": 8.140362290849207,
      "grad_norm": 0.5259611010551453,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.3243,
      "step": 200200
    },
    {
      "epoch": 8.144428405879601,
      "grad_norm": 0.47101184725761414,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.3234,
      "step": 200300
    },
    {
      "epoch": 8.148494520909997,
      "grad_norm": 0.5707786083221436,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.3255,
      "step": 200400
    },
    {
      "epoch": 8.152560635940391,
      "grad_norm": 0.5621221661567688,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3248,
      "step": 200500
    },
    {
      "epoch": 8.156626750970785,
      "grad_norm": 0.4849633276462555,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3247,
      "step": 200600
    },
    {
      "epoch": 8.16069286600118,
      "grad_norm": 0.5613839030265808,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3227,
      "step": 200700
    },
    {
      "epoch": 8.164758981031573,
      "grad_norm": 0.6142703890800476,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.324,
      "step": 200800
    },
    {
      "epoch": 8.168825096061967,
      "grad_norm": 0.5359091758728027,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.3234,
      "step": 200900
    },
    {
      "epoch": 8.172891211092361,
      "grad_norm": 0.47567304968833923,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3247,
      "step": 201000
    },
    {
      "epoch": 8.176957326122755,
      "grad_norm": 0.6188470125198364,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3245,
      "step": 201100
    },
    {
      "epoch": 8.181023441153151,
      "grad_norm": 0.5705640316009521,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.3217,
      "step": 201200
    },
    {
      "epoch": 8.185089556183545,
      "grad_norm": 0.4886772930622101,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3241,
      "step": 201300
    },
    {
      "epoch": 8.189155671213939,
      "grad_norm": 0.5571561455726624,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3222,
      "step": 201400
    },
    {
      "epoch": 8.193221786244333,
      "grad_norm": 0.583153486251831,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.3259,
      "step": 201500
    },
    {
      "epoch": 8.197287901274727,
      "grad_norm": 0.5060574412345886,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.3245,
      "step": 201600
    },
    {
      "epoch": 8.201354016305121,
      "grad_norm": 0.6707000136375427,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3239,
      "step": 201700
    },
    {
      "epoch": 8.205420131335515,
      "grad_norm": 0.5122848153114319,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.3248,
      "step": 201800
    },
    {
      "epoch": 8.209486246365909,
      "grad_norm": 0.5722560882568359,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3243,
      "step": 201900
    },
    {
      "epoch": 8.213552361396303,
      "grad_norm": 0.5533431172370911,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3247,
      "step": 202000
    },
    {
      "epoch": 8.213552361396303,
      "eval_loss": 0.34366104006767273,
      "eval_runtime": 125.4946,
      "eval_samples_per_second": 1393.702,
      "eval_steps_per_second": 43.556,
      "step": 202000
    },
    {
      "epoch": 8.217618476426699,
      "grad_norm": 0.4557178318500519,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.3238,
      "step": 202100
    },
    {
      "epoch": 8.221684591457093,
      "grad_norm": 0.5459716320037842,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3242,
      "step": 202200
    },
    {
      "epoch": 8.225750706487487,
      "grad_norm": 0.5104228258132935,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.324,
      "step": 202300
    },
    {
      "epoch": 8.22981682151788,
      "grad_norm": 0.594293475151062,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.3245,
      "step": 202400
    },
    {
      "epoch": 8.233882936548275,
      "grad_norm": 0.5435747504234314,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3251,
      "step": 202500
    },
    {
      "epoch": 8.237949051578669,
      "grad_norm": 0.5290471911430359,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3237,
      "step": 202600
    },
    {
      "epoch": 8.242015166609063,
      "grad_norm": 0.5352329015731812,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.3248,
      "step": 202700
    },
    {
      "epoch": 8.246081281639457,
      "grad_norm": 0.569402813911438,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3243,
      "step": 202800
    },
    {
      "epoch": 8.250147396669853,
      "grad_norm": 0.466576486825943,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3255,
      "step": 202900
    },
    {
      "epoch": 8.254213511700247,
      "grad_norm": 0.5464662313461304,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3256,
      "step": 203000
    },
    {
      "epoch": 8.25827962673064,
      "grad_norm": 0.5842247009277344,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3235,
      "step": 203100
    },
    {
      "epoch": 8.262345741761035,
      "grad_norm": 0.5060074329376221,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.3234,
      "step": 203200
    },
    {
      "epoch": 8.266411856791429,
      "grad_norm": 0.6178668737411499,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3251,
      "step": 203300
    },
    {
      "epoch": 8.270477971821823,
      "grad_norm": 0.5778864026069641,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.3241,
      "step": 203400
    },
    {
      "epoch": 8.274544086852217,
      "grad_norm": 0.7964345216751099,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.3259,
      "step": 203500
    },
    {
      "epoch": 8.27861020188261,
      "grad_norm": 0.6177813410758972,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.3252,
      "step": 203600
    },
    {
      "epoch": 8.282676316913005,
      "grad_norm": 0.5554516911506653,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3229,
      "step": 203700
    },
    {
      "epoch": 8.2867424319434,
      "grad_norm": 0.5372982621192932,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.3241,
      "step": 203800
    },
    {
      "epoch": 8.290808546973794,
      "grad_norm": 0.539414644241333,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.3236,
      "step": 203900
    },
    {
      "epoch": 8.294874662004188,
      "grad_norm": 0.5653362274169922,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3235,
      "step": 204000
    },
    {
      "epoch": 8.294874662004188,
      "eval_loss": 0.3428196907043457,
      "eval_runtime": 127.4321,
      "eval_samples_per_second": 1372.512,
      "eval_steps_per_second": 42.893,
      "step": 204000
    },
    {
      "epoch": 8.298940777034582,
      "grad_norm": 0.5307513475418091,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.3243,
      "step": 204100
    },
    {
      "epoch": 8.303006892064976,
      "grad_norm": 0.5469528436660767,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.3243,
      "step": 204200
    },
    {
      "epoch": 8.30707300709537,
      "grad_norm": 0.5566498041152954,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.3246,
      "step": 204300
    },
    {
      "epoch": 8.311139122125764,
      "grad_norm": 0.6540603637695312,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3248,
      "step": 204400
    },
    {
      "epoch": 8.315205237156158,
      "grad_norm": 0.5005030632019043,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.3237,
      "step": 204500
    },
    {
      "epoch": 8.319271352186554,
      "grad_norm": 0.578934907913208,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.325,
      "step": 204600
    },
    {
      "epoch": 8.323337467216948,
      "grad_norm": 0.5697755217552185,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.3248,
      "step": 204700
    },
    {
      "epoch": 8.327403582247342,
      "grad_norm": 0.5692412257194519,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3236,
      "step": 204800
    },
    {
      "epoch": 8.331469697277736,
      "grad_norm": 0.5846623182296753,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.323,
      "step": 204900
    },
    {
      "epoch": 8.33553581230813,
      "grad_norm": 0.6183155179023743,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.3237,
      "step": 205000
    },
    {
      "epoch": 8.339601927338524,
      "grad_norm": 0.5004684925079346,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.3242,
      "step": 205100
    },
    {
      "epoch": 8.343668042368918,
      "grad_norm": 0.5323293209075928,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.3234,
      "step": 205200
    },
    {
      "epoch": 8.347734157399312,
      "grad_norm": 0.48270800709724426,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3244,
      "step": 205300
    },
    {
      "epoch": 8.351800272429706,
      "grad_norm": 0.4566842019557953,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3239,
      "step": 205400
    },
    {
      "epoch": 8.355866387460102,
      "grad_norm": 0.5198598504066467,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.324,
      "step": 205500
    },
    {
      "epoch": 8.359932502490496,
      "grad_norm": 0.5649455189704895,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3246,
      "step": 205600
    },
    {
      "epoch": 8.36399861752089,
      "grad_norm": 0.6073098182678223,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3244,
      "step": 205700
    },
    {
      "epoch": 8.368064732551284,
      "grad_norm": 0.5416106581687927,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3248,
      "step": 205800
    },
    {
      "epoch": 8.372130847581678,
      "grad_norm": 0.49781450629234314,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3245,
      "step": 205900
    },
    {
      "epoch": 8.376196962612072,
      "grad_norm": 0.5273549556732178,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3247,
      "step": 206000
    },
    {
      "epoch": 8.376196962612072,
      "eval_loss": 0.34268808364868164,
      "eval_runtime": 126.8347,
      "eval_samples_per_second": 1378.976,
      "eval_steps_per_second": 43.095,
      "step": 206000
    },
    {
      "epoch": 8.380263077642466,
      "grad_norm": 0.527258038520813,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3244,
      "step": 206100
    },
    {
      "epoch": 8.38432919267286,
      "grad_norm": 0.609766960144043,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.3251,
      "step": 206200
    },
    {
      "epoch": 8.388395307703256,
      "grad_norm": 0.5644694566726685,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.3246,
      "step": 206300
    },
    {
      "epoch": 8.39246142273365,
      "grad_norm": 0.5624386668205261,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.327,
      "step": 206400
    },
    {
      "epoch": 8.396527537764044,
      "grad_norm": 0.619145393371582,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3241,
      "step": 206500
    },
    {
      "epoch": 8.400593652794438,
      "grad_norm": 0.6240390539169312,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.3236,
      "step": 206600
    },
    {
      "epoch": 8.404659767824832,
      "grad_norm": 0.6219667792320251,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.3255,
      "step": 206700
    },
    {
      "epoch": 8.408725882855226,
      "grad_norm": 0.5517598390579224,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.3242,
      "step": 206800
    },
    {
      "epoch": 8.41279199788562,
      "grad_norm": 0.5547332763671875,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.3242,
      "step": 206900
    },
    {
      "epoch": 8.416858112916014,
      "grad_norm": 0.5892611742019653,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3242,
      "step": 207000
    },
    {
      "epoch": 8.420924227946408,
      "grad_norm": 0.6412767767906189,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3214,
      "step": 207100
    },
    {
      "epoch": 8.424990342976804,
      "grad_norm": 0.545403003692627,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3235,
      "step": 207200
    },
    {
      "epoch": 8.429056458007198,
      "grad_norm": 0.5961134433746338,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3242,
      "step": 207300
    },
    {
      "epoch": 8.433122573037592,
      "grad_norm": 0.5459085702896118,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3238,
      "step": 207400
    },
    {
      "epoch": 8.437188688067986,
      "grad_norm": 0.5178672671318054,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3243,
      "step": 207500
    },
    {
      "epoch": 8.44125480309838,
      "grad_norm": 0.6128677129745483,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3225,
      "step": 207600
    },
    {
      "epoch": 8.445320918128774,
      "grad_norm": 0.6664710640907288,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3238,
      "step": 207700
    },
    {
      "epoch": 8.449387033159168,
      "grad_norm": 0.5611929893493652,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3211,
      "step": 207800
    },
    {
      "epoch": 8.453453148189562,
      "grad_norm": 0.6343796253204346,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3228,
      "step": 207900
    },
    {
      "epoch": 8.457519263219957,
      "grad_norm": 0.5521082282066345,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.3244,
      "step": 208000
    },
    {
      "epoch": 8.457519263219957,
      "eval_loss": 0.3417506515979767,
      "eval_runtime": 126.0138,
      "eval_samples_per_second": 1387.959,
      "eval_steps_per_second": 43.376,
      "step": 208000
    },
    {
      "epoch": 8.461585378250351,
      "grad_norm": 0.5382850170135498,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.3228,
      "step": 208100
    },
    {
      "epoch": 8.465651493280745,
      "grad_norm": 0.5329755544662476,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.3242,
      "step": 208200
    },
    {
      "epoch": 8.46971760831114,
      "grad_norm": 0.6382584571838379,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.3221,
      "step": 208300
    },
    {
      "epoch": 8.473783723341533,
      "grad_norm": 0.6040070056915283,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3244,
      "step": 208400
    },
    {
      "epoch": 8.477849838371927,
      "grad_norm": 0.6018317937850952,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.324,
      "step": 208500
    },
    {
      "epoch": 8.481915953402321,
      "grad_norm": 0.5356768369674683,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.3237,
      "step": 208600
    },
    {
      "epoch": 8.485982068432715,
      "grad_norm": 0.5347893834114075,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3234,
      "step": 208700
    },
    {
      "epoch": 8.49004818346311,
      "grad_norm": 0.5829744338989258,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.323,
      "step": 208800
    },
    {
      "epoch": 8.494114298493505,
      "grad_norm": 0.556185245513916,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.323,
      "step": 208900
    },
    {
      "epoch": 8.4981804135239,
      "grad_norm": 0.5341342687606812,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3214,
      "step": 209000
    },
    {
      "epoch": 8.502246528554293,
      "grad_norm": 0.6152887344360352,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.3229,
      "step": 209100
    },
    {
      "epoch": 8.506312643584687,
      "grad_norm": 0.5906060338020325,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.3249,
      "step": 209200
    },
    {
      "epoch": 8.510378758615081,
      "grad_norm": 0.6109989881515503,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.3239,
      "step": 209300
    },
    {
      "epoch": 8.514444873645475,
      "grad_norm": 0.6185218691825867,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.323,
      "step": 209400
    },
    {
      "epoch": 8.51851098867587,
      "grad_norm": 0.5958829522132874,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.3253,
      "step": 209500
    },
    {
      "epoch": 8.522577103706263,
      "grad_norm": 0.5146898031234741,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.3218,
      "step": 209600
    },
    {
      "epoch": 8.526643218736659,
      "grad_norm": 0.5494814515113831,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.3231,
      "step": 209700
    },
    {
      "epoch": 8.530709333767053,
      "grad_norm": 0.6782405972480774,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.3231,
      "step": 209800
    },
    {
      "epoch": 8.534775448797447,
      "grad_norm": 0.7223724722862244,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3229,
      "step": 209900
    },
    {
      "epoch": 8.538841563827841,
      "grad_norm": 0.5957633852958679,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3249,
      "step": 210000
    },
    {
      "epoch": 8.538841563827841,
      "eval_loss": 0.34115472435951233,
      "eval_runtime": 126.6421,
      "eval_samples_per_second": 1381.073,
      "eval_steps_per_second": 43.161,
      "step": 210000
    },
    {
      "epoch": 8.542907678858235,
      "grad_norm": 0.6801558136940002,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.3246,
      "step": 210100
    },
    {
      "epoch": 8.546973793888629,
      "grad_norm": 0.5560184717178345,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.3252,
      "step": 210200
    },
    {
      "epoch": 8.551039908919023,
      "grad_norm": 0.6229144334793091,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.324,
      "step": 210300
    },
    {
      "epoch": 8.555106023949417,
      "grad_norm": 0.6415653228759766,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3251,
      "step": 210400
    },
    {
      "epoch": 8.559172138979811,
      "grad_norm": 0.5345995426177979,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3231,
      "step": 210500
    },
    {
      "epoch": 8.563238254010207,
      "grad_norm": 0.5824216604232788,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.324,
      "step": 210600
    },
    {
      "epoch": 8.5673043690406,
      "grad_norm": 0.5989851951599121,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3242,
      "step": 210700
    },
    {
      "epoch": 8.571370484070995,
      "grad_norm": 0.46769317984580994,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.3236,
      "step": 210800
    },
    {
      "epoch": 8.575436599101389,
      "grad_norm": 0.5656070709228516,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3239,
      "step": 210900
    },
    {
      "epoch": 8.579502714131783,
      "grad_norm": 0.5156319737434387,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.3249,
      "step": 211000
    },
    {
      "epoch": 8.583568829162177,
      "grad_norm": 0.49767637252807617,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3241,
      "step": 211100
    },
    {
      "epoch": 8.58763494419257,
      "grad_norm": 0.5974124073982239,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3216,
      "step": 211200
    },
    {
      "epoch": 8.591701059222965,
      "grad_norm": 0.5004975199699402,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3231,
      "step": 211300
    },
    {
      "epoch": 8.59576717425336,
      "grad_norm": 0.5652007460594177,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3242,
      "step": 211400
    },
    {
      "epoch": 8.599833289283755,
      "grad_norm": 0.5291633009910583,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3242,
      "step": 211500
    },
    {
      "epoch": 8.603899404314149,
      "grad_norm": 0.5380128622055054,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.3244,
      "step": 211600
    },
    {
      "epoch": 8.607965519344543,
      "grad_norm": 0.5995064377784729,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.324,
      "step": 211700
    },
    {
      "epoch": 8.612031634374937,
      "grad_norm": 0.5273142457008362,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3223,
      "step": 211800
    },
    {
      "epoch": 8.61609774940533,
      "grad_norm": 0.6042127013206482,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.322,
      "step": 211900
    },
    {
      "epoch": 8.620163864435725,
      "grad_norm": 0.5622503161430359,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3216,
      "step": 212000
    },
    {
      "epoch": 8.620163864435725,
      "eval_loss": 0.34058037400245667,
      "eval_runtime": 125.8032,
      "eval_samples_per_second": 1390.282,
      "eval_steps_per_second": 43.449,
      "step": 212000
    },
    {
      "epoch": 8.624229979466119,
      "grad_norm": 0.5361829996109009,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3242,
      "step": 212100
    },
    {
      "epoch": 8.628296094496513,
      "grad_norm": 0.478762686252594,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.3212,
      "step": 212200
    },
    {
      "epoch": 8.632362209526907,
      "grad_norm": 0.5697663426399231,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3228,
      "step": 212300
    },
    {
      "epoch": 8.636428324557302,
      "grad_norm": 0.5312871336936951,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.3238,
      "step": 212400
    },
    {
      "epoch": 8.640494439587696,
      "grad_norm": 0.6259726285934448,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3251,
      "step": 212500
    },
    {
      "epoch": 8.64456055461809,
      "grad_norm": 0.5901640057563782,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.3224,
      "step": 212600
    },
    {
      "epoch": 8.648626669648484,
      "grad_norm": 0.5484728217124939,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3231,
      "step": 212700
    },
    {
      "epoch": 8.652692784678878,
      "grad_norm": 0.5950224995613098,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.3237,
      "step": 212800
    },
    {
      "epoch": 8.656758899709272,
      "grad_norm": 0.6714872717857361,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3232,
      "step": 212900
    },
    {
      "epoch": 8.660825014739666,
      "grad_norm": 0.5379495620727539,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.3219,
      "step": 213000
    },
    {
      "epoch": 8.66489112977006,
      "grad_norm": 0.6839836239814758,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3204,
      "step": 213100
    },
    {
      "epoch": 8.668957244800456,
      "grad_norm": 0.5571141242980957,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.3225,
      "step": 213200
    },
    {
      "epoch": 8.67302335983085,
      "grad_norm": 0.6249983310699463,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.3215,
      "step": 213300
    },
    {
      "epoch": 8.677089474861244,
      "grad_norm": 0.5314676761627197,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.3222,
      "step": 213400
    },
    {
      "epoch": 8.681155589891638,
      "grad_norm": 0.6459506750106812,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3226,
      "step": 213500
    },
    {
      "epoch": 8.685221704922032,
      "grad_norm": 0.6642819046974182,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3251,
      "step": 213600
    },
    {
      "epoch": 8.689287819952426,
      "grad_norm": 0.5171932578086853,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3206,
      "step": 213700
    },
    {
      "epoch": 8.69335393498282,
      "grad_norm": 0.5894872546195984,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3216,
      "step": 213800
    },
    {
      "epoch": 8.697420050013214,
      "grad_norm": 0.6245993971824646,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.3233,
      "step": 213900
    },
    {
      "epoch": 8.701486165043608,
      "grad_norm": 0.5955812335014343,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.3224,
      "step": 214000
    },
    {
      "epoch": 8.701486165043608,
      "eval_loss": 0.3398797810077667,
      "eval_runtime": 127.4336,
      "eval_samples_per_second": 1372.495,
      "eval_steps_per_second": 42.893,
      "step": 214000
    },
    {
      "epoch": 8.705552280074004,
      "grad_norm": 0.5399561524391174,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.3211,
      "step": 214100
    },
    {
      "epoch": 8.709618395104398,
      "grad_norm": 0.6059597134590149,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.3223,
      "step": 214200
    },
    {
      "epoch": 8.713684510134792,
      "grad_norm": 0.5329326391220093,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.3222,
      "step": 214300
    },
    {
      "epoch": 8.717750625165186,
      "grad_norm": 0.5856539011001587,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3227,
      "step": 214400
    },
    {
      "epoch": 8.72181674019558,
      "grad_norm": 0.696933925151825,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3214,
      "step": 214500
    },
    {
      "epoch": 8.725882855225974,
      "grad_norm": 0.6321088671684265,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.3227,
      "step": 214600
    },
    {
      "epoch": 8.729948970256368,
      "grad_norm": 0.5977274775505066,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.3212,
      "step": 214700
    },
    {
      "epoch": 8.734015085286762,
      "grad_norm": 0.5542429089546204,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3233,
      "step": 214800
    },
    {
      "epoch": 8.738081200317158,
      "grad_norm": 0.5660668015480042,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.3235,
      "step": 214900
    },
    {
      "epoch": 8.742147315347552,
      "grad_norm": 0.6832004189491272,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3231,
      "step": 215000
    },
    {
      "epoch": 8.746213430377946,
      "grad_norm": 0.6087320446968079,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.3233,
      "step": 215100
    },
    {
      "epoch": 8.75027954540834,
      "grad_norm": 0.5402226448059082,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.3254,
      "step": 215200
    },
    {
      "epoch": 8.754345660438734,
      "grad_norm": 0.6681393384933472,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3212,
      "step": 215300
    },
    {
      "epoch": 8.758411775469128,
      "grad_norm": 0.5722990036010742,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.323,
      "step": 215400
    },
    {
      "epoch": 8.762477890499522,
      "grad_norm": 0.5887874960899353,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3211,
      "step": 215500
    },
    {
      "epoch": 8.766544005529916,
      "grad_norm": 0.5611005425453186,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.3229,
      "step": 215600
    },
    {
      "epoch": 8.77061012056031,
      "grad_norm": 0.6432892680168152,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3216,
      "step": 215700
    },
    {
      "epoch": 8.774676235590706,
      "grad_norm": 0.6246300339698792,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3228,
      "step": 215800
    },
    {
      "epoch": 8.7787423506211,
      "grad_norm": 0.6527633666992188,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.3222,
      "step": 215900
    },
    {
      "epoch": 8.782808465651494,
      "grad_norm": 0.6238188743591309,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.3221,
      "step": 216000
    },
    {
      "epoch": 8.782808465651494,
      "eval_loss": 0.3395262658596039,
      "eval_runtime": 127.7523,
      "eval_samples_per_second": 1369.072,
      "eval_steps_per_second": 42.786,
      "step": 216000
    },
    {
      "epoch": 8.786874580681888,
      "grad_norm": 0.5540657639503479,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3219,
      "step": 216100
    },
    {
      "epoch": 8.790940695712282,
      "grad_norm": 0.5367757678031921,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.3221,
      "step": 216200
    },
    {
      "epoch": 8.795006810742676,
      "grad_norm": 0.6013498902320862,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.3218,
      "step": 216300
    },
    {
      "epoch": 8.79907292577307,
      "grad_norm": 0.6808306574821472,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.3208,
      "step": 216400
    },
    {
      "epoch": 8.803139040803464,
      "grad_norm": 0.7188367247581482,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.3232,
      "step": 216500
    },
    {
      "epoch": 8.80720515583386,
      "grad_norm": 0.5679463744163513,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3212,
      "step": 216600
    },
    {
      "epoch": 8.811271270864253,
      "grad_norm": 0.6919251680374146,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.323,
      "step": 216700
    },
    {
      "epoch": 8.815337385894647,
      "grad_norm": 0.5843642950057983,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.3204,
      "step": 216800
    },
    {
      "epoch": 8.819403500925041,
      "grad_norm": 0.5630501508712769,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3228,
      "step": 216900
    },
    {
      "epoch": 8.823469615955435,
      "grad_norm": 0.5527361631393433,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.3233,
      "step": 217000
    },
    {
      "epoch": 8.82753573098583,
      "grad_norm": 0.564268171787262,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3222,
      "step": 217100
    },
    {
      "epoch": 8.831601846016223,
      "grad_norm": 0.6059924364089966,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.3215,
      "step": 217200
    },
    {
      "epoch": 8.835667961046617,
      "grad_norm": 0.5387047529220581,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3219,
      "step": 217300
    },
    {
      "epoch": 8.839734076077011,
      "grad_norm": 0.7388405799865723,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.323,
      "step": 217400
    },
    {
      "epoch": 8.843800191107407,
      "grad_norm": 0.5594924688339233,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3213,
      "step": 217500
    },
    {
      "epoch": 8.847866306137801,
      "grad_norm": 0.5982438921928406,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3211,
      "step": 217600
    },
    {
      "epoch": 8.851932421168195,
      "grad_norm": 0.5701343417167664,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3224,
      "step": 217700
    },
    {
      "epoch": 8.85599853619859,
      "grad_norm": 0.5518773794174194,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.321,
      "step": 217800
    },
    {
      "epoch": 8.860064651228983,
      "grad_norm": 0.6396717429161072,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3216,
      "step": 217900
    },
    {
      "epoch": 8.864130766259377,
      "grad_norm": 0.6561087965965271,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3223,
      "step": 218000
    },
    {
      "epoch": 8.864130766259377,
      "eval_loss": 0.3388533294200897,
      "eval_runtime": 125.883,
      "eval_samples_per_second": 1389.401,
      "eval_steps_per_second": 43.421,
      "step": 218000
    },
    {
      "epoch": 8.868196881289771,
      "grad_norm": 0.6543994545936584,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.3208,
      "step": 218100
    },
    {
      "epoch": 8.872262996320165,
      "grad_norm": 0.6275655627250671,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.3215,
      "step": 218200
    },
    {
      "epoch": 8.876329111350561,
      "grad_norm": 0.5783289074897766,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3224,
      "step": 218300
    },
    {
      "epoch": 8.880395226380955,
      "grad_norm": 0.6332113146781921,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3225,
      "step": 218400
    },
    {
      "epoch": 8.884461341411349,
      "grad_norm": 0.531283974647522,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.3216,
      "step": 218500
    },
    {
      "epoch": 8.888527456441743,
      "grad_norm": 0.7670062780380249,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3219,
      "step": 218600
    },
    {
      "epoch": 8.892593571472137,
      "grad_norm": 0.6178614497184753,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3212,
      "step": 218700
    },
    {
      "epoch": 8.896659686502531,
      "grad_norm": 0.7249001264572144,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3215,
      "step": 218800
    },
    {
      "epoch": 8.900725801532925,
      "grad_norm": 0.6684519052505493,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3197,
      "step": 218900
    },
    {
      "epoch": 8.904791916563319,
      "grad_norm": 0.5629486441612244,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3209,
      "step": 219000
    },
    {
      "epoch": 8.908858031593713,
      "grad_norm": 0.6330548524856567,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3213,
      "step": 219100
    },
    {
      "epoch": 8.912924146624109,
      "grad_norm": 0.6742314696311951,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3213,
      "step": 219200
    },
    {
      "epoch": 8.916990261654503,
      "grad_norm": 0.6169654726982117,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3228,
      "step": 219300
    },
    {
      "epoch": 8.921056376684897,
      "grad_norm": 0.6627618670463562,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3198,
      "step": 219400
    },
    {
      "epoch": 8.92512249171529,
      "grad_norm": 0.6539700031280518,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3214,
      "step": 219500
    },
    {
      "epoch": 8.929188606745685,
      "grad_norm": 0.6527523398399353,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.3209,
      "step": 219600
    },
    {
      "epoch": 8.933254721776079,
      "grad_norm": 0.5931774973869324,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.3209,
      "step": 219700
    },
    {
      "epoch": 8.937320836806473,
      "grad_norm": 0.5869200229644775,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.3214,
      "step": 219800
    },
    {
      "epoch": 8.941386951836867,
      "grad_norm": 0.5857251882553101,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.3224,
      "step": 219900
    },
    {
      "epoch": 8.945453066867262,
      "grad_norm": 0.7319660186767578,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.3215,
      "step": 220000
    },
    {
      "epoch": 8.945453066867262,
      "eval_loss": 0.3381964862346649,
      "eval_runtime": 126.4522,
      "eval_samples_per_second": 1383.148,
      "eval_steps_per_second": 43.226,
      "step": 220000
    },
    {
      "epoch": 8.949519181897656,
      "grad_norm": 0.5513892769813538,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3222,
      "step": 220100
    },
    {
      "epoch": 8.95358529692805,
      "grad_norm": 0.5955435633659363,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.3209,
      "step": 220200
    },
    {
      "epoch": 8.957651411958444,
      "grad_norm": 0.6521206498146057,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.3214,
      "step": 220300
    },
    {
      "epoch": 8.961717526988839,
      "grad_norm": 0.6858500242233276,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.3196,
      "step": 220400
    },
    {
      "epoch": 8.965783642019233,
      "grad_norm": 0.561057984828949,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.321,
      "step": 220500
    },
    {
      "epoch": 8.969849757049627,
      "grad_norm": 0.7764973640441895,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.3215,
      "step": 220600
    },
    {
      "epoch": 8.97391587208002,
      "grad_norm": 0.7101963758468628,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.3209,
      "step": 220700
    },
    {
      "epoch": 8.977981987110415,
      "grad_norm": 0.5678384304046631,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.3206,
      "step": 220800
    },
    {
      "epoch": 8.98204810214081,
      "grad_norm": 0.6303395628929138,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3217,
      "step": 220900
    },
    {
      "epoch": 8.986114217171204,
      "grad_norm": 0.5733339786529541,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.32,
      "step": 221000
    },
    {
      "epoch": 8.990180332201598,
      "grad_norm": 0.5003960728645325,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.3209,
      "step": 221100
    },
    {
      "epoch": 8.994246447231992,
      "grad_norm": 0.5593886375427246,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3234,
      "step": 221200
    },
    {
      "epoch": 8.998312562262386,
      "grad_norm": 0.5741485953330994,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.3207,
      "step": 221300
    },
    {
      "epoch": 9.00237867729278,
      "grad_norm": 0.5194848775863647,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3154,
      "step": 221400
    },
    {
      "epoch": 9.006444792323174,
      "grad_norm": 0.6671139597892761,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.314,
      "step": 221500
    },
    {
      "epoch": 9.010510907353568,
      "grad_norm": 0.6566741466522217,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3127,
      "step": 221600
    },
    {
      "epoch": 9.014577022383964,
      "grad_norm": 0.7316412925720215,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3115,
      "step": 221700
    },
    {
      "epoch": 9.018643137414358,
      "grad_norm": 0.5799965858459473,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.312,
      "step": 221800
    },
    {
      "epoch": 9.022709252444752,
      "grad_norm": 0.6325200796127319,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.3119,
      "step": 221900
    },
    {
      "epoch": 9.026775367475146,
      "grad_norm": 0.605353057384491,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3131,
      "step": 222000
    },
    {
      "epoch": 9.026775367475146,
      "eval_loss": 0.33867397904396057,
      "eval_runtime": 128.3929,
      "eval_samples_per_second": 1362.24,
      "eval_steps_per_second": 42.572,
      "step": 222000
    },
    {
      "epoch": 9.03084148250554,
      "grad_norm": 0.7171403169631958,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3132,
      "step": 222100
    },
    {
      "epoch": 9.034907597535934,
      "grad_norm": 0.6744815111160278,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.3132,
      "step": 222200
    },
    {
      "epoch": 9.038973712566328,
      "grad_norm": 0.5967521071434021,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3132,
      "step": 222300
    },
    {
      "epoch": 9.043039827596722,
      "grad_norm": 0.6541027426719666,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3129,
      "step": 222400
    },
    {
      "epoch": 9.047105942627116,
      "grad_norm": 0.6784618496894836,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.312,
      "step": 222500
    },
    {
      "epoch": 9.051172057657512,
      "grad_norm": 0.652037501335144,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.3122,
      "step": 222600
    },
    {
      "epoch": 9.055238172687906,
      "grad_norm": 0.6841039657592773,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.3122,
      "step": 222700
    },
    {
      "epoch": 9.0593042877183,
      "grad_norm": 0.578379213809967,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.3113,
      "step": 222800
    },
    {
      "epoch": 9.063370402748694,
      "grad_norm": 0.6022517085075378,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3123,
      "step": 222900
    },
    {
      "epoch": 9.067436517779088,
      "grad_norm": 0.6625966429710388,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.3116,
      "step": 223000
    },
    {
      "epoch": 9.071502632809482,
      "grad_norm": 0.5856952667236328,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.3132,
      "step": 223100
    },
    {
      "epoch": 9.075568747839876,
      "grad_norm": 0.6343462467193604,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3117,
      "step": 223200
    },
    {
      "epoch": 9.07963486287027,
      "grad_norm": 0.6197865009307861,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.3112,
      "step": 223300
    },
    {
      "epoch": 9.083700977900666,
      "grad_norm": 0.6574509143829346,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.3117,
      "step": 223400
    },
    {
      "epoch": 9.08776709293106,
      "grad_norm": 0.5810283422470093,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3138,
      "step": 223500
    },
    {
      "epoch": 9.091833207961454,
      "grad_norm": 0.6590033173561096,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.3138,
      "step": 223600
    },
    {
      "epoch": 9.095899322991848,
      "grad_norm": 0.6863391995429993,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.3137,
      "step": 223700
    },
    {
      "epoch": 9.099965438022242,
      "grad_norm": 0.7050468325614929,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3127,
      "step": 223800
    },
    {
      "epoch": 9.104031553052636,
      "grad_norm": 0.6213735938072205,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.3132,
      "step": 223900
    },
    {
      "epoch": 9.10809766808303,
      "grad_norm": 0.6798698306083679,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.3108,
      "step": 224000
    },
    {
      "epoch": 9.10809766808303,
      "eval_loss": 0.33870819211006165,
      "eval_runtime": 125.8605,
      "eval_samples_per_second": 1389.649,
      "eval_steps_per_second": 43.429,
      "step": 224000
    },
    {
      "epoch": 9.112163783113424,
      "grad_norm": 0.6476595997810364,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.3145,
      "step": 224100
    },
    {
      "epoch": 9.116229898143818,
      "grad_norm": 0.7235168814659119,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.3121,
      "step": 224200
    },
    {
      "epoch": 9.120296013174213,
      "grad_norm": 0.7136971950531006,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.313,
      "step": 224300
    },
    {
      "epoch": 9.124362128204607,
      "grad_norm": 0.6491169929504395,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.315,
      "step": 224400
    },
    {
      "epoch": 9.128428243235001,
      "grad_norm": 0.6262320876121521,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3113,
      "step": 224500
    },
    {
      "epoch": 9.132494358265395,
      "grad_norm": 0.7220957279205322,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3123,
      "step": 224600
    },
    {
      "epoch": 9.13656047329579,
      "grad_norm": 0.6768286228179932,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3143,
      "step": 224700
    },
    {
      "epoch": 9.140626588326183,
      "grad_norm": 0.6088793873786926,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3128,
      "step": 224800
    },
    {
      "epoch": 9.144692703356577,
      "grad_norm": 0.6730578541755676,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3123,
      "step": 224900
    },
    {
      "epoch": 9.148758818386971,
      "grad_norm": 0.6418388485908508,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3133,
      "step": 225000
    },
    {
      "epoch": 9.152824933417367,
      "grad_norm": 0.6158279180526733,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3117,
      "step": 225100
    },
    {
      "epoch": 9.156891048447761,
      "grad_norm": 0.6672478914260864,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.314,
      "step": 225200
    },
    {
      "epoch": 9.160957163478155,
      "grad_norm": 0.6527340412139893,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.3127,
      "step": 225300
    },
    {
      "epoch": 9.16502327850855,
      "grad_norm": 0.8573760390281677,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3139,
      "step": 225400
    },
    {
      "epoch": 9.169089393538943,
      "grad_norm": 0.6944387555122375,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3126,
      "step": 225500
    },
    {
      "epoch": 9.173155508569337,
      "grad_norm": 0.682960033416748,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3133,
      "step": 225600
    },
    {
      "epoch": 9.177221623599731,
      "grad_norm": 0.6655485033988953,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.3127,
      "step": 225700
    },
    {
      "epoch": 9.181287738630125,
      "grad_norm": 0.9175841212272644,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3131,
      "step": 225800
    },
    {
      "epoch": 9.18535385366052,
      "grad_norm": 0.6473498940467834,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3119,
      "step": 225900
    },
    {
      "epoch": 9.189419968690915,
      "grad_norm": 0.566412627696991,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3127,
      "step": 226000
    },
    {
      "epoch": 9.189419968690915,
      "eval_loss": 0.3379881680011749,
      "eval_runtime": 126.3629,
      "eval_samples_per_second": 1384.125,
      "eval_steps_per_second": 43.256,
      "step": 226000
    },
    {
      "epoch": 9.193486083721309,
      "grad_norm": 0.6871739029884338,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.3135,
      "step": 226100
    },
    {
      "epoch": 9.197552198751703,
      "grad_norm": 0.6163727641105652,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3119,
      "step": 226200
    },
    {
      "epoch": 9.201618313782097,
      "grad_norm": 0.7290396094322205,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3134,
      "step": 226300
    },
    {
      "epoch": 9.205684428812491,
      "grad_norm": 0.7043532729148865,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3132,
      "step": 226400
    },
    {
      "epoch": 9.209750543842885,
      "grad_norm": 0.6592450141906738,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.3137,
      "step": 226500
    },
    {
      "epoch": 9.213816658873279,
      "grad_norm": 0.7036969065666199,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.3136,
      "step": 226600
    },
    {
      "epoch": 9.217882773903673,
      "grad_norm": 0.6806657314300537,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3136,
      "step": 226700
    },
    {
      "epoch": 9.221948888934069,
      "grad_norm": 0.7059999704360962,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3132,
      "step": 226800
    },
    {
      "epoch": 9.226015003964463,
      "grad_norm": 0.6886582374572754,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3117,
      "step": 226900
    },
    {
      "epoch": 9.230081118994857,
      "grad_norm": 0.6659629940986633,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3127,
      "step": 227000
    },
    {
      "epoch": 9.23414723402525,
      "grad_norm": 0.7362250685691833,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3131,
      "step": 227100
    },
    {
      "epoch": 9.238213349055645,
      "grad_norm": 0.6638413667678833,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.3116,
      "step": 227200
    },
    {
      "epoch": 9.242279464086039,
      "grad_norm": 0.7067233324050903,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3123,
      "step": 227300
    },
    {
      "epoch": 9.246345579116433,
      "grad_norm": 0.8392395973205566,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3119,
      "step": 227400
    },
    {
      "epoch": 9.250411694146827,
      "grad_norm": 0.7493293285369873,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3109,
      "step": 227500
    },
    {
      "epoch": 9.25447780917722,
      "grad_norm": 0.705531895160675,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3108,
      "step": 227600
    },
    {
      "epoch": 9.258543924207617,
      "grad_norm": 0.7012618184089661,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.3112,
      "step": 227700
    },
    {
      "epoch": 9.26261003923801,
      "grad_norm": 0.6067794561386108,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.3124,
      "step": 227800
    },
    {
      "epoch": 9.266676154268405,
      "grad_norm": 0.6757289171218872,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.3127,
      "step": 227900
    },
    {
      "epoch": 9.270742269298799,
      "grad_norm": 0.6779981255531311,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3118,
      "step": 228000
    },
    {
      "epoch": 9.270742269298799,
      "eval_loss": 0.3371310830116272,
      "eval_runtime": 127.6774,
      "eval_samples_per_second": 1369.875,
      "eval_steps_per_second": 42.811,
      "step": 228000
    },
    {
      "epoch": 9.274808384329193,
      "grad_norm": 0.6411961317062378,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.3118,
      "step": 228100
    },
    {
      "epoch": 9.278874499359587,
      "grad_norm": 0.8061448931694031,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.311,
      "step": 228200
    },
    {
      "epoch": 9.28294061438998,
      "grad_norm": 0.6919344067573547,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3127,
      "step": 228300
    },
    {
      "epoch": 9.287006729420375,
      "grad_norm": 0.6530212163925171,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3124,
      "step": 228400
    },
    {
      "epoch": 9.29107284445077,
      "grad_norm": 0.7106884717941284,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3136,
      "step": 228500
    },
    {
      "epoch": 9.295138959481164,
      "grad_norm": 0.7470311522483826,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.314,
      "step": 228600
    },
    {
      "epoch": 9.299205074511558,
      "grad_norm": 0.6259472370147705,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.3119,
      "step": 228700
    },
    {
      "epoch": 9.303271189541952,
      "grad_norm": 0.646015465259552,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3117,
      "step": 228800
    },
    {
      "epoch": 9.307337304572346,
      "grad_norm": 0.6287152171134949,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3123,
      "step": 228900
    },
    {
      "epoch": 9.31140341960274,
      "grad_norm": 0.7171483039855957,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3118,
      "step": 229000
    },
    {
      "epoch": 9.315469534633134,
      "grad_norm": 0.7210533618927002,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.3124,
      "step": 229100
    },
    {
      "epoch": 9.319535649663528,
      "grad_norm": 0.6755879521369934,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3122,
      "step": 229200
    },
    {
      "epoch": 9.323601764693922,
      "grad_norm": 0.7176191806793213,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3123,
      "step": 229300
    },
    {
      "epoch": 9.327667879724318,
      "grad_norm": 0.7896806597709656,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3115,
      "step": 229400
    },
    {
      "epoch": 9.331733994754712,
      "grad_norm": 0.690599799156189,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3122,
      "step": 229500
    },
    {
      "epoch": 9.335800109785106,
      "grad_norm": 0.7483924031257629,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.3127,
      "step": 229600
    },
    {
      "epoch": 9.3398662248155,
      "grad_norm": 0.6719251871109009,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3115,
      "step": 229700
    },
    {
      "epoch": 9.343932339845894,
      "grad_norm": 0.7805375456809998,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3126,
      "step": 229800
    },
    {
      "epoch": 9.347998454876288,
      "grad_norm": 0.7690063714981079,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3134,
      "step": 229900
    },
    {
      "epoch": 9.352064569906682,
      "grad_norm": 0.6612737774848938,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.3114,
      "step": 230000
    },
    {
      "epoch": 9.352064569906682,
      "eval_loss": 0.33677786588668823,
      "eval_runtime": 125.5007,
      "eval_samples_per_second": 1393.634,
      "eval_steps_per_second": 43.554,
      "step": 230000
    },
    {
      "epoch": 9.356130684937076,
      "grad_norm": 0.5858665704727173,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.3131,
      "step": 230100
    },
    {
      "epoch": 9.36019679996747,
      "grad_norm": 0.6301761269569397,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.3137,
      "step": 230200
    },
    {
      "epoch": 9.364262914997866,
      "grad_norm": 0.7900640964508057,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.313,
      "step": 230300
    },
    {
      "epoch": 9.36832903002826,
      "grad_norm": 0.7453104257583618,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.3112,
      "step": 230400
    },
    {
      "epoch": 9.372395145058654,
      "grad_norm": 0.7579889893531799,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3123,
      "step": 230500
    },
    {
      "epoch": 9.376461260089048,
      "grad_norm": 0.6665737628936768,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3118,
      "step": 230600
    },
    {
      "epoch": 9.380527375119442,
      "grad_norm": 0.6954686641693115,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.3145,
      "step": 230700
    },
    {
      "epoch": 9.384593490149836,
      "grad_norm": 0.6948513984680176,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.314,
      "step": 230800
    },
    {
      "epoch": 9.38865960518023,
      "grad_norm": 0.621760368347168,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.3112,
      "step": 230900
    },
    {
      "epoch": 9.392725720210624,
      "grad_norm": 0.8519067764282227,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.3117,
      "step": 231000
    },
    {
      "epoch": 9.39679183524102,
      "grad_norm": 0.6835296154022217,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3125,
      "step": 231100
    },
    {
      "epoch": 9.400857950271414,
      "grad_norm": 0.6399734020233154,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3106,
      "step": 231200
    },
    {
      "epoch": 9.404924065301808,
      "grad_norm": 0.6796531081199646,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3146,
      "step": 231300
    },
    {
      "epoch": 9.408990180332202,
      "grad_norm": 0.706997275352478,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3141,
      "step": 231400
    },
    {
      "epoch": 9.413056295362596,
      "grad_norm": 0.8284805417060852,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3122,
      "step": 231500
    },
    {
      "epoch": 9.41712241039299,
      "grad_norm": 0.7013030648231506,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3126,
      "step": 231600
    },
    {
      "epoch": 9.421188525423384,
      "grad_norm": 0.6755417585372925,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.3129,
      "step": 231700
    },
    {
      "epoch": 9.425254640453778,
      "grad_norm": 0.6905500292778015,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.313,
      "step": 231800
    },
    {
      "epoch": 9.429320755484172,
      "grad_norm": 0.7075082659721375,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3118,
      "step": 231900
    },
    {
      "epoch": 9.433386870514568,
      "grad_norm": 0.716390073299408,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.3133,
      "step": 232000
    },
    {
      "epoch": 9.433386870514568,
      "eval_loss": 0.3363325297832489,
      "eval_runtime": 126.6074,
      "eval_samples_per_second": 1381.452,
      "eval_steps_per_second": 43.173,
      "step": 232000
    },
    {
      "epoch": 9.437452985544962,
      "grad_norm": 0.7443353533744812,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3129,
      "step": 232100
    },
    {
      "epoch": 9.441519100575356,
      "grad_norm": 0.7025230526924133,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3106,
      "step": 232200
    },
    {
      "epoch": 9.44558521560575,
      "grad_norm": 0.661834716796875,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3123,
      "step": 232300
    },
    {
      "epoch": 9.449651330636144,
      "grad_norm": 0.7045462131500244,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.3107,
      "step": 232400
    },
    {
      "epoch": 9.453717445666538,
      "grad_norm": 0.7833547592163086,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.312,
      "step": 232500
    },
    {
      "epoch": 9.457783560696932,
      "grad_norm": 0.730280339717865,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3117,
      "step": 232600
    },
    {
      "epoch": 9.461849675727326,
      "grad_norm": 0.7078977823257446,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3114,
      "step": 232700
    },
    {
      "epoch": 9.465915790757721,
      "grad_norm": 0.7604033350944519,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.3105,
      "step": 232800
    },
    {
      "epoch": 9.469981905788115,
      "grad_norm": 0.6892370581626892,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3121,
      "step": 232900
    },
    {
      "epoch": 9.47404802081851,
      "grad_norm": 0.6530098915100098,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3121,
      "step": 233000
    },
    {
      "epoch": 9.478114135848903,
      "grad_norm": 0.6514192223548889,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.313,
      "step": 233100
    },
    {
      "epoch": 9.482180250879297,
      "grad_norm": 0.7915623784065247,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.3119,
      "step": 233200
    },
    {
      "epoch": 9.486246365909691,
      "grad_norm": 0.69798344373703,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.3109,
      "step": 233300
    },
    {
      "epoch": 9.490312480940085,
      "grad_norm": 0.7318602800369263,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3116,
      "step": 233400
    },
    {
      "epoch": 9.49437859597048,
      "grad_norm": 0.6849133372306824,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3116,
      "step": 233500
    },
    {
      "epoch": 9.498444711000873,
      "grad_norm": 0.696780264377594,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3124,
      "step": 233600
    },
    {
      "epoch": 9.50251082603127,
      "grad_norm": 0.7706059217453003,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.3116,
      "step": 233700
    },
    {
      "epoch": 9.506576941061663,
      "grad_norm": 0.6352129578590393,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3114,
      "step": 233800
    },
    {
      "epoch": 9.510643056092057,
      "grad_norm": 0.8153377771377563,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3122,
      "step": 233900
    },
    {
      "epoch": 9.514709171122451,
      "grad_norm": 0.7236299514770508,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.3105,
      "step": 234000
    },
    {
      "epoch": 9.514709171122451,
      "eval_loss": 0.3357107937335968,
      "eval_runtime": 125.8262,
      "eval_samples_per_second": 1390.028,
      "eval_steps_per_second": 43.441,
      "step": 234000
    },
    {
      "epoch": 9.518775286152845,
      "grad_norm": 0.6115560531616211,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.3102,
      "step": 234100
    },
    {
      "epoch": 9.52284140118324,
      "grad_norm": 0.7528074383735657,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.3117,
      "step": 234200
    },
    {
      "epoch": 9.526907516213633,
      "grad_norm": 0.6636236906051636,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3107,
      "step": 234300
    },
    {
      "epoch": 9.530973631244027,
      "grad_norm": 0.7541869282722473,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3111,
      "step": 234400
    },
    {
      "epoch": 9.535039746274421,
      "grad_norm": 0.7844626307487488,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3128,
      "step": 234500
    },
    {
      "epoch": 9.539105861304817,
      "grad_norm": 0.748648464679718,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3134,
      "step": 234600
    },
    {
      "epoch": 9.543171976335211,
      "grad_norm": 0.740679144859314,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3125,
      "step": 234700
    },
    {
      "epoch": 9.547238091365605,
      "grad_norm": 0.7213742136955261,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.3095,
      "step": 234800
    },
    {
      "epoch": 9.551304206395999,
      "grad_norm": 0.7693489193916321,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.3133,
      "step": 234900
    },
    {
      "epoch": 9.555370321426393,
      "grad_norm": 0.6965947151184082,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.311,
      "step": 235000
    },
    {
      "epoch": 9.559436436456787,
      "grad_norm": 0.8126952052116394,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3091,
      "step": 235100
    },
    {
      "epoch": 9.563502551487181,
      "grad_norm": 0.7854936718940735,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3105,
      "step": 235200
    },
    {
      "epoch": 9.567568666517575,
      "grad_norm": 0.7424224615097046,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3114,
      "step": 235300
    },
    {
      "epoch": 9.57163478154797,
      "grad_norm": 0.7577963471412659,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3125,
      "step": 235400
    },
    {
      "epoch": 9.575700896578365,
      "grad_norm": 0.7298646569252014,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.3108,
      "step": 235500
    },
    {
      "epoch": 9.579767011608759,
      "grad_norm": 0.7345477342605591,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3124,
      "step": 235600
    },
    {
      "epoch": 9.583833126639153,
      "grad_norm": 0.7521331310272217,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.3118,
      "step": 235700
    },
    {
      "epoch": 9.587899241669547,
      "grad_norm": 0.767015814781189,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.3127,
      "step": 235800
    },
    {
      "epoch": 9.59196535669994,
      "grad_norm": 0.7301508784294128,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.3106,
      "step": 235900
    },
    {
      "epoch": 9.596031471730335,
      "grad_norm": 0.7896717190742493,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.3111,
      "step": 236000
    },
    {
      "epoch": 9.596031471730335,
      "eval_loss": 0.33478087186813354,
      "eval_runtime": 125.9895,
      "eval_samples_per_second": 1388.226,
      "eval_steps_per_second": 43.385,
      "step": 236000
    },
    {
      "epoch": 9.600097586760729,
      "grad_norm": 0.8256975412368774,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3107,
      "step": 236100
    },
    {
      "epoch": 9.604163701791123,
      "grad_norm": 0.7286838293075562,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3094,
      "step": 236200
    },
    {
      "epoch": 9.608229816821519,
      "grad_norm": 0.7160773277282715,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.3107,
      "step": 236300
    },
    {
      "epoch": 9.612295931851913,
      "grad_norm": 0.7900270819664001,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3125,
      "step": 236400
    },
    {
      "epoch": 9.616362046882307,
      "grad_norm": 0.7333875894546509,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.311,
      "step": 236500
    },
    {
      "epoch": 9.6204281619127,
      "grad_norm": 0.6898020505905151,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3101,
      "step": 236600
    },
    {
      "epoch": 9.624494276943095,
      "grad_norm": 0.8174799680709839,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3105,
      "step": 236700
    },
    {
      "epoch": 9.628560391973489,
      "grad_norm": 0.6858044266700745,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.3098,
      "step": 236800
    },
    {
      "epoch": 9.632626507003883,
      "grad_norm": 0.7488311529159546,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3101,
      "step": 236900
    },
    {
      "epoch": 9.636692622034277,
      "grad_norm": 0.6433174014091492,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.3118,
      "step": 237000
    },
    {
      "epoch": 9.640758737064672,
      "grad_norm": 0.7225297689437866,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3105,
      "step": 237100
    },
    {
      "epoch": 9.644824852095066,
      "grad_norm": 0.6877755522727966,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.3089,
      "step": 237200
    },
    {
      "epoch": 9.64889096712546,
      "grad_norm": 0.7501218318939209,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3115,
      "step": 237300
    },
    {
      "epoch": 9.652957082155854,
      "grad_norm": 0.7889949679374695,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.3103,
      "step": 237400
    },
    {
      "epoch": 9.657023197186248,
      "grad_norm": 0.7455075979232788,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.3111,
      "step": 237500
    },
    {
      "epoch": 9.661089312216642,
      "grad_norm": 0.6989963054656982,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3118,
      "step": 237600
    },
    {
      "epoch": 9.665155427247036,
      "grad_norm": 0.7515156269073486,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.312,
      "step": 237700
    },
    {
      "epoch": 9.66922154227743,
      "grad_norm": 0.7774211764335632,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.3114,
      "step": 237800
    },
    {
      "epoch": 9.673287657307824,
      "grad_norm": 0.6820225715637207,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3123,
      "step": 237900
    },
    {
      "epoch": 9.67735377233822,
      "grad_norm": 0.7676188945770264,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3105,
      "step": 238000
    },
    {
      "epoch": 9.67735377233822,
      "eval_loss": 0.33438923954963684,
      "eval_runtime": 129.2605,
      "eval_samples_per_second": 1353.098,
      "eval_steps_per_second": 42.287,
      "step": 238000
    },
    {
      "epoch": 9.681419887368614,
      "grad_norm": 0.6912028193473816,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.3112,
      "step": 238100
    },
    {
      "epoch": 9.685486002399008,
      "grad_norm": 0.6439455151557922,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3095,
      "step": 238200
    },
    {
      "epoch": 9.689552117429402,
      "grad_norm": 0.6761178374290466,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3087,
      "step": 238300
    },
    {
      "epoch": 9.693618232459796,
      "grad_norm": 0.7258453369140625,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.3119,
      "step": 238400
    },
    {
      "epoch": 9.69768434749019,
      "grad_norm": 0.6549814939498901,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3096,
      "step": 238500
    },
    {
      "epoch": 9.701750462520584,
      "grad_norm": 0.8151615262031555,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.311,
      "step": 238600
    },
    {
      "epoch": 9.705816577550978,
      "grad_norm": 0.7179726958274841,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3105,
      "step": 238700
    },
    {
      "epoch": 9.709882692581374,
      "grad_norm": 0.7059043049812317,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3101,
      "step": 238800
    },
    {
      "epoch": 9.713948807611768,
      "grad_norm": 0.7020032405853271,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3088,
      "step": 238900
    },
    {
      "epoch": 9.718014922642162,
      "grad_norm": 0.8157217502593994,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.3102,
      "step": 239000
    },
    {
      "epoch": 9.722081037672556,
      "grad_norm": 0.6783232688903809,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.31,
      "step": 239100
    },
    {
      "epoch": 9.72614715270295,
      "grad_norm": 0.7841816544532776,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3081,
      "step": 239200
    },
    {
      "epoch": 9.730213267733344,
      "grad_norm": 0.7125726938247681,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3105,
      "step": 239300
    },
    {
      "epoch": 9.734279382763738,
      "grad_norm": 0.7856519818305969,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.3109,
      "step": 239400
    },
    {
      "epoch": 9.738345497794132,
      "grad_norm": 0.7059460282325745,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3096,
      "step": 239500
    },
    {
      "epoch": 9.742411612824526,
      "grad_norm": 0.75517338514328,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3107,
      "step": 239600
    },
    {
      "epoch": 9.746477727854922,
      "grad_norm": 0.5995936989784241,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3098,
      "step": 239700
    },
    {
      "epoch": 9.750543842885316,
      "grad_norm": 0.7424883246421814,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3109,
      "step": 239800
    },
    {
      "epoch": 9.75460995791571,
      "grad_norm": 0.7613856196403503,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.3085,
      "step": 239900
    },
    {
      "epoch": 9.758676072946104,
      "grad_norm": 0.752713680267334,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3095,
      "step": 240000
    },
    {
      "epoch": 9.758676072946104,
      "eval_loss": 0.3338218629360199,
      "eval_runtime": 125.7221,
      "eval_samples_per_second": 1391.18,
      "eval_steps_per_second": 43.477,
      "step": 240000
    },
    {
      "epoch": 9.762742187976498,
      "grad_norm": 0.7230675220489502,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.3106,
      "step": 240100
    },
    {
      "epoch": 9.766808303006892,
      "grad_norm": 0.7327514886856079,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.311,
      "step": 240200
    },
    {
      "epoch": 9.770874418037286,
      "grad_norm": 0.7138360142707825,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.3117,
      "step": 240300
    },
    {
      "epoch": 9.77494053306768,
      "grad_norm": 0.6582895517349243,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.3088,
      "step": 240400
    },
    {
      "epoch": 9.779006648098076,
      "grad_norm": 0.8091719150543213,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.3085,
      "step": 240500
    },
    {
      "epoch": 9.78307276312847,
      "grad_norm": 0.74457186460495,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3096,
      "step": 240600
    },
    {
      "epoch": 9.787138878158864,
      "grad_norm": 0.8219715356826782,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3105,
      "step": 240700
    },
    {
      "epoch": 9.791204993189258,
      "grad_norm": 0.7813178300857544,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3104,
      "step": 240800
    },
    {
      "epoch": 9.795271108219652,
      "grad_norm": 0.7947746515274048,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.3095,
      "step": 240900
    },
    {
      "epoch": 9.799337223250046,
      "grad_norm": 0.6822255253791809,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3098,
      "step": 241000
    },
    {
      "epoch": 9.80340333828044,
      "grad_norm": 0.7559600472450256,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3112,
      "step": 241100
    },
    {
      "epoch": 9.807469453310834,
      "grad_norm": 0.6441333293914795,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3097,
      "step": 241200
    },
    {
      "epoch": 9.811535568341228,
      "grad_norm": 0.8218786716461182,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.312,
      "step": 241300
    },
    {
      "epoch": 9.815601683371623,
      "grad_norm": 0.831360936164856,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.3117,
      "step": 241400
    },
    {
      "epoch": 9.819667798402017,
      "grad_norm": 0.8283395171165466,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3089,
      "step": 241500
    },
    {
      "epoch": 9.823733913432411,
      "grad_norm": 0.6725932359695435,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.3109,
      "step": 241600
    },
    {
      "epoch": 9.827800028462805,
      "grad_norm": 0.6573253273963928,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3095,
      "step": 241700
    },
    {
      "epoch": 9.8318661434932,
      "grad_norm": 0.7269122004508972,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3086,
      "step": 241800
    },
    {
      "epoch": 9.835932258523593,
      "grad_norm": 0.7733914852142334,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.3077,
      "step": 241900
    },
    {
      "epoch": 9.839998373553987,
      "grad_norm": 0.7569013833999634,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3079,
      "step": 242000
    },
    {
      "epoch": 9.839998373553987,
      "eval_loss": 0.3333629071712494,
      "eval_runtime": 126.6601,
      "eval_samples_per_second": 1380.876,
      "eval_steps_per_second": 43.155,
      "step": 242000
    },
    {
      "epoch": 9.844064488584381,
      "grad_norm": 0.7518772482872009,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3083,
      "step": 242100
    },
    {
      "epoch": 9.848130603614777,
      "grad_norm": 0.8222383856773376,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3111,
      "step": 242200
    },
    {
      "epoch": 9.852196718645171,
      "grad_norm": 0.695873498916626,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.3099,
      "step": 242300
    },
    {
      "epoch": 9.856262833675565,
      "grad_norm": 0.7636775970458984,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.3089,
      "step": 242400
    },
    {
      "epoch": 9.860328948705959,
      "grad_norm": 0.6986979842185974,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.309,
      "step": 242500
    },
    {
      "epoch": 9.864395063736353,
      "grad_norm": 0.8090646266937256,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3102,
      "step": 242600
    },
    {
      "epoch": 9.868461178766747,
      "grad_norm": 0.7314200401306152,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3084,
      "step": 242700
    },
    {
      "epoch": 9.872527293797141,
      "grad_norm": 0.776159942150116,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3097,
      "step": 242800
    },
    {
      "epoch": 9.876593408827535,
      "grad_norm": 0.7304735779762268,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.3086,
      "step": 242900
    },
    {
      "epoch": 9.88065952385793,
      "grad_norm": 0.858653724193573,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3084,
      "step": 243000
    },
    {
      "epoch": 9.884725638888325,
      "grad_norm": 0.692613422870636,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.308,
      "step": 243100
    },
    {
      "epoch": 9.888791753918719,
      "grad_norm": 0.8139683604240417,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.3092,
      "step": 243200
    },
    {
      "epoch": 9.892857868949113,
      "grad_norm": 0.7277364730834961,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3111,
      "step": 243300
    },
    {
      "epoch": 9.896923983979507,
      "grad_norm": 0.7153130173683167,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3089,
      "step": 243400
    },
    {
      "epoch": 9.900990099009901,
      "grad_norm": 0.7379003167152405,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.309,
      "step": 243500
    },
    {
      "epoch": 9.905056214040295,
      "grad_norm": 0.6809394359588623,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.3091,
      "step": 243600
    },
    {
      "epoch": 9.909122329070689,
      "grad_norm": 0.6910817623138428,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3083,
      "step": 243700
    },
    {
      "epoch": 9.913188444101083,
      "grad_norm": 0.8389927744865417,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3088,
      "step": 243800
    },
    {
      "epoch": 9.917254559131479,
      "grad_norm": 0.7226002216339111,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3078,
      "step": 243900
    },
    {
      "epoch": 9.921320674161873,
      "grad_norm": 0.8525264263153076,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3078,
      "step": 244000
    },
    {
      "epoch": 9.921320674161873,
      "eval_loss": 0.33303168416023254,
      "eval_runtime": 127.1922,
      "eval_samples_per_second": 1375.1,
      "eval_steps_per_second": 42.974,
      "step": 244000
    },
    {
      "epoch": 9.925386789192267,
      "grad_norm": 0.708990752696991,
      "learning_rate": 4.049926968530075e-06,
      "loss": 0.3091,
      "step": 244100
    },
    {
      "epoch": 9.92945290422266,
      "grad_norm": 0.7019975185394287,
      "learning_rate": 3.8286194839109455e-06,
      "loss": 0.3094,
      "step": 244200
    },
    {
      "epoch": 9.933519019253055,
      "grad_norm": 0.7790675163269043,
      "learning_rate": 3.607311999291816e-06,
      "loss": 0.3083,
      "step": 244300
    },
    {
      "epoch": 9.937585134283449,
      "grad_norm": 0.6968503594398499,
      "learning_rate": 3.3860045146726864e-06,
      "loss": 0.3104,
      "step": 244400
    },
    {
      "epoch": 9.941651249313843,
      "grad_norm": 0.8294235467910767,
      "learning_rate": 3.1646970300535566e-06,
      "loss": 0.3104,
      "step": 244500
    },
    {
      "epoch": 9.945717364344237,
      "grad_norm": 0.7468599081039429,
      "learning_rate": 2.943389545434427e-06,
      "loss": 0.3074,
      "step": 244600
    },
    {
      "epoch": 9.94978347937463,
      "grad_norm": 0.8207830190658569,
      "learning_rate": 2.7220820608152966e-06,
      "loss": 0.3081,
      "step": 244700
    },
    {
      "epoch": 9.953849594405026,
      "grad_norm": 0.7847347855567932,
      "learning_rate": 2.5007745761961673e-06,
      "loss": 0.3106,
      "step": 244800
    },
    {
      "epoch": 9.95791570943542,
      "grad_norm": 0.7350613474845886,
      "learning_rate": 2.279467091577037e-06,
      "loss": 0.3085,
      "step": 244900
    },
    {
      "epoch": 9.961981824465814,
      "grad_norm": 0.7708951830863953,
      "learning_rate": 2.0581596069579077e-06,
      "loss": 0.3085,
      "step": 245000
    },
    {
      "epoch": 9.966047939496208,
      "grad_norm": 0.6601784229278564,
      "learning_rate": 1.8368521223387775e-06,
      "loss": 0.3083,
      "step": 245100
    },
    {
      "epoch": 9.970114054526602,
      "grad_norm": 0.797866702079773,
      "learning_rate": 1.6155446377196477e-06,
      "loss": 0.3097,
      "step": 245200
    },
    {
      "epoch": 9.974180169556996,
      "grad_norm": 0.7350896000862122,
      "learning_rate": 1.394237153100518e-06,
      "loss": 0.31,
      "step": 245300
    },
    {
      "epoch": 9.97824628458739,
      "grad_norm": 0.8066703081130981,
      "learning_rate": 1.172929668481388e-06,
      "loss": 0.3095,
      "step": 245400
    },
    {
      "epoch": 9.982312399617784,
      "grad_norm": 0.7126213312149048,
      "learning_rate": 9.516221838622583e-07,
      "loss": 0.3068,
      "step": 245500
    },
    {
      "epoch": 9.98637851464818,
      "grad_norm": 0.734767496585846,
      "learning_rate": 7.303146992431284e-07,
      "loss": 0.3088,
      "step": 245600
    },
    {
      "epoch": 9.990444629678574,
      "grad_norm": 0.7187504768371582,
      "learning_rate": 5.090072146239986e-07,
      "loss": 0.3086,
      "step": 245700
    },
    {
      "epoch": 9.994510744708968,
      "grad_norm": 0.6517808437347412,
      "learning_rate": 2.876997300048688e-07,
      "loss": 0.3081,
      "step": 245800
    },
    {
      "epoch": 9.998576859739362,
      "grad_norm": 0.7343142628669739,
      "learning_rate": 6.639224538573895e-08,
      "loss": 0.3098,
      "step": 245900
    },
    {
      "epoch": 9.99979669424848,
      "step": 245930,
      "total_flos": 0.0,
      "train_loss": 0.3584477355033953,
      "train_runtime": 47513.132,
      "train_samples_per_second": 331.273,
      "train_steps_per_second": 5.176
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
