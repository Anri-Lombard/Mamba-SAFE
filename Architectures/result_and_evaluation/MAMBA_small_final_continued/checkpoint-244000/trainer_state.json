{
  "best_metric": 0.3545917272567749,
  "best_model_checkpoint": "/scratch/lmbanr001/MAMBA_small_final_continued/checkpoint-244000",
  "epoch": 9.92150364933824,
  "eval_steps": 2000,
  "global_step": 244000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 7.726099967956543,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.7054,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 8.725400924682617,
      "learning_rate": 2.5e-06,
      "loss": 7.3815,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 3.956162691116333,
      "learning_rate": 5e-06,
      "loss": 5.0343,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 2.2837071418762207,
      "learning_rate": 7.5e-06,
      "loss": 2.8536,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 1.544620156288147,
      "learning_rate": 1e-05,
      "loss": 1.9064,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 1.3683816194534302,
      "learning_rate": 1.25e-05,
      "loss": 1.4165,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 1.1559697389602661,
      "learning_rate": 1.5e-05,
      "loss": 1.187,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 1.1505206823349,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 1.071,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 1.1675097942352295,
      "learning_rate": 2e-05,
      "loss": 0.9947,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 1.1769218444824219,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.9422,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 1.1162277460098267,
      "learning_rate": 2.5e-05,
      "loss": 0.9073,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 1.2975163459777832,
      "learning_rate": 2.75e-05,
      "loss": 0.8687,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 1.1756776571273804,
      "learning_rate": 3e-05,
      "loss": 0.8345,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 1.1306325197219849,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.8052,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 1.1891120672225952,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.776,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 1.2967486381530762,
      "learning_rate": 3.75e-05,
      "loss": 0.7578,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 1.1978428363800049,
      "learning_rate": 4e-05,
      "loss": 0.7383,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 1.1522353887557983,
      "learning_rate": 4.25e-05,
      "loss": 0.7241,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 1.2102032899856567,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.7065,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 1.3368672132492065,
      "learning_rate": 4.75e-05,
      "loss": 0.6883,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 1.563582181930542,
      "learning_rate": 5e-05,
      "loss": 0.6771,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.673986554145813,
      "eval_runtime": 183.5397,
      "eval_samples_per_second": 952.938,
      "eval_steps_per_second": 29.781,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 1.3030526638031006,
      "learning_rate": 5.25e-05,
      "loss": 0.6632,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 1.314577579498291,
      "learning_rate": 5.5e-05,
      "loss": 0.6528,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 1.473032832145691,
      "learning_rate": 5.75e-05,
      "loss": 0.6393,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 1.13030207157135,
      "learning_rate": 6e-05,
      "loss": 0.6332,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 1.1533308029174805,
      "learning_rate": 6.25e-05,
      "loss": 0.6232,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 1.1377556324005127,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.6127,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 1.1618800163269043,
      "learning_rate": 6.75e-05,
      "loss": 0.6018,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 1.4199907779693604,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.5966,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 1.0600342750549316,
      "learning_rate": 7.25e-05,
      "loss": 0.5866,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 1.1421045064926147,
      "learning_rate": 7.5e-05,
      "loss": 0.5811,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 1.2192617654800415,
      "learning_rate": 7.75e-05,
      "loss": 0.5754,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 1.0219833850860596,
      "learning_rate": 8e-05,
      "loss": 0.5695,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 1.044520378112793,
      "learning_rate": 8.25e-05,
      "loss": 0.5613,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 0.9314665794372559,
      "learning_rate": 8.5e-05,
      "loss": 0.5554,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 1.0450018644332886,
      "learning_rate": 8.75e-05,
      "loss": 0.5548,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 1.1048450469970703,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.5473,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 0.9072151184082031,
      "learning_rate": 9.25e-05,
      "loss": 0.5411,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 0.9675235152244568,
      "learning_rate": 9.5e-05,
      "loss": 0.5383,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 1.021924376487732,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.5345,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 0.9302628040313721,
      "learning_rate": 0.0001,
      "loss": 0.5299,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.5656777620315552,
      "eval_runtime": 182.0424,
      "eval_samples_per_second": 960.776,
      "eval_steps_per_second": 30.026,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 0.8766684532165527,
      "learning_rate": 0.0001025,
      "loss": 0.526,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 0.8476037383079529,
      "learning_rate": 0.000105,
      "loss": 0.524,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 0.9231228232383728,
      "learning_rate": 0.0001075,
      "loss": 0.5219,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 0.8641565442085266,
      "learning_rate": 0.00011,
      "loss": 0.5175,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 0.9321250319480896,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.5163,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 0.9454107880592346,
      "learning_rate": 0.000115,
      "loss": 0.5123,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 0.782946765422821,
      "learning_rate": 0.0001175,
      "loss": 0.5073,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 0.853685200214386,
      "learning_rate": 0.00012,
      "loss": 0.5074,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 0.7587763667106628,
      "learning_rate": 0.0001225,
      "loss": 0.5048,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.8026747107505798,
      "learning_rate": 0.000125,
      "loss": 0.5057,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 0.8273468017578125,
      "learning_rate": 0.0001275,
      "loss": 0.5006,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 0.801056444644928,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.4984,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 0.8053549528121948,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.494,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.7548862099647522,
      "learning_rate": 0.000135,
      "loss": 0.4933,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.7583268880844116,
      "learning_rate": 0.0001375,
      "loss": 0.4947,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.7295647263526917,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4918,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.7570592761039734,
      "learning_rate": 0.0001425,
      "loss": 0.4915,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.7022207379341125,
      "learning_rate": 0.000145,
      "loss": 0.4903,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.7670673131942749,
      "learning_rate": 0.0001475,
      "loss": 0.4857,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.6526833176612854,
      "learning_rate": 0.00015,
      "loss": 0.4848,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.5348662734031677,
      "eval_runtime": 180.683,
      "eval_samples_per_second": 968.005,
      "eval_steps_per_second": 30.252,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 0.7564640641212463,
      "learning_rate": 0.0001525,
      "loss": 0.4838,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.6842511892318726,
      "learning_rate": 0.000155,
      "loss": 0.485,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.6306718587875366,
      "learning_rate": 0.0001575,
      "loss": 0.4806,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 0.7607836127281189,
      "learning_rate": 0.00016,
      "loss": 0.4821,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.6108255386352539,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.4814,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.6478765606880188,
      "learning_rate": 0.000165,
      "loss": 0.4817,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.6671855449676514,
      "learning_rate": 0.0001675,
      "loss": 0.4742,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.5839885473251343,
      "learning_rate": 0.00017,
      "loss": 0.4746,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.637346088886261,
      "learning_rate": 0.0001725,
      "loss": 0.4729,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.6019854545593262,
      "learning_rate": 0.000175,
      "loss": 0.4737,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.5582537651062012,
      "learning_rate": 0.0001775,
      "loss": 0.4729,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.5808282494544983,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4717,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6178585886955261,
      "learning_rate": 0.0001825,
      "loss": 0.4695,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.5598225593566895,
      "learning_rate": 0.000185,
      "loss": 0.4699,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.5412583351135254,
      "learning_rate": 0.0001875,
      "loss": 0.4679,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.544890820980072,
      "learning_rate": 0.00019,
      "loss": 0.4666,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.5385115146636963,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4649,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.5248876214027405,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.4653,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.5806059837341309,
      "learning_rate": 0.0001975,
      "loss": 0.4645,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.5433420538902283,
      "learning_rate": 0.0002,
      "loss": 0.4643,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.5202035307884216,
      "eval_runtime": 182.6687,
      "eval_samples_per_second": 957.482,
      "eval_steps_per_second": 29.923,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.5892942547798157,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4649,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.5329964756965637,
      "learning_rate": 0.000205,
      "loss": 0.465,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.5997170805931091,
      "learning_rate": 0.0002075,
      "loss": 0.4606,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.5228137373924255,
      "learning_rate": 0.00021,
      "loss": 0.4597,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.5222150087356567,
      "learning_rate": 0.0002125,
      "loss": 0.4576,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.5079780220985413,
      "learning_rate": 0.000215,
      "loss": 0.4574,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.5245229601860046,
      "learning_rate": 0.0002175,
      "loss": 0.4565,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.4860338270664215,
      "learning_rate": 0.00022,
      "loss": 0.4552,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.48087677359580994,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4542,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.5438094139099121,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.452,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.48698821663856506,
      "learning_rate": 0.0002275,
      "loss": 0.4555,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.4484950602054596,
      "learning_rate": 0.00023,
      "loss": 0.4533,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.4462534487247467,
      "learning_rate": 0.0002325,
      "loss": 0.4532,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.4592955410480499,
      "learning_rate": 0.000235,
      "loss": 0.4518,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.4241902828216553,
      "learning_rate": 0.0002375,
      "loss": 0.4474,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.4496060907840729,
      "learning_rate": 0.00024,
      "loss": 0.4509,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.44067829847335815,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4481,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.5394691824913025,
      "learning_rate": 0.000245,
      "loss": 0.4469,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.4159979522228241,
      "learning_rate": 0.0002475,
      "loss": 0.4523,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.4544731378555298,
      "learning_rate": 0.00025,
      "loss": 0.4494,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.5265554785728455,
      "eval_runtime": 182.5266,
      "eval_samples_per_second": 958.227,
      "eval_steps_per_second": 29.946,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.43952932953834534,
      "learning_rate": 0.0002525,
      "loss": 0.4484,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.41065576672554016,
      "learning_rate": 0.000255,
      "loss": 0.4495,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.4662221670150757,
      "learning_rate": 0.0002575,
      "loss": 0.4492,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.41781410574913025,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4453,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.414955198764801,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4457,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.41084742546081543,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4459,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.4448515474796295,
      "learning_rate": 0.0002675,
      "loss": 0.4449,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.3711046278476715,
      "learning_rate": 0.00027,
      "loss": 0.4433,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.3694390654563904,
      "learning_rate": 0.0002725,
      "loss": 0.4444,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.4272819459438324,
      "learning_rate": 0.000275,
      "loss": 0.4447,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.3786783516407013,
      "learning_rate": 0.0002775,
      "loss": 0.4406,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.3890276551246643,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4456,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.417302668094635,
      "learning_rate": 0.0002825,
      "loss": 0.4435,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.36678221821784973,
      "learning_rate": 0.000285,
      "loss": 0.4399,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.39459067583084106,
      "learning_rate": 0.0002875,
      "loss": 0.4415,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.35228532552719116,
      "learning_rate": 0.00029,
      "loss": 0.4374,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.3899948298931122,
      "learning_rate": 0.0002925,
      "loss": 0.4392,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.4415701925754547,
      "learning_rate": 0.000295,
      "loss": 0.4385,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.3736502528190613,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4373,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.37328705191612244,
      "learning_rate": 0.0003,
      "loss": 0.4367,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.5010666847229004,
      "eval_runtime": 182.7318,
      "eval_samples_per_second": 957.152,
      "eval_steps_per_second": 29.913,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.3700662851333618,
      "learning_rate": 0.0003025,
      "loss": 0.4363,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.3436117470264435,
      "learning_rate": 0.000305,
      "loss": 0.4335,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.3479657471179962,
      "learning_rate": 0.0003075,
      "loss": 0.4375,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.33611929416656494,
      "learning_rate": 0.00031,
      "loss": 0.437,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.3659105896949768,
      "learning_rate": 0.0003125,
      "loss": 0.4371,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.3571989834308624,
      "learning_rate": 0.000315,
      "loss": 0.4348,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.382282555103302,
      "learning_rate": 0.0003175,
      "loss": 0.4334,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.3544960618019104,
      "learning_rate": 0.00032,
      "loss": 0.4364,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.3511248230934143,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4369,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.30085489153862,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4345,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.35457494854927063,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4351,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.34917348623275757,
      "learning_rate": 0.00033,
      "loss": 0.4337,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.33404776453971863,
      "learning_rate": 0.0003325,
      "loss": 0.4317,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.346101850271225,
      "learning_rate": 0.000335,
      "loss": 0.4344,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.33386436104774475,
      "learning_rate": 0.0003375,
      "loss": 0.4314,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.30525603890419006,
      "learning_rate": 0.00034,
      "loss": 0.4316,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.3237873315811157,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.432,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.35243117809295654,
      "learning_rate": 0.000345,
      "loss": 0.432,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.3124537169933319,
      "learning_rate": 0.0003475,
      "loss": 0.4315,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.3403802812099457,
      "learning_rate": 0.00035,
      "loss": 0.4343,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.4617771804332733,
      "eval_runtime": 182.2064,
      "eval_samples_per_second": 959.911,
      "eval_steps_per_second": 29.999,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.33551913499832153,
      "learning_rate": 0.0003525,
      "loss": 0.4335,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.3246770203113556,
      "learning_rate": 0.000355,
      "loss": 0.433,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.29237982630729675,
      "learning_rate": 0.0003575,
      "loss": 0.4306,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.27499160170555115,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4313,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.3271910548210144,
      "learning_rate": 0.0003625,
      "loss": 0.4293,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.32710614800453186,
      "learning_rate": 0.000365,
      "loss": 0.4307,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.3064878284931183,
      "learning_rate": 0.0003675,
      "loss": 0.4309,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.2836151719093323,
      "learning_rate": 0.00037,
      "loss": 0.4276,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.2809831500053406,
      "learning_rate": 0.0003725,
      "loss": 0.4268,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.2936709523200989,
      "learning_rate": 0.000375,
      "loss": 0.4286,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.30242741107940674,
      "learning_rate": 0.0003775,
      "loss": 0.4264,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.29272374510765076,
      "learning_rate": 0.00038,
      "loss": 0.4273,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.3012171685695648,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4297,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.2774675786495209,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4255,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.29706743359565735,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4257,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.28419390320777893,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4246,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.3277592062950134,
      "learning_rate": 0.0003925,
      "loss": 0.4234,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.28950396180152893,
      "learning_rate": 0.000395,
      "loss": 0.4257,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.28230568766593933,
      "learning_rate": 0.0003975,
      "loss": 0.4257,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.31705203652381897,
      "learning_rate": 0.0004,
      "loss": 0.4258,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.4434155821800232,
      "eval_runtime": 178.6995,
      "eval_samples_per_second": 978.749,
      "eval_steps_per_second": 30.588,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.26412782073020935,
      "learning_rate": 0.0004025,
      "loss": 0.427,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.24481536448001862,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4268,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.268583208322525,
      "learning_rate": 0.0004075,
      "loss": 0.427,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.2734808921813965,
      "learning_rate": 0.00041,
      "loss": 0.4243,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.25879496335983276,
      "learning_rate": 0.0004125,
      "loss": 0.4262,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.2889692485332489,
      "learning_rate": 0.000415,
      "loss": 0.4247,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.2701362073421478,
      "learning_rate": 0.0004175,
      "loss": 0.4241,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.2611309885978699,
      "learning_rate": 0.00042,
      "loss": 0.4246,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.24647852778434753,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4248,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.30509647727012634,
      "learning_rate": 0.000425,
      "loss": 0.4234,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.2556268274784088,
      "learning_rate": 0.0004275,
      "loss": 0.4266,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.2716714143753052,
      "learning_rate": 0.00043,
      "loss": 0.4248,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.26713547110557556,
      "learning_rate": 0.0004325,
      "loss": 0.4256,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.27001795172691345,
      "learning_rate": 0.000435,
      "loss": 0.424,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.24870933592319489,
      "learning_rate": 0.0004375,
      "loss": 0.4215,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.276275634765625,
      "learning_rate": 0.00044,
      "loss": 0.4239,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.2450852394104004,
      "learning_rate": 0.0004425,
      "loss": 0.42,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.2762775719165802,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4241,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.25339266657829285,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4224,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.23694366216659546,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4226,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.45380863547325134,
      "eval_runtime": 181.4037,
      "eval_samples_per_second": 964.159,
      "eval_steps_per_second": 30.132,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.2597656548023224,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4189,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.2356131374835968,
      "learning_rate": 0.000455,
      "loss": 0.4221,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.22904561460018158,
      "learning_rate": 0.0004575,
      "loss": 0.4209,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.2532244324684143,
      "learning_rate": 0.00046,
      "loss": 0.422,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.2224941849708557,
      "learning_rate": 0.0004625,
      "loss": 0.4193,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.23735280334949493,
      "learning_rate": 0.000465,
      "loss": 0.4197,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.2213771790266037,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4214,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.22377026081085205,
      "learning_rate": 0.00047,
      "loss": 0.421,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.24335727095603943,
      "learning_rate": 0.0004725,
      "loss": 0.4202,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.22749030590057373,
      "learning_rate": 0.000475,
      "loss": 0.4177,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.2229829728603363,
      "learning_rate": 0.0004775,
      "loss": 0.4194,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.2643355131149292,
      "learning_rate": 0.00048,
      "loss": 0.4193,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.23239274322986603,
      "learning_rate": 0.0004825,
      "loss": 0.4217,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.22401419281959534,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.419,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.2457941621541977,
      "learning_rate": 0.0004875,
      "loss": 0.4165,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.24208222329616547,
      "learning_rate": 0.00049,
      "loss": 0.4184,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.24590946733951569,
      "learning_rate": 0.0004925,
      "loss": 0.4173,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.22880017757415771,
      "learning_rate": 0.000495,
      "loss": 0.4182,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.22116561233997345,
      "learning_rate": 0.0004975,
      "loss": 0.4185,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.23439164459705353,
      "learning_rate": 0.0005,
      "loss": 0.4187,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.4590110182762146,
      "eval_runtime": 182.2072,
      "eval_samples_per_second": 959.907,
      "eval_steps_per_second": 29.999,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.2152048647403717,
      "learning_rate": 0.0004996713790905088,
      "loss": 0.4191,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.21321482956409454,
      "learning_rate": 0.0004993427581810176,
      "loss": 0.4183,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.21662577986717224,
      "learning_rate": 0.0004990141372715264,
      "loss": 0.4147,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.1915331780910492,
      "learning_rate": 0.0004986855163620351,
      "loss": 0.4164,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.22064274549484253,
      "learning_rate": 0.0004983568954525439,
      "loss": 0.4158,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.2113351821899414,
      "learning_rate": 0.0004980282745430526,
      "loss": 0.415,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.21975134313106537,
      "learning_rate": 0.0004976996536335614,
      "loss": 0.4169,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.2062755823135376,
      "learning_rate": 0.0004973710327240702,
      "loss": 0.4174,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.21339364349842072,
      "learning_rate": 0.0004970424118145789,
      "loss": 0.4157,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.20313522219657898,
      "learning_rate": 0.0004967137909050877,
      "loss": 0.4147,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.2253311425447464,
      "learning_rate": 0.0004963851699955965,
      "loss": 0.4145,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.21014812588691711,
      "learning_rate": 0.0004960565490861053,
      "loss": 0.4129,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.22173050045967102,
      "learning_rate": 0.0004957279281766141,
      "loss": 0.4125,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.21446363627910614,
      "learning_rate": 0.0004953993072671228,
      "loss": 0.4155,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.21553382277488708,
      "learning_rate": 0.0004950706863576316,
      "loss": 0.4135,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.2135952264070511,
      "learning_rate": 0.0004947420654481403,
      "loss": 0.413,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.20465070009231567,
      "learning_rate": 0.0004944134445386491,
      "loss": 0.4127,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.1993713676929474,
      "learning_rate": 0.0004940848236291579,
      "loss": 0.412,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.21865099668502808,
      "learning_rate": 0.0004937562027196666,
      "loss": 0.4126,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.20113834738731384,
      "learning_rate": 0.0004934275818101754,
      "loss": 0.4117,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.4432052969932556,
      "eval_runtime": 182.4825,
      "eval_samples_per_second": 958.459,
      "eval_steps_per_second": 29.954,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.22058811783790588,
      "learning_rate": 0.0004930989609006842,
      "loss": 0.4114,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.19908450543880463,
      "learning_rate": 0.000492770339991193,
      "loss": 0.4143,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.21497054398059845,
      "learning_rate": 0.0004924417190817018,
      "loss": 0.4122,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.2104460895061493,
      "learning_rate": 0.0004921130981722105,
      "loss": 0.4118,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.19905096292495728,
      "learning_rate": 0.0004917844772627192,
      "loss": 0.414,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.19110837578773499,
      "learning_rate": 0.000491455856353228,
      "loss": 0.4116,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.19438663125038147,
      "learning_rate": 0.0004911272354437368,
      "loss": 0.4105,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.20690731704235077,
      "learning_rate": 0.0004907986145342456,
      "loss": 0.4116,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.20232519507408142,
      "learning_rate": 0.0004904699936247544,
      "loss": 0.4103,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.20221534371376038,
      "learning_rate": 0.0004901413727152632,
      "loss": 0.4088,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.2029990404844284,
      "learning_rate": 0.0004898127518057719,
      "loss": 0.4094,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.2056126445531845,
      "learning_rate": 0.0004894841308962807,
      "loss": 0.4114,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.19349731504917145,
      "learning_rate": 0.0004891555099867895,
      "loss": 0.4114,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.18970055878162384,
      "learning_rate": 0.0004888268890772983,
      "loss": 0.4079,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.19036908447742462,
      "learning_rate": 0.000488498268167807,
      "loss": 0.4085,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.18497398495674133,
      "learning_rate": 0.00048816964725831573,
      "loss": 0.4083,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.21092914044857025,
      "learning_rate": 0.0004878410263488245,
      "loss": 0.4109,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.19112402200698853,
      "learning_rate": 0.00048751240543933326,
      "loss": 0.4102,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.21280211210250854,
      "learning_rate": 0.00048718378452984205,
      "loss": 0.4074,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.19056591391563416,
      "learning_rate": 0.0004868551636203509,
      "loss": 0.4065,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.43417736887931824,
      "eval_runtime": 183.2594,
      "eval_samples_per_second": 954.396,
      "eval_steps_per_second": 29.827,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.1878925859928131,
      "learning_rate": 0.00048652654271085963,
      "loss": 0.4092,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.18862101435661316,
      "learning_rate": 0.0004861979218013684,
      "loss": 0.4081,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.17611731588840485,
      "learning_rate": 0.00048586930089187716,
      "loss": 0.4088,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.1931733340024948,
      "learning_rate": 0.00048554067998238595,
      "loss": 0.4069,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.17797397077083588,
      "learning_rate": 0.0004852120590728947,
      "loss": 0.408,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.20541207492351532,
      "learning_rate": 0.0004848834381634035,
      "loss": 0.405,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.18580925464630127,
      "learning_rate": 0.00048455481725391227,
      "loss": 0.4054,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.19513782858848572,
      "learning_rate": 0.000484226196344421,
      "loss": 0.4078,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.17724572122097015,
      "learning_rate": 0.0004838975754349298,
      "loss": 0.404,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.19263756275177002,
      "learning_rate": 0.00048356895452543854,
      "loss": 0.4083,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.19815969467163086,
      "learning_rate": 0.00048324033361594733,
      "loss": 0.4031,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.20365414023399353,
      "learning_rate": 0.0004829117127064561,
      "loss": 0.4088,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.19257384538650513,
      "learning_rate": 0.00048258309179696486,
      "loss": 0.4058,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.2245623916387558,
      "learning_rate": 0.00048225447088747365,
      "loss": 0.4062,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.19265179336071014,
      "learning_rate": 0.0004819258499779824,
      "loss": 0.4055,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.17698857188224792,
      "learning_rate": 0.0004815972290684912,
      "loss": 0.4072,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.17338648438453674,
      "learning_rate": 0.00048126860815899997,
      "loss": 0.4049,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.17353032529354095,
      "learning_rate": 0.0004809399872495087,
      "loss": 0.4019,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.17427203059196472,
      "learning_rate": 0.0004806113663400175,
      "loss": 0.4057,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.18390071392059326,
      "learning_rate": 0.00048028274543052623,
      "loss": 0.4048,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.44211217761039734,
      "eval_runtime": 182.7759,
      "eval_samples_per_second": 956.92,
      "eval_steps_per_second": 29.905,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.1633845418691635,
      "learning_rate": 0.000479954124521035,
      "loss": 0.4046,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.18112096190452576,
      "learning_rate": 0.00047962550361154376,
      "loss": 0.4035,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.1799514889717102,
      "learning_rate": 0.00047929688270205255,
      "loss": 0.404,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.17908921837806702,
      "learning_rate": 0.00047896826179256134,
      "loss": 0.4034,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.1961556226015091,
      "learning_rate": 0.0004786396408830701,
      "loss": 0.4018,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.18264953792095184,
      "learning_rate": 0.0004783110199735789,
      "loss": 0.4013,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.1950681209564209,
      "learning_rate": 0.00047798239906408766,
      "loss": 0.4033,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.16139160096645355,
      "learning_rate": 0.00047765377815459645,
      "loss": 0.4009,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.16662371158599854,
      "learning_rate": 0.00047732515724510524,
      "loss": 0.4037,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.1918797791004181,
      "learning_rate": 0.000476996536335614,
      "loss": 0.402,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.16650977730751038,
      "learning_rate": 0.00047666791542612277,
      "loss": 0.4038,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.18112733960151672,
      "learning_rate": 0.0004763392945166315,
      "loss": 0.4023,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.1754048764705658,
      "learning_rate": 0.0004760106736071403,
      "loss": 0.4047,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.18675678968429565,
      "learning_rate": 0.0004756820526976491,
      "loss": 0.4008,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.17692361772060394,
      "learning_rate": 0.00047535343178815783,
      "loss": 0.4004,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.1945224106311798,
      "learning_rate": 0.0004750248108786666,
      "loss": 0.3999,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.1745007187128067,
      "learning_rate": 0.00047469618996917536,
      "loss": 0.402,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.16948354244232178,
      "learning_rate": 0.00047436756905968415,
      "loss": 0.4034,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.17728784680366516,
      "learning_rate": 0.0004740389481501929,
      "loss": 0.4013,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.17120669782161713,
      "learning_rate": 0.0004737103272407017,
      "loss": 0.4016,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.4387125074863434,
      "eval_runtime": 183.2741,
      "eval_samples_per_second": 954.319,
      "eval_steps_per_second": 29.824,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.1887926608324051,
      "learning_rate": 0.00047338170633121047,
      "loss": 0.4006,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.18002167344093323,
      "learning_rate": 0.0004730530854217192,
      "loss": 0.4024,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.17653575539588928,
      "learning_rate": 0.000472724464512228,
      "loss": 0.3982,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.16908098757266998,
      "learning_rate": 0.00047239584360273673,
      "loss": 0.4018,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.1857578158378601,
      "learning_rate": 0.0004720672226932455,
      "loss": 0.3989,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.1680462807416916,
      "learning_rate": 0.0004717386017837543,
      "loss": 0.4015,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.1721952110528946,
      "learning_rate": 0.00047140998087426305,
      "loss": 0.3991,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.18279604613780975,
      "learning_rate": 0.00047108135996477184,
      "loss": 0.3998,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.16130731999874115,
      "learning_rate": 0.0004707527390552806,
      "loss": 0.402,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.1568237692117691,
      "learning_rate": 0.00047042411814578937,
      "loss": 0.401,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.17591843008995056,
      "learning_rate": 0.00047009549723629816,
      "loss": 0.4024,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.1702214926481247,
      "learning_rate": 0.0004697668763268069,
      "loss": 0.3986,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.17657910287380219,
      "learning_rate": 0.00046943825541731574,
      "loss": 0.4005,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.17532747983932495,
      "learning_rate": 0.0004691096345078245,
      "loss": 0.3997,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.17669954895973206,
      "learning_rate": 0.00046878101359833327,
      "loss": 0.4016,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.16789251565933228,
      "learning_rate": 0.000468452392688842,
      "loss": 0.3995,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.1707916408777237,
      "learning_rate": 0.0004681237717793508,
      "loss": 0.3975,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.1860094964504242,
      "learning_rate": 0.0004677951508698596,
      "loss": 0.4,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.17650450766086578,
      "learning_rate": 0.00046746652996036833,
      "loss": 0.4007,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.16407670080661774,
      "learning_rate": 0.0004671379090508771,
      "loss": 0.3974,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.4182779788970947,
      "eval_runtime": 182.7001,
      "eval_samples_per_second": 957.317,
      "eval_steps_per_second": 29.918,
      "step": 30000
    },
    {
      "epoch": 1.223920954723809,
      "grad_norm": 0.19395990669727325,
      "learning_rate": 0.00046680928814138586,
      "loss": 0.3979,
      "step": 30100
    },
    {
      "epoch": 1.2279870697542035,
      "grad_norm": 0.18926838040351868,
      "learning_rate": 0.00046648066723189465,
      "loss": 0.3987,
      "step": 30200
    },
    {
      "epoch": 1.2320531847845975,
      "grad_norm": 0.1793399155139923,
      "learning_rate": 0.00046615204632240344,
      "loss": 0.3962,
      "step": 30300
    },
    {
      "epoch": 1.2361192998149917,
      "grad_norm": 0.17017994821071625,
      "learning_rate": 0.0004658234254129122,
      "loss": 0.4009,
      "step": 30400
    },
    {
      "epoch": 1.240185414845386,
      "grad_norm": 0.18166495859622955,
      "learning_rate": 0.00046549480450342097,
      "loss": 0.3979,
      "step": 30500
    },
    {
      "epoch": 1.2442515298757801,
      "grad_norm": 0.18200816214084625,
      "learning_rate": 0.0004651661835939297,
      "loss": 0.3977,
      "step": 30600
    },
    {
      "epoch": 1.2483176449061744,
      "grad_norm": 0.17918609082698822,
      "learning_rate": 0.0004648375626844385,
      "loss": 0.3962,
      "step": 30700
    },
    {
      "epoch": 1.2523837599365686,
      "grad_norm": 0.174868643283844,
      "learning_rate": 0.0004645089417749473,
      "loss": 0.4005,
      "step": 30800
    },
    {
      "epoch": 1.2564498749669628,
      "grad_norm": 0.16841137409210205,
      "learning_rate": 0.000464180320865456,
      "loss": 0.3994,
      "step": 30900
    },
    {
      "epoch": 1.260515989997357,
      "grad_norm": 0.1683836728334427,
      "learning_rate": 0.0004638516999559648,
      "loss": 0.3972,
      "step": 31000
    },
    {
      "epoch": 1.2645821050277513,
      "grad_norm": 0.1568969041109085,
      "learning_rate": 0.00046352307904647355,
      "loss": 0.3978,
      "step": 31100
    },
    {
      "epoch": 1.2686482200581455,
      "grad_norm": 0.16464075446128845,
      "learning_rate": 0.00046319445813698234,
      "loss": 0.3968,
      "step": 31200
    },
    {
      "epoch": 1.2727143350885397,
      "grad_norm": 0.16192105412483215,
      "learning_rate": 0.0004628658372274911,
      "loss": 0.3952,
      "step": 31300
    },
    {
      "epoch": 1.276780450118934,
      "grad_norm": 0.1809280812740326,
      "learning_rate": 0.00046253721631799987,
      "loss": 0.3996,
      "step": 31400
    },
    {
      "epoch": 1.2808465651493282,
      "grad_norm": 0.15491853654384613,
      "learning_rate": 0.00046220859540850866,
      "loss": 0.3944,
      "step": 31500
    },
    {
      "epoch": 1.2849126801797222,
      "grad_norm": 0.15890845656394958,
      "learning_rate": 0.0004618799744990174,
      "loss": 0.3964,
      "step": 31600
    },
    {
      "epoch": 1.2889787952101166,
      "grad_norm": 0.16692790389060974,
      "learning_rate": 0.0004615513535895262,
      "loss": 0.3964,
      "step": 31700
    },
    {
      "epoch": 1.2930449102405106,
      "grad_norm": 0.1608469933271408,
      "learning_rate": 0.0004612227326800349,
      "loss": 0.3937,
      "step": 31800
    },
    {
      "epoch": 1.297111025270905,
      "grad_norm": 0.16843947768211365,
      "learning_rate": 0.00046089411177054377,
      "loss": 0.3983,
      "step": 31900
    },
    {
      "epoch": 1.301177140301299,
      "grad_norm": 0.1676265448331833,
      "learning_rate": 0.00046056549086105256,
      "loss": 0.3976,
      "step": 32000
    },
    {
      "epoch": 1.301177140301299,
      "eval_loss": 0.4118121266365051,
      "eval_runtime": 182.6098,
      "eval_samples_per_second": 957.791,
      "eval_steps_per_second": 29.933,
      "step": 32000
    },
    {
      "epoch": 1.3052432553316933,
      "grad_norm": 0.16311919689178467,
      "learning_rate": 0.0004602368699515613,
      "loss": 0.3958,
      "step": 32100
    },
    {
      "epoch": 1.3093093703620875,
      "grad_norm": 0.16702140867710114,
      "learning_rate": 0.0004599082490420701,
      "loss": 0.3957,
      "step": 32200
    },
    {
      "epoch": 1.3133754853924817,
      "grad_norm": 0.1540537178516388,
      "learning_rate": 0.0004595796281325788,
      "loss": 0.3979,
      "step": 32300
    },
    {
      "epoch": 1.317441600422876,
      "grad_norm": 0.17295397818088531,
      "learning_rate": 0.0004592510072230876,
      "loss": 0.3967,
      "step": 32400
    },
    {
      "epoch": 1.3215077154532702,
      "grad_norm": 0.1699216514825821,
      "learning_rate": 0.0004589223863135964,
      "loss": 0.3941,
      "step": 32500
    },
    {
      "epoch": 1.3255738304836644,
      "grad_norm": 0.16909319162368774,
      "learning_rate": 0.00045859376540410515,
      "loss": 0.3953,
      "step": 32600
    },
    {
      "epoch": 1.3296399455140586,
      "grad_norm": 0.16375276446342468,
      "learning_rate": 0.00045826514449461394,
      "loss": 0.3945,
      "step": 32700
    },
    {
      "epoch": 1.3337060605444528,
      "grad_norm": 0.17382347583770752,
      "learning_rate": 0.0004579365235851227,
      "loss": 0.3946,
      "step": 32800
    },
    {
      "epoch": 1.337772175574847,
      "grad_norm": 0.16788601875305176,
      "learning_rate": 0.00045760790267563147,
      "loss": 0.3955,
      "step": 32900
    },
    {
      "epoch": 1.3418382906052413,
      "grad_norm": 0.17922332882881165,
      "learning_rate": 0.0004572792817661402,
      "loss": 0.3971,
      "step": 33000
    },
    {
      "epoch": 1.3459044056356355,
      "grad_norm": 0.17897984385490417,
      "learning_rate": 0.000456950660856649,
      "loss": 0.3958,
      "step": 33100
    },
    {
      "epoch": 1.3499705206660297,
      "grad_norm": 0.19032813608646393,
      "learning_rate": 0.0004566220399471578,
      "loss": 0.399,
      "step": 33200
    },
    {
      "epoch": 1.3540366356964237,
      "grad_norm": 0.15989892184734344,
      "learning_rate": 0.0004562934190376665,
      "loss": 0.3928,
      "step": 33300
    },
    {
      "epoch": 1.3581027507268182,
      "grad_norm": 0.16717933118343353,
      "learning_rate": 0.0004559647981281753,
      "loss": 0.3967,
      "step": 33400
    },
    {
      "epoch": 1.3621688657572122,
      "grad_norm": 0.1760602742433548,
      "learning_rate": 0.00045563617721868405,
      "loss": 0.3931,
      "step": 33500
    },
    {
      "epoch": 1.3662349807876064,
      "grad_norm": 0.16290415823459625,
      "learning_rate": 0.00045530755630919284,
      "loss": 0.3973,
      "step": 33600
    },
    {
      "epoch": 1.3703010958180006,
      "grad_norm": 0.17183691263198853,
      "learning_rate": 0.00045497893539970163,
      "loss": 0.3942,
      "step": 33700
    },
    {
      "epoch": 1.3743672108483949,
      "grad_norm": 0.16508899629116058,
      "learning_rate": 0.00045465031449021037,
      "loss": 0.3952,
      "step": 33800
    },
    {
      "epoch": 1.378433325878789,
      "grad_norm": 0.16833290457725525,
      "learning_rate": 0.00045432169358071916,
      "loss": 0.3926,
      "step": 33900
    },
    {
      "epoch": 1.3824994409091833,
      "grad_norm": 0.16974662244319916,
      "learning_rate": 0.0004539930726712279,
      "loss": 0.3953,
      "step": 34000
    },
    {
      "epoch": 1.3824994409091833,
      "eval_loss": 0.40921273827552795,
      "eval_runtime": 179.8978,
      "eval_samples_per_second": 972.23,
      "eval_steps_per_second": 30.384,
      "step": 34000
    },
    {
      "epoch": 1.3865655559395775,
      "grad_norm": 0.1865963190793991,
      "learning_rate": 0.0004536644517617367,
      "loss": 0.395,
      "step": 34100
    },
    {
      "epoch": 1.3906316709699718,
      "grad_norm": 0.16918990015983582,
      "learning_rate": 0.0004533358308522455,
      "loss": 0.3934,
      "step": 34200
    },
    {
      "epoch": 1.394697786000366,
      "grad_norm": 0.16736513376235962,
      "learning_rate": 0.0004530072099427542,
      "loss": 0.395,
      "step": 34300
    },
    {
      "epoch": 1.3987639010307602,
      "grad_norm": 0.1730073094367981,
      "learning_rate": 0.000452678589033263,
      "loss": 0.3952,
      "step": 34400
    },
    {
      "epoch": 1.4028300160611544,
      "grad_norm": 0.164739191532135,
      "learning_rate": 0.0004523499681237718,
      "loss": 0.3944,
      "step": 34500
    },
    {
      "epoch": 1.4068961310915487,
      "grad_norm": 0.1636328250169754,
      "learning_rate": 0.0004520213472142806,
      "loss": 0.3917,
      "step": 34600
    },
    {
      "epoch": 1.4109622461219429,
      "grad_norm": 0.19075725972652435,
      "learning_rate": 0.0004516927263047893,
      "loss": 0.3938,
      "step": 34700
    },
    {
      "epoch": 1.4150283611523369,
      "grad_norm": 0.1435059756040573,
      "learning_rate": 0.0004513641053952981,
      "loss": 0.3928,
      "step": 34800
    },
    {
      "epoch": 1.4190944761827313,
      "grad_norm": 0.1631442755460739,
      "learning_rate": 0.0004510354844858069,
      "loss": 0.3931,
      "step": 34900
    },
    {
      "epoch": 1.4231605912131253,
      "grad_norm": 0.17466998100280762,
      "learning_rate": 0.00045070686357631565,
      "loss": 0.3943,
      "step": 35000
    },
    {
      "epoch": 1.4272267062435195,
      "grad_norm": 0.17253455519676208,
      "learning_rate": 0.00045037824266682444,
      "loss": 0.394,
      "step": 35100
    },
    {
      "epoch": 1.4312928212739138,
      "grad_norm": 0.1649172455072403,
      "learning_rate": 0.0004500496217573332,
      "loss": 0.3948,
      "step": 35200
    },
    {
      "epoch": 1.435358936304308,
      "grad_norm": 0.15898999571800232,
      "learning_rate": 0.00044972100084784196,
      "loss": 0.3936,
      "step": 35300
    },
    {
      "epoch": 1.4394250513347022,
      "grad_norm": 0.15750063955783844,
      "learning_rate": 0.00044939237993835076,
      "loss": 0.3949,
      "step": 35400
    },
    {
      "epoch": 1.4434911663650964,
      "grad_norm": 0.1510254144668579,
      "learning_rate": 0.0004490637590288595,
      "loss": 0.3908,
      "step": 35500
    },
    {
      "epoch": 1.4475572813954907,
      "grad_norm": 0.15696173906326294,
      "learning_rate": 0.0004487351381193683,
      "loss": 0.3953,
      "step": 35600
    },
    {
      "epoch": 1.451623396425885,
      "grad_norm": 0.15199241042137146,
      "learning_rate": 0.000448406517209877,
      "loss": 0.3948,
      "step": 35700
    },
    {
      "epoch": 1.4556895114562791,
      "grad_norm": 0.16171258687973022,
      "learning_rate": 0.0004480778963003858,
      "loss": 0.3936,
      "step": 35800
    },
    {
      "epoch": 1.4597556264866733,
      "grad_norm": 0.16270864009857178,
      "learning_rate": 0.0004477492753908946,
      "loss": 0.3936,
      "step": 35900
    },
    {
      "epoch": 1.4638217415170676,
      "grad_norm": 0.16434581577777863,
      "learning_rate": 0.00044742065448140334,
      "loss": 0.3952,
      "step": 36000
    },
    {
      "epoch": 1.4638217415170676,
      "eval_loss": 0.40948066115379333,
      "eval_runtime": 180.1643,
      "eval_samples_per_second": 970.792,
      "eval_steps_per_second": 30.339,
      "step": 36000
    },
    {
      "epoch": 1.4678878565474618,
      "grad_norm": 0.15360088646411896,
      "learning_rate": 0.00044709203357191213,
      "loss": 0.3967,
      "step": 36100
    },
    {
      "epoch": 1.471953971577856,
      "grad_norm": 0.18275082111358643,
      "learning_rate": 0.00044676341266242087,
      "loss": 0.392,
      "step": 36200
    },
    {
      "epoch": 1.47602008660825,
      "grad_norm": 0.14581458270549774,
      "learning_rate": 0.00044643479175292966,
      "loss": 0.3935,
      "step": 36300
    },
    {
      "epoch": 1.4800862016386445,
      "grad_norm": 0.16350509226322174,
      "learning_rate": 0.0004461061708434384,
      "loss": 0.3936,
      "step": 36400
    },
    {
      "epoch": 1.4841523166690385,
      "grad_norm": 0.1542351245880127,
      "learning_rate": 0.0004457775499339472,
      "loss": 0.3922,
      "step": 36500
    },
    {
      "epoch": 1.488218431699433,
      "grad_norm": 0.17748412489891052,
      "learning_rate": 0.000445448929024456,
      "loss": 0.3951,
      "step": 36600
    },
    {
      "epoch": 1.492284546729827,
      "grad_norm": 0.17347417771816254,
      "learning_rate": 0.0004451203081149647,
      "loss": 0.3906,
      "step": 36700
    },
    {
      "epoch": 1.4963506617602211,
      "grad_norm": 0.1797999143600464,
      "learning_rate": 0.0004447916872054735,
      "loss": 0.3945,
      "step": 36800
    },
    {
      "epoch": 1.5004167767906154,
      "grad_norm": 0.1666792333126068,
      "learning_rate": 0.00044446306629598224,
      "loss": 0.3945,
      "step": 36900
    },
    {
      "epoch": 1.5044828918210096,
      "grad_norm": 0.18385113775730133,
      "learning_rate": 0.00044413444538649103,
      "loss": 0.3931,
      "step": 37000
    },
    {
      "epoch": 1.5085490068514038,
      "grad_norm": 0.1514722853899002,
      "learning_rate": 0.0004438058244769999,
      "loss": 0.3912,
      "step": 37100
    },
    {
      "epoch": 1.512615121881798,
      "grad_norm": 0.1666119396686554,
      "learning_rate": 0.0004434772035675086,
      "loss": 0.3928,
      "step": 37200
    },
    {
      "epoch": 1.5166812369121923,
      "grad_norm": 0.16498933732509613,
      "learning_rate": 0.0004431485826580174,
      "loss": 0.3919,
      "step": 37300
    },
    {
      "epoch": 1.5207473519425865,
      "grad_norm": 0.15782639384269714,
      "learning_rate": 0.00044281996174852614,
      "loss": 0.392,
      "step": 37400
    },
    {
      "epoch": 1.5248134669729807,
      "grad_norm": 0.15054215490818024,
      "learning_rate": 0.00044249134083903494,
      "loss": 0.3914,
      "step": 37500
    },
    {
      "epoch": 1.528879582003375,
      "grad_norm": 0.1583023965358734,
      "learning_rate": 0.00044216271992954373,
      "loss": 0.392,
      "step": 37600
    },
    {
      "epoch": 1.5329456970337692,
      "grad_norm": 0.1796552985906601,
      "learning_rate": 0.00044183409902005246,
      "loss": 0.3908,
      "step": 37700
    },
    {
      "epoch": 1.5370118120641632,
      "grad_norm": 0.15802063047885895,
      "learning_rate": 0.00044150547811056126,
      "loss": 0.3896,
      "step": 37800
    },
    {
      "epoch": 1.5410779270945576,
      "grad_norm": 0.1612427830696106,
      "learning_rate": 0.00044117685720107,
      "loss": 0.3897,
      "step": 37900
    },
    {
      "epoch": 1.5451440421249516,
      "grad_norm": 0.15274864435195923,
      "learning_rate": 0.0004408482362915788,
      "loss": 0.3921,
      "step": 38000
    },
    {
      "epoch": 1.5451440421249516,
      "eval_loss": 0.41768181324005127,
      "eval_runtime": 180.1941,
      "eval_samples_per_second": 970.631,
      "eval_steps_per_second": 30.334,
      "step": 38000
    },
    {
      "epoch": 1.549210157155346,
      "grad_norm": 0.1678156554698944,
      "learning_rate": 0.0004405196153820875,
      "loss": 0.3934,
      "step": 38100
    },
    {
      "epoch": 1.55327627218574,
      "grad_norm": 0.15342995524406433,
      "learning_rate": 0.0004401909944725963,
      "loss": 0.3918,
      "step": 38200
    },
    {
      "epoch": 1.5573423872161345,
      "grad_norm": 0.15914219617843628,
      "learning_rate": 0.0004398623735631051,
      "loss": 0.3907,
      "step": 38300
    },
    {
      "epoch": 1.5614085022465285,
      "grad_norm": 0.17206837236881256,
      "learning_rate": 0.00043953375265361384,
      "loss": 0.3905,
      "step": 38400
    },
    {
      "epoch": 1.5654746172769227,
      "grad_norm": 0.16275349259376526,
      "learning_rate": 0.00043920513174412263,
      "loss": 0.388,
      "step": 38500
    },
    {
      "epoch": 1.569540732307317,
      "grad_norm": 0.15376850962638855,
      "learning_rate": 0.00043887651083463137,
      "loss": 0.3909,
      "step": 38600
    },
    {
      "epoch": 1.5736068473377112,
      "grad_norm": 0.1737605184316635,
      "learning_rate": 0.00043854788992514016,
      "loss": 0.3892,
      "step": 38700
    },
    {
      "epoch": 1.5776729623681054,
      "grad_norm": 0.1582973152399063,
      "learning_rate": 0.00043821926901564895,
      "loss": 0.3929,
      "step": 38800
    },
    {
      "epoch": 1.5817390773984996,
      "grad_norm": 0.16082145273685455,
      "learning_rate": 0.0004378906481061577,
      "loss": 0.3909,
      "step": 38900
    },
    {
      "epoch": 1.5858051924288938,
      "grad_norm": 0.1577177494764328,
      "learning_rate": 0.0004375620271966665,
      "loss": 0.3923,
      "step": 39000
    },
    {
      "epoch": 1.589871307459288,
      "grad_norm": 0.16700029373168945,
      "learning_rate": 0.0004372334062871752,
      "loss": 0.3918,
      "step": 39100
    },
    {
      "epoch": 1.5939374224896823,
      "grad_norm": 0.14457987248897552,
      "learning_rate": 0.000436904785377684,
      "loss": 0.3923,
      "step": 39200
    },
    {
      "epoch": 1.5980035375200763,
      "grad_norm": 0.16143108904361725,
      "learning_rate": 0.0004365761644681928,
      "loss": 0.3897,
      "step": 39300
    },
    {
      "epoch": 1.6020696525504707,
      "grad_norm": 0.17086677253246307,
      "learning_rate": 0.00043624754355870153,
      "loss": 0.3893,
      "step": 39400
    },
    {
      "epoch": 1.6061357675808647,
      "grad_norm": 0.17447222769260406,
      "learning_rate": 0.0004359189226492103,
      "loss": 0.3902,
      "step": 39500
    },
    {
      "epoch": 1.6102018826112592,
      "grad_norm": 0.17602626979351044,
      "learning_rate": 0.00043559030173971906,
      "loss": 0.3872,
      "step": 39600
    },
    {
      "epoch": 1.6142679976416532,
      "grad_norm": 0.1610378473997116,
      "learning_rate": 0.00043526168083022785,
      "loss": 0.3904,
      "step": 39700
    },
    {
      "epoch": 1.6183341126720476,
      "grad_norm": 0.15753309428691864,
      "learning_rate": 0.0004349330599207367,
      "loss": 0.3876,
      "step": 39800
    },
    {
      "epoch": 1.6224002277024416,
      "grad_norm": 0.1836956888437271,
      "learning_rate": 0.00043460443901124544,
      "loss": 0.3911,
      "step": 39900
    },
    {
      "epoch": 1.6264663427328359,
      "grad_norm": 0.15416084229946136,
      "learning_rate": 0.0004342758181017542,
      "loss": 0.3902,
      "step": 40000
    },
    {
      "epoch": 1.6264663427328359,
      "eval_loss": 0.40029191970825195,
      "eval_runtime": 180.2498,
      "eval_samples_per_second": 970.331,
      "eval_steps_per_second": 30.325,
      "step": 40000
    },
    {
      "epoch": 1.63053245776323,
      "grad_norm": 0.1725672036409378,
      "learning_rate": 0.00043394719719226296,
      "loss": 0.3929,
      "step": 40100
    },
    {
      "epoch": 1.6345985727936243,
      "grad_norm": 0.17050452530384064,
      "learning_rate": 0.00043361857628277175,
      "loss": 0.387,
      "step": 40200
    },
    {
      "epoch": 1.6386646878240185,
      "grad_norm": 0.15722711384296417,
      "learning_rate": 0.0004332899553732805,
      "loss": 0.3922,
      "step": 40300
    },
    {
      "epoch": 1.6427308028544128,
      "grad_norm": 0.16886116564273834,
      "learning_rate": 0.0004329613344637893,
      "loss": 0.3904,
      "step": 40400
    },
    {
      "epoch": 1.646796917884807,
      "grad_norm": 0.16731801629066467,
      "learning_rate": 0.0004326327135542981,
      "loss": 0.3911,
      "step": 40500
    },
    {
      "epoch": 1.6508630329152012,
      "grad_norm": 0.1659964621067047,
      "learning_rate": 0.0004323040926448068,
      "loss": 0.3878,
      "step": 40600
    },
    {
      "epoch": 1.6549291479455954,
      "grad_norm": 0.1624077558517456,
      "learning_rate": 0.0004319754717353156,
      "loss": 0.3907,
      "step": 40700
    },
    {
      "epoch": 1.6589952629759894,
      "grad_norm": 0.17315621674060822,
      "learning_rate": 0.00043164685082582434,
      "loss": 0.3891,
      "step": 40800
    },
    {
      "epoch": 1.6630613780063839,
      "grad_norm": 0.16864630579948425,
      "learning_rate": 0.00043131822991633313,
      "loss": 0.389,
      "step": 40900
    },
    {
      "epoch": 1.6671274930367779,
      "grad_norm": 0.17347697913646698,
      "learning_rate": 0.0004309896090068419,
      "loss": 0.3891,
      "step": 41000
    },
    {
      "epoch": 1.6711936080671723,
      "grad_norm": 0.16273026168346405,
      "learning_rate": 0.00043066098809735066,
      "loss": 0.3879,
      "step": 41100
    },
    {
      "epoch": 1.6752597230975663,
      "grad_norm": 0.17344634234905243,
      "learning_rate": 0.00043033236718785945,
      "loss": 0.3896,
      "step": 41200
    },
    {
      "epoch": 1.6793258381279608,
      "grad_norm": 0.15843278169631958,
      "learning_rate": 0.0004300037462783682,
      "loss": 0.3897,
      "step": 41300
    },
    {
      "epoch": 1.6833919531583548,
      "grad_norm": 0.17296206951141357,
      "learning_rate": 0.000429675125368877,
      "loss": 0.3896,
      "step": 41400
    },
    {
      "epoch": 1.6874580681887492,
      "grad_norm": 0.16498510539531708,
      "learning_rate": 0.00042934650445938577,
      "loss": 0.391,
      "step": 41500
    },
    {
      "epoch": 1.6915241832191432,
      "grad_norm": 0.16094407439231873,
      "learning_rate": 0.0004290178835498945,
      "loss": 0.3912,
      "step": 41600
    },
    {
      "epoch": 1.6955902982495374,
      "grad_norm": 0.17194397747516632,
      "learning_rate": 0.0004286892626404033,
      "loss": 0.3892,
      "step": 41700
    },
    {
      "epoch": 1.6996564132799317,
      "grad_norm": 0.16032160818576813,
      "learning_rate": 0.00042836064173091203,
      "loss": 0.3878,
      "step": 41800
    },
    {
      "epoch": 1.703722528310326,
      "grad_norm": 0.14595960080623627,
      "learning_rate": 0.0004280320208214208,
      "loss": 0.3887,
      "step": 41900
    },
    {
      "epoch": 1.7077886433407201,
      "grad_norm": 0.17073261737823486,
      "learning_rate": 0.00042770339991192956,
      "loss": 0.3874,
      "step": 42000
    },
    {
      "epoch": 1.7077886433407201,
      "eval_loss": 0.4093453884124756,
      "eval_runtime": 179.5463,
      "eval_samples_per_second": 974.133,
      "eval_steps_per_second": 30.443,
      "step": 42000
    },
    {
      "epoch": 1.7118547583711143,
      "grad_norm": 0.16186510026454926,
      "learning_rate": 0.00042737477900243835,
      "loss": 0.3863,
      "step": 42100
    },
    {
      "epoch": 1.7159208734015086,
      "grad_norm": 0.15853260457515717,
      "learning_rate": 0.00042704615809294714,
      "loss": 0.3874,
      "step": 42200
    },
    {
      "epoch": 1.7199869884319028,
      "grad_norm": 0.16473126411437988,
      "learning_rate": 0.0004267175371834559,
      "loss": 0.3897,
      "step": 42300
    },
    {
      "epoch": 1.724053103462297,
      "grad_norm": 0.17384326457977295,
      "learning_rate": 0.0004263889162739647,
      "loss": 0.3868,
      "step": 42400
    },
    {
      "epoch": 1.728119218492691,
      "grad_norm": 0.18053624033927917,
      "learning_rate": 0.00042606029536447346,
      "loss": 0.3885,
      "step": 42500
    },
    {
      "epoch": 1.7321853335230855,
      "grad_norm": 0.16999398171901703,
      "learning_rate": 0.00042573167445498225,
      "loss": 0.3902,
      "step": 42600
    },
    {
      "epoch": 1.7362514485534795,
      "grad_norm": 0.1528620570898056,
      "learning_rate": 0.00042540305354549105,
      "loss": 0.3872,
      "step": 42700
    },
    {
      "epoch": 1.740317563583874,
      "grad_norm": 0.16258525848388672,
      "learning_rate": 0.0004250744326359998,
      "loss": 0.3868,
      "step": 42800
    },
    {
      "epoch": 1.744383678614268,
      "grad_norm": 0.1657133847475052,
      "learning_rate": 0.0004247458117265086,
      "loss": 0.3904,
      "step": 42900
    },
    {
      "epoch": 1.7484497936446624,
      "grad_norm": 0.1863744705915451,
      "learning_rate": 0.0004244171908170173,
      "loss": 0.3893,
      "step": 43000
    },
    {
      "epoch": 1.7525159086750564,
      "grad_norm": 0.1672133207321167,
      "learning_rate": 0.0004240885699075261,
      "loss": 0.387,
      "step": 43100
    },
    {
      "epoch": 1.7565820237054506,
      "grad_norm": 0.1619899570941925,
      "learning_rate": 0.0004237599489980349,
      "loss": 0.3861,
      "step": 43200
    },
    {
      "epoch": 1.7606481387358448,
      "grad_norm": 0.15628735721111298,
      "learning_rate": 0.00042343132808854363,
      "loss": 0.388,
      "step": 43300
    },
    {
      "epoch": 1.764714253766239,
      "grad_norm": 0.1661934107542038,
      "learning_rate": 0.0004231027071790524,
      "loss": 0.3856,
      "step": 43400
    },
    {
      "epoch": 1.7687803687966333,
      "grad_norm": 0.17207132279872894,
      "learning_rate": 0.00042277408626956116,
      "loss": 0.3865,
      "step": 43500
    },
    {
      "epoch": 1.7728464838270275,
      "grad_norm": 0.16632573306560516,
      "learning_rate": 0.00042244546536006995,
      "loss": 0.3901,
      "step": 43600
    },
    {
      "epoch": 1.7769125988574217,
      "grad_norm": 0.16740518808364868,
      "learning_rate": 0.0004221168444505787,
      "loss": 0.3897,
      "step": 43700
    },
    {
      "epoch": 1.780978713887816,
      "grad_norm": 0.15919458866119385,
      "learning_rate": 0.0004217882235410875,
      "loss": 0.3872,
      "step": 43800
    },
    {
      "epoch": 1.7850448289182101,
      "grad_norm": 0.1734834909439087,
      "learning_rate": 0.00042145960263159627,
      "loss": 0.3876,
      "step": 43900
    },
    {
      "epoch": 1.7891109439486041,
      "grad_norm": 0.15735432505607605,
      "learning_rate": 0.000421130981722105,
      "loss": 0.3883,
      "step": 44000
    },
    {
      "epoch": 1.7891109439486041,
      "eval_loss": 0.4024648368358612,
      "eval_runtime": 179.8371,
      "eval_samples_per_second": 972.558,
      "eval_steps_per_second": 30.394,
      "step": 44000
    },
    {
      "epoch": 1.7931770589789986,
      "grad_norm": 0.20064181089401245,
      "learning_rate": 0.0004208023608126138,
      "loss": 0.3882,
      "step": 44100
    },
    {
      "epoch": 1.7972431740093926,
      "grad_norm": 0.16825421154499054,
      "learning_rate": 0.00042047373990312253,
      "loss": 0.3885,
      "step": 44200
    },
    {
      "epoch": 1.801309289039787,
      "grad_norm": 0.16880282759666443,
      "learning_rate": 0.0004201451189936313,
      "loss": 0.3865,
      "step": 44300
    },
    {
      "epoch": 1.805375404070181,
      "grad_norm": 0.17154674232006073,
      "learning_rate": 0.0004198164980841401,
      "loss": 0.3874,
      "step": 44400
    },
    {
      "epoch": 1.8094415191005755,
      "grad_norm": 0.15681657195091248,
      "learning_rate": 0.00041948787717464885,
      "loss": 0.3872,
      "step": 44500
    },
    {
      "epoch": 1.8135076341309695,
      "grad_norm": 0.160089373588562,
      "learning_rate": 0.00041915925626515764,
      "loss": 0.3874,
      "step": 44600
    },
    {
      "epoch": 1.817573749161364,
      "grad_norm": 0.17461763322353363,
      "learning_rate": 0.0004188306353556664,
      "loss": 0.3862,
      "step": 44700
    },
    {
      "epoch": 1.821639864191758,
      "grad_norm": 0.16129173338413239,
      "learning_rate": 0.00041850201444617517,
      "loss": 0.388,
      "step": 44800
    },
    {
      "epoch": 1.8257059792221522,
      "grad_norm": 0.1867111623287201,
      "learning_rate": 0.00041817339353668396,
      "loss": 0.3862,
      "step": 44900
    },
    {
      "epoch": 1.8297720942525464,
      "grad_norm": 0.17514640092849731,
      "learning_rate": 0.0004178447726271927,
      "loss": 0.3875,
      "step": 45000
    },
    {
      "epoch": 1.8338382092829406,
      "grad_norm": 0.16434159874916077,
      "learning_rate": 0.00041751615171770154,
      "loss": 0.3853,
      "step": 45100
    },
    {
      "epoch": 1.8379043243133348,
      "grad_norm": 0.1566360890865326,
      "learning_rate": 0.0004171875308082103,
      "loss": 0.3878,
      "step": 45200
    },
    {
      "epoch": 1.841970439343729,
      "grad_norm": 0.18651843070983887,
      "learning_rate": 0.00041685890989871907,
      "loss": 0.3851,
      "step": 45300
    },
    {
      "epoch": 1.8460365543741233,
      "grad_norm": 0.1778472512960434,
      "learning_rate": 0.0004165302889892278,
      "loss": 0.3844,
      "step": 45400
    },
    {
      "epoch": 1.8501026694045175,
      "grad_norm": 0.15949928760528564,
      "learning_rate": 0.0004162016680797366,
      "loss": 0.3876,
      "step": 45500
    },
    {
      "epoch": 1.8541687844349117,
      "grad_norm": 0.1598343700170517,
      "learning_rate": 0.0004158730471702454,
      "loss": 0.386,
      "step": 45600
    },
    {
      "epoch": 1.8582348994653057,
      "grad_norm": 0.14708025753498077,
      "learning_rate": 0.00041554442626075413,
      "loss": 0.3877,
      "step": 45700
    },
    {
      "epoch": 1.8623010144957002,
      "grad_norm": 0.17416438460350037,
      "learning_rate": 0.0004152158053512629,
      "loss": 0.3862,
      "step": 45800
    },
    {
      "epoch": 1.8663671295260942,
      "grad_norm": 0.1651112139225006,
      "learning_rate": 0.00041488718444177166,
      "loss": 0.3883,
      "step": 45900
    },
    {
      "epoch": 1.8704332445564886,
      "grad_norm": 0.17381228506565094,
      "learning_rate": 0.00041455856353228045,
      "loss": 0.3846,
      "step": 46000
    },
    {
      "epoch": 1.8704332445564886,
      "eval_loss": 0.3992159366607666,
      "eval_runtime": 180.0938,
      "eval_samples_per_second": 971.172,
      "eval_steps_per_second": 30.351,
      "step": 46000
    },
    {
      "epoch": 1.8744993595868826,
      "grad_norm": 0.16857610642910004,
      "learning_rate": 0.00041422994262278924,
      "loss": 0.3877,
      "step": 46100
    },
    {
      "epoch": 1.878565474617277,
      "grad_norm": 0.17139647901058197,
      "learning_rate": 0.000413901321713298,
      "loss": 0.385,
      "step": 46200
    },
    {
      "epoch": 1.882631589647671,
      "grad_norm": 0.17286048829555511,
      "learning_rate": 0.00041357270080380677,
      "loss": 0.3876,
      "step": 46300
    },
    {
      "epoch": 1.8866977046780653,
      "grad_norm": 0.17704889178276062,
      "learning_rate": 0.0004132440798943155,
      "loss": 0.3864,
      "step": 46400
    },
    {
      "epoch": 1.8907638197084595,
      "grad_norm": 0.17383939027786255,
      "learning_rate": 0.0004129154589848243,
      "loss": 0.3856,
      "step": 46500
    },
    {
      "epoch": 1.8948299347388537,
      "grad_norm": 0.17805993556976318,
      "learning_rate": 0.0004125868380753331,
      "loss": 0.3865,
      "step": 46600
    },
    {
      "epoch": 1.898896049769248,
      "grad_norm": 0.16704945266246796,
      "learning_rate": 0.0004122582171658418,
      "loss": 0.3876,
      "step": 46700
    },
    {
      "epoch": 1.9029621647996422,
      "grad_norm": 0.16994690895080566,
      "learning_rate": 0.0004119295962563506,
      "loss": 0.3864,
      "step": 46800
    },
    {
      "epoch": 1.9070282798300364,
      "grad_norm": 0.16642150282859802,
      "learning_rate": 0.00041160097534685935,
      "loss": 0.386,
      "step": 46900
    },
    {
      "epoch": 1.9110943948604306,
      "grad_norm": 0.16162297129631042,
      "learning_rate": 0.00041127235443736814,
      "loss": 0.3884,
      "step": 47000
    },
    {
      "epoch": 1.9151605098908249,
      "grad_norm": 0.1599271595478058,
      "learning_rate": 0.0004109437335278769,
      "loss": 0.3886,
      "step": 47100
    },
    {
      "epoch": 1.9192266249212189,
      "grad_norm": 0.16271963715553284,
      "learning_rate": 0.00041061511261838567,
      "loss": 0.387,
      "step": 47200
    },
    {
      "epoch": 1.9232927399516133,
      "grad_norm": 0.1804547756910324,
      "learning_rate": 0.00041028649170889446,
      "loss": 0.3863,
      "step": 47300
    },
    {
      "epoch": 1.9273588549820073,
      "grad_norm": 0.16225716471672058,
      "learning_rate": 0.0004099578707994032,
      "loss": 0.3861,
      "step": 47400
    },
    {
      "epoch": 1.9314249700124018,
      "grad_norm": 0.16281339526176453,
      "learning_rate": 0.000409629249889912,
      "loss": 0.3888,
      "step": 47500
    },
    {
      "epoch": 1.9354910850427958,
      "grad_norm": 0.1490621417760849,
      "learning_rate": 0.0004093006289804207,
      "loss": 0.3841,
      "step": 47600
    },
    {
      "epoch": 1.9395572000731902,
      "grad_norm": 0.17073015868663788,
      "learning_rate": 0.00040897200807092957,
      "loss": 0.385,
      "step": 47700
    },
    {
      "epoch": 1.9436233151035842,
      "grad_norm": 0.18141047656536102,
      "learning_rate": 0.00040864338716143836,
      "loss": 0.3868,
      "step": 47800
    },
    {
      "epoch": 1.9476894301339784,
      "grad_norm": 0.19913238286972046,
      "learning_rate": 0.0004083147662519471,
      "loss": 0.3885,
      "step": 47900
    },
    {
      "epoch": 1.9517555451643727,
      "grad_norm": 0.17725451290607452,
      "learning_rate": 0.0004079861453424559,
      "loss": 0.3852,
      "step": 48000
    },
    {
      "epoch": 1.9517555451643727,
      "eval_loss": 0.3955751955509186,
      "eval_runtime": 179.2246,
      "eval_samples_per_second": 975.882,
      "eval_steps_per_second": 30.498,
      "step": 48000
    },
    {
      "epoch": 1.9558216601947669,
      "grad_norm": 0.17843759059906006,
      "learning_rate": 0.00040765752443296463,
      "loss": 0.384,
      "step": 48100
    },
    {
      "epoch": 1.959887775225161,
      "grad_norm": 0.15729734301567078,
      "learning_rate": 0.0004073289035234734,
      "loss": 0.3868,
      "step": 48200
    },
    {
      "epoch": 1.9639538902555553,
      "grad_norm": 0.15808047354221344,
      "learning_rate": 0.0004070002826139822,
      "loss": 0.3846,
      "step": 48300
    },
    {
      "epoch": 1.9680200052859496,
      "grad_norm": 0.16176244616508484,
      "learning_rate": 0.00040667166170449095,
      "loss": 0.3841,
      "step": 48400
    },
    {
      "epoch": 1.9720861203163438,
      "grad_norm": 0.17742346227169037,
      "learning_rate": 0.00040634304079499974,
      "loss": 0.3853,
      "step": 48500
    },
    {
      "epoch": 1.976152235346738,
      "grad_norm": 0.1632872223854065,
      "learning_rate": 0.0004060144198855085,
      "loss": 0.3868,
      "step": 48600
    },
    {
      "epoch": 1.980218350377132,
      "grad_norm": 0.20529578626155853,
      "learning_rate": 0.00040568579897601727,
      "loss": 0.3859,
      "step": 48700
    },
    {
      "epoch": 1.9842844654075265,
      "grad_norm": 0.17432677745819092,
      "learning_rate": 0.000405357178066526,
      "loss": 0.3869,
      "step": 48800
    },
    {
      "epoch": 1.9883505804379205,
      "grad_norm": 0.18018126487731934,
      "learning_rate": 0.0004050285571570348,
      "loss": 0.3816,
      "step": 48900
    },
    {
      "epoch": 1.992416695468315,
      "grad_norm": 0.17033278942108154,
      "learning_rate": 0.0004046999362475436,
      "loss": 0.3865,
      "step": 49000
    },
    {
      "epoch": 1.996482810498709,
      "grad_norm": 0.16012980043888092,
      "learning_rate": 0.0004043713153380523,
      "loss": 0.3825,
      "step": 49100
    },
    {
      "epoch": 2.0005489255291034,
      "grad_norm": 0.17918436229228973,
      "learning_rate": 0.0004040426944285611,
      "loss": 0.3823,
      "step": 49200
    },
    {
      "epoch": 2.0046150405594974,
      "grad_norm": 0.16124385595321655,
      "learning_rate": 0.00040371407351906985,
      "loss": 0.3843,
      "step": 49300
    },
    {
      "epoch": 2.008681155589892,
      "grad_norm": 0.16861467063426971,
      "learning_rate": 0.00040338545260957864,
      "loss": 0.3818,
      "step": 49400
    },
    {
      "epoch": 2.012747270620286,
      "grad_norm": 0.1777329444885254,
      "learning_rate": 0.00040305683170008743,
      "loss": 0.3825,
      "step": 49500
    },
    {
      "epoch": 2.0168133856506802,
      "grad_norm": 0.1526820808649063,
      "learning_rate": 0.00040272821079059617,
      "loss": 0.3798,
      "step": 49600
    },
    {
      "epoch": 2.0208795006810742,
      "grad_norm": 0.19031424820423126,
      "learning_rate": 0.00040239958988110496,
      "loss": 0.3835,
      "step": 49700
    },
    {
      "epoch": 2.0249456157114687,
      "grad_norm": 0.16882801055908203,
      "learning_rate": 0.0004020709689716137,
      "loss": 0.3819,
      "step": 49800
    },
    {
      "epoch": 2.0290117307418627,
      "grad_norm": 0.17263294756412506,
      "learning_rate": 0.0004017423480621225,
      "loss": 0.3818,
      "step": 49900
    },
    {
      "epoch": 2.0330778457722567,
      "grad_norm": 0.19291962683200836,
      "learning_rate": 0.0004014137271526313,
      "loss": 0.3835,
      "step": 50000
    },
    {
      "epoch": 2.0330778457722567,
      "eval_loss": 0.40070900321006775,
      "eval_runtime": 180.0312,
      "eval_samples_per_second": 971.509,
      "eval_steps_per_second": 30.361,
      "step": 50000
    },
    {
      "epoch": 2.037143960802651,
      "grad_norm": 0.16950516402721405,
      "learning_rate": 0.00040108510624314,
      "loss": 0.385,
      "step": 50100
    },
    {
      "epoch": 2.041210075833045,
      "grad_norm": 0.1757151484489441,
      "learning_rate": 0.0004007564853336488,
      "loss": 0.382,
      "step": 50200
    },
    {
      "epoch": 2.0452761908634396,
      "grad_norm": 0.15545111894607544,
      "learning_rate": 0.0004004278644241576,
      "loss": 0.3815,
      "step": 50300
    },
    {
      "epoch": 2.0493423058938336,
      "grad_norm": 0.1811090111732483,
      "learning_rate": 0.0004000992435146664,
      "loss": 0.3815,
      "step": 50400
    },
    {
      "epoch": 2.053408420924228,
      "grad_norm": 0.1768469363451004,
      "learning_rate": 0.00039977062260517513,
      "loss": 0.3852,
      "step": 50500
    },
    {
      "epoch": 2.057474535954622,
      "grad_norm": 0.15021084249019623,
      "learning_rate": 0.0003994420016956839,
      "loss": 0.383,
      "step": 50600
    },
    {
      "epoch": 2.0615406509850165,
      "grad_norm": 0.17704324424266815,
      "learning_rate": 0.0003991133807861927,
      "loss": 0.3808,
      "step": 50700
    },
    {
      "epoch": 2.0656067660154105,
      "grad_norm": 0.17683333158493042,
      "learning_rate": 0.00039878475987670145,
      "loss": 0.3813,
      "step": 50800
    },
    {
      "epoch": 2.069672881045805,
      "grad_norm": 0.19612325727939606,
      "learning_rate": 0.00039845613896721024,
      "loss": 0.3831,
      "step": 50900
    },
    {
      "epoch": 2.073738996076199,
      "grad_norm": 0.18775209784507751,
      "learning_rate": 0.000398127518057719,
      "loss": 0.382,
      "step": 51000
    },
    {
      "epoch": 2.0778051111065934,
      "grad_norm": 0.15501828491687775,
      "learning_rate": 0.00039779889714822777,
      "loss": 0.382,
      "step": 51100
    },
    {
      "epoch": 2.0818712261369874,
      "grad_norm": 0.16481256484985352,
      "learning_rate": 0.00039747027623873656,
      "loss": 0.3824,
      "step": 51200
    },
    {
      "epoch": 2.085937341167382,
      "grad_norm": 0.1842055320739746,
      "learning_rate": 0.0003971416553292453,
      "loss": 0.3827,
      "step": 51300
    },
    {
      "epoch": 2.090003456197776,
      "grad_norm": 0.187832310795784,
      "learning_rate": 0.0003968130344197541,
      "loss": 0.3826,
      "step": 51400
    },
    {
      "epoch": 2.09406957122817,
      "grad_norm": 0.19207066297531128,
      "learning_rate": 0.0003964844135102628,
      "loss": 0.3827,
      "step": 51500
    },
    {
      "epoch": 2.0981356862585643,
      "grad_norm": 0.17123517394065857,
      "learning_rate": 0.0003961557926007716,
      "loss": 0.3833,
      "step": 51600
    },
    {
      "epoch": 2.1022018012889583,
      "grad_norm": 0.1858905851840973,
      "learning_rate": 0.0003958271716912804,
      "loss": 0.3833,
      "step": 51700
    },
    {
      "epoch": 2.1062679163193527,
      "grad_norm": 0.16532449424266815,
      "learning_rate": 0.00039549855078178914,
      "loss": 0.3799,
      "step": 51800
    },
    {
      "epoch": 2.1103340313497467,
      "grad_norm": 0.16950100660324097,
      "learning_rate": 0.00039516992987229793,
      "loss": 0.3836,
      "step": 51900
    },
    {
      "epoch": 2.114400146380141,
      "grad_norm": 0.19691959023475647,
      "learning_rate": 0.00039484130896280667,
      "loss": 0.3823,
      "step": 52000
    },
    {
      "epoch": 2.114400146380141,
      "eval_loss": 0.3948642909526825,
      "eval_runtime": 180.6517,
      "eval_samples_per_second": 968.173,
      "eval_steps_per_second": 30.257,
      "step": 52000
    },
    {
      "epoch": 2.118466261410535,
      "grad_norm": 0.16426175832748413,
      "learning_rate": 0.00039451268805331546,
      "loss": 0.382,
      "step": 52100
    },
    {
      "epoch": 2.1225323764409296,
      "grad_norm": 0.19762416183948517,
      "learning_rate": 0.0003941840671438242,
      "loss": 0.3841,
      "step": 52200
    },
    {
      "epoch": 2.1265984914713236,
      "grad_norm": 0.16929273307323456,
      "learning_rate": 0.000393855446234333,
      "loss": 0.3836,
      "step": 52300
    },
    {
      "epoch": 2.130664606501718,
      "grad_norm": 0.17707234621047974,
      "learning_rate": 0.0003935268253248418,
      "loss": 0.3823,
      "step": 52400
    },
    {
      "epoch": 2.134730721532112,
      "grad_norm": 0.20768453180789948,
      "learning_rate": 0.0003931982044153505,
      "loss": 0.382,
      "step": 52500
    },
    {
      "epoch": 2.1387968365625065,
      "grad_norm": 0.1694677621126175,
      "learning_rate": 0.0003928695835058593,
      "loss": 0.3837,
      "step": 52600
    },
    {
      "epoch": 2.1428629515929005,
      "grad_norm": 0.19343188405036926,
      "learning_rate": 0.00039254096259636805,
      "loss": 0.3827,
      "step": 52700
    },
    {
      "epoch": 2.146929066623295,
      "grad_norm": 0.1825736165046692,
      "learning_rate": 0.00039221234168687684,
      "loss": 0.3796,
      "step": 52800
    },
    {
      "epoch": 2.150995181653689,
      "grad_norm": 0.19006511569023132,
      "learning_rate": 0.0003918837207773857,
      "loss": 0.3829,
      "step": 52900
    },
    {
      "epoch": 2.1550612966840834,
      "grad_norm": 0.16769222915172577,
      "learning_rate": 0.0003915550998678944,
      "loss": 0.3838,
      "step": 53000
    },
    {
      "epoch": 2.1591274117144774,
      "grad_norm": 0.18791767954826355,
      "learning_rate": 0.0003912264789584032,
      "loss": 0.3804,
      "step": 53100
    },
    {
      "epoch": 2.1631935267448714,
      "grad_norm": 0.1732776165008545,
      "learning_rate": 0.00039089785804891195,
      "loss": 0.3789,
      "step": 53200
    },
    {
      "epoch": 2.167259641775266,
      "grad_norm": 0.1756104975938797,
      "learning_rate": 0.00039056923713942074,
      "loss": 0.3822,
      "step": 53300
    },
    {
      "epoch": 2.17132575680566,
      "grad_norm": 0.15611065924167633,
      "learning_rate": 0.00039024061622992953,
      "loss": 0.3824,
      "step": 53400
    },
    {
      "epoch": 2.1753918718360543,
      "grad_norm": 0.17049533128738403,
      "learning_rate": 0.00038991199532043827,
      "loss": 0.3804,
      "step": 53500
    },
    {
      "epoch": 2.1794579868664483,
      "grad_norm": 0.17108318209648132,
      "learning_rate": 0.00038958337441094706,
      "loss": 0.3811,
      "step": 53600
    },
    {
      "epoch": 2.1835241018968428,
      "grad_norm": 0.19021452963352203,
      "learning_rate": 0.0003892547535014558,
      "loss": 0.3804,
      "step": 53700
    },
    {
      "epoch": 2.1875902169272368,
      "grad_norm": 0.17601363360881805,
      "learning_rate": 0.0003889261325919646,
      "loss": 0.3815,
      "step": 53800
    },
    {
      "epoch": 2.191656331957631,
      "grad_norm": 0.16927701234817505,
      "learning_rate": 0.0003885975116824733,
      "loss": 0.3828,
      "step": 53900
    },
    {
      "epoch": 2.195722446988025,
      "grad_norm": 0.17231962084770203,
      "learning_rate": 0.0003882688907729821,
      "loss": 0.3825,
      "step": 54000
    },
    {
      "epoch": 2.195722446988025,
      "eval_loss": 0.3921763002872467,
      "eval_runtime": 180.683,
      "eval_samples_per_second": 968.005,
      "eval_steps_per_second": 30.252,
      "step": 54000
    },
    {
      "epoch": 2.1997885620184197,
      "grad_norm": 0.16866815090179443,
      "learning_rate": 0.0003879402698634909,
      "loss": 0.3813,
      "step": 54100
    },
    {
      "epoch": 2.2038546770488137,
      "grad_norm": 0.16593506932258606,
      "learning_rate": 0.00038761164895399964,
      "loss": 0.3808,
      "step": 54200
    },
    {
      "epoch": 2.207920792079208,
      "grad_norm": 0.1741839051246643,
      "learning_rate": 0.00038728302804450843,
      "loss": 0.3813,
      "step": 54300
    },
    {
      "epoch": 2.211986907109602,
      "grad_norm": 0.18559034168720245,
      "learning_rate": 0.00038695440713501717,
      "loss": 0.3805,
      "step": 54400
    },
    {
      "epoch": 2.216053022139996,
      "grad_norm": 0.18357430398464203,
      "learning_rate": 0.00038662578622552596,
      "loss": 0.3815,
      "step": 54500
    },
    {
      "epoch": 2.2201191371703906,
      "grad_norm": 0.16634371876716614,
      "learning_rate": 0.00038629716531603475,
      "loss": 0.3819,
      "step": 54600
    },
    {
      "epoch": 2.2241852522007846,
      "grad_norm": 0.178678959608078,
      "learning_rate": 0.0003859685444065435,
      "loss": 0.3836,
      "step": 54700
    },
    {
      "epoch": 2.228251367231179,
      "grad_norm": 0.19501984119415283,
      "learning_rate": 0.0003856399234970523,
      "loss": 0.3807,
      "step": 54800
    },
    {
      "epoch": 2.232317482261573,
      "grad_norm": 0.17050381004810333,
      "learning_rate": 0.000385311302587561,
      "loss": 0.3828,
      "step": 54900
    },
    {
      "epoch": 2.2363835972919675,
      "grad_norm": 0.17059728503227234,
      "learning_rate": 0.0003849826816780698,
      "loss": 0.3831,
      "step": 55000
    },
    {
      "epoch": 2.2404497123223615,
      "grad_norm": 0.19064494967460632,
      "learning_rate": 0.0003846540607685786,
      "loss": 0.3806,
      "step": 55100
    },
    {
      "epoch": 2.244515827352756,
      "grad_norm": 0.1697486937046051,
      "learning_rate": 0.00038432543985908734,
      "loss": 0.3793,
      "step": 55200
    },
    {
      "epoch": 2.24858194238315,
      "grad_norm": 0.16759897768497467,
      "learning_rate": 0.0003839968189495961,
      "loss": 0.3792,
      "step": 55300
    },
    {
      "epoch": 2.2526480574135443,
      "grad_norm": 0.19485731422901154,
      "learning_rate": 0.00038366819804010486,
      "loss": 0.3812,
      "step": 55400
    },
    {
      "epoch": 2.2567141724439383,
      "grad_norm": 0.1714462786912918,
      "learning_rate": 0.00038333957713061365,
      "loss": 0.3809,
      "step": 55500
    },
    {
      "epoch": 2.260780287474333,
      "grad_norm": 0.18981023132801056,
      "learning_rate": 0.00038301095622112245,
      "loss": 0.3802,
      "step": 55600
    },
    {
      "epoch": 2.264846402504727,
      "grad_norm": 0.17835736274719238,
      "learning_rate": 0.00038268233531163124,
      "loss": 0.3812,
      "step": 55700
    },
    {
      "epoch": 2.2689125175351212,
      "grad_norm": 0.17098340392112732,
      "learning_rate": 0.00038235371440214003,
      "loss": 0.3824,
      "step": 55800
    },
    {
      "epoch": 2.2729786325655152,
      "grad_norm": 0.18117421865463257,
      "learning_rate": 0.00038202509349264877,
      "loss": 0.3813,
      "step": 55900
    },
    {
      "epoch": 2.2770447475959097,
      "grad_norm": 0.1793013960123062,
      "learning_rate": 0.00038169647258315756,
      "loss": 0.3822,
      "step": 56000
    },
    {
      "epoch": 2.2770447475959097,
      "eval_loss": 0.39216339588165283,
      "eval_runtime": 179.6418,
      "eval_samples_per_second": 973.615,
      "eval_steps_per_second": 30.427,
      "step": 56000
    },
    {
      "epoch": 2.2811108626263037,
      "grad_norm": 0.18652959167957306,
      "learning_rate": 0.0003813678516736663,
      "loss": 0.3821,
      "step": 56100
    },
    {
      "epoch": 2.2851769776566977,
      "grad_norm": 0.19447067379951477,
      "learning_rate": 0.0003810392307641751,
      "loss": 0.3804,
      "step": 56200
    },
    {
      "epoch": 2.289243092687092,
      "grad_norm": 0.16849827766418457,
      "learning_rate": 0.0003807106098546839,
      "loss": 0.3798,
      "step": 56300
    },
    {
      "epoch": 2.293309207717486,
      "grad_norm": 0.18810497224330902,
      "learning_rate": 0.0003803819889451926,
      "loss": 0.3807,
      "step": 56400
    },
    {
      "epoch": 2.2973753227478806,
      "grad_norm": 0.1936914473772049,
      "learning_rate": 0.0003800533680357014,
      "loss": 0.3826,
      "step": 56500
    },
    {
      "epoch": 2.3014414377782746,
      "grad_norm": 0.1770683377981186,
      "learning_rate": 0.00037972474712621014,
      "loss": 0.3822,
      "step": 56600
    },
    {
      "epoch": 2.305507552808669,
      "grad_norm": 0.20450200140476227,
      "learning_rate": 0.00037939612621671893,
      "loss": 0.3818,
      "step": 56700
    },
    {
      "epoch": 2.309573667839063,
      "grad_norm": 0.19742798805236816,
      "learning_rate": 0.0003790675053072277,
      "loss": 0.3799,
      "step": 56800
    },
    {
      "epoch": 2.3136397828694575,
      "grad_norm": 0.18602684140205383,
      "learning_rate": 0.00037873888439773646,
      "loss": 0.3807,
      "step": 56900
    },
    {
      "epoch": 2.3177058978998515,
      "grad_norm": 0.2030172199010849,
      "learning_rate": 0.00037841026348824525,
      "loss": 0.3837,
      "step": 57000
    },
    {
      "epoch": 2.321772012930246,
      "grad_norm": 0.21516279876232147,
      "learning_rate": 0.000378081642578754,
      "loss": 0.3815,
      "step": 57100
    },
    {
      "epoch": 2.32583812796064,
      "grad_norm": 0.19586069881916046,
      "learning_rate": 0.0003777530216692628,
      "loss": 0.3821,
      "step": 57200
    },
    {
      "epoch": 2.3299042429910344,
      "grad_norm": 0.1828775405883789,
      "learning_rate": 0.0003774244007597715,
      "loss": 0.3832,
      "step": 57300
    },
    {
      "epoch": 2.3339703580214284,
      "grad_norm": 0.1971905380487442,
      "learning_rate": 0.0003770957798502803,
      "loss": 0.3774,
      "step": 57400
    },
    {
      "epoch": 2.338036473051823,
      "grad_norm": 0.1785634160041809,
      "learning_rate": 0.0003767671589407891,
      "loss": 0.3817,
      "step": 57500
    },
    {
      "epoch": 2.342102588082217,
      "grad_norm": 0.19838206470012665,
      "learning_rate": 0.00037643853803129784,
      "loss": 0.3814,
      "step": 57600
    },
    {
      "epoch": 2.3461687031126113,
      "grad_norm": 0.19451121985912323,
      "learning_rate": 0.0003761099171218066,
      "loss": 0.3812,
      "step": 57700
    },
    {
      "epoch": 2.3502348181430053,
      "grad_norm": 0.17520862817764282,
      "learning_rate": 0.00037578129621231536,
      "loss": 0.3811,
      "step": 57800
    },
    {
      "epoch": 2.3543009331733993,
      "grad_norm": 0.1933399885892868,
      "learning_rate": 0.00037545267530282415,
      "loss": 0.3775,
      "step": 57900
    },
    {
      "epoch": 2.3583670482037937,
      "grad_norm": 0.187027707695961,
      "learning_rate": 0.00037512405439333295,
      "loss": 0.3784,
      "step": 58000
    },
    {
      "epoch": 2.3583670482037937,
      "eval_loss": 0.3891008794307709,
      "eval_runtime": 179.4774,
      "eval_samples_per_second": 974.507,
      "eval_steps_per_second": 30.455,
      "step": 58000
    },
    {
      "epoch": 2.3624331632341877,
      "grad_norm": 0.1696118414402008,
      "learning_rate": 0.0003747954334838417,
      "loss": 0.3829,
      "step": 58100
    },
    {
      "epoch": 2.366499278264582,
      "grad_norm": 0.20334173738956451,
      "learning_rate": 0.00037446681257435053,
      "loss": 0.3789,
      "step": 58200
    },
    {
      "epoch": 2.370565393294976,
      "grad_norm": 0.18919135630130768,
      "learning_rate": 0.00037413819166485926,
      "loss": 0.3812,
      "step": 58300
    },
    {
      "epoch": 2.3746315083253706,
      "grad_norm": 0.17435051500797272,
      "learning_rate": 0.00037380957075536806,
      "loss": 0.3782,
      "step": 58400
    },
    {
      "epoch": 2.3786976233557646,
      "grad_norm": 0.18930858373641968,
      "learning_rate": 0.00037348094984587685,
      "loss": 0.3837,
      "step": 58500
    },
    {
      "epoch": 2.382763738386159,
      "grad_norm": 0.18481849133968353,
      "learning_rate": 0.0003731523289363856,
      "loss": 0.3816,
      "step": 58600
    },
    {
      "epoch": 2.386829853416553,
      "grad_norm": 0.18518824875354767,
      "learning_rate": 0.0003728237080268944,
      "loss": 0.376,
      "step": 58700
    },
    {
      "epoch": 2.3908959684469475,
      "grad_norm": 0.1981971710920334,
      "learning_rate": 0.0003724950871174031,
      "loss": 0.3838,
      "step": 58800
    },
    {
      "epoch": 2.3949620834773415,
      "grad_norm": 0.19209247827529907,
      "learning_rate": 0.0003721664662079119,
      "loss": 0.3807,
      "step": 58900
    },
    {
      "epoch": 2.399028198507736,
      "grad_norm": 0.18468481302261353,
      "learning_rate": 0.00037183784529842064,
      "loss": 0.3793,
      "step": 59000
    },
    {
      "epoch": 2.40309431353813,
      "grad_norm": 0.17583799362182617,
      "learning_rate": 0.00037150922438892943,
      "loss": 0.3792,
      "step": 59100
    },
    {
      "epoch": 2.407160428568524,
      "grad_norm": 0.197927325963974,
      "learning_rate": 0.0003711806034794382,
      "loss": 0.3809,
      "step": 59200
    },
    {
      "epoch": 2.4112265435989184,
      "grad_norm": 0.19291119277477264,
      "learning_rate": 0.00037085198256994696,
      "loss": 0.3798,
      "step": 59300
    },
    {
      "epoch": 2.415292658629313,
      "grad_norm": 0.18449430167675018,
      "learning_rate": 0.00037052336166045575,
      "loss": 0.3806,
      "step": 59400
    },
    {
      "epoch": 2.419358773659707,
      "grad_norm": 0.17353759706020355,
      "learning_rate": 0.0003701947407509645,
      "loss": 0.3806,
      "step": 59500
    },
    {
      "epoch": 2.423424888690101,
      "grad_norm": 0.2025233805179596,
      "learning_rate": 0.0003698661198414733,
      "loss": 0.381,
      "step": 59600
    },
    {
      "epoch": 2.4274910037204953,
      "grad_norm": 0.20085610449314117,
      "learning_rate": 0.00036953749893198207,
      "loss": 0.3797,
      "step": 59700
    },
    {
      "epoch": 2.4315571187508893,
      "grad_norm": 0.19073604047298431,
      "learning_rate": 0.0003692088780224908,
      "loss": 0.3789,
      "step": 59800
    },
    {
      "epoch": 2.4356232337812838,
      "grad_norm": 0.19748592376708984,
      "learning_rate": 0.0003688802571129996,
      "loss": 0.3789,
      "step": 59900
    },
    {
      "epoch": 2.4396893488116778,
      "grad_norm": 0.1806422919034958,
      "learning_rate": 0.00036855163620350833,
      "loss": 0.3787,
      "step": 60000
    },
    {
      "epoch": 2.4396893488116778,
      "eval_loss": 0.39070817828178406,
      "eval_runtime": 180.2581,
      "eval_samples_per_second": 970.286,
      "eval_steps_per_second": 30.323,
      "step": 60000
    },
    {
      "epoch": 2.443755463842072,
      "grad_norm": 0.19913873076438904,
      "learning_rate": 0.0003682230152940171,
      "loss": 0.3779,
      "step": 60100
    },
    {
      "epoch": 2.447821578872466,
      "grad_norm": 0.1876501441001892,
      "learning_rate": 0.0003678943943845259,
      "loss": 0.3811,
      "step": 60200
    },
    {
      "epoch": 2.4518876939028607,
      "grad_norm": 0.1883518546819687,
      "learning_rate": 0.00036756577347503465,
      "loss": 0.3776,
      "step": 60300
    },
    {
      "epoch": 2.4559538089332547,
      "grad_norm": 0.19462233781814575,
      "learning_rate": 0.00036723715256554344,
      "loss": 0.3791,
      "step": 60400
    },
    {
      "epoch": 2.460019923963649,
      "grad_norm": 0.21475423872470856,
      "learning_rate": 0.0003669085316560522,
      "loss": 0.3789,
      "step": 60500
    },
    {
      "epoch": 2.464086038994043,
      "grad_norm": 0.19701895117759705,
      "learning_rate": 0.000366579910746561,
      "loss": 0.3793,
      "step": 60600
    },
    {
      "epoch": 2.4681521540244376,
      "grad_norm": 0.18264710903167725,
      "learning_rate": 0.0003662512898370697,
      "loss": 0.3781,
      "step": 60700
    },
    {
      "epoch": 2.4722182690548316,
      "grad_norm": 0.19550460577011108,
      "learning_rate": 0.00036592266892757856,
      "loss": 0.3781,
      "step": 60800
    },
    {
      "epoch": 2.4762843840852256,
      "grad_norm": 0.22296607494354248,
      "learning_rate": 0.00036559404801808735,
      "loss": 0.3791,
      "step": 60900
    },
    {
      "epoch": 2.48035049911562,
      "grad_norm": 0.19265398383140564,
      "learning_rate": 0.0003652654271085961,
      "loss": 0.3776,
      "step": 61000
    },
    {
      "epoch": 2.484416614146014,
      "grad_norm": 0.20441655814647675,
      "learning_rate": 0.0003649368061991049,
      "loss": 0.3805,
      "step": 61100
    },
    {
      "epoch": 2.4884827291764084,
      "grad_norm": 0.18753492832183838,
      "learning_rate": 0.0003646081852896136,
      "loss": 0.3795,
      "step": 61200
    },
    {
      "epoch": 2.4925488442068024,
      "grad_norm": 0.17913833260536194,
      "learning_rate": 0.0003642795643801224,
      "loss": 0.3798,
      "step": 61300
    },
    {
      "epoch": 2.496614959237197,
      "grad_norm": 0.16842599213123322,
      "learning_rate": 0.0003639509434706312,
      "loss": 0.3791,
      "step": 61400
    },
    {
      "epoch": 2.500681074267591,
      "grad_norm": 0.18018284440040588,
      "learning_rate": 0.00036362232256113993,
      "loss": 0.3787,
      "step": 61500
    },
    {
      "epoch": 2.5047471892979853,
      "grad_norm": 0.18852359056472778,
      "learning_rate": 0.0003632937016516487,
      "loss": 0.3798,
      "step": 61600
    },
    {
      "epoch": 2.5088133043283793,
      "grad_norm": 0.19935671985149384,
      "learning_rate": 0.00036296508074215746,
      "loss": 0.3789,
      "step": 61700
    },
    {
      "epoch": 2.512879419358774,
      "grad_norm": 0.18594272434711456,
      "learning_rate": 0.00036263645983266625,
      "loss": 0.3785,
      "step": 61800
    },
    {
      "epoch": 2.516945534389168,
      "grad_norm": 0.19209614396095276,
      "learning_rate": 0.00036230783892317504,
      "loss": 0.3785,
      "step": 61900
    },
    {
      "epoch": 2.5210116494195622,
      "grad_norm": 0.20605826377868652,
      "learning_rate": 0.0003619792180136838,
      "loss": 0.3781,
      "step": 62000
    },
    {
      "epoch": 2.5210116494195622,
      "eval_loss": 0.3894267976284027,
      "eval_runtime": 180.7755,
      "eval_samples_per_second": 967.51,
      "eval_steps_per_second": 30.236,
      "step": 62000
    },
    {
      "epoch": 2.5250777644499562,
      "grad_norm": 0.18775059282779694,
      "learning_rate": 0.00036165059710419257,
      "loss": 0.3795,
      "step": 62100
    },
    {
      "epoch": 2.5291438794803502,
      "grad_norm": 0.19727692008018494,
      "learning_rate": 0.0003613219761947013,
      "loss": 0.3779,
      "step": 62200
    },
    {
      "epoch": 2.5332099945107447,
      "grad_norm": 0.189600870013237,
      "learning_rate": 0.0003609933552852101,
      "loss": 0.3779,
      "step": 62300
    },
    {
      "epoch": 2.537276109541139,
      "grad_norm": 0.17062605917453766,
      "learning_rate": 0.00036066473437571883,
      "loss": 0.3814,
      "step": 62400
    },
    {
      "epoch": 2.541342224571533,
      "grad_norm": 0.21920384466648102,
      "learning_rate": 0.0003603361134662276,
      "loss": 0.3796,
      "step": 62500
    },
    {
      "epoch": 2.545408339601927,
      "grad_norm": 0.18175601959228516,
      "learning_rate": 0.0003600074925567364,
      "loss": 0.3774,
      "step": 62600
    },
    {
      "epoch": 2.5494744546323216,
      "grad_norm": 0.1956445872783661,
      "learning_rate": 0.00035967887164724515,
      "loss": 0.3786,
      "step": 62700
    },
    {
      "epoch": 2.553540569662716,
      "grad_norm": 0.1793583333492279,
      "learning_rate": 0.00035935025073775394,
      "loss": 0.3787,
      "step": 62800
    },
    {
      "epoch": 2.55760668469311,
      "grad_norm": 0.1993609219789505,
      "learning_rate": 0.0003590216298282627,
      "loss": 0.3795,
      "step": 62900
    },
    {
      "epoch": 2.561672799723504,
      "grad_norm": 0.20769855380058289,
      "learning_rate": 0.00035869300891877147,
      "loss": 0.3798,
      "step": 63000
    },
    {
      "epoch": 2.5657389147538985,
      "grad_norm": 0.20494985580444336,
      "learning_rate": 0.00035836438800928026,
      "loss": 0.3765,
      "step": 63100
    },
    {
      "epoch": 2.5698050297842925,
      "grad_norm": 0.19171905517578125,
      "learning_rate": 0.000358035767099789,
      "loss": 0.3786,
      "step": 63200
    },
    {
      "epoch": 2.573871144814687,
      "grad_norm": 0.1981915384531021,
      "learning_rate": 0.0003577071461902978,
      "loss": 0.3779,
      "step": 63300
    },
    {
      "epoch": 2.577937259845081,
      "grad_norm": 0.1899695098400116,
      "learning_rate": 0.00035737852528080653,
      "loss": 0.3787,
      "step": 63400
    },
    {
      "epoch": 2.5820033748754754,
      "grad_norm": 0.16770082712173462,
      "learning_rate": 0.0003570499043713154,
      "loss": 0.3776,
      "step": 63500
    },
    {
      "epoch": 2.5860694899058694,
      "grad_norm": 0.20965828001499176,
      "learning_rate": 0.00035672128346182416,
      "loss": 0.3785,
      "step": 63600
    },
    {
      "epoch": 2.590135604936264,
      "grad_norm": 0.20554125308990479,
      "learning_rate": 0.0003563926625523329,
      "loss": 0.3768,
      "step": 63700
    },
    {
      "epoch": 2.594201719966658,
      "grad_norm": 0.2071893960237503,
      "learning_rate": 0.0003560640416428417,
      "loss": 0.3799,
      "step": 63800
    },
    {
      "epoch": 2.598267834997052,
      "grad_norm": 0.19140897691249847,
      "learning_rate": 0.00035573542073335043,
      "loss": 0.3797,
      "step": 63900
    },
    {
      "epoch": 2.6023339500274463,
      "grad_norm": 0.19396404922008514,
      "learning_rate": 0.0003554067998238592,
      "loss": 0.3769,
      "step": 64000
    },
    {
      "epoch": 2.6023339500274463,
      "eval_loss": 0.39029374718666077,
      "eval_runtime": 179.4501,
      "eval_samples_per_second": 974.655,
      "eval_steps_per_second": 30.46,
      "step": 64000
    },
    {
      "epoch": 2.6064000650578407,
      "grad_norm": 0.20211319625377655,
      "learning_rate": 0.00035507817891436796,
      "loss": 0.3786,
      "step": 64100
    },
    {
      "epoch": 2.6104661800882347,
      "grad_norm": 0.22670625150203705,
      "learning_rate": 0.00035474955800487675,
      "loss": 0.3794,
      "step": 64200
    },
    {
      "epoch": 2.6145322951186287,
      "grad_norm": 0.200079083442688,
      "learning_rate": 0.00035442093709538554,
      "loss": 0.3785,
      "step": 64300
    },
    {
      "epoch": 2.618598410149023,
      "grad_norm": 0.19969797134399414,
      "learning_rate": 0.0003540923161858943,
      "loss": 0.3779,
      "step": 64400
    },
    {
      "epoch": 2.622664525179417,
      "grad_norm": 0.21436485648155212,
      "learning_rate": 0.00035376369527640307,
      "loss": 0.3788,
      "step": 64500
    },
    {
      "epoch": 2.6267306402098116,
      "grad_norm": 0.203441321849823,
      "learning_rate": 0.0003534350743669118,
      "loss": 0.3781,
      "step": 64600
    },
    {
      "epoch": 2.6307967552402056,
      "grad_norm": 0.19233468174934387,
      "learning_rate": 0.0003531064534574206,
      "loss": 0.3795,
      "step": 64700
    },
    {
      "epoch": 2.6348628702706,
      "grad_norm": 0.20058482885360718,
      "learning_rate": 0.0003527778325479294,
      "loss": 0.376,
      "step": 64800
    },
    {
      "epoch": 2.638928985300994,
      "grad_norm": 0.17662860453128815,
      "learning_rate": 0.0003524492116384381,
      "loss": 0.3757,
      "step": 64900
    },
    {
      "epoch": 2.6429951003313885,
      "grad_norm": 0.19233866035938263,
      "learning_rate": 0.0003521205907289469,
      "loss": 0.378,
      "step": 65000
    },
    {
      "epoch": 2.6470612153617825,
      "grad_norm": 0.2056623250246048,
      "learning_rate": 0.00035179196981945565,
      "loss": 0.3781,
      "step": 65100
    },
    {
      "epoch": 2.6511273303921765,
      "grad_norm": 0.21770384907722473,
      "learning_rate": 0.00035146334890996444,
      "loss": 0.3782,
      "step": 65200
    },
    {
      "epoch": 2.655193445422571,
      "grad_norm": 0.20010578632354736,
      "learning_rate": 0.00035113472800047323,
      "loss": 0.3784,
      "step": 65300
    },
    {
      "epoch": 2.6592595604529654,
      "grad_norm": 0.2068118304014206,
      "learning_rate": 0.00035080610709098197,
      "loss": 0.3786,
      "step": 65400
    },
    {
      "epoch": 2.6633256754833594,
      "grad_norm": 0.1958039402961731,
      "learning_rate": 0.00035047748618149076,
      "loss": 0.3788,
      "step": 65500
    },
    {
      "epoch": 2.6673917905137534,
      "grad_norm": 0.18106774985790253,
      "learning_rate": 0.0003501488652719995,
      "loss": 0.3775,
      "step": 65600
    },
    {
      "epoch": 2.671457905544148,
      "grad_norm": 0.22703303396701813,
      "learning_rate": 0.0003498202443625083,
      "loss": 0.3777,
      "step": 65700
    },
    {
      "epoch": 2.6755240205745423,
      "grad_norm": 0.1929607093334198,
      "learning_rate": 0.00034949162345301703,
      "loss": 0.3792,
      "step": 65800
    },
    {
      "epoch": 2.6795901356049363,
      "grad_norm": 0.20244041085243225,
      "learning_rate": 0.0003491630025435258,
      "loss": 0.376,
      "step": 65900
    },
    {
      "epoch": 2.6836562506353303,
      "grad_norm": 0.1941928267478943,
      "learning_rate": 0.0003488343816340346,
      "loss": 0.3801,
      "step": 66000
    },
    {
      "epoch": 2.6836562506353303,
      "eval_loss": 0.3876861333847046,
      "eval_runtime": 180.1872,
      "eval_samples_per_second": 970.668,
      "eval_steps_per_second": 30.335,
      "step": 66000
    },
    {
      "epoch": 2.6877223656657248,
      "grad_norm": 0.21105769276618958,
      "learning_rate": 0.0003485057607245434,
      "loss": 0.3775,
      "step": 66100
    },
    {
      "epoch": 2.6917884806961188,
      "grad_norm": 0.21459200978279114,
      "learning_rate": 0.0003481771398150522,
      "loss": 0.378,
      "step": 66200
    },
    {
      "epoch": 2.695854595726513,
      "grad_norm": 0.20183393359184265,
      "learning_rate": 0.00034784851890556093,
      "loss": 0.3754,
      "step": 66300
    },
    {
      "epoch": 2.699920710756907,
      "grad_norm": 0.21348750591278076,
      "learning_rate": 0.0003475198979960697,
      "loss": 0.3774,
      "step": 66400
    },
    {
      "epoch": 2.7039868257873017,
      "grad_norm": 0.19667558372020721,
      "learning_rate": 0.0003471912770865785,
      "loss": 0.3783,
      "step": 66500
    },
    {
      "epoch": 2.7080529408176957,
      "grad_norm": 0.21388457715511322,
      "learning_rate": 0.00034686265617708725,
      "loss": 0.3771,
      "step": 66600
    },
    {
      "epoch": 2.71211905584809,
      "grad_norm": 0.19961117208003998,
      "learning_rate": 0.00034653403526759604,
      "loss": 0.3774,
      "step": 66700
    },
    {
      "epoch": 2.716185170878484,
      "grad_norm": 0.19054941833019257,
      "learning_rate": 0.0003462054143581048,
      "loss": 0.3766,
      "step": 66800
    },
    {
      "epoch": 2.720251285908878,
      "grad_norm": 0.20653505623340607,
      "learning_rate": 0.00034587679344861357,
      "loss": 0.3786,
      "step": 66900
    },
    {
      "epoch": 2.7243174009392725,
      "grad_norm": 0.21003107726573944,
      "learning_rate": 0.00034554817253912236,
      "loss": 0.3781,
      "step": 67000
    },
    {
      "epoch": 2.728383515969667,
      "grad_norm": 0.17925496399402618,
      "learning_rate": 0.0003452195516296311,
      "loss": 0.376,
      "step": 67100
    },
    {
      "epoch": 2.732449631000061,
      "grad_norm": 0.1900014728307724,
      "learning_rate": 0.0003448909307201399,
      "loss": 0.3768,
      "step": 67200
    },
    {
      "epoch": 2.736515746030455,
      "grad_norm": 0.19840914011001587,
      "learning_rate": 0.0003445623098106486,
      "loss": 0.3776,
      "step": 67300
    },
    {
      "epoch": 2.7405818610608494,
      "grad_norm": 0.21474197506904602,
      "learning_rate": 0.0003442336889011574,
      "loss": 0.3775,
      "step": 67400
    },
    {
      "epoch": 2.744647976091244,
      "grad_norm": 0.20811861753463745,
      "learning_rate": 0.00034390506799166615,
      "loss": 0.3791,
      "step": 67500
    },
    {
      "epoch": 2.748714091121638,
      "grad_norm": 0.2016855776309967,
      "learning_rate": 0.00034357644708217494,
      "loss": 0.3789,
      "step": 67600
    },
    {
      "epoch": 2.752780206152032,
      "grad_norm": 0.19152231514453888,
      "learning_rate": 0.00034324782617268373,
      "loss": 0.3768,
      "step": 67700
    },
    {
      "epoch": 2.7568463211824263,
      "grad_norm": 0.19600412249565125,
      "learning_rate": 0.00034291920526319247,
      "loss": 0.3779,
      "step": 67800
    },
    {
      "epoch": 2.7609124362128203,
      "grad_norm": 0.2577015459537506,
      "learning_rate": 0.00034259058435370126,
      "loss": 0.3761,
      "step": 67900
    },
    {
      "epoch": 2.764978551243215,
      "grad_norm": 0.2097644954919815,
      "learning_rate": 0.00034226196344421,
      "loss": 0.3788,
      "step": 68000
    },
    {
      "epoch": 2.764978551243215,
      "eval_loss": 0.38955020904541016,
      "eval_runtime": 180.4456,
      "eval_samples_per_second": 969.278,
      "eval_steps_per_second": 30.292,
      "step": 68000
    },
    {
      "epoch": 2.769064996848761,
      "grad_norm": 0.18489211797714233,
      "learning_rate": 0.0003419333425347188,
      "loss": 0.3764,
      "step": 68100
    },
    {
      "epoch": 2.773131111879155,
      "grad_norm": 0.20309995114803314,
      "learning_rate": 0.0003416047216252276,
      "loss": 0.3775,
      "step": 68200
    },
    {
      "epoch": 2.777197226909549,
      "grad_norm": 0.19912776350975037,
      "learning_rate": 0.0003412761007157363,
      "loss": 0.375,
      "step": 68300
    },
    {
      "epoch": 2.7812633419399435,
      "grad_norm": 0.2191377729177475,
      "learning_rate": 0.0003409474798062451,
      "loss": 0.3753,
      "step": 68400
    },
    {
      "epoch": 2.785329456970338,
      "grad_norm": 0.22397267818450928,
      "learning_rate": 0.00034061885889675385,
      "loss": 0.3772,
      "step": 68500
    },
    {
      "epoch": 2.789395572000732,
      "grad_norm": 0.1925123780965805,
      "learning_rate": 0.00034029023798726264,
      "loss": 0.3787,
      "step": 68600
    },
    {
      "epoch": 2.793461687031126,
      "grad_norm": 0.2179073691368103,
      "learning_rate": 0.0003399616170777715,
      "loss": 0.3778,
      "step": 68700
    },
    {
      "epoch": 2.7975278020615204,
      "grad_norm": 0.2227046936750412,
      "learning_rate": 0.0003396329961682802,
      "loss": 0.3783,
      "step": 68800
    },
    {
      "epoch": 2.8015939170919144,
      "grad_norm": 0.21079587936401367,
      "learning_rate": 0.000339304375258789,
      "loss": 0.3787,
      "step": 68900
    },
    {
      "epoch": 2.805660032122309,
      "grad_norm": 0.18874216079711914,
      "learning_rate": 0.00033897575434929775,
      "loss": 0.3771,
      "step": 69000
    },
    {
      "epoch": 2.809726147152703,
      "grad_norm": 0.23878617584705353,
      "learning_rate": 0.00033864713343980654,
      "loss": 0.3777,
      "step": 69100
    },
    {
      "epoch": 2.8137922621830973,
      "grad_norm": 0.2050904929637909,
      "learning_rate": 0.0003383185125303153,
      "loss": 0.3776,
      "step": 69200
    },
    {
      "epoch": 2.8178583772134913,
      "grad_norm": 0.19134479761123657,
      "learning_rate": 0.00033798989162082407,
      "loss": 0.3778,
      "step": 69300
    },
    {
      "epoch": 2.8219244922438858,
      "grad_norm": 0.21227656304836273,
      "learning_rate": 0.00033766127071133286,
      "loss": 0.3761,
      "step": 69400
    },
    {
      "epoch": 2.8259906072742798,
      "grad_norm": 0.20889051258563995,
      "learning_rate": 0.0003373326498018416,
      "loss": 0.3753,
      "step": 69500
    },
    {
      "epoch": 2.8300567223046738,
      "grad_norm": 0.1941189467906952,
      "learning_rate": 0.0003370040288923504,
      "loss": 0.3754,
      "step": 69600
    },
    {
      "epoch": 2.834122837335068,
      "grad_norm": 0.24664553999900818,
      "learning_rate": 0.0003366754079828591,
      "loss": 0.3777,
      "step": 69700
    },
    {
      "epoch": 2.8381889523654626,
      "grad_norm": 0.24961812794208527,
      "learning_rate": 0.0003363467870733679,
      "loss": 0.3764,
      "step": 69800
    },
    {
      "epoch": 2.8422550673958566,
      "grad_norm": 0.2222571074962616,
      "learning_rate": 0.0003360181661638767,
      "loss": 0.3767,
      "step": 69900
    },
    {
      "epoch": 2.8463211824262507,
      "grad_norm": 0.18253691494464874,
      "learning_rate": 0.00033568954525438544,
      "loss": 0.3751,
      "step": 70000
    },
    {
      "epoch": 2.8463211824262507,
      "eval_loss": 0.3879353106021881,
      "eval_runtime": 181.4245,
      "eval_samples_per_second": 964.049,
      "eval_steps_per_second": 30.128,
      "step": 70000
    },
    {
      "epoch": 2.850387297456645,
      "grad_norm": 0.1992054283618927,
      "learning_rate": 0.00033536092434489423,
      "loss": 0.3789,
      "step": 70100
    },
    {
      "epoch": 2.854453412487039,
      "grad_norm": 0.20765581727027893,
      "learning_rate": 0.00033503230343540297,
      "loss": 0.3751,
      "step": 70200
    },
    {
      "epoch": 2.8585195275174335,
      "grad_norm": 0.21839456260204315,
      "learning_rate": 0.00033470368252591176,
      "loss": 0.3763,
      "step": 70300
    },
    {
      "epoch": 2.8625856425478275,
      "grad_norm": 0.216915100812912,
      "learning_rate": 0.00033437506161642055,
      "loss": 0.3753,
      "step": 70400
    },
    {
      "epoch": 2.866651757578222,
      "grad_norm": 0.20827347040176392,
      "learning_rate": 0.0003340464407069293,
      "loss": 0.3768,
      "step": 70500
    },
    {
      "epoch": 2.870717872608616,
      "grad_norm": 0.19010399281978607,
      "learning_rate": 0.0003337178197974381,
      "loss": 0.3781,
      "step": 70600
    },
    {
      "epoch": 2.8747839876390104,
      "grad_norm": 0.23412349820137024,
      "learning_rate": 0.0003333891988879468,
      "loss": 0.3771,
      "step": 70700
    },
    {
      "epoch": 2.8788501026694044,
      "grad_norm": 0.19784599542617798,
      "learning_rate": 0.0003330605779784556,
      "loss": 0.3778,
      "step": 70800
    },
    {
      "epoch": 2.882916217699799,
      "grad_norm": 0.21415682137012482,
      "learning_rate": 0.00033273195706896435,
      "loss": 0.3757,
      "step": 70900
    },
    {
      "epoch": 2.886982332730193,
      "grad_norm": 0.21105480194091797,
      "learning_rate": 0.00033240333615947314,
      "loss": 0.3782,
      "step": 71000
    },
    {
      "epoch": 2.8910484477605873,
      "grad_norm": 0.2379133105278015,
      "learning_rate": 0.00033207471524998193,
      "loss": 0.3749,
      "step": 71100
    },
    {
      "epoch": 2.8951145627909813,
      "grad_norm": 0.25991904735565186,
      "learning_rate": 0.00033174609434049067,
      "loss": 0.3775,
      "step": 71200
    },
    {
      "epoch": 2.8991806778213753,
      "grad_norm": 0.23774568736553192,
      "learning_rate": 0.00033141747343099946,
      "loss": 0.3765,
      "step": 71300
    },
    {
      "epoch": 2.90324679285177,
      "grad_norm": 0.2092195451259613,
      "learning_rate": 0.00033108885252150825,
      "loss": 0.3751,
      "step": 71400
    },
    {
      "epoch": 2.9073129078821642,
      "grad_norm": 0.23492461442947388,
      "learning_rate": 0.00033076023161201704,
      "loss": 0.3775,
      "step": 71500
    },
    {
      "epoch": 2.9113790229125582,
      "grad_norm": 0.20053870975971222,
      "learning_rate": 0.00033043161070252583,
      "loss": 0.3777,
      "step": 71600
    },
    {
      "epoch": 2.9154451379429522,
      "grad_norm": 0.21014125645160675,
      "learning_rate": 0.00033010298979303457,
      "loss": 0.3744,
      "step": 71700
    },
    {
      "epoch": 2.9195112529733467,
      "grad_norm": 0.22026506066322327,
      "learning_rate": 0.00032977436888354336,
      "loss": 0.3757,
      "step": 71800
    },
    {
      "epoch": 2.9235773680037407,
      "grad_norm": 0.24011217057704926,
      "learning_rate": 0.0003294457479740521,
      "loss": 0.3753,
      "step": 71900
    },
    {
      "epoch": 2.927643483034135,
      "grad_norm": 0.2389727681875229,
      "learning_rate": 0.0003291171270645609,
      "loss": 0.3761,
      "step": 72000
    },
    {
      "epoch": 2.927643483034135,
      "eval_loss": 0.38459500670433044,
      "eval_runtime": 179.7809,
      "eval_samples_per_second": 972.862,
      "eval_steps_per_second": 30.404,
      "step": 72000
    },
    {
      "epoch": 2.931709598064529,
      "grad_norm": 0.1969374716281891,
      "learning_rate": 0.0003287885061550697,
      "loss": 0.374,
      "step": 72100
    },
    {
      "epoch": 2.9357757130949236,
      "grad_norm": 0.20043067634105682,
      "learning_rate": 0.0003284598852455784,
      "loss": 0.3752,
      "step": 72200
    },
    {
      "epoch": 2.9398418281253176,
      "grad_norm": 0.2338634580373764,
      "learning_rate": 0.0003281312643360872,
      "loss": 0.3748,
      "step": 72300
    },
    {
      "epoch": 2.943907943155712,
      "grad_norm": 0.21424727141857147,
      "learning_rate": 0.00032780264342659594,
      "loss": 0.3765,
      "step": 72400
    },
    {
      "epoch": 2.947974058186106,
      "grad_norm": 0.20395320653915405,
      "learning_rate": 0.00032747402251710473,
      "loss": 0.3737,
      "step": 72500
    },
    {
      "epoch": 2.9520401732165,
      "grad_norm": 0.2531513273715973,
      "learning_rate": 0.00032714540160761347,
      "loss": 0.3749,
      "step": 72600
    },
    {
      "epoch": 2.9561062882468945,
      "grad_norm": 0.22092126309871674,
      "learning_rate": 0.00032681678069812226,
      "loss": 0.3757,
      "step": 72700
    },
    {
      "epoch": 2.960172403277289,
      "grad_norm": 0.23870284855365753,
      "learning_rate": 0.00032648815978863105,
      "loss": 0.3754,
      "step": 72800
    },
    {
      "epoch": 2.964238518307683,
      "grad_norm": 0.1884036511182785,
      "learning_rate": 0.0003261595388791398,
      "loss": 0.3745,
      "step": 72900
    },
    {
      "epoch": 2.968304633338077,
      "grad_norm": 0.2334257960319519,
      "learning_rate": 0.0003258309179696486,
      "loss": 0.3763,
      "step": 73000
    },
    {
      "epoch": 2.9723707483684714,
      "grad_norm": 0.22325101494789124,
      "learning_rate": 0.0003255022970601573,
      "loss": 0.3758,
      "step": 73100
    },
    {
      "epoch": 2.976436863398866,
      "grad_norm": 0.2418118566274643,
      "learning_rate": 0.0003251736761506661,
      "loss": 0.3737,
      "step": 73200
    },
    {
      "epoch": 2.98050297842926,
      "grad_norm": 0.21356989443302155,
      "learning_rate": 0.0003248450552411749,
      "loss": 0.3745,
      "step": 73300
    },
    {
      "epoch": 2.984569093459654,
      "grad_norm": 0.2444600611925125,
      "learning_rate": 0.00032451643433168364,
      "loss": 0.3749,
      "step": 73400
    },
    {
      "epoch": 2.9886352084900483,
      "grad_norm": 0.22936426103115082,
      "learning_rate": 0.00032418781342219243,
      "loss": 0.375,
      "step": 73500
    },
    {
      "epoch": 2.9927013235204423,
      "grad_norm": 0.20157523453235626,
      "learning_rate": 0.00032385919251270116,
      "loss": 0.3744,
      "step": 73600
    },
    {
      "epoch": 2.9967674385508367,
      "grad_norm": 0.24623465538024902,
      "learning_rate": 0.00032353057160320996,
      "loss": 0.3732,
      "step": 73700
    },
    {
      "epoch": 3.0008335535812307,
      "grad_norm": 0.20289115607738495,
      "learning_rate": 0.00032320195069371875,
      "loss": 0.376,
      "step": 73800
    },
    {
      "epoch": 3.004899668611625,
      "grad_norm": 0.2240542769432068,
      "learning_rate": 0.0003228733297842275,
      "loss": 0.3728,
      "step": 73900
    },
    {
      "epoch": 3.008965783642019,
      "grad_norm": 0.23484596610069275,
      "learning_rate": 0.00032254470887473633,
      "loss": 0.3714,
      "step": 74000
    },
    {
      "epoch": 3.008965783642019,
      "eval_loss": 0.3849007189273834,
      "eval_runtime": 180.7536,
      "eval_samples_per_second": 967.626,
      "eval_steps_per_second": 30.24,
      "step": 74000
    },
    {
      "epoch": 3.0130318986724136,
      "grad_norm": 0.23393219709396362,
      "learning_rate": 0.00032221608796524507,
      "loss": 0.3729,
      "step": 74100
    },
    {
      "epoch": 3.0170980137028076,
      "grad_norm": 0.23510046303272247,
      "learning_rate": 0.00032188746705575386,
      "loss": 0.3737,
      "step": 74200
    },
    {
      "epoch": 3.021164128733202,
      "grad_norm": 0.20379924774169922,
      "learning_rate": 0.0003215588461462626,
      "loss": 0.3723,
      "step": 74300
    },
    {
      "epoch": 3.025230243763596,
      "grad_norm": 0.2320871353149414,
      "learning_rate": 0.0003212302252367714,
      "loss": 0.3725,
      "step": 74400
    },
    {
      "epoch": 3.02929635879399,
      "grad_norm": 0.2461317479610443,
      "learning_rate": 0.0003209016043272802,
      "loss": 0.3721,
      "step": 74500
    },
    {
      "epoch": 3.0333624738243845,
      "grad_norm": 0.20927658677101135,
      "learning_rate": 0.0003205729834177889,
      "loss": 0.3716,
      "step": 74600
    },
    {
      "epoch": 3.0374285888547785,
      "grad_norm": 0.22388313710689545,
      "learning_rate": 0.0003202443625082977,
      "loss": 0.3734,
      "step": 74700
    },
    {
      "epoch": 3.041494703885173,
      "grad_norm": 0.23087872564792633,
      "learning_rate": 0.00031991574159880644,
      "loss": 0.3709,
      "step": 74800
    },
    {
      "epoch": 3.045560818915567,
      "grad_norm": 0.2614368200302124,
      "learning_rate": 0.00031958712068931523,
      "loss": 0.3738,
      "step": 74900
    },
    {
      "epoch": 3.0496269339459614,
      "grad_norm": 0.22542835772037506,
      "learning_rate": 0.000319258499779824,
      "loss": 0.3714,
      "step": 75000
    },
    {
      "epoch": 3.0536930489763554,
      "grad_norm": 0.21560034155845642,
      "learning_rate": 0.00031892987887033276,
      "loss": 0.3712,
      "step": 75100
    },
    {
      "epoch": 3.05775916400675,
      "grad_norm": 0.2251923531293869,
      "learning_rate": 0.00031860125796084155,
      "loss": 0.372,
      "step": 75200
    },
    {
      "epoch": 3.061825279037144,
      "grad_norm": 0.2314547896385193,
      "learning_rate": 0.0003182726370513503,
      "loss": 0.3741,
      "step": 75300
    },
    {
      "epoch": 3.0658913940675383,
      "grad_norm": 0.23871265351772308,
      "learning_rate": 0.0003179440161418591,
      "loss": 0.371,
      "step": 75400
    },
    {
      "epoch": 3.0699575090979323,
      "grad_norm": 0.222039595246315,
      "learning_rate": 0.00031761539523236787,
      "loss": 0.3726,
      "step": 75500
    },
    {
      "epoch": 3.0740236241283267,
      "grad_norm": 0.21468155086040497,
      "learning_rate": 0.0003172867743228766,
      "loss": 0.3715,
      "step": 75600
    },
    {
      "epoch": 3.0780897391587208,
      "grad_norm": 0.2176312655210495,
      "learning_rate": 0.0003169581534133854,
      "loss": 0.373,
      "step": 75700
    },
    {
      "epoch": 3.082155854189115,
      "grad_norm": 0.20265425741672516,
      "learning_rate": 0.00031662953250389414,
      "loss": 0.3722,
      "step": 75800
    },
    {
      "epoch": 3.086221969219509,
      "grad_norm": 0.2030731737613678,
      "learning_rate": 0.00031630091159440293,
      "loss": 0.3718,
      "step": 75900
    },
    {
      "epoch": 3.0902880842499036,
      "grad_norm": 0.22776557505130768,
      "learning_rate": 0.00031597229068491166,
      "loss": 0.3747,
      "step": 76000
    },
    {
      "epoch": 3.0902880842499036,
      "eval_loss": 0.38534003496170044,
      "eval_runtime": 178.3624,
      "eval_samples_per_second": 980.599,
      "eval_steps_per_second": 30.645,
      "step": 76000
    },
    {
      "epoch": 3.0943541992802976,
      "grad_norm": 0.2150314450263977,
      "learning_rate": 0.00031564366977542046,
      "loss": 0.3701,
      "step": 76100
    },
    {
      "epoch": 3.0984203143106916,
      "grad_norm": 0.22864025831222534,
      "learning_rate": 0.00031531504886592925,
      "loss": 0.373,
      "step": 76200
    },
    {
      "epoch": 3.102486429341086,
      "grad_norm": 0.21254684031009674,
      "learning_rate": 0.000314986427956438,
      "loss": 0.3719,
      "step": 76300
    },
    {
      "epoch": 3.10655254437148,
      "grad_norm": 0.245059996843338,
      "learning_rate": 0.0003146578070469468,
      "loss": 0.3737,
      "step": 76400
    },
    {
      "epoch": 3.1106186594018745,
      "grad_norm": 0.2305455207824707,
      "learning_rate": 0.0003143291861374555,
      "loss": 0.372,
      "step": 76500
    },
    {
      "epoch": 3.1146847744322685,
      "grad_norm": 0.2116839438676834,
      "learning_rate": 0.00031400056522796436,
      "loss": 0.3732,
      "step": 76600
    },
    {
      "epoch": 3.118750889462663,
      "grad_norm": 0.23294506967067719,
      "learning_rate": 0.00031367194431847315,
      "loss": 0.3714,
      "step": 76700
    },
    {
      "epoch": 3.122817004493057,
      "grad_norm": 0.23761314153671265,
      "learning_rate": 0.0003133433234089819,
      "loss": 0.3742,
      "step": 76800
    },
    {
      "epoch": 3.1268831195234514,
      "grad_norm": 0.2402588576078415,
      "learning_rate": 0.0003130147024994907,
      "loss": 0.3733,
      "step": 76900
    },
    {
      "epoch": 3.1309492345538454,
      "grad_norm": 0.24309639632701874,
      "learning_rate": 0.0003126860815899994,
      "loss": 0.3743,
      "step": 77000
    },
    {
      "epoch": 3.13501534958424,
      "grad_norm": 0.2342146635055542,
      "learning_rate": 0.0003123574606805082,
      "loss": 0.3726,
      "step": 77100
    },
    {
      "epoch": 3.139081464614634,
      "grad_norm": 0.2511315941810608,
      "learning_rate": 0.000312028839771017,
      "loss": 0.3749,
      "step": 77200
    },
    {
      "epoch": 3.1431475796450283,
      "grad_norm": 0.22652360796928406,
      "learning_rate": 0.00031170021886152573,
      "loss": 0.3721,
      "step": 77300
    },
    {
      "epoch": 3.1472136946754223,
      "grad_norm": 0.23855192959308624,
      "learning_rate": 0.0003113715979520345,
      "loss": 0.3722,
      "step": 77400
    },
    {
      "epoch": 3.151279809705817,
      "grad_norm": 0.2196006029844284,
      "learning_rate": 0.00031104297704254326,
      "loss": 0.3721,
      "step": 77500
    },
    {
      "epoch": 3.155345924736211,
      "grad_norm": 0.22040271759033203,
      "learning_rate": 0.00031071435613305205,
      "loss": 0.3715,
      "step": 77600
    },
    {
      "epoch": 3.159412039766605,
      "grad_norm": 0.23095040023326874,
      "learning_rate": 0.00031038573522356084,
      "loss": 0.3735,
      "step": 77700
    },
    {
      "epoch": 3.1634781547969992,
      "grad_norm": 0.20294466614723206,
      "learning_rate": 0.0003100571143140696,
      "loss": 0.3725,
      "step": 77800
    },
    {
      "epoch": 3.1675442698273932,
      "grad_norm": 0.26760223507881165,
      "learning_rate": 0.00030972849340457837,
      "loss": 0.3755,
      "step": 77900
    },
    {
      "epoch": 3.1716103848577877,
      "grad_norm": 0.2500278353691101,
      "learning_rate": 0.0003093998724950871,
      "loss": 0.3739,
      "step": 78000
    },
    {
      "epoch": 3.1716103848577877,
      "eval_loss": 0.3816862106323242,
      "eval_runtime": 178.1777,
      "eval_samples_per_second": 981.616,
      "eval_steps_per_second": 30.677,
      "step": 78000
    },
    {
      "epoch": 3.1756764998881817,
      "grad_norm": 0.24516363441944122,
      "learning_rate": 0.0003090712515855959,
      "loss": 0.3738,
      "step": 78100
    },
    {
      "epoch": 3.179742614918576,
      "grad_norm": 0.21566271781921387,
      "learning_rate": 0.00030874263067610464,
      "loss": 0.373,
      "step": 78200
    },
    {
      "epoch": 3.18380872994897,
      "grad_norm": 0.233263298869133,
      "learning_rate": 0.0003084140097666134,
      "loss": 0.3731,
      "step": 78300
    },
    {
      "epoch": 3.1878748449793646,
      "grad_norm": 0.21368350088596344,
      "learning_rate": 0.0003080853888571222,
      "loss": 0.3732,
      "step": 78400
    },
    {
      "epoch": 3.1919409600097586,
      "grad_norm": 0.22274495661258698,
      "learning_rate": 0.00030775676794763095,
      "loss": 0.3708,
      "step": 78500
    },
    {
      "epoch": 3.196007075040153,
      "grad_norm": 0.23309439420700073,
      "learning_rate": 0.00030742814703813975,
      "loss": 0.3734,
      "step": 78600
    },
    {
      "epoch": 3.200073190070547,
      "grad_norm": 0.2270035445690155,
      "learning_rate": 0.0003070995261286485,
      "loss": 0.3722,
      "step": 78700
    },
    {
      "epoch": 3.2041393051009415,
      "grad_norm": 0.24012111127376556,
      "learning_rate": 0.0003067709052191573,
      "loss": 0.3713,
      "step": 78800
    },
    {
      "epoch": 3.2082054201313355,
      "grad_norm": 0.2818732261657715,
      "learning_rate": 0.00030644228430966607,
      "loss": 0.3737,
      "step": 78900
    },
    {
      "epoch": 3.21227153516173,
      "grad_norm": 0.2538994252681732,
      "learning_rate": 0.0003061136634001748,
      "loss": 0.3727,
      "step": 79000
    },
    {
      "epoch": 3.216337650192124,
      "grad_norm": 0.23956553637981415,
      "learning_rate": 0.0003057850424906836,
      "loss": 0.3718,
      "step": 79100
    },
    {
      "epoch": 3.2204037652225184,
      "grad_norm": 0.22059009969234467,
      "learning_rate": 0.00030545642158119233,
      "loss": 0.3723,
      "step": 79200
    },
    {
      "epoch": 3.2244698802529124,
      "grad_norm": 0.2347526252269745,
      "learning_rate": 0.0003051278006717012,
      "loss": 0.3718,
      "step": 79300
    },
    {
      "epoch": 3.2285359952833064,
      "grad_norm": 0.22952322661876678,
      "learning_rate": 0.00030479917976220997,
      "loss": 0.3715,
      "step": 79400
    },
    {
      "epoch": 3.232602110313701,
      "grad_norm": 0.21787483990192413,
      "learning_rate": 0.0003044705588527187,
      "loss": 0.3717,
      "step": 79500
    },
    {
      "epoch": 3.236668225344095,
      "grad_norm": 0.204186350107193,
      "learning_rate": 0.0003041419379432275,
      "loss": 0.3726,
      "step": 79600
    },
    {
      "epoch": 3.2407343403744893,
      "grad_norm": 0.22948028147220612,
      "learning_rate": 0.00030381331703373623,
      "loss": 0.3712,
      "step": 79700
    },
    {
      "epoch": 3.2448004554048833,
      "grad_norm": 0.23115746676921844,
      "learning_rate": 0.000303484696124245,
      "loss": 0.3707,
      "step": 79800
    },
    {
      "epoch": 3.2488665704352777,
      "grad_norm": 0.2543678879737854,
      "learning_rate": 0.00030315607521475376,
      "loss": 0.3728,
      "step": 79900
    },
    {
      "epoch": 3.2529326854656717,
      "grad_norm": 0.23881548643112183,
      "learning_rate": 0.00030282745430526255,
      "loss": 0.3716,
      "step": 80000
    },
    {
      "epoch": 3.2529326854656717,
      "eval_loss": 0.3825821876525879,
      "eval_runtime": 178.9282,
      "eval_samples_per_second": 977.498,
      "eval_steps_per_second": 30.549,
      "step": 80000
    },
    {
      "epoch": 3.257019131071218,
      "grad_norm": 0.27163684368133545,
      "learning_rate": 0.00030249883339577134,
      "loss": 0.3713,
      "step": 80100
    },
    {
      "epoch": 3.2610852461016124,
      "grad_norm": 0.23516175150871277,
      "learning_rate": 0.0003021702124862801,
      "loss": 0.3725,
      "step": 80200
    },
    {
      "epoch": 3.2651513611320064,
      "grad_norm": 0.23159541189670563,
      "learning_rate": 0.00030184159157678887,
      "loss": 0.3714,
      "step": 80300
    },
    {
      "epoch": 3.2692174761624004,
      "grad_norm": 0.26273876428604126,
      "learning_rate": 0.0003015129706672976,
      "loss": 0.3742,
      "step": 80400
    },
    {
      "epoch": 3.273283591192795,
      "grad_norm": 0.22573453187942505,
      "learning_rate": 0.0003011843497578064,
      "loss": 0.3724,
      "step": 80500
    },
    {
      "epoch": 3.277349706223189,
      "grad_norm": 0.22973984479904175,
      "learning_rate": 0.0003008557288483152,
      "loss": 0.3717,
      "step": 80600
    },
    {
      "epoch": 3.2814158212535833,
      "grad_norm": 0.26788797974586487,
      "learning_rate": 0.0003005271079388239,
      "loss": 0.3724,
      "step": 80700
    },
    {
      "epoch": 3.2854819362839773,
      "grad_norm": 0.2577420175075531,
      "learning_rate": 0.0003001984870293327,
      "loss": 0.3732,
      "step": 80800
    },
    {
      "epoch": 3.289548051314372,
      "grad_norm": 0.23543263971805573,
      "learning_rate": 0.00029986986611984145,
      "loss": 0.3716,
      "step": 80900
    },
    {
      "epoch": 3.293614166344766,
      "grad_norm": 0.2370838224887848,
      "learning_rate": 0.00029954124521035025,
      "loss": 0.3743,
      "step": 81000
    },
    {
      "epoch": 3.2976802813751602,
      "grad_norm": 0.2661401033401489,
      "learning_rate": 0.00029921262430085904,
      "loss": 0.3721,
      "step": 81100
    },
    {
      "epoch": 3.3017463964055542,
      "grad_norm": 0.24150867760181427,
      "learning_rate": 0.0002988840033913678,
      "loss": 0.3749,
      "step": 81200
    },
    {
      "epoch": 3.3058125114359487,
      "grad_norm": 0.2663263976573944,
      "learning_rate": 0.00029855538248187656,
      "loss": 0.3705,
      "step": 81300
    },
    {
      "epoch": 3.3098786264663427,
      "grad_norm": 0.24387362599372864,
      "learning_rate": 0.0002982267615723853,
      "loss": 0.3734,
      "step": 81400
    },
    {
      "epoch": 3.313944741496737,
      "grad_norm": 0.2280982881784439,
      "learning_rate": 0.0002978981406628941,
      "loss": 0.3712,
      "step": 81500
    },
    {
      "epoch": 3.318010856527131,
      "grad_norm": 0.2405635565519333,
      "learning_rate": 0.00029756951975340283,
      "loss": 0.371,
      "step": 81600
    },
    {
      "epoch": 3.322076971557525,
      "grad_norm": 0.2474946230649948,
      "learning_rate": 0.0002972408988439116,
      "loss": 0.3721,
      "step": 81700
    },
    {
      "epoch": 3.3261430865879196,
      "grad_norm": 0.23400193452835083,
      "learning_rate": 0.0002969122779344204,
      "loss": 0.3717,
      "step": 81800
    },
    {
      "epoch": 3.330209201618314,
      "grad_norm": 0.26709723472595215,
      "learning_rate": 0.0002965836570249292,
      "loss": 0.3727,
      "step": 81900
    },
    {
      "epoch": 3.334275316648708,
      "grad_norm": 0.2554362714290619,
      "learning_rate": 0.000296255036115438,
      "loss": 0.3707,
      "step": 82000
    },
    {
      "epoch": 3.334275316648708,
      "eval_loss": 0.3816355764865875,
      "eval_runtime": 179.289,
      "eval_samples_per_second": 975.531,
      "eval_steps_per_second": 30.487,
      "step": 82000
    },
    {
      "epoch": 3.338341431679102,
      "grad_norm": 0.24179372191429138,
      "learning_rate": 0.00029592641520594673,
      "loss": 0.3725,
      "step": 82100
    },
    {
      "epoch": 3.3424075467094965,
      "grad_norm": 0.20538069307804108,
      "learning_rate": 0.0002955977942964555,
      "loss": 0.369,
      "step": 82200
    },
    {
      "epoch": 3.3464736617398905,
      "grad_norm": 0.24408110976219177,
      "learning_rate": 0.0002952691733869643,
      "loss": 0.3716,
      "step": 82300
    },
    {
      "epoch": 3.350539776770285,
      "grad_norm": 0.25038495659828186,
      "learning_rate": 0.00029494055247747305,
      "loss": 0.373,
      "step": 82400
    },
    {
      "epoch": 3.354605891800679,
      "grad_norm": 0.34137895703315735,
      "learning_rate": 0.00029461193156798184,
      "loss": 0.3716,
      "step": 82500
    },
    {
      "epoch": 3.3586720068310734,
      "grad_norm": 0.22841738164424896,
      "learning_rate": 0.0002942833106584906,
      "loss": 0.3712,
      "step": 82600
    },
    {
      "epoch": 3.3627381218614674,
      "grad_norm": 0.2776387929916382,
      "learning_rate": 0.00029395468974899937,
      "loss": 0.3734,
      "step": 82700
    },
    {
      "epoch": 3.366804236891862,
      "grad_norm": 0.2829219400882721,
      "learning_rate": 0.00029362606883950816,
      "loss": 0.3704,
      "step": 82800
    },
    {
      "epoch": 3.370870351922256,
      "grad_norm": 0.21996496617794037,
      "learning_rate": 0.0002932974479300169,
      "loss": 0.3739,
      "step": 82900
    },
    {
      "epoch": 3.3749364669526503,
      "grad_norm": 0.28721460700035095,
      "learning_rate": 0.0002929688270205257,
      "loss": 0.373,
      "step": 83000
    },
    {
      "epoch": 3.3790025819830443,
      "grad_norm": 0.2624121308326721,
      "learning_rate": 0.0002926402061110344,
      "loss": 0.3718,
      "step": 83100
    },
    {
      "epoch": 3.3830686970134387,
      "grad_norm": 0.21543070673942566,
      "learning_rate": 0.0002923115852015432,
      "loss": 0.369,
      "step": 83200
    },
    {
      "epoch": 3.3871348120438327,
      "grad_norm": 0.23749835789203644,
      "learning_rate": 0.00029198296429205195,
      "loss": 0.3722,
      "step": 83300
    },
    {
      "epoch": 3.3912009270742267,
      "grad_norm": 0.23130863904953003,
      "learning_rate": 0.00029165434338256074,
      "loss": 0.3698,
      "step": 83400
    },
    {
      "epoch": 3.395267042104621,
      "grad_norm": 0.27161258459091187,
      "learning_rate": 0.00029132572247306954,
      "loss": 0.3728,
      "step": 83500
    },
    {
      "epoch": 3.399333157135015,
      "grad_norm": 0.21738947927951813,
      "learning_rate": 0.00029099710156357827,
      "loss": 0.3693,
      "step": 83600
    },
    {
      "epoch": 3.4033992721654096,
      "grad_norm": 0.2618773281574249,
      "learning_rate": 0.00029066848065408706,
      "loss": 0.371,
      "step": 83700
    },
    {
      "epoch": 3.4074653871958036,
      "grad_norm": 0.2520848214626312,
      "learning_rate": 0.0002903398597445958,
      "loss": 0.3721,
      "step": 83800
    },
    {
      "epoch": 3.411531502226198,
      "grad_norm": 0.25807079672813416,
      "learning_rate": 0.0002900112388351046,
      "loss": 0.3713,
      "step": 83900
    },
    {
      "epoch": 3.415597617256592,
      "grad_norm": 0.2318444848060608,
      "learning_rate": 0.0002896826179256134,
      "loss": 0.3716,
      "step": 84000
    },
    {
      "epoch": 3.415597617256592,
      "eval_loss": 0.3824315369129181,
      "eval_runtime": 179.2861,
      "eval_samples_per_second": 975.547,
      "eval_steps_per_second": 30.488,
      "step": 84000
    },
    {
      "epoch": 3.4196637322869865,
      "grad_norm": 0.2364267110824585,
      "learning_rate": 0.0002893539970161221,
      "loss": 0.3699,
      "step": 84100
    },
    {
      "epoch": 3.4237298473173805,
      "grad_norm": 0.22248604893684387,
      "learning_rate": 0.0002890253761066309,
      "loss": 0.3694,
      "step": 84200
    },
    {
      "epoch": 3.427795962347775,
      "grad_norm": 0.24082320928573608,
      "learning_rate": 0.00028869675519713965,
      "loss": 0.3712,
      "step": 84300
    },
    {
      "epoch": 3.431862077378169,
      "grad_norm": 0.24325142800807953,
      "learning_rate": 0.00028836813428764844,
      "loss": 0.3697,
      "step": 84400
    },
    {
      "epoch": 3.4359281924085634,
      "grad_norm": 0.2597975432872772,
      "learning_rate": 0.0002880395133781573,
      "loss": 0.3697,
      "step": 84500
    },
    {
      "epoch": 3.4399943074389574,
      "grad_norm": 0.2691650688648224,
      "learning_rate": 0.000287710892468666,
      "loss": 0.3713,
      "step": 84600
    },
    {
      "epoch": 3.444060422469352,
      "grad_norm": 0.2345406860113144,
      "learning_rate": 0.0002873822715591748,
      "loss": 0.3701,
      "step": 84700
    },
    {
      "epoch": 3.448126537499746,
      "grad_norm": 0.2589418292045593,
      "learning_rate": 0.00028705365064968355,
      "loss": 0.3705,
      "step": 84800
    },
    {
      "epoch": 3.4521926525301403,
      "grad_norm": 0.2327764928340912,
      "learning_rate": 0.00028672502974019234,
      "loss": 0.3681,
      "step": 84900
    },
    {
      "epoch": 3.4562587675605343,
      "grad_norm": 0.22116677463054657,
      "learning_rate": 0.0002863964088307011,
      "loss": 0.3728,
      "step": 85000
    },
    {
      "epoch": 3.4603248825909283,
      "grad_norm": 0.2304118424654007,
      "learning_rate": 0.00028606778792120987,
      "loss": 0.3704,
      "step": 85100
    },
    {
      "epoch": 3.4643909976213227,
      "grad_norm": 0.2363440990447998,
      "learning_rate": 0.00028573916701171866,
      "loss": 0.3711,
      "step": 85200
    },
    {
      "epoch": 3.4684571126517167,
      "grad_norm": 0.23390579223632812,
      "learning_rate": 0.0002854105461022274,
      "loss": 0.3695,
      "step": 85300
    },
    {
      "epoch": 3.472523227682111,
      "grad_norm": 0.22879956662654877,
      "learning_rate": 0.0002850819251927362,
      "loss": 0.3704,
      "step": 85400
    },
    {
      "epoch": 3.476589342712505,
      "grad_norm": 0.2604038417339325,
      "learning_rate": 0.0002847533042832449,
      "loss": 0.3712,
      "step": 85500
    },
    {
      "epoch": 3.4806554577428996,
      "grad_norm": 0.25324034690856934,
      "learning_rate": 0.0002844246833737537,
      "loss": 0.375,
      "step": 85600
    },
    {
      "epoch": 3.4847215727732936,
      "grad_norm": 0.25143682956695557,
      "learning_rate": 0.0002840960624642625,
      "loss": 0.3712,
      "step": 85700
    },
    {
      "epoch": 3.488787687803688,
      "grad_norm": 0.3023374080657959,
      "learning_rate": 0.00028376744155477124,
      "loss": 0.3696,
      "step": 85800
    },
    {
      "epoch": 3.492853802834082,
      "grad_norm": 0.24082089960575104,
      "learning_rate": 0.00028343882064528004,
      "loss": 0.3708,
      "step": 85900
    },
    {
      "epoch": 3.4969199178644765,
      "grad_norm": 0.2845539152622223,
      "learning_rate": 0.00028311019973578877,
      "loss": 0.3694,
      "step": 86000
    },
    {
      "epoch": 3.4969199178644765,
      "eval_loss": 0.38160476088523865,
      "eval_runtime": 178.6373,
      "eval_samples_per_second": 979.09,
      "eval_steps_per_second": 30.598,
      "step": 86000
    },
    {
      "epoch": 3.5009860328948705,
      "grad_norm": 0.22536100447177887,
      "learning_rate": 0.00028278157882629756,
      "loss": 0.3713,
      "step": 86100
    },
    {
      "epoch": 3.505052147925265,
      "grad_norm": 0.2423618584871292,
      "learning_rate": 0.00028245295791680635,
      "loss": 0.3712,
      "step": 86200
    },
    {
      "epoch": 3.509118262955659,
      "grad_norm": 0.22175221145153046,
      "learning_rate": 0.0002821243370073151,
      "loss": 0.3692,
      "step": 86300
    },
    {
      "epoch": 3.513184377986053,
      "grad_norm": 0.24443559348583221,
      "learning_rate": 0.0002817957160978239,
      "loss": 0.3749,
      "step": 86400
    },
    {
      "epoch": 3.5172504930164474,
      "grad_norm": 0.26512449979782104,
      "learning_rate": 0.0002814670951883326,
      "loss": 0.3713,
      "step": 86500
    },
    {
      "epoch": 3.521316608046842,
      "grad_norm": 0.2518655061721802,
      "learning_rate": 0.0002811384742788414,
      "loss": 0.3732,
      "step": 86600
    },
    {
      "epoch": 3.525382723077236,
      "grad_norm": 0.2505931556224823,
      "learning_rate": 0.00028080985336935015,
      "loss": 0.3732,
      "step": 86700
    },
    {
      "epoch": 3.52944883810763,
      "grad_norm": 0.25578540563583374,
      "learning_rate": 0.00028048123245985894,
      "loss": 0.3717,
      "step": 86800
    },
    {
      "epoch": 3.5335149531380243,
      "grad_norm": 0.25914567708969116,
      "learning_rate": 0.00028015261155036773,
      "loss": 0.3681,
      "step": 86900
    },
    {
      "epoch": 3.5375810681684183,
      "grad_norm": 0.2790713310241699,
      "learning_rate": 0.00027982399064087647,
      "loss": 0.3712,
      "step": 87000
    },
    {
      "epoch": 3.5416471831988128,
      "grad_norm": 0.24077129364013672,
      "learning_rate": 0.00027949536973138526,
      "loss": 0.3698,
      "step": 87100
    },
    {
      "epoch": 3.545713298229207,
      "grad_norm": 0.26436880230903625,
      "learning_rate": 0.00027916674882189405,
      "loss": 0.3713,
      "step": 87200
    },
    {
      "epoch": 3.5497794132596012,
      "grad_norm": 0.2662826478481293,
      "learning_rate": 0.00027883812791240284,
      "loss": 0.3694,
      "step": 87300
    },
    {
      "epoch": 3.5538455282899952,
      "grad_norm": 0.2504550814628601,
      "learning_rate": 0.00027850950700291163,
      "loss": 0.3702,
      "step": 87400
    },
    {
      "epoch": 3.5579116433203897,
      "grad_norm": 0.24841031432151794,
      "learning_rate": 0.00027818088609342037,
      "loss": 0.3706,
      "step": 87500
    },
    {
      "epoch": 3.5619777583507837,
      "grad_norm": 0.2929099202156067,
      "learning_rate": 0.00027785226518392916,
      "loss": 0.3714,
      "step": 87600
    },
    {
      "epoch": 3.566043873381178,
      "grad_norm": 0.2621239125728607,
      "learning_rate": 0.0002775236442744379,
      "loss": 0.3713,
      "step": 87700
    },
    {
      "epoch": 3.570109988411572,
      "grad_norm": 0.22786949574947357,
      "learning_rate": 0.0002771950233649467,
      "loss": 0.3699,
      "step": 87800
    },
    {
      "epoch": 3.5741761034419666,
      "grad_norm": 0.22758400440216064,
      "learning_rate": 0.0002768664024554555,
      "loss": 0.3714,
      "step": 87900
    },
    {
      "epoch": 3.5782422184723606,
      "grad_norm": 0.2617034912109375,
      "learning_rate": 0.0002765377815459642,
      "loss": 0.37,
      "step": 88000
    },
    {
      "epoch": 3.5782422184723606,
      "eval_loss": 0.3801674544811249,
      "eval_runtime": 179.3026,
      "eval_samples_per_second": 975.457,
      "eval_steps_per_second": 30.485,
      "step": 88000
    },
    {
      "epoch": 3.5823083335027546,
      "grad_norm": 0.23211005330085754,
      "learning_rate": 0.000276209160636473,
      "loss": 0.3711,
      "step": 88100
    },
    {
      "epoch": 3.586374448533149,
      "grad_norm": 0.2649679183959961,
      "learning_rate": 0.00027588053972698174,
      "loss": 0.3701,
      "step": 88200
    },
    {
      "epoch": 3.5904405635635435,
      "grad_norm": 0.24314498901367188,
      "learning_rate": 0.00027555191881749053,
      "loss": 0.3723,
      "step": 88300
    },
    {
      "epoch": 3.5945066785939375,
      "grad_norm": 0.2586786150932312,
      "learning_rate": 0.00027522329790799927,
      "loss": 0.372,
      "step": 88400
    },
    {
      "epoch": 3.5985727936243315,
      "grad_norm": 0.23610512912273407,
      "learning_rate": 0.00027489467699850806,
      "loss": 0.3695,
      "step": 88500
    },
    {
      "epoch": 3.602638908654726,
      "grad_norm": 0.2531549036502838,
      "learning_rate": 0.00027456605608901685,
      "loss": 0.3711,
      "step": 88600
    },
    {
      "epoch": 3.60670502368512,
      "grad_norm": 0.2529066503047943,
      "learning_rate": 0.0002742374351795256,
      "loss": 0.3716,
      "step": 88700
    },
    {
      "epoch": 3.6107711387155144,
      "grad_norm": 0.24111460149288177,
      "learning_rate": 0.0002739088142700344,
      "loss": 0.3714,
      "step": 88800
    },
    {
      "epoch": 3.6148372537459084,
      "grad_norm": 0.266176700592041,
      "learning_rate": 0.0002735801933605431,
      "loss": 0.3682,
      "step": 88900
    },
    {
      "epoch": 3.618903368776303,
      "grad_norm": 0.2507842779159546,
      "learning_rate": 0.0002732515724510519,
      "loss": 0.3709,
      "step": 89000
    },
    {
      "epoch": 3.622969483806697,
      "grad_norm": 0.24534085392951965,
      "learning_rate": 0.0002729229515415607,
      "loss": 0.3729,
      "step": 89100
    },
    {
      "epoch": 3.6270355988370913,
      "grad_norm": 0.24601559340953827,
      "learning_rate": 0.00027259433063206944,
      "loss": 0.3686,
      "step": 89200
    },
    {
      "epoch": 3.6311017138674853,
      "grad_norm": 0.2670627534389496,
      "learning_rate": 0.00027226570972257823,
      "loss": 0.3705,
      "step": 89300
    },
    {
      "epoch": 3.6351678288978793,
      "grad_norm": 0.29728230834007263,
      "learning_rate": 0.00027193708881308697,
      "loss": 0.3714,
      "step": 89400
    },
    {
      "epoch": 3.6392339439282737,
      "grad_norm": 0.24689394235610962,
      "learning_rate": 0.00027160846790359576,
      "loss": 0.3709,
      "step": 89500
    },
    {
      "epoch": 3.643300058958668,
      "grad_norm": 0.24005889892578125,
      "learning_rate": 0.00027127984699410455,
      "loss": 0.3675,
      "step": 89600
    },
    {
      "epoch": 3.647366173989062,
      "grad_norm": 0.27053409814834595,
      "learning_rate": 0.0002709512260846133,
      "loss": 0.3685,
      "step": 89700
    },
    {
      "epoch": 3.651432289019456,
      "grad_norm": 0.26794540882110596,
      "learning_rate": 0.00027062260517512213,
      "loss": 0.37,
      "step": 89800
    },
    {
      "epoch": 3.6554984040498506,
      "grad_norm": 0.2586004436016083,
      "learning_rate": 0.00027029398426563087,
      "loss": 0.3707,
      "step": 89900
    },
    {
      "epoch": 3.659564519080245,
      "grad_norm": 0.2787366509437561,
      "learning_rate": 0.00026996536335613966,
      "loss": 0.3685,
      "step": 90000
    },
    {
      "epoch": 3.659564519080245,
      "eval_loss": 0.37959185242652893,
      "eval_runtime": 175.0024,
      "eval_samples_per_second": 999.426,
      "eval_steps_per_second": 31.234,
      "step": 90000
    },
    {
      "epoch": 3.663630634110639,
      "grad_norm": 0.26756200194358826,
      "learning_rate": 0.0002696367424466484,
      "loss": 0.3687,
      "step": 90100
    },
    {
      "epoch": 3.667696749141033,
      "grad_norm": 0.2415892630815506,
      "learning_rate": 0.0002693081215371572,
      "loss": 0.3734,
      "step": 90200
    },
    {
      "epoch": 3.6717628641714275,
      "grad_norm": 0.21670378744602203,
      "learning_rate": 0.000268979500627666,
      "loss": 0.3688,
      "step": 90300
    },
    {
      "epoch": 3.6758289792018215,
      "grad_norm": 0.2738523781299591,
      "learning_rate": 0.0002686508797181747,
      "loss": 0.3693,
      "step": 90400
    },
    {
      "epoch": 3.679895094232216,
      "grad_norm": 0.2506847083568573,
      "learning_rate": 0.0002683222588086835,
      "loss": 0.3694,
      "step": 90500
    },
    {
      "epoch": 3.68396120926261,
      "grad_norm": 0.25142595171928406,
      "learning_rate": 0.00026799363789919224,
      "loss": 0.3702,
      "step": 90600
    },
    {
      "epoch": 3.6880273242930044,
      "grad_norm": 0.23371033370494843,
      "learning_rate": 0.00026766501698970103,
      "loss": 0.3694,
      "step": 90700
    },
    {
      "epoch": 3.6920934393233984,
      "grad_norm": 0.26692429184913635,
      "learning_rate": 0.0002673363960802098,
      "loss": 0.3693,
      "step": 90800
    },
    {
      "epoch": 3.696159554353793,
      "grad_norm": 0.23246455192565918,
      "learning_rate": 0.00026700777517071856,
      "loss": 0.3715,
      "step": 90900
    },
    {
      "epoch": 3.700225669384187,
      "grad_norm": 0.24133802950382233,
      "learning_rate": 0.00026667915426122735,
      "loss": 0.3691,
      "step": 91000
    },
    {
      "epoch": 3.704291784414581,
      "grad_norm": 0.2670142650604248,
      "learning_rate": 0.0002663505333517361,
      "loss": 0.3684,
      "step": 91100
    },
    {
      "epoch": 3.7083578994449753,
      "grad_norm": 0.2745656371116638,
      "learning_rate": 0.0002660219124422449,
      "loss": 0.3677,
      "step": 91200
    },
    {
      "epoch": 3.7124240144753697,
      "grad_norm": 0.2763259708881378,
      "learning_rate": 0.00026569329153275367,
      "loss": 0.3691,
      "step": 91300
    },
    {
      "epoch": 3.7164901295057637,
      "grad_norm": 0.2904508113861084,
      "learning_rate": 0.0002653646706232624,
      "loss": 0.3715,
      "step": 91400
    },
    {
      "epoch": 3.7205562445361577,
      "grad_norm": 0.26007553935050964,
      "learning_rate": 0.0002650360497137712,
      "loss": 0.3691,
      "step": 91500
    },
    {
      "epoch": 3.724622359566552,
      "grad_norm": 0.251376211643219,
      "learning_rate": 0.00026470742880427994,
      "loss": 0.3716,
      "step": 91600
    },
    {
      "epoch": 3.728688474596946,
      "grad_norm": 0.2754133343696594,
      "learning_rate": 0.00026437880789478873,
      "loss": 0.3675,
      "step": 91700
    },
    {
      "epoch": 3.7327545896273406,
      "grad_norm": 0.2311718761920929,
      "learning_rate": 0.00026405018698529747,
      "loss": 0.3712,
      "step": 91800
    },
    {
      "epoch": 3.7368207046577346,
      "grad_norm": 0.3294662535190582,
      "learning_rate": 0.00026372156607580626,
      "loss": 0.3692,
      "step": 91900
    },
    {
      "epoch": 3.740886819688129,
      "grad_norm": 0.26127028465270996,
      "learning_rate": 0.00026339294516631505,
      "loss": 0.3704,
      "step": 92000
    },
    {
      "epoch": 3.740886819688129,
      "eval_loss": 0.3805251121520996,
      "eval_runtime": 175.8575,
      "eval_samples_per_second": 994.567,
      "eval_steps_per_second": 31.082,
      "step": 92000
    },
    {
      "epoch": 3.744952934718523,
      "grad_norm": 0.24447111785411835,
      "learning_rate": 0.0002630643242568238,
      "loss": 0.3689,
      "step": 92100
    },
    {
      "epoch": 3.7490190497489175,
      "grad_norm": 0.27085742354393005,
      "learning_rate": 0.0002627357033473326,
      "loss": 0.3686,
      "step": 92200
    },
    {
      "epoch": 3.7530851647793115,
      "grad_norm": 0.2565823495388031,
      "learning_rate": 0.0002624070824378413,
      "loss": 0.3693,
      "step": 92300
    },
    {
      "epoch": 3.757151279809706,
      "grad_norm": 0.27937260270118713,
      "learning_rate": 0.00026207846152835016,
      "loss": 0.3696,
      "step": 92400
    },
    {
      "epoch": 3.7612173948401,
      "grad_norm": 0.2746233344078064,
      "learning_rate": 0.00026174984061885895,
      "loss": 0.3688,
      "step": 92500
    },
    {
      "epoch": 3.7652835098704944,
      "grad_norm": 0.2804737687110901,
      "learning_rate": 0.0002614212197093677,
      "loss": 0.3679,
      "step": 92600
    },
    {
      "epoch": 3.7693496249008884,
      "grad_norm": 0.23958329856395721,
      "learning_rate": 0.0002610925987998765,
      "loss": 0.3699,
      "step": 92700
    },
    {
      "epoch": 3.7734157399312824,
      "grad_norm": 0.2379169911146164,
      "learning_rate": 0.0002607639778903852,
      "loss": 0.3701,
      "step": 92800
    },
    {
      "epoch": 3.777481854961677,
      "grad_norm": 0.2616002857685089,
      "learning_rate": 0.000260435356980894,
      "loss": 0.3692,
      "step": 92900
    },
    {
      "epoch": 3.7815479699920713,
      "grad_norm": 0.2552104592323303,
      "learning_rate": 0.0002601067360714028,
      "loss": 0.3687,
      "step": 93000
    },
    {
      "epoch": 3.7856140850224653,
      "grad_norm": 0.23289427161216736,
      "learning_rate": 0.00025977811516191153,
      "loss": 0.3687,
      "step": 93100
    },
    {
      "epoch": 3.7896802000528593,
      "grad_norm": 0.24796833097934723,
      "learning_rate": 0.0002594494942524203,
      "loss": 0.3708,
      "step": 93200
    },
    {
      "epoch": 3.7937463150832538,
      "grad_norm": 0.3001103401184082,
      "learning_rate": 0.00025912087334292906,
      "loss": 0.3694,
      "step": 93300
    },
    {
      "epoch": 3.7978124301136478,
      "grad_norm": 0.25714775919914246,
      "learning_rate": 0.00025879225243343785,
      "loss": 0.3681,
      "step": 93400
    },
    {
      "epoch": 3.801878545144042,
      "grad_norm": 0.2803042232990265,
      "learning_rate": 0.0002584636315239466,
      "loss": 0.3688,
      "step": 93500
    },
    {
      "epoch": 3.8059446601744362,
      "grad_norm": 0.2593652307987213,
      "learning_rate": 0.0002581350106144554,
      "loss": 0.3701,
      "step": 93600
    },
    {
      "epoch": 3.8100107752048307,
      "grad_norm": 0.24127285182476044,
      "learning_rate": 0.00025780638970496417,
      "loss": 0.3681,
      "step": 93700
    },
    {
      "epoch": 3.8140768902352247,
      "grad_norm": 0.24651867151260376,
      "learning_rate": 0.0002574777687954729,
      "loss": 0.3688,
      "step": 93800
    },
    {
      "epoch": 3.818143005265619,
      "grad_norm": 0.2984698712825775,
      "learning_rate": 0.0002571491478859817,
      "loss": 0.3702,
      "step": 93900
    },
    {
      "epoch": 3.822209120296013,
      "grad_norm": 0.24101978540420532,
      "learning_rate": 0.00025682052697649044,
      "loss": 0.3674,
      "step": 94000
    },
    {
      "epoch": 3.822209120296013,
      "eval_loss": 0.37811729311943054,
      "eval_runtime": 178.2292,
      "eval_samples_per_second": 981.332,
      "eval_steps_per_second": 30.668,
      "step": 94000
    },
    {
      "epoch": 3.826275235326407,
      "grad_norm": 0.24856361746788025,
      "learning_rate": 0.00025649190606699923,
      "loss": 0.3692,
      "step": 94100
    },
    {
      "epoch": 3.8303413503568016,
      "grad_norm": 0.2555156946182251,
      "learning_rate": 0.000256163285157508,
      "loss": 0.3685,
      "step": 94200
    },
    {
      "epoch": 3.834407465387196,
      "grad_norm": 0.2676476538181305,
      "learning_rate": 0.00025583466424801676,
      "loss": 0.3675,
      "step": 94300
    },
    {
      "epoch": 3.83847358041759,
      "grad_norm": 0.24484103918075562,
      "learning_rate": 0.00025550604333852555,
      "loss": 0.366,
      "step": 94400
    },
    {
      "epoch": 3.842539695447984,
      "grad_norm": 0.2674429714679718,
      "learning_rate": 0.0002551774224290343,
      "loss": 0.3696,
      "step": 94500
    },
    {
      "epoch": 3.8466058104783785,
      "grad_norm": 0.27148833870887756,
      "learning_rate": 0.0002548488015195431,
      "loss": 0.3678,
      "step": 94600
    },
    {
      "epoch": 3.850671925508773,
      "grad_norm": 0.3049772083759308,
      "learning_rate": 0.00025452018061005187,
      "loss": 0.3714,
      "step": 94700
    },
    {
      "epoch": 3.854738040539167,
      "grad_norm": 0.28183621168136597,
      "learning_rate": 0.0002541915597005606,
      "loss": 0.3659,
      "step": 94800
    },
    {
      "epoch": 3.858804155569561,
      "grad_norm": 0.24145838618278503,
      "learning_rate": 0.0002538629387910694,
      "loss": 0.3682,
      "step": 94900
    },
    {
      "epoch": 3.8628702705999554,
      "grad_norm": 0.2925891578197479,
      "learning_rate": 0.00025353431788157813,
      "loss": 0.3687,
      "step": 95000
    },
    {
      "epoch": 3.8669363856303494,
      "grad_norm": 0.33163073658943176,
      "learning_rate": 0.000253205696972087,
      "loss": 0.3696,
      "step": 95100
    },
    {
      "epoch": 3.871002500660744,
      "grad_norm": 0.27923262119293213,
      "learning_rate": 0.0002528770760625957,
      "loss": 0.3666,
      "step": 95200
    },
    {
      "epoch": 3.875068615691138,
      "grad_norm": 0.26990652084350586,
      "learning_rate": 0.0002525484551531045,
      "loss": 0.3666,
      "step": 95300
    },
    {
      "epoch": 3.8791347307215323,
      "grad_norm": 0.24634326994419098,
      "learning_rate": 0.0002522198342436133,
      "loss": 0.3659,
      "step": 95400
    },
    {
      "epoch": 3.8832008457519263,
      "grad_norm": 0.27203041315078735,
      "learning_rate": 0.00025189121333412203,
      "loss": 0.3685,
      "step": 95500
    },
    {
      "epoch": 3.8872669607823207,
      "grad_norm": 0.2466798722743988,
      "learning_rate": 0.0002515625924246308,
      "loss": 0.3681,
      "step": 95600
    },
    {
      "epoch": 3.8913330758127147,
      "grad_norm": 0.2765027582645416,
      "learning_rate": 0.00025123397151513956,
      "loss": 0.3672,
      "step": 95700
    },
    {
      "epoch": 3.8953991908431087,
      "grad_norm": 0.3053370714187622,
      "learning_rate": 0.00025090535060564835,
      "loss": 0.3686,
      "step": 95800
    },
    {
      "epoch": 3.899465305873503,
      "grad_norm": 0.2604954242706299,
      "learning_rate": 0.00025057672969615714,
      "loss": 0.3657,
      "step": 95900
    },
    {
      "epoch": 3.9035314209038976,
      "grad_norm": 0.27237918972969055,
      "learning_rate": 0.0002502481087866659,
      "loss": 0.3674,
      "step": 96000
    },
    {
      "epoch": 3.9035314209038976,
      "eval_loss": 0.3779986798763275,
      "eval_runtime": 178.5377,
      "eval_samples_per_second": 979.636,
      "eval_steps_per_second": 30.615,
      "step": 96000
    },
    {
      "epoch": 3.9075975359342916,
      "grad_norm": 0.32355600595474243,
      "learning_rate": 0.00024991948787717467,
      "loss": 0.3677,
      "step": 96100
    },
    {
      "epoch": 3.9116636509646856,
      "grad_norm": 0.3131120502948761,
      "learning_rate": 0.0002495908669676834,
      "loss": 0.3681,
      "step": 96200
    },
    {
      "epoch": 3.91572976599508,
      "grad_norm": 0.24208204448223114,
      "learning_rate": 0.0002492622460581922,
      "loss": 0.3653,
      "step": 96300
    },
    {
      "epoch": 3.919795881025474,
      "grad_norm": 0.24221740663051605,
      "learning_rate": 0.000248933625148701,
      "loss": 0.367,
      "step": 96400
    },
    {
      "epoch": 3.9238619960558685,
      "grad_norm": 0.2702468931674957,
      "learning_rate": 0.00024860500423920973,
      "loss": 0.3688,
      "step": 96500
    },
    {
      "epoch": 3.9279281110862625,
      "grad_norm": 0.24596203863620758,
      "learning_rate": 0.0002482763833297185,
      "loss": 0.3669,
      "step": 96600
    },
    {
      "epoch": 3.931994226116657,
      "grad_norm": 0.2554859220981598,
      "learning_rate": 0.0002479477624202273,
      "loss": 0.3673,
      "step": 96700
    },
    {
      "epoch": 3.936060341147051,
      "grad_norm": 0.26416030526161194,
      "learning_rate": 0.00024761914151073605,
      "loss": 0.3673,
      "step": 96800
    },
    {
      "epoch": 3.9401264561774454,
      "grad_norm": 0.25677940249443054,
      "learning_rate": 0.00024729052060124484,
      "loss": 0.3675,
      "step": 96900
    },
    {
      "epoch": 3.9441925712078394,
      "grad_norm": 0.25962698459625244,
      "learning_rate": 0.0002469618996917536,
      "loss": 0.3646,
      "step": 97000
    },
    {
      "epoch": 3.948258686238234,
      "grad_norm": 0.304323673248291,
      "learning_rate": 0.00024663327878226237,
      "loss": 0.3688,
      "step": 97100
    },
    {
      "epoch": 3.952324801268628,
      "grad_norm": 0.2729927599430084,
      "learning_rate": 0.0002463046578727711,
      "loss": 0.3688,
      "step": 97200
    },
    {
      "epoch": 3.9563909162990223,
      "grad_norm": 0.3101339340209961,
      "learning_rate": 0.0002459760369632799,
      "loss": 0.369,
      "step": 97300
    },
    {
      "epoch": 3.9604570313294163,
      "grad_norm": 0.26683172583580017,
      "learning_rate": 0.0002456474160537887,
      "loss": 0.3683,
      "step": 97400
    },
    {
      "epoch": 3.9645231463598103,
      "grad_norm": 0.3030953109264374,
      "learning_rate": 0.0002453187951442974,
      "loss": 0.367,
      "step": 97500
    },
    {
      "epoch": 3.9685892613902047,
      "grad_norm": 0.24420908093452454,
      "learning_rate": 0.0002449901742348062,
      "loss": 0.3683,
      "step": 97600
    },
    {
      "epoch": 3.972655376420599,
      "grad_norm": 0.2704066336154938,
      "learning_rate": 0.000244661553325315,
      "loss": 0.3693,
      "step": 97700
    },
    {
      "epoch": 3.976721491450993,
      "grad_norm": 0.2960028648376465,
      "learning_rate": 0.0002443329324158238,
      "loss": 0.367,
      "step": 97800
    },
    {
      "epoch": 3.980787606481387,
      "grad_norm": 0.29430893063545227,
      "learning_rate": 0.00024400431150633253,
      "loss": 0.3675,
      "step": 97900
    },
    {
      "epoch": 3.9848537215117816,
      "grad_norm": 0.2822321653366089,
      "learning_rate": 0.0002436756905968413,
      "loss": 0.3682,
      "step": 98000
    },
    {
      "epoch": 3.9848537215117816,
      "eval_loss": 0.3779275417327881,
      "eval_runtime": 178.7639,
      "eval_samples_per_second": 978.397,
      "eval_steps_per_second": 30.577,
      "step": 98000
    },
    {
      "epoch": 3.9889198365421756,
      "grad_norm": 0.30759748816490173,
      "learning_rate": 0.00024334706968735006,
      "loss": 0.3675,
      "step": 98100
    },
    {
      "epoch": 3.99298595157257,
      "grad_norm": 0.26765570044517517,
      "learning_rate": 0.00024301844877785882,
      "loss": 0.3674,
      "step": 98200
    },
    {
      "epoch": 3.997052066602964,
      "grad_norm": 0.26815786957740784,
      "learning_rate": 0.0002426898278683676,
      "loss": 0.3668,
      "step": 98300
    },
    {
      "epoch": 4.001118181633358,
      "grad_norm": 0.2623452842235565,
      "learning_rate": 0.0002423612069588764,
      "loss": 0.367,
      "step": 98400
    },
    {
      "epoch": 4.005184296663753,
      "grad_norm": 0.26423391699790955,
      "learning_rate": 0.00024203258604938517,
      "loss": 0.3657,
      "step": 98500
    },
    {
      "epoch": 4.009250411694147,
      "grad_norm": 0.30569887161254883,
      "learning_rate": 0.00024170396513989393,
      "loss": 0.3634,
      "step": 98600
    },
    {
      "epoch": 4.013316526724541,
      "grad_norm": 0.2531425356864929,
      "learning_rate": 0.0002413753442304027,
      "loss": 0.3638,
      "step": 98700
    },
    {
      "epoch": 4.017382641754935,
      "grad_norm": 0.2987527549266815,
      "learning_rate": 0.00024104672332091146,
      "loss": 0.3687,
      "step": 98800
    },
    {
      "epoch": 4.02144875678533,
      "grad_norm": 0.27737942337989807,
      "learning_rate": 0.00024071810241142023,
      "loss": 0.3641,
      "step": 98900
    },
    {
      "epoch": 4.025514871815724,
      "grad_norm": 0.26265913248062134,
      "learning_rate": 0.00024038948150192902,
      "loss": 0.3632,
      "step": 99000
    },
    {
      "epoch": 4.029580986846118,
      "grad_norm": 0.2736159563064575,
      "learning_rate": 0.00024006086059243778,
      "loss": 0.3663,
      "step": 99100
    },
    {
      "epoch": 4.033647101876512,
      "grad_norm": 0.30268728733062744,
      "learning_rate": 0.00023973223968294655,
      "loss": 0.3653,
      "step": 99200
    },
    {
      "epoch": 4.037713216906906,
      "grad_norm": 0.29075485467910767,
      "learning_rate": 0.0002394036187734553,
      "loss": 0.3635,
      "step": 99300
    },
    {
      "epoch": 4.041779331937301,
      "grad_norm": 0.2820662558078766,
      "learning_rate": 0.00023907499786396407,
      "loss": 0.3679,
      "step": 99400
    },
    {
      "epoch": 4.045845446967695,
      "grad_norm": 0.25403085350990295,
      "learning_rate": 0.00023874637695447287,
      "loss": 0.3664,
      "step": 99500
    },
    {
      "epoch": 4.049911561998089,
      "grad_norm": 0.2928805649280548,
      "learning_rate": 0.00023841775604498163,
      "loss": 0.3638,
      "step": 99600
    },
    {
      "epoch": 4.053977677028483,
      "grad_norm": 0.25409653782844543,
      "learning_rate": 0.00023808913513549042,
      "loss": 0.3678,
      "step": 99700
    },
    {
      "epoch": 4.058043792058878,
      "grad_norm": 0.28001654148101807,
      "learning_rate": 0.00023776051422599918,
      "loss": 0.3642,
      "step": 99800
    },
    {
      "epoch": 4.062109907089272,
      "grad_norm": 0.27598127722740173,
      "learning_rate": 0.00023743189331650795,
      "loss": 0.3663,
      "step": 99900
    },
    {
      "epoch": 4.066176022119666,
      "grad_norm": 0.2754174470901489,
      "learning_rate": 0.0002371032724070167,
      "loss": 0.3665,
      "step": 100000
    },
    {
      "epoch": 4.066176022119666,
      "eval_loss": 0.3780457675457001,
      "eval_runtime": 178.1679,
      "eval_samples_per_second": 981.669,
      "eval_steps_per_second": 30.679,
      "step": 100000
    },
    {
      "epoch": 4.07024213715006,
      "grad_norm": 0.2862696349620819,
      "learning_rate": 0.0002367746514975255,
      "loss": 0.3643,
      "step": 100100
    },
    {
      "epoch": 4.074308252180455,
      "grad_norm": 0.2482278198003769,
      "learning_rate": 0.00023644603058803427,
      "loss": 0.3634,
      "step": 100200
    },
    {
      "epoch": 4.078374367210849,
      "grad_norm": 0.2752890884876251,
      "learning_rate": 0.00023611740967854303,
      "loss": 0.3655,
      "step": 100300
    },
    {
      "epoch": 4.082440482241243,
      "grad_norm": 0.2886168360710144,
      "learning_rate": 0.0002357887887690518,
      "loss": 0.3672,
      "step": 100400
    },
    {
      "epoch": 4.086506597271637,
      "grad_norm": 0.2736565172672272,
      "learning_rate": 0.00023546016785956056,
      "loss": 0.3657,
      "step": 100500
    },
    {
      "epoch": 4.0905727123020315,
      "grad_norm": 0.28593581914901733,
      "learning_rate": 0.00023513154695006932,
      "loss": 0.365,
      "step": 100600
    },
    {
      "epoch": 4.0946388273324255,
      "grad_norm": 0.26908278465270996,
      "learning_rate": 0.00023480292604057812,
      "loss": 0.3662,
      "step": 100700
    },
    {
      "epoch": 4.0987049423628195,
      "grad_norm": 0.24981877207756042,
      "learning_rate": 0.00023447430513108688,
      "loss": 0.3649,
      "step": 100800
    },
    {
      "epoch": 4.1027710573932135,
      "grad_norm": 0.29402223229408264,
      "learning_rate": 0.00023414568422159564,
      "loss": 0.3637,
      "step": 100900
    },
    {
      "epoch": 4.1068371724236075,
      "grad_norm": 0.3126484751701355,
      "learning_rate": 0.00023381706331210443,
      "loss": 0.366,
      "step": 101000
    },
    {
      "epoch": 4.110903287454002,
      "grad_norm": 0.2807101905345917,
      "learning_rate": 0.0002334884424026132,
      "loss": 0.3673,
      "step": 101100
    },
    {
      "epoch": 4.114969402484396,
      "grad_norm": 0.295787513256073,
      "learning_rate": 0.000233159821493122,
      "loss": 0.364,
      "step": 101200
    },
    {
      "epoch": 4.11903551751479,
      "grad_norm": 0.2640732526779175,
      "learning_rate": 0.00023283120058363075,
      "loss": 0.3642,
      "step": 101300
    },
    {
      "epoch": 4.123101632545184,
      "grad_norm": 0.2739153802394867,
      "learning_rate": 0.00023250257967413952,
      "loss": 0.3649,
      "step": 101400
    },
    {
      "epoch": 4.127167747575579,
      "grad_norm": 0.25516924262046814,
      "learning_rate": 0.00023217395876464828,
      "loss": 0.365,
      "step": 101500
    },
    {
      "epoch": 4.131233862605973,
      "grad_norm": 0.31870707869529724,
      "learning_rate": 0.00023184533785515705,
      "loss": 0.3652,
      "step": 101600
    },
    {
      "epoch": 4.135299977636367,
      "grad_norm": 0.28129222989082336,
      "learning_rate": 0.0002315167169456658,
      "loss": 0.3645,
      "step": 101700
    },
    {
      "epoch": 4.139366092666761,
      "grad_norm": 0.3139210343360901,
      "learning_rate": 0.0002311880960361746,
      "loss": 0.3666,
      "step": 101800
    },
    {
      "epoch": 4.143432207697156,
      "grad_norm": 0.8678702712059021,
      "learning_rate": 0.00023085947512668336,
      "loss": 0.3663,
      "step": 101900
    },
    {
      "epoch": 4.14749832272755,
      "grad_norm": 0.2731507122516632,
      "learning_rate": 0.00023053085421719213,
      "loss": 0.3635,
      "step": 102000
    },
    {
      "epoch": 4.14749832272755,
      "eval_loss": 0.3755834400653839,
      "eval_runtime": 177.2985,
      "eval_samples_per_second": 986.483,
      "eval_steps_per_second": 30.829,
      "step": 102000
    },
    {
      "epoch": 4.151564437757944,
      "grad_norm": 0.2771477699279785,
      "learning_rate": 0.0002302022333077009,
      "loss": 0.3653,
      "step": 102100
    },
    {
      "epoch": 4.155630552788338,
      "grad_norm": 0.2728710472583771,
      "learning_rate": 0.00022987361239820966,
      "loss": 0.3654,
      "step": 102200
    },
    {
      "epoch": 4.159696667818732,
      "grad_norm": 0.3397580087184906,
      "learning_rate": 0.00022954499148871845,
      "loss": 0.3642,
      "step": 102300
    },
    {
      "epoch": 4.163762782849127,
      "grad_norm": 0.26658734679222107,
      "learning_rate": 0.00022921637057922724,
      "loss": 0.3637,
      "step": 102400
    },
    {
      "epoch": 4.167828897879521,
      "grad_norm": 0.30358800292015076,
      "learning_rate": 0.000228887749669736,
      "loss": 0.3639,
      "step": 102500
    },
    {
      "epoch": 4.171895012909915,
      "grad_norm": 0.28713053464889526,
      "learning_rate": 0.00022855912876024477,
      "loss": 0.3635,
      "step": 102600
    },
    {
      "epoch": 4.175961127940309,
      "grad_norm": 0.30109962821006775,
      "learning_rate": 0.00022823050785075353,
      "loss": 0.3631,
      "step": 102700
    },
    {
      "epoch": 4.180027242970704,
      "grad_norm": 0.2642726004123688,
      "learning_rate": 0.0002279018869412623,
      "loss": 0.3644,
      "step": 102800
    },
    {
      "epoch": 4.184093358001098,
      "grad_norm": 0.25467345118522644,
      "learning_rate": 0.0002275732660317711,
      "loss": 0.366,
      "step": 102900
    },
    {
      "epoch": 4.188159473031492,
      "grad_norm": 0.26631444692611694,
      "learning_rate": 0.00022724464512227985,
      "loss": 0.364,
      "step": 103000
    },
    {
      "epoch": 4.192225588061886,
      "grad_norm": 0.3017711937427521,
      "learning_rate": 0.00022691602421278861,
      "loss": 0.3667,
      "step": 103100
    },
    {
      "epoch": 4.196291703092281,
      "grad_norm": 0.2683909833431244,
      "learning_rate": 0.00022658740330329738,
      "loss": 0.3657,
      "step": 103200
    },
    {
      "epoch": 4.200357818122675,
      "grad_norm": 0.2743692696094513,
      "learning_rate": 0.00022625878239380614,
      "loss": 0.362,
      "step": 103300
    },
    {
      "epoch": 4.204423933153069,
      "grad_norm": 0.2983905076980591,
      "learning_rate": 0.0002259301614843149,
      "loss": 0.3636,
      "step": 103400
    },
    {
      "epoch": 4.208490048183463,
      "grad_norm": 0.2689921259880066,
      "learning_rate": 0.0002256015405748237,
      "loss": 0.3638,
      "step": 103500
    },
    {
      "epoch": 4.212556163213858,
      "grad_norm": 0.33769506216049194,
      "learning_rate": 0.0002252729196653325,
      "loss": 0.3629,
      "step": 103600
    },
    {
      "epoch": 4.216622278244252,
      "grad_norm": 0.3095058798789978,
      "learning_rate": 0.00022494429875584125,
      "loss": 0.3628,
      "step": 103700
    },
    {
      "epoch": 4.220688393274646,
      "grad_norm": 0.2985333800315857,
      "learning_rate": 0.00022461567784635002,
      "loss": 0.3644,
      "step": 103800
    },
    {
      "epoch": 4.22475450830504,
      "grad_norm": 0.2564125061035156,
      "learning_rate": 0.00022428705693685878,
      "loss": 0.3652,
      "step": 103900
    },
    {
      "epoch": 4.228820623335434,
      "grad_norm": 0.27131062746047974,
      "learning_rate": 0.00022395843602736755,
      "loss": 0.3667,
      "step": 104000
    },
    {
      "epoch": 4.228820623335434,
      "eval_loss": 0.3750140368938446,
      "eval_runtime": 178.684,
      "eval_samples_per_second": 978.834,
      "eval_steps_per_second": 30.59,
      "step": 104000
    },
    {
      "epoch": 4.232886738365829,
      "grad_norm": 0.27907121181488037,
      "learning_rate": 0.00022362981511787634,
      "loss": 0.3648,
      "step": 104100
    },
    {
      "epoch": 4.236952853396223,
      "grad_norm": 0.27802571654319763,
      "learning_rate": 0.0002233011942083851,
      "loss": 0.366,
      "step": 104200
    },
    {
      "epoch": 4.241018968426617,
      "grad_norm": 0.27468395233154297,
      "learning_rate": 0.00022297257329889386,
      "loss": 0.3663,
      "step": 104300
    },
    {
      "epoch": 4.245085083457011,
      "grad_norm": 0.3063121736049652,
      "learning_rate": 0.00022264395238940263,
      "loss": 0.3647,
      "step": 104400
    },
    {
      "epoch": 4.2491511984874055,
      "grad_norm": 0.24222159385681152,
      "learning_rate": 0.0002223153314799114,
      "loss": 0.3639,
      "step": 104500
    },
    {
      "epoch": 4.2532173135177995,
      "grad_norm": 0.25832095742225647,
      "learning_rate": 0.00022198671057042018,
      "loss": 0.3656,
      "step": 104600
    },
    {
      "epoch": 4.2572834285481935,
      "grad_norm": 0.3430396020412445,
      "learning_rate": 0.00022165808966092895,
      "loss": 0.3646,
      "step": 104700
    },
    {
      "epoch": 4.2613495435785875,
      "grad_norm": 0.3180409371852875,
      "learning_rate": 0.0002213294687514377,
      "loss": 0.3626,
      "step": 104800
    },
    {
      "epoch": 4.265415658608982,
      "grad_norm": 0.28516310453414917,
      "learning_rate": 0.0002210008478419465,
      "loss": 0.3641,
      "step": 104900
    },
    {
      "epoch": 4.269481773639376,
      "grad_norm": 0.28299784660339355,
      "learning_rate": 0.00022067222693245527,
      "loss": 0.3658,
      "step": 105000
    },
    {
      "epoch": 4.27354788866977,
      "grad_norm": 0.2698621153831482,
      "learning_rate": 0.00022034360602296403,
      "loss": 0.3649,
      "step": 105100
    },
    {
      "epoch": 4.277614003700164,
      "grad_norm": 0.2697751224040985,
      "learning_rate": 0.00022001498511347282,
      "loss": 0.3638,
      "step": 105200
    },
    {
      "epoch": 4.281680118730559,
      "grad_norm": 0.2828874886035919,
      "learning_rate": 0.00021968636420398159,
      "loss": 0.3642,
      "step": 105300
    },
    {
      "epoch": 4.285746233760953,
      "grad_norm": 0.2712065577507019,
      "learning_rate": 0.00021935774329449035,
      "loss": 0.3629,
      "step": 105400
    },
    {
      "epoch": 4.289812348791347,
      "grad_norm": 0.25576597452163696,
      "learning_rate": 0.00021902912238499911,
      "loss": 0.362,
      "step": 105500
    },
    {
      "epoch": 4.293878463821741,
      "grad_norm": 0.24379801750183105,
      "learning_rate": 0.00021870050147550788,
      "loss": 0.3633,
      "step": 105600
    },
    {
      "epoch": 4.297944578852135,
      "grad_norm": 0.3076796531677246,
      "learning_rate": 0.00021837188056601664,
      "loss": 0.3641,
      "step": 105700
    },
    {
      "epoch": 4.30201069388253,
      "grad_norm": 0.29737839102745056,
      "learning_rate": 0.00021804325965652543,
      "loss": 0.3642,
      "step": 105800
    },
    {
      "epoch": 4.306076808912924,
      "grad_norm": 0.243089497089386,
      "learning_rate": 0.0002177146387470342,
      "loss": 0.3657,
      "step": 105900
    },
    {
      "epoch": 4.310142923943318,
      "grad_norm": 0.2897298336029053,
      "learning_rate": 0.00021738601783754296,
      "loss": 0.3647,
      "step": 106000
    },
    {
      "epoch": 4.310142923943318,
      "eval_loss": 0.3738447427749634,
      "eval_runtime": 177.9881,
      "eval_samples_per_second": 982.661,
      "eval_steps_per_second": 30.71,
      "step": 106000
    },
    {
      "epoch": 4.314209038973712,
      "grad_norm": 0.2972826659679413,
      "learning_rate": 0.00021705739692805173,
      "loss": 0.365,
      "step": 106100
    },
    {
      "epoch": 4.318275154004107,
      "grad_norm": 0.276084840297699,
      "learning_rate": 0.0002167287760185605,
      "loss": 0.365,
      "step": 106200
    },
    {
      "epoch": 4.322341269034501,
      "grad_norm": 0.25878292322158813,
      "learning_rate": 0.0002164001551090693,
      "loss": 0.3624,
      "step": 106300
    },
    {
      "epoch": 4.326407384064895,
      "grad_norm": 0.2591889500617981,
      "learning_rate": 0.00021607153419957807,
      "loss": 0.3614,
      "step": 106400
    },
    {
      "epoch": 4.330473499095289,
      "grad_norm": 0.3075600564479828,
      "learning_rate": 0.00021574291329008684,
      "loss": 0.3635,
      "step": 106500
    },
    {
      "epoch": 4.334539614125684,
      "grad_norm": 0.3058619797229767,
      "learning_rate": 0.0002154142923805956,
      "loss": 0.362,
      "step": 106600
    },
    {
      "epoch": 4.338605729156078,
      "grad_norm": 0.2858152985572815,
      "learning_rate": 0.00021508567147110436,
      "loss": 0.3657,
      "step": 106700
    },
    {
      "epoch": 4.342671844186472,
      "grad_norm": 0.3256256580352783,
      "learning_rate": 0.00021475705056161313,
      "loss": 0.3657,
      "step": 106800
    },
    {
      "epoch": 4.346737959216866,
      "grad_norm": 0.2612374424934387,
      "learning_rate": 0.00021442842965212192,
      "loss": 0.3658,
      "step": 106900
    },
    {
      "epoch": 4.350804074247261,
      "grad_norm": 0.29630476236343384,
      "learning_rate": 0.00021409980874263068,
      "loss": 0.365,
      "step": 107000
    },
    {
      "epoch": 4.354870189277655,
      "grad_norm": 0.2604796886444092,
      "learning_rate": 0.00021377118783313945,
      "loss": 0.3662,
      "step": 107100
    },
    {
      "epoch": 4.358936304308049,
      "grad_norm": 0.3182954788208008,
      "learning_rate": 0.0002134425669236482,
      "loss": 0.365,
      "step": 107200
    },
    {
      "epoch": 4.363002419338443,
      "grad_norm": 0.27098602056503296,
      "learning_rate": 0.00021311394601415698,
      "loss": 0.364,
      "step": 107300
    },
    {
      "epoch": 4.367068534368837,
      "grad_norm": 0.2510584592819214,
      "learning_rate": 0.00021278532510466577,
      "loss": 0.3667,
      "step": 107400
    },
    {
      "epoch": 4.371134649399232,
      "grad_norm": 0.32018640637397766,
      "learning_rate": 0.00021245670419517453,
      "loss": 0.3669,
      "step": 107500
    },
    {
      "epoch": 4.375200764429626,
      "grad_norm": 0.3086773753166199,
      "learning_rate": 0.00021212808328568332,
      "loss": 0.3643,
      "step": 107600
    },
    {
      "epoch": 4.37926687946002,
      "grad_norm": 0.31015434861183167,
      "learning_rate": 0.00021179946237619209,
      "loss": 0.3621,
      "step": 107700
    },
    {
      "epoch": 4.383332994490414,
      "grad_norm": 0.29866722226142883,
      "learning_rate": 0.00021147084146670085,
      "loss": 0.3631,
      "step": 107800
    },
    {
      "epoch": 4.387399109520809,
      "grad_norm": 0.28623560070991516,
      "learning_rate": 0.0002111422205572096,
      "loss": 0.3637,
      "step": 107900
    },
    {
      "epoch": 4.391465224551203,
      "grad_norm": 0.28698691725730896,
      "learning_rate": 0.0002108135996477184,
      "loss": 0.3626,
      "step": 108000
    },
    {
      "epoch": 4.391465224551203,
      "eval_loss": 0.37482312321662903,
      "eval_runtime": 177.4162,
      "eval_samples_per_second": 985.829,
      "eval_steps_per_second": 30.809,
      "step": 108000
    },
    {
      "epoch": 4.395531339581597,
      "grad_norm": 0.334648072719574,
      "learning_rate": 0.00021048497873822717,
      "loss": 0.3634,
      "step": 108100
    },
    {
      "epoch": 4.399597454611991,
      "grad_norm": 0.3206329047679901,
      "learning_rate": 0.00021015635782873593,
      "loss": 0.3639,
      "step": 108200
    },
    {
      "epoch": 4.403663569642386,
      "grad_norm": 0.2891662120819092,
      "learning_rate": 0.0002098277369192447,
      "loss": 0.3641,
      "step": 108300
    },
    {
      "epoch": 4.40772968467278,
      "grad_norm": 0.2765689790248871,
      "learning_rate": 0.00020949911600975346,
      "loss": 0.364,
      "step": 108400
    },
    {
      "epoch": 4.411795799703174,
      "grad_norm": 0.2722226679325104,
      "learning_rate": 0.00020917049510026222,
      "loss": 0.3642,
      "step": 108500
    },
    {
      "epoch": 4.415861914733568,
      "grad_norm": 0.2827547788619995,
      "learning_rate": 0.00020884187419077102,
      "loss": 0.3626,
      "step": 108600
    },
    {
      "epoch": 4.4199280297639625,
      "grad_norm": 0.29423975944519043,
      "learning_rate": 0.00020851325328127978,
      "loss": 0.3637,
      "step": 108700
    },
    {
      "epoch": 4.4239941447943565,
      "grad_norm": 0.29646438360214233,
      "learning_rate": 0.00020818463237178854,
      "loss": 0.3643,
      "step": 108800
    },
    {
      "epoch": 4.4280602598247505,
      "grad_norm": 0.31184786558151245,
      "learning_rate": 0.00020785601146229734,
      "loss": 0.3636,
      "step": 108900
    },
    {
      "epoch": 4.4321263748551445,
      "grad_norm": 0.2885788083076477,
      "learning_rate": 0.0002075273905528061,
      "loss": 0.365,
      "step": 109000
    },
    {
      "epoch": 4.4361924898855385,
      "grad_norm": 0.3049427568912506,
      "learning_rate": 0.0002071987696433149,
      "loss": 0.3666,
      "step": 109100
    },
    {
      "epoch": 4.440258604915933,
      "grad_norm": 0.29385197162628174,
      "learning_rate": 0.00020687014873382365,
      "loss": 0.3624,
      "step": 109200
    },
    {
      "epoch": 4.444324719946327,
      "grad_norm": 0.26293814182281494,
      "learning_rate": 0.00020654152782433242,
      "loss": 0.3636,
      "step": 109300
    },
    {
      "epoch": 4.448390834976721,
      "grad_norm": 0.31100431084632874,
      "learning_rate": 0.00020621290691484118,
      "loss": 0.3622,
      "step": 109400
    },
    {
      "epoch": 4.452456950007115,
      "grad_norm": 0.2889203429222107,
      "learning_rate": 0.00020588428600534995,
      "loss": 0.3623,
      "step": 109500
    },
    {
      "epoch": 4.45652306503751,
      "grad_norm": 0.31121841073036194,
      "learning_rate": 0.0002055556650958587,
      "loss": 0.3634,
      "step": 109600
    },
    {
      "epoch": 4.460589180067904,
      "grad_norm": 0.281643807888031,
      "learning_rate": 0.0002052270441863675,
      "loss": 0.3617,
      "step": 109700
    },
    {
      "epoch": 4.464655295098298,
      "grad_norm": 0.2988336682319641,
      "learning_rate": 0.00020489842327687627,
      "loss": 0.3622,
      "step": 109800
    },
    {
      "epoch": 4.468721410128692,
      "grad_norm": 0.31026414036750793,
      "learning_rate": 0.00020456980236738503,
      "loss": 0.3631,
      "step": 109900
    },
    {
      "epoch": 4.472787525159086,
      "grad_norm": 0.2963893711566925,
      "learning_rate": 0.0002042411814578938,
      "loss": 0.3638,
      "step": 110000
    },
    {
      "epoch": 4.472787525159086,
      "eval_loss": 0.3729492425918579,
      "eval_runtime": 177.7777,
      "eval_samples_per_second": 983.824,
      "eval_steps_per_second": 30.746,
      "step": 110000
    },
    {
      "epoch": 4.476853640189481,
      "grad_norm": 0.2828953266143799,
      "learning_rate": 0.00020391256054840256,
      "loss": 0.3624,
      "step": 110100
    },
    {
      "epoch": 4.480919755219875,
      "grad_norm": 0.28489208221435547,
      "learning_rate": 0.00020358393963891135,
      "loss": 0.3668,
      "step": 110200
    },
    {
      "epoch": 4.484985870250269,
      "grad_norm": 0.2696317434310913,
      "learning_rate": 0.00020325531872942014,
      "loss": 0.3636,
      "step": 110300
    },
    {
      "epoch": 4.489051985280663,
      "grad_norm": 0.3238251507282257,
      "learning_rate": 0.0002029266978199289,
      "loss": 0.3628,
      "step": 110400
    },
    {
      "epoch": 4.493118100311058,
      "grad_norm": 0.3653273582458496,
      "learning_rate": 0.00020259807691043767,
      "loss": 0.3646,
      "step": 110500
    },
    {
      "epoch": 4.497184215341452,
      "grad_norm": 0.30114269256591797,
      "learning_rate": 0.00020226945600094643,
      "loss": 0.3635,
      "step": 110600
    },
    {
      "epoch": 4.501250330371846,
      "grad_norm": 0.2870456576347351,
      "learning_rate": 0.0002019408350914552,
      "loss": 0.3644,
      "step": 110700
    },
    {
      "epoch": 4.50531644540224,
      "grad_norm": 0.31426602602005005,
      "learning_rate": 0.000201612214181964,
      "loss": 0.3613,
      "step": 110800
    },
    {
      "epoch": 4.509382560432635,
      "grad_norm": 0.3176015615463257,
      "learning_rate": 0.00020128359327247275,
      "loss": 0.3624,
      "step": 110900
    },
    {
      "epoch": 4.513448675463029,
      "grad_norm": 0.290747731924057,
      "learning_rate": 0.00020095497236298152,
      "loss": 0.3631,
      "step": 111000
    },
    {
      "epoch": 4.517514790493423,
      "grad_norm": 0.2983124554157257,
      "learning_rate": 0.00020062635145349028,
      "loss": 0.3639,
      "step": 111100
    },
    {
      "epoch": 4.521580905523817,
      "grad_norm": 0.28245314955711365,
      "learning_rate": 0.00020029773054399904,
      "loss": 0.3609,
      "step": 111200
    },
    {
      "epoch": 4.525647020554212,
      "grad_norm": 0.2782147526741028,
      "learning_rate": 0.0001999691096345078,
      "loss": 0.3629,
      "step": 111300
    },
    {
      "epoch": 4.529713135584606,
      "grad_norm": 0.2961121201515198,
      "learning_rate": 0.0001996404887250166,
      "loss": 0.3612,
      "step": 111400
    },
    {
      "epoch": 4.533779250615,
      "grad_norm": 0.3083221912384033,
      "learning_rate": 0.0001993118678155254,
      "loss": 0.3634,
      "step": 111500
    },
    {
      "epoch": 4.537845365645394,
      "grad_norm": 0.2860032021999359,
      "learning_rate": 0.00019898324690603415,
      "loss": 0.3621,
      "step": 111600
    },
    {
      "epoch": 4.541911480675788,
      "grad_norm": 0.2843592166900635,
      "learning_rate": 0.00019865462599654292,
      "loss": 0.3639,
      "step": 111700
    },
    {
      "epoch": 4.545977595706183,
      "grad_norm": 0.2550432085990906,
      "learning_rate": 0.00019832600508705168,
      "loss": 0.3619,
      "step": 111800
    },
    {
      "epoch": 4.550043710736577,
      "grad_norm": 0.2699880599975586,
      "learning_rate": 0.00019799738417756045,
      "loss": 0.3624,
      "step": 111900
    },
    {
      "epoch": 4.554109825766971,
      "grad_norm": 0.27080807089805603,
      "learning_rate": 0.00019766876326806924,
      "loss": 0.3616,
      "step": 112000
    },
    {
      "epoch": 4.554109825766971,
      "eval_loss": 0.3714934289455414,
      "eval_runtime": 179.2307,
      "eval_samples_per_second": 975.848,
      "eval_steps_per_second": 30.497,
      "step": 112000
    },
    {
      "epoch": 4.558175940797366,
      "grad_norm": 0.30971255898475647,
      "learning_rate": 0.000197340142358578,
      "loss": 0.3638,
      "step": 112100
    },
    {
      "epoch": 4.56224205582776,
      "grad_norm": 0.2973354756832123,
      "learning_rate": 0.00019701152144908677,
      "loss": 0.364,
      "step": 112200
    },
    {
      "epoch": 4.566308170858154,
      "grad_norm": 0.3192085325717926,
      "learning_rate": 0.00019668290053959553,
      "loss": 0.3645,
      "step": 112300
    },
    {
      "epoch": 4.570374285888548,
      "grad_norm": 0.3026808202266693,
      "learning_rate": 0.0001963542796301043,
      "loss": 0.36,
      "step": 112400
    },
    {
      "epoch": 4.574440400918942,
      "grad_norm": 0.27974969148635864,
      "learning_rate": 0.00019602565872061308,
      "loss": 0.3605,
      "step": 112500
    },
    {
      "epoch": 4.5785065159493366,
      "grad_norm": 0.28138187527656555,
      "learning_rate": 0.00019569703781112185,
      "loss": 0.3633,
      "step": 112600
    },
    {
      "epoch": 4.5825726309797306,
      "grad_norm": 0.303870290517807,
      "learning_rate": 0.0001953684169016306,
      "loss": 0.3643,
      "step": 112700
    },
    {
      "epoch": 4.586638746010125,
      "grad_norm": 0.31748220324516296,
      "learning_rate": 0.0001950397959921394,
      "loss": 0.3621,
      "step": 112800
    },
    {
      "epoch": 4.590704861040519,
      "grad_norm": 0.2645597755908966,
      "learning_rate": 0.00019471117508264817,
      "loss": 0.3622,
      "step": 112900
    },
    {
      "epoch": 4.5947709760709134,
      "grad_norm": 0.30905506014823914,
      "learning_rate": 0.00019438255417315693,
      "loss": 0.3638,
      "step": 113000
    },
    {
      "epoch": 4.5988370911013075,
      "grad_norm": 0.294817715883255,
      "learning_rate": 0.00019405393326366572,
      "loss": 0.3615,
      "step": 113100
    },
    {
      "epoch": 4.6029032061317015,
      "grad_norm": 0.2936936914920807,
      "learning_rate": 0.0001937253123541745,
      "loss": 0.3623,
      "step": 113200
    },
    {
      "epoch": 4.6069693211620955,
      "grad_norm": 0.27733534574508667,
      "learning_rate": 0.00019339669144468325,
      "loss": 0.3614,
      "step": 113300
    },
    {
      "epoch": 4.6110354361924895,
      "grad_norm": 0.2887275516986847,
      "learning_rate": 0.00019306807053519201,
      "loss": 0.3617,
      "step": 113400
    },
    {
      "epoch": 4.615101551222884,
      "grad_norm": 0.34476107358932495,
      "learning_rate": 0.00019273944962570078,
      "loss": 0.3632,
      "step": 113500
    },
    {
      "epoch": 4.619167666253278,
      "grad_norm": 0.2784581184387207,
      "learning_rate": 0.00019241082871620954,
      "loss": 0.3638,
      "step": 113600
    },
    {
      "epoch": 4.623233781283672,
      "grad_norm": 0.29934659600257874,
      "learning_rate": 0.00019208220780671833,
      "loss": 0.3628,
      "step": 113700
    },
    {
      "epoch": 4.627299896314066,
      "grad_norm": 0.2984917461872101,
      "learning_rate": 0.0001917535868972271,
      "loss": 0.3615,
      "step": 113800
    },
    {
      "epoch": 4.631366011344461,
      "grad_norm": 0.3025544285774231,
      "learning_rate": 0.00019142496598773586,
      "loss": 0.3623,
      "step": 113900
    },
    {
      "epoch": 4.635432126374855,
      "grad_norm": 0.276324599981308,
      "learning_rate": 0.00019109634507824463,
      "loss": 0.363,
      "step": 114000
    },
    {
      "epoch": 4.635432126374855,
      "eval_loss": 0.37194961309432983,
      "eval_runtime": 177.9945,
      "eval_samples_per_second": 982.626,
      "eval_steps_per_second": 30.709,
      "step": 114000
    },
    {
      "epoch": 4.639498241405249,
      "grad_norm": 0.2863408029079437,
      "learning_rate": 0.0001907677241687534,
      "loss": 0.3616,
      "step": 114100
    },
    {
      "epoch": 4.643564356435643,
      "grad_norm": 0.3056519031524658,
      "learning_rate": 0.0001904391032592622,
      "loss": 0.3633,
      "step": 114200
    },
    {
      "epoch": 4.647630471466038,
      "grad_norm": 0.33689501881599426,
      "learning_rate": 0.00019011048234977097,
      "loss": 0.362,
      "step": 114300
    },
    {
      "epoch": 4.651696586496432,
      "grad_norm": 0.2985151410102844,
      "learning_rate": 0.00018978186144027974,
      "loss": 0.3631,
      "step": 114400
    },
    {
      "epoch": 4.655762701526826,
      "grad_norm": 0.2842769920825958,
      "learning_rate": 0.0001894532405307885,
      "loss": 0.3606,
      "step": 114500
    },
    {
      "epoch": 4.65982881655722,
      "grad_norm": 0.32750681042671204,
      "learning_rate": 0.00018912461962129726,
      "loss": 0.3623,
      "step": 114600
    },
    {
      "epoch": 4.663894931587615,
      "grad_norm": 0.33322227001190186,
      "learning_rate": 0.00018879599871180603,
      "loss": 0.3595,
      "step": 114700
    },
    {
      "epoch": 4.667961046618009,
      "grad_norm": 0.2641301155090332,
      "learning_rate": 0.00018846737780231482,
      "loss": 0.3641,
      "step": 114800
    },
    {
      "epoch": 4.672027161648403,
      "grad_norm": 0.30983003973960876,
      "learning_rate": 0.00018813875689282358,
      "loss": 0.3611,
      "step": 114900
    },
    {
      "epoch": 4.676093276678797,
      "grad_norm": 0.2717598080635071,
      "learning_rate": 0.00018781013598333235,
      "loss": 0.3603,
      "step": 115000
    },
    {
      "epoch": 4.680159391709191,
      "grad_norm": 0.3442634642124176,
      "learning_rate": 0.0001874815150738411,
      "loss": 0.3588,
      "step": 115100
    },
    {
      "epoch": 4.684225506739586,
      "grad_norm": 0.32055842876434326,
      "learning_rate": 0.00018715289416434988,
      "loss": 0.362,
      "step": 115200
    },
    {
      "epoch": 4.68829162176998,
      "grad_norm": 0.2870786488056183,
      "learning_rate": 0.00018682427325485864,
      "loss": 0.3616,
      "step": 115300
    },
    {
      "epoch": 4.692357736800374,
      "grad_norm": 0.29875925183296204,
      "learning_rate": 0.00018649565234536746,
      "loss": 0.3625,
      "step": 115400
    },
    {
      "epoch": 4.696423851830768,
      "grad_norm": 0.33402296900749207,
      "learning_rate": 0.00018616703143587622,
      "loss": 0.362,
      "step": 115500
    },
    {
      "epoch": 4.700489966861163,
      "grad_norm": 0.31140244007110596,
      "learning_rate": 0.00018583841052638499,
      "loss": 0.3622,
      "step": 115600
    },
    {
      "epoch": 4.704556081891557,
      "grad_norm": 0.3232783377170563,
      "learning_rate": 0.00018550978961689375,
      "loss": 0.3599,
      "step": 115700
    },
    {
      "epoch": 4.708622196921951,
      "grad_norm": 0.3107300102710724,
      "learning_rate": 0.00018518116870740251,
      "loss": 0.3611,
      "step": 115800
    },
    {
      "epoch": 4.712688311952345,
      "grad_norm": 0.2946292757987976,
      "learning_rate": 0.0001848525477979113,
      "loss": 0.3619,
      "step": 115900
    },
    {
      "epoch": 4.71675442698274,
      "grad_norm": 0.3105209767818451,
      "learning_rate": 0.00018452392688842007,
      "loss": 0.3622,
      "step": 116000
    },
    {
      "epoch": 4.71675442698274,
      "eval_loss": 0.3710566461086273,
      "eval_runtime": 178.6249,
      "eval_samples_per_second": 979.158,
      "eval_steps_per_second": 30.6,
      "step": 116000
    },
    {
      "epoch": 4.720840872588285,
      "grad_norm": 0.27448543906211853,
      "learning_rate": 0.00018419530597892883,
      "loss": 0.3617,
      "step": 116100
    },
    {
      "epoch": 4.72490698761868,
      "grad_norm": 0.28665637969970703,
      "learning_rate": 0.0001838666850694376,
      "loss": 0.36,
      "step": 116200
    },
    {
      "epoch": 4.728973102649074,
      "grad_norm": 0.3082980215549469,
      "learning_rate": 0.00018353806415994636,
      "loss": 0.3604,
      "step": 116300
    },
    {
      "epoch": 4.733039217679468,
      "grad_norm": 0.3080659806728363,
      "learning_rate": 0.00018320944325045513,
      "loss": 0.3627,
      "step": 116400
    },
    {
      "epoch": 4.737105332709862,
      "grad_norm": 0.3012043237686157,
      "learning_rate": 0.00018288082234096392,
      "loss": 0.3606,
      "step": 116500
    },
    {
      "epoch": 4.741171447740257,
      "grad_norm": 0.3262506127357483,
      "learning_rate": 0.00018255220143147268,
      "loss": 0.3612,
      "step": 116600
    },
    {
      "epoch": 4.745237562770651,
      "grad_norm": 0.3222080171108246,
      "learning_rate": 0.00018222358052198144,
      "loss": 0.3618,
      "step": 116700
    },
    {
      "epoch": 4.749303677801045,
      "grad_norm": 0.29756394028663635,
      "learning_rate": 0.00018189495961249024,
      "loss": 0.3636,
      "step": 116800
    },
    {
      "epoch": 4.753369792831439,
      "grad_norm": 0.28447964787483215,
      "learning_rate": 0.000181566338702999,
      "loss": 0.3603,
      "step": 116900
    },
    {
      "epoch": 4.757435907861834,
      "grad_norm": 0.31611359119415283,
      "learning_rate": 0.00018123771779350776,
      "loss": 0.362,
      "step": 117000
    },
    {
      "epoch": 4.761502022892228,
      "grad_norm": 0.2953501343727112,
      "learning_rate": 0.00018090909688401656,
      "loss": 0.3628,
      "step": 117100
    },
    {
      "epoch": 4.765568137922622,
      "grad_norm": 0.3280210494995117,
      "learning_rate": 0.00018058047597452532,
      "loss": 0.3597,
      "step": 117200
    },
    {
      "epoch": 4.769634252953016,
      "grad_norm": 0.30004897713661194,
      "learning_rate": 0.00018025185506503408,
      "loss": 0.3603,
      "step": 117300
    },
    {
      "epoch": 4.773700367983411,
      "grad_norm": 0.2717231214046478,
      "learning_rate": 0.00017992323415554285,
      "loss": 0.3624,
      "step": 117400
    },
    {
      "epoch": 4.777766483013805,
      "grad_norm": 0.2904360592365265,
      "learning_rate": 0.0001795946132460516,
      "loss": 0.3614,
      "step": 117500
    },
    {
      "epoch": 4.781832598044199,
      "grad_norm": 0.2899588346481323,
      "learning_rate": 0.0001792659923365604,
      "loss": 0.3619,
      "step": 117600
    },
    {
      "epoch": 4.785898713074593,
      "grad_norm": 0.2770079970359802,
      "learning_rate": 0.00017893737142706917,
      "loss": 0.3617,
      "step": 117700
    },
    {
      "epoch": 4.789964828104987,
      "grad_norm": 0.30352821946144104,
      "learning_rate": 0.00017860875051757793,
      "loss": 0.3604,
      "step": 117800
    },
    {
      "epoch": 4.794030943135382,
      "grad_norm": 0.29566457867622375,
      "learning_rate": 0.0001782801296080867,
      "loss": 0.3608,
      "step": 117900
    },
    {
      "epoch": 4.798097058165776,
      "grad_norm": 0.35031744837760925,
      "learning_rate": 0.00017795150869859546,
      "loss": 0.3634,
      "step": 118000
    },
    {
      "epoch": 4.798097058165776,
      "eval_loss": 0.3707886338233948,
      "eval_runtime": 179.9327,
      "eval_samples_per_second": 972.041,
      "eval_steps_per_second": 30.378,
      "step": 118000
    },
    {
      "epoch": 4.80216317319617,
      "grad_norm": 0.3254874050617218,
      "learning_rate": 0.00017762288778910425,
      "loss": 0.3635,
      "step": 118100
    },
    {
      "epoch": 4.806229288226564,
      "grad_norm": 0.29262596368789673,
      "learning_rate": 0.00017729426687961304,
      "loss": 0.3612,
      "step": 118200
    },
    {
      "epoch": 4.8102954032569585,
      "grad_norm": 0.2963905334472656,
      "learning_rate": 0.0001769656459701218,
      "loss": 0.3605,
      "step": 118300
    },
    {
      "epoch": 4.8143615182873525,
      "grad_norm": 0.2745227515697479,
      "learning_rate": 0.00017663702506063057,
      "loss": 0.3611,
      "step": 118400
    },
    {
      "epoch": 4.8184276333177465,
      "grad_norm": 0.3133622109889984,
      "learning_rate": 0.00017630840415113933,
      "loss": 0.3591,
      "step": 118500
    },
    {
      "epoch": 4.8224937483481405,
      "grad_norm": 0.341741144657135,
      "learning_rate": 0.0001759797832416481,
      "loss": 0.359,
      "step": 118600
    },
    {
      "epoch": 4.8265598633785345,
      "grad_norm": 0.3430042862892151,
      "learning_rate": 0.00017565116233215686,
      "loss": 0.361,
      "step": 118700
    },
    {
      "epoch": 4.830625978408929,
      "grad_norm": 0.3524841368198395,
      "learning_rate": 0.00017532254142266565,
      "loss": 0.3605,
      "step": 118800
    },
    {
      "epoch": 4.834692093439323,
      "grad_norm": 0.3185252845287323,
      "learning_rate": 0.00017499392051317442,
      "loss": 0.3613,
      "step": 118900
    },
    {
      "epoch": 4.838758208469717,
      "grad_norm": 0.3000643849372864,
      "learning_rate": 0.00017466529960368318,
      "loss": 0.3611,
      "step": 119000
    },
    {
      "epoch": 4.842824323500112,
      "grad_norm": 0.30210861563682556,
      "learning_rate": 0.00017433667869419194,
      "loss": 0.3591,
      "step": 119100
    },
    {
      "epoch": 4.846890438530506,
      "grad_norm": 0.3184281885623932,
      "learning_rate": 0.0001740080577847007,
      "loss": 0.3604,
      "step": 119200
    },
    {
      "epoch": 4.8509565535609,
      "grad_norm": 0.2737896740436554,
      "learning_rate": 0.0001736794368752095,
      "loss": 0.3592,
      "step": 119300
    },
    {
      "epoch": 4.855022668591294,
      "grad_norm": 0.32942909002304077,
      "learning_rate": 0.0001733508159657183,
      "loss": 0.3598,
      "step": 119400
    },
    {
      "epoch": 4.859088783621688,
      "grad_norm": 0.3469959497451782,
      "learning_rate": 0.00017302219505622705,
      "loss": 0.361,
      "step": 119500
    },
    {
      "epoch": 4.863154898652083,
      "grad_norm": 0.3172363042831421,
      "learning_rate": 0.00017269357414673582,
      "loss": 0.3631,
      "step": 119600
    },
    {
      "epoch": 4.867221013682477,
      "grad_norm": 0.28859493136405945,
      "learning_rate": 0.00017236495323724458,
      "loss": 0.3595,
      "step": 119700
    },
    {
      "epoch": 4.871287128712871,
      "grad_norm": 0.3328145444393158,
      "learning_rate": 0.00017203633232775335,
      "loss": 0.3601,
      "step": 119800
    },
    {
      "epoch": 4.875353243743265,
      "grad_norm": 0.3093385398387909,
      "learning_rate": 0.00017170771141826214,
      "loss": 0.3617,
      "step": 119900
    },
    {
      "epoch": 4.87941935877366,
      "grad_norm": 0.39050808548927307,
      "learning_rate": 0.0001713790905087709,
      "loss": 0.3596,
      "step": 120000
    },
    {
      "epoch": 4.87941935877366,
      "eval_loss": 0.3710925579071045,
      "eval_runtime": 178.2927,
      "eval_samples_per_second": 980.982,
      "eval_steps_per_second": 30.657,
      "step": 120000
    },
    {
      "epoch": 4.883485473804054,
      "grad_norm": 0.32751619815826416,
      "learning_rate": 0.00017105046959927967,
      "loss": 0.3619,
      "step": 120100
    },
    {
      "epoch": 4.887551588834448,
      "grad_norm": 0.3239472508430481,
      "learning_rate": 0.00017072184868978843,
      "loss": 0.3591,
      "step": 120200
    },
    {
      "epoch": 4.891617703864842,
      "grad_norm": 0.3154587149620056,
      "learning_rate": 0.0001703932277802972,
      "loss": 0.3608,
      "step": 120300
    },
    {
      "epoch": 4.895683818895236,
      "grad_norm": 0.28754737973213196,
      "learning_rate": 0.00017006460687080596,
      "loss": 0.3601,
      "step": 120400
    },
    {
      "epoch": 4.899749933925631,
      "grad_norm": 0.2951747179031372,
      "learning_rate": 0.00016973598596131475,
      "loss": 0.3609,
      "step": 120500
    },
    {
      "epoch": 4.903816048956025,
      "grad_norm": 0.3129939138889313,
      "learning_rate": 0.0001694073650518235,
      "loss": 0.3599,
      "step": 120600
    },
    {
      "epoch": 4.907882163986419,
      "grad_norm": 0.3190418481826782,
      "learning_rate": 0.0001690787441423323,
      "loss": 0.3606,
      "step": 120700
    },
    {
      "epoch": 4.911948279016814,
      "grad_norm": 0.3137624263763428,
      "learning_rate": 0.00016875012323284107,
      "loss": 0.3614,
      "step": 120800
    },
    {
      "epoch": 4.916014394047208,
      "grad_norm": 0.2965547442436218,
      "learning_rate": 0.00016842150232334983,
      "loss": 0.3614,
      "step": 120900
    },
    {
      "epoch": 4.920080509077602,
      "grad_norm": 0.30014097690582275,
      "learning_rate": 0.00016809288141385862,
      "loss": 0.3584,
      "step": 121000
    },
    {
      "epoch": 4.924146624107996,
      "grad_norm": 0.29014769196510315,
      "learning_rate": 0.0001677642605043674,
      "loss": 0.3621,
      "step": 121100
    },
    {
      "epoch": 4.92821273913839,
      "grad_norm": 0.340972363948822,
      "learning_rate": 0.00016743563959487615,
      "loss": 0.3579,
      "step": 121200
    },
    {
      "epoch": 4.932278854168785,
      "grad_norm": 0.3224443793296814,
      "learning_rate": 0.00016710701868538492,
      "loss": 0.3633,
      "step": 121300
    },
    {
      "epoch": 4.936344969199179,
      "grad_norm": 0.31329432129859924,
      "learning_rate": 0.00016677839777589368,
      "loss": 0.3595,
      "step": 121400
    },
    {
      "epoch": 4.940411084229573,
      "grad_norm": 0.3054081201553345,
      "learning_rate": 0.00016644977686640244,
      "loss": 0.3593,
      "step": 121500
    },
    {
      "epoch": 4.944477199259967,
      "grad_norm": 0.3184809386730194,
      "learning_rate": 0.00016612115595691123,
      "loss": 0.3604,
      "step": 121600
    },
    {
      "epoch": 4.948543314290362,
      "grad_norm": 0.3118714988231659,
      "learning_rate": 0.00016579253504742,
      "loss": 0.3594,
      "step": 121700
    },
    {
      "epoch": 4.952609429320756,
      "grad_norm": 0.32591813802719116,
      "learning_rate": 0.00016546391413792876,
      "loss": 0.3585,
      "step": 121800
    },
    {
      "epoch": 4.95667554435115,
      "grad_norm": 0.3007993996143341,
      "learning_rate": 0.00016513529322843753,
      "loss": 0.3607,
      "step": 121900
    },
    {
      "epoch": 4.960741659381544,
      "grad_norm": 0.3407353162765503,
      "learning_rate": 0.00016480667231894632,
      "loss": 0.3604,
      "step": 122000
    },
    {
      "epoch": 4.960741659381544,
      "eval_loss": 0.36938023567199707,
      "eval_runtime": 180.3395,
      "eval_samples_per_second": 969.848,
      "eval_steps_per_second": 30.309,
      "step": 122000
    },
    {
      "epoch": 4.964807774411938,
      "grad_norm": 0.3461964428424835,
      "learning_rate": 0.00016447805140945508,
      "loss": 0.3616,
      "step": 122100
    },
    {
      "epoch": 4.9688738894423325,
      "grad_norm": 0.28096750378608704,
      "learning_rate": 0.00016414943049996387,
      "loss": 0.361,
      "step": 122200
    },
    {
      "epoch": 4.9729400044727265,
      "grad_norm": 0.3711753785610199,
      "learning_rate": 0.00016382080959047264,
      "loss": 0.3607,
      "step": 122300
    },
    {
      "epoch": 4.9770061195031206,
      "grad_norm": 0.32976579666137695,
      "learning_rate": 0.0001634921886809814,
      "loss": 0.3599,
      "step": 122400
    },
    {
      "epoch": 4.981072234533515,
      "grad_norm": 0.33177903294563293,
      "learning_rate": 0.00016316356777149017,
      "loss": 0.3602,
      "step": 122500
    },
    {
      "epoch": 4.985138349563909,
      "grad_norm": 0.3167925477027893,
      "learning_rate": 0.00016283494686199893,
      "loss": 0.36,
      "step": 122600
    },
    {
      "epoch": 4.9892044645943034,
      "grad_norm": 0.34374114871025085,
      "learning_rate": 0.00016250632595250772,
      "loss": 0.36,
      "step": 122700
    },
    {
      "epoch": 4.9932705796246974,
      "grad_norm": 0.3565538823604584,
      "learning_rate": 0.00016217770504301648,
      "loss": 0.3607,
      "step": 122800
    },
    {
      "epoch": 4.9973366946550914,
      "grad_norm": 0.292889267206192,
      "learning_rate": 0.00016184908413352525,
      "loss": 0.3601,
      "step": 122900
    },
    {
      "epoch": 5.001402809685486,
      "grad_norm": 0.3337166905403137,
      "learning_rate": 0.000161520463224034,
      "loss": 0.3586,
      "step": 123000
    },
    {
      "epoch": 5.00546892471588,
      "grad_norm": 0.33184030652046204,
      "learning_rate": 0.00016119184231454278,
      "loss": 0.3587,
      "step": 123100
    },
    {
      "epoch": 5.009535039746274,
      "grad_norm": 0.308619886636734,
      "learning_rate": 0.00016086322140505154,
      "loss": 0.3554,
      "step": 123200
    },
    {
      "epoch": 5.013601154776668,
      "grad_norm": 0.3162480592727661,
      "learning_rate": 0.00016053460049556036,
      "loss": 0.3571,
      "step": 123300
    },
    {
      "epoch": 5.017667269807063,
      "grad_norm": 0.3544783890247345,
      "learning_rate": 0.00016020597958606912,
      "loss": 0.3586,
      "step": 123400
    },
    {
      "epoch": 5.021733384837457,
      "grad_norm": 0.2892090082168579,
      "learning_rate": 0.0001598773586765779,
      "loss": 0.3569,
      "step": 123500
    },
    {
      "epoch": 5.025799499867851,
      "grad_norm": 0.29690131545066833,
      "learning_rate": 0.00015954873776708665,
      "loss": 0.3572,
      "step": 123600
    },
    {
      "epoch": 5.029865614898245,
      "grad_norm": 0.313888281583786,
      "learning_rate": 0.00015922011685759542,
      "loss": 0.3557,
      "step": 123700
    },
    {
      "epoch": 5.033931729928639,
      "grad_norm": 0.2711307108402252,
      "learning_rate": 0.00015889149594810418,
      "loss": 0.3571,
      "step": 123800
    },
    {
      "epoch": 5.037997844959034,
      "grad_norm": 0.3137136697769165,
      "learning_rate": 0.00015856287503861297,
      "loss": 0.3562,
      "step": 123900
    },
    {
      "epoch": 5.042063959989428,
      "grad_norm": 0.32670217752456665,
      "learning_rate": 0.00015823425412912173,
      "loss": 0.3555,
      "step": 124000
    },
    {
      "epoch": 5.042063959989428,
      "eval_loss": 0.36996695399284363,
      "eval_runtime": 180.2178,
      "eval_samples_per_second": 970.504,
      "eval_steps_per_second": 30.33,
      "step": 124000
    },
    {
      "epoch": 5.046130075019822,
      "grad_norm": 0.3566794991493225,
      "learning_rate": 0.0001579056332196305,
      "loss": 0.3583,
      "step": 124100
    },
    {
      "epoch": 5.050196190050216,
      "grad_norm": 0.3075175881385803,
      "learning_rate": 0.00015757701231013926,
      "loss": 0.3556,
      "step": 124200
    },
    {
      "epoch": 5.054262305080611,
      "grad_norm": 0.3526933193206787,
      "learning_rate": 0.00015724839140064803,
      "loss": 0.3551,
      "step": 124300
    },
    {
      "epoch": 5.058328420111005,
      "grad_norm": 0.28298452496528625,
      "learning_rate": 0.00015691977049115682,
      "loss": 0.3575,
      "step": 124400
    },
    {
      "epoch": 5.062394535141399,
      "grad_norm": 0.3270397186279297,
      "learning_rate": 0.00015659114958166558,
      "loss": 0.356,
      "step": 124500
    },
    {
      "epoch": 5.066460650171793,
      "grad_norm": 0.3169913589954376,
      "learning_rate": 0.00015626252867217435,
      "loss": 0.3563,
      "step": 124600
    },
    {
      "epoch": 5.070526765202188,
      "grad_norm": 0.31291547417640686,
      "learning_rate": 0.00015593390776268314,
      "loss": 0.3591,
      "step": 124700
    },
    {
      "epoch": 5.074592880232582,
      "grad_norm": 0.28862684965133667,
      "learning_rate": 0.0001556052868531919,
      "loss": 0.3565,
      "step": 124800
    },
    {
      "epoch": 5.078658995262976,
      "grad_norm": 0.337171733379364,
      "learning_rate": 0.00015527666594370066,
      "loss": 0.3573,
      "step": 124900
    },
    {
      "epoch": 5.08272511029337,
      "grad_norm": 0.3119811415672302,
      "learning_rate": 0.00015494804503420946,
      "loss": 0.3567,
      "step": 125000
    },
    {
      "epoch": 5.086791225323765,
      "grad_norm": 0.2847275733947754,
      "learning_rate": 0.00015461942412471822,
      "loss": 0.3582,
      "step": 125100
    },
    {
      "epoch": 5.090857340354159,
      "grad_norm": 0.30270302295684814,
      "learning_rate": 0.00015429080321522698,
      "loss": 0.3549,
      "step": 125200
    },
    {
      "epoch": 5.094923455384553,
      "grad_norm": 0.34637898206710815,
      "learning_rate": 0.00015396218230573575,
      "loss": 0.3563,
      "step": 125300
    },
    {
      "epoch": 5.098989570414947,
      "grad_norm": 0.32671239972114563,
      "learning_rate": 0.0001536335613962445,
      "loss": 0.3562,
      "step": 125400
    },
    {
      "epoch": 5.103055685445341,
      "grad_norm": 0.34549635648727417,
      "learning_rate": 0.0001533049404867533,
      "loss": 0.3561,
      "step": 125500
    },
    {
      "epoch": 5.107121800475736,
      "grad_norm": 0.3049176037311554,
      "learning_rate": 0.00015297631957726207,
      "loss": 0.3564,
      "step": 125600
    },
    {
      "epoch": 5.11118791550613,
      "grad_norm": 0.3305429518222809,
      "learning_rate": 0.00015264769866777083,
      "loss": 0.3539,
      "step": 125700
    },
    {
      "epoch": 5.115254030536524,
      "grad_norm": 0.32871949672698975,
      "learning_rate": 0.0001523190777582796,
      "loss": 0.3569,
      "step": 125800
    },
    {
      "epoch": 5.119320145566918,
      "grad_norm": 0.3517225682735443,
      "learning_rate": 0.00015199045684878836,
      "loss": 0.3562,
      "step": 125900
    },
    {
      "epoch": 5.123386260597313,
      "grad_norm": 0.3400871753692627,
      "learning_rate": 0.00015166183593929715,
      "loss": 0.3587,
      "step": 126000
    },
    {
      "epoch": 5.123386260597313,
      "eval_loss": 0.36835482716560364,
      "eval_runtime": 180.6303,
      "eval_samples_per_second": 968.287,
      "eval_steps_per_second": 30.261,
      "step": 126000
    },
    {
      "epoch": 5.127452375627707,
      "grad_norm": 0.3229266107082367,
      "learning_rate": 0.00015133321502980594,
      "loss": 0.3565,
      "step": 126100
    },
    {
      "epoch": 5.131518490658101,
      "grad_norm": 0.3123648464679718,
      "learning_rate": 0.0001510045941203147,
      "loss": 0.3565,
      "step": 126200
    },
    {
      "epoch": 5.135584605688495,
      "grad_norm": 0.34865787625312805,
      "learning_rate": 0.00015067597321082347,
      "loss": 0.3568,
      "step": 126300
    },
    {
      "epoch": 5.1396507207188895,
      "grad_norm": 0.34619104862213135,
      "learning_rate": 0.00015034735230133223,
      "loss": 0.3579,
      "step": 126400
    },
    {
      "epoch": 5.1437168357492835,
      "grad_norm": 0.3425236642360687,
      "learning_rate": 0.000150018731391841,
      "loss": 0.3601,
      "step": 126500
    },
    {
      "epoch": 5.1477829507796775,
      "grad_norm": 0.3169468641281128,
      "learning_rate": 0.00014969011048234976,
      "loss": 0.3563,
      "step": 126600
    },
    {
      "epoch": 5.1518490658100715,
      "grad_norm": 0.31618228554725647,
      "learning_rate": 0.00014936148957285855,
      "loss": 0.3563,
      "step": 126700
    },
    {
      "epoch": 5.155915180840466,
      "grad_norm": 0.31965890526771545,
      "learning_rate": 0.00014903286866336732,
      "loss": 0.3567,
      "step": 126800
    },
    {
      "epoch": 5.15998129587086,
      "grad_norm": 0.3107834756374359,
      "learning_rate": 0.00014870424775387608,
      "loss": 0.3582,
      "step": 126900
    },
    {
      "epoch": 5.164047410901254,
      "grad_norm": 0.30338287353515625,
      "learning_rate": 0.00014837562684438485,
      "loss": 0.358,
      "step": 127000
    },
    {
      "epoch": 5.168113525931648,
      "grad_norm": 0.30971989035606384,
      "learning_rate": 0.0001480470059348936,
      "loss": 0.3568,
      "step": 127100
    },
    {
      "epoch": 5.172179640962042,
      "grad_norm": 0.3391033411026001,
      "learning_rate": 0.0001477183850254024,
      "loss": 0.3567,
      "step": 127200
    },
    {
      "epoch": 5.176245755992437,
      "grad_norm": 0.36906856298446655,
      "learning_rate": 0.0001473897641159112,
      "loss": 0.357,
      "step": 127300
    },
    {
      "epoch": 5.180311871022831,
      "grad_norm": 0.3090191185474396,
      "learning_rate": 0.00014706114320641996,
      "loss": 0.3552,
      "step": 127400
    },
    {
      "epoch": 5.184377986053225,
      "grad_norm": 0.35765352845191956,
      "learning_rate": 0.00014673252229692872,
      "loss": 0.355,
      "step": 127500
    },
    {
      "epoch": 5.188444101083619,
      "grad_norm": 0.30189117789268494,
      "learning_rate": 0.00014640390138743748,
      "loss": 0.3571,
      "step": 127600
    },
    {
      "epoch": 5.192510216114014,
      "grad_norm": 0.34776952862739563,
      "learning_rate": 0.00014607528047794625,
      "loss": 0.3534,
      "step": 127700
    },
    {
      "epoch": 5.196576331144408,
      "grad_norm": 0.3142572045326233,
      "learning_rate": 0.00014574665956845504,
      "loss": 0.3574,
      "step": 127800
    },
    {
      "epoch": 5.200642446174802,
      "grad_norm": 0.33784157037734985,
      "learning_rate": 0.0001454180386589638,
      "loss": 0.3582,
      "step": 127900
    },
    {
      "epoch": 5.204708561205196,
      "grad_norm": 0.3017288148403168,
      "learning_rate": 0.00014508941774947257,
      "loss": 0.3576,
      "step": 128000
    },
    {
      "epoch": 5.204708561205196,
      "eval_loss": 0.36724767088890076,
      "eval_runtime": 181.1155,
      "eval_samples_per_second": 965.693,
      "eval_steps_per_second": 30.18,
      "step": 128000
    },
    {
      "epoch": 5.208774676235591,
      "grad_norm": 0.3417576253414154,
      "learning_rate": 0.00014476079683998133,
      "loss": 0.3575,
      "step": 128100
    },
    {
      "epoch": 5.212840791265985,
      "grad_norm": 0.32424506545066833,
      "learning_rate": 0.0001444321759304901,
      "loss": 0.3546,
      "step": 128200
    },
    {
      "epoch": 5.216906906296379,
      "grad_norm": 0.32587310671806335,
      "learning_rate": 0.00014410355502099886,
      "loss": 0.3551,
      "step": 128300
    },
    {
      "epoch": 5.220973021326773,
      "grad_norm": 0.3295217752456665,
      "learning_rate": 0.00014377493411150765,
      "loss": 0.3581,
      "step": 128400
    },
    {
      "epoch": 5.225039136357168,
      "grad_norm": 0.3528684377670288,
      "learning_rate": 0.00014344631320201641,
      "loss": 0.3549,
      "step": 128500
    },
    {
      "epoch": 5.229105251387562,
      "grad_norm": 0.30864638090133667,
      "learning_rate": 0.0001431176922925252,
      "loss": 0.3552,
      "step": 128600
    },
    {
      "epoch": 5.233171366417956,
      "grad_norm": 0.3218235969543457,
      "learning_rate": 0.00014278907138303397,
      "loss": 0.3552,
      "step": 128700
    },
    {
      "epoch": 5.23723748144835,
      "grad_norm": 0.32960814237594604,
      "learning_rate": 0.00014246045047354273,
      "loss": 0.3567,
      "step": 128800
    },
    {
      "epoch": 5.241303596478744,
      "grad_norm": 0.32057034969329834,
      "learning_rate": 0.00014213182956405152,
      "loss": 0.3567,
      "step": 128900
    },
    {
      "epoch": 5.245369711509139,
      "grad_norm": 0.3252527415752411,
      "learning_rate": 0.0001418032086545603,
      "loss": 0.3548,
      "step": 129000
    },
    {
      "epoch": 5.249435826539533,
      "grad_norm": 0.3442874550819397,
      "learning_rate": 0.00014147458774506905,
      "loss": 0.3596,
      "step": 129100
    },
    {
      "epoch": 5.253501941569927,
      "grad_norm": 0.3099400997161865,
      "learning_rate": 0.00014114596683557782,
      "loss": 0.3543,
      "step": 129200
    },
    {
      "epoch": 5.257568056600321,
      "grad_norm": 0.368558794260025,
      "learning_rate": 0.00014081734592608658,
      "loss": 0.3549,
      "step": 129300
    },
    {
      "epoch": 5.261634171630716,
      "grad_norm": 0.32401344180107117,
      "learning_rate": 0.00014048872501659534,
      "loss": 0.3564,
      "step": 129400
    },
    {
      "epoch": 5.26570028666111,
      "grad_norm": 0.3198109269142151,
      "learning_rate": 0.00014016010410710414,
      "loss": 0.3558,
      "step": 129500
    },
    {
      "epoch": 5.269766401691504,
      "grad_norm": 0.3526346981525421,
      "learning_rate": 0.0001398314831976129,
      "loss": 0.3562,
      "step": 129600
    },
    {
      "epoch": 5.273832516721898,
      "grad_norm": 0.3599677085876465,
      "learning_rate": 0.00013950286228812166,
      "loss": 0.3561,
      "step": 129700
    },
    {
      "epoch": 5.277898631752293,
      "grad_norm": 0.3068482279777527,
      "learning_rate": 0.00013917424137863043,
      "loss": 0.356,
      "step": 129800
    },
    {
      "epoch": 5.281964746782687,
      "grad_norm": 0.30239900946617126,
      "learning_rate": 0.00013884562046913922,
      "loss": 0.3529,
      "step": 129900
    },
    {
      "epoch": 5.286030861813081,
      "grad_norm": 0.34076356887817383,
      "learning_rate": 0.00013851699955964798,
      "loss": 0.3558,
      "step": 130000
    },
    {
      "epoch": 5.286030861813081,
      "eval_loss": 0.36879321932792664,
      "eval_runtime": 182.6193,
      "eval_samples_per_second": 957.741,
      "eval_steps_per_second": 29.931,
      "step": 130000
    },
    {
      "epoch": 5.290096976843475,
      "grad_norm": 0.3163837194442749,
      "learning_rate": 0.00013818837865015677,
      "loss": 0.3584,
      "step": 130100
    },
    {
      "epoch": 5.29416309187387,
      "grad_norm": 0.3281727135181427,
      "learning_rate": 0.00013785975774066554,
      "loss": 0.3567,
      "step": 130200
    },
    {
      "epoch": 5.298229206904264,
      "grad_norm": 0.3103511333465576,
      "learning_rate": 0.0001375311368311743,
      "loss": 0.3566,
      "step": 130300
    },
    {
      "epoch": 5.302295321934658,
      "grad_norm": 0.33849912881851196,
      "learning_rate": 0.00013720251592168307,
      "loss": 0.3563,
      "step": 130400
    },
    {
      "epoch": 5.306361436965052,
      "grad_norm": 0.34897711873054504,
      "learning_rate": 0.00013687389501219183,
      "loss": 0.3567,
      "step": 130500
    },
    {
      "epoch": 5.310427551995446,
      "grad_norm": 0.3999898135662079,
      "learning_rate": 0.00013654527410270062,
      "loss": 0.3586,
      "step": 130600
    },
    {
      "epoch": 5.3144936670258405,
      "grad_norm": 0.3416444957256317,
      "learning_rate": 0.00013621665319320939,
      "loss": 0.3549,
      "step": 130700
    },
    {
      "epoch": 5.3185597820562345,
      "grad_norm": 0.36896681785583496,
      "learning_rate": 0.00013588803228371815,
      "loss": 0.3538,
      "step": 130800
    },
    {
      "epoch": 5.3226258970866285,
      "grad_norm": 0.3508346378803253,
      "learning_rate": 0.0001355594113742269,
      "loss": 0.358,
      "step": 130900
    },
    {
      "epoch": 5.3266920121170225,
      "grad_norm": 0.3844847083091736,
      "learning_rate": 0.00013523079046473568,
      "loss": 0.3558,
      "step": 131000
    },
    {
      "epoch": 5.330758127147417,
      "grad_norm": 0.33213797211647034,
      "learning_rate": 0.00013490216955524444,
      "loss": 0.354,
      "step": 131100
    },
    {
      "epoch": 5.334824242177811,
      "grad_norm": 0.35285308957099915,
      "learning_rate": 0.00013457354864575326,
      "loss": 0.3553,
      "step": 131200
    },
    {
      "epoch": 5.338890357208205,
      "grad_norm": 0.36198192834854126,
      "learning_rate": 0.00013424492773626202,
      "loss": 0.3565,
      "step": 131300
    },
    {
      "epoch": 5.342956472238599,
      "grad_norm": 0.34148097038269043,
      "learning_rate": 0.0001339163068267708,
      "loss": 0.3562,
      "step": 131400
    },
    {
      "epoch": 5.347022587268993,
      "grad_norm": 0.3412911891937256,
      "learning_rate": 0.00013358768591727955,
      "loss": 0.3564,
      "step": 131500
    },
    {
      "epoch": 5.351088702299388,
      "grad_norm": 0.33414825797080994,
      "learning_rate": 0.00013325906500778832,
      "loss": 0.3568,
      "step": 131600
    },
    {
      "epoch": 5.355154817329782,
      "grad_norm": 0.32660961151123047,
      "learning_rate": 0.00013293044409829708,
      "loss": 0.3542,
      "step": 131700
    },
    {
      "epoch": 5.359220932360176,
      "grad_norm": 0.33964020013809204,
      "learning_rate": 0.00013260182318880587,
      "loss": 0.3547,
      "step": 131800
    },
    {
      "epoch": 5.36328704739057,
      "grad_norm": 0.31088441610336304,
      "learning_rate": 0.00013227320227931464,
      "loss": 0.3571,
      "step": 131900
    },
    {
      "epoch": 5.367353162420965,
      "grad_norm": 0.33951106667518616,
      "learning_rate": 0.0001319445813698234,
      "loss": 0.3556,
      "step": 132000
    },
    {
      "epoch": 5.367353162420965,
      "eval_loss": 0.3663637042045593,
      "eval_runtime": 181.4231,
      "eval_samples_per_second": 964.056,
      "eval_steps_per_second": 30.128,
      "step": 132000
    },
    {
      "epoch": 5.371419277451359,
      "grad_norm": 0.3431757688522339,
      "learning_rate": 0.00013161596046033216,
      "loss": 0.3549,
      "step": 132100
    },
    {
      "epoch": 5.375485392481753,
      "grad_norm": 0.32931041717529297,
      "learning_rate": 0.00013128733955084093,
      "loss": 0.3547,
      "step": 132200
    },
    {
      "epoch": 5.379551507512147,
      "grad_norm": 0.3023962676525116,
      "learning_rate": 0.00013095871864134972,
      "loss": 0.3532,
      "step": 132300
    },
    {
      "epoch": 5.383617622542542,
      "grad_norm": 0.35479429364204407,
      "learning_rate": 0.00013063009773185848,
      "loss": 0.3558,
      "step": 132400
    },
    {
      "epoch": 5.387683737572936,
      "grad_norm": 0.35935479402542114,
      "learning_rate": 0.00013030147682236725,
      "loss": 0.355,
      "step": 132500
    },
    {
      "epoch": 5.39174985260333,
      "grad_norm": 0.3316444754600525,
      "learning_rate": 0.00012997285591287604,
      "loss": 0.3582,
      "step": 132600
    },
    {
      "epoch": 5.395815967633724,
      "grad_norm": 0.32985466718673706,
      "learning_rate": 0.0001296442350033848,
      "loss": 0.3581,
      "step": 132700
    },
    {
      "epoch": 5.399882082664119,
      "grad_norm": 0.33168867230415344,
      "learning_rate": 0.00012931561409389357,
      "loss": 0.3536,
      "step": 132800
    },
    {
      "epoch": 5.403948197694513,
      "grad_norm": 0.3409610688686371,
      "learning_rate": 0.00012898699318440236,
      "loss": 0.3552,
      "step": 132900
    },
    {
      "epoch": 5.408014312724907,
      "grad_norm": 0.36822381615638733,
      "learning_rate": 0.00012865837227491112,
      "loss": 0.3568,
      "step": 133000
    },
    {
      "epoch": 5.412080427755301,
      "grad_norm": 0.3577481508255005,
      "learning_rate": 0.00012832975136541988,
      "loss": 0.3553,
      "step": 133100
    },
    {
      "epoch": 5.416146542785695,
      "grad_norm": 0.3786623179912567,
      "learning_rate": 0.00012800113045592865,
      "loss": 0.3566,
      "step": 133200
    },
    {
      "epoch": 5.42021265781609,
      "grad_norm": 0.3923126757144928,
      "learning_rate": 0.0001276725095464374,
      "loss": 0.3568,
      "step": 133300
    },
    {
      "epoch": 5.424278772846484,
      "grad_norm": 0.3201490640640259,
      "learning_rate": 0.00012734388863694618,
      "loss": 0.3555,
      "step": 133400
    },
    {
      "epoch": 5.428344887876878,
      "grad_norm": 0.3484715223312378,
      "learning_rate": 0.00012701526772745497,
      "loss": 0.3545,
      "step": 133500
    },
    {
      "epoch": 5.432411002907272,
      "grad_norm": 0.33575648069381714,
      "learning_rate": 0.00012668664681796373,
      "loss": 0.3564,
      "step": 133600
    },
    {
      "epoch": 5.436477117937667,
      "grad_norm": 0.3237088918685913,
      "learning_rate": 0.0001263580259084725,
      "loss": 0.3553,
      "step": 133700
    },
    {
      "epoch": 5.440543232968061,
      "grad_norm": 0.35899919271469116,
      "learning_rate": 0.00012602940499898126,
      "loss": 0.3552,
      "step": 133800
    },
    {
      "epoch": 5.444609347998455,
      "grad_norm": 0.3500903248786926,
      "learning_rate": 0.00012570078408949005,
      "loss": 0.3564,
      "step": 133900
    },
    {
      "epoch": 5.448675463028849,
      "grad_norm": 0.33518218994140625,
      "learning_rate": 0.00012537216317999884,
      "loss": 0.3531,
      "step": 134000
    },
    {
      "epoch": 5.448675463028849,
      "eval_loss": 0.3677363395690918,
      "eval_runtime": 180.378,
      "eval_samples_per_second": 969.642,
      "eval_steps_per_second": 30.303,
      "step": 134000
    },
    {
      "epoch": 5.452741578059244,
      "grad_norm": 0.35580000281333923,
      "learning_rate": 0.0001250435422705076,
      "loss": 0.3545,
      "step": 134100
    },
    {
      "epoch": 5.456807693089638,
      "grad_norm": 0.31221461296081543,
      "learning_rate": 0.00012471492136101637,
      "loss": 0.3545,
      "step": 134200
    },
    {
      "epoch": 5.460873808120032,
      "grad_norm": 0.3421909213066101,
      "learning_rate": 0.00012438630045152513,
      "loss": 0.3534,
      "step": 134300
    },
    {
      "epoch": 5.464939923150426,
      "grad_norm": 0.3297722637653351,
      "learning_rate": 0.0001240576795420339,
      "loss": 0.3549,
      "step": 134400
    },
    {
      "epoch": 5.4690060381808205,
      "grad_norm": 0.3542356789112091,
      "learning_rate": 0.0001237290586325427,
      "loss": 0.3546,
      "step": 134500
    },
    {
      "epoch": 5.4730721532112145,
      "grad_norm": 0.40466758608818054,
      "learning_rate": 0.00012340043772305145,
      "loss": 0.354,
      "step": 134600
    },
    {
      "epoch": 5.4771382682416085,
      "grad_norm": 0.35715562105178833,
      "learning_rate": 0.00012307181681356022,
      "loss": 0.3547,
      "step": 134700
    },
    {
      "epoch": 5.4812043832720025,
      "grad_norm": 0.30713197588920593,
      "learning_rate": 0.00012274319590406898,
      "loss": 0.3556,
      "step": 134800
    },
    {
      "epoch": 5.4852704983023965,
      "grad_norm": 0.3816085159778595,
      "learning_rate": 0.00012241457499457775,
      "loss": 0.3508,
      "step": 134900
    },
    {
      "epoch": 5.489336613332791,
      "grad_norm": 0.3672274351119995,
      "learning_rate": 0.00012208595408508654,
      "loss": 0.3546,
      "step": 135000
    },
    {
      "epoch": 5.493402728363185,
      "grad_norm": 0.31447336077690125,
      "learning_rate": 0.0001217573331755953,
      "loss": 0.3544,
      "step": 135100
    },
    {
      "epoch": 5.497468843393579,
      "grad_norm": 0.3950745165348053,
      "learning_rate": 0.00012142871226610407,
      "loss": 0.3548,
      "step": 135200
    },
    {
      "epoch": 5.501534958423973,
      "grad_norm": 0.3821428716182709,
      "learning_rate": 0.00012110009135661284,
      "loss": 0.3533,
      "step": 135300
    },
    {
      "epoch": 5.505601073454368,
      "grad_norm": 0.37533169984817505,
      "learning_rate": 0.0001207714704471216,
      "loss": 0.3555,
      "step": 135400
    },
    {
      "epoch": 5.509667188484762,
      "grad_norm": 0.3808307647705078,
      "learning_rate": 0.00012044284953763038,
      "loss": 0.3548,
      "step": 135500
    },
    {
      "epoch": 5.513733303515156,
      "grad_norm": 0.39772674441337585,
      "learning_rate": 0.00012011422862813916,
      "loss": 0.3568,
      "step": 135600
    },
    {
      "epoch": 5.51779941854555,
      "grad_norm": 0.3456741273403168,
      "learning_rate": 0.00011978560771864793,
      "loss": 0.3544,
      "step": 135700
    },
    {
      "epoch": 5.521865533575945,
      "grad_norm": 0.35263049602508545,
      "learning_rate": 0.00011945698680915669,
      "loss": 0.3522,
      "step": 135800
    },
    {
      "epoch": 5.525931648606339,
      "grad_norm": 0.4025580585002899,
      "learning_rate": 0.00011912836589966547,
      "loss": 0.3535,
      "step": 135900
    },
    {
      "epoch": 5.529997763636733,
      "grad_norm": 0.3244098424911499,
      "learning_rate": 0.00011879974499017423,
      "loss": 0.353,
      "step": 136000
    },
    {
      "epoch": 5.529997763636733,
      "eval_loss": 0.3659383952617645,
      "eval_runtime": 179.0965,
      "eval_samples_per_second": 976.58,
      "eval_steps_per_second": 30.52,
      "step": 136000
    },
    {
      "epoch": 5.534063878667127,
      "grad_norm": 0.37687766551971436,
      "learning_rate": 0.000118471124080683,
      "loss": 0.3541,
      "step": 136100
    },
    {
      "epoch": 5.538129993697522,
      "grad_norm": 0.35113319754600525,
      "learning_rate": 0.00011814250317119179,
      "loss": 0.354,
      "step": 136200
    },
    {
      "epoch": 5.542196108727916,
      "grad_norm": 0.34287506341934204,
      "learning_rate": 0.00011781388226170055,
      "loss": 0.3545,
      "step": 136300
    },
    {
      "epoch": 5.54626222375831,
      "grad_norm": 0.3358018398284912,
      "learning_rate": 0.00011748526135220933,
      "loss": 0.3557,
      "step": 136400
    },
    {
      "epoch": 5.550328338788704,
      "grad_norm": 0.3293992877006531,
      "learning_rate": 0.00011715664044271809,
      "loss": 0.3544,
      "step": 136500
    },
    {
      "epoch": 5.554394453819098,
      "grad_norm": 0.3606025278568268,
      "learning_rate": 0.00011682801953322686,
      "loss": 0.3546,
      "step": 136600
    },
    {
      "epoch": 5.558460568849493,
      "grad_norm": 0.3511466979980469,
      "learning_rate": 0.00011649939862373563,
      "loss": 0.3541,
      "step": 136700
    },
    {
      "epoch": 5.562526683879887,
      "grad_norm": 0.3654467463493347,
      "learning_rate": 0.00011617077771424441,
      "loss": 0.3525,
      "step": 136800
    },
    {
      "epoch": 5.566592798910281,
      "grad_norm": 0.3890113830566406,
      "learning_rate": 0.00011584215680475318,
      "loss": 0.3531,
      "step": 136900
    },
    {
      "epoch": 5.570658913940675,
      "grad_norm": 0.3234165608882904,
      "learning_rate": 0.00011551353589526195,
      "loss": 0.3557,
      "step": 137000
    },
    {
      "epoch": 5.57472502897107,
      "grad_norm": 0.3332577645778656,
      "learning_rate": 0.00011518491498577072,
      "loss": 0.3553,
      "step": 137100
    },
    {
      "epoch": 5.578791144001464,
      "grad_norm": 0.3301120400428772,
      "learning_rate": 0.00011485629407627948,
      "loss": 0.3543,
      "step": 137200
    },
    {
      "epoch": 5.582857259031858,
      "grad_norm": 0.35350173711776733,
      "learning_rate": 0.00011452767316678826,
      "loss": 0.3536,
      "step": 137300
    },
    {
      "epoch": 5.586923374062252,
      "grad_norm": 0.31718429923057556,
      "learning_rate": 0.00011419905225729702,
      "loss": 0.3514,
      "step": 137400
    },
    {
      "epoch": 5.590989489092647,
      "grad_norm": 0.34727686643600464,
      "learning_rate": 0.0001138704313478058,
      "loss": 0.353,
      "step": 137500
    },
    {
      "epoch": 5.595055604123041,
      "grad_norm": 0.33350682258605957,
      "learning_rate": 0.00011354181043831458,
      "loss": 0.355,
      "step": 137600
    },
    {
      "epoch": 5.599121719153435,
      "grad_norm": 0.4039892256259918,
      "learning_rate": 0.00011321318952882334,
      "loss": 0.3526,
      "step": 137700
    },
    {
      "epoch": 5.603187834183829,
      "grad_norm": 0.37412765622138977,
      "learning_rate": 0.0001128845686193321,
      "loss": 0.3555,
      "step": 137800
    },
    {
      "epoch": 5.607253949214224,
      "grad_norm": 0.35282382369041443,
      "learning_rate": 0.00011255594770984088,
      "loss": 0.3542,
      "step": 137900
    },
    {
      "epoch": 5.611320064244618,
      "grad_norm": 0.3253728151321411,
      "learning_rate": 0.00011222732680034965,
      "loss": 0.3554,
      "step": 138000
    },
    {
      "epoch": 5.611320064244618,
      "eval_loss": 0.3655520975589752,
      "eval_runtime": 179.0125,
      "eval_samples_per_second": 977.038,
      "eval_steps_per_second": 30.534,
      "step": 138000
    },
    {
      "epoch": 5.615386179275012,
      "grad_norm": 0.3502640426158905,
      "learning_rate": 0.00011189870589085843,
      "loss": 0.3516,
      "step": 138100
    },
    {
      "epoch": 5.619452294305406,
      "grad_norm": 0.3431740999221802,
      "learning_rate": 0.0001115700849813672,
      "loss": 0.3535,
      "step": 138200
    },
    {
      "epoch": 5.6235184093358,
      "grad_norm": 0.3549264371395111,
      "learning_rate": 0.00011124146407187597,
      "loss": 0.3533,
      "step": 138300
    },
    {
      "epoch": 5.627584524366195,
      "grad_norm": 0.340442419052124,
      "learning_rate": 0.00011091284316238474,
      "loss": 0.3542,
      "step": 138400
    },
    {
      "epoch": 5.631650639396589,
      "grad_norm": 0.35125112533569336,
      "learning_rate": 0.00011058422225289351,
      "loss": 0.3549,
      "step": 138500
    },
    {
      "epoch": 5.635716754426983,
      "grad_norm": 0.3563002645969391,
      "learning_rate": 0.00011025560134340227,
      "loss": 0.3556,
      "step": 138600
    },
    {
      "epoch": 5.639782869457377,
      "grad_norm": 0.3576701283454895,
      "learning_rate": 0.00010992698043391105,
      "loss": 0.3544,
      "step": 138700
    },
    {
      "epoch": 5.6438489844877715,
      "grad_norm": 0.363912969827652,
      "learning_rate": 0.00010959835952441983,
      "loss": 0.352,
      "step": 138800
    },
    {
      "epoch": 5.6479150995181655,
      "grad_norm": 0.33543670177459717,
      "learning_rate": 0.00010926973861492859,
      "loss": 0.3548,
      "step": 138900
    },
    {
      "epoch": 5.6519812145485595,
      "grad_norm": 0.4218708574771881,
      "learning_rate": 0.00010894111770543737,
      "loss": 0.3536,
      "step": 139000
    },
    {
      "epoch": 5.6560473295789535,
      "grad_norm": 0.3672516942024231,
      "learning_rate": 0.00010861249679594613,
      "loss": 0.3532,
      "step": 139100
    },
    {
      "epoch": 5.6601134446093475,
      "grad_norm": 0.3545786142349243,
      "learning_rate": 0.0001082838758864549,
      "loss": 0.3545,
      "step": 139200
    },
    {
      "epoch": 5.664179559639742,
      "grad_norm": 0.3380220830440521,
      "learning_rate": 0.00010795525497696368,
      "loss": 0.354,
      "step": 139300
    },
    {
      "epoch": 5.668245674670136,
      "grad_norm": 0.34434372186660767,
      "learning_rate": 0.00010762663406747244,
      "loss": 0.3546,
      "step": 139400
    },
    {
      "epoch": 5.67231178970053,
      "grad_norm": 0.3492657542228699,
      "learning_rate": 0.00010729801315798123,
      "loss": 0.3543,
      "step": 139500
    },
    {
      "epoch": 5.676377904730925,
      "grad_norm": 0.35145634412765503,
      "learning_rate": 0.00010696939224849,
      "loss": 0.3528,
      "step": 139600
    },
    {
      "epoch": 5.680444019761319,
      "grad_norm": 0.30972322821617126,
      "learning_rate": 0.00010664077133899876,
      "loss": 0.3528,
      "step": 139700
    },
    {
      "epoch": 5.684510134791713,
      "grad_norm": 0.38626497983932495,
      "learning_rate": 0.00010631215042950754,
      "loss": 0.3534,
      "step": 139800
    },
    {
      "epoch": 5.688576249822107,
      "grad_norm": 0.32104524970054626,
      "learning_rate": 0.0001059835295200163,
      "loss": 0.3526,
      "step": 139900
    },
    {
      "epoch": 5.692642364852501,
      "grad_norm": 0.37615644931793213,
      "learning_rate": 0.00010565490861052506,
      "loss": 0.3517,
      "step": 140000
    },
    {
      "epoch": 5.692642364852501,
      "eval_loss": 0.3649555742740631,
      "eval_runtime": 179.574,
      "eval_samples_per_second": 973.983,
      "eval_steps_per_second": 30.439,
      "step": 140000
    },
    {
      "epoch": 5.696708479882896,
      "grad_norm": 0.3910062313079834,
      "learning_rate": 0.00010532628770103386,
      "loss": 0.354,
      "step": 140100
    },
    {
      "epoch": 5.70077459491329,
      "grad_norm": 0.34333112835884094,
      "learning_rate": 0.00010499766679154262,
      "loss": 0.3514,
      "step": 140200
    },
    {
      "epoch": 5.704840709943684,
      "grad_norm": 0.37462955713272095,
      "learning_rate": 0.00010466904588205138,
      "loss": 0.3503,
      "step": 140300
    },
    {
      "epoch": 5.708906824974078,
      "grad_norm": 0.30874964594841003,
      "learning_rate": 0.00010434042497256016,
      "loss": 0.3523,
      "step": 140400
    },
    {
      "epoch": 5.712972940004473,
      "grad_norm": 0.3151506185531616,
      "learning_rate": 0.00010401180406306892,
      "loss": 0.3534,
      "step": 140500
    },
    {
      "epoch": 5.717039055034867,
      "grad_norm": 0.4278101325035095,
      "learning_rate": 0.00010368318315357769,
      "loss": 0.3526,
      "step": 140600
    },
    {
      "epoch": 5.721105170065261,
      "grad_norm": 0.369361013174057,
      "learning_rate": 0.00010335456224408647,
      "loss": 0.3545,
      "step": 140700
    },
    {
      "epoch": 5.725171285095655,
      "grad_norm": 0.4288560152053833,
      "learning_rate": 0.00010302594133459524,
      "loss": 0.3533,
      "step": 140800
    },
    {
      "epoch": 5.729237400126049,
      "grad_norm": 0.3513893485069275,
      "learning_rate": 0.00010269732042510401,
      "loss": 0.3518,
      "step": 140900
    },
    {
      "epoch": 5.733303515156444,
      "grad_norm": 0.38070496916770935,
      "learning_rate": 0.00010236869951561279,
      "loss": 0.3541,
      "step": 141000
    },
    {
      "epoch": 5.737369630186838,
      "grad_norm": 0.34839579463005066,
      "learning_rate": 0.00010204007860612155,
      "loss": 0.3512,
      "step": 141100
    },
    {
      "epoch": 5.741435745217232,
      "grad_norm": 0.36641791462898254,
      "learning_rate": 0.00010171145769663033,
      "loss": 0.353,
      "step": 141200
    },
    {
      "epoch": 5.745501860247627,
      "grad_norm": 0.3354320824146271,
      "learning_rate": 0.00010138283678713909,
      "loss": 0.3548,
      "step": 141300
    },
    {
      "epoch": 5.749567975278021,
      "grad_norm": 0.3906203508377075,
      "learning_rate": 0.00010105421587764786,
      "loss": 0.3542,
      "step": 141400
    },
    {
      "epoch": 5.753634090308415,
      "grad_norm": 0.3995053470134735,
      "learning_rate": 0.00010072559496815665,
      "loss": 0.3538,
      "step": 141500
    },
    {
      "epoch": 5.757700205338809,
      "grad_norm": 0.390430748462677,
      "learning_rate": 0.00010039697405866541,
      "loss": 0.3513,
      "step": 141600
    },
    {
      "epoch": 5.761766320369203,
      "grad_norm": 0.3780827820301056,
      "learning_rate": 0.00010006835314917417,
      "loss": 0.3559,
      "step": 141700
    },
    {
      "epoch": 5.765832435399598,
      "grad_norm": 0.3208524286746979,
      "learning_rate": 9.973973223968295e-05,
      "loss": 0.3544,
      "step": 141800
    },
    {
      "epoch": 5.769898550429992,
      "grad_norm": 0.3425952196121216,
      "learning_rate": 9.941111133019172e-05,
      "loss": 0.3527,
      "step": 141900
    },
    {
      "epoch": 5.773964665460386,
      "grad_norm": 0.3520117998123169,
      "learning_rate": 9.908249042070048e-05,
      "loss": 0.3532,
      "step": 142000
    },
    {
      "epoch": 5.773964665460386,
      "eval_loss": 0.3634539842605591,
      "eval_runtime": 179.8824,
      "eval_samples_per_second": 972.313,
      "eval_steps_per_second": 30.387,
      "step": 142000
    },
    {
      "epoch": 5.77803078049078,
      "grad_norm": 0.3401296138763428,
      "learning_rate": 9.875386951120927e-05,
      "loss": 0.352,
      "step": 142100
    },
    {
      "epoch": 5.782096895521175,
      "grad_norm": 0.3738936483860016,
      "learning_rate": 9.842524860171804e-05,
      "loss": 0.3531,
      "step": 142200
    },
    {
      "epoch": 5.786163010551569,
      "grad_norm": 0.3554266691207886,
      "learning_rate": 9.80966276922268e-05,
      "loss": 0.3544,
      "step": 142300
    },
    {
      "epoch": 5.790229125581963,
      "grad_norm": 0.36754941940307617,
      "learning_rate": 9.776800678273558e-05,
      "loss": 0.3519,
      "step": 142400
    },
    {
      "epoch": 5.794295240612357,
      "grad_norm": 0.3727729618549347,
      "learning_rate": 9.743938587324434e-05,
      "loss": 0.3514,
      "step": 142500
    },
    {
      "epoch": 5.798361355642751,
      "grad_norm": 0.3330008387565613,
      "learning_rate": 9.71107649637531e-05,
      "loss": 0.3529,
      "step": 142600
    },
    {
      "epoch": 5.802427470673146,
      "grad_norm": 0.3620106279850006,
      "learning_rate": 9.678214405426188e-05,
      "loss": 0.3537,
      "step": 142700
    },
    {
      "epoch": 5.80649358570354,
      "grad_norm": 0.41443702578544617,
      "learning_rate": 9.645352314477066e-05,
      "loss": 0.3521,
      "step": 142800
    },
    {
      "epoch": 5.810559700733934,
      "grad_norm": 0.3524848520755768,
      "learning_rate": 9.612490223527944e-05,
      "loss": 0.3539,
      "step": 142900
    },
    {
      "epoch": 5.8146258157643285,
      "grad_norm": 0.337240993976593,
      "learning_rate": 9.57962813257882e-05,
      "loss": 0.3522,
      "step": 143000
    },
    {
      "epoch": 5.8186919307947225,
      "grad_norm": 0.4155356287956238,
      "learning_rate": 9.546766041629697e-05,
      "loss": 0.3524,
      "step": 143100
    },
    {
      "epoch": 5.8227580458251165,
      "grad_norm": 0.3678880035877228,
      "learning_rate": 9.513903950680574e-05,
      "loss": 0.3534,
      "step": 143200
    },
    {
      "epoch": 5.8268241608555105,
      "grad_norm": 0.3829197883605957,
      "learning_rate": 9.481041859731451e-05,
      "loss": 0.3512,
      "step": 143300
    },
    {
      "epoch": 5.8308902758859045,
      "grad_norm": 0.3885810673236847,
      "learning_rate": 9.448179768782329e-05,
      "loss": 0.3527,
      "step": 143400
    },
    {
      "epoch": 5.834956390916299,
      "grad_norm": 0.3567558228969574,
      "learning_rate": 9.415317677833206e-05,
      "loss": 0.3512,
      "step": 143500
    },
    {
      "epoch": 5.839022505946693,
      "grad_norm": 0.43183663487434387,
      "learning_rate": 9.382455586884083e-05,
      "loss": 0.3523,
      "step": 143600
    },
    {
      "epoch": 5.843088620977087,
      "grad_norm": 0.3562750518321991,
      "learning_rate": 9.349593495934959e-05,
      "loss": 0.3537,
      "step": 143700
    },
    {
      "epoch": 5.847154736007481,
      "grad_norm": 0.3746342360973358,
      "learning_rate": 9.316731404985837e-05,
      "loss": 0.3506,
      "step": 143800
    },
    {
      "epoch": 5.851220851037876,
      "grad_norm": 0.3529314398765564,
      "learning_rate": 9.283869314036713e-05,
      "loss": 0.3535,
      "step": 143900
    },
    {
      "epoch": 5.85528696606827,
      "grad_norm": 0.3043815791606903,
      "learning_rate": 9.25100722308759e-05,
      "loss": 0.3528,
      "step": 144000
    },
    {
      "epoch": 5.85528696606827,
      "eval_loss": 0.3624023497104645,
      "eval_runtime": 179.2623,
      "eval_samples_per_second": 975.677,
      "eval_steps_per_second": 30.492,
      "step": 144000
    },
    {
      "epoch": 5.859353081098664,
      "grad_norm": 0.39007002115249634,
      "learning_rate": 9.218145132138469e-05,
      "loss": 0.3502,
      "step": 144100
    },
    {
      "epoch": 5.863419196129058,
      "grad_norm": 0.35193926095962524,
      "learning_rate": 9.185283041189345e-05,
      "loss": 0.3523,
      "step": 144200
    },
    {
      "epoch": 5.867485311159452,
      "grad_norm": 0.33169031143188477,
      "learning_rate": 9.152420950240222e-05,
      "loss": 0.3541,
      "step": 144300
    },
    {
      "epoch": 5.871551426189847,
      "grad_norm": 0.36321571469306946,
      "learning_rate": 9.119558859291099e-05,
      "loss": 0.3516,
      "step": 144400
    },
    {
      "epoch": 5.875617541220241,
      "grad_norm": 0.4545481204986572,
      "learning_rate": 9.086696768341976e-05,
      "loss": 0.3511,
      "step": 144500
    },
    {
      "epoch": 5.879683656250635,
      "grad_norm": 0.4166298508644104,
      "learning_rate": 9.053834677392853e-05,
      "loss": 0.3529,
      "step": 144600
    },
    {
      "epoch": 5.883749771281029,
      "grad_norm": 0.3628004789352417,
      "learning_rate": 9.020972586443731e-05,
      "loss": 0.3511,
      "step": 144700
    },
    {
      "epoch": 5.887815886311424,
      "grad_norm": 0.3686961829662323,
      "learning_rate": 8.988110495494608e-05,
      "loss": 0.3514,
      "step": 144800
    },
    {
      "epoch": 5.891882001341818,
      "grad_norm": 0.37758395075798035,
      "learning_rate": 8.955248404545485e-05,
      "loss": 0.3508,
      "step": 144900
    },
    {
      "epoch": 5.895948116372212,
      "grad_norm": 0.38884228467941284,
      "learning_rate": 8.922386313596362e-05,
      "loss": 0.3531,
      "step": 145000
    },
    {
      "epoch": 5.900014231402606,
      "grad_norm": 0.3760359585285187,
      "learning_rate": 8.889524222647238e-05,
      "loss": 0.3515,
      "step": 145100
    },
    {
      "epoch": 5.904080346433001,
      "grad_norm": 0.34799957275390625,
      "learning_rate": 8.856662131698116e-05,
      "loss": 0.352,
      "step": 145200
    },
    {
      "epoch": 5.908146461463395,
      "grad_norm": 0.36776626110076904,
      "learning_rate": 8.823800040748992e-05,
      "loss": 0.3539,
      "step": 145300
    },
    {
      "epoch": 5.912212576493789,
      "grad_norm": 0.36370936036109924,
      "learning_rate": 8.79093794979987e-05,
      "loss": 0.3516,
      "step": 145400
    },
    {
      "epoch": 5.916278691524183,
      "grad_norm": 0.3482373058795929,
      "learning_rate": 8.758075858850748e-05,
      "loss": 0.3513,
      "step": 145500
    },
    {
      "epoch": 5.920344806554578,
      "grad_norm": 0.34498926997184753,
      "learning_rate": 8.725213767901624e-05,
      "loss": 0.3526,
      "step": 145600
    },
    {
      "epoch": 5.924410921584972,
      "grad_norm": 0.3476710021495819,
      "learning_rate": 8.692351676952501e-05,
      "loss": 0.3524,
      "step": 145700
    },
    {
      "epoch": 5.928477036615366,
      "grad_norm": 0.39638635516166687,
      "learning_rate": 8.659489586003378e-05,
      "loss": 0.3522,
      "step": 145800
    },
    {
      "epoch": 5.93254315164576,
      "grad_norm": 0.417499303817749,
      "learning_rate": 8.626627495054255e-05,
      "loss": 0.3527,
      "step": 145900
    },
    {
      "epoch": 5.936609266676154,
      "grad_norm": 0.3578754663467407,
      "learning_rate": 8.593765404105131e-05,
      "loss": 0.3526,
      "step": 146000
    },
    {
      "epoch": 5.936609266676154,
      "eval_loss": 0.36232343316078186,
      "eval_runtime": 180.7259,
      "eval_samples_per_second": 967.775,
      "eval_steps_per_second": 30.245,
      "step": 146000
    },
    {
      "epoch": 5.9406957122817,
      "grad_norm": 0.39632487297058105,
      "learning_rate": 8.56090331315601e-05,
      "loss": 0.3511,
      "step": 146100
    },
    {
      "epoch": 5.944761827312095,
      "grad_norm": 0.3970677852630615,
      "learning_rate": 8.528041222206887e-05,
      "loss": 0.351,
      "step": 146200
    },
    {
      "epoch": 5.948827942342489,
      "grad_norm": 0.40391790866851807,
      "learning_rate": 8.495179131257765e-05,
      "loss": 0.3526,
      "step": 146300
    },
    {
      "epoch": 5.952894057372883,
      "grad_norm": 0.4021775424480438,
      "learning_rate": 8.462317040308641e-05,
      "loss": 0.3523,
      "step": 146400
    },
    {
      "epoch": 5.956960172403277,
      "grad_norm": 0.4633374810218811,
      "learning_rate": 8.429454949359517e-05,
      "loss": 0.3508,
      "step": 146500
    },
    {
      "epoch": 5.961026287433672,
      "grad_norm": 0.36672288179397583,
      "learning_rate": 8.396592858410395e-05,
      "loss": 0.3517,
      "step": 146600
    },
    {
      "epoch": 5.965092402464066,
      "grad_norm": 0.3477051556110382,
      "learning_rate": 8.363730767461273e-05,
      "loss": 0.352,
      "step": 146700
    },
    {
      "epoch": 5.96915851749446,
      "grad_norm": 0.3654252588748932,
      "learning_rate": 8.330868676512149e-05,
      "loss": 0.3524,
      "step": 146800
    },
    {
      "epoch": 5.973224632524854,
      "grad_norm": 0.3607597351074219,
      "learning_rate": 8.298006585563027e-05,
      "loss": 0.3525,
      "step": 146900
    },
    {
      "epoch": 5.977290747555248,
      "grad_norm": 0.4014735817909241,
      "learning_rate": 8.265144494613903e-05,
      "loss": 0.3526,
      "step": 147000
    },
    {
      "epoch": 5.981356862585643,
      "grad_norm": 0.3424762189388275,
      "learning_rate": 8.23228240366478e-05,
      "loss": 0.3516,
      "step": 147100
    },
    {
      "epoch": 5.985422977616037,
      "grad_norm": 0.40694716572761536,
      "learning_rate": 8.199420312715658e-05,
      "loss": 0.3524,
      "step": 147200
    },
    {
      "epoch": 5.989489092646431,
      "grad_norm": 0.3761218786239624,
      "learning_rate": 8.166558221766534e-05,
      "loss": 0.3508,
      "step": 147300
    },
    {
      "epoch": 5.993555207676825,
      "grad_norm": 0.3681785762310028,
      "learning_rate": 8.133696130817412e-05,
      "loss": 0.3521,
      "step": 147400
    },
    {
      "epoch": 5.99762132270722,
      "grad_norm": 0.4331994950771332,
      "learning_rate": 8.10083403986829e-05,
      "loss": 0.352,
      "step": 147500
    },
    {
      "epoch": 6.001687437737614,
      "grad_norm": 0.36964699625968933,
      "learning_rate": 8.067971948919166e-05,
      "loss": 0.3491,
      "step": 147600
    },
    {
      "epoch": 6.005753552768008,
      "grad_norm": 0.39074334502220154,
      "learning_rate": 8.035109857970042e-05,
      "loss": 0.3473,
      "step": 147700
    },
    {
      "epoch": 6.009819667798402,
      "grad_norm": 0.42024579644203186,
      "learning_rate": 8.00224776702092e-05,
      "loss": 0.3482,
      "step": 147800
    },
    {
      "epoch": 6.013885782828797,
      "grad_norm": 0.3348500728607178,
      "learning_rate": 7.969385676071796e-05,
      "loss": 0.3469,
      "step": 147900
    },
    {
      "epoch": 6.017951897859191,
      "grad_norm": 0.3859013020992279,
      "learning_rate": 7.936523585122676e-05,
      "loss": 0.3475,
      "step": 148000
    },
    {
      "epoch": 6.017951897859191,
      "eval_loss": 0.36327916383743286,
      "eval_runtime": 179.8753,
      "eval_samples_per_second": 972.351,
      "eval_steps_per_second": 30.388,
      "step": 148000
    },
    {
      "epoch": 6.022018012889585,
      "grad_norm": 0.3960098624229431,
      "learning_rate": 7.903661494173552e-05,
      "loss": 0.3476,
      "step": 148100
    },
    {
      "epoch": 6.026084127919979,
      "grad_norm": 0.35416966676712036,
      "learning_rate": 7.870799403224428e-05,
      "loss": 0.3477,
      "step": 148200
    },
    {
      "epoch": 6.0301502429503735,
      "grad_norm": 0.4513779878616333,
      "learning_rate": 7.837937312275306e-05,
      "loss": 0.3493,
      "step": 148300
    },
    {
      "epoch": 6.0342163579807675,
      "grad_norm": 0.4043681025505066,
      "learning_rate": 7.805075221326183e-05,
      "loss": 0.3468,
      "step": 148400
    },
    {
      "epoch": 6.0382824730111615,
      "grad_norm": 0.38751062750816345,
      "learning_rate": 7.772213130377059e-05,
      "loss": 0.3464,
      "step": 148500
    },
    {
      "epoch": 6.0423485880415555,
      "grad_norm": 0.41619062423706055,
      "learning_rate": 7.739351039427937e-05,
      "loss": 0.3476,
      "step": 148600
    },
    {
      "epoch": 6.0464147030719495,
      "grad_norm": 0.4457462728023529,
      "learning_rate": 7.706488948478814e-05,
      "loss": 0.3479,
      "step": 148700
    },
    {
      "epoch": 6.050480818102344,
      "grad_norm": 0.3934883773326874,
      "learning_rate": 7.673626857529691e-05,
      "loss": 0.3466,
      "step": 148800
    },
    {
      "epoch": 6.054546933132738,
      "grad_norm": 0.3710762560367584,
      "learning_rate": 7.640764766580569e-05,
      "loss": 0.3472,
      "step": 148900
    },
    {
      "epoch": 6.058613048163132,
      "grad_norm": 0.3946742117404938,
      "learning_rate": 7.607902675631445e-05,
      "loss": 0.3495,
      "step": 149000
    },
    {
      "epoch": 6.062679163193526,
      "grad_norm": 0.40756916999816895,
      "learning_rate": 7.575040584682321e-05,
      "loss": 0.349,
      "step": 149100
    },
    {
      "epoch": 6.066745278223921,
      "grad_norm": 0.39324963092803955,
      "learning_rate": 7.542178493733199e-05,
      "loss": 0.3476,
      "step": 149200
    },
    {
      "epoch": 6.070811393254315,
      "grad_norm": 0.32905808091163635,
      "learning_rate": 7.509316402784077e-05,
      "loss": 0.3477,
      "step": 149300
    },
    {
      "epoch": 6.074877508284709,
      "grad_norm": 0.37986963987350464,
      "learning_rate": 7.476454311834955e-05,
      "loss": 0.3502,
      "step": 149400
    },
    {
      "epoch": 6.078943623315103,
      "grad_norm": 0.3957682251930237,
      "learning_rate": 7.443592220885831e-05,
      "loss": 0.3473,
      "step": 149500
    },
    {
      "epoch": 6.083009738345498,
      "grad_norm": 0.38410839438438416,
      "learning_rate": 7.410730129936708e-05,
      "loss": 0.3456,
      "step": 149600
    },
    {
      "epoch": 6.087075853375892,
      "grad_norm": 0.37622758746147156,
      "learning_rate": 7.377868038987585e-05,
      "loss": 0.3468,
      "step": 149700
    },
    {
      "epoch": 6.091141968406286,
      "grad_norm": 0.3948526382446289,
      "learning_rate": 7.345005948038462e-05,
      "loss": 0.346,
      "step": 149800
    },
    {
      "epoch": 6.09520808343668,
      "grad_norm": 0.4097408354282379,
      "learning_rate": 7.312143857089338e-05,
      "loss": 0.3467,
      "step": 149900
    },
    {
      "epoch": 6.099274198467075,
      "grad_norm": 0.45290571451187134,
      "learning_rate": 7.279281766140217e-05,
      "loss": 0.3477,
      "step": 150000
    },
    {
      "epoch": 6.099274198467075,
      "eval_loss": 0.3618956208229065,
      "eval_runtime": 181.124,
      "eval_samples_per_second": 965.648,
      "eval_steps_per_second": 30.178,
      "step": 150000
    },
    {
      "epoch": 6.103340313497469,
      "grad_norm": 0.4145830273628235,
      "learning_rate": 7.246419675191094e-05,
      "loss": 0.3495,
      "step": 150100
    },
    {
      "epoch": 6.107406428527863,
      "grad_norm": 0.4104824662208557,
      "learning_rate": 7.21355758424197e-05,
      "loss": 0.348,
      "step": 150200
    },
    {
      "epoch": 6.111472543558257,
      "grad_norm": 0.38861092925071716,
      "learning_rate": 7.180695493292848e-05,
      "loss": 0.3478,
      "step": 150300
    },
    {
      "epoch": 6.115538658588651,
      "grad_norm": 0.4128968119621277,
      "learning_rate": 7.147833402343724e-05,
      "loss": 0.3484,
      "step": 150400
    },
    {
      "epoch": 6.119604773619046,
      "grad_norm": 0.4215576648712158,
      "learning_rate": 7.1149713113946e-05,
      "loss": 0.3455,
      "step": 150500
    },
    {
      "epoch": 6.12367088864944,
      "grad_norm": 0.3695724308490753,
      "learning_rate": 7.082109220445478e-05,
      "loss": 0.3475,
      "step": 150600
    },
    {
      "epoch": 6.127737003679834,
      "grad_norm": 0.43231430649757385,
      "learning_rate": 7.049247129496356e-05,
      "loss": 0.3477,
      "step": 150700
    },
    {
      "epoch": 6.131803118710228,
      "grad_norm": 0.381588876247406,
      "learning_rate": 7.016385038547233e-05,
      "loss": 0.3464,
      "step": 150800
    },
    {
      "epoch": 6.135869233740623,
      "grad_norm": 0.35957643389701843,
      "learning_rate": 6.98352294759811e-05,
      "loss": 0.3473,
      "step": 150900
    },
    {
      "epoch": 6.139935348771017,
      "grad_norm": 0.44124937057495117,
      "learning_rate": 6.950660856648987e-05,
      "loss": 0.3466,
      "step": 151000
    },
    {
      "epoch": 6.144001463801411,
      "grad_norm": 0.3656165301799774,
      "learning_rate": 6.917798765699864e-05,
      "loss": 0.3479,
      "step": 151100
    },
    {
      "epoch": 6.148067578831805,
      "grad_norm": 0.4421878159046173,
      "learning_rate": 6.884936674750741e-05,
      "loss": 0.3455,
      "step": 151200
    },
    {
      "epoch": 6.1521336938622,
      "grad_norm": 0.3985873758792877,
      "learning_rate": 6.852074583801619e-05,
      "loss": 0.3492,
      "step": 151300
    },
    {
      "epoch": 6.156199808892594,
      "grad_norm": 0.38873091340065,
      "learning_rate": 6.819212492852496e-05,
      "loss": 0.349,
      "step": 151400
    },
    {
      "epoch": 6.160265923922988,
      "grad_norm": 0.42547065019607544,
      "learning_rate": 6.786350401903373e-05,
      "loss": 0.3475,
      "step": 151500
    },
    {
      "epoch": 6.164332038953382,
      "grad_norm": 0.3870846927165985,
      "learning_rate": 6.753488310954249e-05,
      "loss": 0.3472,
      "step": 151600
    },
    {
      "epoch": 6.168398153983776,
      "grad_norm": 0.4133128225803375,
      "learning_rate": 6.720626220005127e-05,
      "loss": 0.3467,
      "step": 151700
    },
    {
      "epoch": 6.172464269014171,
      "grad_norm": 0.4198371469974518,
      "learning_rate": 6.687764129056003e-05,
      "loss": 0.347,
      "step": 151800
    },
    {
      "epoch": 6.176530384044565,
      "grad_norm": 0.44972729682922363,
      "learning_rate": 6.65490203810688e-05,
      "loss": 0.3459,
      "step": 151900
    },
    {
      "epoch": 6.180596499074959,
      "grad_norm": 0.4038814604282379,
      "learning_rate": 6.622039947157759e-05,
      "loss": 0.3481,
      "step": 152000
    },
    {
      "epoch": 6.180596499074959,
      "eval_loss": 0.3615209460258484,
      "eval_runtime": 180.2707,
      "eval_samples_per_second": 970.218,
      "eval_steps_per_second": 30.321,
      "step": 152000
    },
    {
      "epoch": 6.184662614105353,
      "grad_norm": 0.3697458505630493,
      "learning_rate": 6.589177856208635e-05,
      "loss": 0.3495,
      "step": 152100
    },
    {
      "epoch": 6.188728729135748,
      "grad_norm": 0.43598121404647827,
      "learning_rate": 6.556315765259512e-05,
      "loss": 0.3479,
      "step": 152200
    },
    {
      "epoch": 6.192794844166142,
      "grad_norm": 0.42575907707214355,
      "learning_rate": 6.52345367431039e-05,
      "loss": 0.3468,
      "step": 152300
    },
    {
      "epoch": 6.196860959196536,
      "grad_norm": 0.45520564913749695,
      "learning_rate": 6.490591583361266e-05,
      "loss": 0.3469,
      "step": 152400
    },
    {
      "epoch": 6.20092707422693,
      "grad_norm": 0.4191206693649292,
      "learning_rate": 6.457729492412142e-05,
      "loss": 0.3486,
      "step": 152500
    },
    {
      "epoch": 6.2049931892573245,
      "grad_norm": 0.38445204496383667,
      "learning_rate": 6.424867401463021e-05,
      "loss": 0.3464,
      "step": 152600
    },
    {
      "epoch": 6.2090593042877185,
      "grad_norm": 0.40215998888015747,
      "learning_rate": 6.392005310513898e-05,
      "loss": 0.3467,
      "step": 152700
    },
    {
      "epoch": 6.2131254193181125,
      "grad_norm": 0.46399614214897156,
      "learning_rate": 6.359143219564775e-05,
      "loss": 0.3479,
      "step": 152800
    },
    {
      "epoch": 6.2171915343485065,
      "grad_norm": 0.3838426470756531,
      "learning_rate": 6.326281128615652e-05,
      "loss": 0.3481,
      "step": 152900
    },
    {
      "epoch": 6.221257649378901,
      "grad_norm": 0.5340574979782104,
      "learning_rate": 6.293419037666528e-05,
      "loss": 0.3481,
      "step": 153000
    },
    {
      "epoch": 6.225323764409295,
      "grad_norm": 0.39454546570777893,
      "learning_rate": 6.260556946717406e-05,
      "loss": 0.3491,
      "step": 153100
    },
    {
      "epoch": 6.229389879439689,
      "grad_norm": 0.38843196630477905,
      "learning_rate": 6.227694855768282e-05,
      "loss": 0.3459,
      "step": 153200
    },
    {
      "epoch": 6.233455994470083,
      "grad_norm": 0.4127170145511627,
      "learning_rate": 6.19483276481916e-05,
      "loss": 0.3451,
      "step": 153300
    },
    {
      "epoch": 6.237522109500477,
      "grad_norm": 0.41770604252815247,
      "learning_rate": 6.161970673870037e-05,
      "loss": 0.3478,
      "step": 153400
    },
    {
      "epoch": 6.241588224530872,
      "grad_norm": 0.40683838725090027,
      "learning_rate": 6.129108582920914e-05,
      "loss": 0.3464,
      "step": 153500
    },
    {
      "epoch": 6.245654339561266,
      "grad_norm": 0.4371003210544586,
      "learning_rate": 6.0962464919717914e-05,
      "loss": 0.3482,
      "step": 153600
    },
    {
      "epoch": 6.24972045459166,
      "grad_norm": 0.46791326999664307,
      "learning_rate": 6.063384401022668e-05,
      "loss": 0.3463,
      "step": 153700
    },
    {
      "epoch": 6.253786569622054,
      "grad_norm": 0.3921278417110443,
      "learning_rate": 6.0305223100735456e-05,
      "loss": 0.348,
      "step": 153800
    },
    {
      "epoch": 6.257852684652449,
      "grad_norm": 0.41825228929519653,
      "learning_rate": 5.997660219124423e-05,
      "loss": 0.3481,
      "step": 153900
    },
    {
      "epoch": 6.261918799682843,
      "grad_norm": 0.38679927587509155,
      "learning_rate": 5.9647981281753e-05,
      "loss": 0.3463,
      "step": 154000
    },
    {
      "epoch": 6.261918799682843,
      "eval_loss": 0.36001646518707275,
      "eval_runtime": 179.3392,
      "eval_samples_per_second": 975.258,
      "eval_steps_per_second": 30.479,
      "step": 154000
    },
    {
      "epoch": 6.265984914713237,
      "grad_norm": 0.42954233288764954,
      "learning_rate": 5.931936037226177e-05,
      "loss": 0.3433,
      "step": 154100
    },
    {
      "epoch": 6.270051029743631,
      "grad_norm": 0.4079991579055786,
      "learning_rate": 5.899073946277054e-05,
      "loss": 0.3464,
      "step": 154200
    },
    {
      "epoch": 6.274117144774026,
      "grad_norm": 0.3717305660247803,
      "learning_rate": 5.866211855327931e-05,
      "loss": 0.3467,
      "step": 154300
    },
    {
      "epoch": 6.27818325980442,
      "grad_norm": 0.41494929790496826,
      "learning_rate": 5.833349764378808e-05,
      "loss": 0.3463,
      "step": 154400
    },
    {
      "epoch": 6.282249374834814,
      "grad_norm": 0.40912342071533203,
      "learning_rate": 5.800487673429685e-05,
      "loss": 0.3463,
      "step": 154500
    },
    {
      "epoch": 6.286315489865208,
      "grad_norm": 0.4127931296825409,
      "learning_rate": 5.767625582480562e-05,
      "loss": 0.3467,
      "step": 154600
    },
    {
      "epoch": 6.290381604895602,
      "grad_norm": 0.4455711245536804,
      "learning_rate": 5.7347634915314387e-05,
      "loss": 0.3478,
      "step": 154700
    },
    {
      "epoch": 6.294447719925997,
      "grad_norm": 0.4115891456604004,
      "learning_rate": 5.7019014005823164e-05,
      "loss": 0.3444,
      "step": 154800
    },
    {
      "epoch": 6.298513834956391,
      "grad_norm": 0.42277267575263977,
      "learning_rate": 5.6690393096331935e-05,
      "loss": 0.3441,
      "step": 154900
    },
    {
      "epoch": 6.302579949986785,
      "grad_norm": 0.3796849548816681,
      "learning_rate": 5.6361772186840706e-05,
      "loss": 0.3467,
      "step": 155000
    },
    {
      "epoch": 6.306646065017179,
      "grad_norm": 0.4071079194545746,
      "learning_rate": 5.603315127734948e-05,
      "loss": 0.3468,
      "step": 155100
    },
    {
      "epoch": 6.310712180047574,
      "grad_norm": 0.4763311445713043,
      "learning_rate": 5.570453036785825e-05,
      "loss": 0.3471,
      "step": 155200
    },
    {
      "epoch": 6.314778295077968,
      "grad_norm": 0.3922892212867737,
      "learning_rate": 5.537590945836702e-05,
      "loss": 0.3462,
      "step": 155300
    },
    {
      "epoch": 6.318844410108362,
      "grad_norm": 0.3840446174144745,
      "learning_rate": 5.504728854887579e-05,
      "loss": 0.3486,
      "step": 155400
    },
    {
      "epoch": 6.322910525138756,
      "grad_norm": 0.39841216802597046,
      "learning_rate": 5.471866763938456e-05,
      "loss": 0.3469,
      "step": 155500
    },
    {
      "epoch": 6.326976640169151,
      "grad_norm": 0.4191645085811615,
      "learning_rate": 5.439004672989333e-05,
      "loss": 0.3472,
      "step": 155600
    },
    {
      "epoch": 6.331042755199545,
      "grad_norm": 0.45493844151496887,
      "learning_rate": 5.40614258204021e-05,
      "loss": 0.3444,
      "step": 155700
    },
    {
      "epoch": 6.335108870229939,
      "grad_norm": 0.38456177711486816,
      "learning_rate": 5.373280491091087e-05,
      "loss": 0.3463,
      "step": 155800
    },
    {
      "epoch": 6.339174985260333,
      "grad_norm": 0.40781331062316895,
      "learning_rate": 5.340418400141964e-05,
      "loss": 0.3448,
      "step": 155900
    },
    {
      "epoch": 6.343241100290728,
      "grad_norm": 0.43809908628463745,
      "learning_rate": 5.3075563091928414e-05,
      "loss": 0.345,
      "step": 156000
    },
    {
      "epoch": 6.343241100290728,
      "eval_loss": 0.3597397208213806,
      "eval_runtime": 178.564,
      "eval_samples_per_second": 979.492,
      "eval_steps_per_second": 30.611,
      "step": 156000
    },
    {
      "epoch": 6.347307215321122,
      "grad_norm": 0.45042654871940613,
      "learning_rate": 5.2746942182437185e-05,
      "loss": 0.3461,
      "step": 156100
    },
    {
      "epoch": 6.351373330351516,
      "grad_norm": 0.4598473608493805,
      "learning_rate": 5.2418321272945956e-05,
      "loss": 0.3454,
      "step": 156200
    },
    {
      "epoch": 6.35543944538191,
      "grad_norm": 0.5235038995742798,
      "learning_rate": 5.2089700363454726e-05,
      "loss": 0.3441,
      "step": 156300
    },
    {
      "epoch": 6.359505560412304,
      "grad_norm": 0.44743919372558594,
      "learning_rate": 5.1761079453963504e-05,
      "loss": 0.346,
      "step": 156400
    },
    {
      "epoch": 6.3635716754426985,
      "grad_norm": 0.408020943403244,
      "learning_rate": 5.143245854447227e-05,
      "loss": 0.3467,
      "step": 156500
    },
    {
      "epoch": 6.3676377904730925,
      "grad_norm": 0.3962211608886719,
      "learning_rate": 5.110383763498104e-05,
      "loss": 0.3454,
      "step": 156600
    },
    {
      "epoch": 6.3717039055034865,
      "grad_norm": 0.5405176281929016,
      "learning_rate": 5.0775216725489816e-05,
      "loss": 0.3456,
      "step": 156700
    },
    {
      "epoch": 6.3757700205338805,
      "grad_norm": 0.49486297369003296,
      "learning_rate": 5.044659581599858e-05,
      "loss": 0.3465,
      "step": 156800
    },
    {
      "epoch": 6.379836135564275,
      "grad_norm": 0.4176557660102844,
      "learning_rate": 5.011797490650735e-05,
      "loss": 0.3462,
      "step": 156900
    },
    {
      "epoch": 6.383902250594669,
      "grad_norm": 0.39504143595695496,
      "learning_rate": 4.978935399701612e-05,
      "loss": 0.3436,
      "step": 157000
    },
    {
      "epoch": 6.387968365625063,
      "grad_norm": 0.39218491315841675,
      "learning_rate": 4.946073308752489e-05,
      "loss": 0.3466,
      "step": 157100
    },
    {
      "epoch": 6.392034480655457,
      "grad_norm": 0.4301237463951111,
      "learning_rate": 4.9132112178033664e-05,
      "loss": 0.3434,
      "step": 157200
    },
    {
      "epoch": 6.396100595685852,
      "grad_norm": 0.4091190695762634,
      "learning_rate": 4.8803491268542434e-05,
      "loss": 0.3451,
      "step": 157300
    },
    {
      "epoch": 6.400166710716246,
      "grad_norm": 0.37092113494873047,
      "learning_rate": 4.847487035905121e-05,
      "loss": 0.3456,
      "step": 157400
    },
    {
      "epoch": 6.40423282574664,
      "grad_norm": 0.4447796940803528,
      "learning_rate": 4.8146249449559976e-05,
      "loss": 0.3471,
      "step": 157500
    },
    {
      "epoch": 6.408298940777034,
      "grad_norm": 0.4860852360725403,
      "learning_rate": 4.781762854006875e-05,
      "loss": 0.3448,
      "step": 157600
    },
    {
      "epoch": 6.412365055807429,
      "grad_norm": 0.4542187452316284,
      "learning_rate": 4.7489007630577524e-05,
      "loss": 0.345,
      "step": 157700
    },
    {
      "epoch": 6.416431170837823,
      "grad_norm": 0.3931444585323334,
      "learning_rate": 4.716038672108629e-05,
      "loss": 0.3476,
      "step": 157800
    },
    {
      "epoch": 6.420497285868217,
      "grad_norm": 0.42680826783180237,
      "learning_rate": 4.683176581159506e-05,
      "loss": 0.3451,
      "step": 157900
    },
    {
      "epoch": 6.424563400898611,
      "grad_norm": 0.4084273874759674,
      "learning_rate": 4.650314490210383e-05,
      "loss": 0.3452,
      "step": 158000
    },
    {
      "epoch": 6.424563400898611,
      "eval_loss": 0.358787477016449,
      "eval_runtime": 178.3614,
      "eval_samples_per_second": 980.605,
      "eval_steps_per_second": 30.646,
      "step": 158000
    },
    {
      "epoch": 6.428629515929005,
      "grad_norm": 0.4021284282207489,
      "learning_rate": 4.617452399261261e-05,
      "loss": 0.3472,
      "step": 158100
    },
    {
      "epoch": 6.4326956309594,
      "grad_norm": 0.5186684727668762,
      "learning_rate": 4.584590308312137e-05,
      "loss": 0.3455,
      "step": 158200
    },
    {
      "epoch": 6.436761745989794,
      "grad_norm": 0.4368433356285095,
      "learning_rate": 4.551728217363014e-05,
      "loss": 0.3449,
      "step": 158300
    },
    {
      "epoch": 6.440827861020188,
      "grad_norm": 0.4978450536727905,
      "learning_rate": 4.518866126413892e-05,
      "loss": 0.3467,
      "step": 158400
    },
    {
      "epoch": 6.444893976050582,
      "grad_norm": 0.462114155292511,
      "learning_rate": 4.4860040354647684e-05,
      "loss": 0.3454,
      "step": 158500
    },
    {
      "epoch": 6.448960091080977,
      "grad_norm": 0.44948458671569824,
      "learning_rate": 4.4531419445156455e-05,
      "loss": 0.3449,
      "step": 158600
    },
    {
      "epoch": 6.453026206111371,
      "grad_norm": 0.5270408987998962,
      "learning_rate": 4.420279853566523e-05,
      "loss": 0.3442,
      "step": 158700
    },
    {
      "epoch": 6.457092321141765,
      "grad_norm": 0.4348388612270355,
      "learning_rate": 4.3874177626173997e-05,
      "loss": 0.3466,
      "step": 158800
    },
    {
      "epoch": 6.461158436172159,
      "grad_norm": 0.43079718947410583,
      "learning_rate": 4.354555671668277e-05,
      "loss": 0.3438,
      "step": 158900
    },
    {
      "epoch": 6.465224551202554,
      "grad_norm": 0.5011459589004517,
      "learning_rate": 4.3216935807191545e-05,
      "loss": 0.3447,
      "step": 159000
    },
    {
      "epoch": 6.469290666232948,
      "grad_norm": 0.429697722196579,
      "learning_rate": 4.2888314897700316e-05,
      "loss": 0.3474,
      "step": 159100
    },
    {
      "epoch": 6.473356781263342,
      "grad_norm": 0.43161308765411377,
      "learning_rate": 4.255969398820908e-05,
      "loss": 0.3454,
      "step": 159200
    },
    {
      "epoch": 6.477422896293736,
      "grad_norm": 0.4407886862754822,
      "learning_rate": 4.223107307871785e-05,
      "loss": 0.3463,
      "step": 159300
    },
    {
      "epoch": 6.481489011324131,
      "grad_norm": 0.4352245032787323,
      "learning_rate": 4.190245216922663e-05,
      "loss": 0.3431,
      "step": 159400
    },
    {
      "epoch": 6.485555126354525,
      "grad_norm": 0.4721919894218445,
      "learning_rate": 4.157383125973539e-05,
      "loss": 0.346,
      "step": 159500
    },
    {
      "epoch": 6.489621241384919,
      "grad_norm": 0.39717742800712585,
      "learning_rate": 4.124521035024416e-05,
      "loss": 0.3466,
      "step": 159600
    },
    {
      "epoch": 6.493687356415313,
      "grad_norm": 0.40043699741363525,
      "learning_rate": 4.091658944075294e-05,
      "loss": 0.3461,
      "step": 159700
    },
    {
      "epoch": 6.497753471445707,
      "grad_norm": 0.4449097812175751,
      "learning_rate": 4.058796853126171e-05,
      "loss": 0.342,
      "step": 159800
    },
    {
      "epoch": 6.501819586476102,
      "grad_norm": 0.41666194796562195,
      "learning_rate": 4.0259347621770476e-05,
      "loss": 0.3444,
      "step": 159900
    },
    {
      "epoch": 6.505885701506496,
      "grad_norm": 0.44051289558410645,
      "learning_rate": 3.993072671227925e-05,
      "loss": 0.3466,
      "step": 160000
    },
    {
      "epoch": 6.505885701506496,
      "eval_loss": 0.3590751588344574,
      "eval_runtime": 177.6329,
      "eval_samples_per_second": 984.626,
      "eval_steps_per_second": 30.771,
      "step": 160000
    },
    {
      "epoch": 6.50995181653689,
      "grad_norm": 0.4205475449562073,
      "learning_rate": 3.9602105802788024e-05,
      "loss": 0.3457,
      "step": 160100
    },
    {
      "epoch": 6.514017931567284,
      "grad_norm": 0.4070126712322235,
      "learning_rate": 3.927348489329679e-05,
      "loss": 0.3443,
      "step": 160200
    },
    {
      "epoch": 6.518084046597679,
      "grad_norm": 0.46414071321487427,
      "learning_rate": 3.894486398380556e-05,
      "loss": 0.3442,
      "step": 160300
    },
    {
      "epoch": 6.522150161628073,
      "grad_norm": 0.38010698556900024,
      "learning_rate": 3.8616243074314336e-05,
      "loss": 0.3444,
      "step": 160400
    },
    {
      "epoch": 6.526216276658467,
      "grad_norm": 0.4434235095977783,
      "learning_rate": 3.82876221648231e-05,
      "loss": 0.3448,
      "step": 160500
    },
    {
      "epoch": 6.530282391688861,
      "grad_norm": 0.412035197019577,
      "learning_rate": 3.795900125533187e-05,
      "loss": 0.3466,
      "step": 160600
    },
    {
      "epoch": 6.534348506719255,
      "grad_norm": 0.4741666615009308,
      "learning_rate": 3.763038034584065e-05,
      "loss": 0.3435,
      "step": 160700
    },
    {
      "epoch": 6.5384146217496495,
      "grad_norm": 0.4305552542209625,
      "learning_rate": 3.730175943634942e-05,
      "loss": 0.347,
      "step": 160800
    },
    {
      "epoch": 6.5424807367800435,
      "grad_norm": 0.4111440181732178,
      "learning_rate": 3.6973138526858184e-05,
      "loss": 0.3445,
      "step": 160900
    },
    {
      "epoch": 6.5465468518104375,
      "grad_norm": 0.40099236369132996,
      "learning_rate": 3.664451761736696e-05,
      "loss": 0.3449,
      "step": 161000
    },
    {
      "epoch": 6.550612966840832,
      "grad_norm": 0.44497036933898926,
      "learning_rate": 3.631589670787573e-05,
      "loss": 0.344,
      "step": 161100
    },
    {
      "epoch": 6.554679081871226,
      "grad_norm": 0.38036513328552246,
      "learning_rate": 3.5987275798384496e-05,
      "loss": 0.3423,
      "step": 161200
    },
    {
      "epoch": 6.55874519690162,
      "grad_norm": 0.4022628664970398,
      "learning_rate": 3.565865488889327e-05,
      "loss": 0.3454,
      "step": 161300
    },
    {
      "epoch": 6.562811311932014,
      "grad_norm": 0.42137011885643005,
      "learning_rate": 3.5330033979402044e-05,
      "loss": 0.3445,
      "step": 161400
    },
    {
      "epoch": 6.566877426962408,
      "grad_norm": 0.44937440752983093,
      "learning_rate": 3.5001413069910815e-05,
      "loss": 0.3439,
      "step": 161500
    },
    {
      "epoch": 6.570943541992803,
      "grad_norm": 0.40389737486839294,
      "learning_rate": 3.467279216041958e-05,
      "loss": 0.344,
      "step": 161600
    },
    {
      "epoch": 6.575009657023197,
      "grad_norm": 0.4325485825538635,
      "learning_rate": 3.434417125092836e-05,
      "loss": 0.3448,
      "step": 161700
    },
    {
      "epoch": 6.579075772053591,
      "grad_norm": 0.4682362973690033,
      "learning_rate": 3.401555034143713e-05,
      "loss": 0.3446,
      "step": 161800
    },
    {
      "epoch": 6.583141887083985,
      "grad_norm": 0.48598814010620117,
      "learning_rate": 3.368692943194589e-05,
      "loss": 0.3451,
      "step": 161900
    },
    {
      "epoch": 6.58720800211438,
      "grad_norm": 0.35967516899108887,
      "learning_rate": 3.335830852245467e-05,
      "loss": 0.3453,
      "step": 162000
    },
    {
      "epoch": 6.58720800211438,
      "eval_loss": 0.35765454173088074,
      "eval_runtime": 178.2946,
      "eval_samples_per_second": 980.972,
      "eval_steps_per_second": 30.657,
      "step": 162000
    },
    {
      "epoch": 6.591274117144774,
      "grad_norm": 0.4803119897842407,
      "learning_rate": 3.302968761296344e-05,
      "loss": 0.3442,
      "step": 162100
    },
    {
      "epoch": 6.595340232175168,
      "grad_norm": 0.4620813727378845,
      "learning_rate": 3.270106670347221e-05,
      "loss": 0.3444,
      "step": 162200
    },
    {
      "epoch": 6.599406347205562,
      "grad_norm": 0.43000566959381104,
      "learning_rate": 3.237244579398098e-05,
      "loss": 0.3431,
      "step": 162300
    },
    {
      "epoch": 6.603472462235956,
      "grad_norm": 0.4134908616542816,
      "learning_rate": 3.204382488448975e-05,
      "loss": 0.3447,
      "step": 162400
    },
    {
      "epoch": 6.607538577266351,
      "grad_norm": 0.4047413170337677,
      "learning_rate": 3.171520397499852e-05,
      "loss": 0.3424,
      "step": 162500
    },
    {
      "epoch": 6.611604692296745,
      "grad_norm": 0.45930394530296326,
      "learning_rate": 3.138658306550729e-05,
      "loss": 0.3462,
      "step": 162600
    },
    {
      "epoch": 6.615670807327139,
      "grad_norm": 0.42285963892936707,
      "learning_rate": 3.1057962156016065e-05,
      "loss": 0.3404,
      "step": 162700
    },
    {
      "epoch": 6.619736922357534,
      "grad_norm": 0.4658644497394562,
      "learning_rate": 3.0729341246524836e-05,
      "loss": 0.3448,
      "step": 162800
    },
    {
      "epoch": 6.623803037387928,
      "grad_norm": 0.550568699836731,
      "learning_rate": 3.0400720337033607e-05,
      "loss": 0.3468,
      "step": 162900
    },
    {
      "epoch": 6.627869152418322,
      "grad_norm": 0.4092603325843811,
      "learning_rate": 3.0072099427542374e-05,
      "loss": 0.3433,
      "step": 163000
    },
    {
      "epoch": 6.631935267448716,
      "grad_norm": 0.41747546195983887,
      "learning_rate": 2.9743478518051148e-05,
      "loss": 0.3436,
      "step": 163100
    },
    {
      "epoch": 6.63600138247911,
      "grad_norm": 0.4690840542316437,
      "learning_rate": 2.941485760855992e-05,
      "loss": 0.3439,
      "step": 163200
    },
    {
      "epoch": 6.640067497509505,
      "grad_norm": 0.505615770816803,
      "learning_rate": 2.908623669906869e-05,
      "loss": 0.3426,
      "step": 163300
    },
    {
      "epoch": 6.644133612539899,
      "grad_norm": 0.4947834312915802,
      "learning_rate": 2.875761578957746e-05,
      "loss": 0.343,
      "step": 163400
    },
    {
      "epoch": 6.648199727570293,
      "grad_norm": 0.4462716579437256,
      "learning_rate": 2.8428994880086228e-05,
      "loss": 0.3441,
      "step": 163500
    },
    {
      "epoch": 6.652265842600687,
      "grad_norm": 0.4343660771846771,
      "learning_rate": 2.8100373970595002e-05,
      "loss": 0.3442,
      "step": 163600
    },
    {
      "epoch": 6.656331957631082,
      "grad_norm": 0.4685535132884979,
      "learning_rate": 2.7771753061103773e-05,
      "loss": 0.3441,
      "step": 163700
    },
    {
      "epoch": 6.660398072661476,
      "grad_norm": 0.45511868596076965,
      "learning_rate": 2.7443132151612544e-05,
      "loss": 0.3426,
      "step": 163800
    },
    {
      "epoch": 6.66446418769187,
      "grad_norm": 0.4035854935646057,
      "learning_rate": 2.7114511242121315e-05,
      "loss": 0.3437,
      "step": 163900
    },
    {
      "epoch": 6.668530302722264,
      "grad_norm": 0.4150146543979645,
      "learning_rate": 2.6785890332630082e-05,
      "loss": 0.3439,
      "step": 164000
    },
    {
      "epoch": 6.668530302722264,
      "eval_loss": 0.35730698704719543,
      "eval_runtime": 178.2371,
      "eval_samples_per_second": 981.288,
      "eval_steps_per_second": 30.667,
      "step": 164000
    },
    {
      "epoch": 6.672596417752658,
      "grad_norm": 0.4308196008205414,
      "learning_rate": 2.6457269423138856e-05,
      "loss": 0.3454,
      "step": 164100
    },
    {
      "epoch": 6.676662532783053,
      "grad_norm": 0.4388974606990814,
      "learning_rate": 2.6128648513647627e-05,
      "loss": 0.3436,
      "step": 164200
    },
    {
      "epoch": 6.680728647813447,
      "grad_norm": 0.3995724320411682,
      "learning_rate": 2.5800027604156398e-05,
      "loss": 0.3452,
      "step": 164300
    },
    {
      "epoch": 6.684794762843841,
      "grad_norm": 0.4480327069759369,
      "learning_rate": 2.547140669466517e-05,
      "loss": 0.3442,
      "step": 164400
    },
    {
      "epoch": 6.6888608778742356,
      "grad_norm": 0.4911353886127472,
      "learning_rate": 2.514278578517394e-05,
      "loss": 0.3429,
      "step": 164500
    },
    {
      "epoch": 6.69292699290463,
      "grad_norm": 0.5029603242874146,
      "learning_rate": 2.481416487568271e-05,
      "loss": 0.3458,
      "step": 164600
    },
    {
      "epoch": 6.696993107935024,
      "grad_norm": 0.48553434014320374,
      "learning_rate": 2.448554396619148e-05,
      "loss": 0.3443,
      "step": 164700
    },
    {
      "epoch": 6.701059222965418,
      "grad_norm": 0.4384191930294037,
      "learning_rate": 2.4156923056700252e-05,
      "loss": 0.3444,
      "step": 164800
    },
    {
      "epoch": 6.705125337995812,
      "grad_norm": 0.5112583041191101,
      "learning_rate": 2.3828302147209023e-05,
      "loss": 0.3423,
      "step": 164900
    },
    {
      "epoch": 6.7091914530262065,
      "grad_norm": 0.4687518775463104,
      "learning_rate": 2.3499681237717794e-05,
      "loss": 0.3434,
      "step": 165000
    },
    {
      "epoch": 6.7132575680566005,
      "grad_norm": 0.4623989164829254,
      "learning_rate": 2.3171060328226564e-05,
      "loss": 0.343,
      "step": 165100
    },
    {
      "epoch": 6.7173236830869945,
      "grad_norm": 0.43721649050712585,
      "learning_rate": 2.2842439418735335e-05,
      "loss": 0.3452,
      "step": 165200
    },
    {
      "epoch": 6.7213897981173885,
      "grad_norm": 0.4868313670158386,
      "learning_rate": 2.2513818509244106e-05,
      "loss": 0.3419,
      "step": 165300
    },
    {
      "epoch": 6.725455913147783,
      "grad_norm": 0.4428689479827881,
      "learning_rate": 2.2185197599752877e-05,
      "loss": 0.3451,
      "step": 165400
    },
    {
      "epoch": 6.729522028178177,
      "grad_norm": 0.4395216107368469,
      "learning_rate": 2.185657669026165e-05,
      "loss": 0.3438,
      "step": 165500
    },
    {
      "epoch": 6.733588143208571,
      "grad_norm": 0.49600276350975037,
      "learning_rate": 2.152795578077042e-05,
      "loss": 0.3424,
      "step": 165600
    },
    {
      "epoch": 6.737654258238965,
      "grad_norm": 0.4730510413646698,
      "learning_rate": 2.1199334871279193e-05,
      "loss": 0.3415,
      "step": 165700
    },
    {
      "epoch": 6.741720373269359,
      "grad_norm": 0.44765445590019226,
      "learning_rate": 2.087071396178796e-05,
      "loss": 0.3419,
      "step": 165800
    },
    {
      "epoch": 6.745786488299754,
      "grad_norm": 0.4261581003665924,
      "learning_rate": 2.054209305229673e-05,
      "loss": 0.3427,
      "step": 165900
    },
    {
      "epoch": 6.749852603330148,
      "grad_norm": 0.41955041885375977,
      "learning_rate": 2.0213472142805505e-05,
      "loss": 0.3421,
      "step": 166000
    },
    {
      "epoch": 6.749852603330148,
      "eval_loss": 0.3565731346607208,
      "eval_runtime": 178.4824,
      "eval_samples_per_second": 979.94,
      "eval_steps_per_second": 30.625,
      "step": 166000
    },
    {
      "epoch": 6.753918718360542,
      "grad_norm": 0.45772069692611694,
      "learning_rate": 1.9884851233314273e-05,
      "loss": 0.344,
      "step": 166100
    },
    {
      "epoch": 6.757984833390936,
      "grad_norm": 0.43935713171958923,
      "learning_rate": 1.9556230323823047e-05,
      "loss": 0.3432,
      "step": 166200
    },
    {
      "epoch": 6.762050948421331,
      "grad_norm": 0.4311477243900299,
      "learning_rate": 1.9227609414331814e-05,
      "loss": 0.3441,
      "step": 166300
    },
    {
      "epoch": 6.766117063451725,
      "grad_norm": 0.4611395001411438,
      "learning_rate": 1.8898988504840585e-05,
      "loss": 0.3433,
      "step": 166400
    },
    {
      "epoch": 6.770183178482119,
      "grad_norm": 0.46564942598342896,
      "learning_rate": 1.857036759534936e-05,
      "loss": 0.3435,
      "step": 166500
    },
    {
      "epoch": 6.774249293512513,
      "grad_norm": 0.4005905091762543,
      "learning_rate": 1.8241746685858127e-05,
      "loss": 0.3434,
      "step": 166600
    },
    {
      "epoch": 6.778315408542908,
      "grad_norm": 0.4646194577217102,
      "learning_rate": 1.79131257763669e-05,
      "loss": 0.3439,
      "step": 166700
    },
    {
      "epoch": 6.782381523573302,
      "grad_norm": 0.44474270939826965,
      "learning_rate": 1.7584504866875668e-05,
      "loss": 0.3442,
      "step": 166800
    },
    {
      "epoch": 6.786447638603696,
      "grad_norm": 0.421239972114563,
      "learning_rate": 1.725588395738444e-05,
      "loss": 0.3443,
      "step": 166900
    },
    {
      "epoch": 6.79051375363409,
      "grad_norm": 0.4587031304836273,
      "learning_rate": 1.6927263047893213e-05,
      "loss": 0.3406,
      "step": 167000
    },
    {
      "epoch": 6.794579868664485,
      "grad_norm": 0.3997393250465393,
      "learning_rate": 1.659864213840198e-05,
      "loss": 0.3435,
      "step": 167100
    },
    {
      "epoch": 6.798645983694879,
      "grad_norm": 0.4226324260234833,
      "learning_rate": 1.6270021228910755e-05,
      "loss": 0.3415,
      "step": 167200
    },
    {
      "epoch": 6.802712098725273,
      "grad_norm": 0.4403427541255951,
      "learning_rate": 1.5941400319419522e-05,
      "loss": 0.3405,
      "step": 167300
    },
    {
      "epoch": 6.806778213755667,
      "grad_norm": 0.41774898767471313,
      "learning_rate": 1.5612779409928296e-05,
      "loss": 0.3438,
      "step": 167400
    },
    {
      "epoch": 6.810844328786061,
      "grad_norm": 0.4674574136734009,
      "learning_rate": 1.5284158500437067e-05,
      "loss": 0.3422,
      "step": 167500
    },
    {
      "epoch": 6.814910443816456,
      "grad_norm": 0.45717674493789673,
      "learning_rate": 1.4955537590945838e-05,
      "loss": 0.3422,
      "step": 167600
    },
    {
      "epoch": 6.81897655884685,
      "grad_norm": 0.41868355870246887,
      "learning_rate": 1.4626916681454609e-05,
      "loss": 0.3447,
      "step": 167700
    },
    {
      "epoch": 6.823042673877244,
      "grad_norm": 0.4917377829551697,
      "learning_rate": 1.4298295771963378e-05,
      "loss": 0.3427,
      "step": 167800
    },
    {
      "epoch": 6.827108788907638,
      "grad_norm": 0.48045456409454346,
      "learning_rate": 1.3969674862472149e-05,
      "loss": 0.3422,
      "step": 167900
    },
    {
      "epoch": 6.831174903938033,
      "grad_norm": 0.44826462864875793,
      "learning_rate": 1.364105395298092e-05,
      "loss": 0.3429,
      "step": 168000
    },
    {
      "epoch": 6.831174903938033,
      "eval_loss": 0.35635268688201904,
      "eval_runtime": 177.3488,
      "eval_samples_per_second": 986.203,
      "eval_steps_per_second": 30.821,
      "step": 168000
    },
    {
      "epoch": 6.835241018968427,
      "grad_norm": 0.43555375933647156,
      "learning_rate": 1.3312433043489692e-05,
      "loss": 0.3439,
      "step": 168100
    },
    {
      "epoch": 6.839307133998821,
      "grad_norm": 0.4275472164154053,
      "learning_rate": 1.2983812133998463e-05,
      "loss": 0.3443,
      "step": 168200
    },
    {
      "epoch": 6.843373249029215,
      "grad_norm": 0.4493469297885895,
      "learning_rate": 1.2655191224507234e-05,
      "loss": 0.3417,
      "step": 168300
    },
    {
      "epoch": 6.84743936405961,
      "grad_norm": 0.4408527910709381,
      "learning_rate": 1.2326570315016003e-05,
      "loss": 0.3423,
      "step": 168400
    },
    {
      "epoch": 6.851505479090004,
      "grad_norm": 0.4057026207447052,
      "learning_rate": 1.1997949405524775e-05,
      "loss": 0.3426,
      "step": 168500
    },
    {
      "epoch": 6.855571594120398,
      "grad_norm": 0.4377593696117401,
      "learning_rate": 1.1669328496033546e-05,
      "loss": 0.3428,
      "step": 168600
    },
    {
      "epoch": 6.859637709150792,
      "grad_norm": 0.47785693407058716,
      "learning_rate": 1.1340707586542317e-05,
      "loss": 0.3427,
      "step": 168700
    },
    {
      "epoch": 6.8637038241811865,
      "grad_norm": 0.4436753988265991,
      "learning_rate": 1.1012086677051088e-05,
      "loss": 0.3404,
      "step": 168800
    },
    {
      "epoch": 6.8677699392115805,
      "grad_norm": 0.45635363459587097,
      "learning_rate": 1.0683465767559859e-05,
      "loss": 0.3424,
      "step": 168900
    },
    {
      "epoch": 6.8718360542419745,
      "grad_norm": 0.4250273108482361,
      "learning_rate": 1.035484485806863e-05,
      "loss": 0.342,
      "step": 169000
    },
    {
      "epoch": 6.8759021692723685,
      "grad_norm": 0.43969255685806274,
      "learning_rate": 1.00262239485774e-05,
      "loss": 0.3451,
      "step": 169100
    },
    {
      "epoch": 6.8799682843027625,
      "grad_norm": 0.4031040072441101,
      "learning_rate": 9.697603039086171e-06,
      "loss": 0.3409,
      "step": 169200
    },
    {
      "epoch": 6.884034399333157,
      "grad_norm": 0.4392355978488922,
      "learning_rate": 9.368982129594942e-06,
      "loss": 0.3431,
      "step": 169300
    },
    {
      "epoch": 6.888100514363551,
      "grad_norm": 0.40433332324028015,
      "learning_rate": 9.040361220103713e-06,
      "loss": 0.3426,
      "step": 169400
    },
    {
      "epoch": 6.892166629393945,
      "grad_norm": 0.4395308792591095,
      "learning_rate": 8.711740310612485e-06,
      "loss": 0.3396,
      "step": 169500
    },
    {
      "epoch": 6.896232744424339,
      "grad_norm": 0.4145214259624481,
      "learning_rate": 8.383119401121254e-06,
      "loss": 0.3442,
      "step": 169600
    },
    {
      "epoch": 6.900298859454734,
      "grad_norm": 0.39750173687934875,
      "learning_rate": 8.054498491630025e-06,
      "loss": 0.3429,
      "step": 169700
    },
    {
      "epoch": 6.904364974485128,
      "grad_norm": 0.40282484889030457,
      "learning_rate": 7.725877582138796e-06,
      "loss": 0.3413,
      "step": 169800
    },
    {
      "epoch": 6.908431089515522,
      "grad_norm": 0.5458483099937439,
      "learning_rate": 7.3972566726475675e-06,
      "loss": 0.3427,
      "step": 169900
    },
    {
      "epoch": 6.912497204545916,
      "grad_norm": 0.4579951763153076,
      "learning_rate": 7.068635763156338e-06,
      "loss": 0.3443,
      "step": 170000
    },
    {
      "epoch": 6.912497204545916,
      "eval_loss": 0.3556767404079437,
      "eval_runtime": 179.1603,
      "eval_samples_per_second": 976.232,
      "eval_steps_per_second": 30.509,
      "step": 170000
    },
    {
      "epoch": 6.91656331957631,
      "grad_norm": 0.40542474389076233,
      "learning_rate": 6.740014853665109e-06,
      "loss": 0.3434,
      "step": 170100
    },
    {
      "epoch": 6.920629434606705,
      "grad_norm": 0.5333914756774902,
      "learning_rate": 6.41139394417388e-06,
      "loss": 0.3423,
      "step": 170200
    },
    {
      "epoch": 6.924695549637099,
      "grad_norm": 0.474313884973526,
      "learning_rate": 6.082773034682651e-06,
      "loss": 0.3424,
      "step": 170300
    },
    {
      "epoch": 6.928761664667493,
      "grad_norm": 0.47060051560401917,
      "learning_rate": 5.754152125191422e-06,
      "loss": 0.344,
      "step": 170400
    },
    {
      "epoch": 6.932827779697888,
      "grad_norm": 0.4145266115665436,
      "learning_rate": 5.425531215700193e-06,
      "loss": 0.3413,
      "step": 170500
    },
    {
      "epoch": 6.936893894728282,
      "grad_norm": 0.4505425691604614,
      "learning_rate": 5.096910306208963e-06,
      "loss": 0.3423,
      "step": 170600
    },
    {
      "epoch": 6.940960009758676,
      "grad_norm": 0.42016446590423584,
      "learning_rate": 4.768289396717735e-06,
      "loss": 0.342,
      "step": 170700
    },
    {
      "epoch": 6.94502612478907,
      "grad_norm": 0.4592047333717346,
      "learning_rate": 4.439668487226506e-06,
      "loss": 0.3403,
      "step": 170800
    },
    {
      "epoch": 6.949092239819464,
      "grad_norm": 0.4922155439853668,
      "learning_rate": 4.111047577735276e-06,
      "loss": 0.3428,
      "step": 170900
    },
    {
      "epoch": 6.953158354849859,
      "grad_norm": 0.4980693757534027,
      "learning_rate": 3.7824266682440473e-06,
      "loss": 0.3408,
      "step": 171000
    },
    {
      "epoch": 6.957224469880253,
      "grad_norm": 0.4306110441684723,
      "learning_rate": 3.453805758752818e-06,
      "loss": 0.342,
      "step": 171100
    },
    {
      "epoch": 6.961290584910647,
      "grad_norm": 0.4232969284057617,
      "learning_rate": 3.1251848492615885e-06,
      "loss": 0.34,
      "step": 171200
    },
    {
      "epoch": 6.965356699941041,
      "grad_norm": 0.4542054831981659,
      "learning_rate": 2.7965639397703597e-06,
      "loss": 0.3417,
      "step": 171300
    },
    {
      "epoch": 6.969422814971436,
      "grad_norm": 0.46670132875442505,
      "learning_rate": 2.4679430302791305e-06,
      "loss": 0.3422,
      "step": 171400
    },
    {
      "epoch": 6.97348893000183,
      "grad_norm": 0.39855146408081055,
      "learning_rate": 2.1393221207879013e-06,
      "loss": 0.3447,
      "step": 171500
    },
    {
      "epoch": 6.977555045032224,
      "grad_norm": 0.43977728486061096,
      "learning_rate": 1.8107012112966724e-06,
      "loss": 0.3417,
      "step": 171600
    },
    {
      "epoch": 6.981621160062618,
      "grad_norm": 0.4184896945953369,
      "learning_rate": 1.4820803018054432e-06,
      "loss": 0.3421,
      "step": 171700
    },
    {
      "epoch": 6.985687275093012,
      "grad_norm": 0.4700546860694885,
      "learning_rate": 1.1534593923142142e-06,
      "loss": 0.3427,
      "step": 171800
    },
    {
      "epoch": 6.989753390123407,
      "grad_norm": 0.4290590286254883,
      "learning_rate": 8.248384828229851e-07,
      "loss": 0.343,
      "step": 171900
    },
    {
      "epoch": 6.993819505153801,
      "grad_norm": 0.452212393283844,
      "learning_rate": 4.962175733317559e-07,
      "loss": 0.3431,
      "step": 172000
    },
    {
      "epoch": 6.993819505153801,
      "eval_loss": 0.35555920004844666,
      "eval_runtime": 178.7897,
      "eval_samples_per_second": 978.256,
      "eval_steps_per_second": 30.572,
      "step": 172000
    },
    {
      "epoch": 6.997905950759347,
      "grad_norm": 0.45792654156684875,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3474,
      "step": 172100
    },
    {
      "epoch": 7.001972065789741,
      "grad_norm": 0.46301981806755066,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3512,
      "step": 172200
    },
    {
      "epoch": 7.006038180820135,
      "grad_norm": 0.439378559589386,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.3514,
      "step": 172300
    },
    {
      "epoch": 7.01010429585053,
      "grad_norm": 0.48896247148513794,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3508,
      "step": 172400
    },
    {
      "epoch": 7.014170410880924,
      "grad_norm": 0.5250639319419861,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3533,
      "step": 172500
    },
    {
      "epoch": 7.018236525911318,
      "grad_norm": 0.44456809759140015,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.3524,
      "step": 172600
    },
    {
      "epoch": 7.022302640941712,
      "grad_norm": 0.4907638430595398,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.3529,
      "step": 172700
    },
    {
      "epoch": 7.026368755972107,
      "grad_norm": 0.43364056944847107,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.3538,
      "step": 172800
    },
    {
      "epoch": 7.030434871002501,
      "grad_norm": 0.4769628942012787,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.3536,
      "step": 172900
    },
    {
      "epoch": 7.034500986032895,
      "grad_norm": 0.4589196443557739,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3535,
      "step": 173000
    },
    {
      "epoch": 7.038567101063289,
      "grad_norm": 0.4365224540233612,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3522,
      "step": 173100
    },
    {
      "epoch": 7.042633216093683,
      "grad_norm": 0.4255099594593048,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3526,
      "step": 173200
    },
    {
      "epoch": 7.046699331124078,
      "grad_norm": 0.4353930950164795,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.3531,
      "step": 173300
    },
    {
      "epoch": 7.050765446154472,
      "grad_norm": 0.5202565789222717,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3531,
      "step": 173400
    },
    {
      "epoch": 7.054831561184866,
      "grad_norm": 0.4410833716392517,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3561,
      "step": 173500
    },
    {
      "epoch": 7.05889767621526,
      "grad_norm": 0.4512605667114258,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3534,
      "step": 173600
    },
    {
      "epoch": 7.062963791245655,
      "grad_norm": 0.4967605471611023,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.3529,
      "step": 173700
    },
    {
      "epoch": 7.067029906276049,
      "grad_norm": 0.5075139403343201,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3548,
      "step": 173800
    },
    {
      "epoch": 7.071096021306443,
      "grad_norm": 0.4468425512313843,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.3537,
      "step": 173900
    },
    {
      "epoch": 7.075162136336837,
      "grad_norm": 0.4122910797595978,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3528,
      "step": 174000
    },
    {
      "epoch": 7.075162136336837,
      "eval_loss": 0.36774152517318726,
      "eval_runtime": 181.0897,
      "eval_samples_per_second": 965.831,
      "eval_steps_per_second": 30.184,
      "step": 174000
    },
    {
      "epoch": 7.0792282513672316,
      "grad_norm": 0.48056676983833313,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.3539,
      "step": 174100
    },
    {
      "epoch": 7.0832943663976256,
      "grad_norm": 0.4765909016132355,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.3533,
      "step": 174200
    },
    {
      "epoch": 7.0873604814280196,
      "grad_norm": 0.4177037477493286,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.3558,
      "step": 174300
    },
    {
      "epoch": 7.091426596458414,
      "grad_norm": 0.43902388215065,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.3549,
      "step": 174400
    },
    {
      "epoch": 7.0954927114888084,
      "grad_norm": 0.5021026134490967,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3544,
      "step": 174500
    },
    {
      "epoch": 7.0995588265192024,
      "grad_norm": 0.47469836473464966,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.356,
      "step": 174600
    },
    {
      "epoch": 7.1036249415495964,
      "grad_norm": 0.43885841965675354,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3569,
      "step": 174700
    },
    {
      "epoch": 7.1076910565799905,
      "grad_norm": 0.42903846502304077,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.3567,
      "step": 174800
    },
    {
      "epoch": 7.1117571716103845,
      "grad_norm": 0.4986412823200226,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3552,
      "step": 174900
    },
    {
      "epoch": 7.115823286640779,
      "grad_norm": 0.4707866311073303,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3561,
      "step": 175000
    },
    {
      "epoch": 7.119889401671173,
      "grad_norm": 0.5013054013252258,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.3542,
      "step": 175100
    },
    {
      "epoch": 7.123955516701567,
      "grad_norm": 0.4539230167865753,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.3557,
      "step": 175200
    },
    {
      "epoch": 7.128021631731961,
      "grad_norm": 0.4694797396659851,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3556,
      "step": 175300
    },
    {
      "epoch": 7.132087746762356,
      "grad_norm": 0.4559975564479828,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3548,
      "step": 175400
    },
    {
      "epoch": 7.13615386179275,
      "grad_norm": 0.4697091579437256,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3554,
      "step": 175500
    },
    {
      "epoch": 7.140219976823144,
      "grad_norm": 0.4833686351776123,
      "learning_rate": 0.000155645553932634,
      "loss": 0.355,
      "step": 175600
    },
    {
      "epoch": 7.144286091853538,
      "grad_norm": 0.41069287061691284,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3522,
      "step": 175700
    },
    {
      "epoch": 7.148352206883933,
      "grad_norm": 0.49326103925704956,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3557,
      "step": 175800
    },
    {
      "epoch": 7.152418321914327,
      "grad_norm": 0.4018579125404358,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3549,
      "step": 175900
    },
    {
      "epoch": 7.156484436944721,
      "grad_norm": 0.4626718759536743,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.3573,
      "step": 176000
    },
    {
      "epoch": 7.156484436944721,
      "eval_loss": 0.36825424432754517,
      "eval_runtime": 180.3355,
      "eval_samples_per_second": 969.87,
      "eval_steps_per_second": 30.31,
      "step": 176000
    },
    {
      "epoch": 7.160550551975115,
      "grad_norm": 0.4528752267360687,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.357,
      "step": 176100
    },
    {
      "epoch": 7.164616667005509,
      "grad_norm": 0.43316158652305603,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3558,
      "step": 176200
    },
    {
      "epoch": 7.168682782035904,
      "grad_norm": 0.4407332241535187,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.3552,
      "step": 176300
    },
    {
      "epoch": 7.172748897066298,
      "grad_norm": 0.446018785238266,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3563,
      "step": 176400
    },
    {
      "epoch": 7.176815012096692,
      "grad_norm": 0.39698195457458496,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3565,
      "step": 176500
    },
    {
      "epoch": 7.180881127127086,
      "grad_norm": 0.6765422821044922,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3533,
      "step": 176600
    },
    {
      "epoch": 7.184947242157481,
      "grad_norm": 0.40311864018440247,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.354,
      "step": 176700
    },
    {
      "epoch": 7.189013357187875,
      "grad_norm": 0.38691389560699463,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3568,
      "step": 176800
    },
    {
      "epoch": 7.193079472218269,
      "grad_norm": 0.4216156005859375,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3555,
      "step": 176900
    },
    {
      "epoch": 7.197145587248663,
      "grad_norm": 0.415560781955719,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3562,
      "step": 177000
    },
    {
      "epoch": 7.201211702279058,
      "grad_norm": 0.390550434589386,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3564,
      "step": 177100
    },
    {
      "epoch": 7.205277817309452,
      "grad_norm": 0.4623508155345917,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3543,
      "step": 177200
    },
    {
      "epoch": 7.209343932339846,
      "grad_norm": 0.4728924036026001,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.355,
      "step": 177300
    },
    {
      "epoch": 7.21341004737024,
      "grad_norm": 0.4561258852481842,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.3563,
      "step": 177400
    },
    {
      "epoch": 7.217476162400635,
      "grad_norm": 0.42803144454956055,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.3564,
      "step": 177500
    },
    {
      "epoch": 7.221542277431029,
      "grad_norm": 0.4167425036430359,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3555,
      "step": 177600
    },
    {
      "epoch": 7.225608392461423,
      "grad_norm": 0.39031147956848145,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3548,
      "step": 177700
    },
    {
      "epoch": 7.229674507491817,
      "grad_norm": 0.39638471603393555,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.3569,
      "step": 177800
    },
    {
      "epoch": 7.233740622522211,
      "grad_norm": 0.44285768270492554,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3564,
      "step": 177900
    },
    {
      "epoch": 7.237806737552606,
      "grad_norm": 0.40745294094085693,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.3535,
      "step": 178000
    },
    {
      "epoch": 7.237806737552606,
      "eval_loss": 0.3680794835090637,
      "eval_runtime": 180.4139,
      "eval_samples_per_second": 969.449,
      "eval_steps_per_second": 30.297,
      "step": 178000
    },
    {
      "epoch": 7.241872852583,
      "grad_norm": 0.45988476276397705,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3549,
      "step": 178100
    },
    {
      "epoch": 7.245938967613394,
      "grad_norm": 0.4434031546115875,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3551,
      "step": 178200
    },
    {
      "epoch": 7.250005082643788,
      "grad_norm": 0.3838185966014862,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3562,
      "step": 178300
    },
    {
      "epoch": 7.2540711976741825,
      "grad_norm": 0.43218278884887695,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.3558,
      "step": 178400
    },
    {
      "epoch": 7.2581373127045765,
      "grad_norm": 0.503825843334198,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3556,
      "step": 178500
    },
    {
      "epoch": 7.2622034277349705,
      "grad_norm": 0.4908386170864105,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3552,
      "step": 178600
    },
    {
      "epoch": 7.2662695427653645,
      "grad_norm": 0.3616988956928253,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3546,
      "step": 178700
    },
    {
      "epoch": 7.270335657795759,
      "grad_norm": 0.3798689544200897,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3548,
      "step": 178800
    },
    {
      "epoch": 7.274401772826153,
      "grad_norm": 0.43253669142723083,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3559,
      "step": 178900
    },
    {
      "epoch": 7.278467887856547,
      "grad_norm": 0.4325903356075287,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3544,
      "step": 179000
    },
    {
      "epoch": 7.282534002886941,
      "grad_norm": 0.40850844979286194,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.3551,
      "step": 179100
    },
    {
      "epoch": 7.286600117917336,
      "grad_norm": 0.5041275024414062,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3544,
      "step": 179200
    },
    {
      "epoch": 7.29066623294773,
      "grad_norm": 0.45361459255218506,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.3545,
      "step": 179300
    },
    {
      "epoch": 7.294732347978124,
      "grad_norm": 0.4427067041397095,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3546,
      "step": 179400
    },
    {
      "epoch": 7.298798463008518,
      "grad_norm": 0.4489302337169647,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3576,
      "step": 179500
    },
    {
      "epoch": 7.302864578038912,
      "grad_norm": 0.39318710565567017,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3575,
      "step": 179600
    },
    {
      "epoch": 7.306930693069307,
      "grad_norm": 0.3859233260154724,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.3549,
      "step": 179700
    },
    {
      "epoch": 7.310996808099701,
      "grad_norm": 0.4025738835334778,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.3563,
      "step": 179800
    },
    {
      "epoch": 7.315062923130095,
      "grad_norm": 0.4456078112125397,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3553,
      "step": 179900
    },
    {
      "epoch": 7.319129038160489,
      "grad_norm": 0.4225952923297882,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3555,
      "step": 180000
    },
    {
      "epoch": 7.319129038160489,
      "eval_loss": 0.3671973943710327,
      "eval_runtime": 179.7803,
      "eval_samples_per_second": 972.865,
      "eval_steps_per_second": 30.404,
      "step": 180000
    },
    {
      "epoch": 7.323195153190884,
      "grad_norm": 0.41402360796928406,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3558,
      "step": 180100
    },
    {
      "epoch": 7.327261268221278,
      "grad_norm": 0.3933916389942169,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.3556,
      "step": 180200
    },
    {
      "epoch": 7.331327383251672,
      "grad_norm": 0.42808499932289124,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3543,
      "step": 180300
    },
    {
      "epoch": 7.335393498282066,
      "grad_norm": 0.45508959889411926,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.3551,
      "step": 180400
    },
    {
      "epoch": 7.339459613312461,
      "grad_norm": 0.4472837746143341,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3549,
      "step": 180500
    },
    {
      "epoch": 7.343525728342855,
      "grad_norm": 0.4507845938205719,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.3543,
      "step": 180600
    },
    {
      "epoch": 7.347591843373249,
      "grad_norm": 0.40258458256721497,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3572,
      "step": 180700
    },
    {
      "epoch": 7.351657958403643,
      "grad_norm": 0.4064580798149109,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.3549,
      "step": 180800
    },
    {
      "epoch": 7.355724073434038,
      "grad_norm": 0.47038891911506653,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3546,
      "step": 180900
    },
    {
      "epoch": 7.359790188464432,
      "grad_norm": 0.4146696627140045,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3553,
      "step": 181000
    },
    {
      "epoch": 7.363856303494826,
      "grad_norm": 0.46504276990890503,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3567,
      "step": 181100
    },
    {
      "epoch": 7.36792241852522,
      "grad_norm": 0.4555022716522217,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3559,
      "step": 181200
    },
    {
      "epoch": 7.371988533555614,
      "grad_norm": 0.4079533517360687,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3559,
      "step": 181300
    },
    {
      "epoch": 7.376054648586009,
      "grad_norm": 0.4136984050273895,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3552,
      "step": 181400
    },
    {
      "epoch": 7.380120763616403,
      "grad_norm": 0.4659891128540039,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.3544,
      "step": 181500
    },
    {
      "epoch": 7.384186878646797,
      "grad_norm": 0.4578680992126465,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3545,
      "step": 181600
    },
    {
      "epoch": 7.388252993677191,
      "grad_norm": 0.4441680312156677,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.3539,
      "step": 181700
    },
    {
      "epoch": 7.392319108707586,
      "grad_norm": 0.4109514653682709,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3567,
      "step": 181800
    },
    {
      "epoch": 7.39638522373798,
      "grad_norm": 0.39019259810447693,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3553,
      "step": 181900
    },
    {
      "epoch": 7.400451338768374,
      "grad_norm": 0.3869782090187073,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3549,
      "step": 182000
    },
    {
      "epoch": 7.400451338768374,
      "eval_loss": 0.3678610026836395,
      "eval_runtime": 180.7878,
      "eval_samples_per_second": 967.444,
      "eval_steps_per_second": 30.234,
      "step": 182000
    },
    {
      "epoch": 7.404517453798768,
      "grad_norm": 0.4173504412174225,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3548,
      "step": 182100
    },
    {
      "epoch": 7.408583568829163,
      "grad_norm": 0.42489445209503174,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.3559,
      "step": 182200
    },
    {
      "epoch": 7.412649683859557,
      "grad_norm": 0.40816470980644226,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.3554,
      "step": 182300
    },
    {
      "epoch": 7.416715798889951,
      "grad_norm": 0.38168683648109436,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3585,
      "step": 182400
    },
    {
      "epoch": 7.420781913920345,
      "grad_norm": 0.44594064354896545,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3582,
      "step": 182500
    },
    {
      "epoch": 7.4248480289507395,
      "grad_norm": 0.4221908450126648,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.3552,
      "step": 182600
    },
    {
      "epoch": 7.4289141439811335,
      "grad_norm": 0.4642881751060486,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3583,
      "step": 182700
    },
    {
      "epoch": 7.4329802590115275,
      "grad_norm": 0.36513206362724304,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3557,
      "step": 182800
    },
    {
      "epoch": 7.4370463740419215,
      "grad_norm": 0.45249760150909424,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.356,
      "step": 182900
    },
    {
      "epoch": 7.4411124890723155,
      "grad_norm": 0.4512103497982025,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3551,
      "step": 183000
    },
    {
      "epoch": 7.44517860410271,
      "grad_norm": 0.442319393157959,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3553,
      "step": 183100
    },
    {
      "epoch": 7.449244719133104,
      "grad_norm": 0.4050738513469696,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.3543,
      "step": 183200
    },
    {
      "epoch": 7.453310834163498,
      "grad_norm": 0.3664487302303314,
      "learning_rate": 0.000138604877616961,
      "loss": 0.3562,
      "step": 183300
    },
    {
      "epoch": 7.457376949193892,
      "grad_norm": 0.3900451064109802,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.3542,
      "step": 183400
    },
    {
      "epoch": 7.461443064224287,
      "grad_norm": 0.4672265350818634,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3556,
      "step": 183500
    },
    {
      "epoch": 7.465509179254681,
      "grad_norm": 0.5110812783241272,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.356,
      "step": 183600
    },
    {
      "epoch": 7.469575294285075,
      "grad_norm": 0.42297863960266113,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3548,
      "step": 183700
    },
    {
      "epoch": 7.473641409315469,
      "grad_norm": 0.4153025448322296,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.3564,
      "step": 183800
    },
    {
      "epoch": 7.477707524345863,
      "grad_norm": 0.42773398756980896,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3542,
      "step": 183900
    },
    {
      "epoch": 7.481773639376258,
      "grad_norm": 0.498649924993515,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.3563,
      "step": 184000
    },
    {
      "epoch": 7.481773639376258,
      "eval_loss": 0.36726731061935425,
      "eval_runtime": 180.6652,
      "eval_samples_per_second": 968.1,
      "eval_steps_per_second": 30.255,
      "step": 184000
    },
    {
      "epoch": 7.485839754406652,
      "grad_norm": 0.480365514755249,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3563,
      "step": 184100
    },
    {
      "epoch": 7.489905869437046,
      "grad_norm": 0.4063454568386078,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.3571,
      "step": 184200
    },
    {
      "epoch": 7.49397198446744,
      "grad_norm": 0.41436105966567993,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.3555,
      "step": 184300
    },
    {
      "epoch": 7.498038099497835,
      "grad_norm": 0.44394373893737793,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3543,
      "step": 184400
    },
    {
      "epoch": 7.502104214528229,
      "grad_norm": 0.40615755319595337,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3555,
      "step": 184500
    },
    {
      "epoch": 7.506170329558623,
      "grad_norm": 0.4860031306743622,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.3539,
      "step": 184600
    },
    {
      "epoch": 7.510236444589017,
      "grad_norm": 0.41669386625289917,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3547,
      "step": 184700
    },
    {
      "epoch": 7.514302559619412,
      "grad_norm": 0.4243118166923523,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.3536,
      "step": 184800
    },
    {
      "epoch": 7.518368674649806,
      "grad_norm": 0.4170769453048706,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.357,
      "step": 184900
    },
    {
      "epoch": 7.5224347896802,
      "grad_norm": 0.45555099844932556,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3555,
      "step": 185000
    },
    {
      "epoch": 7.526500904710594,
      "grad_norm": 0.4204116761684418,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3552,
      "step": 185100
    },
    {
      "epoch": 7.530567019740989,
      "grad_norm": 0.38542142510414124,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3558,
      "step": 185200
    },
    {
      "epoch": 7.534633134771383,
      "grad_norm": 0.40105485916137695,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3545,
      "step": 185300
    },
    {
      "epoch": 7.538699249801777,
      "grad_norm": 0.5109456181526184,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.3564,
      "step": 185400
    },
    {
      "epoch": 7.542765364832171,
      "grad_norm": 0.4532729685306549,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.3531,
      "step": 185500
    },
    {
      "epoch": 7.546831479862565,
      "grad_norm": 0.41073042154312134,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.3565,
      "step": 185600
    },
    {
      "epoch": 7.55089759489296,
      "grad_norm": 0.4621903598308563,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3558,
      "step": 185700
    },
    {
      "epoch": 7.554963709923354,
      "grad_norm": 0.4010011553764343,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3542,
      "step": 185800
    },
    {
      "epoch": 7.559029824953748,
      "grad_norm": 0.39981257915496826,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.3544,
      "step": 185900
    },
    {
      "epoch": 7.563095939984143,
      "grad_norm": 0.41803649067878723,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.3557,
      "step": 186000
    },
    {
      "epoch": 7.563095939984143,
      "eval_loss": 0.36644551157951355,
      "eval_runtime": 180.1059,
      "eval_samples_per_second": 971.106,
      "eval_steps_per_second": 30.349,
      "step": 186000
    },
    {
      "epoch": 7.567162055014537,
      "grad_norm": 0.3544861972332001,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3563,
      "step": 186100
    },
    {
      "epoch": 7.571228170044931,
      "grad_norm": 0.39433982968330383,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.3548,
      "step": 186200
    },
    {
      "epoch": 7.575294285075325,
      "grad_norm": 0.40579792857170105,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3541,
      "step": 186300
    },
    {
      "epoch": 7.579360400105719,
      "grad_norm": 0.40506717562675476,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3537,
      "step": 186400
    },
    {
      "epoch": 7.5834265151361135,
      "grad_norm": 0.3425442576408386,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.3529,
      "step": 186500
    },
    {
      "epoch": 7.5874926301665075,
      "grad_norm": 0.4497317671775818,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3546,
      "step": 186600
    },
    {
      "epoch": 7.5915587451969015,
      "grad_norm": 0.4335504174232483,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.3558,
      "step": 186700
    },
    {
      "epoch": 7.5956248602272955,
      "grad_norm": 0.48776930570602417,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3538,
      "step": 186800
    },
    {
      "epoch": 7.59969097525769,
      "grad_norm": 0.41319626569747925,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.3577,
      "step": 186900
    },
    {
      "epoch": 7.603757090288084,
      "grad_norm": 0.4085283875465393,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3548,
      "step": 187000
    },
    {
      "epoch": 7.607823205318478,
      "grad_norm": 0.4712797999382019,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3544,
      "step": 187100
    },
    {
      "epoch": 7.6118893203488724,
      "grad_norm": 0.43913763761520386,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.356,
      "step": 187200
    },
    {
      "epoch": 7.6159554353792664,
      "grad_norm": 0.403092622756958,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.3544,
      "step": 187300
    },
    {
      "epoch": 7.620021550409661,
      "grad_norm": 0.42660048604011536,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.3562,
      "step": 187400
    },
    {
      "epoch": 7.624087665440055,
      "grad_norm": 0.47670871019363403,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.3545,
      "step": 187500
    },
    {
      "epoch": 7.628153780470449,
      "grad_norm": 0.4401009678840637,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.3547,
      "step": 187600
    },
    {
      "epoch": 7.632219895500843,
      "grad_norm": 0.48731765151023865,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3529,
      "step": 187700
    },
    {
      "epoch": 7.636286010531238,
      "grad_norm": 0.4463510513305664,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3559,
      "step": 187800
    },
    {
      "epoch": 7.640352125561632,
      "grad_norm": 0.4659038484096527,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3535,
      "step": 187900
    },
    {
      "epoch": 7.644418240592026,
      "grad_norm": 0.41645514965057373,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.3534,
      "step": 188000
    },
    {
      "epoch": 7.644418240592026,
      "eval_loss": 0.36548200249671936,
      "eval_runtime": 179.0047,
      "eval_samples_per_second": 977.081,
      "eval_steps_per_second": 30.536,
      "step": 188000
    },
    {
      "epoch": 7.64848435562242,
      "grad_norm": 0.4910379946231842,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.3529,
      "step": 188100
    },
    {
      "epoch": 7.652550470652815,
      "grad_norm": 0.405222088098526,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3533,
      "step": 188200
    },
    {
      "epoch": 7.656616585683209,
      "grad_norm": 0.4133719205856323,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3547,
      "step": 188300
    },
    {
      "epoch": 7.660682700713603,
      "grad_norm": 0.4273202121257782,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3541,
      "step": 188400
    },
    {
      "epoch": 7.664748815743997,
      "grad_norm": 0.40837299823760986,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3576,
      "step": 188500
    },
    {
      "epoch": 7.668814930774392,
      "grad_norm": 0.3965069651603699,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.356,
      "step": 188600
    },
    {
      "epoch": 7.672881045804786,
      "grad_norm": 0.41814497113227844,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3527,
      "step": 188700
    },
    {
      "epoch": 7.67694716083518,
      "grad_norm": 0.4197523295879364,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.3563,
      "step": 188800
    },
    {
      "epoch": 7.681013275865574,
      "grad_norm": 0.4616160988807678,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.355,
      "step": 188900
    },
    {
      "epoch": 7.685079390895968,
      "grad_norm": 0.44104182720184326,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3552,
      "step": 189000
    },
    {
      "epoch": 7.689145505926363,
      "grad_norm": 0.4591801166534424,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.3547,
      "step": 189100
    },
    {
      "epoch": 7.693211620956757,
      "grad_norm": 0.4464785158634186,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.3531,
      "step": 189200
    },
    {
      "epoch": 7.697277735987151,
      "grad_norm": 0.41915470361709595,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.3546,
      "step": 189300
    },
    {
      "epoch": 7.701343851017545,
      "grad_norm": 0.41998422145843506,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.3551,
      "step": 189400
    },
    {
      "epoch": 7.70540996604794,
      "grad_norm": 0.4247325360774994,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3547,
      "step": 189500
    },
    {
      "epoch": 7.709476081078334,
      "grad_norm": 0.42683514952659607,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.3573,
      "step": 189600
    },
    {
      "epoch": 7.713542196108728,
      "grad_norm": 0.42618897557258606,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3538,
      "step": 189700
    },
    {
      "epoch": 7.717608311139122,
      "grad_norm": 0.3945642113685608,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.3541,
      "step": 189800
    },
    {
      "epoch": 7.721674426169517,
      "grad_norm": 0.4211477041244507,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3558,
      "step": 189900
    },
    {
      "epoch": 7.725740541199911,
      "grad_norm": 0.4226420223712921,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.3552,
      "step": 190000
    },
    {
      "epoch": 7.725740541199911,
      "eval_loss": 0.3651280701160431,
      "eval_runtime": 179.6209,
      "eval_samples_per_second": 973.728,
      "eval_steps_per_second": 30.431,
      "step": 190000
    },
    {
      "epoch": 7.729806656230305,
      "grad_norm": 0.44454440474510193,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3542,
      "step": 190100
    },
    {
      "epoch": 7.733872771260699,
      "grad_norm": 0.44403064250946045,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3546,
      "step": 190200
    },
    {
      "epoch": 7.737938886291094,
      "grad_norm": 0.4409540295600891,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.3547,
      "step": 190300
    },
    {
      "epoch": 7.742005001321488,
      "grad_norm": 0.4399528503417969,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.3533,
      "step": 190400
    },
    {
      "epoch": 7.746071116351882,
      "grad_norm": 0.4810110330581665,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3554,
      "step": 190500
    },
    {
      "epoch": 7.750137231382276,
      "grad_norm": 0.4266311526298523,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.355,
      "step": 190600
    },
    {
      "epoch": 7.75420334641267,
      "grad_norm": 0.45422840118408203,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3528,
      "step": 190700
    },
    {
      "epoch": 7.7582694614430645,
      "grad_norm": 0.4237307608127594,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3535,
      "step": 190800
    },
    {
      "epoch": 7.7623355764734585,
      "grad_norm": 0.4633188843727112,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.3557,
      "step": 190900
    },
    {
      "epoch": 7.7664016915038525,
      "grad_norm": 0.38646045327186584,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3517,
      "step": 191000
    },
    {
      "epoch": 7.7704678065342465,
      "grad_norm": 0.4120621383190155,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3531,
      "step": 191100
    },
    {
      "epoch": 7.774533921564641,
      "grad_norm": 0.4126540720462799,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3549,
      "step": 191200
    },
    {
      "epoch": 7.778600036595035,
      "grad_norm": 0.4094109833240509,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3538,
      "step": 191300
    },
    {
      "epoch": 7.782666151625429,
      "grad_norm": 0.4232017993927002,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.3551,
      "step": 191400
    },
    {
      "epoch": 7.786732266655823,
      "grad_norm": 0.4336546063423157,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3546,
      "step": 191500
    },
    {
      "epoch": 7.790798381686217,
      "grad_norm": 0.4024949073791504,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3544,
      "step": 191600
    },
    {
      "epoch": 7.794864496716612,
      "grad_norm": 0.41049423813819885,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3529,
      "step": 191700
    },
    {
      "epoch": 7.798930611747006,
      "grad_norm": 0.43329891562461853,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.3542,
      "step": 191800
    },
    {
      "epoch": 7.8029967267774,
      "grad_norm": 0.44925615191459656,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3527,
      "step": 191900
    },
    {
      "epoch": 7.807062841807795,
      "grad_norm": 0.40759655833244324,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3535,
      "step": 192000
    },
    {
      "epoch": 7.807062841807795,
      "eval_loss": 0.3646027147769928,
      "eval_runtime": 179.8958,
      "eval_samples_per_second": 972.24,
      "eval_steps_per_second": 30.384,
      "step": 192000
    },
    {
      "epoch": 7.811128956838189,
      "grad_norm": 0.4399188458919525,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.3563,
      "step": 192100
    },
    {
      "epoch": 7.815195071868583,
      "grad_norm": 0.4227396845817566,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.3538,
      "step": 192200
    },
    {
      "epoch": 7.819261186898977,
      "grad_norm": 0.4396582841873169,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3528,
      "step": 192300
    },
    {
      "epoch": 7.823327301929371,
      "grad_norm": 0.4357789158821106,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.3521,
      "step": 192400
    },
    {
      "epoch": 7.827393416959766,
      "grad_norm": 0.5038133263587952,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.3528,
      "step": 192500
    },
    {
      "epoch": 7.83145953199016,
      "grad_norm": 0.48448532819747925,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.355,
      "step": 192600
    },
    {
      "epoch": 7.835525647020554,
      "grad_norm": 0.43474411964416504,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3557,
      "step": 192700
    },
    {
      "epoch": 7.839591762050948,
      "grad_norm": 0.3703165352344513,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.3538,
      "step": 192800
    },
    {
      "epoch": 7.843657877081343,
      "grad_norm": 0.5237111449241638,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.352,
      "step": 192900
    },
    {
      "epoch": 7.847723992111737,
      "grad_norm": 0.43777763843536377,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.3524,
      "step": 193000
    },
    {
      "epoch": 7.851790107142131,
      "grad_norm": 0.5024554133415222,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.3548,
      "step": 193100
    },
    {
      "epoch": 7.855856222172525,
      "grad_norm": 0.411689817905426,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3545,
      "step": 193200
    },
    {
      "epoch": 7.859922337202919,
      "grad_norm": 0.4176710247993469,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.3542,
      "step": 193300
    },
    {
      "epoch": 7.863988452233314,
      "grad_norm": 0.41237661242485046,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.3535,
      "step": 193400
    },
    {
      "epoch": 7.868054567263708,
      "grad_norm": 0.40634697675704956,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3544,
      "step": 193500
    },
    {
      "epoch": 7.872120682294102,
      "grad_norm": 0.3930007815361023,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3524,
      "step": 193600
    },
    {
      "epoch": 7.876186797324497,
      "grad_norm": 0.44590702652931213,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3518,
      "step": 193700
    },
    {
      "epoch": 7.880252912354891,
      "grad_norm": 0.4605790674686432,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3554,
      "step": 193800
    },
    {
      "epoch": 7.884319027385285,
      "grad_norm": 0.4997161030769348,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3532,
      "step": 193900
    },
    {
      "epoch": 7.888385142415679,
      "grad_norm": 0.43833816051483154,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3537,
      "step": 194000
    },
    {
      "epoch": 7.888385142415679,
      "eval_loss": 0.36479121446609497,
      "eval_runtime": 179.0603,
      "eval_samples_per_second": 976.777,
      "eval_steps_per_second": 30.526,
      "step": 194000
    },
    {
      "epoch": 7.892451257446073,
      "grad_norm": 0.5607964992523193,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3539,
      "step": 194100
    },
    {
      "epoch": 7.896517372476468,
      "grad_norm": 0.4116264581680298,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.3517,
      "step": 194200
    },
    {
      "epoch": 7.900583487506862,
      "grad_norm": 0.45003750920295715,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3517,
      "step": 194300
    },
    {
      "epoch": 7.904649602537256,
      "grad_norm": 0.4335114359855652,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3547,
      "step": 194400
    },
    {
      "epoch": 7.90871571756765,
      "grad_norm": 0.47822892665863037,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3537,
      "step": 194500
    },
    {
      "epoch": 7.912781832598045,
      "grad_norm": 0.4636409878730774,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.3537,
      "step": 194600
    },
    {
      "epoch": 7.916847947628439,
      "grad_norm": 0.4317706227302551,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.352,
      "step": 194700
    },
    {
      "epoch": 7.920914062658833,
      "grad_norm": 0.42701369524002075,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3537,
      "step": 194800
    },
    {
      "epoch": 7.924980177689227,
      "grad_norm": 0.44065406918525696,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3539,
      "step": 194900
    },
    {
      "epoch": 7.929046292719621,
      "grad_norm": 0.46366527676582336,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.3561,
      "step": 195000
    },
    {
      "epoch": 7.9331124077500155,
      "grad_norm": 0.43541768193244934,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.3521,
      "step": 195100
    },
    {
      "epoch": 7.9371785227804095,
      "grad_norm": 0.42833417654037476,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.354,
      "step": 195200
    },
    {
      "epoch": 7.9412446378108035,
      "grad_norm": 0.4755467474460602,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.3518,
      "step": 195300
    },
    {
      "epoch": 7.945310752841198,
      "grad_norm": 0.44537293910980225,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3532,
      "step": 195400
    },
    {
      "epoch": 7.949376867871592,
      "grad_norm": 0.42983168363571167,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3549,
      "step": 195500
    },
    {
      "epoch": 7.953442982901986,
      "grad_norm": 0.4173823595046997,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.3549,
      "step": 195600
    },
    {
      "epoch": 7.95750909793238,
      "grad_norm": 0.45608872175216675,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.352,
      "step": 195700
    },
    {
      "epoch": 7.961575212962774,
      "grad_norm": 0.49648693203926086,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.3522,
      "step": 195800
    },
    {
      "epoch": 7.965641327993169,
      "grad_norm": 0.4204748868942261,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.352,
      "step": 195900
    },
    {
      "epoch": 7.969707443023563,
      "grad_norm": 0.4670318365097046,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3561,
      "step": 196000
    },
    {
      "epoch": 7.969707443023563,
      "eval_loss": 0.3655553460121155,
      "eval_runtime": 179.9152,
      "eval_samples_per_second": 972.136,
      "eval_steps_per_second": 30.381,
      "step": 196000
    },
    {
      "epoch": 7.973773558053957,
      "grad_norm": 0.40452226996421814,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.3534,
      "step": 196100
    },
    {
      "epoch": 7.977839673084351,
      "grad_norm": 0.43985602259635925,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3536,
      "step": 196200
    },
    {
      "epoch": 7.981905788114746,
      "grad_norm": 0.4895400106906891,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3528,
      "step": 196300
    },
    {
      "epoch": 7.98597190314514,
      "grad_norm": 0.5035584568977356,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3534,
      "step": 196400
    },
    {
      "epoch": 7.990038018175534,
      "grad_norm": 0.4235173165798187,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3554,
      "step": 196500
    },
    {
      "epoch": 7.994104133205928,
      "grad_norm": 0.46870681643486023,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.3536,
      "step": 196600
    },
    {
      "epoch": 7.998170248236322,
      "grad_norm": 0.44411832094192505,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.3513,
      "step": 196700
    },
    {
      "epoch": 8.002236363266716,
      "grad_norm": 0.4483080506324768,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3521,
      "step": 196800
    },
    {
      "epoch": 8.00630247829711,
      "grad_norm": 0.4499130845069885,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.3491,
      "step": 196900
    },
    {
      "epoch": 8.010368593327506,
      "grad_norm": 0.49937182664871216,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3498,
      "step": 197000
    },
    {
      "epoch": 8.0144347083579,
      "grad_norm": 0.45059001445770264,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3484,
      "step": 197100
    },
    {
      "epoch": 8.018500823388294,
      "grad_norm": 0.49152886867523193,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.3487,
      "step": 197200
    },
    {
      "epoch": 8.022566938418688,
      "grad_norm": 0.4593331217765808,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.3513,
      "step": 197300
    },
    {
      "epoch": 8.026633053449082,
      "grad_norm": 0.459160178899765,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.3505,
      "step": 197400
    },
    {
      "epoch": 8.030699168479476,
      "grad_norm": 0.556049108505249,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3516,
      "step": 197500
    },
    {
      "epoch": 8.03476528350987,
      "grad_norm": 0.4529876112937927,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.3485,
      "step": 197600
    },
    {
      "epoch": 8.038831398540264,
      "grad_norm": 0.48410287499427795,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.3514,
      "step": 197700
    },
    {
      "epoch": 8.04289751357066,
      "grad_norm": 0.5070990920066833,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.3502,
      "step": 197800
    },
    {
      "epoch": 8.046963628601054,
      "grad_norm": 0.46709758043289185,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3499,
      "step": 197900
    },
    {
      "epoch": 8.051029743631448,
      "grad_norm": 0.44185200333595276,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3491,
      "step": 198000
    },
    {
      "epoch": 8.051029743631448,
      "eval_loss": 0.364990234375,
      "eval_runtime": 180.5461,
      "eval_samples_per_second": 968.739,
      "eval_steps_per_second": 30.275,
      "step": 198000
    },
    {
      "epoch": 8.055095858661842,
      "grad_norm": 0.3996957540512085,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3499,
      "step": 198100
    },
    {
      "epoch": 8.059161973692236,
      "grad_norm": 0.4925893247127533,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3487,
      "step": 198200
    },
    {
      "epoch": 8.06322808872263,
      "grad_norm": 0.41440367698669434,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.3499,
      "step": 198300
    },
    {
      "epoch": 8.067294203753024,
      "grad_norm": 0.4499717056751251,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3489,
      "step": 198400
    },
    {
      "epoch": 8.071360318783418,
      "grad_norm": 0.46788543462753296,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.3495,
      "step": 198500
    },
    {
      "epoch": 8.075426433813812,
      "grad_norm": 0.4227502942085266,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3475,
      "step": 198600
    },
    {
      "epoch": 8.079492548844208,
      "grad_norm": 0.44989249110221863,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3493,
      "step": 198700
    },
    {
      "epoch": 8.083558663874602,
      "grad_norm": 0.4036681652069092,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3519,
      "step": 198800
    },
    {
      "epoch": 8.087624778904996,
      "grad_norm": 0.4622458517551422,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.3495,
      "step": 198900
    },
    {
      "epoch": 8.09169089393539,
      "grad_norm": 0.48776230216026306,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3497,
      "step": 199000
    },
    {
      "epoch": 8.095757008965784,
      "grad_norm": 0.5197455883026123,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3511,
      "step": 199100
    },
    {
      "epoch": 8.099823123996178,
      "grad_norm": 0.49188199639320374,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.3503,
      "step": 199200
    },
    {
      "epoch": 8.103889239026572,
      "grad_norm": 0.39575332403182983,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.35,
      "step": 199300
    },
    {
      "epoch": 8.107955354056966,
      "grad_norm": 0.4258301854133606,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3491,
      "step": 199400
    },
    {
      "epoch": 8.112021469087361,
      "grad_norm": 0.5027424693107605,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3505,
      "step": 199500
    },
    {
      "epoch": 8.116087584117755,
      "grad_norm": 0.4741228520870209,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.3502,
      "step": 199600
    },
    {
      "epoch": 8.12015369914815,
      "grad_norm": 0.4325772225856781,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3493,
      "step": 199700
    },
    {
      "epoch": 8.124219814178543,
      "grad_norm": 0.4502670466899872,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.3478,
      "step": 199800
    },
    {
      "epoch": 8.128285929208937,
      "grad_norm": 0.45879143476486206,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3506,
      "step": 199900
    },
    {
      "epoch": 8.132352044239331,
      "grad_norm": 0.422732412815094,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3502,
      "step": 200000
    },
    {
      "epoch": 8.132352044239331,
      "eval_loss": 0.36331063508987427,
      "eval_runtime": 179.8336,
      "eval_samples_per_second": 972.577,
      "eval_steps_per_second": 30.395,
      "step": 200000
    },
    {
      "epoch": 8.136418159269725,
      "grad_norm": 0.4340851306915283,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.3498,
      "step": 200100
    },
    {
      "epoch": 8.14048427430012,
      "grad_norm": 0.40373408794403076,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.35,
      "step": 200200
    },
    {
      "epoch": 8.144550389330513,
      "grad_norm": 0.4672255218029022,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.35,
      "step": 200300
    },
    {
      "epoch": 8.14861650436091,
      "grad_norm": 0.44517064094543457,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.3516,
      "step": 200400
    },
    {
      "epoch": 8.152682619391303,
      "grad_norm": 0.44689828157424927,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3507,
      "step": 200500
    },
    {
      "epoch": 8.156748734421697,
      "grad_norm": 0.39850109815597534,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3505,
      "step": 200600
    },
    {
      "epoch": 8.160814849452091,
      "grad_norm": 0.4883451759815216,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3488,
      "step": 200700
    },
    {
      "epoch": 8.164880964482485,
      "grad_norm": 0.4903694689273834,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.3495,
      "step": 200800
    },
    {
      "epoch": 8.16894707951288,
      "grad_norm": 0.4465125799179077,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.3494,
      "step": 200900
    },
    {
      "epoch": 8.173013194543273,
      "grad_norm": 0.4758217930793762,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3506,
      "step": 201000
    },
    {
      "epoch": 8.177079309573667,
      "grad_norm": 0.4017106294631958,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3502,
      "step": 201100
    },
    {
      "epoch": 8.181145424604063,
      "grad_norm": 0.4600622355937958,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.3475,
      "step": 201200
    },
    {
      "epoch": 8.185211539634457,
      "grad_norm": 0.4653388261795044,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3486,
      "step": 201300
    },
    {
      "epoch": 8.189277654664851,
      "grad_norm": 0.4992482364177704,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3486,
      "step": 201400
    },
    {
      "epoch": 8.193343769695245,
      "grad_norm": 0.41669896245002747,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.3512,
      "step": 201500
    },
    {
      "epoch": 8.197409884725639,
      "grad_norm": 0.46453383564949036,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.3509,
      "step": 201600
    },
    {
      "epoch": 8.201475999756033,
      "grad_norm": 0.45787739753723145,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3498,
      "step": 201700
    },
    {
      "epoch": 8.205542114786427,
      "grad_norm": 0.4027707576751709,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.3505,
      "step": 201800
    },
    {
      "epoch": 8.209608229816821,
      "grad_norm": 0.45414796471595764,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3508,
      "step": 201900
    },
    {
      "epoch": 8.213674344847215,
      "grad_norm": 0.4511052072048187,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3491,
      "step": 202000
    },
    {
      "epoch": 8.213674344847215,
      "eval_loss": 0.36355552077293396,
      "eval_runtime": 180.0165,
      "eval_samples_per_second": 971.589,
      "eval_steps_per_second": 30.364,
      "step": 202000
    },
    {
      "epoch": 8.21774045987761,
      "grad_norm": 0.523356556892395,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.349,
      "step": 202100
    },
    {
      "epoch": 8.221806574908005,
      "grad_norm": 0.4316362738609314,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3499,
      "step": 202200
    },
    {
      "epoch": 8.225872689938399,
      "grad_norm": 0.43699610233306885,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.3499,
      "step": 202300
    },
    {
      "epoch": 8.229938804968793,
      "grad_norm": 0.46481630206108093,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.3504,
      "step": 202400
    },
    {
      "epoch": 8.234004919999187,
      "grad_norm": 0.4434562921524048,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3496,
      "step": 202500
    },
    {
      "epoch": 8.23807103502958,
      "grad_norm": 0.43653595447540283,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3492,
      "step": 202600
    },
    {
      "epoch": 8.242137150059975,
      "grad_norm": 0.4677339196205139,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.3503,
      "step": 202700
    },
    {
      "epoch": 8.246203265090369,
      "grad_norm": 0.498843252658844,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3493,
      "step": 202800
    },
    {
      "epoch": 8.250269380120763,
      "grad_norm": 0.5279980301856995,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3509,
      "step": 202900
    },
    {
      "epoch": 8.254335495151158,
      "grad_norm": 0.42418742179870605,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3501,
      "step": 203000
    },
    {
      "epoch": 8.258401610181552,
      "grad_norm": 0.44399455189704895,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3488,
      "step": 203100
    },
    {
      "epoch": 8.262467725211947,
      "grad_norm": 0.4297846257686615,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.3491,
      "step": 203200
    },
    {
      "epoch": 8.26653384024234,
      "grad_norm": 0.48737335205078125,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3509,
      "step": 203300
    },
    {
      "epoch": 8.270599955272735,
      "grad_norm": 0.4558987021446228,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.3488,
      "step": 203400
    },
    {
      "epoch": 8.274666070303129,
      "grad_norm": 0.49964743852615356,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.351,
      "step": 203500
    },
    {
      "epoch": 8.278732185333523,
      "grad_norm": 0.47022804617881775,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.3507,
      "step": 203600
    },
    {
      "epoch": 8.282798300363917,
      "grad_norm": 0.3933446705341339,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3485,
      "step": 203700
    },
    {
      "epoch": 8.286864415394312,
      "grad_norm": 0.5014642477035522,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.3495,
      "step": 203800
    },
    {
      "epoch": 8.290930530424706,
      "grad_norm": 0.44143152236938477,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.348,
      "step": 203900
    },
    {
      "epoch": 8.2949966454551,
      "grad_norm": 0.433931827545166,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3487,
      "step": 204000
    },
    {
      "epoch": 8.2949966454551,
      "eval_loss": 0.36262160539627075,
      "eval_runtime": 179.6846,
      "eval_samples_per_second": 973.383,
      "eval_steps_per_second": 30.42,
      "step": 204000
    },
    {
      "epoch": 8.299062760485494,
      "grad_norm": 0.4428119957447052,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.35,
      "step": 204100
    },
    {
      "epoch": 8.303128875515888,
      "grad_norm": 0.4654371440410614,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.3496,
      "step": 204200
    },
    {
      "epoch": 8.307194990546282,
      "grad_norm": 0.4821307361125946,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.3499,
      "step": 204300
    },
    {
      "epoch": 8.311261105576676,
      "grad_norm": 0.45342007279396057,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3506,
      "step": 204400
    },
    {
      "epoch": 8.31532722060707,
      "grad_norm": 0.43854275345802307,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.3491,
      "step": 204500
    },
    {
      "epoch": 8.319393335637464,
      "grad_norm": 0.5274447202682495,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.3498,
      "step": 204600
    },
    {
      "epoch": 8.32345945066786,
      "grad_norm": 0.4796973466873169,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.3511,
      "step": 204700
    },
    {
      "epoch": 8.327525565698254,
      "grad_norm": 0.4859972894191742,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3489,
      "step": 204800
    },
    {
      "epoch": 8.331591680728648,
      "grad_norm": 0.4658128321170807,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.349,
      "step": 204900
    },
    {
      "epoch": 8.335657795759042,
      "grad_norm": 0.420564740896225,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.349,
      "step": 205000
    },
    {
      "epoch": 8.339723910789436,
      "grad_norm": 0.4843282103538513,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.3493,
      "step": 205100
    },
    {
      "epoch": 8.34379002581983,
      "grad_norm": 0.4514367878437042,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.3484,
      "step": 205200
    },
    {
      "epoch": 8.347856140850224,
      "grad_norm": 0.5116524696350098,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3492,
      "step": 205300
    },
    {
      "epoch": 8.351922255880618,
      "grad_norm": 0.4238186776638031,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3487,
      "step": 205400
    },
    {
      "epoch": 8.355988370911014,
      "grad_norm": 0.4443289339542389,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.3493,
      "step": 205500
    },
    {
      "epoch": 8.360054485941408,
      "grad_norm": 0.44931885600090027,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3504,
      "step": 205600
    },
    {
      "epoch": 8.364120600971802,
      "grad_norm": 0.4783646762371063,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3495,
      "step": 205700
    },
    {
      "epoch": 8.368186716002196,
      "grad_norm": 0.4771661162376404,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3496,
      "step": 205800
    },
    {
      "epoch": 8.37225283103259,
      "grad_norm": 0.440714567899704,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3497,
      "step": 205900
    },
    {
      "epoch": 8.376318946062984,
      "grad_norm": 0.4151708483695984,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3495,
      "step": 206000
    },
    {
      "epoch": 8.376318946062984,
      "eval_loss": 0.36375463008880615,
      "eval_runtime": 179.2191,
      "eval_samples_per_second": 975.912,
      "eval_steps_per_second": 30.499,
      "step": 206000
    },
    {
      "epoch": 8.380385061093378,
      "grad_norm": 0.4758591055870056,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3497,
      "step": 206100
    },
    {
      "epoch": 8.384451176123772,
      "grad_norm": 0.4516650438308716,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.35,
      "step": 206200
    },
    {
      "epoch": 8.388517291154166,
      "grad_norm": 0.4586210250854492,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.3504,
      "step": 206300
    },
    {
      "epoch": 8.392583406184562,
      "grad_norm": 0.48823270201683044,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.3521,
      "step": 206400
    },
    {
      "epoch": 8.396649521214956,
      "grad_norm": 0.4640977680683136,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3497,
      "step": 206500
    },
    {
      "epoch": 8.40071563624535,
      "grad_norm": 0.5012916922569275,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.3488,
      "step": 206600
    },
    {
      "epoch": 8.404781751275744,
      "grad_norm": 0.46395790576934814,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.3518,
      "step": 206700
    },
    {
      "epoch": 8.408847866306138,
      "grad_norm": 0.42962563037872314,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.3495,
      "step": 206800
    },
    {
      "epoch": 8.412913981336532,
      "grad_norm": 0.4598052203655243,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.3497,
      "step": 206900
    },
    {
      "epoch": 8.416980096366926,
      "grad_norm": 0.4691540598869324,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3489,
      "step": 207000
    },
    {
      "epoch": 8.42104621139732,
      "grad_norm": 0.49896731972694397,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3466,
      "step": 207100
    },
    {
      "epoch": 8.425112326427715,
      "grad_norm": 0.4769485592842102,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3486,
      "step": 207200
    },
    {
      "epoch": 8.42917844145811,
      "grad_norm": 0.4487125277519226,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3494,
      "step": 207300
    },
    {
      "epoch": 8.433244556488503,
      "grad_norm": 0.5062360763549805,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3504,
      "step": 207400
    },
    {
      "epoch": 8.437310671518897,
      "grad_norm": 0.4930303394794464,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3487,
      "step": 207500
    },
    {
      "epoch": 8.441376786549291,
      "grad_norm": 0.4561076760292053,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3467,
      "step": 207600
    },
    {
      "epoch": 8.445442901579685,
      "grad_norm": 0.43910518288612366,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3489,
      "step": 207700
    },
    {
      "epoch": 8.44950901661008,
      "grad_norm": 0.4358501136302948,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3461,
      "step": 207800
    },
    {
      "epoch": 8.453575131640473,
      "grad_norm": 0.45671749114990234,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3474,
      "step": 207900
    },
    {
      "epoch": 8.457641246670867,
      "grad_norm": 0.4595166742801666,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.3493,
      "step": 208000
    },
    {
      "epoch": 8.457641246670867,
      "eval_loss": 0.36175715923309326,
      "eval_runtime": 180.8145,
      "eval_samples_per_second": 967.301,
      "eval_steps_per_second": 30.23,
      "step": 208000
    },
    {
      "epoch": 8.461707361701263,
      "grad_norm": 0.5486360788345337,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.349,
      "step": 208100
    },
    {
      "epoch": 8.465773476731657,
      "grad_norm": 0.506434440612793,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.3485,
      "step": 208200
    },
    {
      "epoch": 8.469839591762051,
      "grad_norm": 0.44387710094451904,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.3467,
      "step": 208300
    },
    {
      "epoch": 8.473905706792445,
      "grad_norm": 0.4864656329154968,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3497,
      "step": 208400
    },
    {
      "epoch": 8.47797182182284,
      "grad_norm": 0.49514052271842957,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.3496,
      "step": 208500
    },
    {
      "epoch": 8.482037936853233,
      "grad_norm": 0.510669469833374,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.3489,
      "step": 208600
    },
    {
      "epoch": 8.486104051883627,
      "grad_norm": 0.4127020537853241,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3482,
      "step": 208700
    },
    {
      "epoch": 8.490170166914021,
      "grad_norm": 0.4419194757938385,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.3472,
      "step": 208800
    },
    {
      "epoch": 8.494236281944417,
      "grad_norm": 0.5117558240890503,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.3477,
      "step": 208900
    },
    {
      "epoch": 8.498302396974811,
      "grad_norm": 0.4858596622943878,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3457,
      "step": 209000
    },
    {
      "epoch": 8.502368512005205,
      "grad_norm": 0.4750203490257263,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.3472,
      "step": 209100
    },
    {
      "epoch": 8.506434627035599,
      "grad_norm": 0.45289793610572815,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.3497,
      "step": 209200
    },
    {
      "epoch": 8.510500742065993,
      "grad_norm": 0.40920713543891907,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.3488,
      "step": 209300
    },
    {
      "epoch": 8.514566857096387,
      "grad_norm": 0.49825161695480347,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.3486,
      "step": 209400
    },
    {
      "epoch": 8.518632972126781,
      "grad_norm": 0.4702237844467163,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.3493,
      "step": 209500
    },
    {
      "epoch": 8.522699087157175,
      "grad_norm": 0.4984365403652191,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.3476,
      "step": 209600
    },
    {
      "epoch": 8.526765202187569,
      "grad_norm": 0.498913049697876,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.3471,
      "step": 209700
    },
    {
      "epoch": 8.530831317217965,
      "grad_norm": 0.5354060530662537,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.347,
      "step": 209800
    },
    {
      "epoch": 8.534897432248359,
      "grad_norm": 0.4297875463962555,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3473,
      "step": 209900
    },
    {
      "epoch": 8.538963547278753,
      "grad_norm": 0.4626595377922058,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3502,
      "step": 210000
    },
    {
      "epoch": 8.538963547278753,
      "eval_loss": 0.36159244179725647,
      "eval_runtime": 177.8821,
      "eval_samples_per_second": 983.247,
      "eval_steps_per_second": 30.728,
      "step": 210000
    },
    {
      "epoch": 8.543029662309147,
      "grad_norm": 0.5182392597198486,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.3498,
      "step": 210100
    },
    {
      "epoch": 8.54709577733954,
      "grad_norm": 0.4738340675830841,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.35,
      "step": 210200
    },
    {
      "epoch": 8.551161892369935,
      "grad_norm": 0.5396156907081604,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.3492,
      "step": 210300
    },
    {
      "epoch": 8.555228007400329,
      "grad_norm": 0.4378066062927246,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3495,
      "step": 210400
    },
    {
      "epoch": 8.559294122430723,
      "grad_norm": 0.5017542243003845,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3473,
      "step": 210500
    },
    {
      "epoch": 8.563360237461119,
      "grad_norm": 0.5107523798942566,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.3492,
      "step": 210600
    },
    {
      "epoch": 8.567426352491513,
      "grad_norm": 0.5119679570198059,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3483,
      "step": 210700
    },
    {
      "epoch": 8.571492467521907,
      "grad_norm": 0.531803548336029,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.348,
      "step": 210800
    },
    {
      "epoch": 8.5755585825523,
      "grad_norm": 0.45794954895973206,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3484,
      "step": 210900
    },
    {
      "epoch": 8.579624697582695,
      "grad_norm": 0.5765626430511475,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.3501,
      "step": 211000
    },
    {
      "epoch": 8.583690812613089,
      "grad_norm": 0.46099376678466797,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3479,
      "step": 211100
    },
    {
      "epoch": 8.587756927643483,
      "grad_norm": 0.4564884901046753,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3466,
      "step": 211200
    },
    {
      "epoch": 8.591823042673877,
      "grad_norm": 0.454774409532547,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3474,
      "step": 211300
    },
    {
      "epoch": 8.59588915770427,
      "grad_norm": 0.41837334632873535,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3492,
      "step": 211400
    },
    {
      "epoch": 8.599955272734666,
      "grad_norm": 0.471418559551239,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3489,
      "step": 211500
    },
    {
      "epoch": 8.60402138776506,
      "grad_norm": 0.5300669074058533,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.3493,
      "step": 211600
    },
    {
      "epoch": 8.608087502795454,
      "grad_norm": 0.6060409545898438,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.3486,
      "step": 211700
    },
    {
      "epoch": 8.612153617825848,
      "grad_norm": 0.5373926758766174,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3469,
      "step": 211800
    },
    {
      "epoch": 8.616219732856242,
      "grad_norm": 0.5140976309776306,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.3465,
      "step": 211900
    },
    {
      "epoch": 8.620285847886636,
      "grad_norm": 0.4839532673358917,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3466,
      "step": 212000
    },
    {
      "epoch": 8.620285847886636,
      "eval_loss": 0.3613482713699341,
      "eval_runtime": 177.7256,
      "eval_samples_per_second": 984.113,
      "eval_steps_per_second": 30.755,
      "step": 212000
    },
    {
      "epoch": 8.62435196291703,
      "grad_norm": 0.4868001639842987,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3487,
      "step": 212100
    },
    {
      "epoch": 8.628418077947424,
      "grad_norm": 0.43807390332221985,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.3463,
      "step": 212200
    },
    {
      "epoch": 8.63248419297782,
      "grad_norm": 0.47512000799179077,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3466,
      "step": 212300
    },
    {
      "epoch": 8.636550308008214,
      "grad_norm": 0.4546678066253662,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.3484,
      "step": 212400
    },
    {
      "epoch": 8.640616423038608,
      "grad_norm": 0.5248333811759949,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3493,
      "step": 212500
    },
    {
      "epoch": 8.644682538069002,
      "grad_norm": 0.527844250202179,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.346,
      "step": 212600
    },
    {
      "epoch": 8.648748653099396,
      "grad_norm": 0.48551762104034424,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3483,
      "step": 212700
    },
    {
      "epoch": 8.65281476812979,
      "grad_norm": 0.4283599853515625,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.348,
      "step": 212800
    },
    {
      "epoch": 8.656880883160184,
      "grad_norm": 0.497994601726532,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3475,
      "step": 212900
    },
    {
      "epoch": 8.660946998190578,
      "grad_norm": 0.4440992772579193,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.3461,
      "step": 213000
    },
    {
      "epoch": 8.665013113220972,
      "grad_norm": 0.45663368701934814,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3455,
      "step": 213100
    },
    {
      "epoch": 8.669079228251368,
      "grad_norm": 0.4733874797821045,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.3473,
      "step": 213200
    },
    {
      "epoch": 8.673145343281762,
      "grad_norm": 0.48209309577941895,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.3469,
      "step": 213300
    },
    {
      "epoch": 8.677211458312156,
      "grad_norm": 0.49366459250450134,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.3477,
      "step": 213400
    },
    {
      "epoch": 8.68127757334255,
      "grad_norm": 0.5084734559059143,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3476,
      "step": 213500
    },
    {
      "epoch": 8.685343688372944,
      "grad_norm": 0.4505099952220917,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3489,
      "step": 213600
    },
    {
      "epoch": 8.689409803403338,
      "grad_norm": 0.5158268213272095,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3447,
      "step": 213700
    },
    {
      "epoch": 8.693475918433732,
      "grad_norm": 0.4650048017501831,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3461,
      "step": 213800
    },
    {
      "epoch": 8.697542033464126,
      "grad_norm": 0.46537113189697266,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.348,
      "step": 213900
    },
    {
      "epoch": 8.701608148494522,
      "grad_norm": 0.4547577500343323,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.3471,
      "step": 214000
    },
    {
      "epoch": 8.701608148494522,
      "eval_loss": 0.35926979780197144,
      "eval_runtime": 177.7055,
      "eval_samples_per_second": 984.224,
      "eval_steps_per_second": 30.759,
      "step": 214000
    },
    {
      "epoch": 8.705674263524916,
      "grad_norm": 0.4540170133113861,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.346,
      "step": 214100
    },
    {
      "epoch": 8.70974037855531,
      "grad_norm": 0.5309880971908569,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.3466,
      "step": 214200
    },
    {
      "epoch": 8.713806493585704,
      "grad_norm": 0.5758212208747864,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.3459,
      "step": 214300
    },
    {
      "epoch": 8.717872608616098,
      "grad_norm": 0.49007895588874817,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3474,
      "step": 214400
    },
    {
      "epoch": 8.721938723646492,
      "grad_norm": 0.4663372337818146,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3458,
      "step": 214500
    },
    {
      "epoch": 8.726004838676886,
      "grad_norm": 0.46121934056282043,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.3474,
      "step": 214600
    },
    {
      "epoch": 8.73007095370728,
      "grad_norm": 0.5052726864814758,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.3455,
      "step": 214700
    },
    {
      "epoch": 8.734137068737674,
      "grad_norm": 0.46650534868240356,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3479,
      "step": 214800
    },
    {
      "epoch": 8.73820318376807,
      "grad_norm": 0.4503546953201294,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.3476,
      "step": 214900
    },
    {
      "epoch": 8.742269298798464,
      "grad_norm": 0.4987226724624634,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3477,
      "step": 215000
    },
    {
      "epoch": 8.746335413828858,
      "grad_norm": 0.4600922763347626,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.3482,
      "step": 215100
    },
    {
      "epoch": 8.750401528859252,
      "grad_norm": 0.5038709044456482,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.3503,
      "step": 215200
    },
    {
      "epoch": 8.754467643889646,
      "grad_norm": 0.44318363070487976,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3463,
      "step": 215300
    },
    {
      "epoch": 8.75853375892004,
      "grad_norm": 0.4610714912414551,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.3468,
      "step": 215400
    },
    {
      "epoch": 8.762599873950434,
      "grad_norm": 0.5630338191986084,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3452,
      "step": 215500
    },
    {
      "epoch": 8.766665988980828,
      "grad_norm": 0.48079201579093933,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.3473,
      "step": 215600
    },
    {
      "epoch": 8.770732104011223,
      "grad_norm": 0.5255101323127747,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3465,
      "step": 215700
    },
    {
      "epoch": 8.774798219041617,
      "grad_norm": 0.5113343596458435,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3473,
      "step": 215800
    },
    {
      "epoch": 8.778864334072011,
      "grad_norm": 0.5174469947814941,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.348,
      "step": 215900
    },
    {
      "epoch": 8.782930449102405,
      "grad_norm": 0.5150189399719238,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.3463,
      "step": 216000
    },
    {
      "epoch": 8.782930449102405,
      "eval_loss": 0.36466148495674133,
      "eval_runtime": 177.9676,
      "eval_samples_per_second": 982.775,
      "eval_steps_per_second": 30.713,
      "step": 216000
    },
    {
      "epoch": 8.7869965641328,
      "grad_norm": 0.4142698347568512,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3468,
      "step": 216100
    },
    {
      "epoch": 8.791062679163193,
      "grad_norm": 0.4822533428668976,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.347,
      "step": 216200
    },
    {
      "epoch": 8.795128794193587,
      "grad_norm": 0.4536459743976593,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.3468,
      "step": 216300
    },
    {
      "epoch": 8.799194909223981,
      "grad_norm": 0.5336624979972839,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.3449,
      "step": 216400
    },
    {
      "epoch": 8.803261024254375,
      "grad_norm": 0.5659288167953491,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.3477,
      "step": 216500
    },
    {
      "epoch": 8.807327139284771,
      "grad_norm": 0.4828963279724121,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3463,
      "step": 216600
    },
    {
      "epoch": 8.811393254315165,
      "grad_norm": 0.4757973253726959,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.3471,
      "step": 216700
    },
    {
      "epoch": 8.81545936934556,
      "grad_norm": 0.5871365666389465,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.3454,
      "step": 216800
    },
    {
      "epoch": 8.819525484375953,
      "grad_norm": 0.474997878074646,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3481,
      "step": 216900
    },
    {
      "epoch": 8.823591599406347,
      "grad_norm": 0.5513600707054138,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.3472,
      "step": 217000
    },
    {
      "epoch": 8.827657714436741,
      "grad_norm": 0.5062065124511719,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3473,
      "step": 217100
    },
    {
      "epoch": 8.831723829467135,
      "grad_norm": 0.4910731613636017,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.3459,
      "step": 217200
    },
    {
      "epoch": 8.83578994449753,
      "grad_norm": 0.4339156746864319,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3474,
      "step": 217300
    },
    {
      "epoch": 8.839856059527925,
      "grad_norm": 0.5242474675178528,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.3486,
      "step": 217400
    },
    {
      "epoch": 8.843922174558319,
      "grad_norm": 0.49677297472953796,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3459,
      "step": 217500
    },
    {
      "epoch": 8.847988289588713,
      "grad_norm": 0.4717256426811218,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3463,
      "step": 217600
    },
    {
      "epoch": 8.852054404619107,
      "grad_norm": 0.5283221006393433,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3474,
      "step": 217700
    },
    {
      "epoch": 8.856120519649501,
      "grad_norm": 0.44838687777519226,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.345,
      "step": 217800
    },
    {
      "epoch": 8.860186634679895,
      "grad_norm": 0.4792559742927551,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3466,
      "step": 217900
    },
    {
      "epoch": 8.864252749710289,
      "grad_norm": 0.4417882561683655,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3459,
      "step": 218000
    },
    {
      "epoch": 8.864252749710289,
      "eval_loss": 0.3593805134296417,
      "eval_runtime": 177.6716,
      "eval_samples_per_second": 984.412,
      "eval_steps_per_second": 30.765,
      "step": 218000
    },
    {
      "epoch": 8.868318864740683,
      "grad_norm": 0.5083594918251038,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.3457,
      "step": 218100
    },
    {
      "epoch": 8.872384979771077,
      "grad_norm": 0.5373953580856323,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.3456,
      "step": 218200
    },
    {
      "epoch": 8.876451094801473,
      "grad_norm": 0.5145464539527893,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3468,
      "step": 218300
    },
    {
      "epoch": 8.880517209831867,
      "grad_norm": 0.4725281298160553,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3472,
      "step": 218400
    },
    {
      "epoch": 8.88458332486226,
      "grad_norm": 0.5174747705459595,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.3464,
      "step": 218500
    },
    {
      "epoch": 8.888649439892655,
      "grad_norm": 0.5314701199531555,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3461,
      "step": 218600
    },
    {
      "epoch": 8.892715554923049,
      "grad_norm": 0.49829092621803284,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3455,
      "step": 218700
    },
    {
      "epoch": 8.896781669953443,
      "grad_norm": 0.5175495147705078,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3452,
      "step": 218800
    },
    {
      "epoch": 8.900847784983837,
      "grad_norm": 0.4523300230503082,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3441,
      "step": 218900
    },
    {
      "epoch": 8.90491390001423,
      "grad_norm": 0.4673571288585663,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3456,
      "step": 219000
    },
    {
      "epoch": 8.908980015044627,
      "grad_norm": 0.5667555928230286,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3458,
      "step": 219100
    },
    {
      "epoch": 8.91304613007502,
      "grad_norm": 0.43601834774017334,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3451,
      "step": 219200
    },
    {
      "epoch": 8.917112245105415,
      "grad_norm": 0.4503079354763031,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3471,
      "step": 219300
    },
    {
      "epoch": 8.921178360135809,
      "grad_norm": 0.5516650080680847,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3444,
      "step": 219400
    },
    {
      "epoch": 8.925244475166203,
      "grad_norm": 0.5025402307510376,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3464,
      "step": 219500
    },
    {
      "epoch": 8.929310590196597,
      "grad_norm": 0.5262659788131714,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.3459,
      "step": 219600
    },
    {
      "epoch": 8.93337670522699,
      "grad_norm": 0.5689342021942139,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.3449,
      "step": 219700
    },
    {
      "epoch": 8.937442820257385,
      "grad_norm": 0.5837925672531128,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.346,
      "step": 219800
    },
    {
      "epoch": 8.941508935287779,
      "grad_norm": 0.4622768461704254,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.3471,
      "step": 219900
    },
    {
      "epoch": 8.945575050318173,
      "grad_norm": 0.6045251488685608,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.3462,
      "step": 220000
    },
    {
      "epoch": 8.945575050318173,
      "eval_loss": 0.3599220812320709,
      "eval_runtime": 176.9409,
      "eval_samples_per_second": 988.477,
      "eval_steps_per_second": 30.892,
      "step": 220000
    },
    {
      "epoch": 8.949641165348568,
      "grad_norm": 0.5142091512680054,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3471,
      "step": 220100
    },
    {
      "epoch": 8.953707280378962,
      "grad_norm": 0.49500367045402527,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.3452,
      "step": 220200
    },
    {
      "epoch": 8.957773395409356,
      "grad_norm": 0.4912053048610687,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.3447,
      "step": 220300
    },
    {
      "epoch": 8.96183951043975,
      "grad_norm": 0.46844518184661865,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.3438,
      "step": 220400
    },
    {
      "epoch": 8.965905625470144,
      "grad_norm": 0.49282196164131165,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.3451,
      "step": 220500
    },
    {
      "epoch": 8.969971740500538,
      "grad_norm": 0.5006913542747498,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.3464,
      "step": 220600
    },
    {
      "epoch": 8.974037855530932,
      "grad_norm": 0.5539650321006775,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.3447,
      "step": 220700
    },
    {
      "epoch": 8.978103970561326,
      "grad_norm": 0.5333869457244873,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.3452,
      "step": 220800
    },
    {
      "epoch": 8.982170085591722,
      "grad_norm": 0.4644298553466797,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3458,
      "step": 220900
    },
    {
      "epoch": 8.986236200622116,
      "grad_norm": 0.5264043211936951,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.3442,
      "step": 221000
    },
    {
      "epoch": 8.99030231565251,
      "grad_norm": 0.5029421448707581,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.346,
      "step": 221100
    },
    {
      "epoch": 8.994368430682904,
      "grad_norm": 0.46351611614227295,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3477,
      "step": 221200
    },
    {
      "epoch": 8.998434545713298,
      "grad_norm": 0.4846799075603485,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.345,
      "step": 221300
    },
    {
      "epoch": 9.002500660743692,
      "grad_norm": 0.48478031158447266,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3427,
      "step": 221400
    },
    {
      "epoch": 9.006566775774086,
      "grad_norm": 0.5356911420822144,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.3446,
      "step": 221500
    },
    {
      "epoch": 9.01063289080448,
      "grad_norm": 0.5216041803359985,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3421,
      "step": 221600
    },
    {
      "epoch": 9.014699005834876,
      "grad_norm": 0.529930591583252,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3407,
      "step": 221700
    },
    {
      "epoch": 9.01876512086527,
      "grad_norm": 0.5445515513420105,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.3432,
      "step": 221800
    },
    {
      "epoch": 9.022831235895664,
      "grad_norm": 0.5254808664321899,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.3408,
      "step": 221900
    },
    {
      "epoch": 9.026897350926058,
      "grad_norm": 0.48711097240448,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3425,
      "step": 222000
    },
    {
      "epoch": 9.026897350926058,
      "eval_loss": 0.35987263917922974,
      "eval_runtime": 177.6189,
      "eval_samples_per_second": 984.704,
      "eval_steps_per_second": 30.774,
      "step": 222000
    },
    {
      "epoch": 9.030963465956452,
      "grad_norm": 0.45988553762435913,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3424,
      "step": 222100
    },
    {
      "epoch": 9.035029580986846,
      "grad_norm": 0.5504340529441833,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.3441,
      "step": 222200
    },
    {
      "epoch": 9.03909569601724,
      "grad_norm": 0.5692464709281921,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3427,
      "step": 222300
    },
    {
      "epoch": 9.043161811047634,
      "grad_norm": 0.508006751537323,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3431,
      "step": 222400
    },
    {
      "epoch": 9.047227926078028,
      "grad_norm": 0.4625706374645233,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.3417,
      "step": 222500
    },
    {
      "epoch": 9.051294041108424,
      "grad_norm": 0.5016468167304993,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.3414,
      "step": 222600
    },
    {
      "epoch": 9.055360156138818,
      "grad_norm": 0.5149527192115784,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.3408,
      "step": 222700
    },
    {
      "epoch": 9.059426271169212,
      "grad_norm": 0.4987490773200989,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.3402,
      "step": 222800
    },
    {
      "epoch": 9.063492386199606,
      "grad_norm": 0.5115808844566345,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3424,
      "step": 222900
    },
    {
      "epoch": 9.06755850123,
      "grad_norm": 0.544435977935791,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.341,
      "step": 223000
    },
    {
      "epoch": 9.071624616260394,
      "grad_norm": 0.41622158885002136,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.3437,
      "step": 223100
    },
    {
      "epoch": 9.075690731290788,
      "grad_norm": 0.4912833273410797,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3414,
      "step": 223200
    },
    {
      "epoch": 9.079756846321182,
      "grad_norm": 0.49794337153434753,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.3406,
      "step": 223300
    },
    {
      "epoch": 9.083822961351576,
      "grad_norm": 0.49989375472068787,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.3418,
      "step": 223400
    },
    {
      "epoch": 9.087889076381972,
      "grad_norm": 0.5106154084205627,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3423,
      "step": 223500
    },
    {
      "epoch": 9.091955191412366,
      "grad_norm": 0.5662368535995483,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.3427,
      "step": 223600
    },
    {
      "epoch": 9.09602130644276,
      "grad_norm": 0.5202585458755493,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.3423,
      "step": 223700
    },
    {
      "epoch": 9.100087421473154,
      "grad_norm": 0.5876662731170654,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3422,
      "step": 223800
    },
    {
      "epoch": 9.104153536503548,
      "grad_norm": 0.5638019442558289,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.3425,
      "step": 223900
    },
    {
      "epoch": 9.108219651533942,
      "grad_norm": 0.4818621575832367,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.3396,
      "step": 224000
    },
    {
      "epoch": 9.108219651533942,
      "eval_loss": 0.3589322865009308,
      "eval_runtime": 177.6545,
      "eval_samples_per_second": 984.507,
      "eval_steps_per_second": 30.768,
      "step": 224000
    },
    {
      "epoch": 9.112346758289792,
      "grad_norm": 0.6512404680252075,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.3429,
      "step": 224100
    },
    {
      "epoch": 9.116412873320186,
      "grad_norm": 0.548422634601593,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.3417,
      "step": 224200
    },
    {
      "epoch": 9.12047898835058,
      "grad_norm": 0.5874506831169128,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.342,
      "step": 224300
    },
    {
      "epoch": 9.124545103380974,
      "grad_norm": 0.5375291705131531,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.3441,
      "step": 224400
    },
    {
      "epoch": 9.128611218411368,
      "grad_norm": 0.5640034079551697,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3408,
      "step": 224500
    },
    {
      "epoch": 9.132677333441762,
      "grad_norm": 0.5439643859863281,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3411,
      "step": 224600
    },
    {
      "epoch": 9.136743448472158,
      "grad_norm": 0.6359906792640686,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3443,
      "step": 224700
    },
    {
      "epoch": 9.140809563502552,
      "grad_norm": 0.5837103128433228,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3413,
      "step": 224800
    },
    {
      "epoch": 9.144875678532946,
      "grad_norm": 0.5417654514312744,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3416,
      "step": 224900
    },
    {
      "epoch": 9.14894179356334,
      "grad_norm": 0.5170644521713257,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3417,
      "step": 225000
    },
    {
      "epoch": 9.153007908593734,
      "grad_norm": 0.5150091052055359,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3402,
      "step": 225100
    },
    {
      "epoch": 9.157074023624128,
      "grad_norm": 0.5458959341049194,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.3439,
      "step": 225200
    },
    {
      "epoch": 9.161140138654522,
      "grad_norm": 0.5628359913825989,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.342,
      "step": 225300
    },
    {
      "epoch": 9.165206253684916,
      "grad_norm": 0.5698845982551575,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3433,
      "step": 225400
    },
    {
      "epoch": 9.16927236871531,
      "grad_norm": 0.5163738131523132,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3421,
      "step": 225500
    },
    {
      "epoch": 9.173338483745706,
      "grad_norm": 0.5459647178649902,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3422,
      "step": 225600
    },
    {
      "epoch": 9.1774045987761,
      "grad_norm": 0.6189751029014587,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.3419,
      "step": 225700
    },
    {
      "epoch": 9.181470713806494,
      "grad_norm": 0.6080498695373535,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3408,
      "step": 225800
    },
    {
      "epoch": 9.185536828836888,
      "grad_norm": 0.588683009147644,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3412,
      "step": 225900
    },
    {
      "epoch": 9.189602943867282,
      "grad_norm": 0.5807748436927795,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3413,
      "step": 226000
    },
    {
      "epoch": 9.189602943867282,
      "eval_loss": 0.35838136076927185,
      "eval_runtime": 178.2714,
      "eval_samples_per_second": 981.1,
      "eval_steps_per_second": 30.661,
      "step": 226000
    },
    {
      "epoch": 9.193669058897676,
      "grad_norm": 0.5429773926734924,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.3413,
      "step": 226100
    },
    {
      "epoch": 9.19773517392807,
      "grad_norm": 0.588578999042511,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3414,
      "step": 226200
    },
    {
      "epoch": 9.201801288958464,
      "grad_norm": 0.6810935139656067,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3416,
      "step": 226300
    },
    {
      "epoch": 9.205867403988858,
      "grad_norm": 0.6215605735778809,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3423,
      "step": 226400
    },
    {
      "epoch": 9.209933519019254,
      "grad_norm": 0.5550220608711243,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.342,
      "step": 226500
    },
    {
      "epoch": 9.213999634049648,
      "grad_norm": 0.5404359102249146,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.343,
      "step": 226600
    },
    {
      "epoch": 9.218065749080042,
      "grad_norm": 0.6215680837631226,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3424,
      "step": 226700
    },
    {
      "epoch": 9.222131864110436,
      "grad_norm": 0.5558348298072815,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3417,
      "step": 226800
    },
    {
      "epoch": 9.22619797914083,
      "grad_norm": 0.496311753988266,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3407,
      "step": 226900
    },
    {
      "epoch": 9.230264094171224,
      "grad_norm": 0.5148354172706604,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3406,
      "step": 227000
    },
    {
      "epoch": 9.234330209201618,
      "grad_norm": 0.5372742414474487,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3424,
      "step": 227100
    },
    {
      "epoch": 9.238396324232012,
      "grad_norm": 0.5395659804344177,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.3395,
      "step": 227200
    },
    {
      "epoch": 9.242462439262408,
      "grad_norm": 0.5231228470802307,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3409,
      "step": 227300
    },
    {
      "epoch": 9.246528554292802,
      "grad_norm": 0.5177929997444153,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3412,
      "step": 227400
    },
    {
      "epoch": 9.250594669323196,
      "grad_norm": 0.5310794115066528,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3396,
      "step": 227500
    },
    {
      "epoch": 9.25466078435359,
      "grad_norm": 0.4829423427581787,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3395,
      "step": 227600
    },
    {
      "epoch": 9.258726899383984,
      "grad_norm": 0.5274266004562378,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.34,
      "step": 227700
    },
    {
      "epoch": 9.262793014414378,
      "grad_norm": 0.5095306038856506,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.34,
      "step": 227800
    },
    {
      "epoch": 9.266859129444772,
      "grad_norm": 0.5931822657585144,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.3413,
      "step": 227900
    },
    {
      "epoch": 9.270925244475166,
      "grad_norm": 0.49549153447151184,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3407,
      "step": 228000
    },
    {
      "epoch": 9.270925244475166,
      "eval_loss": 0.35768598318099976,
      "eval_runtime": 175.4271,
      "eval_samples_per_second": 997.007,
      "eval_steps_per_second": 31.158,
      "step": 228000
    },
    {
      "epoch": 9.27499135950556,
      "grad_norm": 0.47950664162635803,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.34,
      "step": 228100
    },
    {
      "epoch": 9.279057474535955,
      "grad_norm": 0.5631899237632751,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.3405,
      "step": 228200
    },
    {
      "epoch": 9.28312358956635,
      "grad_norm": 0.591254711151123,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3412,
      "step": 228300
    },
    {
      "epoch": 9.287189704596743,
      "grad_norm": 0.492341011762619,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3411,
      "step": 228400
    },
    {
      "epoch": 9.291255819627137,
      "grad_norm": 0.5752748847007751,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3422,
      "step": 228500
    },
    {
      "epoch": 9.295321934657531,
      "grad_norm": 0.5699339509010315,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.3422,
      "step": 228600
    },
    {
      "epoch": 9.299388049687925,
      "grad_norm": 0.4699257016181946,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.3411,
      "step": 228700
    },
    {
      "epoch": 9.30345416471832,
      "grad_norm": 0.5327040553092957,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3405,
      "step": 228800
    },
    {
      "epoch": 9.307520279748713,
      "grad_norm": 0.5163933634757996,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3409,
      "step": 228900
    },
    {
      "epoch": 9.311586394779109,
      "grad_norm": 0.5802011489868164,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3394,
      "step": 229000
    },
    {
      "epoch": 9.315652509809503,
      "grad_norm": 0.5477530360221863,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.3415,
      "step": 229100
    },
    {
      "epoch": 9.319718624839897,
      "grad_norm": 0.5427278280258179,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3403,
      "step": 229200
    },
    {
      "epoch": 9.323784739870291,
      "grad_norm": 0.5527195930480957,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3405,
      "step": 229300
    },
    {
      "epoch": 9.327850854900685,
      "grad_norm": 0.5234529972076416,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3397,
      "step": 229400
    },
    {
      "epoch": 9.331916969931079,
      "grad_norm": 0.5758467316627502,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3412,
      "step": 229500
    },
    {
      "epoch": 9.335983084961473,
      "grad_norm": 0.574126124382019,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.341,
      "step": 229600
    },
    {
      "epoch": 9.340049199991867,
      "grad_norm": 0.6230711936950684,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3401,
      "step": 229700
    },
    {
      "epoch": 9.344115315022261,
      "grad_norm": 0.5867433547973633,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3424,
      "step": 229800
    },
    {
      "epoch": 9.348181430052657,
      "grad_norm": 0.5489650964736938,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3412,
      "step": 229900
    },
    {
      "epoch": 9.352247545083051,
      "grad_norm": 0.5199025273323059,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.3406,
      "step": 230000
    },
    {
      "epoch": 9.352247545083051,
      "eval_loss": 0.35986441373825073,
      "eval_runtime": 177.91,
      "eval_samples_per_second": 983.092,
      "eval_steps_per_second": 30.723,
      "step": 230000
    },
    {
      "epoch": 9.356313660113445,
      "grad_norm": 0.5842835903167725,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.3413,
      "step": 230100
    },
    {
      "epoch": 9.360379775143839,
      "grad_norm": 0.5902110934257507,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.343,
      "step": 230200
    },
    {
      "epoch": 9.364445890174233,
      "grad_norm": 0.5480619072914124,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.3411,
      "step": 230300
    },
    {
      "epoch": 9.368512005204627,
      "grad_norm": 0.5120476484298706,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.3402,
      "step": 230400
    },
    {
      "epoch": 9.372578120235021,
      "grad_norm": 0.5708504915237427,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3405,
      "step": 230500
    },
    {
      "epoch": 9.376644235265415,
      "grad_norm": 0.5250758528709412,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3393,
      "step": 230600
    },
    {
      "epoch": 9.38071035029581,
      "grad_norm": 0.6109057664871216,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.3435,
      "step": 230700
    },
    {
      "epoch": 9.384776465326205,
      "grad_norm": 0.5878432989120483,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.342,
      "step": 230800
    },
    {
      "epoch": 9.388842580356599,
      "grad_norm": 0.5228235721588135,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.3397,
      "step": 230900
    },
    {
      "epoch": 9.392908695386993,
      "grad_norm": 0.6011304259300232,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.3396,
      "step": 231000
    },
    {
      "epoch": 9.396974810417387,
      "grad_norm": 0.47298499941825867,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3417,
      "step": 231100
    },
    {
      "epoch": 9.40104092544778,
      "grad_norm": 0.5269228219985962,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3395,
      "step": 231200
    },
    {
      "epoch": 9.405107040478175,
      "grad_norm": 0.5585724711418152,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3428,
      "step": 231300
    },
    {
      "epoch": 9.409173155508569,
      "grad_norm": 0.5348098278045654,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3435,
      "step": 231400
    },
    {
      "epoch": 9.413239270538963,
      "grad_norm": 0.5879834890365601,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3412,
      "step": 231500
    },
    {
      "epoch": 9.417305385569358,
      "grad_norm": 0.5301827788352966,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3413,
      "step": 231600
    },
    {
      "epoch": 9.421371500599752,
      "grad_norm": 0.5246706008911133,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.3409,
      "step": 231700
    },
    {
      "epoch": 9.425437615630146,
      "grad_norm": 0.565112829208374,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.3416,
      "step": 231800
    },
    {
      "epoch": 9.42950373066054,
      "grad_norm": 0.5759055614471436,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3406,
      "step": 231900
    },
    {
      "epoch": 9.433569845690934,
      "grad_norm": 0.5909526348114014,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.3414,
      "step": 232000
    },
    {
      "epoch": 9.433569845690934,
      "eval_loss": 0.3576495945453644,
      "eval_runtime": 176.2124,
      "eval_samples_per_second": 992.563,
      "eval_steps_per_second": 31.019,
      "step": 232000
    },
    {
      "epoch": 9.437635960721328,
      "grad_norm": 0.5145888328552246,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3416,
      "step": 232100
    },
    {
      "epoch": 9.441702075751722,
      "grad_norm": 0.5169333219528198,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3388,
      "step": 232200
    },
    {
      "epoch": 9.445768190782116,
      "grad_norm": 0.6487212181091309,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3415,
      "step": 232300
    },
    {
      "epoch": 9.449834305812512,
      "grad_norm": 0.5343571305274963,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.3392,
      "step": 232400
    },
    {
      "epoch": 9.453900420842906,
      "grad_norm": 0.5676660537719727,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.3401,
      "step": 232500
    },
    {
      "epoch": 9.4579665358733,
      "grad_norm": 0.5388279557228088,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3403,
      "step": 232600
    },
    {
      "epoch": 9.462032650903694,
      "grad_norm": 0.5126330852508545,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3395,
      "step": 232700
    },
    {
      "epoch": 9.466098765934088,
      "grad_norm": 0.4928448498249054,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.339,
      "step": 232800
    },
    {
      "epoch": 9.470164880964482,
      "grad_norm": 0.5496385097503662,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3409,
      "step": 232900
    },
    {
      "epoch": 9.474230995994876,
      "grad_norm": 0.5378733277320862,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3395,
      "step": 233000
    },
    {
      "epoch": 9.47829711102527,
      "grad_norm": 0.5994634628295898,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.3405,
      "step": 233100
    },
    {
      "epoch": 9.482363226055664,
      "grad_norm": 0.5227369070053101,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.3402,
      "step": 233200
    },
    {
      "epoch": 9.48642934108606,
      "grad_norm": 0.6002354025840759,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.34,
      "step": 233300
    },
    {
      "epoch": 9.490495456116454,
      "grad_norm": 0.5207005143165588,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3403,
      "step": 233400
    },
    {
      "epoch": 9.494561571146848,
      "grad_norm": 0.5356465578079224,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3398,
      "step": 233500
    },
    {
      "epoch": 9.498627686177242,
      "grad_norm": 0.5485942363739014,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3405,
      "step": 233600
    },
    {
      "epoch": 9.502693801207636,
      "grad_norm": 0.5413693189620972,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.34,
      "step": 233700
    },
    {
      "epoch": 9.50675991623803,
      "grad_norm": 0.6238476634025574,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3396,
      "step": 233800
    },
    {
      "epoch": 9.510826031268424,
      "grad_norm": 0.5645650029182434,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3411,
      "step": 233900
    },
    {
      "epoch": 9.514892146298818,
      "grad_norm": 0.576461672782898,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.339,
      "step": 234000
    },
    {
      "epoch": 9.514892146298818,
      "eval_loss": 0.3571878969669342,
      "eval_runtime": 175.7544,
      "eval_samples_per_second": 995.15,
      "eval_steps_per_second": 31.1,
      "step": 234000
    },
    {
      "epoch": 9.518958261329214,
      "grad_norm": 0.579674243927002,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.3388,
      "step": 234100
    },
    {
      "epoch": 9.523024376359608,
      "grad_norm": 0.5513972640037537,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.3406,
      "step": 234200
    },
    {
      "epoch": 9.527090491390002,
      "grad_norm": 0.5346689224243164,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3388,
      "step": 234300
    },
    {
      "epoch": 9.531156606420396,
      "grad_norm": 0.5584662556648254,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3397,
      "step": 234400
    },
    {
      "epoch": 9.53522272145079,
      "grad_norm": 0.4996408522129059,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3417,
      "step": 234500
    },
    {
      "epoch": 9.539288836481184,
      "grad_norm": 0.5688729286193848,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3424,
      "step": 234600
    },
    {
      "epoch": 9.543354951511578,
      "grad_norm": 0.669508159160614,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3411,
      "step": 234700
    },
    {
      "epoch": 9.547421066541972,
      "grad_norm": 0.5107696652412415,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.3367,
      "step": 234800
    },
    {
      "epoch": 9.551487181572366,
      "grad_norm": 0.5740365386009216,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.3426,
      "step": 234900
    },
    {
      "epoch": 9.555553296602762,
      "grad_norm": 0.5815560221672058,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.3394,
      "step": 235000
    },
    {
      "epoch": 9.559619411633156,
      "grad_norm": 0.6818611025810242,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3369,
      "step": 235100
    },
    {
      "epoch": 9.56368552666355,
      "grad_norm": 0.6345147490501404,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3389,
      "step": 235200
    },
    {
      "epoch": 9.567751641693944,
      "grad_norm": 0.6158398389816284,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3393,
      "step": 235300
    },
    {
      "epoch": 9.571817756724338,
      "grad_norm": 0.515329122543335,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3417,
      "step": 235400
    },
    {
      "epoch": 9.575883871754732,
      "grad_norm": 0.6250300407409668,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.3403,
      "step": 235500
    },
    {
      "epoch": 9.579949986785126,
      "grad_norm": 0.5294403433799744,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3404,
      "step": 235600
    },
    {
      "epoch": 9.58401610181552,
      "grad_norm": 0.6875442862510681,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.3414,
      "step": 235700
    },
    {
      "epoch": 9.588082216845915,
      "grad_norm": 0.5889889001846313,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.3421,
      "step": 235800
    },
    {
      "epoch": 9.59214833187631,
      "grad_norm": 0.5662277340888977,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.339,
      "step": 235900
    },
    {
      "epoch": 9.596214446906703,
      "grad_norm": 0.5990158915519714,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.3391,
      "step": 236000
    },
    {
      "epoch": 9.596214446906703,
      "eval_loss": 0.35593777894973755,
      "eval_runtime": 176.643,
      "eval_samples_per_second": 990.144,
      "eval_steps_per_second": 30.944,
      "step": 236000
    },
    {
      "epoch": 9.600280561937097,
      "grad_norm": 0.5886687636375427,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3406,
      "step": 236100
    },
    {
      "epoch": 9.604346676967491,
      "grad_norm": 0.5423166751861572,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3378,
      "step": 236200
    },
    {
      "epoch": 9.608412791997885,
      "grad_norm": 0.5559226870536804,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.339,
      "step": 236300
    },
    {
      "epoch": 9.61247890702828,
      "grad_norm": 0.6716707944869995,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3425,
      "step": 236400
    },
    {
      "epoch": 9.616545022058673,
      "grad_norm": 0.5998630523681641,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.3393,
      "step": 236500
    },
    {
      "epoch": 9.620611137089067,
      "grad_norm": 0.6384658217430115,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3391,
      "step": 236600
    },
    {
      "epoch": 9.624677252119463,
      "grad_norm": 0.48306652903556824,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3388,
      "step": 236700
    },
    {
      "epoch": 9.628743367149857,
      "grad_norm": 0.6559733748435974,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.3383,
      "step": 236800
    },
    {
      "epoch": 9.632809482180251,
      "grad_norm": 0.5715212225914001,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3383,
      "step": 236900
    },
    {
      "epoch": 9.636875597210645,
      "grad_norm": 0.6155053973197937,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.3403,
      "step": 237000
    },
    {
      "epoch": 9.64094171224104,
      "grad_norm": 0.6193813681602478,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3384,
      "step": 237100
    },
    {
      "epoch": 9.645007827271433,
      "grad_norm": 0.6734554767608643,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.3382,
      "step": 237200
    },
    {
      "epoch": 9.649073942301827,
      "grad_norm": 0.5775081515312195,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3395,
      "step": 237300
    },
    {
      "epoch": 9.653140057332221,
      "grad_norm": 0.511085569858551,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.3398,
      "step": 237400
    },
    {
      "epoch": 9.657206172362617,
      "grad_norm": 0.5918099284172058,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.3403,
      "step": 237500
    },
    {
      "epoch": 9.661272287393011,
      "grad_norm": 0.6499940752983093,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3409,
      "step": 237600
    },
    {
      "epoch": 9.665338402423405,
      "grad_norm": 0.5452268123626709,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.3406,
      "step": 237700
    },
    {
      "epoch": 9.669404517453799,
      "grad_norm": 0.5573933124542236,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.3405,
      "step": 237800
    },
    {
      "epoch": 9.673470632484193,
      "grad_norm": 0.6329991817474365,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3404,
      "step": 237900
    },
    {
      "epoch": 9.677536747514587,
      "grad_norm": 0.6986934542655945,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3388,
      "step": 238000
    },
    {
      "epoch": 9.677536747514587,
      "eval_loss": 0.35573065280914307,
      "eval_runtime": 176.2002,
      "eval_samples_per_second": 992.632,
      "eval_steps_per_second": 31.022,
      "step": 238000
    },
    {
      "epoch": 9.681602862544981,
      "grad_norm": 0.5950670838356018,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.3402,
      "step": 238100
    },
    {
      "epoch": 9.685668977575375,
      "grad_norm": 0.6183905601501465,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3382,
      "step": 238200
    },
    {
      "epoch": 9.689735092605769,
      "grad_norm": 0.6214443445205688,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3382,
      "step": 238300
    },
    {
      "epoch": 9.693801207636165,
      "grad_norm": 0.511603593826294,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.3394,
      "step": 238400
    },
    {
      "epoch": 9.697867322666559,
      "grad_norm": 0.5656466484069824,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3384,
      "step": 238500
    },
    {
      "epoch": 9.701933437696953,
      "grad_norm": 0.5675368309020996,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.3402,
      "step": 238600
    },
    {
      "epoch": 9.705999552727347,
      "grad_norm": 0.570831298828125,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3386,
      "step": 238700
    },
    {
      "epoch": 9.71006566775774,
      "grad_norm": 0.5896002650260925,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3386,
      "step": 238800
    },
    {
      "epoch": 9.714131782788135,
      "grad_norm": 0.5252227783203125,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3374,
      "step": 238900
    },
    {
      "epoch": 9.718197897818529,
      "grad_norm": 0.5496220588684082,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.3378,
      "step": 239000
    },
    {
      "epoch": 9.722264012848923,
      "grad_norm": 0.4906662702560425,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.3386,
      "step": 239100
    },
    {
      "epoch": 9.726330127879319,
      "grad_norm": 0.5692787766456604,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3373,
      "step": 239200
    },
    {
      "epoch": 9.730396242909713,
      "grad_norm": 0.7372103333473206,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3395,
      "step": 239300
    },
    {
      "epoch": 9.734462357940107,
      "grad_norm": 0.5959627628326416,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.339,
      "step": 239400
    },
    {
      "epoch": 9.7385284729705,
      "grad_norm": 0.5756567716598511,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3392,
      "step": 239500
    },
    {
      "epoch": 9.742594588000895,
      "grad_norm": 0.5615240335464478,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3398,
      "step": 239600
    },
    {
      "epoch": 9.746660703031289,
      "grad_norm": 0.6524375677108765,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3382,
      "step": 239700
    },
    {
      "epoch": 9.750726818061683,
      "grad_norm": 0.530045211315155,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3398,
      "step": 239800
    },
    {
      "epoch": 9.754792933092077,
      "grad_norm": 0.6956000328063965,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.3368,
      "step": 239900
    },
    {
      "epoch": 9.75885904812247,
      "grad_norm": 0.5980508327484131,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3388,
      "step": 240000
    },
    {
      "epoch": 9.75885904812247,
      "eval_loss": 0.3552040159702301,
      "eval_runtime": 179.1508,
      "eval_samples_per_second": 976.284,
      "eval_steps_per_second": 30.511,
      "step": 240000
    },
    {
      "epoch": 9.762925163152866,
      "grad_norm": 0.5127406716346741,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.3393,
      "step": 240100
    },
    {
      "epoch": 9.76699127818326,
      "grad_norm": 0.5158478617668152,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.3399,
      "step": 240200
    },
    {
      "epoch": 9.771057393213654,
      "grad_norm": 0.619898796081543,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.34,
      "step": 240300
    },
    {
      "epoch": 9.775123508244048,
      "grad_norm": 0.5738189816474915,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.3377,
      "step": 240400
    },
    {
      "epoch": 9.779189623274442,
      "grad_norm": 0.5755717754364014,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.3373,
      "step": 240500
    },
    {
      "epoch": 9.783255738304836,
      "grad_norm": 0.6190699934959412,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3384,
      "step": 240600
    },
    {
      "epoch": 9.78732185333523,
      "grad_norm": 0.6111100316047668,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3384,
      "step": 240700
    },
    {
      "epoch": 9.791387968365624,
      "grad_norm": 0.5872693061828613,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3387,
      "step": 240800
    },
    {
      "epoch": 9.79545408339602,
      "grad_norm": 0.6200760006904602,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.3376,
      "step": 240900
    },
    {
      "epoch": 9.799520198426414,
      "grad_norm": 0.6077477335929871,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3384,
      "step": 241000
    },
    {
      "epoch": 9.803586313456808,
      "grad_norm": 0.5562413334846497,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3393,
      "step": 241100
    },
    {
      "epoch": 9.807652428487202,
      "grad_norm": 0.5563671588897705,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3379,
      "step": 241200
    },
    {
      "epoch": 9.811718543517596,
      "grad_norm": 0.6184241771697998,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.3418,
      "step": 241300
    },
    {
      "epoch": 9.81578465854799,
      "grad_norm": 0.5991564989089966,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.3401,
      "step": 241400
    },
    {
      "epoch": 9.819850773578384,
      "grad_norm": 0.6042897701263428,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3377,
      "step": 241500
    },
    {
      "epoch": 9.823916888608778,
      "grad_norm": 0.556849479675293,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.3395,
      "step": 241600
    },
    {
      "epoch": 9.827983003639172,
      "grad_norm": 0.5288267135620117,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3377,
      "step": 241700
    },
    {
      "epoch": 9.832049118669568,
      "grad_norm": 0.5823928713798523,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3369,
      "step": 241800
    },
    {
      "epoch": 9.836115233699962,
      "grad_norm": 0.5559309124946594,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.3362,
      "step": 241900
    },
    {
      "epoch": 9.840181348730356,
      "grad_norm": 0.6159840226173401,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3359,
      "step": 242000
    },
    {
      "epoch": 9.840181348730356,
      "eval_loss": 0.3550792932510376,
      "eval_runtime": 176.0042,
      "eval_samples_per_second": 993.738,
      "eval_steps_per_second": 31.056,
      "step": 242000
    },
    {
      "epoch": 9.84424746376075,
      "grad_norm": 0.6385065913200378,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3369,
      "step": 242100
    },
    {
      "epoch": 9.848313578791144,
      "grad_norm": 0.6454667448997498,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3397,
      "step": 242200
    },
    {
      "epoch": 9.852379693821538,
      "grad_norm": 0.5493858456611633,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.3379,
      "step": 242300
    },
    {
      "epoch": 9.856445808851932,
      "grad_norm": 0.5052401423454285,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.3385,
      "step": 242400
    },
    {
      "epoch": 9.860511923882326,
      "grad_norm": 0.5727826356887817,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.3389,
      "step": 242500
    },
    {
      "epoch": 9.864578038912722,
      "grad_norm": 0.5709972977638245,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3386,
      "step": 242600
    },
    {
      "epoch": 9.868644153943116,
      "grad_norm": 0.6134854555130005,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3376,
      "step": 242700
    },
    {
      "epoch": 9.87271026897351,
      "grad_norm": 0.566681981086731,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3389,
      "step": 242800
    },
    {
      "epoch": 9.876776384003904,
      "grad_norm": 0.6365966796875,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.3374,
      "step": 242900
    },
    {
      "epoch": 9.880842499034298,
      "grad_norm": 0.5877270102500916,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3367,
      "step": 243000
    },
    {
      "epoch": 9.884908614064692,
      "grad_norm": 0.5654466152191162,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.3366,
      "step": 243100
    },
    {
      "epoch": 9.888974729095086,
      "grad_norm": 0.687704861164093,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.3378,
      "step": 243200
    },
    {
      "epoch": 9.89304084412548,
      "grad_norm": 0.5546140074729919,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3391,
      "step": 243300
    },
    {
      "epoch": 9.897106959155874,
      "grad_norm": 0.6049624681472778,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3375,
      "step": 243400
    },
    {
      "epoch": 9.901173074186268,
      "grad_norm": 0.6206561923027039,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.3375,
      "step": 243500
    },
    {
      "epoch": 9.905239189216664,
      "grad_norm": 0.5351167321205139,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.3375,
      "step": 243600
    },
    {
      "epoch": 9.909305304247058,
      "grad_norm": 0.5249307751655579,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3377,
      "step": 243700
    },
    {
      "epoch": 9.913371419277452,
      "grad_norm": 0.5534294247627258,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3373,
      "step": 243800
    },
    {
      "epoch": 9.917437534307846,
      "grad_norm": 0.7184047102928162,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3368,
      "step": 243900
    },
    {
      "epoch": 9.92150364933824,
      "grad_norm": 0.5966858267784119,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3354,
      "step": 244000
    },
    {
      "epoch": 9.92150364933824,
      "eval_loss": 0.3545917272567749,
      "eval_runtime": 176.3537,
      "eval_samples_per_second": 991.768,
      "eval_steps_per_second": 30.995,
      "step": 244000
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
