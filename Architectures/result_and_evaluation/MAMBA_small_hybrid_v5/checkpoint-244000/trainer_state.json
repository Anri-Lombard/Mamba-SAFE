{
  "best_metric": 0.4006349444389343,
  "best_model_checkpoint": "/scratch/lmbanr001/MAMBA_small_hybrid_v5/checkpoint-244000",
  "epoch": 9.921483318763087,
  "eval_steps": 2000,
  "global_step": 244000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 6.648299694061279,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.7243,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 7.187061786651611,
      "learning_rate": 2.5e-06,
      "loss": 7.46,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 5.149593830108643,
      "learning_rate": 5e-06,
      "loss": 5.7072,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 2.5548486709594727,
      "learning_rate": 7.5e-06,
      "loss": 3.329,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 1.5000848770141602,
      "learning_rate": 1e-05,
      "loss": 2.2303,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 1.0492773056030273,
      "learning_rate": 1.25e-05,
      "loss": 1.605,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 0.8974050879478455,
      "learning_rate": 1.5e-05,
      "loss": 1.2792,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 0.9203891158103943,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 1.1336,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 0.8747056722640991,
      "learning_rate": 2e-05,
      "loss": 1.0492,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 0.8571110367774963,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.9894,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 0.8811379075050354,
      "learning_rate": 2.5e-05,
      "loss": 0.9515,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 0.8697758913040161,
      "learning_rate": 2.75e-05,
      "loss": 0.9125,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 0.866915225982666,
      "learning_rate": 3e-05,
      "loss": 0.8799,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 0.8206590414047241,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.8528,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 0.9026392698287964,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.8224,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 0.862490177154541,
      "learning_rate": 3.75e-05,
      "loss": 0.8038,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 1.1185704469680786,
      "learning_rate": 4e-05,
      "loss": 0.7875,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 0.8854719400405884,
      "learning_rate": 4.25e-05,
      "loss": 0.7706,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 0.9242362976074219,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.7505,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 1.0068656206130981,
      "learning_rate": 4.75e-05,
      "loss": 0.7309,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 0.8626031279563904,
      "learning_rate": 5e-05,
      "loss": 0.7178,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.7162554264068604,
      "eval_runtime": 117.8056,
      "eval_samples_per_second": 1484.666,
      "eval_steps_per_second": 46.398,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 0.8844246864318848,
      "learning_rate": 5.25e-05,
      "loss": 0.7024,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 0.9854876399040222,
      "learning_rate": 5.5e-05,
      "loss": 0.6892,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 0.9321017265319824,
      "learning_rate": 5.75e-05,
      "loss": 0.6754,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 1.015744686126709,
      "learning_rate": 6e-05,
      "loss": 0.6708,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 0.9181295037269592,
      "learning_rate": 6.25e-05,
      "loss": 0.6591,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 0.8860442042350769,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.6501,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 0.9603210091590881,
      "learning_rate": 6.75e-05,
      "loss": 0.6383,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 0.8772632479667664,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.6352,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 0.9499489665031433,
      "learning_rate": 7.25e-05,
      "loss": 0.6259,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 0.9262073636054993,
      "learning_rate": 7.5e-05,
      "loss": 0.6205,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 0.8877493739128113,
      "learning_rate": 7.75e-05,
      "loss": 0.6151,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 0.8472123742103577,
      "learning_rate": 8e-05,
      "loss": 0.6081,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 0.8906165957450867,
      "learning_rate": 8.25e-05,
      "loss": 0.6006,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 0.9496507048606873,
      "learning_rate": 8.5e-05,
      "loss": 0.5931,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 0.8778951168060303,
      "learning_rate": 8.75e-05,
      "loss": 0.5945,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 0.7894253730773926,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.5847,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 0.7608239650726318,
      "learning_rate": 9.25e-05,
      "loss": 0.579,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 0.8906697034835815,
      "learning_rate": 9.5e-05,
      "loss": 0.5748,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 0.7956642508506775,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.5716,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 0.7557162642478943,
      "learning_rate": 0.0001,
      "loss": 0.566,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.603012204170227,
      "eval_runtime": 116.0869,
      "eval_samples_per_second": 1506.648,
      "eval_steps_per_second": 47.085,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 0.7884549498558044,
      "learning_rate": 0.0001025,
      "loss": 0.561,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 0.778335690498352,
      "learning_rate": 0.000105,
      "loss": 0.5593,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 0.8058322668075562,
      "learning_rate": 0.0001075,
      "loss": 0.5565,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 0.768696665763855,
      "learning_rate": 0.00011,
      "loss": 0.5539,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 0.7817416191101074,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.5522,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 0.7693118453025818,
      "learning_rate": 0.000115,
      "loss": 0.5451,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 0.7466491460800171,
      "learning_rate": 0.0001175,
      "loss": 0.5405,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 0.8047905564308167,
      "learning_rate": 0.00012,
      "loss": 0.5409,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 0.7496913075447083,
      "learning_rate": 0.0001225,
      "loss": 0.539,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.7105668783187866,
      "learning_rate": 0.000125,
      "loss": 0.5398,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 0.7145279049873352,
      "learning_rate": 0.0001275,
      "loss": 0.5336,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 0.8180571794509888,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.5298,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 0.7325477004051208,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.5273,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.6727519631385803,
      "learning_rate": 0.000135,
      "loss": 0.5249,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.686347484588623,
      "learning_rate": 0.0001375,
      "loss": 0.5265,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.6832918524742126,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.5237,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.6487113833427429,
      "learning_rate": 0.0001425,
      "loss": 0.5234,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.6288950443267822,
      "learning_rate": 0.000145,
      "loss": 0.5228,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.6819550395011902,
      "learning_rate": 0.0001475,
      "loss": 0.5161,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.658378541469574,
      "learning_rate": 0.00015,
      "loss": 0.5163,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.5691545009613037,
      "eval_runtime": 115.7829,
      "eval_samples_per_second": 1510.603,
      "eval_steps_per_second": 47.209,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 0.7012491226196289,
      "learning_rate": 0.0001525,
      "loss": 0.5143,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.6394129991531372,
      "learning_rate": 0.000155,
      "loss": 0.5146,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.6244602203369141,
      "learning_rate": 0.0001575,
      "loss": 0.5107,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 0.6728499531745911,
      "learning_rate": 0.00016,
      "loss": 0.511,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.6092978119850159,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.5109,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.5671720504760742,
      "learning_rate": 0.000165,
      "loss": 0.5112,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.5900999307632446,
      "learning_rate": 0.0001675,
      "loss": 0.5042,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.6045922040939331,
      "learning_rate": 0.00017,
      "loss": 0.5042,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.5938379168510437,
      "learning_rate": 0.0001725,
      "loss": 0.5011,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.5608240962028503,
      "learning_rate": 0.000175,
      "loss": 0.5014,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.5257234573364258,
      "learning_rate": 0.0001775,
      "loss": 0.501,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.5404513478279114,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.5007,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6293803453445435,
      "learning_rate": 0.0001825,
      "loss": 0.4975,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.5719749331474304,
      "learning_rate": 0.000185,
      "loss": 0.4981,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.540571928024292,
      "learning_rate": 0.0001875,
      "loss": 0.4949,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.566013514995575,
      "learning_rate": 0.00019,
      "loss": 0.4944,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.5484259724617004,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4918,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.5204970836639404,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.4922,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.5422401428222656,
      "learning_rate": 0.0001975,
      "loss": 0.4918,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.5468020439147949,
      "learning_rate": 0.0002,
      "loss": 0.4921,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.5663769245147705,
      "eval_runtime": 117.3001,
      "eval_samples_per_second": 1491.065,
      "eval_steps_per_second": 46.598,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.5771986842155457,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4919,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.504027783870697,
      "learning_rate": 0.000205,
      "loss": 0.4917,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.5461302399635315,
      "learning_rate": 0.0002075,
      "loss": 0.4869,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.5075660347938538,
      "learning_rate": 0.00021,
      "loss": 0.4875,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.538486897945404,
      "learning_rate": 0.0002125,
      "loss": 0.4844,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.5263410210609436,
      "learning_rate": 0.000215,
      "loss": 0.4833,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.5630006194114685,
      "learning_rate": 0.0002175,
      "loss": 0.4835,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.5052092671394348,
      "learning_rate": 0.00022,
      "loss": 0.4824,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.4854602515697479,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4802,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.5085421204566956,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.479,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.4907592833042145,
      "learning_rate": 0.0002275,
      "loss": 0.4818,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.4496403634548187,
      "learning_rate": 0.00023,
      "loss": 0.4802,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.44514521956443787,
      "learning_rate": 0.0002325,
      "loss": 0.4795,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.471487820148468,
      "learning_rate": 0.000235,
      "loss": 0.4783,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.4202428162097931,
      "learning_rate": 0.0002375,
      "loss": 0.4744,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.4495793879032135,
      "learning_rate": 0.00024,
      "loss": 0.4765,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.4639137089252472,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4732,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.45121848583221436,
      "learning_rate": 0.000245,
      "loss": 0.4731,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.4245070815086365,
      "learning_rate": 0.0002475,
      "loss": 0.4772,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.43321338295936584,
      "learning_rate": 0.00025,
      "loss": 0.4745,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.5625048279762268,
      "eval_runtime": 116.9039,
      "eval_samples_per_second": 1496.118,
      "eval_steps_per_second": 46.756,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.4366503059864044,
      "learning_rate": 0.0002525,
      "loss": 0.4736,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.42306819558143616,
      "learning_rate": 0.000255,
      "loss": 0.4754,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.44180208444595337,
      "learning_rate": 0.0002575,
      "loss": 0.474,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.4079338312149048,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4705,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.414730429649353,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4703,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.42741888761520386,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4706,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.43074360489845276,
      "learning_rate": 0.0002675,
      "loss": 0.4707,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.3865162432193756,
      "learning_rate": 0.00027,
      "loss": 0.4687,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.3878847062587738,
      "learning_rate": 0.0002725,
      "loss": 0.4685,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.4450129568576813,
      "learning_rate": 0.000275,
      "loss": 0.4686,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.4150707721710205,
      "learning_rate": 0.0002775,
      "loss": 0.4652,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.36810675263404846,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4702,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.41063952445983887,
      "learning_rate": 0.0002825,
      "loss": 0.468,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.38039204478263855,
      "learning_rate": 0.000285,
      "loss": 0.4654,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.40097102522850037,
      "learning_rate": 0.0002875,
      "loss": 0.4656,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.35915035009384155,
      "learning_rate": 0.00029,
      "loss": 0.4622,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.4302135109901428,
      "learning_rate": 0.0002925,
      "loss": 0.4622,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.4295339584350586,
      "learning_rate": 0.000295,
      "loss": 0.462,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.3769051432609558,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4614,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.3756481409072876,
      "learning_rate": 0.0003,
      "loss": 0.4609,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.5619151592254639,
      "eval_runtime": 116.5949,
      "eval_samples_per_second": 1500.083,
      "eval_steps_per_second": 46.88,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.36690250039100647,
      "learning_rate": 0.0003025,
      "loss": 0.4616,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.3337150812149048,
      "learning_rate": 0.000305,
      "loss": 0.4579,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.3701806366443634,
      "learning_rate": 0.0003075,
      "loss": 0.4612,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.3293773829936981,
      "learning_rate": 0.00031,
      "loss": 0.4606,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.37586042284965515,
      "learning_rate": 0.0003125,
      "loss": 0.4607,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.3601223826408386,
      "learning_rate": 0.000315,
      "loss": 0.4597,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.35526323318481445,
      "learning_rate": 0.0003175,
      "loss": 0.4575,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.3695663809776306,
      "learning_rate": 0.00032,
      "loss": 0.4593,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.3530036509037018,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4597,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.32512781023979187,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4586,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.3495703637599945,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4584,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.3683543801307678,
      "learning_rate": 0.00033,
      "loss": 0.457,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.33667466044425964,
      "learning_rate": 0.0003325,
      "loss": 0.4553,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.35135918855667114,
      "learning_rate": 0.000335,
      "loss": 0.457,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.38514643907546997,
      "learning_rate": 0.0003375,
      "loss": 0.4542,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.3499225974082947,
      "learning_rate": 0.00034,
      "loss": 0.4538,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.33248037099838257,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.4565,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.3400520086288452,
      "learning_rate": 0.000345,
      "loss": 0.4551,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.33822348713874817,
      "learning_rate": 0.0003475,
      "loss": 0.4554,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.32280707359313965,
      "learning_rate": 0.00035,
      "loss": 0.4564,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.5645858645439148,
      "eval_runtime": 116.3408,
      "eval_samples_per_second": 1503.36,
      "eval_steps_per_second": 46.983,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.3348741829395294,
      "learning_rate": 0.0003525,
      "loss": 0.456,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.33182963728904724,
      "learning_rate": 0.000355,
      "loss": 0.4557,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.29533281922340393,
      "learning_rate": 0.0003575,
      "loss": 0.4547,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.3107776939868927,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4541,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.34090983867645264,
      "learning_rate": 0.0003625,
      "loss": 0.4534,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.3243291676044464,
      "learning_rate": 0.000365,
      "loss": 0.4535,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.3280371129512787,
      "learning_rate": 0.0003675,
      "loss": 0.4544,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.3484269380569458,
      "learning_rate": 0.00037,
      "loss": 0.4503,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.29424092173576355,
      "learning_rate": 0.0003725,
      "loss": 0.4499,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.2980213761329651,
      "learning_rate": 0.000375,
      "loss": 0.4515,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.33323419094085693,
      "learning_rate": 0.0003775,
      "loss": 0.45,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.31338372826576233,
      "learning_rate": 0.00038,
      "loss": 0.4502,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.3060026466846466,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.452,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.32632264494895935,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4473,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.314433217048645,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4481,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.3069707155227661,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4471,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.3713074028491974,
      "learning_rate": 0.0003925,
      "loss": 0.4465,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.2965793013572693,
      "learning_rate": 0.000395,
      "loss": 0.4494,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.2996373176574707,
      "learning_rate": 0.0003975,
      "loss": 0.4482,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.3303757607936859,
      "learning_rate": 0.0004,
      "loss": 0.4478,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.517291784286499,
      "eval_runtime": 116.0717,
      "eval_samples_per_second": 1506.845,
      "eval_steps_per_second": 47.092,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.2934027314186096,
      "learning_rate": 0.0004025,
      "loss": 0.4497,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.28898999094963074,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4482,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.2975221872329712,
      "learning_rate": 0.0004075,
      "loss": 0.4503,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.2983630299568176,
      "learning_rate": 0.00041,
      "loss": 0.4464,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.2780956029891968,
      "learning_rate": 0.0004125,
      "loss": 0.4482,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.28252285718917847,
      "learning_rate": 0.000415,
      "loss": 0.447,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.2911960482597351,
      "learning_rate": 0.0004175,
      "loss": 0.447,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.283329576253891,
      "learning_rate": 0.00042,
      "loss": 0.4469,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.24934999644756317,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4469,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.31126704812049866,
      "learning_rate": 0.000425,
      "loss": 0.4452,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.2681165337562561,
      "learning_rate": 0.0004275,
      "loss": 0.4475,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.28770601749420166,
      "learning_rate": 0.00043,
      "loss": 0.4473,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.29153022170066833,
      "learning_rate": 0.0004325,
      "loss": 0.446,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.2861917316913605,
      "learning_rate": 0.000435,
      "loss": 0.4458,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.2700251042842865,
      "learning_rate": 0.0004375,
      "loss": 0.4428,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.280246764421463,
      "learning_rate": 0.00044,
      "loss": 0.4459,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.28011152148246765,
      "learning_rate": 0.0004425,
      "loss": 0.4425,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.27020078897476196,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4464,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.2909884452819824,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4435,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.2706397473812103,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4431,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.5257366299629211,
      "eval_runtime": 117.3303,
      "eval_samples_per_second": 1490.681,
      "eval_steps_per_second": 46.586,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.2938229739665985,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4406,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.263924241065979,
      "learning_rate": 0.000455,
      "loss": 0.4437,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.24900399148464203,
      "learning_rate": 0.0004575,
      "loss": 0.4427,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.2563669979572296,
      "learning_rate": 0.00046,
      "loss": 0.4434,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.2210289090871811,
      "learning_rate": 0.0004625,
      "loss": 0.4407,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.2584390938282013,
      "learning_rate": 0.000465,
      "loss": 0.4407,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.246989443898201,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4437,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.24783720076084137,
      "learning_rate": 0.00047,
      "loss": 0.4418,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.25241997838020325,
      "learning_rate": 0.0004725,
      "loss": 0.4414,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.24875901639461517,
      "learning_rate": 0.000475,
      "loss": 0.4389,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.2405153065919876,
      "learning_rate": 0.0004775,
      "loss": 0.4412,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.3175632953643799,
      "learning_rate": 0.00048,
      "loss": 0.4409,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.26456958055496216,
      "learning_rate": 0.0004825,
      "loss": 0.4437,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.24949023127555847,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.441,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.24400973320007324,
      "learning_rate": 0.0004875,
      "loss": 0.4386,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.2681307792663574,
      "learning_rate": 0.00049,
      "loss": 0.44,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.2726179361343384,
      "learning_rate": 0.0004925,
      "loss": 0.4375,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.24627171456813812,
      "learning_rate": 0.000495,
      "loss": 0.4396,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.2479817420244217,
      "learning_rate": 0.0004975,
      "loss": 0.44,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.25813135504722595,
      "learning_rate": 0.0005,
      "loss": 0.4406,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.5336812138557434,
      "eval_runtime": 116.3715,
      "eval_samples_per_second": 1502.963,
      "eval_steps_per_second": 46.97,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.2270563393831253,
      "learning_rate": 0.0004997786925153809,
      "loss": 0.4404,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.22832977771759033,
      "learning_rate": 0.0004995573850307618,
      "loss": 0.4406,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.2352728247642517,
      "learning_rate": 0.0004993360775461426,
      "loss": 0.4358,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.214106023311615,
      "learning_rate": 0.0004991147700615235,
      "loss": 0.4383,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.23737414181232452,
      "learning_rate": 0.0004988934625769043,
      "loss": 0.4372,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.2422059029340744,
      "learning_rate": 0.0004986721550922853,
      "loss": 0.4375,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.22657932341098785,
      "learning_rate": 0.0004984508476076661,
      "loss": 0.4387,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.22282657027244568,
      "learning_rate": 0.000498229540123047,
      "loss": 0.4392,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.2298659235239029,
      "learning_rate": 0.0004980082326384278,
      "loss": 0.4378,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.2093954086303711,
      "learning_rate": 0.0004977869251538087,
      "loss": 0.4357,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.2388942688703537,
      "learning_rate": 0.0004975656176691896,
      "loss": 0.4363,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.23317761719226837,
      "learning_rate": 0.0004973443101845705,
      "loss": 0.4345,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.23008643090724945,
      "learning_rate": 0.0004971230026999513,
      "loss": 0.4347,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.23498126864433289,
      "learning_rate": 0.0004969016952153321,
      "loss": 0.4371,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.25228625535964966,
      "learning_rate": 0.0004966803877307131,
      "loss": 0.4344,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.22827547788619995,
      "learning_rate": 0.0004964590802460939,
      "loss": 0.4347,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.2167341262102127,
      "learning_rate": 0.0004962377727614748,
      "loss": 0.4349,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.22475235164165497,
      "learning_rate": 0.0004960164652768557,
      "loss": 0.4326,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.2394157499074936,
      "learning_rate": 0.0004957951577922366,
      "loss": 0.4334,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.2335519641637802,
      "learning_rate": 0.0004955738503076174,
      "loss": 0.4332,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.5186643600463867,
      "eval_runtime": 115.2456,
      "eval_samples_per_second": 1517.646,
      "eval_steps_per_second": 47.429,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.2247656285762787,
      "learning_rate": 0.0004953525428229983,
      "loss": 0.4326,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.2345740795135498,
      "learning_rate": 0.0004951312353383792,
      "loss": 0.4357,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.2169950008392334,
      "learning_rate": 0.00049490992785376,
      "loss": 0.4325,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.23627135157585144,
      "learning_rate": 0.0004946886203691409,
      "loss": 0.4323,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.20908638834953308,
      "learning_rate": 0.0004944673128845217,
      "loss": 0.4359,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.22583654522895813,
      "learning_rate": 0.0004942460053999026,
      "loss": 0.4326,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.1987469494342804,
      "learning_rate": 0.0004940246979152835,
      "loss": 0.4319,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.2226099669933319,
      "learning_rate": 0.0004938033904306644,
      "loss": 0.4326,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.22687700390815735,
      "learning_rate": 0.0004935820829460452,
      "loss": 0.4313,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.2139730304479599,
      "learning_rate": 0.0004933607754614261,
      "loss": 0.4306,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.20685148239135742,
      "learning_rate": 0.000493139467976807,
      "loss": 0.4295,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.21969200670719147,
      "learning_rate": 0.0004929181604921879,
      "loss": 0.4329,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.22019410133361816,
      "learning_rate": 0.0004926968530075687,
      "loss": 0.4325,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.21324209868907928,
      "learning_rate": 0.0004924755455229495,
      "loss": 0.4293,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.20246896147727966,
      "learning_rate": 0.0004922542380383305,
      "loss": 0.4305,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.2185569554567337,
      "learning_rate": 0.0004920329305537113,
      "loss": 0.4285,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.21322093904018402,
      "learning_rate": 0.0004918116230690922,
      "loss": 0.432,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.21830891072750092,
      "learning_rate": 0.0004915903155844731,
      "loss": 0.4311,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.22211898863315582,
      "learning_rate": 0.000491369008099854,
      "loss": 0.4291,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.2132042497396469,
      "learning_rate": 0.0004911477006152348,
      "loss": 0.4287,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.5066636204719543,
      "eval_runtime": 113.8375,
      "eval_samples_per_second": 1536.419,
      "eval_steps_per_second": 48.016,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.20799531042575836,
      "learning_rate": 0.0004909263931306157,
      "loss": 0.4308,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.21297697722911835,
      "learning_rate": 0.0004907050856459966,
      "loss": 0.4287,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.20183277130126953,
      "learning_rate": 0.0004904837781613775,
      "loss": 0.4306,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.2176464945077896,
      "learning_rate": 0.0004902624706767583,
      "loss": 0.4279,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.19442857801914215,
      "learning_rate": 0.0004900411631921391,
      "loss": 0.4294,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.22381189465522766,
      "learning_rate": 0.00048981985570752,
      "loss": 0.4262,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.20639482140541077,
      "learning_rate": 0.0004895985482229009,
      "loss": 0.4267,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.23004984855651855,
      "learning_rate": 0.0004893772407382818,
      "loss": 0.4303,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.21127398312091827,
      "learning_rate": 0.0004891559332536626,
      "loss": 0.4264,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.21079003810882568,
      "learning_rate": 0.0004889346257690435,
      "loss": 0.43,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.22427143156528473,
      "learning_rate": 0.0004887133182844244,
      "loss": 0.4259,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.1944534331560135,
      "learning_rate": 0.0004884920107998053,
      "loss": 0.4312,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.21248772740364075,
      "learning_rate": 0.00048827070331518616,
      "loss": 0.4274,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.22808541357517242,
      "learning_rate": 0.000488049395830567,
      "loss": 0.4274,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.211823970079422,
      "learning_rate": 0.0004878280883459479,
      "loss": 0.4281,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.1997738927602768,
      "learning_rate": 0.00048760678086132874,
      "loss": 0.4287,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.1997644156217575,
      "learning_rate": 0.00048738547337670964,
      "loss": 0.4267,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.18318761885166168,
      "learning_rate": 0.0004871641658920905,
      "loss": 0.4237,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.22012756764888763,
      "learning_rate": 0.0004869428584074714,
      "loss": 0.427,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.19096128642559052,
      "learning_rate": 0.00048672155092285217,
      "loss": 0.4259,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.4912418723106384,
      "eval_runtime": 114.0819,
      "eval_samples_per_second": 1533.127,
      "eval_steps_per_second": 47.913,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.182876318693161,
      "learning_rate": 0.00048650024343823307,
      "loss": 0.4259,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.1973588764667511,
      "learning_rate": 0.00048627893595361396,
      "loss": 0.4261,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.1926240622997284,
      "learning_rate": 0.0004860576284689948,
      "loss": 0.4255,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.21514910459518433,
      "learning_rate": 0.0004858363209843757,
      "loss": 0.4258,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.19832777976989746,
      "learning_rate": 0.00048561501349975655,
      "loss": 0.4238,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.19369089603424072,
      "learning_rate": 0.00048539370601513744,
      "loss": 0.4236,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.2078576385974884,
      "learning_rate": 0.0004851723985305183,
      "loss": 0.4249,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.17853562533855438,
      "learning_rate": 0.0004849510910458992,
      "loss": 0.4228,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.1858651340007782,
      "learning_rate": 0.0004847297835612801,
      "loss": 0.425,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.19810311496257782,
      "learning_rate": 0.0004845084760766609,
      "loss": 0.4242,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.19430610537528992,
      "learning_rate": 0.0004842871685920418,
      "loss": 0.425,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.18673446774482727,
      "learning_rate": 0.00048406586110742267,
      "loss": 0.4243,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.18472951650619507,
      "learning_rate": 0.00048384455362280356,
      "loss": 0.4267,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.2007882446050644,
      "learning_rate": 0.0004836232461381844,
      "loss": 0.4222,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.19441765546798706,
      "learning_rate": 0.0004834019386535653,
      "loss": 0.4209,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.20907536149024963,
      "learning_rate": 0.0004831806311689461,
      "loss": 0.4227,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.18542170524597168,
      "learning_rate": 0.000482959323684327,
      "loss": 0.4236,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.18599316477775574,
      "learning_rate": 0.0004827380161997079,
      "loss": 0.4261,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.2044823169708252,
      "learning_rate": 0.00048251670871508873,
      "loss": 0.4228,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.17706483602523804,
      "learning_rate": 0.00048229540123046963,
      "loss": 0.424,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.4926212728023529,
      "eval_runtime": 113.723,
      "eval_samples_per_second": 1537.965,
      "eval_steps_per_second": 48.064,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.20589084923267365,
      "learning_rate": 0.00048207409374585047,
      "loss": 0.4228,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.19177189469337463,
      "learning_rate": 0.00048185278626123137,
      "loss": 0.4227,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.19351474940776825,
      "learning_rate": 0.0004816314787766122,
      "loss": 0.4206,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.18106846511363983,
      "learning_rate": 0.0004814101712919931,
      "loss": 0.4233,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.19397799670696259,
      "learning_rate": 0.00048118886380737395,
      "loss": 0.4208,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.18231692910194397,
      "learning_rate": 0.00048096755632275485,
      "loss": 0.4242,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.184158593416214,
      "learning_rate": 0.00048074624883813575,
      "loss": 0.4208,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.2005988359451294,
      "learning_rate": 0.0004805249413535166,
      "loss": 0.4218,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.17632173001766205,
      "learning_rate": 0.0004803036338688975,
      "loss": 0.4237,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.1918221414089203,
      "learning_rate": 0.00048008232638427833,
      "loss": 0.4229,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.21225833892822266,
      "learning_rate": 0.00047986101889965923,
      "loss": 0.4244,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.18133167922496796,
      "learning_rate": 0.00047963971141504007,
      "loss": 0.4206,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.1829236000776291,
      "learning_rate": 0.0004794184039304209,
      "loss": 0.4222,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.18250735104084015,
      "learning_rate": 0.00047919709644580176,
      "loss": 0.4212,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.20000477135181427,
      "learning_rate": 0.00047897578896118265,
      "loss": 0.423,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.17472587525844574,
      "learning_rate": 0.00047875448147656355,
      "loss": 0.4212,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.178742453455925,
      "learning_rate": 0.0004785331739919444,
      "loss": 0.42,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.1976068913936615,
      "learning_rate": 0.0004783118665073253,
      "loss": 0.4216,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.19339267909526825,
      "learning_rate": 0.00047809055902270614,
      "loss": 0.4218,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.17484915256500244,
      "learning_rate": 0.00047786925153808703,
      "loss": 0.4193,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.48805496096611023,
      "eval_runtime": 114.0053,
      "eval_samples_per_second": 1534.157,
      "eval_steps_per_second": 47.945,
      "step": 30000
    },
    {
      "epoch": 1.2239006241486572,
      "grad_norm": 0.19689129292964935,
      "learning_rate": 0.0004776479440534679,
      "loss": 0.4204,
      "step": 30100
    },
    {
      "epoch": 1.2279667391790514,
      "grad_norm": 0.18576563894748688,
      "learning_rate": 0.0004774266365688488,
      "loss": 0.4197,
      "step": 30200
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.19491258263587952,
      "learning_rate": 0.00047720532908422967,
      "loss": 0.4185,
      "step": 30300
    },
    {
      "epoch": 1.2360989692398399,
      "grad_norm": 0.16808368265628815,
      "learning_rate": 0.0004769840215996105,
      "loss": 0.4227,
      "step": 30400
    },
    {
      "epoch": 1.240165084270234,
      "grad_norm": 0.18995808064937592,
      "learning_rate": 0.0004767627141149914,
      "loss": 0.4199,
      "step": 30500
    },
    {
      "epoch": 1.2442311993006283,
      "grad_norm": 0.19082197546958923,
      "learning_rate": 0.00047654140663037225,
      "loss": 0.4192,
      "step": 30600
    },
    {
      "epoch": 1.2482973143310225,
      "grad_norm": 0.1798078566789627,
      "learning_rate": 0.00047632009914575315,
      "loss": 0.4179,
      "step": 30700
    },
    {
      "epoch": 1.2523634293614165,
      "grad_norm": 0.1877773106098175,
      "learning_rate": 0.000476098791661134,
      "loss": 0.4231,
      "step": 30800
    },
    {
      "epoch": 1.256429544391811,
      "grad_norm": 0.18309947848320007,
      "learning_rate": 0.0004758774841765149,
      "loss": 0.4211,
      "step": 30900
    },
    {
      "epoch": 1.260495659422205,
      "grad_norm": 0.17904874682426453,
      "learning_rate": 0.0004756561766918957,
      "loss": 0.4181,
      "step": 31000
    },
    {
      "epoch": 1.2645617744525992,
      "grad_norm": 0.16806288063526154,
      "learning_rate": 0.0004754348692072766,
      "loss": 0.4194,
      "step": 31100
    },
    {
      "epoch": 1.2686278894829934,
      "grad_norm": 0.19538480043411255,
      "learning_rate": 0.0004752135617226575,
      "loss": 0.419,
      "step": 31200
    },
    {
      "epoch": 1.2726940045133877,
      "grad_norm": 0.18942782282829285,
      "learning_rate": 0.0004749922542380383,
      "loss": 0.4175,
      "step": 31300
    },
    {
      "epoch": 1.2767601195437819,
      "grad_norm": 0.1794613003730774,
      "learning_rate": 0.0004747709467534192,
      "loss": 0.4214,
      "step": 31400
    },
    {
      "epoch": 1.280826234574176,
      "grad_norm": 0.1759817898273468,
      "learning_rate": 0.00047454963926880006,
      "loss": 0.4162,
      "step": 31500
    },
    {
      "epoch": 1.2848923496045703,
      "grad_norm": 0.1785297989845276,
      "learning_rate": 0.00047432833178418096,
      "loss": 0.4183,
      "step": 31600
    },
    {
      "epoch": 1.2889584646349646,
      "grad_norm": 0.1783282458782196,
      "learning_rate": 0.0004741070242995618,
      "loss": 0.4179,
      "step": 31700
    },
    {
      "epoch": 1.2930245796653588,
      "grad_norm": 0.18255029618740082,
      "learning_rate": 0.0004738857168149427,
      "loss": 0.4156,
      "step": 31800
    },
    {
      "epoch": 1.297090694695753,
      "grad_norm": 0.20226337015628815,
      "learning_rate": 0.00047366440933032354,
      "loss": 0.4204,
      "step": 31900
    },
    {
      "epoch": 1.3011568097261472,
      "grad_norm": 0.1784653514623642,
      "learning_rate": 0.00047344310184570444,
      "loss": 0.4189,
      "step": 32000
    },
    {
      "epoch": 1.3011568097261472,
      "eval_loss": 0.48155778646469116,
      "eval_runtime": 113.7922,
      "eval_samples_per_second": 1537.029,
      "eval_steps_per_second": 48.035,
      "step": 32000
    },
    {
      "epoch": 1.3052229247565412,
      "grad_norm": 0.1728534996509552,
      "learning_rate": 0.00047322179436108533,
      "loss": 0.4178,
      "step": 32100
    },
    {
      "epoch": 1.3092890397869357,
      "grad_norm": 0.18046227097511292,
      "learning_rate": 0.0004730004868764662,
      "loss": 0.4169,
      "step": 32200
    },
    {
      "epoch": 1.3133551548173297,
      "grad_norm": 0.18280324339866638,
      "learning_rate": 0.0004727791793918471,
      "loss": 0.4204,
      "step": 32300
    },
    {
      "epoch": 1.3174212698477241,
      "grad_norm": 0.1878003627061844,
      "learning_rate": 0.0004725578719072279,
      "loss": 0.4185,
      "step": 32400
    },
    {
      "epoch": 1.3214873848781181,
      "grad_norm": 0.18027950823307037,
      "learning_rate": 0.0004723365644226088,
      "loss": 0.4158,
      "step": 32500
    },
    {
      "epoch": 1.3255534999085123,
      "grad_norm": 0.18271410465240479,
      "learning_rate": 0.00047211525693798966,
      "loss": 0.4169,
      "step": 32600
    },
    {
      "epoch": 1.3296196149389066,
      "grad_norm": 0.18401940166950226,
      "learning_rate": 0.0004718939494533705,
      "loss": 0.4175,
      "step": 32700
    },
    {
      "epoch": 1.3336857299693008,
      "grad_norm": 0.19410870969295502,
      "learning_rate": 0.00047167264196875134,
      "loss": 0.417,
      "step": 32800
    },
    {
      "epoch": 1.337751844999695,
      "grad_norm": 0.19827929139137268,
      "learning_rate": 0.00047145133448413224,
      "loss": 0.4173,
      "step": 32900
    },
    {
      "epoch": 1.3418179600300892,
      "grad_norm": 0.20867396891117096,
      "learning_rate": 0.00047123002699951314,
      "loss": 0.4192,
      "step": 33000
    },
    {
      "epoch": 1.3458840750604835,
      "grad_norm": 0.20374862849712372,
      "learning_rate": 0.000471008719514894,
      "loss": 0.418,
      "step": 33100
    },
    {
      "epoch": 1.3499501900908777,
      "grad_norm": 0.1708553433418274,
      "learning_rate": 0.0004707874120302749,
      "loss": 0.4211,
      "step": 33200
    },
    {
      "epoch": 1.354016305121272,
      "grad_norm": 0.18388181924819946,
      "learning_rate": 0.0004705661045456557,
      "loss": 0.4154,
      "step": 33300
    },
    {
      "epoch": 1.3580824201516661,
      "grad_norm": 0.19565318524837494,
      "learning_rate": 0.0004703447970610366,
      "loss": 0.4187,
      "step": 33400
    },
    {
      "epoch": 1.3621485351820604,
      "grad_norm": 0.18209555745124817,
      "learning_rate": 0.00047012348957641746,
      "loss": 0.4147,
      "step": 33500
    },
    {
      "epoch": 1.3662146502124546,
      "grad_norm": 0.1949210911989212,
      "learning_rate": 0.00046990218209179836,
      "loss": 0.42,
      "step": 33600
    },
    {
      "epoch": 1.3702807652428488,
      "grad_norm": 0.18083259463310242,
      "learning_rate": 0.00046968087460717926,
      "loss": 0.4158,
      "step": 33700
    },
    {
      "epoch": 1.3743468802732428,
      "grad_norm": 0.2040509581565857,
      "learning_rate": 0.0004694595671225601,
      "loss": 0.417,
      "step": 33800
    },
    {
      "epoch": 1.3784129953036373,
      "grad_norm": 0.19734236598014832,
      "learning_rate": 0.000469238259637941,
      "loss": 0.4151,
      "step": 33900
    },
    {
      "epoch": 1.3824791103340313,
      "grad_norm": 0.1770646870136261,
      "learning_rate": 0.00046901695215332184,
      "loss": 0.417,
      "step": 34000
    },
    {
      "epoch": 1.3824791103340313,
      "eval_loss": 0.4873586893081665,
      "eval_runtime": 113.7825,
      "eval_samples_per_second": 1537.161,
      "eval_steps_per_second": 48.039,
      "step": 34000
    },
    {
      "epoch": 1.3865452253644255,
      "grad_norm": 0.19198957085609436,
      "learning_rate": 0.00046879564466870274,
      "loss": 0.4161,
      "step": 34100
    },
    {
      "epoch": 1.3906113403948197,
      "grad_norm": 0.18618299067020416,
      "learning_rate": 0.0004685743371840836,
      "loss": 0.4149,
      "step": 34200
    },
    {
      "epoch": 1.394677455425214,
      "grad_norm": 0.17860567569732666,
      "learning_rate": 0.0004683530296994645,
      "loss": 0.4177,
      "step": 34300
    },
    {
      "epoch": 1.3987435704556082,
      "grad_norm": 0.18826648592948914,
      "learning_rate": 0.00046813172221484527,
      "loss": 0.4172,
      "step": 34400
    },
    {
      "epoch": 1.4028096854860024,
      "grad_norm": 0.1833271086215973,
      "learning_rate": 0.00046791041473022617,
      "loss": 0.4163,
      "step": 34500
    },
    {
      "epoch": 1.4068758005163966,
      "grad_norm": 0.17486049234867096,
      "learning_rate": 0.00046768910724560706,
      "loss": 0.4137,
      "step": 34600
    },
    {
      "epoch": 1.4109419155467908,
      "grad_norm": 0.17895196378231049,
      "learning_rate": 0.0004674677997609879,
      "loss": 0.4149,
      "step": 34700
    },
    {
      "epoch": 1.415008030577185,
      "grad_norm": 0.18297740817070007,
      "learning_rate": 0.0004672464922763688,
      "loss": 0.4167,
      "step": 34800
    },
    {
      "epoch": 1.4190741456075793,
      "grad_norm": 0.17572054266929626,
      "learning_rate": 0.00046702518479174965,
      "loss": 0.4137,
      "step": 34900
    },
    {
      "epoch": 1.4231402606379735,
      "grad_norm": 0.18397001922130585,
      "learning_rate": 0.00046680387730713054,
      "loss": 0.4168,
      "step": 35000
    },
    {
      "epoch": 1.4272063756683677,
      "grad_norm": 0.17352798581123352,
      "learning_rate": 0.0004665825698225114,
      "loss": 0.416,
      "step": 35100
    },
    {
      "epoch": 1.431272490698762,
      "grad_norm": 0.1738823652267456,
      "learning_rate": 0.0004663612623378923,
      "loss": 0.4163,
      "step": 35200
    },
    {
      "epoch": 1.435338605729156,
      "grad_norm": 0.16454729437828064,
      "learning_rate": 0.0004661399548532731,
      "loss": 0.4157,
      "step": 35300
    },
    {
      "epoch": 1.4394047207595504,
      "grad_norm": 0.17690032720565796,
      "learning_rate": 0.000465918647368654,
      "loss": 0.4172,
      "step": 35400
    },
    {
      "epoch": 1.4434708357899444,
      "grad_norm": 0.19831690192222595,
      "learning_rate": 0.0004656973398840349,
      "loss": 0.4132,
      "step": 35500
    },
    {
      "epoch": 1.4475369508203388,
      "grad_norm": 0.19803959131240845,
      "learning_rate": 0.00046547603239941576,
      "loss": 0.4163,
      "step": 35600
    },
    {
      "epoch": 1.4516030658507328,
      "grad_norm": 0.17397642135620117,
      "learning_rate": 0.00046525472491479666,
      "loss": 0.4167,
      "step": 35700
    },
    {
      "epoch": 1.455669180881127,
      "grad_norm": 0.1862030029296875,
      "learning_rate": 0.0004650334174301775,
      "loss": 0.4151,
      "step": 35800
    },
    {
      "epoch": 1.4597352959115213,
      "grad_norm": 0.17086435854434967,
      "learning_rate": 0.0004648121099455584,
      "loss": 0.4155,
      "step": 35900
    },
    {
      "epoch": 1.4638014109419155,
      "grad_norm": 0.1935316026210785,
      "learning_rate": 0.00046459080246093925,
      "loss": 0.4169,
      "step": 36000
    },
    {
      "epoch": 1.4638014109419155,
      "eval_loss": 0.4841325879096985,
      "eval_runtime": 113.9527,
      "eval_samples_per_second": 1534.865,
      "eval_steps_per_second": 47.967,
      "step": 36000
    },
    {
      "epoch": 1.4678675259723097,
      "grad_norm": 0.17663568258285522,
      "learning_rate": 0.0004643694949763201,
      "loss": 0.4189,
      "step": 36100
    },
    {
      "epoch": 1.471933641002704,
      "grad_norm": 0.17727093398571014,
      "learning_rate": 0.00046414818749170093,
      "loss": 0.4148,
      "step": 36200
    },
    {
      "epoch": 1.4759997560330982,
      "grad_norm": 0.18335196375846863,
      "learning_rate": 0.00046392688000708183,
      "loss": 0.4153,
      "step": 36300
    },
    {
      "epoch": 1.4800658710634924,
      "grad_norm": 0.17249910533428192,
      "learning_rate": 0.0004637055725224627,
      "loss": 0.4151,
      "step": 36400
    },
    {
      "epoch": 1.4841319860938866,
      "grad_norm": 0.17696142196655273,
      "learning_rate": 0.00046348426503784357,
      "loss": 0.4148,
      "step": 36500
    },
    {
      "epoch": 1.4881981011242809,
      "grad_norm": 0.17616519331932068,
      "learning_rate": 0.00046326295755322447,
      "loss": 0.417,
      "step": 36600
    },
    {
      "epoch": 1.492264216154675,
      "grad_norm": 0.1915477216243744,
      "learning_rate": 0.0004630416500686053,
      "loss": 0.4122,
      "step": 36700
    },
    {
      "epoch": 1.4963303311850693,
      "grad_norm": 0.16478241980075836,
      "learning_rate": 0.0004628203425839862,
      "loss": 0.4171,
      "step": 36800
    },
    {
      "epoch": 1.5003964462154635,
      "grad_norm": 0.1785358190536499,
      "learning_rate": 0.00046259903509936705,
      "loss": 0.417,
      "step": 36900
    },
    {
      "epoch": 1.5044625612458575,
      "grad_norm": 0.17838986217975616,
      "learning_rate": 0.00046237772761474795,
      "loss": 0.4151,
      "step": 37000
    },
    {
      "epoch": 1.508528676276252,
      "grad_norm": 0.17175084352493286,
      "learning_rate": 0.00046215642013012885,
      "loss": 0.4137,
      "step": 37100
    },
    {
      "epoch": 1.512594791306646,
      "grad_norm": 0.19086894392967224,
      "learning_rate": 0.0004619351126455097,
      "loss": 0.415,
      "step": 37200
    },
    {
      "epoch": 1.5166609063370404,
      "grad_norm": 0.20087134838104248,
      "learning_rate": 0.0004617138051608906,
      "loss": 0.4137,
      "step": 37300
    },
    {
      "epoch": 1.5207270213674344,
      "grad_norm": 0.20011676847934723,
      "learning_rate": 0.00046149249767627143,
      "loss": 0.4142,
      "step": 37400
    },
    {
      "epoch": 1.5247931363978287,
      "grad_norm": 0.1745918244123459,
      "learning_rate": 0.0004612711901916523,
      "loss": 0.4132,
      "step": 37500
    },
    {
      "epoch": 1.5288592514282229,
      "grad_norm": 0.15753096342086792,
      "learning_rate": 0.00046104988270703317,
      "loss": 0.4133,
      "step": 37600
    },
    {
      "epoch": 1.532925366458617,
      "grad_norm": 0.1827968955039978,
      "learning_rate": 0.00046082857522241407,
      "loss": 0.4124,
      "step": 37700
    },
    {
      "epoch": 1.5369914814890113,
      "grad_norm": 0.19240403175354004,
      "learning_rate": 0.00046060726773779486,
      "loss": 0.4128,
      "step": 37800
    },
    {
      "epoch": 1.5410575965194055,
      "grad_norm": 0.17907467484474182,
      "learning_rate": 0.00046038596025317575,
      "loss": 0.4116,
      "step": 37900
    },
    {
      "epoch": 1.5451237115497998,
      "grad_norm": 0.16762705147266388,
      "learning_rate": 0.00046016465276855665,
      "loss": 0.4134,
      "step": 38000
    },
    {
      "epoch": 1.5451237115497998,
      "eval_loss": 0.4820251166820526,
      "eval_runtime": 113.6826,
      "eval_samples_per_second": 1538.512,
      "eval_steps_per_second": 48.081,
      "step": 38000
    },
    {
      "epoch": 1.549189826580194,
      "grad_norm": 0.19144229590892792,
      "learning_rate": 0.0004599433452839375,
      "loss": 0.4154,
      "step": 38100
    },
    {
      "epoch": 1.5532559416105882,
      "grad_norm": 0.17966778576374054,
      "learning_rate": 0.0004597220377993184,
      "loss": 0.415,
      "step": 38200
    },
    {
      "epoch": 1.5573220566409822,
      "grad_norm": 0.174627423286438,
      "learning_rate": 0.00045950073031469923,
      "loss": 0.4123,
      "step": 38300
    },
    {
      "epoch": 1.5613881716713767,
      "grad_norm": 0.18120840191841125,
      "learning_rate": 0.00045927942283008013,
      "loss": 0.4128,
      "step": 38400
    },
    {
      "epoch": 1.5654542867017707,
      "grad_norm": 0.18144215643405914,
      "learning_rate": 0.000459058115345461,
      "loss": 0.4105,
      "step": 38500
    },
    {
      "epoch": 1.5695204017321651,
      "grad_norm": 0.1936521977186203,
      "learning_rate": 0.00045883680786084187,
      "loss": 0.4127,
      "step": 38600
    },
    {
      "epoch": 1.5735865167625591,
      "grad_norm": 0.18281902372837067,
      "learning_rate": 0.0004586155003762227,
      "loss": 0.4116,
      "step": 38700
    },
    {
      "epoch": 1.5776526317929536,
      "grad_norm": 0.18015916645526886,
      "learning_rate": 0.0004583941928916036,
      "loss": 0.4148,
      "step": 38800
    },
    {
      "epoch": 1.5817187468233476,
      "grad_norm": 0.17451633512973785,
      "learning_rate": 0.0004581728854069845,
      "loss": 0.4127,
      "step": 38900
    },
    {
      "epoch": 1.5857848618537418,
      "grad_norm": 0.1695067584514618,
      "learning_rate": 0.00045795157792236535,
      "loss": 0.4139,
      "step": 39000
    },
    {
      "epoch": 1.589850976884136,
      "grad_norm": 0.17551881074905396,
      "learning_rate": 0.00045773027043774625,
      "loss": 0.4137,
      "step": 39100
    },
    {
      "epoch": 1.5939170919145302,
      "grad_norm": 0.1770668625831604,
      "learning_rate": 0.0004575089629531271,
      "loss": 0.4142,
      "step": 39200
    },
    {
      "epoch": 1.5979832069449245,
      "grad_norm": 0.1817394495010376,
      "learning_rate": 0.000457287655468508,
      "loss": 0.4112,
      "step": 39300
    },
    {
      "epoch": 1.6020493219753187,
      "grad_norm": 0.1731005609035492,
      "learning_rate": 0.0004570663479838888,
      "loss": 0.411,
      "step": 39400
    },
    {
      "epoch": 1.606115437005713,
      "grad_norm": 0.1877812296152115,
      "learning_rate": 0.0004568450404992697,
      "loss": 0.4122,
      "step": 39500
    },
    {
      "epoch": 1.6101815520361071,
      "grad_norm": 0.1892969012260437,
      "learning_rate": 0.0004566237330146505,
      "loss": 0.4104,
      "step": 39600
    },
    {
      "epoch": 1.6142476670665014,
      "grad_norm": 0.18251553177833557,
      "learning_rate": 0.0004564024255300314,
      "loss": 0.413,
      "step": 39700
    },
    {
      "epoch": 1.6183137820968954,
      "grad_norm": 0.1746293306350708,
      "learning_rate": 0.0004561811180454123,
      "loss": 0.4103,
      "step": 39800
    },
    {
      "epoch": 1.6223798971272898,
      "grad_norm": 0.18061937391757965,
      "learning_rate": 0.00045595981056079316,
      "loss": 0.4142,
      "step": 39900
    },
    {
      "epoch": 1.6264460121576838,
      "grad_norm": 0.1799560934305191,
      "learning_rate": 0.00045573850307617405,
      "loss": 0.4125,
      "step": 40000
    },
    {
      "epoch": 1.6264460121576838,
      "eval_loss": 0.4851503074169159,
      "eval_runtime": 114.0274,
      "eval_samples_per_second": 1533.86,
      "eval_steps_per_second": 47.936,
      "step": 40000
    },
    {
      "epoch": 1.6305121271880783,
      "grad_norm": 0.1806836873292923,
      "learning_rate": 0.0004555171955915549,
      "loss": 0.4148,
      "step": 40100
    },
    {
      "epoch": 1.6345782422184723,
      "grad_norm": 0.20210453867912292,
      "learning_rate": 0.0004552958881069358,
      "loss": 0.41,
      "step": 40200
    },
    {
      "epoch": 1.6386443572488667,
      "grad_norm": 0.1842343807220459,
      "learning_rate": 0.00045507458062231664,
      "loss": 0.415,
      "step": 40300
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.17964164912700653,
      "learning_rate": 0.00045485327313769754,
      "loss": 0.4122,
      "step": 40400
    },
    {
      "epoch": 1.6467765873096551,
      "grad_norm": 0.18041451275348663,
      "learning_rate": 0.0004546319656530784,
      "loss": 0.414,
      "step": 40500
    },
    {
      "epoch": 1.6508427023400492,
      "grad_norm": 0.19278931617736816,
      "learning_rate": 0.0004544106581684593,
      "loss": 0.4092,
      "step": 40600
    },
    {
      "epoch": 1.6549088173704434,
      "grad_norm": 0.17823195457458496,
      "learning_rate": 0.0004541893506838402,
      "loss": 0.4131,
      "step": 40700
    },
    {
      "epoch": 1.6589749324008376,
      "grad_norm": 0.18720252811908722,
      "learning_rate": 0.000453968043199221,
      "loss": 0.4111,
      "step": 40800
    },
    {
      "epoch": 1.6630410474312318,
      "grad_norm": 0.1791732907295227,
      "learning_rate": 0.0004537467357146019,
      "loss": 0.4103,
      "step": 40900
    },
    {
      "epoch": 1.667107162461626,
      "grad_norm": 0.1765388697385788,
      "learning_rate": 0.00045352542822998276,
      "loss": 0.4123,
      "step": 41000
    },
    {
      "epoch": 1.6711732774920203,
      "grad_norm": 0.18422004580497742,
      "learning_rate": 0.0004533041207453636,
      "loss": 0.4113,
      "step": 41100
    },
    {
      "epoch": 1.6752393925224145,
      "grad_norm": 0.17122739553451538,
      "learning_rate": 0.00045308281326074444,
      "loss": 0.4123,
      "step": 41200
    },
    {
      "epoch": 1.6793055075528087,
      "grad_norm": 0.19917483627796173,
      "learning_rate": 0.00045286150577612534,
      "loss": 0.4116,
      "step": 41300
    },
    {
      "epoch": 1.683371622583203,
      "grad_norm": 0.20268474519252777,
      "learning_rate": 0.00045264019829150624,
      "loss": 0.412,
      "step": 41400
    },
    {
      "epoch": 1.687437737613597,
      "grad_norm": 0.17472772300243378,
      "learning_rate": 0.0004524188908068871,
      "loss": 0.4129,
      "step": 41500
    },
    {
      "epoch": 1.6915038526439914,
      "grad_norm": 0.17090405523777008,
      "learning_rate": 0.000452197583322268,
      "loss": 0.4133,
      "step": 41600
    },
    {
      "epoch": 1.6955699676743854,
      "grad_norm": 0.18810084462165833,
      "learning_rate": 0.0004519762758376488,
      "loss": 0.4121,
      "step": 41700
    },
    {
      "epoch": 1.6996360827047798,
      "grad_norm": 0.1872638314962387,
      "learning_rate": 0.0004517549683530297,
      "loss": 0.4103,
      "step": 41800
    },
    {
      "epoch": 1.7037021977351738,
      "grad_norm": 0.16966219246387482,
      "learning_rate": 0.00045153366086841056,
      "loss": 0.4116,
      "step": 41900
    },
    {
      "epoch": 1.7077683127655683,
      "grad_norm": 0.19414423406124115,
      "learning_rate": 0.00045131235338379146,
      "loss": 0.4086,
      "step": 42000
    },
    {
      "epoch": 1.7077683127655683,
      "eval_loss": 0.45741453766822815,
      "eval_runtime": 114.0647,
      "eval_samples_per_second": 1533.358,
      "eval_steps_per_second": 47.92,
      "step": 42000
    },
    {
      "epoch": 1.7118344277959623,
      "grad_norm": 0.1815088838338852,
      "learning_rate": 0.0004510910458991723,
      "loss": 0.4087,
      "step": 42100
    },
    {
      "epoch": 1.7159005428263565,
      "grad_norm": 0.17851513624191284,
      "learning_rate": 0.0004508697384145532,
      "loss": 0.4095,
      "step": 42200
    },
    {
      "epoch": 1.7199666578567507,
      "grad_norm": 0.19257596135139465,
      "learning_rate": 0.0004506484309299341,
      "loss": 0.4126,
      "step": 42300
    },
    {
      "epoch": 1.724032772887145,
      "grad_norm": 0.1868821382522583,
      "learning_rate": 0.00045042712344531494,
      "loss": 0.4091,
      "step": 42400
    },
    {
      "epoch": 1.7280988879175392,
      "grad_norm": 0.19478142261505127,
      "learning_rate": 0.00045020581596069584,
      "loss": 0.4102,
      "step": 42500
    },
    {
      "epoch": 1.7321650029479334,
      "grad_norm": 0.1732124239206314,
      "learning_rate": 0.0004499845084760767,
      "loss": 0.4131,
      "step": 42600
    },
    {
      "epoch": 1.7362311179783276,
      "grad_norm": 0.17427758872509003,
      "learning_rate": 0.0004497632009914576,
      "loss": 0.4101,
      "step": 42700
    },
    {
      "epoch": 1.7402972330087219,
      "grad_norm": 0.18091969192028046,
      "learning_rate": 0.00044954189350683837,
      "loss": 0.4095,
      "step": 42800
    },
    {
      "epoch": 1.744363348039116,
      "grad_norm": 0.17718912661075592,
      "learning_rate": 0.00044932058602221926,
      "loss": 0.4129,
      "step": 42900
    },
    {
      "epoch": 1.74842946306951,
      "grad_norm": 0.16553032398223877,
      "learning_rate": 0.0004490992785376001,
      "loss": 0.4111,
      "step": 43000
    },
    {
      "epoch": 1.7524955780999045,
      "grad_norm": 0.17670051753520966,
      "learning_rate": 0.000448877971052981,
      "loss": 0.4095,
      "step": 43100
    },
    {
      "epoch": 1.7565616931302985,
      "grad_norm": 0.18079091608524323,
      "learning_rate": 0.0004486566635683619,
      "loss": 0.4085,
      "step": 43200
    },
    {
      "epoch": 1.760627808160693,
      "grad_norm": 0.16274748742580414,
      "learning_rate": 0.00044843535608374274,
      "loss": 0.4098,
      "step": 43300
    },
    {
      "epoch": 1.764693923191087,
      "grad_norm": 0.17738661170005798,
      "learning_rate": 0.00044821404859912364,
      "loss": 0.4079,
      "step": 43400
    },
    {
      "epoch": 1.7687600382214814,
      "grad_norm": 0.1887243092060089,
      "learning_rate": 0.0004479927411145045,
      "loss": 0.4087,
      "step": 43500
    },
    {
      "epoch": 1.7728261532518754,
      "grad_norm": 0.1838107407093048,
      "learning_rate": 0.0004477714336298854,
      "loss": 0.4132,
      "step": 43600
    },
    {
      "epoch": 1.7768922682822699,
      "grad_norm": 0.18598568439483643,
      "learning_rate": 0.0004475501261452662,
      "loss": 0.4121,
      "step": 43700
    },
    {
      "epoch": 1.7809583833126639,
      "grad_norm": 0.17834600806236267,
      "learning_rate": 0.0004473288186606471,
      "loss": 0.4109,
      "step": 43800
    },
    {
      "epoch": 1.785024498343058,
      "grad_norm": 0.18961688876152039,
      "learning_rate": 0.00044710751117602797,
      "loss": 0.4103,
      "step": 43900
    },
    {
      "epoch": 1.7890906133734523,
      "grad_norm": 0.1749494969844818,
      "learning_rate": 0.00044688620369140886,
      "loss": 0.4114,
      "step": 44000
    },
    {
      "epoch": 1.7890906133734523,
      "eval_loss": 0.4623814821243286,
      "eval_runtime": 113.9049,
      "eval_samples_per_second": 1535.509,
      "eval_steps_per_second": 47.987,
      "step": 44000
    },
    {
      "epoch": 1.7931567284038465,
      "grad_norm": 0.19060185551643372,
      "learning_rate": 0.00044666489620678976,
      "loss": 0.4103,
      "step": 44100
    },
    {
      "epoch": 1.7972228434342408,
      "grad_norm": 0.1637125015258789,
      "learning_rate": 0.0004464435887221706,
      "loss": 0.4107,
      "step": 44200
    },
    {
      "epoch": 1.801288958464635,
      "grad_norm": 0.18680500984191895,
      "learning_rate": 0.0004462222812375515,
      "loss": 0.4094,
      "step": 44300
    },
    {
      "epoch": 1.8053550734950292,
      "grad_norm": 0.18249303102493286,
      "learning_rate": 0.00044600097375293234,
      "loss": 0.4109,
      "step": 44400
    },
    {
      "epoch": 1.8094211885254232,
      "grad_norm": 0.17863886058330536,
      "learning_rate": 0.0004457796662683132,
      "loss": 0.4105,
      "step": 44500
    },
    {
      "epoch": 1.8134873035558177,
      "grad_norm": 0.17086054384708405,
      "learning_rate": 0.00044555835878369403,
      "loss": 0.4103,
      "step": 44600
    },
    {
      "epoch": 1.8175534185862117,
      "grad_norm": 0.19314458966255188,
      "learning_rate": 0.00044533705129907493,
      "loss": 0.4092,
      "step": 44700
    },
    {
      "epoch": 1.8216195336166061,
      "grad_norm": 0.18774546682834625,
      "learning_rate": 0.00044511574381445577,
      "loss": 0.411,
      "step": 44800
    },
    {
      "epoch": 1.8256856486470001,
      "grad_norm": 0.2015821635723114,
      "learning_rate": 0.00044489443632983667,
      "loss": 0.4079,
      "step": 44900
    },
    {
      "epoch": 1.8297517636773946,
      "grad_norm": 0.1732320338487625,
      "learning_rate": 0.00044467312884521757,
      "loss": 0.4102,
      "step": 45000
    },
    {
      "epoch": 1.8338178787077886,
      "grad_norm": 0.18641671538352966,
      "learning_rate": 0.0004444518213605984,
      "loss": 0.4084,
      "step": 45100
    },
    {
      "epoch": 1.837883993738183,
      "grad_norm": 0.18359090387821198,
      "learning_rate": 0.0004442305138759793,
      "loss": 0.4107,
      "step": 45200
    },
    {
      "epoch": 1.841950108768577,
      "grad_norm": 0.2024274468421936,
      "learning_rate": 0.00044400920639136015,
      "loss": 0.4074,
      "step": 45300
    },
    {
      "epoch": 1.8460162237989712,
      "grad_norm": 0.19638767838478088,
      "learning_rate": 0.00044378789890674105,
      "loss": 0.4071,
      "step": 45400
    },
    {
      "epoch": 1.8500823388293655,
      "grad_norm": 0.18368321657180786,
      "learning_rate": 0.0004435665914221219,
      "loss": 0.411,
      "step": 45500
    },
    {
      "epoch": 1.8541484538597597,
      "grad_norm": 0.1689586043357849,
      "learning_rate": 0.0004433452839375028,
      "loss": 0.4073,
      "step": 45600
    },
    {
      "epoch": 1.858214568890154,
      "grad_norm": 0.17557911574840546,
      "learning_rate": 0.0004431239764528837,
      "loss": 0.4109,
      "step": 45700
    },
    {
      "epoch": 1.8622806839205481,
      "grad_norm": 0.18170781433582306,
      "learning_rate": 0.00044290266896826453,
      "loss": 0.408,
      "step": 45800
    },
    {
      "epoch": 1.8663467989509424,
      "grad_norm": 0.20001006126403809,
      "learning_rate": 0.0004426813614836454,
      "loss": 0.4116,
      "step": 45900
    },
    {
      "epoch": 1.8704129139813366,
      "grad_norm": 0.19605419039726257,
      "learning_rate": 0.00044246005399902627,
      "loss": 0.4068,
      "step": 46000
    },
    {
      "epoch": 1.8704129139813366,
      "eval_loss": 0.45151209831237793,
      "eval_runtime": 114.019,
      "eval_samples_per_second": 1533.972,
      "eval_steps_per_second": 47.939,
      "step": 46000
    },
    {
      "epoch": 1.8744790290117308,
      "grad_norm": 0.1696373075246811,
      "learning_rate": 0.00044223874651440717,
      "loss": 0.4106,
      "step": 46100
    },
    {
      "epoch": 1.8785451440421248,
      "grad_norm": 0.1663631796836853,
      "learning_rate": 0.00044201743902978795,
      "loss": 0.4087,
      "step": 46200
    },
    {
      "epoch": 1.8826112590725192,
      "grad_norm": 0.18049664795398712,
      "learning_rate": 0.00044179613154516885,
      "loss": 0.4108,
      "step": 46300
    },
    {
      "epoch": 1.8866773741029133,
      "grad_norm": 0.18957769870758057,
      "learning_rate": 0.0004415748240605497,
      "loss": 0.4089,
      "step": 46400
    },
    {
      "epoch": 1.8907434891333077,
      "grad_norm": 0.19157682359218597,
      "learning_rate": 0.0004413535165759306,
      "loss": 0.4081,
      "step": 46500
    },
    {
      "epoch": 1.8948096041637017,
      "grad_norm": 0.20152215659618378,
      "learning_rate": 0.0004411322090913115,
      "loss": 0.4086,
      "step": 46600
    },
    {
      "epoch": 1.8988757191940961,
      "grad_norm": 0.19631308317184448,
      "learning_rate": 0.00044091090160669233,
      "loss": 0.4104,
      "step": 46700
    },
    {
      "epoch": 1.9029418342244901,
      "grad_norm": 0.19397176802158356,
      "learning_rate": 0.00044068959412207323,
      "loss": 0.4084,
      "step": 46800
    },
    {
      "epoch": 1.9070079492548844,
      "grad_norm": 0.18982358276844025,
      "learning_rate": 0.00044046828663745407,
      "loss": 0.409,
      "step": 46900
    },
    {
      "epoch": 1.9110740642852786,
      "grad_norm": 0.18949897587299347,
      "learning_rate": 0.00044024697915283497,
      "loss": 0.4107,
      "step": 47000
    },
    {
      "epoch": 1.9151401793156728,
      "grad_norm": 0.1875125765800476,
      "learning_rate": 0.0004400256716682158,
      "loss": 0.4109,
      "step": 47100
    },
    {
      "epoch": 1.919206294346067,
      "grad_norm": 0.1825484335422516,
      "learning_rate": 0.0004398043641835967,
      "loss": 0.4098,
      "step": 47200
    },
    {
      "epoch": 1.9232724093764613,
      "grad_norm": 0.20640335977077484,
      "learning_rate": 0.00043958305669897755,
      "loss": 0.4088,
      "step": 47300
    },
    {
      "epoch": 1.9273385244068555,
      "grad_norm": 0.1913188397884369,
      "learning_rate": 0.00043936174921435845,
      "loss": 0.4094,
      "step": 47400
    },
    {
      "epoch": 1.9314046394372497,
      "grad_norm": 0.1869620978832245,
      "learning_rate": 0.00043914044172973935,
      "loss": 0.4117,
      "step": 47500
    },
    {
      "epoch": 1.935470754467644,
      "grad_norm": 0.1835249960422516,
      "learning_rate": 0.0004389191342451202,
      "loss": 0.4064,
      "step": 47600
    },
    {
      "epoch": 1.939536869498038,
      "grad_norm": 0.1851554960012436,
      "learning_rate": 0.0004386978267605011,
      "loss": 0.4069,
      "step": 47700
    },
    {
      "epoch": 1.9436029845284324,
      "grad_norm": 0.18843774497509003,
      "learning_rate": 0.00043847651927588193,
      "loss": 0.4103,
      "step": 47800
    },
    {
      "epoch": 1.9476690995588264,
      "grad_norm": 0.2283075451850891,
      "learning_rate": 0.0004382552117912628,
      "loss": 0.4123,
      "step": 47900
    },
    {
      "epoch": 1.9517352145892208,
      "grad_norm": 0.2041732370853424,
      "learning_rate": 0.0004380339043066436,
      "loss": 0.4077,
      "step": 48000
    },
    {
      "epoch": 1.9517352145892208,
      "eval_loss": 0.4601059556007385,
      "eval_runtime": 114.1026,
      "eval_samples_per_second": 1532.848,
      "eval_steps_per_second": 47.904,
      "step": 48000
    },
    {
      "epoch": 1.9558013296196148,
      "grad_norm": 0.18949222564697266,
      "learning_rate": 0.0004378125968220245,
      "loss": 0.4072,
      "step": 48100
    },
    {
      "epoch": 1.9598674446500093,
      "grad_norm": 0.17699675261974335,
      "learning_rate": 0.00043759128933740536,
      "loss": 0.4101,
      "step": 48200
    },
    {
      "epoch": 1.9639335596804033,
      "grad_norm": 0.1841522753238678,
      "learning_rate": 0.00043736998185278626,
      "loss": 0.4076,
      "step": 48300
    },
    {
      "epoch": 1.9679996747107977,
      "grad_norm": 0.19394592940807343,
      "learning_rate": 0.00043714867436816715,
      "loss": 0.4064,
      "step": 48400
    },
    {
      "epoch": 1.9720657897411917,
      "grad_norm": 0.19894365966320038,
      "learning_rate": 0.000436927366883548,
      "loss": 0.4082,
      "step": 48500
    },
    {
      "epoch": 1.976131904771586,
      "grad_norm": 0.18577024340629578,
      "learning_rate": 0.0004367060593989289,
      "loss": 0.4104,
      "step": 48600
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 0.17443683743476868,
      "learning_rate": 0.00043648475191430974,
      "loss": 0.4092,
      "step": 48700
    },
    {
      "epoch": 1.9842641348323744,
      "grad_norm": 0.17964491248130798,
      "learning_rate": 0.00043626344442969063,
      "loss": 0.4098,
      "step": 48800
    },
    {
      "epoch": 1.9883302498627686,
      "grad_norm": 0.21132618188858032,
      "learning_rate": 0.0004360421369450715,
      "loss": 0.405,
      "step": 48900
    },
    {
      "epoch": 1.9923963648931629,
      "grad_norm": 0.1888483613729477,
      "learning_rate": 0.0004358208294604524,
      "loss": 0.4096,
      "step": 49000
    },
    {
      "epoch": 1.996462479923557,
      "grad_norm": 0.18211126327514648,
      "learning_rate": 0.00043559952197583327,
      "loss": 0.4054,
      "step": 49100
    },
    {
      "epoch": 2.000528594953951,
      "grad_norm": 0.18316707015037537,
      "learning_rate": 0.0004353782144912141,
      "loss": 0.4053,
      "step": 49200
    },
    {
      "epoch": 2.0045947099843455,
      "grad_norm": 0.1787765771150589,
      "learning_rate": 0.000435156907006595,
      "loss": 0.4088,
      "step": 49300
    },
    {
      "epoch": 2.0086608250147395,
      "grad_norm": 0.18754738569259644,
      "learning_rate": 0.00043493559952197586,
      "loss": 0.4054,
      "step": 49400
    },
    {
      "epoch": 2.012726940045134,
      "grad_norm": 0.20062367618083954,
      "learning_rate": 0.00043471429203735675,
      "loss": 0.4066,
      "step": 49500
    },
    {
      "epoch": 2.016793055075528,
      "grad_norm": 0.1730446070432663,
      "learning_rate": 0.00043449298455273754,
      "loss": 0.4027,
      "step": 49600
    },
    {
      "epoch": 2.0208591701059224,
      "grad_norm": 0.18507978320121765,
      "learning_rate": 0.00043427167706811844,
      "loss": 0.4066,
      "step": 49700
    },
    {
      "epoch": 2.0249252851363164,
      "grad_norm": 0.18379950523376465,
      "learning_rate": 0.0004340503695834993,
      "loss": 0.4056,
      "step": 49800
    },
    {
      "epoch": 2.028991400166711,
      "grad_norm": 0.20259110629558563,
      "learning_rate": 0.0004338290620988802,
      "loss": 0.4055,
      "step": 49900
    },
    {
      "epoch": 2.033057515197105,
      "grad_norm": 0.1960059404373169,
      "learning_rate": 0.0004336077546142611,
      "loss": 0.4064,
      "step": 50000
    },
    {
      "epoch": 2.033057515197105,
      "eval_loss": 0.46984797716140747,
      "eval_runtime": 113.8854,
      "eval_samples_per_second": 1535.772,
      "eval_steps_per_second": 47.996,
      "step": 50000
    },
    {
      "epoch": 2.0371236302274993,
      "grad_norm": 0.1823187917470932,
      "learning_rate": 0.0004333864471296419,
      "loss": 0.4085,
      "step": 50100
    },
    {
      "epoch": 2.0411897452578933,
      "grad_norm": 0.19069400429725647,
      "learning_rate": 0.0004331651396450228,
      "loss": 0.4059,
      "step": 50200
    },
    {
      "epoch": 2.0452558602882878,
      "grad_norm": 0.17383648455142975,
      "learning_rate": 0.00043294383216040366,
      "loss": 0.4063,
      "step": 50300
    },
    {
      "epoch": 2.0493219753186818,
      "grad_norm": 0.210851788520813,
      "learning_rate": 0.00043272252467578456,
      "loss": 0.406,
      "step": 50400
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.21163809299468994,
      "learning_rate": 0.0004325012171911654,
      "loss": 0.4093,
      "step": 50500
    },
    {
      "epoch": 2.05745420537947,
      "grad_norm": 0.18779195845127106,
      "learning_rate": 0.0004322799097065463,
      "loss": 0.4062,
      "step": 50600
    },
    {
      "epoch": 2.061520320409864,
      "grad_norm": 0.18390922248363495,
      "learning_rate": 0.00043205860222192714,
      "loss": 0.4042,
      "step": 50700
    },
    {
      "epoch": 2.0655864354402587,
      "grad_norm": 0.2000400424003601,
      "learning_rate": 0.00043183729473730804,
      "loss": 0.4051,
      "step": 50800
    },
    {
      "epoch": 2.0696525504706527,
      "grad_norm": 0.2074478715658188,
      "learning_rate": 0.00043161598725268894,
      "loss": 0.4072,
      "step": 50900
    },
    {
      "epoch": 2.073718665501047,
      "grad_norm": 0.19453707337379456,
      "learning_rate": 0.0004313946797680698,
      "loss": 0.4057,
      "step": 51000
    },
    {
      "epoch": 2.077784780531441,
      "grad_norm": 0.19512204825878143,
      "learning_rate": 0.0004311733722834507,
      "loss": 0.4062,
      "step": 51100
    },
    {
      "epoch": 2.0818508955618356,
      "grad_norm": 0.1995730847120285,
      "learning_rate": 0.00043095206479883147,
      "loss": 0.4062,
      "step": 51200
    },
    {
      "epoch": 2.0859170105922296,
      "grad_norm": 0.19921579957008362,
      "learning_rate": 0.00043073075731421236,
      "loss": 0.4062,
      "step": 51300
    },
    {
      "epoch": 2.089983125622624,
      "grad_norm": 0.19278985261917114,
      "learning_rate": 0.0004305094498295932,
      "loss": 0.4066,
      "step": 51400
    },
    {
      "epoch": 2.094049240653018,
      "grad_norm": 0.19680380821228027,
      "learning_rate": 0.0004302881423449741,
      "loss": 0.4063,
      "step": 51500
    },
    {
      "epoch": 2.0981153556834125,
      "grad_norm": 0.18233366310596466,
      "learning_rate": 0.00043006683486035495,
      "loss": 0.4069,
      "step": 51600
    },
    {
      "epoch": 2.1021814707138065,
      "grad_norm": 0.19934852421283722,
      "learning_rate": 0.00042984552737573584,
      "loss": 0.4079,
      "step": 51700
    },
    {
      "epoch": 2.106247585744201,
      "grad_norm": 0.17234855890274048,
      "learning_rate": 0.00042962421989111674,
      "loss": 0.4037,
      "step": 51800
    },
    {
      "epoch": 2.110313700774595,
      "grad_norm": 0.2076251208782196,
      "learning_rate": 0.0004294029124064976,
      "loss": 0.4076,
      "step": 51900
    },
    {
      "epoch": 2.1143798158049893,
      "grad_norm": 0.2049364149570465,
      "learning_rate": 0.0004291816049218785,
      "loss": 0.4052,
      "step": 52000
    },
    {
      "epoch": 2.1143798158049893,
      "eval_loss": 0.45482906699180603,
      "eval_runtime": 114.4943,
      "eval_samples_per_second": 1527.605,
      "eval_steps_per_second": 47.74,
      "step": 52000
    },
    {
      "epoch": 2.1184865919856875,
      "grad_norm": 0.175212562084198,
      "learning_rate": 0.0004289602974372593,
      "loss": 0.4047,
      "step": 52100
    },
    {
      "epoch": 2.1225527070160815,
      "grad_norm": 0.1976061314344406,
      "learning_rate": 0.0004287389899526402,
      "loss": 0.4075,
      "step": 52200
    },
    {
      "epoch": 2.126618822046476,
      "grad_norm": 0.18492653965950012,
      "learning_rate": 0.00042851768246802106,
      "loss": 0.4076,
      "step": 52300
    },
    {
      "epoch": 2.13068493707687,
      "grad_norm": 0.18915997445583344,
      "learning_rate": 0.00042829637498340196,
      "loss": 0.4057,
      "step": 52400
    },
    {
      "epoch": 2.134751052107264,
      "grad_norm": 0.20411108434200287,
      "learning_rate": 0.00042807506749878286,
      "loss": 0.4059,
      "step": 52500
    },
    {
      "epoch": 2.1388171671376583,
      "grad_norm": 0.18661662936210632,
      "learning_rate": 0.0004278537600141637,
      "loss": 0.4071,
      "step": 52600
    },
    {
      "epoch": 2.1428832821680524,
      "grad_norm": 0.17623968422412872,
      "learning_rate": 0.0004276324525295446,
      "loss": 0.407,
      "step": 52700
    },
    {
      "epoch": 2.146949397198447,
      "grad_norm": 0.2023492157459259,
      "learning_rate": 0.00042741114504492544,
      "loss": 0.4024,
      "step": 52800
    },
    {
      "epoch": 2.151015512228841,
      "grad_norm": 0.19339703023433685,
      "learning_rate": 0.0004271898375603063,
      "loss": 0.4071,
      "step": 52900
    },
    {
      "epoch": 2.1550816272592352,
      "grad_norm": 0.20038403570652008,
      "learning_rate": 0.00042696853007568713,
      "loss": 0.407,
      "step": 53000
    },
    {
      "epoch": 2.1591477422896292,
      "grad_norm": 0.18409894406795502,
      "learning_rate": 0.000426747222591068,
      "loss": 0.4043,
      "step": 53100
    },
    {
      "epoch": 2.1632138573200237,
      "grad_norm": 0.20321835577487946,
      "learning_rate": 0.00042652591510644887,
      "loss": 0.402,
      "step": 53200
    },
    {
      "epoch": 2.1672799723504177,
      "grad_norm": 0.19512754678726196,
      "learning_rate": 0.00042630460762182977,
      "loss": 0.406,
      "step": 53300
    },
    {
      "epoch": 2.171346087380812,
      "grad_norm": 0.19191592931747437,
      "learning_rate": 0.00042608330013721066,
      "loss": 0.4065,
      "step": 53400
    },
    {
      "epoch": 2.175412202411206,
      "grad_norm": 0.1990126222372055,
      "learning_rate": 0.0004258619926525915,
      "loss": 0.4043,
      "step": 53500
    },
    {
      "epoch": 2.1794783174416006,
      "grad_norm": 0.20023827254772186,
      "learning_rate": 0.0004256406851679724,
      "loss": 0.405,
      "step": 53600
    },
    {
      "epoch": 2.1835444324719946,
      "grad_norm": 0.19769497215747833,
      "learning_rate": 0.00042541937768335325,
      "loss": 0.4037,
      "step": 53700
    },
    {
      "epoch": 2.187610547502389,
      "grad_norm": 0.2025981992483139,
      "learning_rate": 0.00042519807019873415,
      "loss": 0.4052,
      "step": 53800
    },
    {
      "epoch": 2.191676662532783,
      "grad_norm": 0.19289462268352509,
      "learning_rate": 0.000424976762714115,
      "loss": 0.4069,
      "step": 53900
    },
    {
      "epoch": 2.1957427775631775,
      "grad_norm": 0.19834086298942566,
      "learning_rate": 0.0004247554552294959,
      "loss": 0.4069,
      "step": 54000
    },
    {
      "epoch": 2.1957427775631775,
      "eval_loss": 0.4477100968360901,
      "eval_runtime": 115.9631,
      "eval_samples_per_second": 1508.255,
      "eval_steps_per_second": 47.136,
      "step": 54000
    },
    {
      "epoch": 2.1998088925935715,
      "grad_norm": 0.17982231080532074,
      "learning_rate": 0.00042453414774487673,
      "loss": 0.4044,
      "step": 54100
    },
    {
      "epoch": 2.2038750076239655,
      "grad_norm": 0.19023920595645905,
      "learning_rate": 0.0004243128402602576,
      "loss": 0.4055,
      "step": 54200
    },
    {
      "epoch": 2.20794112265436,
      "grad_norm": 0.18387927114963531,
      "learning_rate": 0.0004240915327756385,
      "loss": 0.4044,
      "step": 54300
    },
    {
      "epoch": 2.212007237684754,
      "grad_norm": 0.20939859747886658,
      "learning_rate": 0.00042387022529101937,
      "loss": 0.404,
      "step": 54400
    },
    {
      "epoch": 2.2160733527151484,
      "grad_norm": 0.1949683129787445,
      "learning_rate": 0.00042364891780640026,
      "loss": 0.4051,
      "step": 54500
    },
    {
      "epoch": 2.2201394677455424,
      "grad_norm": 0.19291695952415466,
      "learning_rate": 0.00042342761032178105,
      "loss": 0.4064,
      "step": 54600
    },
    {
      "epoch": 2.224205582775937,
      "grad_norm": 0.19467782974243164,
      "learning_rate": 0.00042320630283716195,
      "loss": 0.4074,
      "step": 54700
    },
    {
      "epoch": 2.228271697806331,
      "grad_norm": 0.21345122158527374,
      "learning_rate": 0.0004229849953525428,
      "loss": 0.4048,
      "step": 54800
    },
    {
      "epoch": 2.2323378128367253,
      "grad_norm": 0.19633059203624725,
      "learning_rate": 0.0004227636878679237,
      "loss": 0.4071,
      "step": 54900
    },
    {
      "epoch": 2.2364039278671193,
      "grad_norm": 0.18264012038707733,
      "learning_rate": 0.00042254238038330453,
      "loss": 0.4064,
      "step": 55000
    },
    {
      "epoch": 2.2404700428975137,
      "grad_norm": 0.2121364176273346,
      "learning_rate": 0.00042232107289868543,
      "loss": 0.4047,
      "step": 55100
    },
    {
      "epoch": 2.2445361579279077,
      "grad_norm": 0.18813444674015045,
      "learning_rate": 0.00042209976541406633,
      "loss": 0.4023,
      "step": 55200
    },
    {
      "epoch": 2.248602272958302,
      "grad_norm": 0.1890118420124054,
      "learning_rate": 0.00042187845792944717,
      "loss": 0.4031,
      "step": 55300
    },
    {
      "epoch": 2.252668387988696,
      "grad_norm": 0.18296106159687042,
      "learning_rate": 0.00042165715044482807,
      "loss": 0.4047,
      "step": 55400
    },
    {
      "epoch": 2.25673450301909,
      "grad_norm": 0.17508235573768616,
      "learning_rate": 0.0004214358429602089,
      "loss": 0.4053,
      "step": 55500
    },
    {
      "epoch": 2.2608006180494846,
      "grad_norm": 0.20245666801929474,
      "learning_rate": 0.0004212145354755898,
      "loss": 0.4034,
      "step": 55600
    },
    {
      "epoch": 2.264866733079879,
      "grad_norm": 0.19689610600471497,
      "learning_rate": 0.00042099322799097065,
      "loss": 0.4049,
      "step": 55700
    },
    {
      "epoch": 2.268932848110273,
      "grad_norm": 0.19138966500759125,
      "learning_rate": 0.00042077192050635155,
      "loss": 0.4058,
      "step": 55800
    },
    {
      "epoch": 2.272998963140667,
      "grad_norm": 0.18563935160636902,
      "learning_rate": 0.00042055061302173245,
      "loss": 0.4055,
      "step": 55900
    },
    {
      "epoch": 2.2770650781710615,
      "grad_norm": 0.19346244633197784,
      "learning_rate": 0.0004203293055371133,
      "loss": 0.4059,
      "step": 56000
    },
    {
      "epoch": 2.2770650781710615,
      "eval_loss": 0.44810938835144043,
      "eval_runtime": 114.8414,
      "eval_samples_per_second": 1522.988,
      "eval_steps_per_second": 47.596,
      "step": 56000
    },
    {
      "epoch": 2.2811311932014555,
      "grad_norm": 0.18759411573410034,
      "learning_rate": 0.0004201079980524942,
      "loss": 0.4053,
      "step": 56100
    },
    {
      "epoch": 2.28519730823185,
      "grad_norm": 0.19760571420192719,
      "learning_rate": 0.00041988669056787503,
      "loss": 0.4044,
      "step": 56200
    },
    {
      "epoch": 2.289263423262244,
      "grad_norm": 0.1729007065296173,
      "learning_rate": 0.0004196653830832559,
      "loss": 0.403,
      "step": 56300
    },
    {
      "epoch": 2.2933295382926384,
      "grad_norm": 0.19207225739955902,
      "learning_rate": 0.0004194440755986367,
      "loss": 0.4043,
      "step": 56400
    },
    {
      "epoch": 2.2973956533230324,
      "grad_norm": 0.20643426477909088,
      "learning_rate": 0.0004192227681140176,
      "loss": 0.406,
      "step": 56500
    },
    {
      "epoch": 2.301461768353427,
      "grad_norm": 0.1845054179430008,
      "learning_rate": 0.00041900146062939846,
      "loss": 0.4062,
      "step": 56600
    },
    {
      "epoch": 2.305527883383821,
      "grad_norm": 0.18692828714847565,
      "learning_rate": 0.00041878015314477935,
      "loss": 0.4055,
      "step": 56700
    },
    {
      "epoch": 2.3095939984142153,
      "grad_norm": 0.20163437724113464,
      "learning_rate": 0.00041855884566016025,
      "loss": 0.4046,
      "step": 56800
    },
    {
      "epoch": 2.3136601134446093,
      "grad_norm": 0.19971154630184174,
      "learning_rate": 0.0004183375381755411,
      "loss": 0.4042,
      "step": 56900
    },
    {
      "epoch": 2.3177262284750038,
      "grad_norm": 0.19020308554172516,
      "learning_rate": 0.000418116230690922,
      "loss": 0.4073,
      "step": 57000
    },
    {
      "epoch": 2.3217923435053978,
      "grad_norm": 0.21673975884914398,
      "learning_rate": 0.00041789492320630284,
      "loss": 0.4056,
      "step": 57100
    },
    {
      "epoch": 2.3258584585357918,
      "grad_norm": 0.2212207317352295,
      "learning_rate": 0.00041767361572168373,
      "loss": 0.4063,
      "step": 57200
    },
    {
      "epoch": 2.329924573566186,
      "grad_norm": 0.210725337266922,
      "learning_rate": 0.0004174523082370646,
      "loss": 0.4081,
      "step": 57300
    },
    {
      "epoch": 2.33399068859658,
      "grad_norm": 0.2196648269891739,
      "learning_rate": 0.0004172310007524455,
      "loss": 0.4015,
      "step": 57400
    },
    {
      "epoch": 2.3380568036269747,
      "grad_norm": 0.18972350656986237,
      "learning_rate": 0.0004170096932678263,
      "loss": 0.4057,
      "step": 57500
    },
    {
      "epoch": 2.3421229186573687,
      "grad_norm": 0.1981489211320877,
      "learning_rate": 0.0004167883857832072,
      "loss": 0.4047,
      "step": 57600
    },
    {
      "epoch": 2.346189033687763,
      "grad_norm": 0.20187443494796753,
      "learning_rate": 0.0004165670782985881,
      "loss": 0.4041,
      "step": 57700
    },
    {
      "epoch": 2.350255148718157,
      "grad_norm": 0.16694127023220062,
      "learning_rate": 0.00041634577081396895,
      "loss": 0.4059,
      "step": 57800
    },
    {
      "epoch": 2.3543212637485516,
      "grad_norm": 0.20496554672718048,
      "learning_rate": 0.00041612446332934985,
      "loss": 0.4018,
      "step": 57900
    },
    {
      "epoch": 2.3583873787789456,
      "grad_norm": 0.18693120777606964,
      "learning_rate": 0.00041590315584473064,
      "loss": 0.4018,
      "step": 58000
    },
    {
      "epoch": 2.3583873787789456,
      "eval_loss": 0.4498234987258911,
      "eval_runtime": 114.6706,
      "eval_samples_per_second": 1525.255,
      "eval_steps_per_second": 47.667,
      "step": 58000
    },
    {
      "epoch": 2.36245349380934,
      "grad_norm": 0.18372724950313568,
      "learning_rate": 0.00041568184836011154,
      "loss": 0.4067,
      "step": 58100
    },
    {
      "epoch": 2.366519608839734,
      "grad_norm": 0.2067928910255432,
      "learning_rate": 0.0004154605408754924,
      "loss": 0.4031,
      "step": 58200
    },
    {
      "epoch": 2.3705857238701284,
      "grad_norm": 0.18127961456775665,
      "learning_rate": 0.0004152392333908733,
      "loss": 0.4046,
      "step": 58300
    },
    {
      "epoch": 2.3746518389005224,
      "grad_norm": 0.20339930057525635,
      "learning_rate": 0.0004150179259062541,
      "loss": 0.403,
      "step": 58400
    },
    {
      "epoch": 2.378717953930917,
      "grad_norm": 0.19435888528823853,
      "learning_rate": 0.000414796618421635,
      "loss": 0.4073,
      "step": 58500
    },
    {
      "epoch": 2.382784068961311,
      "grad_norm": 0.21079054474830627,
      "learning_rate": 0.0004145753109370159,
      "loss": 0.4054,
      "step": 58600
    },
    {
      "epoch": 2.3868501839917053,
      "grad_norm": 0.20196500420570374,
      "learning_rate": 0.00041435400345239676,
      "loss": 0.4,
      "step": 58700
    },
    {
      "epoch": 2.3909162990220993,
      "grad_norm": 0.20410612225532532,
      "learning_rate": 0.00041413269596777766,
      "loss": 0.4079,
      "step": 58800
    },
    {
      "epoch": 2.3949824140524933,
      "grad_norm": 0.2158791422843933,
      "learning_rate": 0.0004139113884831585,
      "loss": 0.4038,
      "step": 58900
    },
    {
      "epoch": 2.399048529082888,
      "grad_norm": 0.1985781192779541,
      "learning_rate": 0.0004136900809985394,
      "loss": 0.403,
      "step": 59000
    },
    {
      "epoch": 2.403114644113282,
      "grad_norm": 0.19455307722091675,
      "learning_rate": 0.00041346877351392024,
      "loss": 0.4024,
      "step": 59100
    },
    {
      "epoch": 2.4071807591436762,
      "grad_norm": 0.21600952744483948,
      "learning_rate": 0.00041324746602930114,
      "loss": 0.4055,
      "step": 59200
    },
    {
      "epoch": 2.4112468741740702,
      "grad_norm": 0.17581556737422943,
      "learning_rate": 0.000413026158544682,
      "loss": 0.4034,
      "step": 59300
    },
    {
      "epoch": 2.4153129892044647,
      "grad_norm": 0.19294463098049164,
      "learning_rate": 0.0004128048510600629,
      "loss": 0.4043,
      "step": 59400
    },
    {
      "epoch": 2.4193791042348587,
      "grad_norm": 0.19545958936214447,
      "learning_rate": 0.0004125835435754438,
      "loss": 0.404,
      "step": 59500
    },
    {
      "epoch": 2.423445219265253,
      "grad_norm": 0.20135116577148438,
      "learning_rate": 0.0004123622360908246,
      "loss": 0.4044,
      "step": 59600
    },
    {
      "epoch": 2.427511334295647,
      "grad_norm": 0.20161718130111694,
      "learning_rate": 0.00041214092860620546,
      "loss": 0.4025,
      "step": 59700
    },
    {
      "epoch": 2.4315774493260416,
      "grad_norm": 0.186545267701149,
      "learning_rate": 0.0004119196211215863,
      "loss": 0.402,
      "step": 59800
    },
    {
      "epoch": 2.4356435643564356,
      "grad_norm": 0.1853260099887848,
      "learning_rate": 0.0004116983136369672,
      "loss": 0.4034,
      "step": 59900
    },
    {
      "epoch": 2.43970967938683,
      "grad_norm": 0.188669815659523,
      "learning_rate": 0.00041147700615234804,
      "loss": 0.4025,
      "step": 60000
    },
    {
      "epoch": 2.43970967938683,
      "eval_loss": 0.45130425691604614,
      "eval_runtime": 115.5208,
      "eval_samples_per_second": 1514.03,
      "eval_steps_per_second": 47.316,
      "step": 60000
    },
    {
      "epoch": 2.443775794417224,
      "grad_norm": 0.20139649510383606,
      "learning_rate": 0.00041125569866772894,
      "loss": 0.4025,
      "step": 60100
    },
    {
      "epoch": 2.447841909447618,
      "grad_norm": 0.19560059905052185,
      "learning_rate": 0.00041103439118310984,
      "loss": 0.4042,
      "step": 60200
    },
    {
      "epoch": 2.4519080244780125,
      "grad_norm": 0.2163267731666565,
      "learning_rate": 0.0004108130836984907,
      "loss": 0.4022,
      "step": 60300
    },
    {
      "epoch": 2.455974139508407,
      "grad_norm": 0.1935776174068451,
      "learning_rate": 0.0004105917762138716,
      "loss": 0.4031,
      "step": 60400
    },
    {
      "epoch": 2.460040254538801,
      "grad_norm": 0.2192911058664322,
      "learning_rate": 0.0004103704687292524,
      "loss": 0.4031,
      "step": 60500
    },
    {
      "epoch": 2.464106369569195,
      "grad_norm": 0.21082155406475067,
      "learning_rate": 0.0004101491612446333,
      "loss": 0.4026,
      "step": 60600
    },
    {
      "epoch": 2.4681724845995894,
      "grad_norm": 0.19751393795013428,
      "learning_rate": 0.00040992785376001416,
      "loss": 0.4029,
      "step": 60700
    },
    {
      "epoch": 2.4722385996299834,
      "grad_norm": 0.19605232775211334,
      "learning_rate": 0.00040970654627539506,
      "loss": 0.4019,
      "step": 60800
    },
    {
      "epoch": 2.476304714660378,
      "grad_norm": 0.21509158611297607,
      "learning_rate": 0.0004094852387907759,
      "loss": 0.403,
      "step": 60900
    },
    {
      "epoch": 2.480370829690772,
      "grad_norm": 0.21610727906227112,
      "learning_rate": 0.0004092639313061568,
      "loss": 0.4016,
      "step": 61000
    },
    {
      "epoch": 2.4844369447211663,
      "grad_norm": 0.21504323184490204,
      "learning_rate": 0.0004090426238215377,
      "loss": 0.4047,
      "step": 61100
    },
    {
      "epoch": 2.4885030597515603,
      "grad_norm": 0.1911885142326355,
      "learning_rate": 0.00040882131633691854,
      "loss": 0.4028,
      "step": 61200
    },
    {
      "epoch": 2.4925691747819547,
      "grad_norm": 0.21423566341400146,
      "learning_rate": 0.00040860000885229944,
      "loss": 0.4038,
      "step": 61300
    },
    {
      "epoch": 2.4966352898123487,
      "grad_norm": 0.19003000855445862,
      "learning_rate": 0.00040837870136768023,
      "loss": 0.4026,
      "step": 61400
    },
    {
      "epoch": 2.5007014048427427,
      "grad_norm": 0.21026362478733063,
      "learning_rate": 0.0004081573938830611,
      "loss": 0.4034,
      "step": 61500
    },
    {
      "epoch": 2.504767519873137,
      "grad_norm": 0.20945636928081512,
      "learning_rate": 0.00040793608639844197,
      "loss": 0.4033,
      "step": 61600
    },
    {
      "epoch": 2.5088336349035316,
      "grad_norm": 0.21476492285728455,
      "learning_rate": 0.00040771477891382287,
      "loss": 0.4031,
      "step": 61700
    },
    {
      "epoch": 2.5128997499339256,
      "grad_norm": 0.22338491678237915,
      "learning_rate": 0.0004074934714292037,
      "loss": 0.4023,
      "step": 61800
    },
    {
      "epoch": 2.5169658649643196,
      "grad_norm": 0.1858643889427185,
      "learning_rate": 0.0004072721639445846,
      "loss": 0.4033,
      "step": 61900
    },
    {
      "epoch": 2.521031979994714,
      "grad_norm": 0.1959802508354187,
      "learning_rate": 0.0004070508564599655,
      "loss": 0.4019,
      "step": 62000
    },
    {
      "epoch": 2.521031979994714,
      "eval_loss": 0.45247846841812134,
      "eval_runtime": 115.1988,
      "eval_samples_per_second": 1518.262,
      "eval_steps_per_second": 47.448,
      "step": 62000
    },
    {
      "epoch": 2.5250980950251085,
      "grad_norm": 0.21009497344493866,
      "learning_rate": 0.00040682954897534635,
      "loss": 0.4043,
      "step": 62100
    },
    {
      "epoch": 2.5291642100555025,
      "grad_norm": 0.2030039280653,
      "learning_rate": 0.00040660824149072724,
      "loss": 0.4015,
      "step": 62200
    },
    {
      "epoch": 2.5332303250858965,
      "grad_norm": 0.18870988488197327,
      "learning_rate": 0.0004063869340061081,
      "loss": 0.4023,
      "step": 62300
    },
    {
      "epoch": 2.537296440116291,
      "grad_norm": 0.2089983969926834,
      "learning_rate": 0.000406165626521489,
      "loss": 0.4055,
      "step": 62400
    },
    {
      "epoch": 2.541362555146685,
      "grad_norm": 0.22536323964595795,
      "learning_rate": 0.00040594431903686983,
      "loss": 0.404,
      "step": 62500
    },
    {
      "epoch": 2.5454286701770794,
      "grad_norm": 0.19542300701141357,
      "learning_rate": 0.0004057230115522507,
      "loss": 0.4022,
      "step": 62600
    },
    {
      "epoch": 2.5494947852074734,
      "grad_norm": 0.2042333036661148,
      "learning_rate": 0.00040550170406763157,
      "loss": 0.4027,
      "step": 62700
    },
    {
      "epoch": 2.553560900237868,
      "grad_norm": 0.19417770206928253,
      "learning_rate": 0.00040528039658301246,
      "loss": 0.4026,
      "step": 62800
    },
    {
      "epoch": 2.557627015268262,
      "grad_norm": 0.19885775446891785,
      "learning_rate": 0.00040505908909839336,
      "loss": 0.403,
      "step": 62900
    },
    {
      "epoch": 2.5616931302986563,
      "grad_norm": 0.22337263822555542,
      "learning_rate": 0.00040483778161377415,
      "loss": 0.4044,
      "step": 63000
    },
    {
      "epoch": 2.5657592453290503,
      "grad_norm": 0.19848237931728363,
      "learning_rate": 0.00040461647412915505,
      "loss": 0.4006,
      "step": 63100
    },
    {
      "epoch": 2.5698253603594443,
      "grad_norm": 0.21021653711795807,
      "learning_rate": 0.0004043951666445359,
      "loss": 0.4027,
      "step": 63200
    },
    {
      "epoch": 2.5738914753898388,
      "grad_norm": 0.20413973927497864,
      "learning_rate": 0.0004041738591599168,
      "loss": 0.4022,
      "step": 63300
    },
    {
      "epoch": 2.577957590420233,
      "grad_norm": 0.2062940001487732,
      "learning_rate": 0.00040395255167529763,
      "loss": 0.4032,
      "step": 63400
    },
    {
      "epoch": 2.582023705450627,
      "grad_norm": 0.17817486822605133,
      "learning_rate": 0.00040373124419067853,
      "loss": 0.4015,
      "step": 63500
    },
    {
      "epoch": 2.586089820481021,
      "grad_norm": 0.21110007166862488,
      "learning_rate": 0.00040350993670605937,
      "loss": 0.4034,
      "step": 63600
    },
    {
      "epoch": 2.5901559355114157,
      "grad_norm": 0.24144890904426575,
      "learning_rate": 0.00040328862922144027,
      "loss": 0.4012,
      "step": 63700
    },
    {
      "epoch": 2.59422205054181,
      "grad_norm": 0.20556803047657013,
      "learning_rate": 0.00040306732173682117,
      "loss": 0.4044,
      "step": 63800
    },
    {
      "epoch": 2.598288165572204,
      "grad_norm": 0.2069433480501175,
      "learning_rate": 0.000402846014252202,
      "loss": 0.404,
      "step": 63900
    },
    {
      "epoch": 2.602354280602598,
      "grad_norm": 0.19737617671489716,
      "learning_rate": 0.0004026247067675829,
      "loss": 0.4015,
      "step": 64000
    },
    {
      "epoch": 2.602354280602598,
      "eval_loss": 0.45019644498825073,
      "eval_runtime": 116.182,
      "eval_samples_per_second": 1505.414,
      "eval_steps_per_second": 47.047,
      "step": 64000
    },
    {
      "epoch": 2.6064203956329925,
      "grad_norm": 0.21116699278354645,
      "learning_rate": 0.00040240339928296375,
      "loss": 0.4029,
      "step": 64100
    },
    {
      "epoch": 2.6104865106633866,
      "grad_norm": 0.2263619601726532,
      "learning_rate": 0.00040218209179834465,
      "loss": 0.4036,
      "step": 64200
    },
    {
      "epoch": 2.614552625693781,
      "grad_norm": 0.228434219956398,
      "learning_rate": 0.0004019607843137255,
      "loss": 0.4022,
      "step": 64300
    },
    {
      "epoch": 2.618618740724175,
      "grad_norm": 0.20447391271591187,
      "learning_rate": 0.0004017394768291064,
      "loss": 0.4021,
      "step": 64400
    },
    {
      "epoch": 2.6226848557545694,
      "grad_norm": 0.19799093902111053,
      "learning_rate": 0.0004015181693444873,
      "loss": 0.4032,
      "step": 64500
    },
    {
      "epoch": 2.6267509707849634,
      "grad_norm": 0.20102456212043762,
      "learning_rate": 0.00040129686185986813,
      "loss": 0.4028,
      "step": 64600
    },
    {
      "epoch": 2.630817085815358,
      "grad_norm": 0.20285925269126892,
      "learning_rate": 0.00040107555437524897,
      "loss": 0.4045,
      "step": 64700
    },
    {
      "epoch": 2.634883200845752,
      "grad_norm": 0.22687144577503204,
      "learning_rate": 0.0004008542468906298,
      "loss": 0.3995,
      "step": 64800
    },
    {
      "epoch": 2.638949315876146,
      "grad_norm": 0.19547425210475922,
      "learning_rate": 0.0004006329394060107,
      "loss": 0.3999,
      "step": 64900
    },
    {
      "epoch": 2.6430154309065403,
      "grad_norm": 0.19817499816417694,
      "learning_rate": 0.00040041163192139156,
      "loss": 0.4024,
      "step": 65000
    },
    {
      "epoch": 2.647081545936935,
      "grad_norm": 0.19032175838947296,
      "learning_rate": 0.00040019032443677245,
      "loss": 0.4027,
      "step": 65100
    },
    {
      "epoch": 2.651147660967329,
      "grad_norm": 0.21887566149234772,
      "learning_rate": 0.0003999690169521533,
      "loss": 0.4024,
      "step": 65200
    },
    {
      "epoch": 2.655213775997723,
      "grad_norm": 0.2083883285522461,
      "learning_rate": 0.0003997477094675342,
      "loss": 0.4031,
      "step": 65300
    },
    {
      "epoch": 2.6592798910281172,
      "grad_norm": 0.20371781289577484,
      "learning_rate": 0.0003995264019829151,
      "loss": 0.4029,
      "step": 65400
    },
    {
      "epoch": 2.6633460060585112,
      "grad_norm": 0.20892050862312317,
      "learning_rate": 0.00039930509449829593,
      "loss": 0.4032,
      "step": 65500
    },
    {
      "epoch": 2.6674121210889057,
      "grad_norm": 0.19626092910766602,
      "learning_rate": 0.00039908378701367683,
      "loss": 0.4005,
      "step": 65600
    },
    {
      "epoch": 2.6714782361192997,
      "grad_norm": 0.22439414262771606,
      "learning_rate": 0.0003988624795290577,
      "loss": 0.4021,
      "step": 65700
    },
    {
      "epoch": 2.675544351149694,
      "grad_norm": 0.19434739649295807,
      "learning_rate": 0.00039864117204443857,
      "loss": 0.403,
      "step": 65800
    },
    {
      "epoch": 2.679610466180088,
      "grad_norm": 0.2140137404203415,
      "learning_rate": 0.0003984198645598194,
      "loss": 0.4003,
      "step": 65900
    },
    {
      "epoch": 2.6836765812104826,
      "grad_norm": 0.20885765552520752,
      "learning_rate": 0.0003981985570752003,
      "loss": 0.4034,
      "step": 66000
    },
    {
      "epoch": 2.6836765812104826,
      "eval_loss": 0.44307374954223633,
      "eval_runtime": 114.7051,
      "eval_samples_per_second": 1524.797,
      "eval_steps_per_second": 47.653,
      "step": 66000
    },
    {
      "epoch": 2.6877426962408766,
      "grad_norm": 0.221218079328537,
      "learning_rate": 0.00039797724959058116,
      "loss": 0.4011,
      "step": 66100
    },
    {
      "epoch": 2.691808811271271,
      "grad_norm": 0.20064926147460938,
      "learning_rate": 0.00039775594210596205,
      "loss": 0.4024,
      "step": 66200
    },
    {
      "epoch": 2.695874926301665,
      "grad_norm": 0.21495790779590607,
      "learning_rate": 0.00039753463462134295,
      "loss": 0.3995,
      "step": 66300
    },
    {
      "epoch": 2.6999410413320595,
      "grad_norm": 0.22280235588550568,
      "learning_rate": 0.00039731332713672374,
      "loss": 0.4011,
      "step": 66400
    },
    {
      "epoch": 2.7040071563624535,
      "grad_norm": 0.21957215666770935,
      "learning_rate": 0.00039709201965210464,
      "loss": 0.4024,
      "step": 66500
    },
    {
      "epoch": 2.7080732713928475,
      "grad_norm": 0.21979780495166779,
      "learning_rate": 0.0003968707121674855,
      "loss": 0.4012,
      "step": 66600
    },
    {
      "epoch": 2.712139386423242,
      "grad_norm": 0.20023436844348907,
      "learning_rate": 0.0003966494046828664,
      "loss": 0.4015,
      "step": 66700
    },
    {
      "epoch": 2.7162055014536364,
      "grad_norm": 0.20902946591377258,
      "learning_rate": 0.0003964280971982472,
      "loss": 0.4009,
      "step": 66800
    },
    {
      "epoch": 2.7202716164840304,
      "grad_norm": 0.19481535255908966,
      "learning_rate": 0.0003962067897136281,
      "loss": 0.4022,
      "step": 66900
    },
    {
      "epoch": 2.7243377315144244,
      "grad_norm": 0.19934304058551788,
      "learning_rate": 0.00039598548222900896,
      "loss": 0.4013,
      "step": 67000
    },
    {
      "epoch": 2.728403846544819,
      "grad_norm": 0.205505833029747,
      "learning_rate": 0.00039576417474438986,
      "loss": 0.4004,
      "step": 67100
    },
    {
      "epoch": 2.732469961575213,
      "grad_norm": 0.21889255940914154,
      "learning_rate": 0.00039554286725977075,
      "loss": 0.4013,
      "step": 67200
    },
    {
      "epoch": 2.7365360766056073,
      "grad_norm": 0.20078401267528534,
      "learning_rate": 0.0003953215597751516,
      "loss": 0.402,
      "step": 67300
    },
    {
      "epoch": 2.7406021916360013,
      "grad_norm": 0.22745680809020996,
      "learning_rate": 0.0003951002522905325,
      "loss": 0.4024,
      "step": 67400
    },
    {
      "epoch": 2.7446683066663957,
      "grad_norm": 0.23127131164073944,
      "learning_rate": 0.00039487894480591334,
      "loss": 0.4031,
      "step": 67500
    },
    {
      "epoch": 2.7487344216967897,
      "grad_norm": 0.2017846256494522,
      "learning_rate": 0.00039465763732129424,
      "loss": 0.4026,
      "step": 67600
    },
    {
      "epoch": 2.752800536727184,
      "grad_norm": 0.2145346701145172,
      "learning_rate": 0.0003944363298366751,
      "loss": 0.4013,
      "step": 67700
    },
    {
      "epoch": 2.756866651757578,
      "grad_norm": 0.21111373603343964,
      "learning_rate": 0.000394215022352056,
      "loss": 0.4015,
      "step": 67800
    },
    {
      "epoch": 2.760932766787972,
      "grad_norm": 0.22407199442386627,
      "learning_rate": 0.0003939937148674369,
      "loss": 0.4018,
      "step": 67900
    },
    {
      "epoch": 2.7649988818183666,
      "grad_norm": 0.22048626840114594,
      "learning_rate": 0.0003937724073828177,
      "loss": 0.403,
      "step": 68000
    },
    {
      "epoch": 2.7649988818183666,
      "eval_loss": 0.45478877425193787,
      "eval_runtime": 115.7767,
      "eval_samples_per_second": 1510.684,
      "eval_steps_per_second": 47.212,
      "step": 68000
    },
    {
      "epoch": 2.769064996848761,
      "grad_norm": 0.20324751734733582,
      "learning_rate": 0.00039355109989819856,
      "loss": 0.3999,
      "step": 68100
    },
    {
      "epoch": 2.773131111879155,
      "grad_norm": 0.20141412317752838,
      "learning_rate": 0.0003933297924135794,
      "loss": 0.4024,
      "step": 68200
    },
    {
      "epoch": 2.777197226909549,
      "grad_norm": 0.21138042211532593,
      "learning_rate": 0.0003931084849289603,
      "loss": 0.3992,
      "step": 68300
    },
    {
      "epoch": 2.7812633419399435,
      "grad_norm": 0.22184251248836517,
      "learning_rate": 0.00039288717744434114,
      "loss": 0.4016,
      "step": 68400
    },
    {
      "epoch": 2.785329456970338,
      "grad_norm": 0.23744814097881317,
      "learning_rate": 0.00039266586995972204,
      "loss": 0.401,
      "step": 68500
    },
    {
      "epoch": 2.789395572000732,
      "grad_norm": 0.19355988502502441,
      "learning_rate": 0.0003924445624751029,
      "loss": 0.4036,
      "step": 68600
    },
    {
      "epoch": 2.793461687031126,
      "grad_norm": 0.22477979958057404,
      "learning_rate": 0.0003922232549904838,
      "loss": 0.4019,
      "step": 68700
    },
    {
      "epoch": 2.7975278020615204,
      "grad_norm": 0.21094386279582977,
      "learning_rate": 0.0003920019475058647,
      "loss": 0.4011,
      "step": 68800
    },
    {
      "epoch": 2.8015939170919144,
      "grad_norm": 0.21081461012363434,
      "learning_rate": 0.0003917806400212455,
      "loss": 0.4023,
      "step": 68900
    },
    {
      "epoch": 2.805660032122309,
      "grad_norm": 0.1932348906993866,
      "learning_rate": 0.0003915593325366264,
      "loss": 0.4023,
      "step": 69000
    },
    {
      "epoch": 2.809726147152703,
      "grad_norm": 0.2271660715341568,
      "learning_rate": 0.00039133802505200726,
      "loss": 0.4006,
      "step": 69100
    },
    {
      "epoch": 2.8137922621830973,
      "grad_norm": 0.2252127081155777,
      "learning_rate": 0.00039111671756738816,
      "loss": 0.4018,
      "step": 69200
    },
    {
      "epoch": 2.8178583772134913,
      "grad_norm": 0.19551804661750793,
      "learning_rate": 0.000390895410082769,
      "loss": 0.4016,
      "step": 69300
    },
    {
      "epoch": 2.8219244922438858,
      "grad_norm": 0.2098180204629898,
      "learning_rate": 0.0003906741025981499,
      "loss": 0.4003,
      "step": 69400
    },
    {
      "epoch": 2.8259906072742798,
      "grad_norm": 0.21959969401359558,
      "learning_rate": 0.00039045279511353074,
      "loss": 0.4005,
      "step": 69500
    },
    {
      "epoch": 2.8300567223046738,
      "grad_norm": 0.20016829669475555,
      "learning_rate": 0.00039023148762891164,
      "loss": 0.4007,
      "step": 69600
    },
    {
      "epoch": 2.834122837335068,
      "grad_norm": 0.2467602789402008,
      "learning_rate": 0.00039001018014429254,
      "loss": 0.4021,
      "step": 69700
    },
    {
      "epoch": 2.8381889523654626,
      "grad_norm": 0.2195807248353958,
      "learning_rate": 0.0003897888726596733,
      "loss": 0.4022,
      "step": 69800
    },
    {
      "epoch": 2.8422550673958566,
      "grad_norm": 0.22825515270233154,
      "learning_rate": 0.0003895675651750542,
      "loss": 0.4018,
      "step": 69900
    },
    {
      "epoch": 2.8463211824262507,
      "grad_norm": 0.20065774023532867,
      "learning_rate": 0.00038934625769043507,
      "loss": 0.3994,
      "step": 70000
    },
    {
      "epoch": 2.8463211824262507,
      "eval_loss": 0.44557324051856995,
      "eval_runtime": 115.2052,
      "eval_samples_per_second": 1518.177,
      "eval_steps_per_second": 47.446,
      "step": 70000
    },
    {
      "epoch": 2.850387297456645,
      "grad_norm": 0.21188929677009583,
      "learning_rate": 0.00038912495020581596,
      "loss": 0.4039,
      "step": 70100
    },
    {
      "epoch": 2.854453412487039,
      "grad_norm": 0.210530623793602,
      "learning_rate": 0.0003889036427211968,
      "loss": 0.4007,
      "step": 70200
    },
    {
      "epoch": 2.8585195275174335,
      "grad_norm": 0.23559369146823883,
      "learning_rate": 0.0003886823352365777,
      "loss": 0.4015,
      "step": 70300
    },
    {
      "epoch": 2.8625856425478275,
      "grad_norm": 0.21691632270812988,
      "learning_rate": 0.00038846102775195855,
      "loss": 0.3996,
      "step": 70400
    },
    {
      "epoch": 2.866651757578222,
      "grad_norm": 0.21905070543289185,
      "learning_rate": 0.00038823972026733944,
      "loss": 0.4008,
      "step": 70500
    },
    {
      "epoch": 2.870717872608616,
      "grad_norm": 0.2040892243385315,
      "learning_rate": 0.00038801841278272034,
      "loss": 0.402,
      "step": 70600
    },
    {
      "epoch": 2.8747839876390104,
      "grad_norm": 0.2321806252002716,
      "learning_rate": 0.0003877971052981012,
      "loss": 0.4019,
      "step": 70700
    },
    {
      "epoch": 2.8788501026694044,
      "grad_norm": 0.18856056034564972,
      "learning_rate": 0.0003875757978134821,
      "loss": 0.4018,
      "step": 70800
    },
    {
      "epoch": 2.882916217699799,
      "grad_norm": 0.21973693370819092,
      "learning_rate": 0.0003873544903288629,
      "loss": 0.4016,
      "step": 70900
    },
    {
      "epoch": 2.886982332730193,
      "grad_norm": 0.2109801471233368,
      "learning_rate": 0.0003871331828442438,
      "loss": 0.4028,
      "step": 71000
    },
    {
      "epoch": 2.8910484477605873,
      "grad_norm": 0.23332171142101288,
      "learning_rate": 0.00038691187535962467,
      "loss": 0.399,
      "step": 71100
    },
    {
      "epoch": 2.8951145627909813,
      "grad_norm": 0.2460988163948059,
      "learning_rate": 0.00038669056787500556,
      "loss": 0.4012,
      "step": 71200
    },
    {
      "epoch": 2.8991806778213753,
      "grad_norm": 0.22211724519729614,
      "learning_rate": 0.00038646926039038646,
      "loss": 0.4007,
      "step": 71300
    },
    {
      "epoch": 2.90324679285177,
      "grad_norm": 0.20289728045463562,
      "learning_rate": 0.0003862479529057673,
      "loss": 0.4006,
      "step": 71400
    },
    {
      "epoch": 2.9073129078821642,
      "grad_norm": 0.2193448841571808,
      "learning_rate": 0.00038602664542114815,
      "loss": 0.4029,
      "step": 71500
    },
    {
      "epoch": 2.9113790229125582,
      "grad_norm": 0.2238321751356125,
      "learning_rate": 0.000385805337936529,
      "loss": 0.4027,
      "step": 71600
    },
    {
      "epoch": 2.9154451379429522,
      "grad_norm": 0.21547487378120422,
      "learning_rate": 0.0003855840304519099,
      "loss": 0.3988,
      "step": 71700
    },
    {
      "epoch": 2.9195112529733467,
      "grad_norm": 0.22483348846435547,
      "learning_rate": 0.00038536272296729073,
      "loss": 0.4005,
      "step": 71800
    },
    {
      "epoch": 2.9235773680037407,
      "grad_norm": 0.2323235720396042,
      "learning_rate": 0.00038514141548267163,
      "loss": 0.4004,
      "step": 71900
    },
    {
      "epoch": 2.927643483034135,
      "grad_norm": 0.2153867930173874,
      "learning_rate": 0.00038492010799805247,
      "loss": 0.401,
      "step": 72000
    },
    {
      "epoch": 2.927643483034135,
      "eval_loss": 0.44808176159858704,
      "eval_runtime": 115.0322,
      "eval_samples_per_second": 1520.461,
      "eval_steps_per_second": 47.517,
      "step": 72000
    },
    {
      "epoch": 2.931709598064529,
      "grad_norm": 0.19490709900856018,
      "learning_rate": 0.00038469880051343337,
      "loss": 0.3985,
      "step": 72100
    },
    {
      "epoch": 2.9357757130949236,
      "grad_norm": 0.21257314085960388,
      "learning_rate": 0.00038447749302881427,
      "loss": 0.4003,
      "step": 72200
    },
    {
      "epoch": 2.9398418281253176,
      "grad_norm": 0.21901896595954895,
      "learning_rate": 0.0003842561855441951,
      "loss": 0.4004,
      "step": 72300
    },
    {
      "epoch": 2.943907943155712,
      "grad_norm": 0.22585010528564453,
      "learning_rate": 0.000384034878059576,
      "loss": 0.4016,
      "step": 72400
    },
    {
      "epoch": 2.947974058186106,
      "grad_norm": 0.21171370148658752,
      "learning_rate": 0.00038381357057495685,
      "loss": 0.3988,
      "step": 72500
    },
    {
      "epoch": 2.9520401732165,
      "grad_norm": 0.22528883814811707,
      "learning_rate": 0.00038359226309033775,
      "loss": 0.3998,
      "step": 72600
    },
    {
      "epoch": 2.9561062882468945,
      "grad_norm": 0.23929578065872192,
      "learning_rate": 0.0003833709556057186,
      "loss": 0.4005,
      "step": 72700
    },
    {
      "epoch": 2.960172403277289,
      "grad_norm": 0.2097124606370926,
      "learning_rate": 0.0003831496481210995,
      "loss": 0.4002,
      "step": 72800
    },
    {
      "epoch": 2.964238518307683,
      "grad_norm": 0.21063444018363953,
      "learning_rate": 0.00038292834063648033,
      "loss": 0.399,
      "step": 72900
    },
    {
      "epoch": 2.968304633338077,
      "grad_norm": 0.22118233144283295,
      "learning_rate": 0.00038270703315186123,
      "loss": 0.4003,
      "step": 73000
    },
    {
      "epoch": 2.9723707483684714,
      "grad_norm": 0.2104925960302353,
      "learning_rate": 0.0003824857256672421,
      "loss": 0.4003,
      "step": 73100
    },
    {
      "epoch": 2.976436863398866,
      "grad_norm": 0.23028439283370972,
      "learning_rate": 0.0003822644181826229,
      "loss": 0.3986,
      "step": 73200
    },
    {
      "epoch": 2.98050297842926,
      "grad_norm": 0.24370650947093964,
      "learning_rate": 0.0003820431106980038,
      "loss": 0.4,
      "step": 73300
    },
    {
      "epoch": 2.984569093459654,
      "grad_norm": 0.2224891632795334,
      "learning_rate": 0.00038182180321338465,
      "loss": 0.4001,
      "step": 73400
    },
    {
      "epoch": 2.9886352084900483,
      "grad_norm": 0.26045453548431396,
      "learning_rate": 0.00038160049572876555,
      "loss": 0.3998,
      "step": 73500
    },
    {
      "epoch": 2.9927013235204423,
      "grad_norm": 0.2115888148546219,
      "learning_rate": 0.0003813791882441464,
      "loss": 0.3996,
      "step": 73600
    },
    {
      "epoch": 2.9967674385508367,
      "grad_norm": 0.22742488980293274,
      "learning_rate": 0.0003811578807595273,
      "loss": 0.3978,
      "step": 73700
    },
    {
      "epoch": 3.0008335535812307,
      "grad_norm": 0.20804844796657562,
      "learning_rate": 0.00038093657327490813,
      "loss": 0.4004,
      "step": 73800
    },
    {
      "epoch": 3.004899668611625,
      "grad_norm": 0.22616849839687347,
      "learning_rate": 0.00038071526579028903,
      "loss": 0.399,
      "step": 73900
    },
    {
      "epoch": 3.008965783642019,
      "grad_norm": 0.21751706302165985,
      "learning_rate": 0.00038049395830566993,
      "loss": 0.3976,
      "step": 74000
    },
    {
      "epoch": 3.008965783642019,
      "eval_loss": 0.43822041153907776,
      "eval_runtime": 115.3059,
      "eval_samples_per_second": 1516.852,
      "eval_steps_per_second": 47.404,
      "step": 74000
    },
    {
      "epoch": 3.0130318986724136,
      "grad_norm": 0.21963642537593842,
      "learning_rate": 0.00038027265082105077,
      "loss": 0.3987,
      "step": 74100
    },
    {
      "epoch": 3.0170980137028076,
      "grad_norm": 0.219636008143425,
      "learning_rate": 0.00038005134333643167,
      "loss": 0.4001,
      "step": 74200
    },
    {
      "epoch": 3.021164128733202,
      "grad_norm": 0.2092304676771164,
      "learning_rate": 0.0003798300358518125,
      "loss": 0.3977,
      "step": 74300
    },
    {
      "epoch": 3.025230243763596,
      "grad_norm": 0.22148601710796356,
      "learning_rate": 0.0003796087283671934,
      "loss": 0.3983,
      "step": 74400
    },
    {
      "epoch": 3.02929635879399,
      "grad_norm": 0.24300798773765564,
      "learning_rate": 0.00037938742088257425,
      "loss": 0.3976,
      "step": 74500
    },
    {
      "epoch": 3.0333624738243845,
      "grad_norm": 0.19375695288181305,
      "learning_rate": 0.00037916611339795515,
      "loss": 0.3976,
      "step": 74600
    },
    {
      "epoch": 3.0374285888547785,
      "grad_norm": 0.21067942678928375,
      "learning_rate": 0.00037894480591333605,
      "loss": 0.3983,
      "step": 74700
    },
    {
      "epoch": 3.041494703885173,
      "grad_norm": 0.25197479128837585,
      "learning_rate": 0.00037872349842871684,
      "loss": 0.3968,
      "step": 74800
    },
    {
      "epoch": 3.045560818915567,
      "grad_norm": 0.24721691012382507,
      "learning_rate": 0.00037850219094409773,
      "loss": 0.3995,
      "step": 74900
    },
    {
      "epoch": 3.0496269339459614,
      "grad_norm": 0.20096233487129211,
      "learning_rate": 0.0003782808834594786,
      "loss": 0.397,
      "step": 75000
    },
    {
      "epoch": 3.0536930489763554,
      "grad_norm": 0.22984115779399872,
      "learning_rate": 0.0003780595759748595,
      "loss": 0.3961,
      "step": 75100
    },
    {
      "epoch": 3.05775916400675,
      "grad_norm": 0.22467267513275146,
      "learning_rate": 0.0003778382684902403,
      "loss": 0.3987,
      "step": 75200
    },
    {
      "epoch": 3.061825279037144,
      "grad_norm": 0.24248835444450378,
      "learning_rate": 0.0003776169610056212,
      "loss": 0.3995,
      "step": 75300
    },
    {
      "epoch": 3.0658913940675383,
      "grad_norm": 0.2197420299053192,
      "learning_rate": 0.00037739565352100206,
      "loss": 0.3966,
      "step": 75400
    },
    {
      "epoch": 3.0699575090979323,
      "grad_norm": 0.21086694300174713,
      "learning_rate": 0.00037717434603638296,
      "loss": 0.3984,
      "step": 75500
    },
    {
      "epoch": 3.0740236241283267,
      "grad_norm": 0.21543219685554504,
      "learning_rate": 0.00037695303855176385,
      "loss": 0.397,
      "step": 75600
    },
    {
      "epoch": 3.0780897391587208,
      "grad_norm": 0.21015314757823944,
      "learning_rate": 0.0003767317310671447,
      "loss": 0.3983,
      "step": 75700
    },
    {
      "epoch": 3.082155854189115,
      "grad_norm": 0.21128930151462555,
      "learning_rate": 0.0003765104235825256,
      "loss": 0.3984,
      "step": 75800
    },
    {
      "epoch": 3.086221969219509,
      "grad_norm": 0.22372502088546753,
      "learning_rate": 0.00037628911609790644,
      "loss": 0.3978,
      "step": 75900
    },
    {
      "epoch": 3.0902880842499036,
      "grad_norm": 0.22157692909240723,
      "learning_rate": 0.00037606780861328733,
      "loss": 0.4011,
      "step": 76000
    },
    {
      "epoch": 3.0902880842499036,
      "eval_loss": 0.44336578249931335,
      "eval_runtime": 114.5394,
      "eval_samples_per_second": 1527.003,
      "eval_steps_per_second": 47.722,
      "step": 76000
    },
    {
      "epoch": 3.0943541992802976,
      "grad_norm": 0.21352946758270264,
      "learning_rate": 0.0003758465011286682,
      "loss": 0.3957,
      "step": 76100
    },
    {
      "epoch": 3.0984203143106916,
      "grad_norm": 0.2218306064605713,
      "learning_rate": 0.0003756251936440491,
      "loss": 0.3994,
      "step": 76200
    },
    {
      "epoch": 3.102486429341086,
      "grad_norm": 0.24112558364868164,
      "learning_rate": 0.0003754038861594299,
      "loss": 0.398,
      "step": 76300
    },
    {
      "epoch": 3.10655254437148,
      "grad_norm": 0.22432014346122742,
      "learning_rate": 0.0003751825786748108,
      "loss": 0.4005,
      "step": 76400
    },
    {
      "epoch": 3.1106186594018745,
      "grad_norm": 0.21462062001228333,
      "learning_rate": 0.00037496127119019166,
      "loss": 0.3983,
      "step": 76500
    },
    {
      "epoch": 3.1146847744322685,
      "grad_norm": 0.19831764698028564,
      "learning_rate": 0.0003747399637055725,
      "loss": 0.3999,
      "step": 76600
    },
    {
      "epoch": 3.118750889462663,
      "grad_norm": 0.230667382478714,
      "learning_rate": 0.0003745186562209534,
      "loss": 0.3986,
      "step": 76700
    },
    {
      "epoch": 3.122817004493057,
      "grad_norm": 0.22507616877555847,
      "learning_rate": 0.00037429734873633424,
      "loss": 0.3992,
      "step": 76800
    },
    {
      "epoch": 3.1268831195234514,
      "grad_norm": 0.2445908486843109,
      "learning_rate": 0.00037407604125171514,
      "loss": 0.3999,
      "step": 76900
    },
    {
      "epoch": 3.1309492345538454,
      "grad_norm": 0.23688407242298126,
      "learning_rate": 0.000373854733767096,
      "loss": 0.4005,
      "step": 77000
    },
    {
      "epoch": 3.13501534958424,
      "grad_norm": 0.24830396473407745,
      "learning_rate": 0.0003736334262824769,
      "loss": 0.3985,
      "step": 77100
    },
    {
      "epoch": 3.139081464614634,
      "grad_norm": 0.2462916523218155,
      "learning_rate": 0.0003734121187978577,
      "loss": 0.4002,
      "step": 77200
    },
    {
      "epoch": 3.1431475796450283,
      "grad_norm": 0.2163131982088089,
      "learning_rate": 0.0003731908113132386,
      "loss": 0.3977,
      "step": 77300
    },
    {
      "epoch": 3.1472136946754223,
      "grad_norm": 0.2312283217906952,
      "learning_rate": 0.0003729695038286195,
      "loss": 0.3982,
      "step": 77400
    },
    {
      "epoch": 3.151279809705817,
      "grad_norm": 0.20785513520240784,
      "learning_rate": 0.00037274819634400036,
      "loss": 0.3977,
      "step": 77500
    },
    {
      "epoch": 3.155345924736211,
      "grad_norm": 0.20229649543762207,
      "learning_rate": 0.00037252688885938126,
      "loss": 0.3984,
      "step": 77600
    },
    {
      "epoch": 3.159412039766605,
      "grad_norm": 0.2166094183921814,
      "learning_rate": 0.0003723055813747621,
      "loss": 0.3987,
      "step": 77700
    },
    {
      "epoch": 3.1634781547969992,
      "grad_norm": 0.2089460790157318,
      "learning_rate": 0.000372084273890143,
      "loss": 0.3987,
      "step": 77800
    },
    {
      "epoch": 3.1675442698273932,
      "grad_norm": 0.2328217625617981,
      "learning_rate": 0.00037186296640552384,
      "loss": 0.4017,
      "step": 77900
    },
    {
      "epoch": 3.1716103848577877,
      "grad_norm": 0.23428624868392944,
      "learning_rate": 0.00037164165892090474,
      "loss": 0.399,
      "step": 78000
    },
    {
      "epoch": 3.1716103848577877,
      "eval_loss": 0.4373752474784851,
      "eval_runtime": 116.0108,
      "eval_samples_per_second": 1507.635,
      "eval_steps_per_second": 47.116,
      "step": 78000
    },
    {
      "epoch": 3.1756764998881817,
      "grad_norm": 0.2261817753314972,
      "learning_rate": 0.0003714203514362856,
      "loss": 0.4003,
      "step": 78100
    },
    {
      "epoch": 3.179742614918576,
      "grad_norm": 0.20677222311496735,
      "learning_rate": 0.0003711990439516664,
      "loss": 0.3999,
      "step": 78200
    },
    {
      "epoch": 3.18380872994897,
      "grad_norm": 0.22775466740131378,
      "learning_rate": 0.0003709777364670473,
      "loss": 0.3982,
      "step": 78300
    },
    {
      "epoch": 3.1878748449793646,
      "grad_norm": 0.21132323145866394,
      "learning_rate": 0.00037075642898242817,
      "loss": 0.3995,
      "step": 78400
    },
    {
      "epoch": 3.1919409600097586,
      "grad_norm": 0.22452102601528168,
      "learning_rate": 0.00037053512149780906,
      "loss": 0.3954,
      "step": 78500
    },
    {
      "epoch": 3.196007075040153,
      "grad_norm": 0.2069147527217865,
      "learning_rate": 0.0003703138140131899,
      "loss": 0.3991,
      "step": 78600
    },
    {
      "epoch": 3.200073190070547,
      "grad_norm": 0.2371913492679596,
      "learning_rate": 0.0003700925065285708,
      "loss": 0.3973,
      "step": 78700
    },
    {
      "epoch": 3.2041393051009415,
      "grad_norm": 0.25051066279411316,
      "learning_rate": 0.00036987119904395165,
      "loss": 0.3971,
      "step": 78800
    },
    {
      "epoch": 3.2082054201313355,
      "grad_norm": 0.2195352166891098,
      "learning_rate": 0.00036964989155933254,
      "loss": 0.3994,
      "step": 78900
    },
    {
      "epoch": 3.21227153516173,
      "grad_norm": 0.24454890191555023,
      "learning_rate": 0.00036942858407471344,
      "loss": 0.3977,
      "step": 79000
    },
    {
      "epoch": 3.216337650192124,
      "grad_norm": 0.22308532893657684,
      "learning_rate": 0.0003692072765900943,
      "loss": 0.3988,
      "step": 79100
    },
    {
      "epoch": 3.2204037652225184,
      "grad_norm": 0.21718211472034454,
      "learning_rate": 0.0003689859691054752,
      "loss": 0.3976,
      "step": 79200
    },
    {
      "epoch": 3.2244698802529124,
      "grad_norm": 0.2351120114326477,
      "learning_rate": 0.000368764661620856,
      "loss": 0.3977,
      "step": 79300
    },
    {
      "epoch": 3.2285359952833064,
      "grad_norm": 0.2279558926820755,
      "learning_rate": 0.0003685433541362369,
      "loss": 0.3971,
      "step": 79400
    },
    {
      "epoch": 3.232602110313701,
      "grad_norm": 0.22782829403877258,
      "learning_rate": 0.00036832204665161776,
      "loss": 0.3981,
      "step": 79500
    },
    {
      "epoch": 3.236668225344095,
      "grad_norm": 0.20082299411296844,
      "learning_rate": 0.00036810073916699866,
      "loss": 0.3974,
      "step": 79600
    },
    {
      "epoch": 3.2407343403744893,
      "grad_norm": 0.21869982779026031,
      "learning_rate": 0.0003678794316823795,
      "loss": 0.3968,
      "step": 79700
    },
    {
      "epoch": 3.2448004554048833,
      "grad_norm": 0.22444625198841095,
      "learning_rate": 0.0003676581241977604,
      "loss": 0.3969,
      "step": 79800
    },
    {
      "epoch": 3.2488665704352777,
      "grad_norm": 0.23298406600952148,
      "learning_rate": 0.00036743681671314125,
      "loss": 0.3988,
      "step": 79900
    },
    {
      "epoch": 3.2529326854656717,
      "grad_norm": 0.22772470116615295,
      "learning_rate": 0.0003672155092285221,
      "loss": 0.3978,
      "step": 80000
    },
    {
      "epoch": 3.2529326854656717,
      "eval_loss": 0.4402998685836792,
      "eval_runtime": 114.9233,
      "eval_samples_per_second": 1521.902,
      "eval_steps_per_second": 47.562,
      "step": 80000
    },
    {
      "epoch": 3.256998800496066,
      "grad_norm": 0.2311621904373169,
      "learning_rate": 0.000366994201743903,
      "loss": 0.3972,
      "step": 80100
    },
    {
      "epoch": 3.26106491552646,
      "grad_norm": 0.22497941553592682,
      "learning_rate": 0.00036677289425928383,
      "loss": 0.3977,
      "step": 80200
    },
    {
      "epoch": 3.2651310305568546,
      "grad_norm": 0.22719109058380127,
      "learning_rate": 0.0003665515867746647,
      "loss": 0.3962,
      "step": 80300
    },
    {
      "epoch": 3.2691971455872486,
      "grad_norm": 0.20510618388652802,
      "learning_rate": 0.00036633027929004557,
      "loss": 0.4006,
      "step": 80400
    },
    {
      "epoch": 3.273263260617643,
      "grad_norm": 0.2135077863931656,
      "learning_rate": 0.00036610897180542647,
      "loss": 0.3976,
      "step": 80500
    },
    {
      "epoch": 3.277329375648037,
      "grad_norm": 0.2360115647315979,
      "learning_rate": 0.0003658876643208073,
      "loss": 0.398,
      "step": 80600
    },
    {
      "epoch": 3.281395490678431,
      "grad_norm": 0.22835451364517212,
      "learning_rate": 0.0003656663568361882,
      "loss": 0.3983,
      "step": 80700
    },
    {
      "epoch": 3.2854616057088255,
      "grad_norm": 0.20878750085830688,
      "learning_rate": 0.0003654450493515691,
      "loss": 0.3986,
      "step": 80800
    },
    {
      "epoch": 3.28952772073922,
      "grad_norm": 0.2255656123161316,
      "learning_rate": 0.00036522374186694995,
      "loss": 0.398,
      "step": 80900
    },
    {
      "epoch": 3.293593835769614,
      "grad_norm": 0.21829400956630707,
      "learning_rate": 0.00036500243438233085,
      "loss": 0.3998,
      "step": 81000
    },
    {
      "epoch": 3.297659950800008,
      "grad_norm": 0.25310829281806946,
      "learning_rate": 0.0003647811268977117,
      "loss": 0.398,
      "step": 81100
    },
    {
      "epoch": 3.3017260658304024,
      "grad_norm": 0.2153090387582779,
      "learning_rate": 0.0003645598194130926,
      "loss": 0.401,
      "step": 81200
    },
    {
      "epoch": 3.3057921808607964,
      "grad_norm": 0.21070703864097595,
      "learning_rate": 0.00036433851192847343,
      "loss": 0.3959,
      "step": 81300
    },
    {
      "epoch": 3.309858295891191,
      "grad_norm": 0.22458837926387787,
      "learning_rate": 0.0003641172044438543,
      "loss": 0.4006,
      "step": 81400
    },
    {
      "epoch": 3.313924410921585,
      "grad_norm": 0.2278248369693756,
      "learning_rate": 0.00036389589695923517,
      "loss": 0.3974,
      "step": 81500
    },
    {
      "epoch": 3.3179905259519793,
      "grad_norm": 0.23923614621162415,
      "learning_rate": 0.000363674589474616,
      "loss": 0.3973,
      "step": 81600
    },
    {
      "epoch": 3.3220566409823733,
      "grad_norm": 0.2228403240442276,
      "learning_rate": 0.0003634532819899969,
      "loss": 0.3975,
      "step": 81700
    },
    {
      "epoch": 3.3261227560127677,
      "grad_norm": 0.20904844999313354,
      "learning_rate": 0.00036323197450537775,
      "loss": 0.398,
      "step": 81800
    },
    {
      "epoch": 3.3301888710431617,
      "grad_norm": 0.20628665387630463,
      "learning_rate": 0.00036301066702075865,
      "loss": 0.3982,
      "step": 81900
    },
    {
      "epoch": 3.334254986073556,
      "grad_norm": 0.2740456461906433,
      "learning_rate": 0.0003627893595361395,
      "loss": 0.397,
      "step": 82000
    },
    {
      "epoch": 3.334254986073556,
      "eval_loss": 0.4391574561595917,
      "eval_runtime": 115.1865,
      "eval_samples_per_second": 1518.425,
      "eval_steps_per_second": 47.453,
      "step": 82000
    },
    {
      "epoch": 3.33832110110395,
      "grad_norm": 0.22616887092590332,
      "learning_rate": 0.0003625680520515204,
      "loss": 0.3984,
      "step": 82100
    },
    {
      "epoch": 3.3423872161343446,
      "grad_norm": 0.21967017650604248,
      "learning_rate": 0.00036234674456690123,
      "loss": 0.3951,
      "step": 82200
    },
    {
      "epoch": 3.3464533311647386,
      "grad_norm": 0.23786409199237823,
      "learning_rate": 0.00036212543708228213,
      "loss": 0.397,
      "step": 82300
    },
    {
      "epoch": 3.3505194461951326,
      "grad_norm": 0.21802546083927155,
      "learning_rate": 0.000361904129597663,
      "loss": 0.3989,
      "step": 82400
    },
    {
      "epoch": 3.354585561225527,
      "grad_norm": 0.2254008948802948,
      "learning_rate": 0.00036168282211304387,
      "loss": 0.3966,
      "step": 82500
    },
    {
      "epoch": 3.358651676255921,
      "grad_norm": 0.2374015599489212,
      "learning_rate": 0.00036146151462842477,
      "loss": 0.3976,
      "step": 82600
    },
    {
      "epoch": 3.3627177912863155,
      "grad_norm": 0.2433760017156601,
      "learning_rate": 0.0003612402071438056,
      "loss": 0.4005,
      "step": 82700
    },
    {
      "epoch": 3.3667839063167095,
      "grad_norm": 0.21729305386543274,
      "learning_rate": 0.0003610188996591865,
      "loss": 0.3961,
      "step": 82800
    },
    {
      "epoch": 3.370850021347104,
      "grad_norm": 0.2378968596458435,
      "learning_rate": 0.00036079759217456735,
      "loss": 0.3995,
      "step": 82900
    },
    {
      "epoch": 3.374916136377498,
      "grad_norm": 0.24547737836837769,
      "learning_rate": 0.00036057628468994825,
      "loss": 0.3995,
      "step": 83000
    },
    {
      "epoch": 3.3789822514078924,
      "grad_norm": 0.2533748745918274,
      "learning_rate": 0.0003603549772053291,
      "loss": 0.3974,
      "step": 83100
    },
    {
      "epoch": 3.3830483664382864,
      "grad_norm": 0.228825643658638,
      "learning_rate": 0.00036013366972071,
      "loss": 0.3943,
      "step": 83200
    },
    {
      "epoch": 3.387114481468681,
      "grad_norm": 0.23477770388126373,
      "learning_rate": 0.00035991236223609083,
      "loss": 0.3975,
      "step": 83300
    },
    {
      "epoch": 3.391180596499075,
      "grad_norm": 0.24356666207313538,
      "learning_rate": 0.0003596910547514717,
      "loss": 0.397,
      "step": 83400
    },
    {
      "epoch": 3.3952467115294693,
      "grad_norm": 0.21759594976902008,
      "learning_rate": 0.0003594697472668526,
      "loss": 0.3988,
      "step": 83500
    },
    {
      "epoch": 3.3993128265598633,
      "grad_norm": 0.26741597056388855,
      "learning_rate": 0.0003592484397822334,
      "loss": 0.3955,
      "step": 83600
    },
    {
      "epoch": 3.403378941590258,
      "grad_norm": 0.22010646760463715,
      "learning_rate": 0.0003590271322976143,
      "loss": 0.397,
      "step": 83700
    },
    {
      "epoch": 3.407445056620652,
      "grad_norm": 0.26721882820129395,
      "learning_rate": 0.00035880582481299516,
      "loss": 0.3976,
      "step": 83800
    },
    {
      "epoch": 3.4115111716510462,
      "grad_norm": 0.26108598709106445,
      "learning_rate": 0.00035858451732837605,
      "loss": 0.3964,
      "step": 83900
    },
    {
      "epoch": 3.4155772866814402,
      "grad_norm": 0.2085309624671936,
      "learning_rate": 0.0003583632098437569,
      "loss": 0.3973,
      "step": 84000
    },
    {
      "epoch": 3.4155772866814402,
      "eval_loss": 0.4404836893081665,
      "eval_runtime": 115.121,
      "eval_samples_per_second": 1519.289,
      "eval_steps_per_second": 47.48,
      "step": 84000
    },
    {
      "epoch": 3.4196434017118342,
      "grad_norm": 0.20532278716564178,
      "learning_rate": 0.0003581419023591378,
      "loss": 0.3965,
      "step": 84100
    },
    {
      "epoch": 3.4237095167422287,
      "grad_norm": 0.22837544977664948,
      "learning_rate": 0.0003579205948745187,
      "loss": 0.3955,
      "step": 84200
    },
    {
      "epoch": 3.4277756317726227,
      "grad_norm": 0.2569047510623932,
      "learning_rate": 0.00035769928738989954,
      "loss": 0.3981,
      "step": 84300
    },
    {
      "epoch": 3.431841746803017,
      "grad_norm": 0.25254547595977783,
      "learning_rate": 0.00035747797990528043,
      "loss": 0.3967,
      "step": 84400
    },
    {
      "epoch": 3.435907861833411,
      "grad_norm": 0.22784346342086792,
      "learning_rate": 0.0003572566724206613,
      "loss": 0.395,
      "step": 84500
    },
    {
      "epoch": 3.4399739768638056,
      "grad_norm": 0.23351284861564636,
      "learning_rate": 0.0003570353649360422,
      "loss": 0.397,
      "step": 84600
    },
    {
      "epoch": 3.4440400918941996,
      "grad_norm": 0.2317182719707489,
      "learning_rate": 0.000356814057451423,
      "loss": 0.3955,
      "step": 84700
    },
    {
      "epoch": 3.448106206924594,
      "grad_norm": 0.25107067823410034,
      "learning_rate": 0.0003565927499668039,
      "loss": 0.3966,
      "step": 84800
    },
    {
      "epoch": 3.452172321954988,
      "grad_norm": 0.21086472272872925,
      "learning_rate": 0.00035637144248218476,
      "loss": 0.3943,
      "step": 84900
    },
    {
      "epoch": 3.4562384369853825,
      "grad_norm": 0.22853703796863556,
      "learning_rate": 0.0003561501349975656,
      "loss": 0.3988,
      "step": 85000
    },
    {
      "epoch": 3.4603045520157765,
      "grad_norm": 0.24048171937465668,
      "learning_rate": 0.0003559288275129465,
      "loss": 0.3963,
      "step": 85100
    },
    {
      "epoch": 3.464370667046171,
      "grad_norm": 0.23565144836902618,
      "learning_rate": 0.00035570752002832734,
      "loss": 0.3968,
      "step": 85200
    },
    {
      "epoch": 3.468436782076565,
      "grad_norm": 0.2117065191268921,
      "learning_rate": 0.00035548621254370824,
      "loss": 0.3959,
      "step": 85300
    },
    {
      "epoch": 3.472502897106959,
      "grad_norm": 0.23404641449451447,
      "learning_rate": 0.0003552649050590891,
      "loss": 0.3961,
      "step": 85400
    },
    {
      "epoch": 3.4765690121373534,
      "grad_norm": 0.21584801375865936,
      "learning_rate": 0.00035504359757447,
      "loss": 0.3972,
      "step": 85500
    },
    {
      "epoch": 3.480635127167748,
      "grad_norm": 0.22268903255462646,
      "learning_rate": 0.0003548222900898508,
      "loss": 0.4004,
      "step": 85600
    },
    {
      "epoch": 3.484701242198142,
      "grad_norm": 0.21347077190876007,
      "learning_rate": 0.0003546009826052317,
      "loss": 0.3976,
      "step": 85700
    },
    {
      "epoch": 3.488767357228536,
      "grad_norm": 0.27014297246932983,
      "learning_rate": 0.00035437967512061256,
      "loss": 0.3958,
      "step": 85800
    },
    {
      "epoch": 3.4928334722589303,
      "grad_norm": 0.21676094830036163,
      "learning_rate": 0.00035415836763599346,
      "loss": 0.3969,
      "step": 85900
    },
    {
      "epoch": 3.4968995872893243,
      "grad_norm": 0.22325299680233002,
      "learning_rate": 0.00035393706015137436,
      "loss": 0.3951,
      "step": 86000
    },
    {
      "epoch": 3.4968995872893243,
      "eval_loss": 0.441256046295166,
      "eval_runtime": 114.8267,
      "eval_samples_per_second": 1523.183,
      "eval_steps_per_second": 47.602,
      "step": 86000
    },
    {
      "epoch": 3.5009657023197187,
      "grad_norm": 0.22949229180812836,
      "learning_rate": 0.0003537157526667552,
      "loss": 0.3971,
      "step": 86100
    },
    {
      "epoch": 3.5050318173501127,
      "grad_norm": 0.23601941764354706,
      "learning_rate": 0.0003534944451821361,
      "loss": 0.3972,
      "step": 86200
    },
    {
      "epoch": 3.509097932380507,
      "grad_norm": 0.2260889858007431,
      "learning_rate": 0.00035327313769751694,
      "loss": 0.3965,
      "step": 86300
    },
    {
      "epoch": 3.513164047410901,
      "grad_norm": 0.24184080958366394,
      "learning_rate": 0.00035305183021289784,
      "loss": 0.4016,
      "step": 86400
    },
    {
      "epoch": 3.5172301624412956,
      "grad_norm": 0.22178740799427032,
      "learning_rate": 0.0003528305227282787,
      "loss": 0.3977,
      "step": 86500
    },
    {
      "epoch": 3.5212962774716896,
      "grad_norm": 0.2568581998348236,
      "learning_rate": 0.0003526092152436595,
      "loss": 0.3998,
      "step": 86600
    },
    {
      "epoch": 3.5253623925020836,
      "grad_norm": 0.23992028832435608,
      "learning_rate": 0.0003523879077590404,
      "loss": 0.3989,
      "step": 86700
    },
    {
      "epoch": 3.529428507532478,
      "grad_norm": 0.2487696260213852,
      "learning_rate": 0.00035216660027442126,
      "loss": 0.3985,
      "step": 86800
    },
    {
      "epoch": 3.5334946225628725,
      "grad_norm": 0.2248936891555786,
      "learning_rate": 0.00035194529278980216,
      "loss": 0.3944,
      "step": 86900
    },
    {
      "epoch": 3.5375607375932665,
      "grad_norm": 0.2230139970779419,
      "learning_rate": 0.000351723985305183,
      "loss": 0.3969,
      "step": 87000
    },
    {
      "epoch": 3.5416268526236605,
      "grad_norm": 0.2024313360452652,
      "learning_rate": 0.0003515026778205639,
      "loss": 0.396,
      "step": 87100
    },
    {
      "epoch": 3.545692967654055,
      "grad_norm": 0.24027280509471893,
      "learning_rate": 0.00035128137033594474,
      "loss": 0.3975,
      "step": 87200
    },
    {
      "epoch": 3.5497590826844494,
      "grad_norm": 0.26251712441444397,
      "learning_rate": 0.00035106006285132564,
      "loss": 0.395,
      "step": 87300
    },
    {
      "epoch": 3.5538251977148434,
      "grad_norm": 0.2522057890892029,
      "learning_rate": 0.0003508387553667065,
      "loss": 0.3975,
      "step": 87400
    },
    {
      "epoch": 3.5578913127452374,
      "grad_norm": 0.23863264918327332,
      "learning_rate": 0.0003506174478820874,
      "loss": 0.3968,
      "step": 87500
    },
    {
      "epoch": 3.561957427775632,
      "grad_norm": 0.23752515017986298,
      "learning_rate": 0.0003503961403974683,
      "loss": 0.3977,
      "step": 87600
    },
    {
      "epoch": 3.566023542806026,
      "grad_norm": 0.22336333990097046,
      "learning_rate": 0.0003501748329128491,
      "loss": 0.397,
      "step": 87700
    },
    {
      "epoch": 3.5700896578364203,
      "grad_norm": 0.22587230801582336,
      "learning_rate": 0.00034995352542823,
      "loss": 0.3963,
      "step": 87800
    },
    {
      "epoch": 3.5741557728668143,
      "grad_norm": 0.2487921267747879,
      "learning_rate": 0.00034973221794361086,
      "loss": 0.3971,
      "step": 87900
    },
    {
      "epoch": 3.5782218878972087,
      "grad_norm": 0.23381111025810242,
      "learning_rate": 0.00034951091045899176,
      "loss": 0.3962,
      "step": 88000
    },
    {
      "epoch": 3.5782218878972087,
      "eval_loss": 0.437908411026001,
      "eval_runtime": 115.8893,
      "eval_samples_per_second": 1509.216,
      "eval_steps_per_second": 47.166,
      "step": 88000
    },
    {
      "epoch": 3.5822880029276027,
      "grad_norm": 0.24772046506404877,
      "learning_rate": 0.0003492896029743726,
      "loss": 0.398,
      "step": 88100
    },
    {
      "epoch": 3.586354117957997,
      "grad_norm": 0.23590834438800812,
      "learning_rate": 0.0003490682954897535,
      "loss": 0.3959,
      "step": 88200
    },
    {
      "epoch": 3.590420232988391,
      "grad_norm": 0.22047476470470428,
      "learning_rate": 0.0003488469880051343,
      "loss": 0.3981,
      "step": 88300
    },
    {
      "epoch": 3.594486348018785,
      "grad_norm": 0.2287278175354004,
      "learning_rate": 0.0003486256805205152,
      "loss": 0.3987,
      "step": 88400
    },
    {
      "epoch": 3.5985524630491796,
      "grad_norm": 0.21779431402683258,
      "learning_rate": 0.0003484043730358961,
      "loss": 0.3957,
      "step": 88500
    },
    {
      "epoch": 3.602618578079574,
      "grad_norm": 0.26220256090164185,
      "learning_rate": 0.00034818306555127693,
      "loss": 0.3977,
      "step": 88600
    },
    {
      "epoch": 3.606684693109968,
      "grad_norm": 0.22603701055049896,
      "learning_rate": 0.0003479617580666578,
      "loss": 0.3988,
      "step": 88700
    },
    {
      "epoch": 3.610750808140362,
      "grad_norm": 0.263782262802124,
      "learning_rate": 0.00034774045058203867,
      "loss": 0.3967,
      "step": 88800
    },
    {
      "epoch": 3.6148169231707565,
      "grad_norm": 0.22765344381332397,
      "learning_rate": 0.00034751914309741957,
      "loss": 0.3954,
      "step": 88900
    },
    {
      "epoch": 3.618883038201151,
      "grad_norm": 0.2185765504837036,
      "learning_rate": 0.0003472978356128004,
      "loss": 0.3962,
      "step": 89000
    },
    {
      "epoch": 3.622949153231545,
      "grad_norm": 0.2603181302547455,
      "learning_rate": 0.0003470765281281813,
      "loss": 0.3994,
      "step": 89100
    },
    {
      "epoch": 3.627015268261939,
      "grad_norm": 0.23435674607753754,
      "learning_rate": 0.00034685522064356215,
      "loss": 0.3959,
      "step": 89200
    },
    {
      "epoch": 3.6310813832923334,
      "grad_norm": 0.2607937157154083,
      "learning_rate": 0.00034663391315894305,
      "loss": 0.3967,
      "step": 89300
    },
    {
      "epoch": 3.6351474983227274,
      "grad_norm": 0.25190046429634094,
      "learning_rate": 0.00034641260567432394,
      "loss": 0.3966,
      "step": 89400
    },
    {
      "epoch": 3.639213613353122,
      "grad_norm": 0.23726405203342438,
      "learning_rate": 0.0003461912981897048,
      "loss": 0.3969,
      "step": 89500
    },
    {
      "epoch": 3.643279728383516,
      "grad_norm": 0.20885616540908813,
      "learning_rate": 0.0003459699907050857,
      "loss": 0.395,
      "step": 89600
    },
    {
      "epoch": 3.6473458434139103,
      "grad_norm": 0.23306168615818024,
      "learning_rate": 0.00034574868322046653,
      "loss": 0.3943,
      "step": 89700
    },
    {
      "epoch": 3.6514119584443043,
      "grad_norm": 0.227387472987175,
      "learning_rate": 0.0003455273757358474,
      "loss": 0.3973,
      "step": 89800
    },
    {
      "epoch": 3.6554780734746988,
      "grad_norm": 0.24982406198978424,
      "learning_rate": 0.00034530606825122827,
      "loss": 0.3966,
      "step": 89900
    },
    {
      "epoch": 3.6595441885050928,
      "grad_norm": 0.22592119872570038,
      "learning_rate": 0.0003450847607666091,
      "loss": 0.3944,
      "step": 90000
    },
    {
      "epoch": 3.6595441885050928,
      "eval_loss": 0.4362455904483795,
      "eval_runtime": 114.7718,
      "eval_samples_per_second": 1523.911,
      "eval_steps_per_second": 47.625,
      "step": 90000
    },
    {
      "epoch": 3.663610303535487,
      "grad_norm": 0.22852106392383575,
      "learning_rate": 0.00034486345328198995,
      "loss": 0.3948,
      "step": 90100
    },
    {
      "epoch": 3.6676764185658812,
      "grad_norm": 0.22765187919139862,
      "learning_rate": 0.00034464214579737085,
      "loss": 0.4001,
      "step": 90200
    },
    {
      "epoch": 3.6717425335962757,
      "grad_norm": 0.2098361849784851,
      "learning_rate": 0.00034442083831275175,
      "loss": 0.3958,
      "step": 90300
    },
    {
      "epoch": 3.6758086486266697,
      "grad_norm": 0.25249382853507996,
      "learning_rate": 0.0003441995308281326,
      "loss": 0.3956,
      "step": 90400
    },
    {
      "epoch": 3.6798747636570637,
      "grad_norm": 0.2358839064836502,
      "learning_rate": 0.0003439782233435135,
      "loss": 0.3963,
      "step": 90500
    },
    {
      "epoch": 3.683940878687458,
      "grad_norm": 0.23031726479530334,
      "learning_rate": 0.00034375691585889433,
      "loss": 0.3977,
      "step": 90600
    },
    {
      "epoch": 3.688006993717852,
      "grad_norm": 0.26805856823921204,
      "learning_rate": 0.00034353560837427523,
      "loss": 0.3959,
      "step": 90700
    },
    {
      "epoch": 3.6920731087482466,
      "grad_norm": 0.2689443528652191,
      "learning_rate": 0.00034331430088965607,
      "loss": 0.3964,
      "step": 90800
    },
    {
      "epoch": 3.6961392237786406,
      "grad_norm": 0.21294726431369781,
      "learning_rate": 0.00034309299340503697,
      "loss": 0.3976,
      "step": 90900
    },
    {
      "epoch": 3.700205338809035,
      "grad_norm": 0.23679815232753754,
      "learning_rate": 0.00034287168592041787,
      "loss": 0.3945,
      "step": 91000
    },
    {
      "epoch": 3.704271453839429,
      "grad_norm": 0.26086533069610596,
      "learning_rate": 0.0003426503784357987,
      "loss": 0.395,
      "step": 91100
    },
    {
      "epoch": 3.7083375688698235,
      "grad_norm": 0.23401281237602234,
      "learning_rate": 0.0003424290709511796,
      "loss": 0.3948,
      "step": 91200
    },
    {
      "epoch": 3.7124036839002175,
      "grad_norm": 0.22481240332126617,
      "learning_rate": 0.00034220776346656045,
      "loss": 0.3949,
      "step": 91300
    },
    {
      "epoch": 3.716469798930612,
      "grad_norm": 0.24142326414585114,
      "learning_rate": 0.00034198645598194135,
      "loss": 0.3994,
      "step": 91400
    },
    {
      "epoch": 3.720535913961006,
      "grad_norm": 0.25303441286087036,
      "learning_rate": 0.0003417651484973222,
      "loss": 0.3956,
      "step": 91500
    },
    {
      "epoch": 3.7246020289914004,
      "grad_norm": 0.2652737498283386,
      "learning_rate": 0.0003415438410127031,
      "loss": 0.3983,
      "step": 91600
    },
    {
      "epoch": 3.7286681440217944,
      "grad_norm": 0.24447157979011536,
      "learning_rate": 0.0003413225335280839,
      "loss": 0.3936,
      "step": 91700
    },
    {
      "epoch": 3.7327342590521884,
      "grad_norm": 0.23804056644439697,
      "learning_rate": 0.0003411012260434648,
      "loss": 0.3978,
      "step": 91800
    },
    {
      "epoch": 3.736800374082583,
      "grad_norm": 0.2373138964176178,
      "learning_rate": 0.00034087991855884567,
      "loss": 0.3968,
      "step": 91900
    },
    {
      "epoch": 3.7408664891129773,
      "grad_norm": 0.254049152135849,
      "learning_rate": 0.0003406586110742265,
      "loss": 0.3971,
      "step": 92000
    },
    {
      "epoch": 3.7408664891129773,
      "eval_loss": 0.4377232491970062,
      "eval_runtime": 115.7939,
      "eval_samples_per_second": 1510.46,
      "eval_steps_per_second": 47.205,
      "step": 92000
    },
    {
      "epoch": 3.7449326041433713,
      "grad_norm": 0.23925913870334625,
      "learning_rate": 0.0003404373035896074,
      "loss": 0.396,
      "step": 92100
    },
    {
      "epoch": 3.7489987191737653,
      "grad_norm": 0.2469586580991745,
      "learning_rate": 0.00034021599610498826,
      "loss": 0.3949,
      "step": 92200
    },
    {
      "epoch": 3.7530648342041597,
      "grad_norm": 0.24521464109420776,
      "learning_rate": 0.00033999468862036915,
      "loss": 0.3954,
      "step": 92300
    },
    {
      "epoch": 3.7571309492345537,
      "grad_norm": 0.263725608587265,
      "learning_rate": 0.00033977338113575,
      "loss": 0.3976,
      "step": 92400
    },
    {
      "epoch": 3.761197064264948,
      "grad_norm": 0.23301759362220764,
      "learning_rate": 0.0003395520736511309,
      "loss": 0.3965,
      "step": 92500
    },
    {
      "epoch": 3.765263179295342,
      "grad_norm": 0.24567808210849762,
      "learning_rate": 0.00033933076616651174,
      "loss": 0.3951,
      "step": 92600
    },
    {
      "epoch": 3.7693292943257366,
      "grad_norm": 0.23673757910728455,
      "learning_rate": 0.00033910945868189263,
      "loss": 0.3977,
      "step": 92700
    },
    {
      "epoch": 3.7733954093561306,
      "grad_norm": 0.22055760025978088,
      "learning_rate": 0.00033888815119727353,
      "loss": 0.3961,
      "step": 92800
    },
    {
      "epoch": 3.777461524386525,
      "grad_norm": 0.2496461719274521,
      "learning_rate": 0.0003386668437126544,
      "loss": 0.3962,
      "step": 92900
    },
    {
      "epoch": 3.781527639416919,
      "grad_norm": 0.22528427839279175,
      "learning_rate": 0.00033844553622803527,
      "loss": 0.395,
      "step": 93000
    },
    {
      "epoch": 3.785593754447313,
      "grad_norm": 0.22767682373523712,
      "learning_rate": 0.0003382242287434161,
      "loss": 0.3952,
      "step": 93100
    },
    {
      "epoch": 3.7896598694777075,
      "grad_norm": 0.2508605122566223,
      "learning_rate": 0.000338002921258797,
      "loss": 0.3979,
      "step": 93200
    },
    {
      "epoch": 3.793725984508102,
      "grad_norm": 0.24931810796260834,
      "learning_rate": 0.00033778161377417786,
      "loss": 0.3966,
      "step": 93300
    },
    {
      "epoch": 3.797792099538496,
      "grad_norm": 0.2342595010995865,
      "learning_rate": 0.0003375603062895587,
      "loss": 0.3952,
      "step": 93400
    },
    {
      "epoch": 3.80185821456889,
      "grad_norm": 0.22758780419826508,
      "learning_rate": 0.00033733899880493954,
      "loss": 0.3957,
      "step": 93500
    },
    {
      "epoch": 3.8059243295992844,
      "grad_norm": 0.23652935028076172,
      "learning_rate": 0.00033711769132032044,
      "loss": 0.3959,
      "step": 93600
    },
    {
      "epoch": 3.809990444629679,
      "grad_norm": 0.2473151683807373,
      "learning_rate": 0.00033689638383570134,
      "loss": 0.3945,
      "step": 93700
    },
    {
      "epoch": 3.814056559660073,
      "grad_norm": 0.2593778371810913,
      "learning_rate": 0.0003366750763510822,
      "loss": 0.3957,
      "step": 93800
    },
    {
      "epoch": 3.818122674690467,
      "grad_norm": 0.27139812707901,
      "learning_rate": 0.0003364537688664631,
      "loss": 0.3962,
      "step": 93900
    },
    {
      "epoch": 3.8221887897208613,
      "grad_norm": 0.23543161153793335,
      "learning_rate": 0.0003362324613818439,
      "loss": 0.3948,
      "step": 94000
    },
    {
      "epoch": 3.8221887897208613,
      "eval_loss": 0.43984076380729675,
      "eval_runtime": 114.8417,
      "eval_samples_per_second": 1522.984,
      "eval_steps_per_second": 47.596,
      "step": 94000
    },
    {
      "epoch": 3.8262549047512553,
      "grad_norm": 0.22715860605239868,
      "learning_rate": 0.0003360111538972248,
      "loss": 0.397,
      "step": 94100
    },
    {
      "epoch": 3.8303210197816497,
      "grad_norm": 0.23810261487960815,
      "learning_rate": 0.00033578984641260566,
      "loss": 0.3965,
      "step": 94200
    },
    {
      "epoch": 3.8343871348120437,
      "grad_norm": 0.24043050408363342,
      "learning_rate": 0.00033556853892798656,
      "loss": 0.3945,
      "step": 94300
    },
    {
      "epoch": 3.838453249842438,
      "grad_norm": 0.25137412548065186,
      "learning_rate": 0.00033534723144336745,
      "loss": 0.3935,
      "step": 94400
    },
    {
      "epoch": 3.842519364872832,
      "grad_norm": 0.2529657483100891,
      "learning_rate": 0.0003351259239587483,
      "loss": 0.3961,
      "step": 94500
    },
    {
      "epoch": 3.8465854799032266,
      "grad_norm": 0.2558858394622803,
      "learning_rate": 0.0003349046164741292,
      "loss": 0.3941,
      "step": 94600
    },
    {
      "epoch": 3.8506515949336206,
      "grad_norm": 0.25626760721206665,
      "learning_rate": 0.00033468330898951004,
      "loss": 0.3983,
      "step": 94700
    },
    {
      "epoch": 3.8547177099640146,
      "grad_norm": 0.23762652277946472,
      "learning_rate": 0.00033446200150489094,
      "loss": 0.3932,
      "step": 94800
    },
    {
      "epoch": 3.858783824994409,
      "grad_norm": 0.253703773021698,
      "learning_rate": 0.0003342406940202718,
      "loss": 0.3948,
      "step": 94900
    },
    {
      "epoch": 3.8628499400248035,
      "grad_norm": 0.26411184668540955,
      "learning_rate": 0.0003340193865356527,
      "loss": 0.3955,
      "step": 95000
    },
    {
      "epoch": 3.8669160550551975,
      "grad_norm": 0.23567956686019897,
      "learning_rate": 0.00033379807905103346,
      "loss": 0.3964,
      "step": 95100
    },
    {
      "epoch": 3.8709821700855915,
      "grad_norm": 0.24016544222831726,
      "learning_rate": 0.00033357677156641436,
      "loss": 0.3924,
      "step": 95200
    },
    {
      "epoch": 3.875048285115986,
      "grad_norm": 0.22734464704990387,
      "learning_rate": 0.00033335546408179526,
      "loss": 0.3935,
      "step": 95300
    },
    {
      "epoch": 3.87911440014638,
      "grad_norm": 0.24865520000457764,
      "learning_rate": 0.0003331341565971761,
      "loss": 0.3919,
      "step": 95400
    },
    {
      "epoch": 3.8831805151767744,
      "grad_norm": 0.23883792757987976,
      "learning_rate": 0.000332912849112557,
      "loss": 0.3954,
      "step": 95500
    },
    {
      "epoch": 3.8872466302071684,
      "grad_norm": 0.25652414560317993,
      "learning_rate": 0.00033269154162793784,
      "loss": 0.3947,
      "step": 95600
    },
    {
      "epoch": 3.891312745237563,
      "grad_norm": 0.23525084555149078,
      "learning_rate": 0.00033247023414331874,
      "loss": 0.3934,
      "step": 95700
    },
    {
      "epoch": 3.895378860267957,
      "grad_norm": 0.2676992118358612,
      "learning_rate": 0.0003322489266586996,
      "loss": 0.3946,
      "step": 95800
    },
    {
      "epoch": 3.8994449752983513,
      "grad_norm": 0.27198612689971924,
      "learning_rate": 0.0003320276191740805,
      "loss": 0.3938,
      "step": 95900
    },
    {
      "epoch": 3.9035110903287453,
      "grad_norm": 0.23690487444400787,
      "learning_rate": 0.0003318063116894613,
      "loss": 0.394,
      "step": 96000
    },
    {
      "epoch": 3.9035110903287453,
      "eval_loss": 0.43429893255233765,
      "eval_runtime": 114.8596,
      "eval_samples_per_second": 1522.746,
      "eval_steps_per_second": 47.589,
      "step": 96000
    },
    {
      "epoch": 3.9075772053591398,
      "grad_norm": 0.26549145579338074,
      "learning_rate": 0.0003315850042048422,
      "loss": 0.3947,
      "step": 96100
    },
    {
      "epoch": 3.9116433203895338,
      "grad_norm": 0.2447892129421234,
      "learning_rate": 0.0003313636967202231,
      "loss": 0.3956,
      "step": 96200
    },
    {
      "epoch": 3.915709435419928,
      "grad_norm": 0.22061699628829956,
      "learning_rate": 0.00033114238923560396,
      "loss": 0.3915,
      "step": 96300
    },
    {
      "epoch": 3.919775550450322,
      "grad_norm": 0.218787282705307,
      "learning_rate": 0.00033092108175098486,
      "loss": 0.3939,
      "step": 96400
    },
    {
      "epoch": 3.9238416654807162,
      "grad_norm": 0.24879641830921173,
      "learning_rate": 0.0003306997742663657,
      "loss": 0.3958,
      "step": 96500
    },
    {
      "epoch": 3.9279077805111107,
      "grad_norm": 0.24318982660770416,
      "learning_rate": 0.0003304784667817466,
      "loss": 0.3934,
      "step": 96600
    },
    {
      "epoch": 3.931973895541505,
      "grad_norm": 0.24154052138328552,
      "learning_rate": 0.00033025715929712744,
      "loss": 0.3947,
      "step": 96700
    },
    {
      "epoch": 3.936040010571899,
      "grad_norm": 0.23355787992477417,
      "learning_rate": 0.0003300358518125083,
      "loss": 0.3952,
      "step": 96800
    },
    {
      "epoch": 3.940106125602293,
      "grad_norm": 0.2453259974718094,
      "learning_rate": 0.00032981454432788913,
      "loss": 0.3947,
      "step": 96900
    },
    {
      "epoch": 3.9441722406326876,
      "grad_norm": 0.22811654210090637,
      "learning_rate": 0.00032959323684327,
      "loss": 0.3914,
      "step": 97000
    },
    {
      "epoch": 3.9482383556630816,
      "grad_norm": 0.26573270559310913,
      "learning_rate": 0.0003293719293586509,
      "loss": 0.3955,
      "step": 97100
    },
    {
      "epoch": 3.952304470693476,
      "grad_norm": 0.23486043512821198,
      "learning_rate": 0.00032915062187403177,
      "loss": 0.3958,
      "step": 97200
    },
    {
      "epoch": 3.95637058572387,
      "grad_norm": 0.22893263399600983,
      "learning_rate": 0.00032892931438941266,
      "loss": 0.3968,
      "step": 97300
    },
    {
      "epoch": 3.9604367007542645,
      "grad_norm": 0.25417575240135193,
      "learning_rate": 0.0003287080069047935,
      "loss": 0.3951,
      "step": 97400
    },
    {
      "epoch": 3.9645028157846585,
      "grad_norm": 0.23918934166431427,
      "learning_rate": 0.0003284866994201744,
      "loss": 0.3939,
      "step": 97500
    },
    {
      "epoch": 3.968568930815053,
      "grad_norm": 0.2237841933965683,
      "learning_rate": 0.00032826539193555525,
      "loss": 0.3959,
      "step": 97600
    },
    {
      "epoch": 3.972635045845447,
      "grad_norm": 0.26583436131477356,
      "learning_rate": 0.00032804408445093614,
      "loss": 0.3971,
      "step": 97700
    },
    {
      "epoch": 3.976701160875841,
      "grad_norm": 0.29027071595191956,
      "learning_rate": 0.00032782277696631704,
      "loss": 0.3945,
      "step": 97800
    },
    {
      "epoch": 3.9807672759062354,
      "grad_norm": 0.27160143852233887,
      "learning_rate": 0.0003276014694816979,
      "loss": 0.3937,
      "step": 97900
    },
    {
      "epoch": 3.98483339093663,
      "grad_norm": 0.24194563925266266,
      "learning_rate": 0.0003273801619970788,
      "loss": 0.3952,
      "step": 98000
    },
    {
      "epoch": 3.98483339093663,
      "eval_loss": 0.42932015657424927,
      "eval_runtime": 115.0171,
      "eval_samples_per_second": 1520.661,
      "eval_steps_per_second": 47.523,
      "step": 98000
    },
    {
      "epoch": 3.988899505967024,
      "grad_norm": 0.23573049902915955,
      "learning_rate": 0.0003271588545124596,
      "loss": 0.3955,
      "step": 98100
    },
    {
      "epoch": 3.992965620997418,
      "grad_norm": 0.27804210782051086,
      "learning_rate": 0.0003269375470278405,
      "loss": 0.3941,
      "step": 98200
    },
    {
      "epoch": 3.9970317360278123,
      "grad_norm": 0.2656119167804718,
      "learning_rate": 0.00032671623954322137,
      "loss": 0.3939,
      "step": 98300
    },
    {
      "epoch": 4.001097851058207,
      "grad_norm": 0.2649715542793274,
      "learning_rate": 0.00032649493205860226,
      "loss": 0.3946,
      "step": 98400
    },
    {
      "epoch": 4.005163966088601,
      "grad_norm": 0.2596368193626404,
      "learning_rate": 0.00032627362457398305,
      "loss": 0.3933,
      "step": 98500
    },
    {
      "epoch": 4.009230081118995,
      "grad_norm": 0.25167617201805115,
      "learning_rate": 0.00032605231708936395,
      "loss": 0.3924,
      "step": 98600
    },
    {
      "epoch": 4.013296196149389,
      "grad_norm": 0.2590992748737335,
      "learning_rate": 0.00032583100960474485,
      "loss": 0.392,
      "step": 98700
    },
    {
      "epoch": 4.017362311179784,
      "grad_norm": 0.22960105538368225,
      "learning_rate": 0.0003256097021201257,
      "loss": 0.3969,
      "step": 98800
    },
    {
      "epoch": 4.021428426210178,
      "grad_norm": 0.27661317586898804,
      "learning_rate": 0.0003253883946355066,
      "loss": 0.3934,
      "step": 98900
    },
    {
      "epoch": 4.025494541240572,
      "grad_norm": 0.25277140736579895,
      "learning_rate": 0.00032516708715088743,
      "loss": 0.3913,
      "step": 99000
    },
    {
      "epoch": 4.029560656270966,
      "grad_norm": 0.22330595552921295,
      "learning_rate": 0.00032494577966626833,
      "loss": 0.3947,
      "step": 99100
    },
    {
      "epoch": 4.0336267713013605,
      "grad_norm": 0.2601206600666046,
      "learning_rate": 0.00032472447218164917,
      "loss": 0.3935,
      "step": 99200
    },
    {
      "epoch": 4.0376928863317545,
      "grad_norm": 0.23572322726249695,
      "learning_rate": 0.00032450316469703007,
      "loss": 0.3917,
      "step": 99300
    },
    {
      "epoch": 4.0417590013621485,
      "grad_norm": 0.22971011698246002,
      "learning_rate": 0.0003242818572124109,
      "loss": 0.3962,
      "step": 99400
    },
    {
      "epoch": 4.0458251163925425,
      "grad_norm": 0.2366645783185959,
      "learning_rate": 0.0003240605497277918,
      "loss": 0.396,
      "step": 99500
    },
    {
      "epoch": 4.049891231422937,
      "grad_norm": 0.23343151807785034,
      "learning_rate": 0.0003238392422431727,
      "loss": 0.393,
      "step": 99600
    },
    {
      "epoch": 4.053957346453331,
      "grad_norm": 0.22713999450206757,
      "learning_rate": 0.00032361793475855355,
      "loss": 0.3963,
      "step": 99700
    },
    {
      "epoch": 4.058023461483725,
      "grad_norm": 0.23037730157375336,
      "learning_rate": 0.00032339662727393445,
      "loss": 0.3918,
      "step": 99800
    },
    {
      "epoch": 4.062089576514119,
      "grad_norm": 0.25817301869392395,
      "learning_rate": 0.0003231753197893153,
      "loss": 0.3949,
      "step": 99900
    },
    {
      "epoch": 4.066155691544513,
      "grad_norm": 0.2477005124092102,
      "learning_rate": 0.0003229540123046962,
      "loss": 0.3953,
      "step": 100000
    },
    {
      "epoch": 4.066155691544513,
      "eval_loss": 0.438430517911911,
      "eval_runtime": 114.7277,
      "eval_samples_per_second": 1524.497,
      "eval_steps_per_second": 47.643,
      "step": 100000
    },
    {
      "epoch": 4.070221806574908,
      "grad_norm": 0.2517576515674591,
      "learning_rate": 0.000322732704820077,
      "loss": 0.3923,
      "step": 100100
    },
    {
      "epoch": 4.074287921605302,
      "grad_norm": 0.24385540187358856,
      "learning_rate": 0.0003225113973354579,
      "loss": 0.3915,
      "step": 100200
    },
    {
      "epoch": 4.078354036635696,
      "grad_norm": 0.2595002353191376,
      "learning_rate": 0.0003222900898508387,
      "loss": 0.3939,
      "step": 100300
    },
    {
      "epoch": 4.08242015166609,
      "grad_norm": 0.23163416981697083,
      "learning_rate": 0.0003220687823662196,
      "loss": 0.3954,
      "step": 100400
    },
    {
      "epoch": 4.086486266696485,
      "grad_norm": 0.22915148735046387,
      "learning_rate": 0.0003218474748816005,
      "loss": 0.3932,
      "step": 100500
    },
    {
      "epoch": 4.090552381726879,
      "grad_norm": 0.24447114765644073,
      "learning_rate": 0.00032162616739698135,
      "loss": 0.3929,
      "step": 100600
    },
    {
      "epoch": 4.094618496757273,
      "grad_norm": 0.23451784253120422,
      "learning_rate": 0.00032140485991236225,
      "loss": 0.394,
      "step": 100700
    },
    {
      "epoch": 4.098684611787667,
      "grad_norm": 0.24711982905864716,
      "learning_rate": 0.0003211835524277431,
      "loss": 0.3929,
      "step": 100800
    },
    {
      "epoch": 4.102750726818062,
      "grad_norm": 0.253917396068573,
      "learning_rate": 0.000320962244943124,
      "loss": 0.3924,
      "step": 100900
    },
    {
      "epoch": 4.106816841848456,
      "grad_norm": 0.2663743197917938,
      "learning_rate": 0.00032074093745850484,
      "loss": 0.395,
      "step": 101000
    },
    {
      "epoch": 4.11088295687885,
      "grad_norm": 0.2594830393791199,
      "learning_rate": 0.00032051962997388573,
      "loss": 0.3959,
      "step": 101100
    },
    {
      "epoch": 4.114949071909244,
      "grad_norm": 0.2530764937400818,
      "learning_rate": 0.0003202983224892666,
      "loss": 0.3917,
      "step": 101200
    },
    {
      "epoch": 4.119015186939638,
      "grad_norm": 0.23361293971538544,
      "learning_rate": 0.00032007701500464747,
      "loss": 0.393,
      "step": 101300
    },
    {
      "epoch": 4.123081301970033,
      "grad_norm": 0.24407686293125153,
      "learning_rate": 0.00031985570752002837,
      "loss": 0.3934,
      "step": 101400
    },
    {
      "epoch": 4.127147417000427,
      "grad_norm": 0.22057077288627625,
      "learning_rate": 0.0003196344000354092,
      "loss": 0.393,
      "step": 101500
    },
    {
      "epoch": 4.131213532030821,
      "grad_norm": 0.24607083201408386,
      "learning_rate": 0.0003194130925507901,
      "loss": 0.3939,
      "step": 101600
    },
    {
      "epoch": 4.135279647061215,
      "grad_norm": 0.22963577508926392,
      "learning_rate": 0.00031919178506617095,
      "loss": 0.3925,
      "step": 101700
    },
    {
      "epoch": 4.13934576209161,
      "grad_norm": 0.2654676139354706,
      "learning_rate": 0.0003189704775815518,
      "loss": 0.3955,
      "step": 101800
    },
    {
      "epoch": 4.143411877122004,
      "grad_norm": 0.26656782627105713,
      "learning_rate": 0.00031874917009693264,
      "loss": 0.3943,
      "step": 101900
    },
    {
      "epoch": 4.147477992152398,
      "grad_norm": 0.2544730603694916,
      "learning_rate": 0.00031852786261231354,
      "loss": 0.3912,
      "step": 102000
    },
    {
      "epoch": 4.147477992152398,
      "eval_loss": 0.44021353125572205,
      "eval_runtime": 115.9849,
      "eval_samples_per_second": 1507.972,
      "eval_steps_per_second": 47.127,
      "step": 102000
    },
    {
      "epoch": 4.151544107182792,
      "grad_norm": 0.2344752699136734,
      "learning_rate": 0.00031830655512769443,
      "loss": 0.3938,
      "step": 102100
    },
    {
      "epoch": 4.155610222213187,
      "grad_norm": 0.2705771028995514,
      "learning_rate": 0.0003180852476430753,
      "loss": 0.3942,
      "step": 102200
    },
    {
      "epoch": 4.159676337243581,
      "grad_norm": 0.2835954427719116,
      "learning_rate": 0.0003178639401584562,
      "loss": 0.3929,
      "step": 102300
    },
    {
      "epoch": 4.163742452273975,
      "grad_norm": 0.24852396547794342,
      "learning_rate": 0.000317642632673837,
      "loss": 0.393,
      "step": 102400
    },
    {
      "epoch": 4.167808567304369,
      "grad_norm": 0.24117757380008698,
      "learning_rate": 0.0003174213251892179,
      "loss": 0.3913,
      "step": 102500
    },
    {
      "epoch": 4.171874682334764,
      "grad_norm": 0.27413123846054077,
      "learning_rate": 0.00031720001770459876,
      "loss": 0.3917,
      "step": 102600
    },
    {
      "epoch": 4.175940797365158,
      "grad_norm": 0.2542276382446289,
      "learning_rate": 0.00031697871021997966,
      "loss": 0.3918,
      "step": 102700
    },
    {
      "epoch": 4.180006912395552,
      "grad_norm": 0.24465441703796387,
      "learning_rate": 0.0003167574027353605,
      "loss": 0.393,
      "step": 102800
    },
    {
      "epoch": 4.184073027425946,
      "grad_norm": 0.2566421627998352,
      "learning_rate": 0.0003165360952507414,
      "loss": 0.3955,
      "step": 102900
    },
    {
      "epoch": 4.18813914245634,
      "grad_norm": 0.2596305012702942,
      "learning_rate": 0.0003163147877661223,
      "loss": 0.3922,
      "step": 103000
    },
    {
      "epoch": 4.192205257486735,
      "grad_norm": 0.2584192752838135,
      "learning_rate": 0.00031609348028150314,
      "loss": 0.3954,
      "step": 103100
    },
    {
      "epoch": 4.196271372517129,
      "grad_norm": 0.2261662632226944,
      "learning_rate": 0.00031587217279688403,
      "loss": 0.3943,
      "step": 103200
    },
    {
      "epoch": 4.200337487547523,
      "grad_norm": 0.2626812756061554,
      "learning_rate": 0.0003156508653122649,
      "loss": 0.3897,
      "step": 103300
    },
    {
      "epoch": 4.204403602577917,
      "grad_norm": 0.24255026876926422,
      "learning_rate": 0.0003154295578276458,
      "loss": 0.392,
      "step": 103400
    },
    {
      "epoch": 4.2084697176083115,
      "grad_norm": 0.2419266700744629,
      "learning_rate": 0.00031520825034302656,
      "loss": 0.3929,
      "step": 103500
    },
    {
      "epoch": 4.2125358326387055,
      "grad_norm": 0.2641991972923279,
      "learning_rate": 0.00031498694285840746,
      "loss": 0.3914,
      "step": 103600
    },
    {
      "epoch": 4.2166019476690995,
      "grad_norm": 0.2615331709384918,
      "learning_rate": 0.0003147656353737883,
      "loss": 0.3905,
      "step": 103700
    },
    {
      "epoch": 4.2206680626994935,
      "grad_norm": 0.24509665369987488,
      "learning_rate": 0.0003145443278891692,
      "loss": 0.3936,
      "step": 103800
    },
    {
      "epoch": 4.224734177729888,
      "grad_norm": 0.2163834273815155,
      "learning_rate": 0.0003143230204045501,
      "loss": 0.3939,
      "step": 103900
    },
    {
      "epoch": 4.228800292760282,
      "grad_norm": 0.2266758382320404,
      "learning_rate": 0.00031410171291993094,
      "loss": 0.3942,
      "step": 104000
    },
    {
      "epoch": 4.228800292760282,
      "eval_loss": 0.43236252665519714,
      "eval_runtime": 114.9856,
      "eval_samples_per_second": 1521.077,
      "eval_steps_per_second": 47.536,
      "step": 104000
    },
    {
      "epoch": 4.232866407790676,
      "grad_norm": 0.2742578983306885,
      "learning_rate": 0.00031388040543531184,
      "loss": 0.3934,
      "step": 104100
    },
    {
      "epoch": 4.23693252282107,
      "grad_norm": 0.248498797416687,
      "learning_rate": 0.0003136590979506927,
      "loss": 0.3943,
      "step": 104200
    },
    {
      "epoch": 4.240998637851465,
      "grad_norm": 0.2700386345386505,
      "learning_rate": 0.0003134377904660736,
      "loss": 0.395,
      "step": 104300
    },
    {
      "epoch": 4.245064752881859,
      "grad_norm": 0.2326725274324417,
      "learning_rate": 0.0003132164829814544,
      "loss": 0.3938,
      "step": 104400
    },
    {
      "epoch": 4.249130867912253,
      "grad_norm": 0.23092861473560333,
      "learning_rate": 0.0003129951754968353,
      "loss": 0.3919,
      "step": 104500
    },
    {
      "epoch": 4.253196982942647,
      "grad_norm": 0.22194355726242065,
      "learning_rate": 0.00031277386801221616,
      "loss": 0.394,
      "step": 104600
    },
    {
      "epoch": 4.257263097973041,
      "grad_norm": 0.25693947076797485,
      "learning_rate": 0.00031255256052759706,
      "loss": 0.3935,
      "step": 104700
    },
    {
      "epoch": 4.261329213003436,
      "grad_norm": 0.24628719687461853,
      "learning_rate": 0.00031233125304297796,
      "loss": 0.391,
      "step": 104800
    },
    {
      "epoch": 4.26539532803383,
      "grad_norm": 0.28740572929382324,
      "learning_rate": 0.0003121099455583588,
      "loss": 0.3929,
      "step": 104900
    },
    {
      "epoch": 4.269461443064224,
      "grad_norm": 0.23257087171077728,
      "learning_rate": 0.0003118886380737397,
      "loss": 0.3946,
      "step": 105000
    },
    {
      "epoch": 4.273527558094618,
      "grad_norm": 0.25668269395828247,
      "learning_rate": 0.00031166733058912054,
      "loss": 0.3935,
      "step": 105100
    },
    {
      "epoch": 4.277593673125013,
      "grad_norm": 0.2661014795303345,
      "learning_rate": 0.0003114460231045014,
      "loss": 0.3928,
      "step": 105200
    },
    {
      "epoch": 4.281659788155407,
      "grad_norm": 0.2396858185529709,
      "learning_rate": 0.00031122471561988223,
      "loss": 0.393,
      "step": 105300
    },
    {
      "epoch": 4.285725903185801,
      "grad_norm": 0.27019888162612915,
      "learning_rate": 0.0003110034081352631,
      "loss": 0.3917,
      "step": 105400
    },
    {
      "epoch": 4.289792018216195,
      "grad_norm": 0.2721758484840393,
      "learning_rate": 0.000310782100650644,
      "loss": 0.3896,
      "step": 105500
    },
    {
      "epoch": 4.29385813324659,
      "grad_norm": 0.24301226437091827,
      "learning_rate": 0.00031056079316602487,
      "loss": 0.392,
      "step": 105600
    },
    {
      "epoch": 4.297924248276984,
      "grad_norm": 0.276118665933609,
      "learning_rate": 0.00031033948568140576,
      "loss": 0.3921,
      "step": 105700
    },
    {
      "epoch": 4.301990363307378,
      "grad_norm": 0.2552901804447174,
      "learning_rate": 0.0003101181781967866,
      "loss": 0.3929,
      "step": 105800
    },
    {
      "epoch": 4.306056478337772,
      "grad_norm": 0.28010764718055725,
      "learning_rate": 0.0003098968707121675,
      "loss": 0.394,
      "step": 105900
    },
    {
      "epoch": 4.310122593368167,
      "grad_norm": 0.27749204635620117,
      "learning_rate": 0.00030967556322754835,
      "loss": 0.3935,
      "step": 106000
    },
    {
      "epoch": 4.310122593368167,
      "eval_loss": 0.43530207872390747,
      "eval_runtime": 115.8077,
      "eval_samples_per_second": 1510.279,
      "eval_steps_per_second": 47.199,
      "step": 106000
    },
    {
      "epoch": 4.314188708398561,
      "grad_norm": 0.2488134354352951,
      "learning_rate": 0.00030945425574292924,
      "loss": 0.3938,
      "step": 106100
    },
    {
      "epoch": 4.318254823428955,
      "grad_norm": 0.2637314200401306,
      "learning_rate": 0.0003092329482583101,
      "loss": 0.394,
      "step": 106200
    },
    {
      "epoch": 4.322320938459349,
      "grad_norm": 0.2569512128829956,
      "learning_rate": 0.000309011640773691,
      "loss": 0.3908,
      "step": 106300
    },
    {
      "epoch": 4.326387053489743,
      "grad_norm": 0.24101032316684723,
      "learning_rate": 0.0003087903332890719,
      "loss": 0.3895,
      "step": 106400
    },
    {
      "epoch": 4.330453168520138,
      "grad_norm": 0.24999059736728668,
      "learning_rate": 0.0003085690258044527,
      "loss": 0.3916,
      "step": 106500
    },
    {
      "epoch": 4.334519283550532,
      "grad_norm": 0.3086279034614563,
      "learning_rate": 0.0003083477183198336,
      "loss": 0.3908,
      "step": 106600
    },
    {
      "epoch": 4.338585398580926,
      "grad_norm": 0.2465122491121292,
      "learning_rate": 0.00030812641083521446,
      "loss": 0.3947,
      "step": 106700
    },
    {
      "epoch": 4.34265151361132,
      "grad_norm": 0.2658776044845581,
      "learning_rate": 0.00030790510335059536,
      "loss": 0.3946,
      "step": 106800
    },
    {
      "epoch": 4.346717628641715,
      "grad_norm": 0.24676091969013214,
      "learning_rate": 0.00030768379586597615,
      "loss": 0.3954,
      "step": 106900
    },
    {
      "epoch": 4.350783743672109,
      "grad_norm": 0.2786778211593628,
      "learning_rate": 0.00030746248838135705,
      "loss": 0.3934,
      "step": 107000
    },
    {
      "epoch": 4.354849858702503,
      "grad_norm": 0.24163034558296204,
      "learning_rate": 0.0003072411808967379,
      "loss": 0.3947,
      "step": 107100
    },
    {
      "epoch": 4.358915973732897,
      "grad_norm": 0.2494439035654068,
      "learning_rate": 0.0003070198734121188,
      "loss": 0.394,
      "step": 107200
    },
    {
      "epoch": 4.3629820887632915,
      "grad_norm": 0.24670210480690002,
      "learning_rate": 0.0003067985659274997,
      "loss": 0.3935,
      "step": 107300
    },
    {
      "epoch": 4.3670482037936855,
      "grad_norm": 0.25724416971206665,
      "learning_rate": 0.00030657725844288053,
      "loss": 0.3952,
      "step": 107400
    },
    {
      "epoch": 4.3711143188240795,
      "grad_norm": 0.26960068941116333,
      "learning_rate": 0.0003063559509582614,
      "loss": 0.3952,
      "step": 107500
    },
    {
      "epoch": 4.3751804338544735,
      "grad_norm": 0.25339192152023315,
      "learning_rate": 0.00030613464347364227,
      "loss": 0.3935,
      "step": 107600
    },
    {
      "epoch": 4.379246548884868,
      "grad_norm": 0.3036259412765503,
      "learning_rate": 0.00030591333598902317,
      "loss": 0.3913,
      "step": 107700
    },
    {
      "epoch": 4.383312663915262,
      "grad_norm": 0.2746398448944092,
      "learning_rate": 0.000305692028504404,
      "loss": 0.3921,
      "step": 107800
    },
    {
      "epoch": 4.387378778945656,
      "grad_norm": 0.26012539863586426,
      "learning_rate": 0.0003054707210197849,
      "loss": 0.3935,
      "step": 107900
    },
    {
      "epoch": 4.39144489397605,
      "grad_norm": 0.25337696075439453,
      "learning_rate": 0.00030524941353516575,
      "loss": 0.3904,
      "step": 108000
    },
    {
      "epoch": 4.39144489397605,
      "eval_loss": 0.4367273449897766,
      "eval_runtime": 114.9239,
      "eval_samples_per_second": 1521.895,
      "eval_steps_per_second": 47.562,
      "step": 108000
    },
    {
      "epoch": 4.395511009006444,
      "grad_norm": 0.26730215549468994,
      "learning_rate": 0.00030502810605054665,
      "loss": 0.3924,
      "step": 108100
    },
    {
      "epoch": 4.399577124036839,
      "grad_norm": 0.2680087387561798,
      "learning_rate": 0.00030480679856592755,
      "loss": 0.393,
      "step": 108200
    },
    {
      "epoch": 4.403643239067233,
      "grad_norm": 0.25605204701423645,
      "learning_rate": 0.0003045854910813084,
      "loss": 0.3929,
      "step": 108300
    },
    {
      "epoch": 4.407709354097627,
      "grad_norm": 0.21628306806087494,
      "learning_rate": 0.0003043641835966893,
      "loss": 0.3927,
      "step": 108400
    },
    {
      "epoch": 4.411775469128021,
      "grad_norm": 0.22627383470535278,
      "learning_rate": 0.00030414287611207013,
      "loss": 0.3931,
      "step": 108500
    },
    {
      "epoch": 4.415841584158416,
      "grad_norm": 0.2589804530143738,
      "learning_rate": 0.00030392156862745097,
      "loss": 0.3918,
      "step": 108600
    },
    {
      "epoch": 4.41990769918881,
      "grad_norm": 0.2542020380496979,
      "learning_rate": 0.0003037002611428318,
      "loss": 0.3928,
      "step": 108700
    },
    {
      "epoch": 4.423973814219204,
      "grad_norm": 0.23355543613433838,
      "learning_rate": 0.0003034789536582127,
      "loss": 0.3934,
      "step": 108800
    },
    {
      "epoch": 4.428039929249598,
      "grad_norm": 0.2521224021911621,
      "learning_rate": 0.00030325764617359356,
      "loss": 0.3922,
      "step": 108900
    },
    {
      "epoch": 4.432106044279992,
      "grad_norm": 0.25907114148139954,
      "learning_rate": 0.00030303633868897445,
      "loss": 0.3947,
      "step": 109000
    },
    {
      "epoch": 4.436172159310387,
      "grad_norm": 0.26014572381973267,
      "learning_rate": 0.00030281503120435535,
      "loss": 0.3953,
      "step": 109100
    },
    {
      "epoch": 4.440238274340781,
      "grad_norm": 0.24612319469451904,
      "learning_rate": 0.0003025937237197362,
      "loss": 0.3903,
      "step": 109200
    },
    {
      "epoch": 4.444304389371175,
      "grad_norm": 0.24808940291404724,
      "learning_rate": 0.0003023724162351171,
      "loss": 0.3931,
      "step": 109300
    },
    {
      "epoch": 4.448370504401569,
      "grad_norm": 0.26974889636039734,
      "learning_rate": 0.00030215110875049793,
      "loss": 0.3918,
      "step": 109400
    },
    {
      "epoch": 4.452436619431964,
      "grad_norm": 0.2960178256034851,
      "learning_rate": 0.00030192980126587883,
      "loss": 0.3904,
      "step": 109500
    },
    {
      "epoch": 4.456502734462358,
      "grad_norm": 0.25175750255584717,
      "learning_rate": 0.0003017084937812597,
      "loss": 0.3917,
      "step": 109600
    },
    {
      "epoch": 4.460568849492752,
      "grad_norm": 0.23107293248176575,
      "learning_rate": 0.00030148718629664057,
      "loss": 0.3917,
      "step": 109700
    },
    {
      "epoch": 4.464634964523146,
      "grad_norm": 0.27870896458625793,
      "learning_rate": 0.00030126587881202147,
      "loss": 0.3912,
      "step": 109800
    },
    {
      "epoch": 4.468701079553541,
      "grad_norm": 0.25898024439811707,
      "learning_rate": 0.0003010445713274023,
      "loss": 0.3905,
      "step": 109900
    },
    {
      "epoch": 4.472767194583935,
      "grad_norm": 0.2717416286468506,
      "learning_rate": 0.0003008232638427832,
      "loss": 0.393,
      "step": 110000
    },
    {
      "epoch": 4.472767194583935,
      "eval_loss": 0.4285784959793091,
      "eval_runtime": 115.1362,
      "eval_samples_per_second": 1519.087,
      "eval_steps_per_second": 47.474,
      "step": 110000
    },
    {
      "epoch": 4.476833309614329,
      "grad_norm": 0.2534532845020294,
      "learning_rate": 0.00030060195635816405,
      "loss": 0.3919,
      "step": 110100
    },
    {
      "epoch": 4.480899424644723,
      "grad_norm": 0.24238242208957672,
      "learning_rate": 0.00030038064887354495,
      "loss": 0.3956,
      "step": 110200
    },
    {
      "epoch": 4.484965539675118,
      "grad_norm": 0.2734701633453369,
      "learning_rate": 0.00030015934138892574,
      "loss": 0.3926,
      "step": 110300
    },
    {
      "epoch": 4.489031654705512,
      "grad_norm": 0.2511979937553406,
      "learning_rate": 0.00029993803390430664,
      "loss": 0.3917,
      "step": 110400
    },
    {
      "epoch": 4.493097769735906,
      "grad_norm": 0.29746758937835693,
      "learning_rate": 0.0002997167264196875,
      "loss": 0.3939,
      "step": 110500
    },
    {
      "epoch": 4.4971638847663,
      "grad_norm": 0.26796773076057434,
      "learning_rate": 0.0002994954189350684,
      "loss": 0.3927,
      "step": 110600
    },
    {
      "epoch": 4.501229999796694,
      "grad_norm": 0.27460846304893494,
      "learning_rate": 0.0002992741114504493,
      "loss": 0.3928,
      "step": 110700
    },
    {
      "epoch": 4.505296114827089,
      "grad_norm": 0.25731539726257324,
      "learning_rate": 0.0002990528039658301,
      "loss": 0.3891,
      "step": 110800
    },
    {
      "epoch": 4.509362229857483,
      "grad_norm": 0.2688233256340027,
      "learning_rate": 0.000298831496481211,
      "loss": 0.3907,
      "step": 110900
    },
    {
      "epoch": 4.513428344887877,
      "grad_norm": 0.2683413624763489,
      "learning_rate": 0.00029861018899659186,
      "loss": 0.3921,
      "step": 111000
    },
    {
      "epoch": 4.517494459918271,
      "grad_norm": 0.26391544938087463,
      "learning_rate": 0.00029838888151197275,
      "loss": 0.393,
      "step": 111100
    },
    {
      "epoch": 4.521560574948666,
      "grad_norm": 0.24683518707752228,
      "learning_rate": 0.0002981675740273536,
      "loss": 0.3902,
      "step": 111200
    },
    {
      "epoch": 4.52562668997906,
      "grad_norm": 0.25436827540397644,
      "learning_rate": 0.0002979462665427345,
      "loss": 0.392,
      "step": 111300
    },
    {
      "epoch": 4.529692805009454,
      "grad_norm": 0.262698769569397,
      "learning_rate": 0.00029772495905811534,
      "loss": 0.3901,
      "step": 111400
    },
    {
      "epoch": 4.533758920039848,
      "grad_norm": 0.2569425702095032,
      "learning_rate": 0.00029750365157349624,
      "loss": 0.3917,
      "step": 111500
    },
    {
      "epoch": 4.5378250350702425,
      "grad_norm": 0.2706833779811859,
      "learning_rate": 0.00029728234408887713,
      "loss": 0.3915,
      "step": 111600
    },
    {
      "epoch": 4.5418911501006365,
      "grad_norm": 0.2772815227508545,
      "learning_rate": 0.000297061036604258,
      "loss": 0.3921,
      "step": 111700
    },
    {
      "epoch": 4.5459572651310305,
      "grad_norm": 0.2502959668636322,
      "learning_rate": 0.0002968397291196389,
      "loss": 0.3911,
      "step": 111800
    },
    {
      "epoch": 4.5500233801614245,
      "grad_norm": 0.24589207768440247,
      "learning_rate": 0.00029661842163501966,
      "loss": 0.3918,
      "step": 111900
    },
    {
      "epoch": 4.554089495191819,
      "grad_norm": 0.2343342900276184,
      "learning_rate": 0.00029639711415040056,
      "loss": 0.3908,
      "step": 112000
    },
    {
      "epoch": 4.554089495191819,
      "eval_loss": 0.4273008108139038,
      "eval_runtime": 115.2711,
      "eval_samples_per_second": 1517.309,
      "eval_steps_per_second": 47.419,
      "step": 112000
    },
    {
      "epoch": 4.558155610222213,
      "grad_norm": 0.23364482820034027,
      "learning_rate": 0.0002961758066657814,
      "loss": 0.3924,
      "step": 112100
    },
    {
      "epoch": 4.562221725252607,
      "grad_norm": 0.29146358370780945,
      "learning_rate": 0.0002959544991811623,
      "loss": 0.3928,
      "step": 112200
    },
    {
      "epoch": 4.566287840283001,
      "grad_norm": 0.2418350875377655,
      "learning_rate": 0.00029573319169654314,
      "loss": 0.3939,
      "step": 112300
    },
    {
      "epoch": 4.570353955313395,
      "grad_norm": 0.26621681451797485,
      "learning_rate": 0.00029551188421192404,
      "loss": 0.3878,
      "step": 112400
    },
    {
      "epoch": 4.57442007034379,
      "grad_norm": 0.23548151552677155,
      "learning_rate": 0.00029529057672730494,
      "loss": 0.3886,
      "step": 112500
    },
    {
      "epoch": 4.578486185374184,
      "grad_norm": 0.258346825838089,
      "learning_rate": 0.0002950692692426858,
      "loss": 0.392,
      "step": 112600
    },
    {
      "epoch": 4.582552300404578,
      "grad_norm": 0.2753172516822815,
      "learning_rate": 0.0002948479617580667,
      "loss": 0.3928,
      "step": 112700
    },
    {
      "epoch": 4.586618415434972,
      "grad_norm": 0.23332951962947845,
      "learning_rate": 0.0002946266542734475,
      "loss": 0.3924,
      "step": 112800
    },
    {
      "epoch": 4.590684530465367,
      "grad_norm": 0.25794434547424316,
      "learning_rate": 0.0002944053467888284,
      "loss": 0.3918,
      "step": 112900
    },
    {
      "epoch": 4.594750645495761,
      "grad_norm": 0.24026380479335785,
      "learning_rate": 0.00029418403930420926,
      "loss": 0.3926,
      "step": 113000
    },
    {
      "epoch": 4.598816760526155,
      "grad_norm": 0.2396906167268753,
      "learning_rate": 0.00029396273181959016,
      "loss": 0.3897,
      "step": 113100
    },
    {
      "epoch": 4.602882875556549,
      "grad_norm": 0.27370986342430115,
      "learning_rate": 0.00029374142433497106,
      "loss": 0.3914,
      "step": 113200
    },
    {
      "epoch": 4.606948990586944,
      "grad_norm": 0.24508658051490784,
      "learning_rate": 0.0002935201168503519,
      "loss": 0.3906,
      "step": 113300
    },
    {
      "epoch": 4.611015105617338,
      "grad_norm": 0.2573504149913788,
      "learning_rate": 0.0002932988093657328,
      "loss": 0.39,
      "step": 113400
    },
    {
      "epoch": 4.615081220647732,
      "grad_norm": 0.29389339685440063,
      "learning_rate": 0.00029307750188111364,
      "loss": 0.3915,
      "step": 113500
    },
    {
      "epoch": 4.619147335678126,
      "grad_norm": 0.2602679133415222,
      "learning_rate": 0.0002928561943964945,
      "loss": 0.3934,
      "step": 113600
    },
    {
      "epoch": 4.623213450708521,
      "grad_norm": 0.24238833785057068,
      "learning_rate": 0.0002926348869118753,
      "loss": 0.3912,
      "step": 113700
    },
    {
      "epoch": 4.627279565738915,
      "grad_norm": 0.262154221534729,
      "learning_rate": 0.0002924135794272562,
      "loss": 0.3904,
      "step": 113800
    },
    {
      "epoch": 4.631345680769309,
      "grad_norm": 0.25610676407814026,
      "learning_rate": 0.00029219227194263707,
      "loss": 0.3914,
      "step": 113900
    },
    {
      "epoch": 4.635411795799703,
      "grad_norm": 0.26882264018058777,
      "learning_rate": 0.00029197096445801796,
      "loss": 0.3929,
      "step": 114000
    },
    {
      "epoch": 4.635411795799703,
      "eval_loss": 0.42650720477104187,
      "eval_runtime": 114.8332,
      "eval_samples_per_second": 1523.097,
      "eval_steps_per_second": 47.599,
      "step": 114000
    },
    {
      "epoch": 4.639477910830097,
      "grad_norm": 0.26825860142707825,
      "learning_rate": 0.00029174965697339886,
      "loss": 0.3908,
      "step": 114100
    },
    {
      "epoch": 4.643544025860492,
      "grad_norm": 0.25357770919799805,
      "learning_rate": 0.0002915283494887797,
      "loss": 0.3924,
      "step": 114200
    },
    {
      "epoch": 4.647610140890886,
      "grad_norm": 0.2600676715373993,
      "learning_rate": 0.0002913070420041606,
      "loss": 0.3913,
      "step": 114300
    },
    {
      "epoch": 4.65167625592128,
      "grad_norm": 0.23902468383312225,
      "learning_rate": 0.00029108573451954144,
      "loss": 0.3928,
      "step": 114400
    },
    {
      "epoch": 4.655742370951674,
      "grad_norm": 0.25853198766708374,
      "learning_rate": 0.00029086442703492234,
      "loss": 0.39,
      "step": 114500
    },
    {
      "epoch": 4.659808485982069,
      "grad_norm": 0.253526896238327,
      "learning_rate": 0.0002906431195503032,
      "loss": 0.3911,
      "step": 114600
    },
    {
      "epoch": 4.663874601012463,
      "grad_norm": 0.2611309289932251,
      "learning_rate": 0.0002904218120656841,
      "loss": 0.3884,
      "step": 114700
    },
    {
      "epoch": 4.667940716042857,
      "grad_norm": 0.251853883266449,
      "learning_rate": 0.0002902005045810649,
      "loss": 0.3923,
      "step": 114800
    },
    {
      "epoch": 4.672006831073251,
      "grad_norm": 0.29009127616882324,
      "learning_rate": 0.0002899791970964458,
      "loss": 0.3901,
      "step": 114900
    },
    {
      "epoch": 4.676072946103646,
      "grad_norm": 0.2614200711250305,
      "learning_rate": 0.0002897578896118267,
      "loss": 0.3895,
      "step": 115000
    },
    {
      "epoch": 4.68013906113404,
      "grad_norm": 0.2803070843219757,
      "learning_rate": 0.00028953658212720756,
      "loss": 0.3879,
      "step": 115100
    },
    {
      "epoch": 4.684205176164434,
      "grad_norm": 0.256398469209671,
      "learning_rate": 0.00028931527464258846,
      "loss": 0.3902,
      "step": 115200
    },
    {
      "epoch": 4.688271291194828,
      "grad_norm": 0.2141856998205185,
      "learning_rate": 0.00028909396715796925,
      "loss": 0.39,
      "step": 115300
    },
    {
      "epoch": 4.6923374062252226,
      "grad_norm": 0.24871326982975006,
      "learning_rate": 0.00028887265967335015,
      "loss": 0.3921,
      "step": 115400
    },
    {
      "epoch": 4.6964035212556166,
      "grad_norm": 0.2961153984069824,
      "learning_rate": 0.000288651352188731,
      "loss": 0.3917,
      "step": 115500
    },
    {
      "epoch": 4.7004696362860106,
      "grad_norm": 0.25791093707084656,
      "learning_rate": 0.0002884300447041119,
      "loss": 0.3922,
      "step": 115600
    },
    {
      "epoch": 4.704535751316405,
      "grad_norm": 0.25560930371284485,
      "learning_rate": 0.00028820873721949273,
      "loss": 0.3898,
      "step": 115700
    },
    {
      "epoch": 4.708601866346799,
      "grad_norm": 0.2583239674568176,
      "learning_rate": 0.00028798742973487363,
      "loss": 0.3899,
      "step": 115800
    },
    {
      "epoch": 4.7126679813771934,
      "grad_norm": 0.2618028223514557,
      "learning_rate": 0.0002877661222502545,
      "loss": 0.3909,
      "step": 115900
    },
    {
      "epoch": 4.7167340964075875,
      "grad_norm": 0.23349644243717194,
      "learning_rate": 0.00028754481476563537,
      "loss": 0.3925,
      "step": 116000
    },
    {
      "epoch": 4.7167340964075875,
      "eval_loss": 0.4309951961040497,
      "eval_runtime": 116.1875,
      "eval_samples_per_second": 1505.343,
      "eval_steps_per_second": 47.045,
      "step": 116000
    },
    {
      "epoch": 4.720840872588285,
      "grad_norm": 0.24847188591957092,
      "learning_rate": 0.00028732350728101627,
      "loss": 0.3912,
      "step": 116100
    },
    {
      "epoch": 4.72490698761868,
      "grad_norm": 0.25626689195632935,
      "learning_rate": 0.0002871021997963971,
      "loss": 0.3899,
      "step": 116200
    },
    {
      "epoch": 4.728973102649074,
      "grad_norm": 0.2691675126552582,
      "learning_rate": 0.000286880892311778,
      "loss": 0.3903,
      "step": 116300
    },
    {
      "epoch": 4.733039217679468,
      "grad_norm": 0.2751506567001343,
      "learning_rate": 0.00028665958482715885,
      "loss": 0.3926,
      "step": 116400
    },
    {
      "epoch": 4.737105332709862,
      "grad_norm": 0.2608185112476349,
      "learning_rate": 0.00028643827734253975,
      "loss": 0.3899,
      "step": 116500
    },
    {
      "epoch": 4.741171447740257,
      "grad_norm": 0.2648087441921234,
      "learning_rate": 0.00028621696985792064,
      "loss": 0.3908,
      "step": 116600
    },
    {
      "epoch": 4.745237562770651,
      "grad_norm": 0.26617470383644104,
      "learning_rate": 0.0002859956623733015,
      "loss": 0.3907,
      "step": 116700
    },
    {
      "epoch": 4.749303677801045,
      "grad_norm": 0.27839553356170654,
      "learning_rate": 0.0002857743548886824,
      "loss": 0.3938,
      "step": 116800
    },
    {
      "epoch": 4.753369792831439,
      "grad_norm": 0.27559083700180054,
      "learning_rate": 0.00028555304740406323,
      "loss": 0.3898,
      "step": 116900
    },
    {
      "epoch": 4.757435907861834,
      "grad_norm": 0.28861454129219055,
      "learning_rate": 0.00028533173991944407,
      "loss": 0.3918,
      "step": 117000
    },
    {
      "epoch": 4.761502022892228,
      "grad_norm": 0.28604856133461,
      "learning_rate": 0.0002851104324348249,
      "loss": 0.3921,
      "step": 117100
    },
    {
      "epoch": 4.765568137922622,
      "grad_norm": 0.27111899852752686,
      "learning_rate": 0.0002848891249502058,
      "loss": 0.39,
      "step": 117200
    },
    {
      "epoch": 4.769634252953016,
      "grad_norm": 0.26729804277420044,
      "learning_rate": 0.00028466781746558665,
      "loss": 0.3893,
      "step": 117300
    },
    {
      "epoch": 4.773700367983411,
      "grad_norm": 0.25696876645088196,
      "learning_rate": 0.00028444650998096755,
      "loss": 0.3916,
      "step": 117400
    },
    {
      "epoch": 4.777766483013805,
      "grad_norm": 0.25466397404670715,
      "learning_rate": 0.00028422520249634845,
      "loss": 0.389,
      "step": 117500
    },
    {
      "epoch": 4.781832598044199,
      "grad_norm": 0.27107277512550354,
      "learning_rate": 0.0002840038950117293,
      "loss": 0.3905,
      "step": 117600
    },
    {
      "epoch": 4.785898713074593,
      "grad_norm": 0.27085787057876587,
      "learning_rate": 0.0002837825875271102,
      "loss": 0.3907,
      "step": 117700
    },
    {
      "epoch": 4.789964828104987,
      "grad_norm": 0.2698114216327667,
      "learning_rate": 0.00028356128004249103,
      "loss": 0.3901,
      "step": 117800
    },
    {
      "epoch": 4.794030943135382,
      "grad_norm": 0.2605772018432617,
      "learning_rate": 0.00028333997255787193,
      "loss": 0.3914,
      "step": 117900
    },
    {
      "epoch": 4.798097058165776,
      "grad_norm": 0.2899966537952423,
      "learning_rate": 0.00028311866507325277,
      "loss": 0.3933,
      "step": 118000
    },
    {
      "epoch": 4.798097058165776,
      "eval_loss": 0.43257537484169006,
      "eval_runtime": 117.0624,
      "eval_samples_per_second": 1494.092,
      "eval_steps_per_second": 46.693,
      "step": 118000
    },
    {
      "epoch": 4.80216317319617,
      "grad_norm": 0.26453694701194763,
      "learning_rate": 0.00028289735758863367,
      "loss": 0.3936,
      "step": 118100
    },
    {
      "epoch": 4.806229288226564,
      "grad_norm": 0.2647060453891754,
      "learning_rate": 0.0002826760501040145,
      "loss": 0.3904,
      "step": 118200
    },
    {
      "epoch": 4.8102954032569585,
      "grad_norm": 0.2468961775302887,
      "learning_rate": 0.0002824547426193954,
      "loss": 0.3902,
      "step": 118300
    },
    {
      "epoch": 4.8143615182873525,
      "grad_norm": 0.26660794019699097,
      "learning_rate": 0.0002822334351347763,
      "loss": 0.3907,
      "step": 118400
    },
    {
      "epoch": 4.8184276333177465,
      "grad_norm": 0.2830119729042053,
      "learning_rate": 0.00028201212765015715,
      "loss": 0.3883,
      "step": 118500
    },
    {
      "epoch": 4.8224937483481405,
      "grad_norm": 0.28950244188308716,
      "learning_rate": 0.00028179082016553805,
      "loss": 0.389,
      "step": 118600
    },
    {
      "epoch": 4.8265598633785345,
      "grad_norm": 0.2918719947338104,
      "learning_rate": 0.00028156951268091884,
      "loss": 0.3914,
      "step": 118700
    },
    {
      "epoch": 4.830625978408929,
      "grad_norm": 0.30496689677238464,
      "learning_rate": 0.00028134820519629973,
      "loss": 0.3905,
      "step": 118800
    },
    {
      "epoch": 4.834692093439323,
      "grad_norm": 0.283965140581131,
      "learning_rate": 0.0002811268977116806,
      "loss": 0.3922,
      "step": 118900
    },
    {
      "epoch": 4.838758208469717,
      "grad_norm": 0.26295003294944763,
      "learning_rate": 0.0002809055902270615,
      "loss": 0.3905,
      "step": 119000
    },
    {
      "epoch": 4.842824323500112,
      "grad_norm": 0.2838132977485657,
      "learning_rate": 0.0002806842827424423,
      "loss": 0.3887,
      "step": 119100
    },
    {
      "epoch": 4.846890438530506,
      "grad_norm": 0.29670387506484985,
      "learning_rate": 0.0002804629752578232,
      "loss": 0.3907,
      "step": 119200
    },
    {
      "epoch": 4.8509565535609,
      "grad_norm": 0.2613529860973358,
      "learning_rate": 0.0002802416677732041,
      "loss": 0.3888,
      "step": 119300
    },
    {
      "epoch": 4.855022668591294,
      "grad_norm": 0.2966924011707306,
      "learning_rate": 0.00028002036028858496,
      "loss": 0.3896,
      "step": 119400
    },
    {
      "epoch": 4.859088783621688,
      "grad_norm": 0.28433510661125183,
      "learning_rate": 0.00027979905280396585,
      "loss": 0.391,
      "step": 119500
    },
    {
      "epoch": 4.863154898652083,
      "grad_norm": 0.3019857704639435,
      "learning_rate": 0.0002795777453193467,
      "loss": 0.392,
      "step": 119600
    },
    {
      "epoch": 4.867221013682477,
      "grad_norm": 0.2864759862422943,
      "learning_rate": 0.0002793564378347276,
      "loss": 0.3893,
      "step": 119700
    },
    {
      "epoch": 4.871287128712871,
      "grad_norm": 0.32399964332580566,
      "learning_rate": 0.00027913513035010844,
      "loss": 0.3906,
      "step": 119800
    },
    {
      "epoch": 4.875353243743265,
      "grad_norm": 0.25350385904312134,
      "learning_rate": 0.00027891382286548933,
      "loss": 0.3922,
      "step": 119900
    },
    {
      "epoch": 4.87941935877366,
      "grad_norm": 0.3235713839530945,
      "learning_rate": 0.0002786925153808702,
      "loss": 0.3897,
      "step": 120000
    },
    {
      "epoch": 4.87941935877366,
      "eval_loss": 0.43688347935676575,
      "eval_runtime": 115.4563,
      "eval_samples_per_second": 1514.877,
      "eval_steps_per_second": 47.343,
      "step": 120000
    },
    {
      "epoch": 4.883485473804054,
      "grad_norm": 0.25412270426750183,
      "learning_rate": 0.0002784712078962511,
      "loss": 0.3917,
      "step": 120100
    },
    {
      "epoch": 4.887551588834448,
      "grad_norm": 0.27301129698753357,
      "learning_rate": 0.00027824990041163197,
      "loss": 0.3902,
      "step": 120200
    },
    {
      "epoch": 4.891617703864842,
      "grad_norm": 0.28999999165534973,
      "learning_rate": 0.0002780285929270128,
      "loss": 0.391,
      "step": 120300
    },
    {
      "epoch": 4.895683818895236,
      "grad_norm": 0.2631937265396118,
      "learning_rate": 0.00027780728544239366,
      "loss": 0.3899,
      "step": 120400
    },
    {
      "epoch": 4.899749933925631,
      "grad_norm": 0.271829754114151,
      "learning_rate": 0.0002775859779577745,
      "loss": 0.3913,
      "step": 120500
    },
    {
      "epoch": 4.903816048956025,
      "grad_norm": 0.27597805857658386,
      "learning_rate": 0.0002773646704731554,
      "loss": 0.39,
      "step": 120600
    },
    {
      "epoch": 4.907882163986419,
      "grad_norm": 0.2824796140193939,
      "learning_rate": 0.00027714336298853624,
      "loss": 0.3905,
      "step": 120700
    },
    {
      "epoch": 4.911948279016814,
      "grad_norm": 0.2770897448062897,
      "learning_rate": 0.00027692205550391714,
      "loss": 0.3923,
      "step": 120800
    },
    {
      "epoch": 4.916014394047208,
      "grad_norm": 0.226296067237854,
      "learning_rate": 0.00027670074801929804,
      "loss": 0.3915,
      "step": 120900
    },
    {
      "epoch": 4.920080509077602,
      "grad_norm": 0.2730811536312103,
      "learning_rate": 0.0002764794405346789,
      "loss": 0.3889,
      "step": 121000
    },
    {
      "epoch": 4.924146624107996,
      "grad_norm": 0.255916953086853,
      "learning_rate": 0.0002762581330500598,
      "loss": 0.392,
      "step": 121100
    },
    {
      "epoch": 4.92821273913839,
      "grad_norm": 0.2781888246536255,
      "learning_rate": 0.0002760368255654406,
      "loss": 0.3875,
      "step": 121200
    },
    {
      "epoch": 4.932278854168785,
      "grad_norm": 0.26191237568855286,
      "learning_rate": 0.0002758155180808215,
      "loss": 0.3939,
      "step": 121300
    },
    {
      "epoch": 4.936344969199179,
      "grad_norm": 0.2694697082042694,
      "learning_rate": 0.00027559421059620236,
      "loss": 0.3888,
      "step": 121400
    },
    {
      "epoch": 4.940411084229573,
      "grad_norm": 0.27261996269226074,
      "learning_rate": 0.00027537290311158326,
      "loss": 0.3898,
      "step": 121500
    },
    {
      "epoch": 4.944477199259967,
      "grad_norm": 0.263596773147583,
      "learning_rate": 0.0002751515956269641,
      "loss": 0.39,
      "step": 121600
    },
    {
      "epoch": 4.948543314290362,
      "grad_norm": 0.26577478647232056,
      "learning_rate": 0.000274930288142345,
      "loss": 0.3896,
      "step": 121700
    },
    {
      "epoch": 4.952609429320756,
      "grad_norm": 0.26891711354255676,
      "learning_rate": 0.0002747089806577259,
      "loss": 0.3877,
      "step": 121800
    },
    {
      "epoch": 4.95667554435115,
      "grad_norm": 0.2600351870059967,
      "learning_rate": 0.00027448767317310674,
      "loss": 0.3905,
      "step": 121900
    },
    {
      "epoch": 4.960741659381544,
      "grad_norm": 0.2987220287322998,
      "learning_rate": 0.00027426636568848764,
      "loss": 0.3906,
      "step": 122000
    },
    {
      "epoch": 4.960741659381544,
      "eval_loss": 0.4273160696029663,
      "eval_runtime": 117.4831,
      "eval_samples_per_second": 1488.742,
      "eval_steps_per_second": 46.526,
      "step": 122000
    },
    {
      "epoch": 4.964807774411938,
      "grad_norm": 0.2807454466819763,
      "learning_rate": 0.0002740450582038684,
      "loss": 0.3915,
      "step": 122100
    },
    {
      "epoch": 4.9688738894423325,
      "grad_norm": 0.2488810420036316,
      "learning_rate": 0.0002738237507192493,
      "loss": 0.3919,
      "step": 122200
    },
    {
      "epoch": 4.9729400044727265,
      "grad_norm": 0.298004150390625,
      "learning_rate": 0.00027360244323463016,
      "loss": 0.3907,
      "step": 122300
    },
    {
      "epoch": 4.9770061195031206,
      "grad_norm": 0.31938233971595764,
      "learning_rate": 0.00027338113575001106,
      "loss": 0.3907,
      "step": 122400
    },
    {
      "epoch": 4.981072234533515,
      "grad_norm": 0.26740849018096924,
      "learning_rate": 0.0002731598282653919,
      "loss": 0.3903,
      "step": 122500
    },
    {
      "epoch": 4.985138349563909,
      "grad_norm": 0.2556244730949402,
      "learning_rate": 0.0002729385207807728,
      "loss": 0.3897,
      "step": 122600
    },
    {
      "epoch": 4.9892044645943034,
      "grad_norm": 0.30739158391952515,
      "learning_rate": 0.0002727172132961537,
      "loss": 0.3903,
      "step": 122700
    },
    {
      "epoch": 4.9932705796246974,
      "grad_norm": 0.2884052097797394,
      "learning_rate": 0.00027249590581153454,
      "loss": 0.3901,
      "step": 122800
    },
    {
      "epoch": 4.9973366946550914,
      "grad_norm": 0.25780022144317627,
      "learning_rate": 0.00027227459832691544,
      "loss": 0.3899,
      "step": 122900
    },
    {
      "epoch": 5.001402809685486,
      "grad_norm": 0.28909850120544434,
      "learning_rate": 0.0002720532908422963,
      "loss": 0.3889,
      "step": 123000
    },
    {
      "epoch": 5.00546892471588,
      "grad_norm": 0.29889246821403503,
      "learning_rate": 0.0002718319833576772,
      "loss": 0.3899,
      "step": 123100
    },
    {
      "epoch": 5.009535039746274,
      "grad_norm": 0.2585124671459198,
      "learning_rate": 0.000271610675873058,
      "loss": 0.3862,
      "step": 123200
    },
    {
      "epoch": 5.013601154776668,
      "grad_norm": 0.29395365715026855,
      "learning_rate": 0.0002713893683884389,
      "loss": 0.3895,
      "step": 123300
    },
    {
      "epoch": 5.017667269807063,
      "grad_norm": 0.2983319163322449,
      "learning_rate": 0.00027116806090381976,
      "loss": 0.3908,
      "step": 123400
    },
    {
      "epoch": 5.021733384837457,
      "grad_norm": 0.26834046840667725,
      "learning_rate": 0.00027094675341920066,
      "loss": 0.3885,
      "step": 123500
    },
    {
      "epoch": 5.025799499867851,
      "grad_norm": 0.24052530527114868,
      "learning_rate": 0.00027072544593458156,
      "loss": 0.3892,
      "step": 123600
    },
    {
      "epoch": 5.029865614898245,
      "grad_norm": 0.2925211489200592,
      "learning_rate": 0.00027050413844996235,
      "loss": 0.3875,
      "step": 123700
    },
    {
      "epoch": 5.033931729928639,
      "grad_norm": 0.23064473271369934,
      "learning_rate": 0.00027028283096534325,
      "loss": 0.3899,
      "step": 123800
    },
    {
      "epoch": 5.037997844959034,
      "grad_norm": 0.272068589925766,
      "learning_rate": 0.0002700615234807241,
      "loss": 0.3882,
      "step": 123900
    },
    {
      "epoch": 5.042063959989428,
      "grad_norm": 0.28522631525993347,
      "learning_rate": 0.000269840215996105,
      "loss": 0.3869,
      "step": 124000
    },
    {
      "epoch": 5.042063959989428,
      "eval_loss": 0.43383848667144775,
      "eval_runtime": 115.2399,
      "eval_samples_per_second": 1517.721,
      "eval_steps_per_second": 47.432,
      "step": 124000
    },
    {
      "epoch": 5.046130075019822,
      "grad_norm": 0.2536967396736145,
      "learning_rate": 0.00026961890851148583,
      "loss": 0.3908,
      "step": 124100
    },
    {
      "epoch": 5.050196190050216,
      "grad_norm": 0.2447281777858734,
      "learning_rate": 0.0002693976010268667,
      "loss": 0.3877,
      "step": 124200
    },
    {
      "epoch": 5.054262305080611,
      "grad_norm": 0.27691447734832764,
      "learning_rate": 0.0002691762935422476,
      "loss": 0.3879,
      "step": 124300
    },
    {
      "epoch": 5.058328420111005,
      "grad_norm": 0.2589169144630432,
      "learning_rate": 0.00026895498605762847,
      "loss": 0.3897,
      "step": 124400
    },
    {
      "epoch": 5.062394535141399,
      "grad_norm": 0.27979475259780884,
      "learning_rate": 0.00026873367857300936,
      "loss": 0.3877,
      "step": 124500
    },
    {
      "epoch": 5.066460650171793,
      "grad_norm": 0.2756308317184448,
      "learning_rate": 0.0002685123710883902,
      "loss": 0.388,
      "step": 124600
    },
    {
      "epoch": 5.070526765202188,
      "grad_norm": 0.265943318605423,
      "learning_rate": 0.0002682910636037711,
      "loss": 0.3916,
      "step": 124700
    },
    {
      "epoch": 5.074592880232582,
      "grad_norm": 0.26712360978126526,
      "learning_rate": 0.00026806975611915195,
      "loss": 0.3877,
      "step": 124800
    },
    {
      "epoch": 5.078658995262976,
      "grad_norm": 0.28686678409576416,
      "learning_rate": 0.00026784844863453284,
      "loss": 0.3897,
      "step": 124900
    },
    {
      "epoch": 5.08272511029337,
      "grad_norm": 0.28649792075157166,
      "learning_rate": 0.0002676271411499137,
      "loss": 0.3872,
      "step": 125000
    },
    {
      "epoch": 5.086791225323765,
      "grad_norm": 0.24484997987747192,
      "learning_rate": 0.0002674058336652946,
      "loss": 0.3906,
      "step": 125100
    },
    {
      "epoch": 5.090857340354159,
      "grad_norm": 0.2744687795639038,
      "learning_rate": 0.0002671845261806755,
      "loss": 0.3875,
      "step": 125200
    },
    {
      "epoch": 5.094923455384553,
      "grad_norm": 0.30470356345176697,
      "learning_rate": 0.0002669632186960563,
      "loss": 0.3888,
      "step": 125300
    },
    {
      "epoch": 5.098989570414947,
      "grad_norm": 0.27562811970710754,
      "learning_rate": 0.00026674191121143717,
      "loss": 0.3869,
      "step": 125400
    },
    {
      "epoch": 5.103055685445341,
      "grad_norm": 0.2938006520271301,
      "learning_rate": 0.000266520603726818,
      "loss": 0.3886,
      "step": 125500
    },
    {
      "epoch": 5.107121800475736,
      "grad_norm": 0.29022619128227234,
      "learning_rate": 0.0002662992962421989,
      "loss": 0.3872,
      "step": 125600
    },
    {
      "epoch": 5.11118791550613,
      "grad_norm": 0.26442772150039673,
      "learning_rate": 0.00026607798875757975,
      "loss": 0.3862,
      "step": 125700
    },
    {
      "epoch": 5.115254030536524,
      "grad_norm": 0.2698806822299957,
      "learning_rate": 0.00026585668127296065,
      "loss": 0.3881,
      "step": 125800
    },
    {
      "epoch": 5.119320145566918,
      "grad_norm": 0.28828227519989014,
      "learning_rate": 0.0002656353737883415,
      "loss": 0.3873,
      "step": 125900
    },
    {
      "epoch": 5.123386260597313,
      "grad_norm": 0.28266847133636475,
      "learning_rate": 0.0002654140663037224,
      "loss": 0.391,
      "step": 126000
    },
    {
      "epoch": 5.123386260597313,
      "eval_loss": 0.428706556558609,
      "eval_runtime": 115.0893,
      "eval_samples_per_second": 1519.707,
      "eval_steps_per_second": 47.494,
      "step": 126000
    },
    {
      "epoch": 5.127452375627707,
      "grad_norm": 0.2681363821029663,
      "learning_rate": 0.0002651927588191033,
      "loss": 0.387,
      "step": 126100
    },
    {
      "epoch": 5.131518490658101,
      "grad_norm": 0.28912463784217834,
      "learning_rate": 0.00026497145133448413,
      "loss": 0.3882,
      "step": 126200
    },
    {
      "epoch": 5.135584605688495,
      "grad_norm": 0.299315482378006,
      "learning_rate": 0.00026475014384986503,
      "loss": 0.3898,
      "step": 126300
    },
    {
      "epoch": 5.1396507207188895,
      "grad_norm": 0.29691773653030396,
      "learning_rate": 0.00026452883636524587,
      "loss": 0.3901,
      "step": 126400
    },
    {
      "epoch": 5.1437168357492835,
      "grad_norm": 0.2941441237926483,
      "learning_rate": 0.00026430752888062677,
      "loss": 0.3918,
      "step": 126500
    },
    {
      "epoch": 5.1477829507796775,
      "grad_norm": 0.246874138712883,
      "learning_rate": 0.0002640862213960076,
      "loss": 0.3889,
      "step": 126600
    },
    {
      "epoch": 5.1518490658100715,
      "grad_norm": 0.27629417181015015,
      "learning_rate": 0.0002638649139113885,
      "loss": 0.3895,
      "step": 126700
    },
    {
      "epoch": 5.155915180840466,
      "grad_norm": 0.24290740489959717,
      "learning_rate": 0.00026364360642676935,
      "loss": 0.3873,
      "step": 126800
    },
    {
      "epoch": 5.15998129587086,
      "grad_norm": 0.26067695021629333,
      "learning_rate": 0.00026342229894215025,
      "loss": 0.3909,
      "step": 126900
    },
    {
      "epoch": 5.164047410901254,
      "grad_norm": 0.28880539536476135,
      "learning_rate": 0.00026320099145753115,
      "loss": 0.3896,
      "step": 127000
    },
    {
      "epoch": 5.168113525931648,
      "grad_norm": 0.2664151191711426,
      "learning_rate": 0.00026297968397291194,
      "loss": 0.3887,
      "step": 127100
    },
    {
      "epoch": 5.172179640962042,
      "grad_norm": 0.2838999330997467,
      "learning_rate": 0.00026275837648829283,
      "loss": 0.3887,
      "step": 127200
    },
    {
      "epoch": 5.176245755992437,
      "grad_norm": 0.3115323483943939,
      "learning_rate": 0.0002625370690036737,
      "loss": 0.3886,
      "step": 127300
    },
    {
      "epoch": 5.180311871022831,
      "grad_norm": 0.2797093093395233,
      "learning_rate": 0.0002623157615190546,
      "loss": 0.3876,
      "step": 127400
    },
    {
      "epoch": 5.184377986053225,
      "grad_norm": 0.28172174096107483,
      "learning_rate": 0.0002620944540344354,
      "loss": 0.3871,
      "step": 127500
    },
    {
      "epoch": 5.188444101083619,
      "grad_norm": 0.26817116141319275,
      "learning_rate": 0.0002618731465498163,
      "loss": 0.3889,
      "step": 127600
    },
    {
      "epoch": 5.192510216114014,
      "grad_norm": 0.27128058671951294,
      "learning_rate": 0.00026165183906519716,
      "loss": 0.386,
      "step": 127700
    },
    {
      "epoch": 5.196576331144408,
      "grad_norm": 0.2962075471878052,
      "learning_rate": 0.00026143053158057805,
      "loss": 0.389,
      "step": 127800
    },
    {
      "epoch": 5.200642446174802,
      "grad_norm": 0.2812057137489319,
      "learning_rate": 0.00026120922409595895,
      "loss": 0.3899,
      "step": 127900
    },
    {
      "epoch": 5.204708561205196,
      "grad_norm": 0.24964399635791779,
      "learning_rate": 0.0002609879166113398,
      "loss": 0.3896,
      "step": 128000
    },
    {
      "epoch": 5.204708561205196,
      "eval_loss": 0.42939960956573486,
      "eval_runtime": 115.7517,
      "eval_samples_per_second": 1511.01,
      "eval_steps_per_second": 47.222,
      "step": 128000
    },
    {
      "epoch": 5.208774676235591,
      "grad_norm": 0.299096941947937,
      "learning_rate": 0.0002607666091267207,
      "loss": 0.3904,
      "step": 128100
    },
    {
      "epoch": 5.212840791265985,
      "grad_norm": 0.2742798328399658,
      "learning_rate": 0.00026054530164210154,
      "loss": 0.386,
      "step": 128200
    },
    {
      "epoch": 5.216906906296379,
      "grad_norm": 0.27865928411483765,
      "learning_rate": 0.00026032399415748243,
      "loss": 0.3872,
      "step": 128300
    },
    {
      "epoch": 5.220973021326773,
      "grad_norm": 0.2740043103694916,
      "learning_rate": 0.0002601026866728633,
      "loss": 0.3907,
      "step": 128400
    },
    {
      "epoch": 5.225039136357168,
      "grad_norm": 0.28337496519088745,
      "learning_rate": 0.00025988137918824417,
      "loss": 0.3859,
      "step": 128500
    },
    {
      "epoch": 5.229105251387562,
      "grad_norm": 0.2773047983646393,
      "learning_rate": 0.00025966007170362507,
      "loss": 0.3876,
      "step": 128600
    },
    {
      "epoch": 5.233171366417956,
      "grad_norm": 0.27912718057632446,
      "learning_rate": 0.0002594387642190059,
      "loss": 0.3867,
      "step": 128700
    },
    {
      "epoch": 5.23723748144835,
      "grad_norm": 0.289467453956604,
      "learning_rate": 0.00025921745673438676,
      "loss": 0.3889,
      "step": 128800
    },
    {
      "epoch": 5.241303596478744,
      "grad_norm": 0.284037321805954,
      "learning_rate": 0.0002589961492497676,
      "loss": 0.3878,
      "step": 128900
    },
    {
      "epoch": 5.245369711509139,
      "grad_norm": 0.2671233117580414,
      "learning_rate": 0.0002587748417651485,
      "loss": 0.3868,
      "step": 129000
    },
    {
      "epoch": 5.249435826539533,
      "grad_norm": 0.26763978600502014,
      "learning_rate": 0.00025855353428052934,
      "loss": 0.3918,
      "step": 129100
    },
    {
      "epoch": 5.253501941569927,
      "grad_norm": 0.28392356634140015,
      "learning_rate": 0.00025833222679591024,
      "loss": 0.3865,
      "step": 129200
    },
    {
      "epoch": 5.257568056600321,
      "grad_norm": 0.2960604429244995,
      "learning_rate": 0.0002581109193112911,
      "loss": 0.3868,
      "step": 129300
    },
    {
      "epoch": 5.261634171630716,
      "grad_norm": 0.24759957194328308,
      "learning_rate": 0.000257889611826672,
      "loss": 0.3882,
      "step": 129400
    },
    {
      "epoch": 5.26570028666111,
      "grad_norm": 0.2930241525173187,
      "learning_rate": 0.0002576683043420529,
      "loss": 0.3882,
      "step": 129500
    },
    {
      "epoch": 5.269766401691504,
      "grad_norm": 0.3188512325286865,
      "learning_rate": 0.0002574469968574337,
      "loss": 0.3891,
      "step": 129600
    },
    {
      "epoch": 5.273832516721898,
      "grad_norm": 0.2961437702178955,
      "learning_rate": 0.0002572256893728146,
      "loss": 0.3884,
      "step": 129700
    },
    {
      "epoch": 5.277898631752293,
      "grad_norm": 0.2622429430484772,
      "learning_rate": 0.00025700438188819546,
      "loss": 0.3875,
      "step": 129800
    },
    {
      "epoch": 5.281964746782687,
      "grad_norm": 0.2656790018081665,
      "learning_rate": 0.00025678307440357636,
      "loss": 0.3847,
      "step": 129900
    },
    {
      "epoch": 5.286030861813081,
      "grad_norm": 0.26140767335891724,
      "learning_rate": 0.0002565617669189572,
      "loss": 0.3883,
      "step": 130000
    },
    {
      "epoch": 5.286030861813081,
      "eval_loss": 0.4312443435192108,
      "eval_runtime": 115.7934,
      "eval_samples_per_second": 1510.466,
      "eval_steps_per_second": 47.205,
      "step": 130000
    },
    {
      "epoch": 5.290096976843475,
      "grad_norm": 0.2947918474674225,
      "learning_rate": 0.0002563404594343381,
      "loss": 0.391,
      "step": 130100
    },
    {
      "epoch": 5.29416309187387,
      "grad_norm": 0.27970510721206665,
      "learning_rate": 0.00025611915194971894,
      "loss": 0.3888,
      "step": 130200
    },
    {
      "epoch": 5.298229206904264,
      "grad_norm": 0.26058486104011536,
      "learning_rate": 0.00025589784446509984,
      "loss": 0.3883,
      "step": 130300
    },
    {
      "epoch": 5.302295321934658,
      "grad_norm": 0.28749993443489075,
      "learning_rate": 0.00025567653698048073,
      "loss": 0.3877,
      "step": 130400
    },
    {
      "epoch": 5.306361436965052,
      "grad_norm": 0.2845536768436432,
      "learning_rate": 0.0002554552294958615,
      "loss": 0.3892,
      "step": 130500
    },
    {
      "epoch": 5.310427551995446,
      "grad_norm": 0.2860094904899597,
      "learning_rate": 0.0002552339220112424,
      "loss": 0.3901,
      "step": 130600
    },
    {
      "epoch": 5.3144936670258405,
      "grad_norm": 0.28296613693237305,
      "learning_rate": 0.00025501261452662326,
      "loss": 0.3876,
      "step": 130700
    },
    {
      "epoch": 5.3185597820562345,
      "grad_norm": 0.2648969292640686,
      "learning_rate": 0.00025479130704200416,
      "loss": 0.386,
      "step": 130800
    },
    {
      "epoch": 5.3226258970866285,
      "grad_norm": 0.2628331482410431,
      "learning_rate": 0.000254569999557385,
      "loss": 0.391,
      "step": 130900
    },
    {
      "epoch": 5.3266920121170225,
      "grad_norm": 0.2689237892627716,
      "learning_rate": 0.0002543486920727659,
      "loss": 0.3875,
      "step": 131000
    },
    {
      "epoch": 5.330758127147417,
      "grad_norm": 0.2809916138648987,
      "learning_rate": 0.00025412738458814674,
      "loss": 0.3845,
      "step": 131100
    },
    {
      "epoch": 5.334824242177811,
      "grad_norm": 0.2661357522010803,
      "learning_rate": 0.00025390607710352764,
      "loss": 0.3865,
      "step": 131200
    },
    {
      "epoch": 5.338890357208205,
      "grad_norm": 0.2775728702545166,
      "learning_rate": 0.00025368476961890854,
      "loss": 0.3888,
      "step": 131300
    },
    {
      "epoch": 5.342956472238599,
      "grad_norm": 0.2570585012435913,
      "learning_rate": 0.0002534634621342894,
      "loss": 0.3882,
      "step": 131400
    },
    {
      "epoch": 5.347022587268993,
      "grad_norm": 0.27817022800445557,
      "learning_rate": 0.0002532421546496703,
      "loss": 0.3891,
      "step": 131500
    },
    {
      "epoch": 5.351088702299388,
      "grad_norm": 0.2644197940826416,
      "learning_rate": 0.0002530208471650511,
      "loss": 0.3893,
      "step": 131600
    },
    {
      "epoch": 5.355154817329782,
      "grad_norm": 0.27621200680732727,
      "learning_rate": 0.000252799539680432,
      "loss": 0.3862,
      "step": 131700
    },
    {
      "epoch": 5.359220932360176,
      "grad_norm": 0.3024686872959137,
      "learning_rate": 0.00025257823219581286,
      "loss": 0.3869,
      "step": 131800
    },
    {
      "epoch": 5.36328704739057,
      "grad_norm": 0.2540075480937958,
      "learning_rate": 0.00025235692471119376,
      "loss": 0.3903,
      "step": 131900
    },
    {
      "epoch": 5.367353162420965,
      "grad_norm": 0.3300374746322632,
      "learning_rate": 0.00025213561722657466,
      "loss": 0.3879,
      "step": 132000
    },
    {
      "epoch": 5.367353162420965,
      "eval_loss": 0.42570164799690247,
      "eval_runtime": 116.8904,
      "eval_samples_per_second": 1496.291,
      "eval_steps_per_second": 46.762,
      "step": 132000
    },
    {
      "epoch": 5.371439608026511,
      "grad_norm": 0.2859431505203247,
      "learning_rate": 0.0002519143097419555,
      "loss": 0.3872,
      "step": 132100
    },
    {
      "epoch": 5.375505723056905,
      "grad_norm": 0.2877204418182373,
      "learning_rate": 0.00025169300225733634,
      "loss": 0.3874,
      "step": 132200
    },
    {
      "epoch": 5.379571838087299,
      "grad_norm": 0.236015185713768,
      "learning_rate": 0.0002514716947727172,
      "loss": 0.3853,
      "step": 132300
    },
    {
      "epoch": 5.383637953117693,
      "grad_norm": 0.2755698263645172,
      "learning_rate": 0.0002512503872880981,
      "loss": 0.3897,
      "step": 132400
    },
    {
      "epoch": 5.387704068148087,
      "grad_norm": 0.2775174379348755,
      "learning_rate": 0.00025102907980347893,
      "loss": 0.3872,
      "step": 132500
    },
    {
      "epoch": 5.391770183178482,
      "grad_norm": 0.28567469120025635,
      "learning_rate": 0.0002508077723188598,
      "loss": 0.3907,
      "step": 132600
    },
    {
      "epoch": 5.395836298208876,
      "grad_norm": 0.28721439838409424,
      "learning_rate": 0.00025058646483424067,
      "loss": 0.3919,
      "step": 132700
    },
    {
      "epoch": 5.39990241323927,
      "grad_norm": 0.27419358491897583,
      "learning_rate": 0.00025036515734962157,
      "loss": 0.3851,
      "step": 132800
    },
    {
      "epoch": 5.403968528269664,
      "grad_norm": 0.29032444953918457,
      "learning_rate": 0.00025014384986500246,
      "loss": 0.3874,
      "step": 132900
    },
    {
      "epoch": 5.408034643300059,
      "grad_norm": 0.31498104333877563,
      "learning_rate": 0.0002499225423803833,
      "loss": 0.3892,
      "step": 133000
    },
    {
      "epoch": 5.412100758330453,
      "grad_norm": 0.2862599790096283,
      "learning_rate": 0.0002497012348957642,
      "loss": 0.3875,
      "step": 133100
    },
    {
      "epoch": 5.416166873360847,
      "grad_norm": 0.2955448031425476,
      "learning_rate": 0.00024947992741114505,
      "loss": 0.3883,
      "step": 133200
    },
    {
      "epoch": 5.420232988391241,
      "grad_norm": 0.2870903015136719,
      "learning_rate": 0.00024925861992652594,
      "loss": 0.3899,
      "step": 133300
    },
    {
      "epoch": 5.424299103421636,
      "grad_norm": 0.28222066164016724,
      "learning_rate": 0.0002490373124419068,
      "loss": 0.3885,
      "step": 133400
    },
    {
      "epoch": 5.42836521845203,
      "grad_norm": 0.3118886351585388,
      "learning_rate": 0.00024881600495728763,
      "loss": 0.3879,
      "step": 133500
    },
    {
      "epoch": 5.432431333482424,
      "grad_norm": 0.27717122435569763,
      "learning_rate": 0.0002485946974726685,
      "loss": 0.3897,
      "step": 133600
    },
    {
      "epoch": 5.436497448512818,
      "grad_norm": 0.2916163206100464,
      "learning_rate": 0.0002483733899880494,
      "loss": 0.3874,
      "step": 133700
    },
    {
      "epoch": 5.440563563543213,
      "grad_norm": 0.3297065794467926,
      "learning_rate": 0.00024815208250343027,
      "loss": 0.3872,
      "step": 133800
    },
    {
      "epoch": 5.444629678573607,
      "grad_norm": 0.2960517704486847,
      "learning_rate": 0.00024793077501881116,
      "loss": 0.389,
      "step": 133900
    },
    {
      "epoch": 5.448695793604001,
      "grad_norm": 0.2536526322364807,
      "learning_rate": 0.000247709467534192,
      "loss": 0.3857,
      "step": 134000
    },
    {
      "epoch": 5.448695793604001,
      "eval_loss": 0.4250790774822235,
      "eval_runtime": 116.9325,
      "eval_samples_per_second": 1495.752,
      "eval_steps_per_second": 46.745,
      "step": 134000
    },
    {
      "epoch": 5.452761908634395,
      "grad_norm": 0.3117794692516327,
      "learning_rate": 0.0002474881600495729,
      "loss": 0.3867,
      "step": 134100
    },
    {
      "epoch": 5.456828023664789,
      "grad_norm": 0.2992858290672302,
      "learning_rate": 0.00024726685256495375,
      "loss": 0.3867,
      "step": 134200
    },
    {
      "epoch": 5.460894138695184,
      "grad_norm": 0.2775003910064697,
      "learning_rate": 0.0002470455450803346,
      "loss": 0.3852,
      "step": 134300
    },
    {
      "epoch": 5.464960253725578,
      "grad_norm": 0.2724407911300659,
      "learning_rate": 0.0002468242375957155,
      "loss": 0.388,
      "step": 134400
    },
    {
      "epoch": 5.469026368755972,
      "grad_norm": 0.3052152693271637,
      "learning_rate": 0.00024660293011109633,
      "loss": 0.3865,
      "step": 134500
    },
    {
      "epoch": 5.473092483786366,
      "grad_norm": 0.30424466729164124,
      "learning_rate": 0.00024638162262647723,
      "loss": 0.3865,
      "step": 134600
    },
    {
      "epoch": 5.477158598816761,
      "grad_norm": 0.26332947611808777,
      "learning_rate": 0.0002461603151418581,
      "loss": 0.3879,
      "step": 134700
    },
    {
      "epoch": 5.481224713847155,
      "grad_norm": 0.27183932065963745,
      "learning_rate": 0.00024593900765723897,
      "loss": 0.3872,
      "step": 134800
    },
    {
      "epoch": 5.485290828877549,
      "grad_norm": 0.28296545147895813,
      "learning_rate": 0.00024571770017261987,
      "loss": 0.3839,
      "step": 134900
    },
    {
      "epoch": 5.489356943907943,
      "grad_norm": 0.30981314182281494,
      "learning_rate": 0.0002454963926880007,
      "loss": 0.3869,
      "step": 135000
    },
    {
      "epoch": 5.493423058938338,
      "grad_norm": 0.29738107323646545,
      "learning_rate": 0.00024527508520338155,
      "loss": 0.3872,
      "step": 135100
    },
    {
      "epoch": 5.497489173968732,
      "grad_norm": 0.28378617763519287,
      "learning_rate": 0.00024505377771876245,
      "loss": 0.3874,
      "step": 135200
    },
    {
      "epoch": 5.501555288999126,
      "grad_norm": 0.2920936942100525,
      "learning_rate": 0.0002448324702341433,
      "loss": 0.3853,
      "step": 135300
    },
    {
      "epoch": 5.50562140402952,
      "grad_norm": 0.3165377378463745,
      "learning_rate": 0.0002446111627495242,
      "loss": 0.3876,
      "step": 135400
    },
    {
      "epoch": 5.509687519059915,
      "grad_norm": 0.316789835691452,
      "learning_rate": 0.0002443898552649051,
      "loss": 0.3868,
      "step": 135500
    },
    {
      "epoch": 5.513753634090309,
      "grad_norm": 0.2972957491874695,
      "learning_rate": 0.00024416854778028593,
      "loss": 0.3891,
      "step": 135600
    },
    {
      "epoch": 5.517819749120703,
      "grad_norm": 0.28172749280929565,
      "learning_rate": 0.0002439472402956668,
      "loss": 0.3879,
      "step": 135700
    },
    {
      "epoch": 5.521885864151097,
      "grad_norm": 0.2797256410121918,
      "learning_rate": 0.00024372593281104767,
      "loss": 0.3851,
      "step": 135800
    },
    {
      "epoch": 5.525951979181491,
      "grad_norm": 0.31142547726631165,
      "learning_rate": 0.00024350462532642857,
      "loss": 0.3857,
      "step": 135900
    },
    {
      "epoch": 5.5300180942118855,
      "grad_norm": 0.28969207406044006,
      "learning_rate": 0.0002432833178418094,
      "loss": 0.386,
      "step": 136000
    },
    {
      "epoch": 5.5300180942118855,
      "eval_loss": 0.4250774681568146,
      "eval_runtime": 115.7602,
      "eval_samples_per_second": 1510.9,
      "eval_steps_per_second": 47.218,
      "step": 136000
    },
    {
      "epoch": 5.5340842092422795,
      "grad_norm": 0.30965983867645264,
      "learning_rate": 0.00024306201035719028,
      "loss": 0.3872,
      "step": 136100
    },
    {
      "epoch": 5.5381503242726735,
      "grad_norm": 0.25857073068618774,
      "learning_rate": 0.00024284070287257115,
      "loss": 0.3865,
      "step": 136200
    },
    {
      "epoch": 5.5422164393030675,
      "grad_norm": 0.28962916135787964,
      "learning_rate": 0.00024261939538795202,
      "loss": 0.3875,
      "step": 136300
    },
    {
      "epoch": 5.546282554333462,
      "grad_norm": 0.2771768867969513,
      "learning_rate": 0.0002423980879033329,
      "loss": 0.388,
      "step": 136400
    },
    {
      "epoch": 5.550348669363856,
      "grad_norm": 0.24899770319461823,
      "learning_rate": 0.00024217678041871376,
      "loss": 0.387,
      "step": 136500
    },
    {
      "epoch": 5.55441478439425,
      "grad_norm": 0.29787328839302063,
      "learning_rate": 0.00024195547293409463,
      "loss": 0.3883,
      "step": 136600
    },
    {
      "epoch": 5.558480899424644,
      "grad_norm": 0.2978112995624542,
      "learning_rate": 0.00024173416544947553,
      "loss": 0.387,
      "step": 136700
    },
    {
      "epoch": 5.562547014455039,
      "grad_norm": 0.2648744285106659,
      "learning_rate": 0.00024151285796485637,
      "loss": 0.3848,
      "step": 136800
    },
    {
      "epoch": 5.566613129485433,
      "grad_norm": 0.27043601870536804,
      "learning_rate": 0.00024129155048023724,
      "loss": 0.3858,
      "step": 136900
    },
    {
      "epoch": 5.570679244515827,
      "grad_norm": 0.2497398555278778,
      "learning_rate": 0.00024107024299561811,
      "loss": 0.3884,
      "step": 137000
    },
    {
      "epoch": 5.574745359546221,
      "grad_norm": 0.33664190769195557,
      "learning_rate": 0.00024084893551099898,
      "loss": 0.388,
      "step": 137100
    },
    {
      "epoch": 5.578811474576616,
      "grad_norm": 0.29208213090896606,
      "learning_rate": 0.00024062762802637985,
      "loss": 0.3876,
      "step": 137200
    },
    {
      "epoch": 5.58287758960701,
      "grad_norm": 0.3014526069164276,
      "learning_rate": 0.00024040632054176073,
      "loss": 0.3867,
      "step": 137300
    },
    {
      "epoch": 5.586943704637404,
      "grad_norm": 0.2716483771800995,
      "learning_rate": 0.0002401850130571416,
      "loss": 0.383,
      "step": 137400
    },
    {
      "epoch": 5.591009819667798,
      "grad_norm": 0.32867443561553955,
      "learning_rate": 0.00023996370557252247,
      "loss": 0.3858,
      "step": 137500
    },
    {
      "epoch": 5.595075934698192,
      "grad_norm": 0.2582293748855591,
      "learning_rate": 0.00023974239808790336,
      "loss": 0.388,
      "step": 137600
    },
    {
      "epoch": 5.599142049728587,
      "grad_norm": 0.33334821462631226,
      "learning_rate": 0.0002395210906032842,
      "loss": 0.3855,
      "step": 137700
    },
    {
      "epoch": 5.603208164758981,
      "grad_norm": 0.2845669388771057,
      "learning_rate": 0.00023929978311866508,
      "loss": 0.3884,
      "step": 137800
    },
    {
      "epoch": 5.607274279789375,
      "grad_norm": 0.2850375771522522,
      "learning_rate": 0.00023907847563404595,
      "loss": 0.3874,
      "step": 137900
    },
    {
      "epoch": 5.611340394819769,
      "grad_norm": 0.29257598519325256,
      "learning_rate": 0.00023885716814942682,
      "loss": 0.3881,
      "step": 138000
    },
    {
      "epoch": 5.611340394819769,
      "eval_loss": 0.42941221594810486,
      "eval_runtime": 116.62,
      "eval_samples_per_second": 1499.76,
      "eval_steps_per_second": 46.87,
      "step": 138000
    },
    {
      "epoch": 5.615406509850164,
      "grad_norm": 0.29930490255355835,
      "learning_rate": 0.0002386358606648077,
      "loss": 0.3842,
      "step": 138100
    },
    {
      "epoch": 5.619472624880558,
      "grad_norm": 0.2813359797000885,
      "learning_rate": 0.00023841455318018856,
      "loss": 0.387,
      "step": 138200
    },
    {
      "epoch": 5.623538739910952,
      "grad_norm": 0.27144986391067505,
      "learning_rate": 0.00023819324569556943,
      "loss": 0.3871,
      "step": 138300
    },
    {
      "epoch": 5.627604854941346,
      "grad_norm": 0.2948499321937561,
      "learning_rate": 0.00023797193821095032,
      "loss": 0.3867,
      "step": 138400
    },
    {
      "epoch": 5.631670969971741,
      "grad_norm": 0.3327611982822418,
      "learning_rate": 0.00023775063072633117,
      "loss": 0.3881,
      "step": 138500
    },
    {
      "epoch": 5.635737085002135,
      "grad_norm": 0.32205599546432495,
      "learning_rate": 0.00023752932324171204,
      "loss": 0.3887,
      "step": 138600
    },
    {
      "epoch": 5.639803200032529,
      "grad_norm": 0.30916163325309753,
      "learning_rate": 0.0002373080157570929,
      "loss": 0.387,
      "step": 138700
    },
    {
      "epoch": 5.643869315062923,
      "grad_norm": 0.2526690661907196,
      "learning_rate": 0.00023708670827247378,
      "loss": 0.3849,
      "step": 138800
    },
    {
      "epoch": 5.647935430093318,
      "grad_norm": 0.287769615650177,
      "learning_rate": 0.00023686540078785465,
      "loss": 0.3876,
      "step": 138900
    },
    {
      "epoch": 5.652001545123712,
      "grad_norm": 0.29091039299964905,
      "learning_rate": 0.00023664409330323552,
      "loss": 0.3868,
      "step": 139000
    },
    {
      "epoch": 5.656067660154106,
      "grad_norm": 0.2915109097957611,
      "learning_rate": 0.0002364227858186164,
      "loss": 0.387,
      "step": 139100
    },
    {
      "epoch": 5.6601337751845,
      "grad_norm": 0.2496257871389389,
      "learning_rate": 0.00023620147833399726,
      "loss": 0.3886,
      "step": 139200
    },
    {
      "epoch": 5.664199890214894,
      "grad_norm": 0.26365798711776733,
      "learning_rate": 0.00023598017084937813,
      "loss": 0.3871,
      "step": 139300
    },
    {
      "epoch": 5.668266005245289,
      "grad_norm": 0.29275792837142944,
      "learning_rate": 0.000235758863364759,
      "loss": 0.3884,
      "step": 139400
    },
    {
      "epoch": 5.672332120275683,
      "grad_norm": 0.30515262484550476,
      "learning_rate": 0.00023553755588013987,
      "loss": 0.3875,
      "step": 139500
    },
    {
      "epoch": 5.676398235306077,
      "grad_norm": 0.26493725180625916,
      "learning_rate": 0.00023531624839552074,
      "loss": 0.3858,
      "step": 139600
    },
    {
      "epoch": 5.680464350336471,
      "grad_norm": 0.2567162811756134,
      "learning_rate": 0.0002350949409109016,
      "loss": 0.3865,
      "step": 139700
    },
    {
      "epoch": 5.684530465366866,
      "grad_norm": 0.3132031261920929,
      "learning_rate": 0.00023487363342628248,
      "loss": 0.3867,
      "step": 139800
    },
    {
      "epoch": 5.68859658039726,
      "grad_norm": 0.2832438349723816,
      "learning_rate": 0.00023465232594166335,
      "loss": 0.3853,
      "step": 139900
    },
    {
      "epoch": 5.692662695427654,
      "grad_norm": 0.2777945399284363,
      "learning_rate": 0.00023443101845704422,
      "loss": 0.3848,
      "step": 140000
    },
    {
      "epoch": 5.692662695427654,
      "eval_loss": 0.4231880009174347,
      "eval_runtime": 115.6901,
      "eval_samples_per_second": 1511.814,
      "eval_steps_per_second": 47.247,
      "step": 140000
    },
    {
      "epoch": 5.696728810458048,
      "grad_norm": 0.28306683897972107,
      "learning_rate": 0.00023420971097242512,
      "loss": 0.3872,
      "step": 140100
    },
    {
      "epoch": 5.700794925488442,
      "grad_norm": 0.2824951410293579,
      "learning_rate": 0.00023398840348780596,
      "loss": 0.3848,
      "step": 140200
    },
    {
      "epoch": 5.7048610405188365,
      "grad_norm": 0.2804540991783142,
      "learning_rate": 0.00023376709600318683,
      "loss": 0.3829,
      "step": 140300
    },
    {
      "epoch": 5.7089271555492305,
      "grad_norm": 0.25673916935920715,
      "learning_rate": 0.0002335457885185677,
      "loss": 0.3855,
      "step": 140400
    },
    {
      "epoch": 5.7129932705796245,
      "grad_norm": 0.2778720259666443,
      "learning_rate": 0.00023332448103394857,
      "loss": 0.3872,
      "step": 140500
    },
    {
      "epoch": 5.717059385610019,
      "grad_norm": 0.26350730657577515,
      "learning_rate": 0.00023310317354932944,
      "loss": 0.3852,
      "step": 140600
    },
    {
      "epoch": 5.721125500640413,
      "grad_norm": 0.29396113753318787,
      "learning_rate": 0.0002328818660647103,
      "loss": 0.3878,
      "step": 140700
    },
    {
      "epoch": 5.725191615670807,
      "grad_norm": 0.32855746150016785,
      "learning_rate": 0.00023266055858009118,
      "loss": 0.3865,
      "step": 140800
    },
    {
      "epoch": 5.729257730701201,
      "grad_norm": 0.2798190414905548,
      "learning_rate": 0.00023243925109547205,
      "loss": 0.3845,
      "step": 140900
    },
    {
      "epoch": 5.733323845731595,
      "grad_norm": 0.2917514443397522,
      "learning_rate": 0.00023221794361085292,
      "loss": 0.3867,
      "step": 141000
    },
    {
      "epoch": 5.73738996076199,
      "grad_norm": 0.28922104835510254,
      "learning_rate": 0.0002319966361262338,
      "loss": 0.3844,
      "step": 141100
    },
    {
      "epoch": 5.741456075792384,
      "grad_norm": 0.28744280338287354,
      "learning_rate": 0.00023177532864161466,
      "loss": 0.3872,
      "step": 141200
    },
    {
      "epoch": 5.745522190822778,
      "grad_norm": 0.2822403013706207,
      "learning_rate": 0.00023155402115699553,
      "loss": 0.3882,
      "step": 141300
    },
    {
      "epoch": 5.749588305853172,
      "grad_norm": 0.2894233763217926,
      "learning_rate": 0.0002313327136723764,
      "loss": 0.3879,
      "step": 141400
    },
    {
      "epoch": 5.753654420883567,
      "grad_norm": 0.31492725014686584,
      "learning_rate": 0.00023111140618775727,
      "loss": 0.3882,
      "step": 141500
    },
    {
      "epoch": 5.757720535913961,
      "grad_norm": 0.31829750537872314,
      "learning_rate": 0.00023089009870313814,
      "loss": 0.3846,
      "step": 141600
    },
    {
      "epoch": 5.761786650944355,
      "grad_norm": 0.2848344147205353,
      "learning_rate": 0.00023066879121851901,
      "loss": 0.3892,
      "step": 141700
    },
    {
      "epoch": 5.765852765974749,
      "grad_norm": 0.3076757788658142,
      "learning_rate": 0.00023044748373389989,
      "loss": 0.3883,
      "step": 141800
    },
    {
      "epoch": 5.769918881005143,
      "grad_norm": 0.2644425630569458,
      "learning_rate": 0.00023022617624928076,
      "loss": 0.3859,
      "step": 141900
    },
    {
      "epoch": 5.773984996035538,
      "grad_norm": 0.287383109331131,
      "learning_rate": 0.00023000486876466163,
      "loss": 0.3877,
      "step": 142000
    },
    {
      "epoch": 5.773984996035538,
      "eval_loss": 0.4238862097263336,
      "eval_runtime": 116.0087,
      "eval_samples_per_second": 1507.663,
      "eval_steps_per_second": 47.117,
      "step": 142000
    },
    {
      "epoch": 5.778051111065932,
      "grad_norm": 0.2929086983203888,
      "learning_rate": 0.0002297835612800425,
      "loss": 0.3847,
      "step": 142100
    },
    {
      "epoch": 5.782117226096326,
      "grad_norm": 0.28326234221458435,
      "learning_rate": 0.00022956225379542337,
      "loss": 0.3872,
      "step": 142200
    },
    {
      "epoch": 5.786183341126721,
      "grad_norm": 0.26747268438339233,
      "learning_rate": 0.00022934094631080424,
      "loss": 0.3878,
      "step": 142300
    },
    {
      "epoch": 5.790249456157115,
      "grad_norm": 0.2673978805541992,
      "learning_rate": 0.0002291196388261851,
      "loss": 0.3865,
      "step": 142400
    },
    {
      "epoch": 5.794315571187509,
      "grad_norm": 0.27433839440345764,
      "learning_rate": 0.00022889833134156598,
      "loss": 0.3847,
      "step": 142500
    },
    {
      "epoch": 5.798381686217903,
      "grad_norm": 0.2689759433269501,
      "learning_rate": 0.00022867702385694685,
      "loss": 0.3859,
      "step": 142600
    },
    {
      "epoch": 5.802447801248297,
      "grad_norm": 0.3031505346298218,
      "learning_rate": 0.00022845571637232772,
      "loss": 0.387,
      "step": 142700
    },
    {
      "epoch": 5.806513916278692,
      "grad_norm": 0.31153547763824463,
      "learning_rate": 0.0002282344088877086,
      "loss": 0.3853,
      "step": 142800
    },
    {
      "epoch": 5.810580031309086,
      "grad_norm": 0.2755105495452881,
      "learning_rate": 0.00022801310140308946,
      "loss": 0.3879,
      "step": 142900
    },
    {
      "epoch": 5.81464614633948,
      "grad_norm": 0.29164373874664307,
      "learning_rate": 0.00022779179391847033,
      "loss": 0.3873,
      "step": 143000
    },
    {
      "epoch": 5.818712261369874,
      "grad_norm": 0.3131345808506012,
      "learning_rate": 0.0002275704864338512,
      "loss": 0.3861,
      "step": 143100
    },
    {
      "epoch": 5.822778376400269,
      "grad_norm": 0.2814885675907135,
      "learning_rate": 0.00022734917894923207,
      "loss": 0.3869,
      "step": 143200
    },
    {
      "epoch": 5.826844491430663,
      "grad_norm": 0.3259332776069641,
      "learning_rate": 0.00022712787146461294,
      "loss": 0.385,
      "step": 143300
    },
    {
      "epoch": 5.830910606461057,
      "grad_norm": 0.322162389755249,
      "learning_rate": 0.0002269065639799938,
      "loss": 0.3857,
      "step": 143400
    },
    {
      "epoch": 5.834976721491451,
      "grad_norm": 0.26163604855537415,
      "learning_rate": 0.00022668525649537468,
      "loss": 0.385,
      "step": 143500
    },
    {
      "epoch": 5.839042836521845,
      "grad_norm": 0.31805145740509033,
      "learning_rate": 0.00022646394901075555,
      "loss": 0.3861,
      "step": 143600
    },
    {
      "epoch": 5.84310895155224,
      "grad_norm": 0.2896900475025177,
      "learning_rate": 0.00022624264152613642,
      "loss": 0.3883,
      "step": 143700
    },
    {
      "epoch": 5.847175066582634,
      "grad_norm": 0.3131246566772461,
      "learning_rate": 0.0002260213340415173,
      "loss": 0.384,
      "step": 143800
    },
    {
      "epoch": 5.851241181613028,
      "grad_norm": 0.3270280063152313,
      "learning_rate": 0.00022580002655689816,
      "loss": 0.3864,
      "step": 143900
    },
    {
      "epoch": 5.8553072966434225,
      "grad_norm": 0.29899919033050537,
      "learning_rate": 0.00022557871907227903,
      "loss": 0.3866,
      "step": 144000
    },
    {
      "epoch": 5.8553072966434225,
      "eval_loss": 0.4266214072704315,
      "eval_runtime": 115.5347,
      "eval_samples_per_second": 1513.848,
      "eval_steps_per_second": 47.31,
      "step": 144000
    },
    {
      "epoch": 5.8593734116738165,
      "grad_norm": 0.2928067445755005,
      "learning_rate": 0.0002253574115876599,
      "loss": 0.3836,
      "step": 144100
    },
    {
      "epoch": 5.8634395267042105,
      "grad_norm": 0.29902806878089905,
      "learning_rate": 0.00022513610410304077,
      "loss": 0.3864,
      "step": 144200
    },
    {
      "epoch": 5.8675056417346045,
      "grad_norm": 0.28893548250198364,
      "learning_rate": 0.00022491479661842164,
      "loss": 0.3884,
      "step": 144300
    },
    {
      "epoch": 5.8715717567649985,
      "grad_norm": 0.3000164330005646,
      "learning_rate": 0.0002246934891338025,
      "loss": 0.3847,
      "step": 144400
    },
    {
      "epoch": 5.875637871795393,
      "grad_norm": 0.3118540942668915,
      "learning_rate": 0.00022447218164918338,
      "loss": 0.3854,
      "step": 144500
    },
    {
      "epoch": 5.879703986825787,
      "grad_norm": 0.31925374269485474,
      "learning_rate": 0.00022425087416456425,
      "loss": 0.3861,
      "step": 144600
    },
    {
      "epoch": 5.883770101856181,
      "grad_norm": 0.30686667561531067,
      "learning_rate": 0.00022402956667994512,
      "loss": 0.384,
      "step": 144700
    },
    {
      "epoch": 5.887836216886575,
      "grad_norm": 0.3233722150325775,
      "learning_rate": 0.000223808259195326,
      "loss": 0.3855,
      "step": 144800
    },
    {
      "epoch": 5.89190233191697,
      "grad_norm": 0.2904854118824005,
      "learning_rate": 0.00022358695171070686,
      "loss": 0.3841,
      "step": 144900
    },
    {
      "epoch": 5.895968446947364,
      "grad_norm": 0.3016626536846161,
      "learning_rate": 0.00022336564422608773,
      "loss": 0.3873,
      "step": 145000
    },
    {
      "epoch": 5.900034561977758,
      "grad_norm": 0.27981698513031006,
      "learning_rate": 0.0002231443367414686,
      "loss": 0.3848,
      "step": 145100
    },
    {
      "epoch": 5.904100677008152,
      "grad_norm": 0.3156346082687378,
      "learning_rate": 0.00022292302925684945,
      "loss": 0.3862,
      "step": 145200
    },
    {
      "epoch": 5.908166792038546,
      "grad_norm": 0.3031073212623596,
      "learning_rate": 0.00022270172177223034,
      "loss": 0.3875,
      "step": 145300
    },
    {
      "epoch": 5.912232907068941,
      "grad_norm": 0.29842427372932434,
      "learning_rate": 0.0002224804142876112,
      "loss": 0.3859,
      "step": 145400
    },
    {
      "epoch": 5.916299022099335,
      "grad_norm": 0.27090027928352356,
      "learning_rate": 0.00022225910680299208,
      "loss": 0.3857,
      "step": 145500
    },
    {
      "epoch": 5.920365137129729,
      "grad_norm": 0.3112843930721283,
      "learning_rate": 0.00022203779931837295,
      "loss": 0.3871,
      "step": 145600
    },
    {
      "epoch": 5.924431252160123,
      "grad_norm": 0.306355744600296,
      "learning_rate": 0.00022181649183375382,
      "loss": 0.3865,
      "step": 145700
    },
    {
      "epoch": 5.928497367190518,
      "grad_norm": 0.2907913029193878,
      "learning_rate": 0.0002215951843491347,
      "loss": 0.3855,
      "step": 145800
    },
    {
      "epoch": 5.932563482220912,
      "grad_norm": 0.32450374960899353,
      "learning_rate": 0.00022137387686451556,
      "loss": 0.3871,
      "step": 145900
    },
    {
      "epoch": 5.936629597251306,
      "grad_norm": 0.28217196464538574,
      "learning_rate": 0.00022115256937989643,
      "loss": 0.3869,
      "step": 146000
    },
    {
      "epoch": 5.936629597251306,
      "eval_loss": 0.4211070239543915,
      "eval_runtime": 115.0264,
      "eval_samples_per_second": 1520.538,
      "eval_steps_per_second": 47.52,
      "step": 146000
    },
    {
      "epoch": 5.9406957122817,
      "grad_norm": 0.3149111568927765,
      "learning_rate": 0.0002209312618952773,
      "loss": 0.3855,
      "step": 146100
    },
    {
      "epoch": 5.944761827312095,
      "grad_norm": 0.31181204319000244,
      "learning_rate": 0.00022070995441065817,
      "loss": 0.3851,
      "step": 146200
    },
    {
      "epoch": 5.948827942342489,
      "grad_norm": 0.30492767691612244,
      "learning_rate": 0.00022048864692603905,
      "loss": 0.3871,
      "step": 146300
    },
    {
      "epoch": 5.952894057372883,
      "grad_norm": 0.3347945809364319,
      "learning_rate": 0.00022026733944141992,
      "loss": 0.3866,
      "step": 146400
    },
    {
      "epoch": 5.956960172403277,
      "grad_norm": 0.3268507122993469,
      "learning_rate": 0.00022004603195680079,
      "loss": 0.3852,
      "step": 146500
    },
    {
      "epoch": 5.961026287433672,
      "grad_norm": 0.28516289591789246,
      "learning_rate": 0.00021982472447218166,
      "loss": 0.386,
      "step": 146600
    },
    {
      "epoch": 5.965092402464066,
      "grad_norm": 0.31451112031936646,
      "learning_rate": 0.00021960341698756253,
      "loss": 0.3864,
      "step": 146700
    },
    {
      "epoch": 5.96915851749446,
      "grad_norm": 0.28702613711357117,
      "learning_rate": 0.0002193821095029434,
      "loss": 0.3869,
      "step": 146800
    },
    {
      "epoch": 5.973224632524854,
      "grad_norm": 0.2723599374294281,
      "learning_rate": 0.00021916080201832424,
      "loss": 0.3858,
      "step": 146900
    },
    {
      "epoch": 5.977290747555248,
      "grad_norm": 0.283764511346817,
      "learning_rate": 0.00021893949453370514,
      "loss": 0.3868,
      "step": 147000
    },
    {
      "epoch": 5.981356862585643,
      "grad_norm": 0.2953172028064728,
      "learning_rate": 0.000218718187049086,
      "loss": 0.3857,
      "step": 147100
    },
    {
      "epoch": 5.985422977616037,
      "grad_norm": 0.2819613218307495,
      "learning_rate": 0.00021849687956446688,
      "loss": 0.3872,
      "step": 147200
    },
    {
      "epoch": 5.989489092646431,
      "grad_norm": 0.2973901629447937,
      "learning_rate": 0.00021827557207984775,
      "loss": 0.385,
      "step": 147300
    },
    {
      "epoch": 5.993555207676825,
      "grad_norm": 0.2883446216583252,
      "learning_rate": 0.00021805426459522862,
      "loss": 0.3864,
      "step": 147400
    },
    {
      "epoch": 5.99762132270722,
      "grad_norm": 0.27940818667411804,
      "learning_rate": 0.0002178329571106095,
      "loss": 0.3872,
      "step": 147500
    },
    {
      "epoch": 6.001687437737614,
      "grad_norm": 0.2817601263523102,
      "learning_rate": 0.00021761164962599036,
      "loss": 0.3849,
      "step": 147600
    },
    {
      "epoch": 6.005753552768008,
      "grad_norm": 0.318145215511322,
      "learning_rate": 0.00021739034214137123,
      "loss": 0.3834,
      "step": 147700
    },
    {
      "epoch": 6.009819667798402,
      "grad_norm": 0.3033268451690674,
      "learning_rate": 0.00021716903465675207,
      "loss": 0.385,
      "step": 147800
    },
    {
      "epoch": 6.013885782828797,
      "grad_norm": 0.25899580121040344,
      "learning_rate": 0.00021694772717213297,
      "loss": 0.3836,
      "step": 147900
    },
    {
      "epoch": 6.017951897859191,
      "grad_norm": 0.2919735908508301,
      "learning_rate": 0.00021672641968751384,
      "loss": 0.3828,
      "step": 148000
    },
    {
      "epoch": 6.017951897859191,
      "eval_loss": 0.42082011699676514,
      "eval_runtime": 116.8568,
      "eval_samples_per_second": 1496.721,
      "eval_steps_per_second": 46.775,
      "step": 148000
    },
    {
      "epoch": 6.022018012889585,
      "grad_norm": 0.26863524317741394,
      "learning_rate": 0.0002165051122028947,
      "loss": 0.3839,
      "step": 148100
    },
    {
      "epoch": 6.026084127919979,
      "grad_norm": 0.3030194044113159,
      "learning_rate": 0.00021628380471827558,
      "loss": 0.384,
      "step": 148200
    },
    {
      "epoch": 6.0301502429503735,
      "grad_norm": 0.3618159592151642,
      "learning_rate": 0.00021606249723365645,
      "loss": 0.3851,
      "step": 148300
    },
    {
      "epoch": 6.0342163579807675,
      "grad_norm": 0.3090188801288605,
      "learning_rate": 0.00021584118974903732,
      "loss": 0.3822,
      "step": 148400
    },
    {
      "epoch": 6.0382824730111615,
      "grad_norm": 0.3251413404941559,
      "learning_rate": 0.0002156198822644182,
      "loss": 0.3824,
      "step": 148500
    },
    {
      "epoch": 6.0423485880415555,
      "grad_norm": 0.3183114230632782,
      "learning_rate": 0.00021539857477979903,
      "loss": 0.3839,
      "step": 148600
    },
    {
      "epoch": 6.0464147030719495,
      "grad_norm": 0.32428058981895447,
      "learning_rate": 0.00021517726729517993,
      "loss": 0.3838,
      "step": 148700
    },
    {
      "epoch": 6.050480818102344,
      "grad_norm": 0.3143313229084015,
      "learning_rate": 0.0002149559598105608,
      "loss": 0.3828,
      "step": 148800
    },
    {
      "epoch": 6.054546933132738,
      "grad_norm": 0.28792038559913635,
      "learning_rate": 0.00021473465232594167,
      "loss": 0.3845,
      "step": 148900
    },
    {
      "epoch": 6.058613048163132,
      "grad_norm": 0.3246903121471405,
      "learning_rate": 0.00021451334484132254,
      "loss": 0.386,
      "step": 149000
    },
    {
      "epoch": 6.062679163193526,
      "grad_norm": 0.3270414173603058,
      "learning_rate": 0.0002142920373567034,
      "loss": 0.3858,
      "step": 149100
    },
    {
      "epoch": 6.066745278223921,
      "grad_norm": 0.29805997014045715,
      "learning_rate": 0.00021407072987208428,
      "loss": 0.3841,
      "step": 149200
    },
    {
      "epoch": 6.070811393254315,
      "grad_norm": 0.25337472558021545,
      "learning_rate": 0.00021384942238746515,
      "loss": 0.3843,
      "step": 149300
    },
    {
      "epoch": 6.074877508284709,
      "grad_norm": 0.3368959426879883,
      "learning_rate": 0.00021362811490284602,
      "loss": 0.3866,
      "step": 149400
    },
    {
      "epoch": 6.078943623315103,
      "grad_norm": 0.2916508615016937,
      "learning_rate": 0.00021340680741822687,
      "loss": 0.3836,
      "step": 149500
    },
    {
      "epoch": 6.083009738345498,
      "grad_norm": 0.3003414571285248,
      "learning_rate": 0.00021318549993360776,
      "loss": 0.3823,
      "step": 149600
    },
    {
      "epoch": 6.087075853375892,
      "grad_norm": 0.28906840085983276,
      "learning_rate": 0.00021296419244898863,
      "loss": 0.3831,
      "step": 149700
    },
    {
      "epoch": 6.091141968406286,
      "grad_norm": 0.3024364113807678,
      "learning_rate": 0.0002127428849643695,
      "loss": 0.3823,
      "step": 149800
    },
    {
      "epoch": 6.09520808343668,
      "grad_norm": 0.3242819607257843,
      "learning_rate": 0.00021252157747975037,
      "loss": 0.3826,
      "step": 149900
    },
    {
      "epoch": 6.099274198467075,
      "grad_norm": 0.3348431885242462,
      "learning_rate": 0.00021230026999513124,
      "loss": 0.3844,
      "step": 150000
    },
    {
      "epoch": 6.099274198467075,
      "eval_loss": 0.4270555377006531,
      "eval_runtime": 115.4543,
      "eval_samples_per_second": 1514.903,
      "eval_steps_per_second": 47.343,
      "step": 150000
    },
    {
      "epoch": 6.103340313497469,
      "grad_norm": 0.3495458960533142,
      "learning_rate": 0.0002120789625105121,
      "loss": 0.386,
      "step": 150100
    },
    {
      "epoch": 6.107406428527863,
      "grad_norm": 0.31514084339141846,
      "learning_rate": 0.00021185765502589298,
      "loss": 0.385,
      "step": 150200
    },
    {
      "epoch": 6.111472543558257,
      "grad_norm": 0.3001972436904907,
      "learning_rate": 0.00021163634754127383,
      "loss": 0.3846,
      "step": 150300
    },
    {
      "epoch": 6.115538658588651,
      "grad_norm": 0.2957358956336975,
      "learning_rate": 0.00021141504005665472,
      "loss": 0.3851,
      "step": 150400
    },
    {
      "epoch": 6.119604773619046,
      "grad_norm": 0.26169484853744507,
      "learning_rate": 0.0002111937325720356,
      "loss": 0.3815,
      "step": 150500
    },
    {
      "epoch": 6.12367088864944,
      "grad_norm": 0.27928683161735535,
      "learning_rate": 0.00021097242508741646,
      "loss": 0.3826,
      "step": 150600
    },
    {
      "epoch": 6.127737003679834,
      "grad_norm": 0.3339880704879761,
      "learning_rate": 0.00021075111760279733,
      "loss": 0.3844,
      "step": 150700
    },
    {
      "epoch": 6.131803118710228,
      "grad_norm": 0.31503576040267944,
      "learning_rate": 0.0002105298101181782,
      "loss": 0.3825,
      "step": 150800
    },
    {
      "epoch": 6.135869233740623,
      "grad_norm": 0.285052627325058,
      "learning_rate": 0.00021030850263355908,
      "loss": 0.3831,
      "step": 150900
    },
    {
      "epoch": 6.139935348771017,
      "grad_norm": 0.3167891204357147,
      "learning_rate": 0.00021008719514893995,
      "loss": 0.383,
      "step": 151000
    },
    {
      "epoch": 6.144001463801411,
      "grad_norm": 0.2804487645626068,
      "learning_rate": 0.0002098658876643208,
      "loss": 0.3838,
      "step": 151100
    },
    {
      "epoch": 6.148067578831805,
      "grad_norm": 0.35590410232543945,
      "learning_rate": 0.00020964458017970166,
      "loss": 0.382,
      "step": 151200
    },
    {
      "epoch": 6.1521336938622,
      "grad_norm": 0.33550825715065,
      "learning_rate": 0.00020942327269508256,
      "loss": 0.3854,
      "step": 151300
    },
    {
      "epoch": 6.156199808892594,
      "grad_norm": 0.2964485287666321,
      "learning_rate": 0.00020920196521046343,
      "loss": 0.3858,
      "step": 151400
    },
    {
      "epoch": 6.160265923922988,
      "grad_norm": 0.2891186475753784,
      "learning_rate": 0.0002089806577258443,
      "loss": 0.3837,
      "step": 151500
    },
    {
      "epoch": 6.164332038953382,
      "grad_norm": 0.2959677278995514,
      "learning_rate": 0.00020875935024122517,
      "loss": 0.3833,
      "step": 151600
    },
    {
      "epoch": 6.168398153983776,
      "grad_norm": 0.31221485137939453,
      "learning_rate": 0.00020853804275660604,
      "loss": 0.3835,
      "step": 151700
    },
    {
      "epoch": 6.172464269014171,
      "grad_norm": 0.3100234866142273,
      "learning_rate": 0.0002083167352719869,
      "loss": 0.384,
      "step": 151800
    },
    {
      "epoch": 6.176530384044565,
      "grad_norm": 0.3716905415058136,
      "learning_rate": 0.00020809542778736778,
      "loss": 0.382,
      "step": 151900
    },
    {
      "epoch": 6.180596499074959,
      "grad_norm": 0.32208725810050964,
      "learning_rate": 0.00020787412030274862,
      "loss": 0.3849,
      "step": 152000
    },
    {
      "epoch": 6.180596499074959,
      "eval_loss": 0.4254268407821655,
      "eval_runtime": 117.0088,
      "eval_samples_per_second": 1494.776,
      "eval_steps_per_second": 46.714,
      "step": 152000
    },
    {
      "epoch": 6.184662614105353,
      "grad_norm": 0.282954603433609,
      "learning_rate": 0.00020765281281812952,
      "loss": 0.3866,
      "step": 152100
    },
    {
      "epoch": 6.188728729135748,
      "grad_norm": 0.3422304689884186,
      "learning_rate": 0.0002074315053335104,
      "loss": 0.3842,
      "step": 152200
    },
    {
      "epoch": 6.192794844166142,
      "grad_norm": 0.3137388825416565,
      "learning_rate": 0.00020721019784889126,
      "loss": 0.3833,
      "step": 152300
    },
    {
      "epoch": 6.196860959196536,
      "grad_norm": 0.33247125148773193,
      "learning_rate": 0.00020698889036427213,
      "loss": 0.3846,
      "step": 152400
    },
    {
      "epoch": 6.20092707422693,
      "grad_norm": 0.3292924761772156,
      "learning_rate": 0.000206767582879653,
      "loss": 0.3856,
      "step": 152500
    },
    {
      "epoch": 6.2049931892573245,
      "grad_norm": 0.31060880422592163,
      "learning_rate": 0.00020654627539503387,
      "loss": 0.3838,
      "step": 152600
    },
    {
      "epoch": 6.2090593042877185,
      "grad_norm": 0.32980239391326904,
      "learning_rate": 0.00020632496791041474,
      "loss": 0.3834,
      "step": 152700
    },
    {
      "epoch": 6.2131254193181125,
      "grad_norm": 0.31514817476272583,
      "learning_rate": 0.00020610366042579558,
      "loss": 0.3849,
      "step": 152800
    },
    {
      "epoch": 6.2171915343485065,
      "grad_norm": 0.3456808924674988,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.3854,
      "step": 152900
    },
    {
      "epoch": 6.221257649378901,
      "grad_norm": 0.3530426025390625,
      "learning_rate": 0.00020566104545655735,
      "loss": 0.3845,
      "step": 153000
    },
    {
      "epoch": 6.225323764409295,
      "grad_norm": 0.29165899753570557,
      "learning_rate": 0.00020543973797193822,
      "loss": 0.3853,
      "step": 153100
    },
    {
      "epoch": 6.229389879439689,
      "grad_norm": 0.31088709831237793,
      "learning_rate": 0.0002052184304873191,
      "loss": 0.383,
      "step": 153200
    },
    {
      "epoch": 6.233455994470083,
      "grad_norm": 0.31214338541030884,
      "learning_rate": 0.00020499712300269996,
      "loss": 0.3804,
      "step": 153300
    },
    {
      "epoch": 6.237522109500477,
      "grad_norm": 0.33987846970558167,
      "learning_rate": 0.00020477581551808083,
      "loss": 0.3839,
      "step": 153400
    },
    {
      "epoch": 6.241588224530872,
      "grad_norm": 0.3065178394317627,
      "learning_rate": 0.0002045545080334617,
      "loss": 0.3837,
      "step": 153500
    },
    {
      "epoch": 6.245654339561266,
      "grad_norm": 0.3187817335128784,
      "learning_rate": 0.00020433320054884257,
      "loss": 0.3849,
      "step": 153600
    },
    {
      "epoch": 6.24972045459166,
      "grad_norm": 0.3307322859764099,
      "learning_rate": 0.00020411189306422341,
      "loss": 0.3838,
      "step": 153700
    },
    {
      "epoch": 6.253786569622054,
      "grad_norm": 0.30951061844825745,
      "learning_rate": 0.0002038905855796043,
      "loss": 0.3846,
      "step": 153800
    },
    {
      "epoch": 6.257852684652449,
      "grad_norm": 0.305528849363327,
      "learning_rate": 0.00020366927809498518,
      "loss": 0.3846,
      "step": 153900
    },
    {
      "epoch": 6.261918799682843,
      "grad_norm": 0.2688665986061096,
      "learning_rate": 0.00020344797061036605,
      "loss": 0.3833,
      "step": 154000
    },
    {
      "epoch": 6.261918799682843,
      "eval_loss": 0.421390563249588,
      "eval_runtime": 116.3325,
      "eval_samples_per_second": 1503.467,
      "eval_steps_per_second": 46.986,
      "step": 154000
    },
    {
      "epoch": 6.265984914713237,
      "grad_norm": 0.31086310744285583,
      "learning_rate": 0.00020322666312574692,
      "loss": 0.3794,
      "step": 154100
    },
    {
      "epoch": 6.270051029743631,
      "grad_norm": 0.33176612854003906,
      "learning_rate": 0.0002030053556411278,
      "loss": 0.3835,
      "step": 154200
    },
    {
      "epoch": 6.274117144774026,
      "grad_norm": 0.31889235973358154,
      "learning_rate": 0.00020278404815650866,
      "loss": 0.3834,
      "step": 154300
    },
    {
      "epoch": 6.27818325980442,
      "grad_norm": 0.29693078994750977,
      "learning_rate": 0.00020256274067188953,
      "loss": 0.3836,
      "step": 154400
    },
    {
      "epoch": 6.282249374834814,
      "grad_norm": 0.3003003001213074,
      "learning_rate": 0.00020234143318727038,
      "loss": 0.3826,
      "step": 154500
    },
    {
      "epoch": 6.286315489865208,
      "grad_norm": 0.3074086606502533,
      "learning_rate": 0.00020212012570265125,
      "loss": 0.383,
      "step": 154600
    },
    {
      "epoch": 6.290381604895602,
      "grad_norm": 0.3080226480960846,
      "learning_rate": 0.00020189881821803214,
      "loss": 0.3844,
      "step": 154700
    },
    {
      "epoch": 6.294447719925997,
      "grad_norm": 0.3166583180427551,
      "learning_rate": 0.00020167751073341301,
      "loss": 0.3812,
      "step": 154800
    },
    {
      "epoch": 6.298513834956391,
      "grad_norm": 0.2986464500427246,
      "learning_rate": 0.00020145620324879388,
      "loss": 0.3819,
      "step": 154900
    },
    {
      "epoch": 6.302579949986785,
      "grad_norm": 0.3177468776702881,
      "learning_rate": 0.00020123489576417475,
      "loss": 0.3839,
      "step": 155000
    },
    {
      "epoch": 6.306646065017179,
      "grad_norm": 0.3140467405319214,
      "learning_rate": 0.00020101358827955562,
      "loss": 0.3844,
      "step": 155100
    },
    {
      "epoch": 6.310712180047574,
      "grad_norm": 0.3508355915546417,
      "learning_rate": 0.0002007922807949365,
      "loss": 0.3845,
      "step": 155200
    },
    {
      "epoch": 6.314778295077968,
      "grad_norm": 0.3006902039051056,
      "learning_rate": 0.00020057097331031736,
      "loss": 0.3835,
      "step": 155300
    },
    {
      "epoch": 6.318844410108362,
      "grad_norm": 0.2958090901374817,
      "learning_rate": 0.0002003496658256982,
      "loss": 0.3859,
      "step": 155400
    },
    {
      "epoch": 6.322910525138756,
      "grad_norm": 0.3361320495605469,
      "learning_rate": 0.0002001283583410791,
      "loss": 0.385,
      "step": 155500
    },
    {
      "epoch": 6.326976640169151,
      "grad_norm": 0.2830665111541748,
      "learning_rate": 0.00019990705085645998,
      "loss": 0.3843,
      "step": 155600
    },
    {
      "epoch": 6.331042755199545,
      "grad_norm": 0.3195453882217407,
      "learning_rate": 0.00019968574337184085,
      "loss": 0.3817,
      "step": 155700
    },
    {
      "epoch": 6.335108870229939,
      "grad_norm": 0.29468587040901184,
      "learning_rate": 0.00019946443588722172,
      "loss": 0.3831,
      "step": 155800
    },
    {
      "epoch": 6.339174985260333,
      "grad_norm": 0.303591251373291,
      "learning_rate": 0.00019924312840260259,
      "loss": 0.3817,
      "step": 155900
    },
    {
      "epoch": 6.343241100290728,
      "grad_norm": 0.29412445425987244,
      "learning_rate": 0.00019902182091798346,
      "loss": 0.3831,
      "step": 156000
    },
    {
      "epoch": 6.343241100290728,
      "eval_loss": 0.4231654405593872,
      "eval_runtime": 117.6698,
      "eval_samples_per_second": 1486.38,
      "eval_steps_per_second": 46.452,
      "step": 156000
    },
    {
      "epoch": 6.347307215321122,
      "grad_norm": 0.32802656292915344,
      "learning_rate": 0.00019880051343336433,
      "loss": 0.3832,
      "step": 156100
    },
    {
      "epoch": 6.351373330351516,
      "grad_norm": 0.33635056018829346,
      "learning_rate": 0.00019857920594874517,
      "loss": 0.3827,
      "step": 156200
    },
    {
      "epoch": 6.35543944538191,
      "grad_norm": 0.35382407903671265,
      "learning_rate": 0.00019835789846412604,
      "loss": 0.3808,
      "step": 156300
    },
    {
      "epoch": 6.359505560412304,
      "grad_norm": 0.30874499678611755,
      "learning_rate": 0.00019813659097950694,
      "loss": 0.3833,
      "step": 156400
    },
    {
      "epoch": 6.3635716754426985,
      "grad_norm": 0.30299559235572815,
      "learning_rate": 0.0001979152834948878,
      "loss": 0.3834,
      "step": 156500
    },
    {
      "epoch": 6.3676377904730925,
      "grad_norm": 0.28711462020874023,
      "learning_rate": 0.00019769397601026868,
      "loss": 0.3812,
      "step": 156600
    },
    {
      "epoch": 6.3717039055034865,
      "grad_norm": 0.34964340925216675,
      "learning_rate": 0.00019747266852564955,
      "loss": 0.384,
      "step": 156700
    },
    {
      "epoch": 6.3757700205338805,
      "grad_norm": 0.3440895676612854,
      "learning_rate": 0.00019725136104103042,
      "loss": 0.3828,
      "step": 156800
    },
    {
      "epoch": 6.379836135564275,
      "grad_norm": 0.2835633456707001,
      "learning_rate": 0.0001970300535564113,
      "loss": 0.3837,
      "step": 156900
    },
    {
      "epoch": 6.383902250594669,
      "grad_norm": 0.30152183771133423,
      "learning_rate": 0.00019680874607179213,
      "loss": 0.3809,
      "step": 157000
    },
    {
      "epoch": 6.387968365625063,
      "grad_norm": 0.3036932945251465,
      "learning_rate": 0.000196587438587173,
      "loss": 0.384,
      "step": 157100
    },
    {
      "epoch": 6.392034480655457,
      "grad_norm": 0.3273507356643677,
      "learning_rate": 0.00019636613110255387,
      "loss": 0.3804,
      "step": 157200
    },
    {
      "epoch": 6.396100595685852,
      "grad_norm": 0.2648567855358124,
      "learning_rate": 0.00019614482361793477,
      "loss": 0.3817,
      "step": 157300
    },
    {
      "epoch": 6.400166710716246,
      "grad_norm": 0.27771157026290894,
      "learning_rate": 0.00019592351613331564,
      "loss": 0.383,
      "step": 157400
    },
    {
      "epoch": 6.40423282574664,
      "grad_norm": 0.3165484070777893,
      "learning_rate": 0.0001957022086486965,
      "loss": 0.3845,
      "step": 157500
    },
    {
      "epoch": 6.408298940777034,
      "grad_norm": 0.38199812173843384,
      "learning_rate": 0.00019548090116407738,
      "loss": 0.382,
      "step": 157600
    },
    {
      "epoch": 6.412365055807429,
      "grad_norm": 0.3017682731151581,
      "learning_rate": 0.00019525959367945825,
      "loss": 0.3822,
      "step": 157700
    },
    {
      "epoch": 6.416431170837823,
      "grad_norm": 0.3118172585964203,
      "learning_rate": 0.00019503828619483912,
      "loss": 0.3854,
      "step": 157800
    },
    {
      "epoch": 6.420497285868217,
      "grad_norm": 0.33711475133895874,
      "learning_rate": 0.00019481697871021996,
      "loss": 0.3831,
      "step": 157900
    },
    {
      "epoch": 6.424563400898611,
      "grad_norm": 0.31304025650024414,
      "learning_rate": 0.00019459567122560083,
      "loss": 0.3831,
      "step": 158000
    },
    {
      "epoch": 6.424563400898611,
      "eval_loss": 0.41989848017692566,
      "eval_runtime": 116.4396,
      "eval_samples_per_second": 1502.083,
      "eval_steps_per_second": 46.943,
      "step": 158000
    },
    {
      "epoch": 6.428629515929005,
      "grad_norm": 0.3075679540634155,
      "learning_rate": 0.00019437436374098173,
      "loss": 0.385,
      "step": 158100
    },
    {
      "epoch": 6.4326956309594,
      "grad_norm": 0.3084182143211365,
      "learning_rate": 0.0001941530562563626,
      "loss": 0.3837,
      "step": 158200
    },
    {
      "epoch": 6.436761745989794,
      "grad_norm": 0.3184679448604584,
      "learning_rate": 0.00019393174877174347,
      "loss": 0.3831,
      "step": 158300
    },
    {
      "epoch": 6.440827861020188,
      "grad_norm": 0.3282398283481598,
      "learning_rate": 0.00019371044128712434,
      "loss": 0.3849,
      "step": 158400
    },
    {
      "epoch": 6.444893976050582,
      "grad_norm": 0.330558180809021,
      "learning_rate": 0.0001934891338025052,
      "loss": 0.3821,
      "step": 158500
    },
    {
      "epoch": 6.448960091080977,
      "grad_norm": 0.298393577337265,
      "learning_rate": 0.00019326782631788608,
      "loss": 0.383,
      "step": 158600
    },
    {
      "epoch": 6.453026206111371,
      "grad_norm": 0.35460424423217773,
      "learning_rate": 0.00019304651883326693,
      "loss": 0.3812,
      "step": 158700
    },
    {
      "epoch": 6.457092321141765,
      "grad_norm": 0.3446047902107239,
      "learning_rate": 0.0001928252113486478,
      "loss": 0.384,
      "step": 158800
    },
    {
      "epoch": 6.461158436172159,
      "grad_norm": 0.28349679708480835,
      "learning_rate": 0.00019260390386402867,
      "loss": 0.381,
      "step": 158900
    },
    {
      "epoch": 6.465224551202554,
      "grad_norm": 0.35709014534950256,
      "learning_rate": 0.00019238259637940956,
      "loss": 0.3818,
      "step": 159000
    },
    {
      "epoch": 6.469290666232948,
      "grad_norm": 0.3211115300655365,
      "learning_rate": 0.00019216128889479043,
      "loss": 0.3855,
      "step": 159100
    },
    {
      "epoch": 6.473356781263342,
      "grad_norm": 0.3340644836425781,
      "learning_rate": 0.0001919399814101713,
      "loss": 0.3829,
      "step": 159200
    },
    {
      "epoch": 6.477422896293736,
      "grad_norm": 0.34150388836860657,
      "learning_rate": 0.00019171867392555217,
      "loss": 0.3844,
      "step": 159300
    },
    {
      "epoch": 6.481489011324131,
      "grad_norm": 0.3352709412574768,
      "learning_rate": 0.00019149736644093304,
      "loss": 0.3808,
      "step": 159400
    },
    {
      "epoch": 6.485555126354525,
      "grad_norm": 0.33854249119758606,
      "learning_rate": 0.00019127605895631391,
      "loss": 0.3834,
      "step": 159500
    },
    {
      "epoch": 6.489621241384919,
      "grad_norm": 0.2873185873031616,
      "learning_rate": 0.00019105475147169476,
      "loss": 0.3838,
      "step": 159600
    },
    {
      "epoch": 6.493687356415313,
      "grad_norm": 0.30888670682907104,
      "learning_rate": 0.00019083344398707563,
      "loss": 0.3836,
      "step": 159700
    },
    {
      "epoch": 6.497753471445707,
      "grad_norm": 0.34674498438835144,
      "learning_rate": 0.00019061213650245652,
      "loss": 0.3806,
      "step": 159800
    },
    {
      "epoch": 6.501819586476102,
      "grad_norm": 0.2956823706626892,
      "learning_rate": 0.0001903908290178374,
      "loss": 0.3819,
      "step": 159900
    },
    {
      "epoch": 6.505885701506496,
      "grad_norm": 0.32684326171875,
      "learning_rate": 0.00019016952153321827,
      "loss": 0.3845,
      "step": 160000
    },
    {
      "epoch": 6.505885701506496,
      "eval_loss": 0.42037877440452576,
      "eval_runtime": 116.6429,
      "eval_samples_per_second": 1499.465,
      "eval_steps_per_second": 46.861,
      "step": 160000
    },
    {
      "epoch": 6.50995181653689,
      "grad_norm": 0.2999209761619568,
      "learning_rate": 0.00018994821404859914,
      "loss": 0.3846,
      "step": 160100
    },
    {
      "epoch": 6.514017931567284,
      "grad_norm": 0.2757568955421448,
      "learning_rate": 0.00018972690656398,
      "loss": 0.3813,
      "step": 160200
    },
    {
      "epoch": 6.518084046597679,
      "grad_norm": 0.36072856187820435,
      "learning_rate": 0.00018950559907936088,
      "loss": 0.3836,
      "step": 160300
    },
    {
      "epoch": 6.522150161628073,
      "grad_norm": 0.3113633394241333,
      "learning_rate": 0.00018928429159474172,
      "loss": 0.3824,
      "step": 160400
    },
    {
      "epoch": 6.526216276658467,
      "grad_norm": 0.3277401328086853,
      "learning_rate": 0.0001890629841101226,
      "loss": 0.3827,
      "step": 160500
    },
    {
      "epoch": 6.530282391688861,
      "grad_norm": 0.32612815499305725,
      "learning_rate": 0.00018884167662550346,
      "loss": 0.3851,
      "step": 160600
    },
    {
      "epoch": 6.534348506719255,
      "grad_norm": 0.34872695803642273,
      "learning_rate": 0.00018862036914088436,
      "loss": 0.3814,
      "step": 160700
    },
    {
      "epoch": 6.5384146217496495,
      "grad_norm": 0.34347644448280334,
      "learning_rate": 0.00018839906165626523,
      "loss": 0.3852,
      "step": 160800
    },
    {
      "epoch": 6.5424807367800435,
      "grad_norm": 0.34841716289520264,
      "learning_rate": 0.0001881777541716461,
      "loss": 0.3823,
      "step": 160900
    },
    {
      "epoch": 6.5465468518104375,
      "grad_norm": 0.3113255798816681,
      "learning_rate": 0.00018795644668702697,
      "loss": 0.3816,
      "step": 161000
    },
    {
      "epoch": 6.550612966840832,
      "grad_norm": 0.30346834659576416,
      "learning_rate": 0.00018773513920240784,
      "loss": 0.3825,
      "step": 161100
    },
    {
      "epoch": 6.554679081871226,
      "grad_norm": 0.2864808142185211,
      "learning_rate": 0.0001875138317177887,
      "loss": 0.3797,
      "step": 161200
    },
    {
      "epoch": 6.55874519690162,
      "grad_norm": 0.2827818691730499,
      "learning_rate": 0.00018729252423316955,
      "loss": 0.3836,
      "step": 161300
    },
    {
      "epoch": 6.562811311932014,
      "grad_norm": 0.29360902309417725,
      "learning_rate": 0.00018707121674855042,
      "loss": 0.3827,
      "step": 161400
    },
    {
      "epoch": 6.566877426962408,
      "grad_norm": 0.3369327485561371,
      "learning_rate": 0.00018684990926393132,
      "loss": 0.3825,
      "step": 161500
    },
    {
      "epoch": 6.570943541992803,
      "grad_norm": 0.29951056838035583,
      "learning_rate": 0.0001866286017793122,
      "loss": 0.3826,
      "step": 161600
    },
    {
      "epoch": 6.575009657023197,
      "grad_norm": 0.3138681650161743,
      "learning_rate": 0.00018640729429469306,
      "loss": 0.3829,
      "step": 161700
    },
    {
      "epoch": 6.579075772053591,
      "grad_norm": 0.30310767889022827,
      "learning_rate": 0.00018618598681007393,
      "loss": 0.3824,
      "step": 161800
    },
    {
      "epoch": 6.583141887083985,
      "grad_norm": 0.33627742528915405,
      "learning_rate": 0.0001859646793254548,
      "loss": 0.3843,
      "step": 161900
    },
    {
      "epoch": 6.58720800211438,
      "grad_norm": 0.2871074080467224,
      "learning_rate": 0.00018574337184083567,
      "loss": 0.3823,
      "step": 162000
    },
    {
      "epoch": 6.58720800211438,
      "eval_loss": 0.4216671586036682,
      "eval_runtime": 117.2106,
      "eval_samples_per_second": 1492.204,
      "eval_steps_per_second": 46.634,
      "step": 162000
    },
    {
      "epoch": 6.591274117144774,
      "grad_norm": 0.35738468170166016,
      "learning_rate": 0.0001855220643562165,
      "loss": 0.382,
      "step": 162100
    },
    {
      "epoch": 6.595340232175168,
      "grad_norm": 0.3395436406135559,
      "learning_rate": 0.00018530075687159738,
      "loss": 0.3825,
      "step": 162200
    },
    {
      "epoch": 6.599406347205562,
      "grad_norm": 0.3089408576488495,
      "learning_rate": 0.00018507944938697825,
      "loss": 0.3813,
      "step": 162300
    },
    {
      "epoch": 6.603472462235956,
      "grad_norm": 0.3164050579071045,
      "learning_rate": 0.00018485814190235915,
      "loss": 0.3823,
      "step": 162400
    },
    {
      "epoch": 6.607538577266351,
      "grad_norm": 0.3096346855163574,
      "learning_rate": 0.00018463683441774002,
      "loss": 0.3802,
      "step": 162500
    },
    {
      "epoch": 6.611604692296745,
      "grad_norm": 0.3061307668685913,
      "learning_rate": 0.0001844155269331209,
      "loss": 0.3841,
      "step": 162600
    },
    {
      "epoch": 6.615670807327139,
      "grad_norm": 0.30012816190719604,
      "learning_rate": 0.00018419421944850176,
      "loss": 0.3776,
      "step": 162700
    },
    {
      "epoch": 6.619736922357534,
      "grad_norm": 0.34159669280052185,
      "learning_rate": 0.00018397291196388263,
      "loss": 0.3829,
      "step": 162800
    },
    {
      "epoch": 6.623803037387928,
      "grad_norm": 0.3503316640853882,
      "learning_rate": 0.00018375160447926347,
      "loss": 0.3843,
      "step": 162900
    },
    {
      "epoch": 6.627869152418322,
      "grad_norm": 0.28905218839645386,
      "learning_rate": 0.00018353029699464434,
      "loss": 0.3811,
      "step": 163000
    },
    {
      "epoch": 6.631935267448716,
      "grad_norm": 0.3108663260936737,
      "learning_rate": 0.00018330898951002522,
      "loss": 0.3822,
      "step": 163100
    },
    {
      "epoch": 6.63600138247911,
      "grad_norm": 0.34426149725914,
      "learning_rate": 0.0001830876820254061,
      "loss": 0.3825,
      "step": 163200
    },
    {
      "epoch": 6.640067497509505,
      "grad_norm": 0.34412500262260437,
      "learning_rate": 0.00018286637454078698,
      "loss": 0.3812,
      "step": 163300
    },
    {
      "epoch": 6.644133612539899,
      "grad_norm": 0.3426623046398163,
      "learning_rate": 0.00018264506705616785,
      "loss": 0.3813,
      "step": 163400
    },
    {
      "epoch": 6.648199727570293,
      "grad_norm": 0.3076300024986267,
      "learning_rate": 0.00018242375957154872,
      "loss": 0.3819,
      "step": 163500
    },
    {
      "epoch": 6.652265842600687,
      "grad_norm": 0.32437294721603394,
      "learning_rate": 0.0001822024520869296,
      "loss": 0.382,
      "step": 163600
    },
    {
      "epoch": 6.656331957631082,
      "grad_norm": 0.3185428977012634,
      "learning_rate": 0.00018198114460231046,
      "loss": 0.3832,
      "step": 163700
    },
    {
      "epoch": 6.660398072661476,
      "grad_norm": 0.3290576636791229,
      "learning_rate": 0.0001817598371176913,
      "loss": 0.3811,
      "step": 163800
    },
    {
      "epoch": 6.66446418769187,
      "grad_norm": 0.335040807723999,
      "learning_rate": 0.00018153852963307218,
      "loss": 0.382,
      "step": 163900
    },
    {
      "epoch": 6.668530302722264,
      "grad_norm": 0.33175358176231384,
      "learning_rate": 0.00018131722214845305,
      "loss": 0.3813,
      "step": 164000
    },
    {
      "epoch": 6.668530302722264,
      "eval_loss": 0.42406582832336426,
      "eval_runtime": 116.4762,
      "eval_samples_per_second": 1501.611,
      "eval_steps_per_second": 46.928,
      "step": 164000
    },
    {
      "epoch": 6.672596417752658,
      "grad_norm": 0.32018062472343445,
      "learning_rate": 0.00018109591466383394,
      "loss": 0.383,
      "step": 164100
    },
    {
      "epoch": 6.676662532783053,
      "grad_norm": 0.2956872582435608,
      "learning_rate": 0.00018087460717921481,
      "loss": 0.3823,
      "step": 164200
    },
    {
      "epoch": 6.680728647813447,
      "grad_norm": 0.2825334072113037,
      "learning_rate": 0.00018065329969459568,
      "loss": 0.3837,
      "step": 164300
    },
    {
      "epoch": 6.684794762843841,
      "grad_norm": 0.3270452916622162,
      "learning_rate": 0.00018043199220997656,
      "loss": 0.3834,
      "step": 164400
    },
    {
      "epoch": 6.6888608778742356,
      "grad_norm": 0.35555747151374817,
      "learning_rate": 0.00018021068472535743,
      "loss": 0.3808,
      "step": 164500
    },
    {
      "epoch": 6.69292699290463,
      "grad_norm": 0.3408244550228119,
      "learning_rate": 0.00017998937724073827,
      "loss": 0.3842,
      "step": 164600
    },
    {
      "epoch": 6.696993107935024,
      "grad_norm": 0.3268231749534607,
      "learning_rate": 0.00017976806975611914,
      "loss": 0.383,
      "step": 164700
    },
    {
      "epoch": 6.701059222965418,
      "grad_norm": 0.31399184465408325,
      "learning_rate": 0.0001795467622715,
      "loss": 0.3827,
      "step": 164800
    },
    {
      "epoch": 6.705125337995812,
      "grad_norm": 0.35086217522621155,
      "learning_rate": 0.0001793254547868809,
      "loss": 0.3814,
      "step": 164900
    },
    {
      "epoch": 6.7091914530262065,
      "grad_norm": 0.33380305767059326,
      "learning_rate": 0.00017910414730226178,
      "loss": 0.3813,
      "step": 165000
    },
    {
      "epoch": 6.7132575680566005,
      "grad_norm": 0.3435332477092743,
      "learning_rate": 0.00017888283981764265,
      "loss": 0.3811,
      "step": 165100
    },
    {
      "epoch": 6.7173236830869945,
      "grad_norm": 0.3208691477775574,
      "learning_rate": 0.00017866153233302352,
      "loss": 0.3834,
      "step": 165200
    },
    {
      "epoch": 6.7213897981173885,
      "grad_norm": 0.32343876361846924,
      "learning_rate": 0.0001784402248484044,
      "loss": 0.3807,
      "step": 165300
    },
    {
      "epoch": 6.725455913147783,
      "grad_norm": 0.345018208026886,
      "learning_rate": 0.00017821891736378526,
      "loss": 0.3832,
      "step": 165400
    },
    {
      "epoch": 6.729522028178177,
      "grad_norm": 0.3317769467830658,
      "learning_rate": 0.0001779976098791661,
      "loss": 0.3828,
      "step": 165500
    },
    {
      "epoch": 6.733588143208571,
      "grad_norm": 0.33864498138427734,
      "learning_rate": 0.00017777630239454697,
      "loss": 0.3811,
      "step": 165600
    },
    {
      "epoch": 6.737654258238965,
      "grad_norm": 0.37451815605163574,
      "learning_rate": 0.00017755499490992784,
      "loss": 0.3785,
      "step": 165700
    },
    {
      "epoch": 6.741720373269359,
      "grad_norm": 0.3482227623462677,
      "learning_rate": 0.00017733368742530874,
      "loss": 0.3802,
      "step": 165800
    },
    {
      "epoch": 6.745786488299754,
      "grad_norm": 0.3238178789615631,
      "learning_rate": 0.0001771123799406896,
      "loss": 0.3799,
      "step": 165900
    },
    {
      "epoch": 6.749852603330148,
      "grad_norm": 0.30651599168777466,
      "learning_rate": 0.00017689107245607048,
      "loss": 0.3804,
      "step": 166000
    },
    {
      "epoch": 6.749852603330148,
      "eval_loss": 0.42246976494789124,
      "eval_runtime": 117.8206,
      "eval_samples_per_second": 1484.478,
      "eval_steps_per_second": 46.393,
      "step": 166000
    },
    {
      "epoch": 6.753918718360542,
      "grad_norm": 0.3484559953212738,
      "learning_rate": 0.00017666976497145135,
      "loss": 0.3823,
      "step": 166100
    },
    {
      "epoch": 6.757984833390936,
      "grad_norm": 0.3440537750720978,
      "learning_rate": 0.00017644845748683222,
      "loss": 0.3814,
      "step": 166200
    },
    {
      "epoch": 6.762050948421331,
      "grad_norm": 0.3248240649700165,
      "learning_rate": 0.00017622715000221306,
      "loss": 0.3832,
      "step": 166300
    },
    {
      "epoch": 6.766117063451725,
      "grad_norm": 0.3390739858150482,
      "learning_rate": 0.00017600584251759393,
      "loss": 0.3821,
      "step": 166400
    },
    {
      "epoch": 6.770183178482119,
      "grad_norm": 0.3116447627544403,
      "learning_rate": 0.0001757845350329748,
      "loss": 0.3825,
      "step": 166500
    },
    {
      "epoch": 6.774249293512513,
      "grad_norm": 0.3228241503238678,
      "learning_rate": 0.00017556322754835567,
      "loss": 0.3821,
      "step": 166600
    },
    {
      "epoch": 6.778315408542908,
      "grad_norm": 0.34115663170814514,
      "learning_rate": 0.00017534192006373657,
      "loss": 0.3828,
      "step": 166700
    },
    {
      "epoch": 6.782381523573302,
      "grad_norm": 0.3507660925388336,
      "learning_rate": 0.00017512061257911744,
      "loss": 0.3826,
      "step": 166800
    },
    {
      "epoch": 6.786447638603696,
      "grad_norm": 0.31684595346450806,
      "learning_rate": 0.0001748993050944983,
      "loss": 0.3833,
      "step": 166900
    },
    {
      "epoch": 6.79051375363409,
      "grad_norm": 0.3077879846096039,
      "learning_rate": 0.00017467799760987918,
      "loss": 0.3796,
      "step": 167000
    },
    {
      "epoch": 6.794579868664485,
      "grad_norm": 0.3344704210758209,
      "learning_rate": 0.00017445669012526005,
      "loss": 0.3815,
      "step": 167100
    },
    {
      "epoch": 6.798645983694879,
      "grad_norm": 0.30558276176452637,
      "learning_rate": 0.0001742353826406409,
      "loss": 0.3803,
      "step": 167200
    },
    {
      "epoch": 6.802712098725273,
      "grad_norm": 0.3709225654602051,
      "learning_rate": 0.00017401407515602176,
      "loss": 0.3792,
      "step": 167300
    },
    {
      "epoch": 6.806778213755667,
      "grad_norm": 0.31551095843315125,
      "learning_rate": 0.00017379276767140263,
      "loss": 0.3822,
      "step": 167400
    },
    {
      "epoch": 6.810844328786061,
      "grad_norm": 0.3393966555595398,
      "learning_rate": 0.00017357146018678353,
      "loss": 0.3813,
      "step": 167500
    },
    {
      "epoch": 6.814910443816456,
      "grad_norm": 0.3349848985671997,
      "learning_rate": 0.0001733501527021644,
      "loss": 0.3799,
      "step": 167600
    },
    {
      "epoch": 6.81897655884685,
      "grad_norm": 0.3127693235874176,
      "learning_rate": 0.00017312884521754527,
      "loss": 0.3836,
      "step": 167700
    },
    {
      "epoch": 6.823042673877244,
      "grad_norm": 0.3374948501586914,
      "learning_rate": 0.00017290753773292614,
      "loss": 0.381,
      "step": 167800
    },
    {
      "epoch": 6.827108788907638,
      "grad_norm": 0.34352147579193115,
      "learning_rate": 0.000172686230248307,
      "loss": 0.3813,
      "step": 167900
    },
    {
      "epoch": 6.831174903938033,
      "grad_norm": 0.3476889431476593,
      "learning_rate": 0.00017246492276368786,
      "loss": 0.3808,
      "step": 168000
    },
    {
      "epoch": 6.831174903938033,
      "eval_loss": 0.4205378592014313,
      "eval_runtime": 116.3849,
      "eval_samples_per_second": 1502.789,
      "eval_steps_per_second": 46.965,
      "step": 168000
    },
    {
      "epoch": 6.835241018968427,
      "grad_norm": 0.2953392267227173,
      "learning_rate": 0.00017224361527906873,
      "loss": 0.3831,
      "step": 168100
    },
    {
      "epoch": 6.839307133998821,
      "grad_norm": 0.32893607020378113,
      "learning_rate": 0.0001720223077944496,
      "loss": 0.3839,
      "step": 168200
    },
    {
      "epoch": 6.843373249029215,
      "grad_norm": 0.3102986812591553,
      "learning_rate": 0.00017180100030983047,
      "loss": 0.3795,
      "step": 168300
    },
    {
      "epoch": 6.84743936405961,
      "grad_norm": 0.3310215473175049,
      "learning_rate": 0.00017157969282521136,
      "loss": 0.382,
      "step": 168400
    },
    {
      "epoch": 6.851505479090004,
      "grad_norm": 0.3324502110481262,
      "learning_rate": 0.00017135838534059223,
      "loss": 0.3808,
      "step": 168500
    },
    {
      "epoch": 6.855571594120398,
      "grad_norm": 0.32919546961784363,
      "learning_rate": 0.0001711370778559731,
      "loss": 0.381,
      "step": 168600
    },
    {
      "epoch": 6.859637709150792,
      "grad_norm": 0.30852797627449036,
      "learning_rate": 0.00017091577037135397,
      "loss": 0.381,
      "step": 168700
    },
    {
      "epoch": 6.8637038241811865,
      "grad_norm": 0.3330884575843811,
      "learning_rate": 0.00017069446288673482,
      "loss": 0.3798,
      "step": 168800
    },
    {
      "epoch": 6.8677699392115805,
      "grad_norm": 0.3072091341018677,
      "learning_rate": 0.0001704731554021157,
      "loss": 0.3819,
      "step": 168900
    },
    {
      "epoch": 6.8718360542419745,
      "grad_norm": 0.32535865902900696,
      "learning_rate": 0.00017025184791749656,
      "loss": 0.382,
      "step": 169000
    },
    {
      "epoch": 6.8759021692723685,
      "grad_norm": 0.3637346029281616,
      "learning_rate": 0.00017003054043287743,
      "loss": 0.3838,
      "step": 169100
    },
    {
      "epoch": 6.8799682843027625,
      "grad_norm": 0.3316764533519745,
      "learning_rate": 0.00016980923294825833,
      "loss": 0.3808,
      "step": 169200
    },
    {
      "epoch": 6.884034399333157,
      "grad_norm": 0.3275231420993805,
      "learning_rate": 0.0001695879254636392,
      "loss": 0.382,
      "step": 169300
    },
    {
      "epoch": 6.888100514363551,
      "grad_norm": 0.29803046584129333,
      "learning_rate": 0.00016936661797902007,
      "loss": 0.3811,
      "step": 169400
    },
    {
      "epoch": 6.892166629393945,
      "grad_norm": 0.3323259651660919,
      "learning_rate": 0.00016914531049440094,
      "loss": 0.3781,
      "step": 169500
    },
    {
      "epoch": 6.896232744424339,
      "grad_norm": 0.3159109652042389,
      "learning_rate": 0.0001689240030097818,
      "loss": 0.3831,
      "step": 169600
    },
    {
      "epoch": 6.900298859454734,
      "grad_norm": 0.2880994975566864,
      "learning_rate": 0.00016870269552516265,
      "loss": 0.3818,
      "step": 169700
    },
    {
      "epoch": 6.904364974485128,
      "grad_norm": 0.3036905825138092,
      "learning_rate": 0.00016848138804054352,
      "loss": 0.3802,
      "step": 169800
    },
    {
      "epoch": 6.908431089515522,
      "grad_norm": 0.35509830713272095,
      "learning_rate": 0.0001682600805559244,
      "loss": 0.3821,
      "step": 169900
    },
    {
      "epoch": 6.912497204545916,
      "grad_norm": 0.3174981474876404,
      "learning_rate": 0.00016803877307130526,
      "loss": 0.3833,
      "step": 170000
    },
    {
      "epoch": 6.912497204545916,
      "eval_loss": 0.4151359498500824,
      "eval_runtime": 116.4201,
      "eval_samples_per_second": 1502.335,
      "eval_steps_per_second": 46.951,
      "step": 170000
    },
    {
      "epoch": 6.91656331957631,
      "grad_norm": 0.3007708191871643,
      "learning_rate": 0.00016781746558668616,
      "loss": 0.383,
      "step": 170100
    },
    {
      "epoch": 6.920629434606705,
      "grad_norm": 0.3163921535015106,
      "learning_rate": 0.00016759615810206703,
      "loss": 0.3808,
      "step": 170200
    },
    {
      "epoch": 6.924695549637099,
      "grad_norm": 0.3114466965198517,
      "learning_rate": 0.0001673748506174479,
      "loss": 0.3817,
      "step": 170300
    },
    {
      "epoch": 6.928761664667493,
      "grad_norm": 0.33379408717155457,
      "learning_rate": 0.00016715354313282877,
      "loss": 0.3831,
      "step": 170400
    },
    {
      "epoch": 6.932827779697888,
      "grad_norm": 0.31206634640693665,
      "learning_rate": 0.0001669322356482096,
      "loss": 0.3805,
      "step": 170500
    },
    {
      "epoch": 6.936893894728282,
      "grad_norm": 0.3208954632282257,
      "learning_rate": 0.00016671092816359048,
      "loss": 0.3805,
      "step": 170600
    },
    {
      "epoch": 6.940960009758676,
      "grad_norm": 0.30892089009284973,
      "learning_rate": 0.00016648962067897135,
      "loss": 0.3808,
      "step": 170700
    },
    {
      "epoch": 6.94502612478907,
      "grad_norm": 0.30475130677223206,
      "learning_rate": 0.00016626831319435222,
      "loss": 0.3793,
      "step": 170800
    },
    {
      "epoch": 6.949092239819464,
      "grad_norm": 0.2948262691497803,
      "learning_rate": 0.00016604700570973312,
      "loss": 0.3817,
      "step": 170900
    },
    {
      "epoch": 6.953158354849859,
      "grad_norm": 0.33661526441574097,
      "learning_rate": 0.000165825698225114,
      "loss": 0.3793,
      "step": 171000
    },
    {
      "epoch": 6.957224469880253,
      "grad_norm": 0.32305094599723816,
      "learning_rate": 0.00016560439074049486,
      "loss": 0.3816,
      "step": 171100
    },
    {
      "epoch": 6.961290584910647,
      "grad_norm": 0.34300389885902405,
      "learning_rate": 0.00016538308325587573,
      "loss": 0.3788,
      "step": 171200
    },
    {
      "epoch": 6.965356699941041,
      "grad_norm": 0.3567957282066345,
      "learning_rate": 0.0001651617757712566,
      "loss": 0.3798,
      "step": 171300
    },
    {
      "epoch": 6.969422814971436,
      "grad_norm": 0.33109956979751587,
      "learning_rate": 0.00016494046828663744,
      "loss": 0.381,
      "step": 171400
    },
    {
      "epoch": 6.97348893000183,
      "grad_norm": 0.3210655450820923,
      "learning_rate": 0.00016471916080201831,
      "loss": 0.3842,
      "step": 171500
    },
    {
      "epoch": 6.977555045032224,
      "grad_norm": 0.32757511734962463,
      "learning_rate": 0.00016449785331739918,
      "loss": 0.3813,
      "step": 171600
    },
    {
      "epoch": 6.981621160062618,
      "grad_norm": 0.3276362121105194,
      "learning_rate": 0.00016427654583278005,
      "loss": 0.3805,
      "step": 171700
    },
    {
      "epoch": 6.985687275093012,
      "grad_norm": 0.3572881519794464,
      "learning_rate": 0.00016405523834816095,
      "loss": 0.3812,
      "step": 171800
    },
    {
      "epoch": 6.989753390123407,
      "grad_norm": 0.3467954397201538,
      "learning_rate": 0.00016383393086354182,
      "loss": 0.3821,
      "step": 171900
    },
    {
      "epoch": 6.993819505153801,
      "grad_norm": 0.35190001130104065,
      "learning_rate": 0.0001636126233789227,
      "loss": 0.3815,
      "step": 172000
    },
    {
      "epoch": 6.993819505153801,
      "eval_loss": 0.41519683599472046,
      "eval_runtime": 116.6952,
      "eval_samples_per_second": 1498.794,
      "eval_steps_per_second": 46.84,
      "step": 172000
    },
    {
      "epoch": 6.997885620184195,
      "grad_norm": 0.3229966163635254,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3798,
      "step": 172100
    },
    {
      "epoch": 7.001951735214589,
      "grad_norm": 0.33036789298057556,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3816,
      "step": 172200
    },
    {
      "epoch": 7.006017850244984,
      "grad_norm": 0.3870692253112793,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.3806,
      "step": 172300
    },
    {
      "epoch": 7.010083965275378,
      "grad_norm": 0.3389478027820587,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3781,
      "step": 172400
    },
    {
      "epoch": 7.014150080305772,
      "grad_norm": 0.35826370120048523,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3809,
      "step": 172500
    },
    {
      "epoch": 7.018216195336166,
      "grad_norm": 0.3241184949874878,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.3799,
      "step": 172600
    },
    {
      "epoch": 7.022282310366561,
      "grad_norm": 0.3232346177101135,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.3797,
      "step": 172700
    },
    {
      "epoch": 7.026348425396955,
      "grad_norm": 0.34014081954956055,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.3791,
      "step": 172800
    },
    {
      "epoch": 7.030414540427349,
      "grad_norm": 0.33896952867507935,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.3795,
      "step": 172900
    },
    {
      "epoch": 7.034480655457743,
      "grad_norm": 0.3766055703163147,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3796,
      "step": 173000
    },
    {
      "epoch": 7.0385467704881375,
      "grad_norm": 0.32124391198158264,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3786,
      "step": 173100
    },
    {
      "epoch": 7.0426128855185315,
      "grad_norm": 0.30449560284614563,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3786,
      "step": 173200
    },
    {
      "epoch": 7.0466790005489255,
      "grad_norm": 0.3346886932849884,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.379,
      "step": 173300
    },
    {
      "epoch": 7.0507451155793195,
      "grad_norm": 0.3657158613204956,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3778,
      "step": 173400
    },
    {
      "epoch": 7.054811230609714,
      "grad_norm": 0.32034823298454285,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3805,
      "step": 173500
    },
    {
      "epoch": 7.058877345640108,
      "grad_norm": 0.3230416476726532,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3782,
      "step": 173600
    },
    {
      "epoch": 7.062943460670502,
      "grad_norm": 0.33793291449546814,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.3772,
      "step": 173700
    },
    {
      "epoch": 7.067009575700896,
      "grad_norm": 0.3497971296310425,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3795,
      "step": 173800
    },
    {
      "epoch": 7.07107569073129,
      "grad_norm": 0.3230345845222473,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.3793,
      "step": 173900
    },
    {
      "epoch": 7.075141805761685,
      "grad_norm": 0.32513725757598877,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3777,
      "step": 174000
    },
    {
      "epoch": 7.075141805761685,
      "eval_loss": 0.4213036596775055,
      "eval_runtime": 117.0294,
      "eval_samples_per_second": 1494.513,
      "eval_steps_per_second": 46.706,
      "step": 174000
    },
    {
      "epoch": 7.079207920792079,
      "grad_norm": 0.38490068912506104,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.3787,
      "step": 174100
    },
    {
      "epoch": 7.083274035822473,
      "grad_norm": 0.3421696424484253,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.3783,
      "step": 174200
    },
    {
      "epoch": 7.087340150852867,
      "grad_norm": 0.3488793671131134,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.3801,
      "step": 174300
    },
    {
      "epoch": 7.091406265883262,
      "grad_norm": 0.3404024839401245,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.3791,
      "step": 174400
    },
    {
      "epoch": 7.095472380913656,
      "grad_norm": 0.3534823954105377,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3792,
      "step": 174500
    },
    {
      "epoch": 7.09953849594405,
      "grad_norm": 0.31738829612731934,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.3804,
      "step": 174600
    },
    {
      "epoch": 7.103604610974444,
      "grad_norm": 0.30837008357048035,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3814,
      "step": 174700
    },
    {
      "epoch": 7.107670726004839,
      "grad_norm": 0.30513250827789307,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.3815,
      "step": 174800
    },
    {
      "epoch": 7.111736841035233,
      "grad_norm": 0.3333376348018646,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3786,
      "step": 174900
    },
    {
      "epoch": 7.115802956065627,
      "grad_norm": 0.4271174967288971,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3797,
      "step": 175000
    },
    {
      "epoch": 7.119869071096021,
      "grad_norm": 0.3287263810634613,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.3779,
      "step": 175100
    },
    {
      "epoch": 7.123935186126415,
      "grad_norm": 0.32951128482818604,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.3786,
      "step": 175200
    },
    {
      "epoch": 7.12800130115681,
      "grad_norm": 0.33261287212371826,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3797,
      "step": 175300
    },
    {
      "epoch": 7.132067416187204,
      "grad_norm": 0.35109198093414307,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3789,
      "step": 175400
    },
    {
      "epoch": 7.136133531217598,
      "grad_norm": 0.3964429795742035,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3798,
      "step": 175500
    },
    {
      "epoch": 7.140199646247992,
      "grad_norm": 0.37924879789352417,
      "learning_rate": 0.000155645553932634,
      "loss": 0.3778,
      "step": 175600
    },
    {
      "epoch": 7.144265761278387,
      "grad_norm": 0.3524000644683838,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3759,
      "step": 175700
    },
    {
      "epoch": 7.148331876308781,
      "grad_norm": 0.3580563962459564,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3794,
      "step": 175800
    },
    {
      "epoch": 7.152397991339175,
      "grad_norm": 0.33896902203559875,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3791,
      "step": 175900
    },
    {
      "epoch": 7.156464106369569,
      "grad_norm": 0.32229453325271606,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.381,
      "step": 176000
    },
    {
      "epoch": 7.156464106369569,
      "eval_loss": 0.4170382618904114,
      "eval_runtime": 117.7661,
      "eval_samples_per_second": 1485.164,
      "eval_steps_per_second": 46.414,
      "step": 176000
    },
    {
      "epoch": 7.160530221399964,
      "grad_norm": 0.37108609080314636,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.3811,
      "step": 176100
    },
    {
      "epoch": 7.164596336430358,
      "grad_norm": 0.3531918525695801,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3794,
      "step": 176200
    },
    {
      "epoch": 7.168662451460752,
      "grad_norm": 0.34092965722084045,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.3781,
      "step": 176300
    },
    {
      "epoch": 7.172728566491146,
      "grad_norm": 0.3050365149974823,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3804,
      "step": 176400
    },
    {
      "epoch": 7.176794681521541,
      "grad_norm": 0.3692329525947571,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3799,
      "step": 176500
    },
    {
      "epoch": 7.180860796551935,
      "grad_norm": 0.34727972745895386,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3769,
      "step": 176600
    },
    {
      "epoch": 7.184926911582329,
      "grad_norm": 0.36229366064071655,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.3774,
      "step": 176700
    },
    {
      "epoch": 7.188993026612723,
      "grad_norm": 0.3493765592575073,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3809,
      "step": 176800
    },
    {
      "epoch": 7.193059141643117,
      "grad_norm": 0.3148101270198822,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3788,
      "step": 176900
    },
    {
      "epoch": 7.1971252566735116,
      "grad_norm": 0.32616153359413147,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3796,
      "step": 177000
    },
    {
      "epoch": 7.2011913717039056,
      "grad_norm": 0.3328644037246704,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3807,
      "step": 177100
    },
    {
      "epoch": 7.2052574867342996,
      "grad_norm": 0.3206740617752075,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3778,
      "step": 177200
    },
    {
      "epoch": 7.209323601764694,
      "grad_norm": 0.34965780377388,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.3787,
      "step": 177300
    },
    {
      "epoch": 7.2133897167950884,
      "grad_norm": 0.3522849380970001,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.3806,
      "step": 177400
    },
    {
      "epoch": 7.2174558318254824,
      "grad_norm": 0.37255772948265076,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.379,
      "step": 177500
    },
    {
      "epoch": 7.2215219468558765,
      "grad_norm": 0.3512808084487915,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3791,
      "step": 177600
    },
    {
      "epoch": 7.2255880618862705,
      "grad_norm": 0.3352816104888916,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3778,
      "step": 177700
    },
    {
      "epoch": 7.229654176916665,
      "grad_norm": 0.32701805233955383,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.3798,
      "step": 177800
    },
    {
      "epoch": 7.233720291947059,
      "grad_norm": 0.363005131483078,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3804,
      "step": 177900
    },
    {
      "epoch": 7.237786406977453,
      "grad_norm": 0.34867551922798157,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.376,
      "step": 178000
    },
    {
      "epoch": 7.237786406977453,
      "eval_loss": 0.4175160825252533,
      "eval_runtime": 117.1082,
      "eval_samples_per_second": 1493.508,
      "eval_steps_per_second": 46.675,
      "step": 178000
    },
    {
      "epoch": 7.241852522007847,
      "grad_norm": 0.3496239185333252,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3774,
      "step": 178100
    },
    {
      "epoch": 7.245918637038242,
      "grad_norm": 0.342343807220459,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3781,
      "step": 178200
    },
    {
      "epoch": 7.249984752068636,
      "grad_norm": 0.3037126660346985,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3781,
      "step": 178300
    },
    {
      "epoch": 7.25405086709903,
      "grad_norm": 0.3624262511730194,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.3777,
      "step": 178400
    },
    {
      "epoch": 7.258116982129424,
      "grad_norm": 0.35382795333862305,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3788,
      "step": 178500
    },
    {
      "epoch": 7.262183097159818,
      "grad_norm": 0.35863178968429565,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3783,
      "step": 178600
    },
    {
      "epoch": 7.266249212190213,
      "grad_norm": 0.3638271987438202,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3789,
      "step": 178700
    },
    {
      "epoch": 7.270315327220607,
      "grad_norm": 0.342277467250824,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3782,
      "step": 178800
    },
    {
      "epoch": 7.274381442251001,
      "grad_norm": 0.33803167939186096,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3786,
      "step": 178900
    },
    {
      "epoch": 7.278447557281395,
      "grad_norm": 0.37450480461120605,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3765,
      "step": 179000
    },
    {
      "epoch": 7.28251367231179,
      "grad_norm": 0.3776898980140686,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.3786,
      "step": 179100
    },
    {
      "epoch": 7.286579787342184,
      "grad_norm": 0.43772369623184204,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3782,
      "step": 179200
    },
    {
      "epoch": 7.290645902372578,
      "grad_norm": 0.3670327365398407,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.377,
      "step": 179300
    },
    {
      "epoch": 7.294712017402972,
      "grad_norm": 0.34938526153564453,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3778,
      "step": 179400
    },
    {
      "epoch": 7.298778132433367,
      "grad_norm": 0.31391194462776184,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3801,
      "step": 179500
    },
    {
      "epoch": 7.302844247463761,
      "grad_norm": 0.38835227489471436,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3796,
      "step": 179600
    },
    {
      "epoch": 7.306910362494155,
      "grad_norm": 0.34269407391548157,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.3778,
      "step": 179700
    },
    {
      "epoch": 7.310976477524549,
      "grad_norm": 0.35534951090812683,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.3784,
      "step": 179800
    },
    {
      "epoch": 7.315042592554944,
      "grad_norm": 0.31373488903045654,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3786,
      "step": 179900
    },
    {
      "epoch": 7.319108707585338,
      "grad_norm": 0.40317481756210327,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3795,
      "step": 180000
    },
    {
      "epoch": 7.319108707585338,
      "eval_loss": 0.41766947507858276,
      "eval_runtime": 117.0173,
      "eval_samples_per_second": 1494.668,
      "eval_steps_per_second": 46.711,
      "step": 180000
    },
    {
      "epoch": 7.323174822615732,
      "grad_norm": 0.39979058504104614,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3785,
      "step": 180100
    },
    {
      "epoch": 7.327240937646126,
      "grad_norm": 0.3243303596973419,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.378,
      "step": 180200
    },
    {
      "epoch": 7.33130705267652,
      "grad_norm": 0.33159124851226807,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3764,
      "step": 180300
    },
    {
      "epoch": 7.335373167706915,
      "grad_norm": 0.3477363884449005,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.3779,
      "step": 180400
    },
    {
      "epoch": 7.339439282737309,
      "grad_norm": 0.3710249960422516,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3771,
      "step": 180500
    },
    {
      "epoch": 7.343505397767703,
      "grad_norm": 0.3590192198753357,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.3773,
      "step": 180600
    },
    {
      "epoch": 7.347571512798097,
      "grad_norm": 0.36279556155204773,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3793,
      "step": 180700
    },
    {
      "epoch": 7.351637627828492,
      "grad_norm": 0.3314878046512604,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.3769,
      "step": 180800
    },
    {
      "epoch": 7.355703742858886,
      "grad_norm": 0.326408326625824,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3776,
      "step": 180900
    },
    {
      "epoch": 7.35976985788928,
      "grad_norm": 0.33279192447662354,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3779,
      "step": 181000
    },
    {
      "epoch": 7.363835972919674,
      "grad_norm": 0.32388272881507874,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3784,
      "step": 181100
    },
    {
      "epoch": 7.3679020879500685,
      "grad_norm": 0.3618750274181366,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3789,
      "step": 181200
    },
    {
      "epoch": 7.3719682029804625,
      "grad_norm": 0.37346598505973816,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3791,
      "step": 181300
    },
    {
      "epoch": 7.3760343180108565,
      "grad_norm": 0.33048540353775024,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3779,
      "step": 181400
    },
    {
      "epoch": 7.3801004330412505,
      "grad_norm": 0.3518636226654053,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.3769,
      "step": 181500
    },
    {
      "epoch": 7.384166548071645,
      "grad_norm": 0.34983429312705994,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3772,
      "step": 181600
    },
    {
      "epoch": 7.388232663102039,
      "grad_norm": 0.32709646224975586,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.3766,
      "step": 181700
    },
    {
      "epoch": 7.392298778132433,
      "grad_norm": 0.30453380942344666,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3794,
      "step": 181800
    },
    {
      "epoch": 7.396364893162827,
      "grad_norm": 0.3568879961967468,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3785,
      "step": 181900
    },
    {
      "epoch": 7.400431008193221,
      "grad_norm": 0.35531091690063477,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3775,
      "step": 182000
    },
    {
      "epoch": 7.400431008193221,
      "eval_loss": 0.42134279012680054,
      "eval_runtime": 116.7598,
      "eval_samples_per_second": 1497.965,
      "eval_steps_per_second": 46.814,
      "step": 182000
    },
    {
      "epoch": 7.404497123223616,
      "grad_norm": 0.37128061056137085,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3775,
      "step": 182100
    },
    {
      "epoch": 7.40856323825401,
      "grad_norm": 0.3524180054664612,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.3789,
      "step": 182200
    },
    {
      "epoch": 7.412629353284404,
      "grad_norm": 0.3832598924636841,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.3776,
      "step": 182300
    },
    {
      "epoch": 7.416695468314798,
      "grad_norm": 0.3753471374511719,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3801,
      "step": 182400
    },
    {
      "epoch": 7.420761583345193,
      "grad_norm": 0.39491990208625793,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3812,
      "step": 182500
    },
    {
      "epoch": 7.424827698375587,
      "grad_norm": 0.35126689076423645,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.3772,
      "step": 182600
    },
    {
      "epoch": 7.428893813405981,
      "grad_norm": 0.391150563955307,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3817,
      "step": 182700
    },
    {
      "epoch": 7.432959928436375,
      "grad_norm": 0.34989219903945923,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3793,
      "step": 182800
    },
    {
      "epoch": 7.437026043466769,
      "grad_norm": 0.33644479513168335,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.3781,
      "step": 182900
    },
    {
      "epoch": 7.441092158497164,
      "grad_norm": 0.3360000252723694,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3774,
      "step": 183000
    },
    {
      "epoch": 7.445158273527558,
      "grad_norm": 0.3256724774837494,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3782,
      "step": 183100
    },
    {
      "epoch": 7.449224388557952,
      "grad_norm": 0.37202998995780945,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.3774,
      "step": 183200
    },
    {
      "epoch": 7.453290503588346,
      "grad_norm": 0.33421292901039124,
      "learning_rate": 0.000138604877616961,
      "loss": 0.3788,
      "step": 183300
    },
    {
      "epoch": 7.457356618618741,
      "grad_norm": 0.3719066083431244,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.3771,
      "step": 183400
    },
    {
      "epoch": 7.461422733649135,
      "grad_norm": 0.3457280099391937,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3772,
      "step": 183500
    },
    {
      "epoch": 7.465488848679529,
      "grad_norm": 0.3649623394012451,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.3787,
      "step": 183600
    },
    {
      "epoch": 7.469554963709923,
      "grad_norm": 0.3848874270915985,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3768,
      "step": 183700
    },
    {
      "epoch": 7.473621078740318,
      "grad_norm": 0.3216354250907898,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.379,
      "step": 183800
    },
    {
      "epoch": 7.477687193770712,
      "grad_norm": 0.33110350370407104,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3764,
      "step": 183900
    },
    {
      "epoch": 7.481753308801106,
      "grad_norm": 0.3667187988758087,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.3801,
      "step": 184000
    },
    {
      "epoch": 7.481753308801106,
      "eval_loss": 0.4155440330505371,
      "eval_runtime": 116.6478,
      "eval_samples_per_second": 1499.403,
      "eval_steps_per_second": 46.859,
      "step": 184000
    },
    {
      "epoch": 7.485860084981804,
      "grad_norm": 0.36135271191596985,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3783,
      "step": 184100
    },
    {
      "epoch": 7.489926200012198,
      "grad_norm": 0.3650515079498291,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.3801,
      "step": 184200
    },
    {
      "epoch": 7.4939923150425924,
      "grad_norm": 0.35262852907180786,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.3774,
      "step": 184300
    },
    {
      "epoch": 7.4980584300729864,
      "grad_norm": 0.3418218195438385,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3775,
      "step": 184400
    },
    {
      "epoch": 7.502124545103381,
      "grad_norm": 0.3473627269268036,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3781,
      "step": 184500
    },
    {
      "epoch": 7.506190660133775,
      "grad_norm": 0.3711613118648529,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.3769,
      "step": 184600
    },
    {
      "epoch": 7.510256775164169,
      "grad_norm": 0.3566746711730957,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3782,
      "step": 184700
    },
    {
      "epoch": 7.514322890194563,
      "grad_norm": 0.3807142376899719,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.376,
      "step": 184800
    },
    {
      "epoch": 7.518389005224957,
      "grad_norm": 0.3488597273826599,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.379,
      "step": 184900
    },
    {
      "epoch": 7.522455120255352,
      "grad_norm": 0.32796695828437805,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3779,
      "step": 185000
    },
    {
      "epoch": 7.526521235285746,
      "grad_norm": 0.3136918246746063,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3778,
      "step": 185100
    },
    {
      "epoch": 7.53058735031614,
      "grad_norm": 0.31661078333854675,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3784,
      "step": 185200
    },
    {
      "epoch": 7.534653465346535,
      "grad_norm": 0.3678698241710663,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3758,
      "step": 185300
    },
    {
      "epoch": 7.538719580376929,
      "grad_norm": 0.3636533319950104,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.3788,
      "step": 185400
    },
    {
      "epoch": 7.542785695407323,
      "grad_norm": 0.3837902843952179,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.3749,
      "step": 185500
    },
    {
      "epoch": 7.546851810437717,
      "grad_norm": 0.3336033523082733,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.3782,
      "step": 185600
    },
    {
      "epoch": 7.550917925468111,
      "grad_norm": 0.3258998692035675,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3775,
      "step": 185700
    },
    {
      "epoch": 7.554984040498506,
      "grad_norm": 0.3521130681037903,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3771,
      "step": 185800
    },
    {
      "epoch": 7.5590501555289,
      "grad_norm": 0.36469483375549316,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.3765,
      "step": 185900
    },
    {
      "epoch": 7.563116270559294,
      "grad_norm": 0.3326331675052643,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.3787,
      "step": 186000
    },
    {
      "epoch": 7.563116270559294,
      "eval_loss": 0.4130783677101135,
      "eval_runtime": 116.5135,
      "eval_samples_per_second": 1501.131,
      "eval_steps_per_second": 46.913,
      "step": 186000
    },
    {
      "epoch": 7.567182385589688,
      "grad_norm": 0.3436070382595062,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3786,
      "step": 186100
    },
    {
      "epoch": 7.571248500620083,
      "grad_norm": 0.3288513123989105,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.377,
      "step": 186200
    },
    {
      "epoch": 7.575314615650477,
      "grad_norm": 0.40096205472946167,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3767,
      "step": 186300
    },
    {
      "epoch": 7.579380730680871,
      "grad_norm": 0.3897892236709595,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3755,
      "step": 186400
    },
    {
      "epoch": 7.583446845711265,
      "grad_norm": 0.3156145215034485,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.3754,
      "step": 186500
    },
    {
      "epoch": 7.587512960741659,
      "grad_norm": 0.40213122963905334,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3765,
      "step": 186600
    },
    {
      "epoch": 7.591579075772054,
      "grad_norm": 0.3745218515396118,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.378,
      "step": 186700
    },
    {
      "epoch": 7.595645190802448,
      "grad_norm": 0.3553021550178528,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3759,
      "step": 186800
    },
    {
      "epoch": 7.599711305832842,
      "grad_norm": 0.389140248298645,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.3792,
      "step": 186900
    },
    {
      "epoch": 7.603777420863237,
      "grad_norm": 0.39100855588912964,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3775,
      "step": 187000
    },
    {
      "epoch": 7.607843535893631,
      "grad_norm": 0.39444035291671753,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3767,
      "step": 187100
    },
    {
      "epoch": 7.611909650924025,
      "grad_norm": 0.4089307487010956,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.3781,
      "step": 187200
    },
    {
      "epoch": 7.615975765954419,
      "grad_norm": 0.3468402624130249,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.3778,
      "step": 187300
    },
    {
      "epoch": 7.620041880984813,
      "grad_norm": 0.35555198788642883,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.3781,
      "step": 187400
    },
    {
      "epoch": 7.624107996015208,
      "grad_norm": 0.4116779863834381,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.3777,
      "step": 187500
    },
    {
      "epoch": 7.628174111045602,
      "grad_norm": 0.3399258553981781,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.3768,
      "step": 187600
    },
    {
      "epoch": 7.632240226075996,
      "grad_norm": 0.36313191056251526,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3749,
      "step": 187700
    },
    {
      "epoch": 7.63630634110639,
      "grad_norm": 0.3564719557762146,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3777,
      "step": 187800
    },
    {
      "epoch": 7.6403724561367845,
      "grad_norm": 0.35725346207618713,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3764,
      "step": 187900
    },
    {
      "epoch": 7.6444385711671785,
      "grad_norm": 0.3526036739349365,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.3755,
      "step": 188000
    },
    {
      "epoch": 7.6444385711671785,
      "eval_loss": 0.4138912558555603,
      "eval_runtime": 114.765,
      "eval_samples_per_second": 1524.001,
      "eval_steps_per_second": 47.628,
      "step": 188000
    },
    {
      "epoch": 7.6485046861975725,
      "grad_norm": 0.4227762520313263,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.3748,
      "step": 188100
    },
    {
      "epoch": 7.6525708012279665,
      "grad_norm": 0.35810020565986633,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3755,
      "step": 188200
    },
    {
      "epoch": 7.6566369162583605,
      "grad_norm": 0.382333368062973,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3774,
      "step": 188300
    },
    {
      "epoch": 7.660703031288755,
      "grad_norm": 0.3580095171928406,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3759,
      "step": 188400
    },
    {
      "epoch": 7.664769146319149,
      "grad_norm": 0.32940012216567993,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3795,
      "step": 188500
    },
    {
      "epoch": 7.668835261349543,
      "grad_norm": 0.36121487617492676,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.3779,
      "step": 188600
    },
    {
      "epoch": 7.672901376379937,
      "grad_norm": 0.3982482850551605,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3752,
      "step": 188700
    },
    {
      "epoch": 7.676967491410332,
      "grad_norm": 0.37678638100624084,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.3788,
      "step": 188800
    },
    {
      "epoch": 7.681033606440726,
      "grad_norm": 0.3549688458442688,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.3768,
      "step": 188900
    },
    {
      "epoch": 7.68509972147112,
      "grad_norm": 0.38393914699554443,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3771,
      "step": 189000
    },
    {
      "epoch": 7.689165836501514,
      "grad_norm": 0.3774562180042267,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.377,
      "step": 189100
    },
    {
      "epoch": 7.693231951531909,
      "grad_norm": 0.3784199059009552,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.3746,
      "step": 189200
    },
    {
      "epoch": 7.697298066562303,
      "grad_norm": 0.3424302041530609,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.3769,
      "step": 189300
    },
    {
      "epoch": 7.701364181592697,
      "grad_norm": 0.37412723898887634,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.3767,
      "step": 189400
    },
    {
      "epoch": 7.705430296623091,
      "grad_norm": 0.37623053789138794,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3768,
      "step": 189500
    },
    {
      "epoch": 7.709496411653486,
      "grad_norm": 0.3473663926124573,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.3792,
      "step": 189600
    },
    {
      "epoch": 7.71356252668388,
      "grad_norm": 0.3928166627883911,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3772,
      "step": 189700
    },
    {
      "epoch": 7.717628641714274,
      "grad_norm": 0.3358934223651886,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.376,
      "step": 189800
    },
    {
      "epoch": 7.721694756744668,
      "grad_norm": 0.32667264342308044,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3777,
      "step": 189900
    },
    {
      "epoch": 7.725760871775062,
      "grad_norm": 0.39512112736701965,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.3773,
      "step": 190000
    },
    {
      "epoch": 7.725760871775062,
      "eval_loss": 0.41272541880607605,
      "eval_runtime": 116.4473,
      "eval_samples_per_second": 1501.984,
      "eval_steps_per_second": 46.94,
      "step": 190000
    },
    {
      "epoch": 7.729826986805457,
      "grad_norm": 0.391378790140152,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3768,
      "step": 190100
    },
    {
      "epoch": 7.733893101835851,
      "grad_norm": 0.36994534730911255,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3771,
      "step": 190200
    },
    {
      "epoch": 7.737959216866245,
      "grad_norm": 0.3859698474407196,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.377,
      "step": 190300
    },
    {
      "epoch": 7.742025331896639,
      "grad_norm": 0.35545074939727783,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.3759,
      "step": 190400
    },
    {
      "epoch": 7.746091446927034,
      "grad_norm": 0.34354496002197266,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3776,
      "step": 190500
    },
    {
      "epoch": 7.750157561957428,
      "grad_norm": 0.3506121337413788,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.3778,
      "step": 190600
    },
    {
      "epoch": 7.754223676987822,
      "grad_norm": 0.38855549693107605,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3758,
      "step": 190700
    },
    {
      "epoch": 7.758289792018216,
      "grad_norm": 0.3588859736919403,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3756,
      "step": 190800
    },
    {
      "epoch": 7.762355907048611,
      "grad_norm": 0.3493208587169647,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.3785,
      "step": 190900
    },
    {
      "epoch": 7.766422022079005,
      "grad_norm": 0.33172911405563354,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3741,
      "step": 191000
    },
    {
      "epoch": 7.770488137109399,
      "grad_norm": 0.3387766182422638,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3757,
      "step": 191100
    },
    {
      "epoch": 7.774554252139793,
      "grad_norm": 0.3587525486946106,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3774,
      "step": 191200
    },
    {
      "epoch": 7.778620367170188,
      "grad_norm": 0.4135570228099823,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3762,
      "step": 191300
    },
    {
      "epoch": 7.782686482200582,
      "grad_norm": 0.3831793963909149,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.378,
      "step": 191400
    },
    {
      "epoch": 7.786752597230976,
      "grad_norm": 0.3588210642337799,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3763,
      "step": 191500
    },
    {
      "epoch": 7.79081871226137,
      "grad_norm": 0.3269636034965515,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3772,
      "step": 191600
    },
    {
      "epoch": 7.794884827291764,
      "grad_norm": 0.3566107451915741,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3747,
      "step": 191700
    },
    {
      "epoch": 7.798950942322159,
      "grad_norm": 0.3509789705276489,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.3768,
      "step": 191800
    },
    {
      "epoch": 7.803017057352553,
      "grad_norm": 0.3702279031276703,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3748,
      "step": 191900
    },
    {
      "epoch": 7.807083172382947,
      "grad_norm": 0.37120819091796875,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3757,
      "step": 192000
    },
    {
      "epoch": 7.807083172382947,
      "eval_loss": 0.41299110651016235,
      "eval_runtime": 112.8838,
      "eval_samples_per_second": 1549.399,
      "eval_steps_per_second": 48.421,
      "step": 192000
    },
    {
      "epoch": 7.811149287413341,
      "grad_norm": 0.36080870032310486,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.3782,
      "step": 192100
    },
    {
      "epoch": 7.8152154024437355,
      "grad_norm": 0.34161436557769775,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.3764,
      "step": 192200
    },
    {
      "epoch": 7.8192815174741295,
      "grad_norm": 0.42201969027519226,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3754,
      "step": 192300
    },
    {
      "epoch": 7.8233476325045235,
      "grad_norm": 0.3593432307243347,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.3749,
      "step": 192400
    },
    {
      "epoch": 7.8274137475349175,
      "grad_norm": 0.38182148337364197,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.3749,
      "step": 192500
    },
    {
      "epoch": 7.8314798625653115,
      "grad_norm": 0.3766591548919678,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.3772,
      "step": 192600
    },
    {
      "epoch": 7.835545977595706,
      "grad_norm": 0.34120216965675354,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3782,
      "step": 192700
    },
    {
      "epoch": 7.8396120926261,
      "grad_norm": 0.3736251890659332,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.376,
      "step": 192800
    },
    {
      "epoch": 7.843678207656494,
      "grad_norm": 0.34316399693489075,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.3742,
      "step": 192900
    },
    {
      "epoch": 7.847744322686889,
      "grad_norm": 0.3860973119735718,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.3742,
      "step": 193000
    },
    {
      "epoch": 7.851810437717283,
      "grad_norm": 0.36398714780807495,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.3769,
      "step": 193100
    },
    {
      "epoch": 7.855876552747677,
      "grad_norm": 0.3520142436027527,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3761,
      "step": 193200
    },
    {
      "epoch": 7.859942667778071,
      "grad_norm": 0.37783893942832947,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.3762,
      "step": 193300
    },
    {
      "epoch": 7.864008782808465,
      "grad_norm": 0.3477385938167572,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.3755,
      "step": 193400
    },
    {
      "epoch": 7.86807489783886,
      "grad_norm": 0.328410267829895,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3774,
      "step": 193500
    },
    {
      "epoch": 7.872141012869254,
      "grad_norm": 0.35896193981170654,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3759,
      "step": 193600
    },
    {
      "epoch": 7.876207127899648,
      "grad_norm": 0.3833966851234436,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3747,
      "step": 193700
    },
    {
      "epoch": 7.880273242930042,
      "grad_norm": 0.38931554555892944,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3776,
      "step": 193800
    },
    {
      "epoch": 7.884339357960437,
      "grad_norm": 0.3343258202075958,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3752,
      "step": 193900
    },
    {
      "epoch": 7.888405472990831,
      "grad_norm": 0.3420082926750183,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3751,
      "step": 194000
    },
    {
      "epoch": 7.888405472990831,
      "eval_loss": 0.41321223974227905,
      "eval_runtime": 111.8311,
      "eval_samples_per_second": 1563.984,
      "eval_steps_per_second": 48.877,
      "step": 194000
    },
    {
      "epoch": 7.892471588021225,
      "grad_norm": 0.3627462685108185,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3755,
      "step": 194100
    },
    {
      "epoch": 7.896537703051619,
      "grad_norm": 0.34130859375,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.3737,
      "step": 194200
    },
    {
      "epoch": 7.900603818082013,
      "grad_norm": 0.3624629080295563,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3732,
      "step": 194300
    },
    {
      "epoch": 7.904669933112408,
      "grad_norm": 0.35341566801071167,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3772,
      "step": 194400
    },
    {
      "epoch": 7.908736048142802,
      "grad_norm": 0.3648647964000702,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3753,
      "step": 194500
    },
    {
      "epoch": 7.912802163173196,
      "grad_norm": 0.4088689386844635,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.375,
      "step": 194600
    },
    {
      "epoch": 7.916868278203591,
      "grad_norm": 0.35054221749305725,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.3743,
      "step": 194700
    },
    {
      "epoch": 7.920934393233985,
      "grad_norm": 0.3965303599834442,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3763,
      "step": 194800
    },
    {
      "epoch": 7.925000508264379,
      "grad_norm": 0.4139070510864258,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3768,
      "step": 194900
    },
    {
      "epoch": 7.929066623294773,
      "grad_norm": 0.3829210698604584,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.3792,
      "step": 195000
    },
    {
      "epoch": 7.933132738325167,
      "grad_norm": 0.3668234646320343,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.3735,
      "step": 195100
    },
    {
      "epoch": 7.937198853355562,
      "grad_norm": 0.3753340244293213,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.376,
      "step": 195200
    },
    {
      "epoch": 7.941264968385956,
      "grad_norm": 0.3722160756587982,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.3742,
      "step": 195300
    },
    {
      "epoch": 7.94533108341635,
      "grad_norm": 0.3555489778518677,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3759,
      "step": 195400
    },
    {
      "epoch": 7.949397198446744,
      "grad_norm": 0.36220741271972656,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3774,
      "step": 195500
    },
    {
      "epoch": 7.953463313477139,
      "grad_norm": 0.3887833058834076,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.3773,
      "step": 195600
    },
    {
      "epoch": 7.957529428507533,
      "grad_norm": 0.39968326687812805,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.374,
      "step": 195700
    },
    {
      "epoch": 7.961595543537927,
      "grad_norm": 0.4474896788597107,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.375,
      "step": 195800
    },
    {
      "epoch": 7.965661658568321,
      "grad_norm": 0.34386876225471497,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.3741,
      "step": 195900
    },
    {
      "epoch": 7.969727773598715,
      "grad_norm": 0.3994640111923218,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3781,
      "step": 196000
    },
    {
      "epoch": 7.969727773598715,
      "eval_loss": 0.41186976432800293,
      "eval_runtime": 111.3664,
      "eval_samples_per_second": 1570.51,
      "eval_steps_per_second": 49.081,
      "step": 196000
    },
    {
      "epoch": 7.9737938886291095,
      "grad_norm": 0.34784331917762756,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.375,
      "step": 196100
    },
    {
      "epoch": 7.9778600036595035,
      "grad_norm": 0.37983155250549316,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3753,
      "step": 196200
    },
    {
      "epoch": 7.9819261186898975,
      "grad_norm": 0.37735143303871155,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3751,
      "step": 196300
    },
    {
      "epoch": 7.985992233720292,
      "grad_norm": 0.39402300119400024,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3751,
      "step": 196400
    },
    {
      "epoch": 7.990058348750686,
      "grad_norm": 0.3391478657722473,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3777,
      "step": 196500
    },
    {
      "epoch": 7.99412446378108,
      "grad_norm": 0.37323832511901855,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.3764,
      "step": 196600
    },
    {
      "epoch": 7.998190578811474,
      "grad_norm": 0.4089670479297638,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.374,
      "step": 196700
    },
    {
      "epoch": 8.002256693841868,
      "grad_norm": 0.41676363348960876,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3746,
      "step": 196800
    },
    {
      "epoch": 8.006322808872262,
      "grad_norm": 0.388052761554718,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.3725,
      "step": 196900
    },
    {
      "epoch": 8.010388923902656,
      "grad_norm": 0.3999345600605011,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3731,
      "step": 197000
    },
    {
      "epoch": 8.014455038933052,
      "grad_norm": 0.3750264346599579,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3719,
      "step": 197100
    },
    {
      "epoch": 8.018521153963446,
      "grad_norm": 0.40620920062065125,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.3732,
      "step": 197200
    },
    {
      "epoch": 8.02258726899384,
      "grad_norm": 0.40485140681266785,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.375,
      "step": 197300
    },
    {
      "epoch": 8.026653384024234,
      "grad_norm": 0.37460190057754517,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.3746,
      "step": 197400
    },
    {
      "epoch": 8.030719499054628,
      "grad_norm": 0.3713420629501343,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3752,
      "step": 197500
    },
    {
      "epoch": 8.034785614085022,
      "grad_norm": 0.40525224804878235,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.373,
      "step": 197600
    },
    {
      "epoch": 8.038851729115416,
      "grad_norm": 0.43311890959739685,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.375,
      "step": 197700
    },
    {
      "epoch": 8.04291784414581,
      "grad_norm": 0.38621264696121216,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.3739,
      "step": 197800
    },
    {
      "epoch": 8.046983959176204,
      "grad_norm": 0.4166795015335083,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3736,
      "step": 197900
    },
    {
      "epoch": 8.0510500742066,
      "grad_norm": 0.3925679326057434,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3729,
      "step": 198000
    },
    {
      "epoch": 8.0510500742066,
      "eval_loss": 0.4150751531124115,
      "eval_runtime": 112.3875,
      "eval_samples_per_second": 1556.24,
      "eval_steps_per_second": 48.635,
      "step": 198000
    },
    {
      "epoch": 8.055116189236994,
      "grad_norm": 0.34769153594970703,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3734,
      "step": 198100
    },
    {
      "epoch": 8.059182304267388,
      "grad_norm": 0.3976491391658783,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3723,
      "step": 198200
    },
    {
      "epoch": 8.063248419297782,
      "grad_norm": 0.39839306473731995,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.3734,
      "step": 198300
    },
    {
      "epoch": 8.067314534328176,
      "grad_norm": 0.3590143620967865,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3723,
      "step": 198400
    },
    {
      "epoch": 8.07138064935857,
      "grad_norm": 0.38834619522094727,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.3728,
      "step": 198500
    },
    {
      "epoch": 8.075446764388964,
      "grad_norm": 0.37820467352867126,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3712,
      "step": 198600
    },
    {
      "epoch": 8.079512879419358,
      "grad_norm": 0.39215603470802307,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3732,
      "step": 198700
    },
    {
      "epoch": 8.083578994449754,
      "grad_norm": 0.3287199139595032,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3751,
      "step": 198800
    },
    {
      "epoch": 8.087645109480148,
      "grad_norm": 0.4155929684638977,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.374,
      "step": 198900
    },
    {
      "epoch": 8.091711224510542,
      "grad_norm": 0.4008813500404358,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3726,
      "step": 199000
    },
    {
      "epoch": 8.095777339540936,
      "grad_norm": 0.4355078637599945,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3748,
      "step": 199100
    },
    {
      "epoch": 8.09984345457133,
      "grad_norm": 0.37879469990730286,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.3751,
      "step": 199200
    },
    {
      "epoch": 8.103909569601724,
      "grad_norm": 0.365409791469574,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.3733,
      "step": 199300
    },
    {
      "epoch": 8.107975684632118,
      "grad_norm": 0.3945283889770508,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3733,
      "step": 199400
    },
    {
      "epoch": 8.112041799662512,
      "grad_norm": 0.3946223855018616,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3743,
      "step": 199500
    },
    {
      "epoch": 8.116107914692906,
      "grad_norm": 0.3838559687137604,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.3747,
      "step": 199600
    },
    {
      "epoch": 8.120174029723302,
      "grad_norm": 0.3993114233016968,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3732,
      "step": 199700
    },
    {
      "epoch": 8.124240144753696,
      "grad_norm": 0.40629804134368896,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.3713,
      "step": 199800
    },
    {
      "epoch": 8.12830625978409,
      "grad_norm": 0.40289241075515747,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3745,
      "step": 199900
    },
    {
      "epoch": 8.132372374814484,
      "grad_norm": 0.3497574031352997,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3742,
      "step": 200000
    },
    {
      "epoch": 8.132372374814484,
      "eval_loss": 0.4099712371826172,
      "eval_runtime": 113.3065,
      "eval_samples_per_second": 1543.619,
      "eval_steps_per_second": 48.241,
      "step": 200000
    },
    {
      "epoch": 8.136438489844878,
      "grad_norm": 0.37629348039627075,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.3742,
      "step": 200100
    },
    {
      "epoch": 8.140504604875272,
      "grad_norm": 0.38531792163848877,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.3738,
      "step": 200200
    },
    {
      "epoch": 8.144570719905666,
      "grad_norm": 0.36525192856788635,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.3724,
      "step": 200300
    },
    {
      "epoch": 8.14863683493606,
      "grad_norm": 0.38604217767715454,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.3747,
      "step": 200400
    },
    {
      "epoch": 8.152702949966455,
      "grad_norm": 0.4019140899181366,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3745,
      "step": 200500
    },
    {
      "epoch": 8.15676906499685,
      "grad_norm": 0.3535730540752411,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3743,
      "step": 200600
    },
    {
      "epoch": 8.160835180027243,
      "grad_norm": 0.38113275170326233,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3735,
      "step": 200700
    },
    {
      "epoch": 8.164901295057637,
      "grad_norm": 0.37362462282180786,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.3737,
      "step": 200800
    },
    {
      "epoch": 8.168967410088031,
      "grad_norm": 0.3875325918197632,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.3723,
      "step": 200900
    },
    {
      "epoch": 8.173033525118425,
      "grad_norm": 0.4087509512901306,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3747,
      "step": 201000
    },
    {
      "epoch": 8.17709964014882,
      "grad_norm": 0.3831847012042999,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3742,
      "step": 201100
    },
    {
      "epoch": 8.181165755179213,
      "grad_norm": 0.37994807958602905,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.3706,
      "step": 201200
    },
    {
      "epoch": 8.185231870209607,
      "grad_norm": 0.3706941306591034,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3726,
      "step": 201300
    },
    {
      "epoch": 8.189297985240003,
      "grad_norm": 0.4006076455116272,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3724,
      "step": 201400
    },
    {
      "epoch": 8.193364100270397,
      "grad_norm": 0.41868355870246887,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.3747,
      "step": 201500
    },
    {
      "epoch": 8.197430215300791,
      "grad_norm": 0.40569567680358887,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.3751,
      "step": 201600
    },
    {
      "epoch": 8.201496330331185,
      "grad_norm": 0.371749609708786,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3734,
      "step": 201700
    },
    {
      "epoch": 8.20556244536158,
      "grad_norm": 0.36721310019493103,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.3744,
      "step": 201800
    },
    {
      "epoch": 8.209628560391973,
      "grad_norm": 0.3496685326099396,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3744,
      "step": 201900
    },
    {
      "epoch": 8.213694675422367,
      "grad_norm": 0.3700066804885864,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3735,
      "step": 202000
    },
    {
      "epoch": 8.213694675422367,
      "eval_loss": 0.41133370995521545,
      "eval_runtime": 112.5456,
      "eval_samples_per_second": 1554.054,
      "eval_steps_per_second": 48.567,
      "step": 202000
    },
    {
      "epoch": 8.217781121027913,
      "grad_norm": 0.4096511900424957,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.3726,
      "step": 202100
    },
    {
      "epoch": 8.221847236058307,
      "grad_norm": 0.4477269947528839,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3736,
      "step": 202200
    },
    {
      "epoch": 8.225913351088701,
      "grad_norm": 0.3908054232597351,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.373,
      "step": 202300
    },
    {
      "epoch": 8.229979466119097,
      "grad_norm": 0.3913763761520386,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.3742,
      "step": 202400
    },
    {
      "epoch": 8.234045581149491,
      "grad_norm": 0.3809155225753784,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3729,
      "step": 202500
    },
    {
      "epoch": 8.238111696179885,
      "grad_norm": 0.37241706252098083,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3734,
      "step": 202600
    },
    {
      "epoch": 8.24217781121028,
      "grad_norm": 0.3775654435157776,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.3728,
      "step": 202700
    },
    {
      "epoch": 8.246243926240673,
      "grad_norm": 0.40232378244400024,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3718,
      "step": 202800
    },
    {
      "epoch": 8.250310041271067,
      "grad_norm": 0.3695456385612488,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3741,
      "step": 202900
    },
    {
      "epoch": 8.254376156301461,
      "grad_norm": 0.3718167245388031,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3744,
      "step": 203000
    },
    {
      "epoch": 8.258442271331855,
      "grad_norm": 0.35586610436439514,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3722,
      "step": 203100
    },
    {
      "epoch": 8.262508386362251,
      "grad_norm": 0.394890695810318,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.3726,
      "step": 203200
    },
    {
      "epoch": 8.266574501392645,
      "grad_norm": 0.43298184871673584,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3741,
      "step": 203300
    },
    {
      "epoch": 8.270640616423039,
      "grad_norm": 0.453068345785141,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.3714,
      "step": 203400
    },
    {
      "epoch": 8.274706731453433,
      "grad_norm": 0.369244784116745,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.3745,
      "step": 203500
    },
    {
      "epoch": 8.278772846483827,
      "grad_norm": 0.39466142654418945,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.374,
      "step": 203600
    },
    {
      "epoch": 8.282838961514221,
      "grad_norm": 0.4045288562774658,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3714,
      "step": 203700
    },
    {
      "epoch": 8.286905076544615,
      "grad_norm": 0.3470304310321808,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.373,
      "step": 203800
    },
    {
      "epoch": 8.290971191575009,
      "grad_norm": 0.36913001537323,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.3716,
      "step": 203900
    },
    {
      "epoch": 8.295037306605403,
      "grad_norm": 0.4206335246562958,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3725,
      "step": 204000
    },
    {
      "epoch": 8.295037306605403,
      "eval_loss": 0.4111412763595581,
      "eval_runtime": 115.8254,
      "eval_samples_per_second": 1510.048,
      "eval_steps_per_second": 47.192,
      "step": 204000
    },
    {
      "epoch": 8.299103421635799,
      "grad_norm": 0.4679277837276459,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.3741,
      "step": 204100
    },
    {
      "epoch": 8.303169536666193,
      "grad_norm": 0.4362282454967499,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.3737,
      "step": 204200
    },
    {
      "epoch": 8.307235651696587,
      "grad_norm": 0.40130335092544556,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.373,
      "step": 204300
    },
    {
      "epoch": 8.31130176672698,
      "grad_norm": 0.4109551012516022,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3749,
      "step": 204400
    },
    {
      "epoch": 8.315367881757375,
      "grad_norm": 0.4175693392753601,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.3725,
      "step": 204500
    },
    {
      "epoch": 8.319433996787769,
      "grad_norm": 0.40773993730545044,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.3735,
      "step": 204600
    },
    {
      "epoch": 8.323500111818163,
      "grad_norm": 0.42735469341278076,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.3744,
      "step": 204700
    },
    {
      "epoch": 8.327566226848557,
      "grad_norm": 0.36960867047309875,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3721,
      "step": 204800
    },
    {
      "epoch": 8.33163234187895,
      "grad_norm": 0.4241281747817993,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.3724,
      "step": 204900
    },
    {
      "epoch": 8.335698456909347,
      "grad_norm": 0.380122572183609,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.3723,
      "step": 205000
    },
    {
      "epoch": 8.33976457193974,
      "grad_norm": 0.3761797547340393,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.3726,
      "step": 205100
    },
    {
      "epoch": 8.343830686970135,
      "grad_norm": 0.4409853219985962,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.3719,
      "step": 205200
    },
    {
      "epoch": 8.347896802000529,
      "grad_norm": 0.3695942461490631,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3729,
      "step": 205300
    },
    {
      "epoch": 8.351962917030923,
      "grad_norm": 0.3460690379142761,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3722,
      "step": 205400
    },
    {
      "epoch": 8.356029032061317,
      "grad_norm": 0.40665996074676514,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.3724,
      "step": 205500
    },
    {
      "epoch": 8.36009514709171,
      "grad_norm": 0.4089488685131073,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3739,
      "step": 205600
    },
    {
      "epoch": 8.364161262122105,
      "grad_norm": 0.3980875611305237,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3721,
      "step": 205700
    },
    {
      "epoch": 8.3682273771525,
      "grad_norm": 0.3869912028312683,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3734,
      "step": 205800
    },
    {
      "epoch": 8.372293492182894,
      "grad_norm": 0.3797460198402405,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3726,
      "step": 205900
    },
    {
      "epoch": 8.376359607213288,
      "grad_norm": 0.3745254576206207,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3736,
      "step": 206000
    },
    {
      "epoch": 8.376359607213288,
      "eval_loss": 0.40958985686302185,
      "eval_runtime": 114.3835,
      "eval_samples_per_second": 1529.084,
      "eval_steps_per_second": 47.787,
      "step": 206000
    },
    {
      "epoch": 8.380425722243682,
      "grad_norm": 0.39019644260406494,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3742,
      "step": 206100
    },
    {
      "epoch": 8.384491837274076,
      "grad_norm": 0.4930214583873749,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.3743,
      "step": 206200
    },
    {
      "epoch": 8.38855795230447,
      "grad_norm": 0.427432119846344,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.374,
      "step": 206300
    },
    {
      "epoch": 8.392624067334864,
      "grad_norm": 0.39461424946784973,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.3756,
      "step": 206400
    },
    {
      "epoch": 8.396690182365258,
      "grad_norm": 0.37745705246925354,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3729,
      "step": 206500
    },
    {
      "epoch": 8.400756297395652,
      "grad_norm": 0.403889536857605,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.3728,
      "step": 206600
    },
    {
      "epoch": 8.404822412426048,
      "grad_norm": 0.41693633794784546,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.3753,
      "step": 206700
    },
    {
      "epoch": 8.408888527456442,
      "grad_norm": 0.42556819319725037,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.3725,
      "step": 206800
    },
    {
      "epoch": 8.412954642486836,
      "grad_norm": 0.37538978457450867,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.373,
      "step": 206900
    },
    {
      "epoch": 8.41702075751723,
      "grad_norm": 0.40582382678985596,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3731,
      "step": 207000
    },
    {
      "epoch": 8.421086872547624,
      "grad_norm": 0.4374498426914215,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3704,
      "step": 207100
    },
    {
      "epoch": 8.425152987578018,
      "grad_norm": 0.3519763946533203,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3719,
      "step": 207200
    },
    {
      "epoch": 8.429219102608412,
      "grad_norm": 0.3936666250228882,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3732,
      "step": 207300
    },
    {
      "epoch": 8.433285217638806,
      "grad_norm": 0.36597904562950134,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3736,
      "step": 207400
    },
    {
      "epoch": 8.437351332669202,
      "grad_norm": 0.3973657786846161,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3727,
      "step": 207500
    },
    {
      "epoch": 8.441417447699596,
      "grad_norm": 0.40503427386283875,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3705,
      "step": 207600
    },
    {
      "epoch": 8.44548356272999,
      "grad_norm": 0.39518582820892334,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3727,
      "step": 207700
    },
    {
      "epoch": 8.449549677760384,
      "grad_norm": 0.42455631494522095,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3696,
      "step": 207800
    },
    {
      "epoch": 8.453615792790778,
      "grad_norm": 0.38290777802467346,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3707,
      "step": 207900
    },
    {
      "epoch": 8.457681907821172,
      "grad_norm": 0.4082309901714325,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.373,
      "step": 208000
    },
    {
      "epoch": 8.457681907821172,
      "eval_loss": 0.4104074537754059,
      "eval_runtime": 114.8398,
      "eval_samples_per_second": 1523.008,
      "eval_steps_per_second": 47.597,
      "step": 208000
    },
    {
      "epoch": 8.461748022851566,
      "grad_norm": 0.3910624086856842,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.3724,
      "step": 208100
    },
    {
      "epoch": 8.46581413788196,
      "grad_norm": 0.41007688641548157,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.372,
      "step": 208200
    },
    {
      "epoch": 8.469880252912354,
      "grad_norm": 0.3897729218006134,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.3699,
      "step": 208300
    },
    {
      "epoch": 8.47394636794275,
      "grad_norm": 0.3944070637226105,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3723,
      "step": 208400
    },
    {
      "epoch": 8.478012482973144,
      "grad_norm": 0.3820875287055969,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.3737,
      "step": 208500
    },
    {
      "epoch": 8.482078598003538,
      "grad_norm": 0.40453770756721497,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.3726,
      "step": 208600
    },
    {
      "epoch": 8.486144713033932,
      "grad_norm": 0.4103662669658661,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3707,
      "step": 208700
    },
    {
      "epoch": 8.490210828064326,
      "grad_norm": 0.39571067690849304,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.3709,
      "step": 208800
    },
    {
      "epoch": 8.49427694309472,
      "grad_norm": 0.3818860948085785,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.3718,
      "step": 208900
    },
    {
      "epoch": 8.498343058125114,
      "grad_norm": 0.40268340706825256,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3688,
      "step": 209000
    },
    {
      "epoch": 8.502409173155508,
      "grad_norm": 0.44223135709762573,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.37,
      "step": 209100
    },
    {
      "epoch": 8.506475288185904,
      "grad_norm": 0.40262219309806824,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.373,
      "step": 209200
    },
    {
      "epoch": 8.510541403216298,
      "grad_norm": 0.41467130184173584,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.3718,
      "step": 209300
    },
    {
      "epoch": 8.514607518246692,
      "grad_norm": 0.4176449775695801,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.3726,
      "step": 209400
    },
    {
      "epoch": 8.518673633277086,
      "grad_norm": 0.43975818157196045,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.373,
      "step": 209500
    },
    {
      "epoch": 8.52273974830748,
      "grad_norm": 0.3746131360530853,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.37,
      "step": 209600
    },
    {
      "epoch": 8.526805863337874,
      "grad_norm": 0.396621435880661,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.3722,
      "step": 209700
    },
    {
      "epoch": 8.530871978368268,
      "grad_norm": 0.3985048532485962,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.3706,
      "step": 209800
    },
    {
      "epoch": 8.534938093398662,
      "grad_norm": 0.37979716062545776,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3713,
      "step": 209900
    },
    {
      "epoch": 8.539004208429056,
      "grad_norm": 0.40999022126197815,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3727,
      "step": 210000
    },
    {
      "epoch": 8.539004208429056,
      "eval_loss": 0.4068204164505005,
      "eval_runtime": 114.5547,
      "eval_samples_per_second": 1526.799,
      "eval_steps_per_second": 47.715,
      "step": 210000
    },
    {
      "epoch": 8.543070323459451,
      "grad_norm": 0.3953986167907715,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.3729,
      "step": 210100
    },
    {
      "epoch": 8.547136438489845,
      "grad_norm": 0.36844301223754883,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.3732,
      "step": 210200
    },
    {
      "epoch": 8.55120255352024,
      "grad_norm": 0.3567005693912506,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.3725,
      "step": 210300
    },
    {
      "epoch": 8.555268668550633,
      "grad_norm": 0.36580705642700195,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3725,
      "step": 210400
    },
    {
      "epoch": 8.559334783581027,
      "grad_norm": 0.4239518642425537,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3711,
      "step": 210500
    },
    {
      "epoch": 8.563400898611421,
      "grad_norm": 0.39359867572784424,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.3729,
      "step": 210600
    },
    {
      "epoch": 8.567467013641815,
      "grad_norm": 0.40025028586387634,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3722,
      "step": 210700
    },
    {
      "epoch": 8.57153312867221,
      "grad_norm": 0.4278576076030731,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.3718,
      "step": 210800
    },
    {
      "epoch": 8.575599243702605,
      "grad_norm": 0.4197598397731781,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3719,
      "step": 210900
    },
    {
      "epoch": 8.579665358733,
      "grad_norm": 0.41571637988090515,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.3739,
      "step": 211000
    },
    {
      "epoch": 8.583731473763393,
      "grad_norm": 0.430169939994812,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3722,
      "step": 211100
    },
    {
      "epoch": 8.587797588793787,
      "grad_norm": 0.4323541820049286,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3698,
      "step": 211200
    },
    {
      "epoch": 8.591863703824181,
      "grad_norm": 0.398980975151062,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3701,
      "step": 211300
    },
    {
      "epoch": 8.595929818854575,
      "grad_norm": 0.4331798255443573,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3726,
      "step": 211400
    },
    {
      "epoch": 8.59999593388497,
      "grad_norm": 0.40380579233169556,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3719,
      "step": 211500
    },
    {
      "epoch": 8.604062048915363,
      "grad_norm": 0.47386327385902405,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.3735,
      "step": 211600
    },
    {
      "epoch": 8.608128163945757,
      "grad_norm": 0.4390915334224701,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.3726,
      "step": 211700
    },
    {
      "epoch": 8.612194278976153,
      "grad_norm": 0.4453466236591339,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3709,
      "step": 211800
    },
    {
      "epoch": 8.616260394006547,
      "grad_norm": 0.3973677158355713,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.3704,
      "step": 211900
    },
    {
      "epoch": 8.620326509036941,
      "grad_norm": 0.41699448227882385,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3699,
      "step": 212000
    },
    {
      "epoch": 8.620326509036941,
      "eval_loss": 0.40809711813926697,
      "eval_runtime": 115.0411,
      "eval_samples_per_second": 1520.344,
      "eval_steps_per_second": 47.513,
      "step": 212000
    },
    {
      "epoch": 8.624392624067335,
      "grad_norm": 0.40763458609580994,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3712,
      "step": 212100
    },
    {
      "epoch": 8.628458739097729,
      "grad_norm": 0.3949742913246155,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.37,
      "step": 212200
    },
    {
      "epoch": 8.632524854128123,
      "grad_norm": 0.42427706718444824,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3697,
      "step": 212300
    },
    {
      "epoch": 8.636590969158517,
      "grad_norm": 0.43921956419944763,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.3719,
      "step": 212400
    },
    {
      "epoch": 8.640657084188911,
      "grad_norm": 0.44723787903785706,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3739,
      "step": 212500
    },
    {
      "epoch": 8.644723199219307,
      "grad_norm": 0.4811580777168274,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.3704,
      "step": 212600
    },
    {
      "epoch": 8.6487893142497,
      "grad_norm": 0.39301034808158875,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3711,
      "step": 212700
    },
    {
      "epoch": 8.652855429280095,
      "grad_norm": 0.38832002878189087,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.3712,
      "step": 212800
    },
    {
      "epoch": 8.656921544310489,
      "grad_norm": 0.39381158351898193,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3717,
      "step": 212900
    },
    {
      "epoch": 8.660987659340883,
      "grad_norm": 0.46999451518058777,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.3693,
      "step": 213000
    },
    {
      "epoch": 8.665053774371277,
      "grad_norm": 0.4000014364719391,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3687,
      "step": 213100
    },
    {
      "epoch": 8.66911988940167,
      "grad_norm": 0.430826336145401,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.37,
      "step": 213200
    },
    {
      "epoch": 8.673186004432065,
      "grad_norm": 0.41436055302619934,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.37,
      "step": 213300
    },
    {
      "epoch": 8.677252119462459,
      "grad_norm": 0.4294015169143677,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.3704,
      "step": 213400
    },
    {
      "epoch": 8.681318234492855,
      "grad_norm": 0.44828858971595764,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3718,
      "step": 213500
    },
    {
      "epoch": 8.685384349523249,
      "grad_norm": 0.4163806736469269,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3727,
      "step": 213600
    },
    {
      "epoch": 8.689450464553643,
      "grad_norm": 0.4320105016231537,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3683,
      "step": 213700
    },
    {
      "epoch": 8.693516579584037,
      "grad_norm": 0.3710872530937195,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3695,
      "step": 213800
    },
    {
      "epoch": 8.69758269461443,
      "grad_norm": 0.44277119636535645,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.3714,
      "step": 213900
    },
    {
      "epoch": 8.701648809644825,
      "grad_norm": 0.39872023463249207,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.37,
      "step": 214000
    },
    {
      "epoch": 8.701648809644825,
      "eval_loss": 0.40704384446144104,
      "eval_runtime": 115.709,
      "eval_samples_per_second": 1511.568,
      "eval_steps_per_second": 47.239,
      "step": 214000
    },
    {
      "epoch": 8.705714924675219,
      "grad_norm": 0.3771839439868927,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.3693,
      "step": 214100
    },
    {
      "epoch": 8.709781039705613,
      "grad_norm": 0.4011389911174774,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.3702,
      "step": 214200
    },
    {
      "epoch": 8.713847154736008,
      "grad_norm": 0.42920634150505066,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.37,
      "step": 214300
    },
    {
      "epoch": 8.717913269766402,
      "grad_norm": 0.3737325370311737,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3702,
      "step": 214400
    },
    {
      "epoch": 8.721979384796796,
      "grad_norm": 0.4359290301799774,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3697,
      "step": 214500
    },
    {
      "epoch": 8.72604549982719,
      "grad_norm": 0.3864075243473053,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.3703,
      "step": 214600
    },
    {
      "epoch": 8.730111614857584,
      "grad_norm": 0.42098644375801086,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.369,
      "step": 214700
    },
    {
      "epoch": 8.734177729887978,
      "grad_norm": 0.428571492433548,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3713,
      "step": 214800
    },
    {
      "epoch": 8.738243844918372,
      "grad_norm": 0.39241328835487366,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.3714,
      "step": 214900
    },
    {
      "epoch": 8.742309959948766,
      "grad_norm": 0.42227423191070557,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3714,
      "step": 215000
    },
    {
      "epoch": 8.74637607497916,
      "grad_norm": 0.39031121134757996,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.3719,
      "step": 215100
    },
    {
      "epoch": 8.750442190009556,
      "grad_norm": 0.39886805415153503,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.3737,
      "step": 215200
    },
    {
      "epoch": 8.75450830503995,
      "grad_norm": 0.43195584416389465,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3695,
      "step": 215300
    },
    {
      "epoch": 8.758574420070344,
      "grad_norm": 0.3926783800125122,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.3703,
      "step": 215400
    },
    {
      "epoch": 8.762640535100738,
      "grad_norm": 0.42510485649108887,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3685,
      "step": 215500
    },
    {
      "epoch": 8.766706650131132,
      "grad_norm": 0.3964292109012604,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.3717,
      "step": 215600
    },
    {
      "epoch": 8.770772765161526,
      "grad_norm": 0.3862358033657074,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3703,
      "step": 215700
    },
    {
      "epoch": 8.77483888019192,
      "grad_norm": 0.4622710645198822,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3711,
      "step": 215800
    },
    {
      "epoch": 8.778904995222314,
      "grad_norm": 0.3992788791656494,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.3717,
      "step": 215900
    },
    {
      "epoch": 8.78297111025271,
      "grad_norm": 0.41547995805740356,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.37,
      "step": 216000
    },
    {
      "epoch": 8.78297111025271,
      "eval_loss": 0.4093831479549408,
      "eval_runtime": 113.8574,
      "eval_samples_per_second": 1536.149,
      "eval_steps_per_second": 48.007,
      "step": 216000
    },
    {
      "epoch": 8.787037225283104,
      "grad_norm": 0.44443029165267944,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3709,
      "step": 216100
    },
    {
      "epoch": 8.791103340313498,
      "grad_norm": 0.38159704208374023,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.37,
      "step": 216200
    },
    {
      "epoch": 8.795169455343892,
      "grad_norm": 0.4384934902191162,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.3708,
      "step": 216300
    },
    {
      "epoch": 8.799235570374286,
      "grad_norm": 0.41387230157852173,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.369,
      "step": 216400
    },
    {
      "epoch": 8.80330168540468,
      "grad_norm": 0.36571207642555237,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.372,
      "step": 216500
    },
    {
      "epoch": 8.807367800435074,
      "grad_norm": 0.3838341236114502,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3706,
      "step": 216600
    },
    {
      "epoch": 8.811433915465468,
      "grad_norm": 0.4268839955329895,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.3709,
      "step": 216700
    },
    {
      "epoch": 8.815500030495862,
      "grad_norm": 0.44744089245796204,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.369,
      "step": 216800
    },
    {
      "epoch": 8.819566145526258,
      "grad_norm": 0.44912028312683105,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3716,
      "step": 216900
    },
    {
      "epoch": 8.823632260556652,
      "grad_norm": 0.3474094569683075,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.3707,
      "step": 217000
    },
    {
      "epoch": 8.827698375587046,
      "grad_norm": 0.4478427469730377,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3707,
      "step": 217100
    },
    {
      "epoch": 8.83176449061744,
      "grad_norm": 0.4310213625431061,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.3695,
      "step": 217200
    },
    {
      "epoch": 8.835830605647834,
      "grad_norm": 0.4276115298271179,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3704,
      "step": 217300
    },
    {
      "epoch": 8.839896720678228,
      "grad_norm": 0.4716995656490326,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.3722,
      "step": 217400
    },
    {
      "epoch": 8.843962835708622,
      "grad_norm": 0.4638940989971161,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3693,
      "step": 217500
    },
    {
      "epoch": 8.848028950739016,
      "grad_norm": 0.40784820914268494,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3688,
      "step": 217600
    },
    {
      "epoch": 8.852095065769412,
      "grad_norm": 0.3954802453517914,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3707,
      "step": 217700
    },
    {
      "epoch": 8.856161180799806,
      "grad_norm": 0.4242844581604004,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.3685,
      "step": 217800
    },
    {
      "epoch": 8.8602272958302,
      "grad_norm": 0.4042769968509674,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3696,
      "step": 217900
    },
    {
      "epoch": 8.864293410860594,
      "grad_norm": 0.3961040675640106,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3693,
      "step": 218000
    },
    {
      "epoch": 8.864293410860594,
      "eval_loss": 0.40532243251800537,
      "eval_runtime": 114.8968,
      "eval_samples_per_second": 1522.253,
      "eval_steps_per_second": 47.573,
      "step": 218000
    },
    {
      "epoch": 8.868359525890988,
      "grad_norm": 0.4380209445953369,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.3693,
      "step": 218100
    },
    {
      "epoch": 8.872425640921382,
      "grad_norm": 0.49774450063705444,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.3694,
      "step": 218200
    },
    {
      "epoch": 8.876491755951776,
      "grad_norm": 0.42581865191459656,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3687,
      "step": 218300
    },
    {
      "epoch": 8.88055787098217,
      "grad_norm": 0.46274083852767944,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3715,
      "step": 218400
    },
    {
      "epoch": 8.884623986012564,
      "grad_norm": 0.4614596962928772,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.37,
      "step": 218500
    },
    {
      "epoch": 8.88869010104296,
      "grad_norm": 0.40344133973121643,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3696,
      "step": 218600
    },
    {
      "epoch": 8.892756216073353,
      "grad_norm": 0.39753037691116333,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3696,
      "step": 218700
    },
    {
      "epoch": 8.896822331103747,
      "grad_norm": 0.4161393642425537,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3689,
      "step": 218800
    },
    {
      "epoch": 8.900888446134141,
      "grad_norm": 0.46266674995422363,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3678,
      "step": 218900
    },
    {
      "epoch": 8.904954561164535,
      "grad_norm": 0.38714340329170227,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3683,
      "step": 219000
    },
    {
      "epoch": 8.90902067619493,
      "grad_norm": 0.4066910147666931,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3685,
      "step": 219100
    },
    {
      "epoch": 8.913086791225323,
      "grad_norm": 0.429300993680954,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3694,
      "step": 219200
    },
    {
      "epoch": 8.917152906255717,
      "grad_norm": 0.4300520718097687,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3704,
      "step": 219300
    },
    {
      "epoch": 8.921219021286113,
      "grad_norm": 0.40052929520606995,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3677,
      "step": 219400
    },
    {
      "epoch": 8.925285136316507,
      "grad_norm": 0.42560097575187683,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3698,
      "step": 219500
    },
    {
      "epoch": 8.929351251346901,
      "grad_norm": 0.4314994812011719,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.3694,
      "step": 219600
    },
    {
      "epoch": 8.933417366377295,
      "grad_norm": 0.4181961417198181,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.3686,
      "step": 219700
    },
    {
      "epoch": 8.93748348140769,
      "grad_norm": 0.4201706051826477,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.3699,
      "step": 219800
    },
    {
      "epoch": 8.941549596438083,
      "grad_norm": 0.4706692695617676,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.3701,
      "step": 219900
    },
    {
      "epoch": 8.945615711468477,
      "grad_norm": 0.44510048627853394,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.3693,
      "step": 220000
    },
    {
      "epoch": 8.945615711468477,
      "eval_loss": 0.40570732951164246,
      "eval_runtime": 114.0085,
      "eval_samples_per_second": 1534.114,
      "eval_steps_per_second": 47.944,
      "step": 220000
    },
    {
      "epoch": 8.949681826498871,
      "grad_norm": 0.3933359980583191,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3713,
      "step": 220100
    },
    {
      "epoch": 8.953747941529265,
      "grad_norm": 0.46416571736335754,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.3691,
      "step": 220200
    },
    {
      "epoch": 8.957814056559661,
      "grad_norm": 0.3993928134441376,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.369,
      "step": 220300
    },
    {
      "epoch": 8.961880171590055,
      "grad_norm": 0.43521490693092346,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.3675,
      "step": 220400
    },
    {
      "epoch": 8.965946286620449,
      "grad_norm": 0.41441789269447327,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.369,
      "step": 220500
    },
    {
      "epoch": 8.970012401650843,
      "grad_norm": 0.38168448209762573,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.3692,
      "step": 220600
    },
    {
      "epoch": 8.974078516681237,
      "grad_norm": 0.41003894805908203,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.3688,
      "step": 220700
    },
    {
      "epoch": 8.978144631711631,
      "grad_norm": 0.37805870175361633,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.3697,
      "step": 220800
    },
    {
      "epoch": 8.982210746742025,
      "grad_norm": 0.3904385566711426,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3688,
      "step": 220900
    },
    {
      "epoch": 8.986276861772419,
      "grad_norm": 0.445896714925766,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.3673,
      "step": 221000
    },
    {
      "epoch": 8.990342976802815,
      "grad_norm": 0.4255598783493042,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.3702,
      "step": 221100
    },
    {
      "epoch": 8.994409091833209,
      "grad_norm": 0.5257754921913147,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3716,
      "step": 221200
    },
    {
      "epoch": 8.998475206863603,
      "grad_norm": 0.41525396704673767,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.3688,
      "step": 221300
    },
    {
      "epoch": 9.002541321893997,
      "grad_norm": 0.4408513307571411,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3665,
      "step": 221400
    },
    {
      "epoch": 9.00660743692439,
      "grad_norm": 0.3832250237464905,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.3697,
      "step": 221500
    },
    {
      "epoch": 9.010673551954785,
      "grad_norm": 0.4310609996318817,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3674,
      "step": 221600
    },
    {
      "epoch": 9.014739666985179,
      "grad_norm": 0.3943355977535248,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3666,
      "step": 221700
    },
    {
      "epoch": 9.018805782015573,
      "grad_norm": 0.4314779043197632,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.3681,
      "step": 221800
    },
    {
      "epoch": 9.022871897045967,
      "grad_norm": 0.4299289584159851,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.3671,
      "step": 221900
    },
    {
      "epoch": 9.026938012076362,
      "grad_norm": 0.4368744492530823,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3679,
      "step": 222000
    },
    {
      "epoch": 9.026938012076362,
      "eval_loss": 0.4064003527164459,
      "eval_runtime": 113.9507,
      "eval_samples_per_second": 1534.892,
      "eval_steps_per_second": 47.968,
      "step": 222000
    },
    {
      "epoch": 9.031004127106756,
      "grad_norm": 0.4791490435600281,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3684,
      "step": 222100
    },
    {
      "epoch": 9.03507024213715,
      "grad_norm": 0.4297138452529907,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.369,
      "step": 222200
    },
    {
      "epoch": 9.039136357167544,
      "grad_norm": 0.44636252522468567,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3673,
      "step": 222300
    },
    {
      "epoch": 9.043202472197938,
      "grad_norm": 0.44970211386680603,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3691,
      "step": 222400
    },
    {
      "epoch": 9.047268587228332,
      "grad_norm": 0.47238603234291077,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.3668,
      "step": 222500
    },
    {
      "epoch": 9.051334702258726,
      "grad_norm": 0.4254510998725891,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.3665,
      "step": 222600
    },
    {
      "epoch": 9.05540081728912,
      "grad_norm": 0.43417227268218994,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.3659,
      "step": 222700
    },
    {
      "epoch": 9.059466932319514,
      "grad_norm": 0.4300791621208191,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.365,
      "step": 222800
    },
    {
      "epoch": 9.06353304734991,
      "grad_norm": 0.42985495924949646,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3677,
      "step": 222900
    },
    {
      "epoch": 9.067599162380304,
      "grad_norm": 0.4420727491378784,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.3664,
      "step": 223000
    },
    {
      "epoch": 9.071665277410698,
      "grad_norm": 0.4240531623363495,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.369,
      "step": 223100
    },
    {
      "epoch": 9.075731392441092,
      "grad_norm": 0.3823119103908539,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3669,
      "step": 223200
    },
    {
      "epoch": 9.079797507471486,
      "grad_norm": 0.38106769323349,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.3655,
      "step": 223300
    },
    {
      "epoch": 9.08386362250188,
      "grad_norm": 0.4520387053489685,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.3676,
      "step": 223400
    },
    {
      "epoch": 9.087929737532274,
      "grad_norm": 0.44551387429237366,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3669,
      "step": 223500
    },
    {
      "epoch": 9.091995852562668,
      "grad_norm": 0.4748404920101166,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.3682,
      "step": 223600
    },
    {
      "epoch": 9.096061967593064,
      "grad_norm": 0.45078375935554504,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.3676,
      "step": 223700
    },
    {
      "epoch": 9.100128082623458,
      "grad_norm": 0.4201398193836212,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3673,
      "step": 223800
    },
    {
      "epoch": 9.104194197653852,
      "grad_norm": 0.4370073676109314,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.368,
      "step": 223900
    },
    {
      "epoch": 9.108260312684246,
      "grad_norm": 0.5003136992454529,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.3651,
      "step": 224000
    },
    {
      "epoch": 9.108260312684246,
      "eval_loss": 0.40427693724632263,
      "eval_runtime": 113.0971,
      "eval_samples_per_second": 1546.476,
      "eval_steps_per_second": 48.33,
      "step": 224000
    },
    {
      "epoch": 9.11232642771464,
      "grad_norm": 0.4203301668167114,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.3685,
      "step": 224100
    },
    {
      "epoch": 9.116392542745034,
      "grad_norm": 0.4555685222148895,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.3667,
      "step": 224200
    },
    {
      "epoch": 9.120458657775428,
      "grad_norm": 0.5149263143539429,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.3673,
      "step": 224300
    },
    {
      "epoch": 9.124524772805822,
      "grad_norm": 0.4839043915271759,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.3698,
      "step": 224400
    },
    {
      "epoch": 9.128590887836216,
      "grad_norm": 0.4773216247558594,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3664,
      "step": 224500
    },
    {
      "epoch": 9.132657002866612,
      "grad_norm": 0.4334961771965027,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3658,
      "step": 224600
    },
    {
      "epoch": 9.136723117897006,
      "grad_norm": 0.46670693159103394,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3698,
      "step": 224700
    },
    {
      "epoch": 9.1407892329274,
      "grad_norm": 0.4573892056941986,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3661,
      "step": 224800
    },
    {
      "epoch": 9.144855347957794,
      "grad_norm": 0.4787267744541168,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3676,
      "step": 224900
    },
    {
      "epoch": 9.148921462988188,
      "grad_norm": 0.3734365403652191,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3664,
      "step": 225000
    },
    {
      "epoch": 9.152987578018582,
      "grad_norm": 0.4124315083026886,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3648,
      "step": 225100
    },
    {
      "epoch": 9.157053693048976,
      "grad_norm": 0.5048057436943054,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.3692,
      "step": 225200
    },
    {
      "epoch": 9.16111980807937,
      "grad_norm": 0.46585461497306824,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.3672,
      "step": 225300
    },
    {
      "epoch": 9.165185923109764,
      "grad_norm": 0.4765598177909851,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3691,
      "step": 225400
    },
    {
      "epoch": 9.16925203814016,
      "grad_norm": 0.43799787759780884,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3665,
      "step": 225500
    },
    {
      "epoch": 9.173318153170554,
      "grad_norm": 0.43749377131462097,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3671,
      "step": 225600
    },
    {
      "epoch": 9.177384268200948,
      "grad_norm": 0.48359057307243347,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.3669,
      "step": 225700
    },
    {
      "epoch": 9.181450383231342,
      "grad_norm": 0.42062908411026,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3662,
      "step": 225800
    },
    {
      "epoch": 9.185516498261736,
      "grad_norm": 0.4518316090106964,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3659,
      "step": 225900
    },
    {
      "epoch": 9.18958261329213,
      "grad_norm": 0.4676932990550995,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3663,
      "step": 226000
    },
    {
      "epoch": 9.18958261329213,
      "eval_loss": 0.4061470031738281,
      "eval_runtime": 112.8703,
      "eval_samples_per_second": 1549.584,
      "eval_steps_per_second": 48.427,
      "step": 226000
    },
    {
      "epoch": 9.193648728322524,
      "grad_norm": 0.4165547490119934,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.3671,
      "step": 226100
    },
    {
      "epoch": 9.197714843352918,
      "grad_norm": 0.41358286142349243,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3663,
      "step": 226200
    },
    {
      "epoch": 9.201780958383313,
      "grad_norm": 0.4426957368850708,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3668,
      "step": 226300
    },
    {
      "epoch": 9.205847073413707,
      "grad_norm": 0.45742473006248474,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3671,
      "step": 226400
    },
    {
      "epoch": 9.209913188444101,
      "grad_norm": 0.4546065330505371,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.368,
      "step": 226500
    },
    {
      "epoch": 9.213979303474495,
      "grad_norm": 0.48088905215263367,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.3684,
      "step": 226600
    },
    {
      "epoch": 9.21804541850489,
      "grad_norm": 0.4273219406604767,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3679,
      "step": 226700
    },
    {
      "epoch": 9.222111533535283,
      "grad_norm": 0.4172734320163727,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3672,
      "step": 226800
    },
    {
      "epoch": 9.226177648565677,
      "grad_norm": 0.4560542404651642,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3661,
      "step": 226900
    },
    {
      "epoch": 9.230243763596071,
      "grad_norm": 0.427399218082428,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3652,
      "step": 227000
    },
    {
      "epoch": 9.234309878626465,
      "grad_norm": 0.4444613754749298,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3674,
      "step": 227100
    },
    {
      "epoch": 9.238375993656861,
      "grad_norm": 0.41394954919815063,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.365,
      "step": 227200
    },
    {
      "epoch": 9.242442108687255,
      "grad_norm": 0.46422913670539856,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3658,
      "step": 227300
    },
    {
      "epoch": 9.24650822371765,
      "grad_norm": 0.4076548218727112,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3669,
      "step": 227400
    },
    {
      "epoch": 9.250574338748043,
      "grad_norm": 0.4324248135089874,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3642,
      "step": 227500
    },
    {
      "epoch": 9.254640453778437,
      "grad_norm": 0.37609177827835083,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3652,
      "step": 227600
    },
    {
      "epoch": 9.258706568808831,
      "grad_norm": 0.44608554244041443,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.3658,
      "step": 227700
    },
    {
      "epoch": 9.262772683839225,
      "grad_norm": 0.4506262540817261,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.3653,
      "step": 227800
    },
    {
      "epoch": 9.26683879886962,
      "grad_norm": 0.4784921407699585,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.367,
      "step": 227900
    },
    {
      "epoch": 9.270904913900015,
      "grad_norm": 0.44617849588394165,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3651,
      "step": 228000
    },
    {
      "epoch": 9.270904913900015,
      "eval_loss": 0.40401437878608704,
      "eval_runtime": 114.1776,
      "eval_samples_per_second": 1531.842,
      "eval_steps_per_second": 47.873,
      "step": 228000
    },
    {
      "epoch": 9.274971028930409,
      "grad_norm": 0.4170697033405304,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.3646,
      "step": 228100
    },
    {
      "epoch": 9.279037143960803,
      "grad_norm": 0.47064006328582764,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.3651,
      "step": 228200
    },
    {
      "epoch": 9.283103258991197,
      "grad_norm": 0.48869478702545166,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3662,
      "step": 228300
    },
    {
      "epoch": 9.287169374021591,
      "grad_norm": 0.39376139640808105,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3667,
      "step": 228400
    },
    {
      "epoch": 9.291235489051985,
      "grad_norm": 0.46706998348236084,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3672,
      "step": 228500
    },
    {
      "epoch": 9.295301604082379,
      "grad_norm": 0.4132418632507324,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.3675,
      "step": 228600
    },
    {
      "epoch": 9.299367719112773,
      "grad_norm": 0.48267364501953125,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.3661,
      "step": 228700
    },
    {
      "epoch": 9.303433834143167,
      "grad_norm": 0.4557712972164154,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3654,
      "step": 228800
    },
    {
      "epoch": 9.307499949173563,
      "grad_norm": 0.40293070673942566,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3648,
      "step": 228900
    },
    {
      "epoch": 9.311566064203957,
      "grad_norm": 0.4629492461681366,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3649,
      "step": 229000
    },
    {
      "epoch": 9.31563217923435,
      "grad_norm": 0.44210830330848694,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.3666,
      "step": 229100
    },
    {
      "epoch": 9.319698294264745,
      "grad_norm": 0.45015424489974976,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3648,
      "step": 229200
    },
    {
      "epoch": 9.323764409295139,
      "grad_norm": 0.44332462549209595,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3654,
      "step": 229300
    },
    {
      "epoch": 9.327830524325533,
      "grad_norm": 0.4427969455718994,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3647,
      "step": 229400
    },
    {
      "epoch": 9.331896639355927,
      "grad_norm": 0.4452226161956787,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3661,
      "step": 229500
    },
    {
      "epoch": 9.33596275438632,
      "grad_norm": 0.48504823446273804,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.3656,
      "step": 229600
    },
    {
      "epoch": 9.340028869416717,
      "grad_norm": 0.4571911692619324,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3648,
      "step": 229700
    },
    {
      "epoch": 9.34409498444711,
      "grad_norm": 0.4659838080406189,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3674,
      "step": 229800
    },
    {
      "epoch": 9.348161099477505,
      "grad_norm": 0.46782031655311584,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3668,
      "step": 229900
    },
    {
      "epoch": 9.352227214507899,
      "grad_norm": 0.4274970293045044,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.3656,
      "step": 230000
    },
    {
      "epoch": 9.352227214507899,
      "eval_loss": 0.4038630425930023,
      "eval_runtime": 113.0436,
      "eval_samples_per_second": 1547.208,
      "eval_steps_per_second": 48.353,
      "step": 230000
    },
    {
      "epoch": 9.356293329538293,
      "grad_norm": 0.473469614982605,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.3657,
      "step": 230100
    },
    {
      "epoch": 9.360359444568687,
      "grad_norm": 0.4324599802494049,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.3684,
      "step": 230200
    },
    {
      "epoch": 9.36442555959908,
      "grad_norm": 0.4211844503879547,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.3663,
      "step": 230300
    },
    {
      "epoch": 9.368491674629475,
      "grad_norm": 0.4309455156326294,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.3657,
      "step": 230400
    },
    {
      "epoch": 9.372557789659869,
      "grad_norm": 0.4672020971775055,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3657,
      "step": 230500
    },
    {
      "epoch": 9.376623904690264,
      "grad_norm": 0.4558252990245819,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3654,
      "step": 230600
    },
    {
      "epoch": 9.380690019720658,
      "grad_norm": 0.48272091150283813,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.3678,
      "step": 230700
    },
    {
      "epoch": 9.384756134751052,
      "grad_norm": 0.4824022650718689,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.368,
      "step": 230800
    },
    {
      "epoch": 9.388822249781446,
      "grad_norm": 0.45083025097846985,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.3661,
      "step": 230900
    },
    {
      "epoch": 9.39288836481184,
      "grad_norm": 0.460965096950531,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.365,
      "step": 231000
    },
    {
      "epoch": 9.396954479842234,
      "grad_norm": 0.43525615334510803,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3665,
      "step": 231100
    },
    {
      "epoch": 9.401020594872628,
      "grad_norm": 0.4538396894931793,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3647,
      "step": 231200
    },
    {
      "epoch": 9.405086709903022,
      "grad_norm": 0.3777768015861511,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3677,
      "step": 231300
    },
    {
      "epoch": 9.409152824933418,
      "grad_norm": 0.47940441966056824,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3686,
      "step": 231400
    },
    {
      "epoch": 9.413218939963812,
      "grad_norm": 0.45020851492881775,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3659,
      "step": 231500
    },
    {
      "epoch": 9.417285054994206,
      "grad_norm": 0.4549993574619293,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3668,
      "step": 231600
    },
    {
      "epoch": 9.4213511700246,
      "grad_norm": 0.4703373908996582,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.3662,
      "step": 231700
    },
    {
      "epoch": 9.425417285054994,
      "grad_norm": 0.4420551359653473,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.3676,
      "step": 231800
    },
    {
      "epoch": 9.429483400085388,
      "grad_norm": 0.49772652983665466,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3658,
      "step": 231900
    },
    {
      "epoch": 9.433549515115782,
      "grad_norm": 0.41264188289642334,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.3662,
      "step": 232000
    },
    {
      "epoch": 9.433549515115782,
      "eval_loss": 0.4031658172607422,
      "eval_runtime": 114.6933,
      "eval_samples_per_second": 1524.954,
      "eval_steps_per_second": 47.658,
      "step": 232000
    },
    {
      "epoch": 9.437615630146176,
      "grad_norm": 0.45816248655319214,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3663,
      "step": 232100
    },
    {
      "epoch": 9.44168174517657,
      "grad_norm": 0.4220966398715973,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3643,
      "step": 232200
    },
    {
      "epoch": 9.445747860206966,
      "grad_norm": 0.4543639123439789,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3666,
      "step": 232300
    },
    {
      "epoch": 9.44981397523736,
      "grad_norm": 0.4240396320819855,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.364,
      "step": 232400
    },
    {
      "epoch": 9.453880090267754,
      "grad_norm": 0.42029786109924316,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.3642,
      "step": 232500
    },
    {
      "epoch": 9.457946205298148,
      "grad_norm": 0.4904967248439789,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3653,
      "step": 232600
    },
    {
      "epoch": 9.462012320328542,
      "grad_norm": 0.45647045969963074,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3648,
      "step": 232700
    },
    {
      "epoch": 9.466078435358936,
      "grad_norm": 0.4442128539085388,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.3645,
      "step": 232800
    },
    {
      "epoch": 9.47014455038933,
      "grad_norm": 0.4839707911014557,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3666,
      "step": 232900
    },
    {
      "epoch": 9.474210665419724,
      "grad_norm": 0.4652620255947113,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3652,
      "step": 233000
    },
    {
      "epoch": 9.47827678045012,
      "grad_norm": 0.4596995711326599,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.3665,
      "step": 233100
    },
    {
      "epoch": 9.482342895480514,
      "grad_norm": 0.45668888092041016,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.366,
      "step": 233200
    },
    {
      "epoch": 9.486409010510908,
      "grad_norm": 0.5058043003082275,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.3644,
      "step": 233300
    },
    {
      "epoch": 9.490475125541302,
      "grad_norm": 0.49070897698402405,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3656,
      "step": 233400
    },
    {
      "epoch": 9.494541240571696,
      "grad_norm": 0.4437198042869568,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3656,
      "step": 233500
    },
    {
      "epoch": 9.49860735560209,
      "grad_norm": 0.46864044666290283,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3648,
      "step": 233600
    },
    {
      "epoch": 9.502673470632484,
      "grad_norm": 0.40679478645324707,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.3655,
      "step": 233700
    },
    {
      "epoch": 9.506739585662878,
      "grad_norm": 0.5007681250572205,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3648,
      "step": 233800
    },
    {
      "epoch": 9.510805700693272,
      "grad_norm": 0.44871804118156433,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3662,
      "step": 233900
    },
    {
      "epoch": 9.514871815723668,
      "grad_norm": 0.46630075573921204,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.3644,
      "step": 234000
    },
    {
      "epoch": 9.514871815723668,
      "eval_loss": 0.4038068950176239,
      "eval_runtime": 114.2741,
      "eval_samples_per_second": 1530.549,
      "eval_steps_per_second": 47.832,
      "step": 234000
    },
    {
      "epoch": 9.518937930754062,
      "grad_norm": 0.48301243782043457,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.3633,
      "step": 234100
    },
    {
      "epoch": 9.523004045784456,
      "grad_norm": 0.43923360109329224,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.3659,
      "step": 234200
    },
    {
      "epoch": 9.52707016081485,
      "grad_norm": 0.47120770812034607,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3637,
      "step": 234300
    },
    {
      "epoch": 9.531136275845244,
      "grad_norm": 0.4448743760585785,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3645,
      "step": 234400
    },
    {
      "epoch": 9.535202390875638,
      "grad_norm": 0.42060133814811707,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3671,
      "step": 234500
    },
    {
      "epoch": 9.539268505906032,
      "grad_norm": 0.4639585018157959,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3669,
      "step": 234600
    },
    {
      "epoch": 9.543334620936426,
      "grad_norm": 0.5178585052490234,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3664,
      "step": 234700
    },
    {
      "epoch": 9.547400735966821,
      "grad_norm": 0.4067503809928894,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.3622,
      "step": 234800
    },
    {
      "epoch": 9.551466850997215,
      "grad_norm": 0.4578099846839905,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.3682,
      "step": 234900
    },
    {
      "epoch": 9.55553296602761,
      "grad_norm": 0.42637792229652405,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.3647,
      "step": 235000
    },
    {
      "epoch": 9.559599081058003,
      "grad_norm": 0.45038506388664246,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3625,
      "step": 235100
    },
    {
      "epoch": 9.563665196088397,
      "grad_norm": 0.44730621576309204,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3637,
      "step": 235200
    },
    {
      "epoch": 9.567731311118791,
      "grad_norm": 0.4658794701099396,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3647,
      "step": 235300
    },
    {
      "epoch": 9.571797426149185,
      "grad_norm": 0.4195837080478668,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3665,
      "step": 235400
    },
    {
      "epoch": 9.57586354117958,
      "grad_norm": 0.47582685947418213,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.366,
      "step": 235500
    },
    {
      "epoch": 9.579929656209973,
      "grad_norm": 0.46111059188842773,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3663,
      "step": 235600
    },
    {
      "epoch": 9.58399577124037,
      "grad_norm": 0.5249542593955994,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.3658,
      "step": 235700
    },
    {
      "epoch": 9.588061886270763,
      "grad_norm": 0.4577867090702057,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.367,
      "step": 235800
    },
    {
      "epoch": 9.592128001301157,
      "grad_norm": 0.45553967356681824,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.3638,
      "step": 235900
    },
    {
      "epoch": 9.596194116331551,
      "grad_norm": 0.49421700835227966,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.364,
      "step": 236000
    },
    {
      "epoch": 9.596194116331551,
      "eval_loss": 0.40337297320365906,
      "eval_runtime": 114.5174,
      "eval_samples_per_second": 1527.296,
      "eval_steps_per_second": 47.731,
      "step": 236000
    },
    {
      "epoch": 9.600260231361945,
      "grad_norm": 0.47877976298332214,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3662,
      "step": 236100
    },
    {
      "epoch": 9.60432634639234,
      "grad_norm": 0.43287527561187744,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3631,
      "step": 236200
    },
    {
      "epoch": 9.608392461422733,
      "grad_norm": 0.49392807483673096,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.3631,
      "step": 236300
    },
    {
      "epoch": 9.612458576453127,
      "grad_norm": 0.46463853120803833,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3675,
      "step": 236400
    },
    {
      "epoch": 9.616524691483523,
      "grad_norm": 0.4343237578868866,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.3641,
      "step": 236500
    },
    {
      "epoch": 9.620590806513917,
      "grad_norm": 0.4360748529434204,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3637,
      "step": 236600
    },
    {
      "epoch": 9.624656921544311,
      "grad_norm": 0.4233454465866089,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3643,
      "step": 236700
    },
    {
      "epoch": 9.628723036574705,
      "grad_norm": 0.5063087344169617,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.3637,
      "step": 236800
    },
    {
      "epoch": 9.632789151605099,
      "grad_norm": 0.5069452524185181,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3646,
      "step": 236900
    },
    {
      "epoch": 9.636855266635493,
      "grad_norm": 0.49425268173217773,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.366,
      "step": 237000
    },
    {
      "epoch": 9.640921381665887,
      "grad_norm": 0.4458315372467041,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3637,
      "step": 237100
    },
    {
      "epoch": 9.644987496696281,
      "grad_norm": 0.45037826895713806,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.3637,
      "step": 237200
    },
    {
      "epoch": 9.649053611726675,
      "grad_norm": 0.4815753400325775,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3655,
      "step": 237300
    },
    {
      "epoch": 9.65311972675707,
      "grad_norm": 0.4533965289592743,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.3656,
      "step": 237400
    },
    {
      "epoch": 9.657185841787465,
      "grad_norm": 0.5038490891456604,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.3657,
      "step": 237500
    },
    {
      "epoch": 9.661251956817859,
      "grad_norm": 0.46941840648651123,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3672,
      "step": 237600
    },
    {
      "epoch": 9.665318071848253,
      "grad_norm": 0.42705968022346497,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.3664,
      "step": 237700
    },
    {
      "epoch": 9.669384186878647,
      "grad_norm": 0.4987459182739258,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.3659,
      "step": 237800
    },
    {
      "epoch": 9.67345030190904,
      "grad_norm": 0.5085052847862244,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3655,
      "step": 237900
    },
    {
      "epoch": 9.677516416939435,
      "grad_norm": 0.46659210324287415,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3649,
      "step": 238000
    },
    {
      "epoch": 9.677516416939435,
      "eval_loss": 0.40346282720565796,
      "eval_runtime": 113.9111,
      "eval_samples_per_second": 1535.426,
      "eval_steps_per_second": 47.985,
      "step": 238000
    },
    {
      "epoch": 9.681582531969829,
      "grad_norm": 0.4840560555458069,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.3642,
      "step": 238100
    },
    {
      "epoch": 9.685648647000225,
      "grad_norm": 0.4574327766895294,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3628,
      "step": 238200
    },
    {
      "epoch": 9.689714762030619,
      "grad_norm": 0.51557856798172,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3637,
      "step": 238300
    },
    {
      "epoch": 9.693780877061013,
      "grad_norm": 0.45086386799812317,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.365,
      "step": 238400
    },
    {
      "epoch": 9.697846992091407,
      "grad_norm": 0.5083655118942261,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3646,
      "step": 238500
    },
    {
      "epoch": 9.7019131071218,
      "grad_norm": 0.4706665277481079,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.3661,
      "step": 238600
    },
    {
      "epoch": 9.705979222152195,
      "grad_norm": 0.49540823698043823,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3643,
      "step": 238700
    },
    {
      "epoch": 9.710045337182589,
      "grad_norm": 0.460950642824173,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3637,
      "step": 238800
    },
    {
      "epoch": 9.714111452212983,
      "grad_norm": 0.5025404691696167,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3637,
      "step": 238900
    },
    {
      "epoch": 9.718177567243377,
      "grad_norm": 0.46455106139183044,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.363,
      "step": 239000
    },
    {
      "epoch": 9.722243682273772,
      "grad_norm": 0.46142715215682983,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.3636,
      "step": 239100
    },
    {
      "epoch": 9.726309797304166,
      "grad_norm": 0.47251492738723755,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3621,
      "step": 239200
    },
    {
      "epoch": 9.73037591233456,
      "grad_norm": 0.5139342546463013,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3649,
      "step": 239300
    },
    {
      "epoch": 9.734442027364954,
      "grad_norm": 0.4781619608402252,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.3652,
      "step": 239400
    },
    {
      "epoch": 9.738508142395348,
      "grad_norm": 0.557368814945221,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3639,
      "step": 239500
    },
    {
      "epoch": 9.742574257425742,
      "grad_norm": 0.49582624435424805,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3657,
      "step": 239600
    },
    {
      "epoch": 9.746640372456136,
      "grad_norm": 0.45328250527381897,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3641,
      "step": 239700
    },
    {
      "epoch": 9.75070648748653,
      "grad_norm": 0.4403734803199768,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3653,
      "step": 239800
    },
    {
      "epoch": 9.754772602516926,
      "grad_norm": 0.44661983847618103,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.361,
      "step": 239900
    },
    {
      "epoch": 9.75883871754732,
      "grad_norm": 0.4452238082885742,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3642,
      "step": 240000
    },
    {
      "epoch": 9.75883871754732,
      "eval_loss": 0.4009245038032532,
      "eval_runtime": 114.0782,
      "eval_samples_per_second": 1533.176,
      "eval_steps_per_second": 47.914,
      "step": 240000
    },
    {
      "epoch": 9.762904832577714,
      "grad_norm": 0.4842585325241089,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.3653,
      "step": 240100
    },
    {
      "epoch": 9.766970947608108,
      "grad_norm": 0.4822750687599182,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.3653,
      "step": 240200
    },
    {
      "epoch": 9.771037062638502,
      "grad_norm": 0.5007006525993347,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.3652,
      "step": 240300
    },
    {
      "epoch": 9.775103177668896,
      "grad_norm": 0.455204576253891,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.3631,
      "step": 240400
    },
    {
      "epoch": 9.77916929269929,
      "grad_norm": 0.4637089967727661,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.3629,
      "step": 240500
    },
    {
      "epoch": 9.783235407729684,
      "grad_norm": 0.46570131182670593,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3643,
      "step": 240600
    },
    {
      "epoch": 9.787301522760078,
      "grad_norm": 0.45757168531417847,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3645,
      "step": 240700
    },
    {
      "epoch": 9.791367637790474,
      "grad_norm": 0.47913071513175964,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3646,
      "step": 240800
    },
    {
      "epoch": 9.795433752820868,
      "grad_norm": 0.4470236599445343,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.3624,
      "step": 240900
    },
    {
      "epoch": 9.799499867851262,
      "grad_norm": 0.4814554750919342,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3642,
      "step": 241000
    },
    {
      "epoch": 9.803565982881656,
      "grad_norm": 0.4473150372505188,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3646,
      "step": 241100
    },
    {
      "epoch": 9.80763209791205,
      "grad_norm": 0.43386903405189514,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3627,
      "step": 241200
    },
    {
      "epoch": 9.811698212942444,
      "grad_norm": 0.4807589650154114,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.3673,
      "step": 241300
    },
    {
      "epoch": 9.815764327972838,
      "grad_norm": 0.5992690324783325,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.3664,
      "step": 241400
    },
    {
      "epoch": 9.819830443003232,
      "grad_norm": 0.4905920624732971,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3625,
      "step": 241500
    },
    {
      "epoch": 9.823896558033628,
      "grad_norm": 0.49314236640930176,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.3655,
      "step": 241600
    },
    {
      "epoch": 9.827962673064022,
      "grad_norm": 0.44076767563819885,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3636,
      "step": 241700
    },
    {
      "epoch": 9.832028788094416,
      "grad_norm": 0.4323311448097229,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3625,
      "step": 241800
    },
    {
      "epoch": 9.83609490312481,
      "grad_norm": 0.4551492929458618,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.3613,
      "step": 241900
    },
    {
      "epoch": 9.840161018155204,
      "grad_norm": 0.46343404054641724,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3606,
      "step": 242000
    },
    {
      "epoch": 9.840161018155204,
      "eval_loss": 0.4016621708869934,
      "eval_runtime": 114.8031,
      "eval_samples_per_second": 1523.495,
      "eval_steps_per_second": 47.612,
      "step": 242000
    },
    {
      "epoch": 9.844227133185598,
      "grad_norm": 0.48467931151390076,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3617,
      "step": 242100
    },
    {
      "epoch": 9.848293248215992,
      "grad_norm": 0.4441748559474945,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3653,
      "step": 242200
    },
    {
      "epoch": 9.852359363246386,
      "grad_norm": 0.4647011458873749,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.3634,
      "step": 242300
    },
    {
      "epoch": 9.85642547827678,
      "grad_norm": 0.4107426702976227,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.3641,
      "step": 242400
    },
    {
      "epoch": 9.860491593307174,
      "grad_norm": 0.47591838240623474,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.3638,
      "step": 242500
    },
    {
      "epoch": 9.86455770833757,
      "grad_norm": 0.4681588113307953,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3634,
      "step": 242600
    },
    {
      "epoch": 9.868623823367964,
      "grad_norm": 0.4770169258117676,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3626,
      "step": 242700
    },
    {
      "epoch": 9.872689938398358,
      "grad_norm": 0.5027459263801575,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3645,
      "step": 242800
    },
    {
      "epoch": 9.876756053428752,
      "grad_norm": 0.46606573462486267,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.3631,
      "step": 242900
    },
    {
      "epoch": 9.880822168459146,
      "grad_norm": 0.4882763624191284,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3627,
      "step": 243000
    },
    {
      "epoch": 9.88488828348954,
      "grad_norm": 0.4375627934932709,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.3619,
      "step": 243100
    },
    {
      "epoch": 9.888954398519934,
      "grad_norm": 0.48414015769958496,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.363,
      "step": 243200
    },
    {
      "epoch": 9.893020513550328,
      "grad_norm": 0.5045265555381775,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3651,
      "step": 243300
    },
    {
      "epoch": 9.897086628580723,
      "grad_norm": 0.4972701668739319,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3632,
      "step": 243400
    },
    {
      "epoch": 9.901152743611117,
      "grad_norm": 0.4617198407649994,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.3629,
      "step": 243500
    },
    {
      "epoch": 9.905218858641511,
      "grad_norm": 0.46072712540626526,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.3632,
      "step": 243600
    },
    {
      "epoch": 9.909284973671905,
      "grad_norm": 0.4616471230983734,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3627,
      "step": 243700
    },
    {
      "epoch": 9.9133510887023,
      "grad_norm": 0.4867503046989441,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3625,
      "step": 243800
    },
    {
      "epoch": 9.917417203732693,
      "grad_norm": 0.4851626455783844,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3614,
      "step": 243900
    },
    {
      "epoch": 9.921483318763087,
      "grad_norm": 0.41955995559692383,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3613,
      "step": 244000
    },
    {
      "epoch": 9.921483318763087,
      "eval_loss": 0.4006349444389343,
      "eval_runtime": 113.8831,
      "eval_samples_per_second": 1535.803,
      "eval_steps_per_second": 47.997,
      "step": 244000
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
