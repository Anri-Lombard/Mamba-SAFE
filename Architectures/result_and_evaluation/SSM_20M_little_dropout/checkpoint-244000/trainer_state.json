{
  "best_metric": 0.3329470455646515,
  "best_model_checkpoint": "/scratch/lmbanr001/SSM_20M_little_dropout/checkpoint-244000",
  "epoch": 9.921462988187935,
  "eval_steps": 2000,
  "global_step": 244000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 20.148107528686523,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.7939,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 10.745707511901855,
      "learning_rate": 2.5e-06,
      "loss": 6.8568,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 2.6882011890411377,
      "learning_rate": 5e-06,
      "loss": 3.3725,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 1.7433016300201416,
      "learning_rate": 7.5e-06,
      "loss": 1.6827,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 2.4732108116149902,
      "learning_rate": 1e-05,
      "loss": 1.2138,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 2.330375909805298,
      "learning_rate": 1.25e-05,
      "loss": 1.037,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 3.0661094188690186,
      "learning_rate": 1.5e-05,
      "loss": 0.9275,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 3.0767593383789062,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.8643,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 2.2557942867279053,
      "learning_rate": 2e-05,
      "loss": 0.8139,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 2.7602546215057373,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.7741,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 3.066828966140747,
      "learning_rate": 2.5e-05,
      "loss": 0.7482,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 2.906054735183716,
      "learning_rate": 2.75e-05,
      "loss": 0.7152,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 3.010803699493408,
      "learning_rate": 3e-05,
      "loss": 0.6867,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 2.590272903442383,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.6638,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 3.1229991912841797,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.6414,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 2.6472530364990234,
      "learning_rate": 3.75e-05,
      "loss": 0.6278,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 2.2911882400512695,
      "learning_rate": 4e-05,
      "loss": 0.6146,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 2.8818860054016113,
      "learning_rate": 4.25e-05,
      "loss": 0.6025,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 2.4729936122894287,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.5881,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 3.8937368392944336,
      "learning_rate": 4.75e-05,
      "loss": 0.5743,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 2.27569317817688,
      "learning_rate": 5e-05,
      "loss": 0.5668,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.5662603378295898,
      "eval_runtime": 129.528,
      "eval_samples_per_second": 1350.302,
      "eval_steps_per_second": 42.199,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 2.6941123008728027,
      "learning_rate": 5.25e-05,
      "loss": 0.559,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 2.68497633934021,
      "learning_rate": 5.5e-05,
      "loss": 0.5519,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 2.771723508834839,
      "learning_rate": 5.75e-05,
      "loss": 0.5426,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 2.1498312950134277,
      "learning_rate": 6e-05,
      "loss": 0.5391,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 2.229731559753418,
      "learning_rate": 6.25e-05,
      "loss": 0.5324,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 1.7788009643554688,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.5254,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 2.3062965869903564,
      "learning_rate": 6.75e-05,
      "loss": 0.5179,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 2.0490458011627197,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.5153,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 1.8090740442276,
      "learning_rate": 7.25e-05,
      "loss": 0.5104,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 2.657374620437622,
      "learning_rate": 7.5e-05,
      "loss": 0.5072,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 1.7845385074615479,
      "learning_rate": 7.75e-05,
      "loss": 0.5046,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 1.7019948959350586,
      "learning_rate": 8e-05,
      "loss": 0.5007,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 2.190263032913208,
      "learning_rate": 8.25e-05,
      "loss": 0.4951,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 1.8702505826950073,
      "learning_rate": 8.5e-05,
      "loss": 0.4908,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 1.4771983623504639,
      "learning_rate": 8.75e-05,
      "loss": 0.4928,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 1.3755372762680054,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.4863,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 1.5510787963867188,
      "learning_rate": 9.25e-05,
      "loss": 0.4827,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 1.4641170501708984,
      "learning_rate": 9.5e-05,
      "loss": 0.4792,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 1.366790771484375,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.4792,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 1.3549631834030151,
      "learning_rate": 0.0001,
      "loss": 0.4757,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.4845942258834839,
      "eval_runtime": 128.4296,
      "eval_samples_per_second": 1361.852,
      "eval_steps_per_second": 42.56,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 1.2034014463424683,
      "learning_rate": 0.0001025,
      "loss": 0.4718,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 1.2850279808044434,
      "learning_rate": 0.000105,
      "loss": 0.4709,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 1.3612101078033447,
      "learning_rate": 0.0001075,
      "loss": 0.4704,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 1.1575970649719238,
      "learning_rate": 0.00011,
      "loss": 0.4673,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 1.189535140991211,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.4664,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 1.0694835186004639,
      "learning_rate": 0.000115,
      "loss": 0.4619,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 1.0287176370620728,
      "learning_rate": 0.0001175,
      "loss": 0.4594,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 1.1026235818862915,
      "learning_rate": 0.00012,
      "loss": 0.4604,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 0.9934907555580139,
      "learning_rate": 0.0001225,
      "loss": 0.4591,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.9020723700523376,
      "learning_rate": 0.000125,
      "loss": 0.4588,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 1.0732640027999878,
      "learning_rate": 0.0001275,
      "loss": 0.4556,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 1.0027148723602295,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.4536,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 0.9345815181732178,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.4495,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.8518876433372498,
      "learning_rate": 0.000135,
      "loss": 0.4494,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.8373232483863831,
      "learning_rate": 0.0001375,
      "loss": 0.4506,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.8805164694786072,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4481,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.9199620485305786,
      "learning_rate": 0.0001425,
      "loss": 0.4475,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.8165016174316406,
      "learning_rate": 0.000145,
      "loss": 0.4478,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.8446570038795471,
      "learning_rate": 0.0001475,
      "loss": 0.4428,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.802059531211853,
      "learning_rate": 0.00015,
      "loss": 0.4438,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.4504336714744568,
      "eval_runtime": 128.7034,
      "eval_samples_per_second": 1358.954,
      "eval_steps_per_second": 42.47,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 0.9189386367797852,
      "learning_rate": 0.0001525,
      "loss": 0.4417,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.8628349304199219,
      "learning_rate": 0.000155,
      "loss": 0.4437,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.7572553753852844,
      "learning_rate": 0.0001575,
      "loss": 0.4393,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 0.8165538311004639,
      "learning_rate": 0.00016,
      "loss": 0.4404,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.6959249377250671,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.4401,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.6824169158935547,
      "learning_rate": 0.000165,
      "loss": 0.4417,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.6836370825767517,
      "learning_rate": 0.0001675,
      "loss": 0.4344,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.7615443468093872,
      "learning_rate": 0.00017,
      "loss": 0.434,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.7115674614906311,
      "learning_rate": 0.0001725,
      "loss": 0.4344,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.6492370963096619,
      "learning_rate": 0.000175,
      "loss": 0.4353,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.7039196491241455,
      "learning_rate": 0.0001775,
      "loss": 0.4353,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.7057081460952759,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4338,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6679012179374695,
      "learning_rate": 0.0001825,
      "loss": 0.4314,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.6397450566291809,
      "learning_rate": 0.000185,
      "loss": 0.4334,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.6094369888305664,
      "learning_rate": 0.0001875,
      "loss": 0.4299,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.6296700239181519,
      "learning_rate": 0.00019,
      "loss": 0.4301,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.610196590423584,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4282,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.6316863298416138,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.4281,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.6855349540710449,
      "learning_rate": 0.0001975,
      "loss": 0.4297,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.6374816298484802,
      "learning_rate": 0.0002,
      "loss": 0.43,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.4369107782840729,
      "eval_runtime": 127.9251,
      "eval_samples_per_second": 1367.221,
      "eval_steps_per_second": 42.728,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.7004527449607849,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4301,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.6277512311935425,
      "learning_rate": 0.000205,
      "loss": 0.4311,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.6339156031608582,
      "learning_rate": 0.0002075,
      "loss": 0.4264,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.6110216379165649,
      "learning_rate": 0.00021,
      "loss": 0.4266,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.5686254501342773,
      "learning_rate": 0.0002125,
      "loss": 0.4242,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.6009511947631836,
      "learning_rate": 0.000215,
      "loss": 0.4235,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.6042144894599915,
      "learning_rate": 0.0002175,
      "loss": 0.4245,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.6410089135169983,
      "learning_rate": 0.00022,
      "loss": 0.4238,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.5465577840805054,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4225,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.6768233180046082,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.4209,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.5699335932731628,
      "learning_rate": 0.0002275,
      "loss": 0.4239,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.48973900079727173,
      "learning_rate": 0.00023,
      "loss": 0.4227,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.48985007405281067,
      "learning_rate": 0.0002325,
      "loss": 0.4223,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.5395894646644592,
      "learning_rate": 0.000235,
      "loss": 0.4211,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.49655449390411377,
      "learning_rate": 0.0002375,
      "loss": 0.418,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.51816326379776,
      "learning_rate": 0.00024,
      "loss": 0.4204,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.5614078044891357,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4177,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.4970824718475342,
      "learning_rate": 0.000245,
      "loss": 0.4176,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.48516979813575745,
      "learning_rate": 0.0002475,
      "loss": 0.4217,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.4677104353904724,
      "learning_rate": 0.00025,
      "loss": 0.42,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.42737236618995667,
      "eval_runtime": 129.4185,
      "eval_samples_per_second": 1351.446,
      "eval_steps_per_second": 42.235,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.4865271747112274,
      "learning_rate": 0.0002525,
      "loss": 0.4193,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.46163859963417053,
      "learning_rate": 0.000255,
      "loss": 0.4214,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.5060335993766785,
      "learning_rate": 0.0002575,
      "loss": 0.4209,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.4948841631412506,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4175,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.441733717918396,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4172,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.4747803509235382,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4184,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.5074777603149414,
      "learning_rate": 0.0002675,
      "loss": 0.417,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.45933592319488525,
      "learning_rate": 0.00027,
      "loss": 0.4163,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.4192236363887787,
      "learning_rate": 0.0002725,
      "loss": 0.4166,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.4391326606273651,
      "learning_rate": 0.000275,
      "loss": 0.4174,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.42312613129615784,
      "learning_rate": 0.0002775,
      "loss": 0.4134,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.40407946705818176,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4184,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.48777297139167786,
      "learning_rate": 0.0002825,
      "loss": 0.4166,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.4021095037460327,
      "learning_rate": 0.000285,
      "loss": 0.4139,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.4206571578979492,
      "learning_rate": 0.0002875,
      "loss": 0.4151,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.40110212564468384,
      "learning_rate": 0.00029,
      "loss": 0.4114,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.45749855041503906,
      "learning_rate": 0.0002925,
      "loss": 0.4131,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.4581412374973297,
      "learning_rate": 0.000295,
      "loss": 0.4124,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.4041414260864258,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4119,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.4053143560886383,
      "learning_rate": 0.0003,
      "loss": 0.4115,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.4224972724914551,
      "eval_runtime": 129.452,
      "eval_samples_per_second": 1351.096,
      "eval_steps_per_second": 42.224,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.3942982852458954,
      "learning_rate": 0.0003025,
      "loss": 0.4122,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.37164565920829773,
      "learning_rate": 0.000305,
      "loss": 0.4084,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.39092904329299927,
      "learning_rate": 0.0003075,
      "loss": 0.4133,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.3906428813934326,
      "learning_rate": 0.00031,
      "loss": 0.4124,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.44472792744636536,
      "learning_rate": 0.0003125,
      "loss": 0.4127,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.4198342561721802,
      "learning_rate": 0.000315,
      "loss": 0.4117,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.3808361291885376,
      "learning_rate": 0.0003175,
      "loss": 0.4102,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.40211760997772217,
      "learning_rate": 0.00032,
      "loss": 0.4124,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.3892241418361664,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4116,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.45234212279319763,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.411,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.3995421528816223,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4111,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.38047540187835693,
      "learning_rate": 0.00033,
      "loss": 0.4089,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.35546979308128357,
      "learning_rate": 0.0003325,
      "loss": 0.4083,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.3998681306838989,
      "learning_rate": 0.000335,
      "loss": 0.41,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.37506037950515747,
      "learning_rate": 0.0003375,
      "loss": 0.4088,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.33378902077674866,
      "learning_rate": 0.00034,
      "loss": 0.4082,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.340838760137558,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.4097,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.3572237193584442,
      "learning_rate": 0.000345,
      "loss": 0.4101,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.34534335136413574,
      "learning_rate": 0.0003475,
      "loss": 0.4092,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.3258318603038788,
      "learning_rate": 0.00035,
      "loss": 0.4109,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.4171728193759918,
      "eval_runtime": 128.7573,
      "eval_samples_per_second": 1358.386,
      "eval_steps_per_second": 42.452,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.35878270864486694,
      "learning_rate": 0.0003525,
      "loss": 0.4104,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.3481902480125427,
      "learning_rate": 0.000355,
      "loss": 0.4094,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.2805223762989044,
      "learning_rate": 0.0003575,
      "loss": 0.4083,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.31772246956825256,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4088,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.3188650608062744,
      "learning_rate": 0.0003625,
      "loss": 0.4073,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.36809444427490234,
      "learning_rate": 0.000365,
      "loss": 0.4087,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.3807595670223236,
      "learning_rate": 0.0003675,
      "loss": 0.4088,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.32038646936416626,
      "learning_rate": 0.00037,
      "loss": 0.4053,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.311273992061615,
      "learning_rate": 0.0003725,
      "loss": 0.4048,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.31213462352752686,
      "learning_rate": 0.000375,
      "loss": 0.4073,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.3381391167640686,
      "learning_rate": 0.0003775,
      "loss": 0.4049,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.3235557973384857,
      "learning_rate": 0.00038,
      "loss": 0.4061,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.35423457622528076,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4081,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.34133782982826233,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4046,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.32381564378738403,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4047,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.32525336742401123,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4044,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.37486958503723145,
      "learning_rate": 0.0003925,
      "loss": 0.4025,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.29943546652793884,
      "learning_rate": 0.000395,
      "loss": 0.405,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.30476880073547363,
      "learning_rate": 0.0003975,
      "loss": 0.4052,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.3299487829208374,
      "learning_rate": 0.0004,
      "loss": 0.4043,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.4150128960609436,
      "eval_runtime": 128.3355,
      "eval_samples_per_second": 1362.849,
      "eval_steps_per_second": 42.591,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.2903866469860077,
      "learning_rate": 0.0004025,
      "loss": 0.4067,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.2625872790813446,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4055,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.30442285537719727,
      "learning_rate": 0.0004075,
      "loss": 0.4057,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.29190775752067566,
      "learning_rate": 0.00041,
      "loss": 0.4047,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.2684473693370819,
      "learning_rate": 0.0004125,
      "loss": 0.4053,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.29497671127319336,
      "learning_rate": 0.000415,
      "loss": 0.4042,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.2875654399394989,
      "learning_rate": 0.0004175,
      "loss": 0.4039,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.26540109515190125,
      "learning_rate": 0.00042,
      "loss": 0.4033,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.2759135663509369,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4043,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.3055497705936432,
      "learning_rate": 0.000425,
      "loss": 0.4027,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.2600659728050232,
      "learning_rate": 0.0004275,
      "loss": 0.4053,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.32753193378448486,
      "learning_rate": 0.00043,
      "loss": 0.4054,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.296796977519989,
      "learning_rate": 0.0004325,
      "loss": 0.4046,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.28143325448036194,
      "learning_rate": 0.000435,
      "loss": 0.4035,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.28534504771232605,
      "learning_rate": 0.0004375,
      "loss": 0.4012,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.29474538564682007,
      "learning_rate": 0.00044,
      "loss": 0.4035,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.24983559548854828,
      "learning_rate": 0.0004425,
      "loss": 0.4003,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.27723661065101624,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4041,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.2717572748661041,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4022,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.25229397416114807,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4015,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.41004738211631775,
      "eval_runtime": 128.1463,
      "eval_samples_per_second": 1364.862,
      "eval_steps_per_second": 42.654,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.2946473956108093,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4001,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.25171709060668945,
      "learning_rate": 0.000455,
      "loss": 0.4019,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.23573456704616547,
      "learning_rate": 0.0004575,
      "loss": 0.4008,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.2536202371120453,
      "learning_rate": 0.00046,
      "loss": 0.4023,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.2345058023929596,
      "learning_rate": 0.0004625,
      "loss": 0.3988,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.2331751137971878,
      "learning_rate": 0.000465,
      "loss": 0.4002,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.2300814390182495,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4024,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.2421596646308899,
      "learning_rate": 0.00047,
      "loss": 0.4022,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.25403597950935364,
      "learning_rate": 0.0004725,
      "loss": 0.4008,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.26269328594207764,
      "learning_rate": 0.000475,
      "loss": 0.3986,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.21604667603969574,
      "learning_rate": 0.0004775,
      "loss": 0.4004,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.29476335644721985,
      "learning_rate": 0.00048,
      "loss": 0.4006,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.2432163506746292,
      "learning_rate": 0.0004825,
      "loss": 0.4026,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.25108200311660767,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.4011,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.2479996532201767,
      "learning_rate": 0.0004875,
      "loss": 0.3979,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.2779645323753357,
      "learning_rate": 0.00049,
      "loss": 0.3997,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.2758745551109314,
      "learning_rate": 0.0004925,
      "loss": 0.3974,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.25865718722343445,
      "learning_rate": 0.000495,
      "loss": 0.3996,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.23608845472335815,
      "learning_rate": 0.0004975,
      "loss": 0.3988,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.25587818026542664,
      "learning_rate": 0.0005,
      "loss": 0.3997,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.4099375009536743,
      "eval_runtime": 128.3481,
      "eval_samples_per_second": 1362.716,
      "eval_steps_per_second": 42.587,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.24976427853107452,
      "learning_rate": 0.0004997786925153809,
      "loss": 0.3997,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.2500334084033966,
      "learning_rate": 0.0004995573850307618,
      "loss": 0.4006,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.22166067361831665,
      "learning_rate": 0.0004993360775461426,
      "loss": 0.3953,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.2115657478570938,
      "learning_rate": 0.0004991147700615235,
      "loss": 0.3981,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.24348744750022888,
      "learning_rate": 0.0004988934625769043,
      "loss": 0.3964,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.2155817300081253,
      "learning_rate": 0.0004986721550922853,
      "loss": 0.3965,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.222042515873909,
      "learning_rate": 0.0004984508476076661,
      "loss": 0.3988,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.2094678431749344,
      "learning_rate": 0.000498229540123047,
      "loss": 0.399,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.2305668145418167,
      "learning_rate": 0.0004980082326384278,
      "loss": 0.3965,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.20722277462482452,
      "learning_rate": 0.0004977869251538087,
      "loss": 0.396,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.2356901615858078,
      "learning_rate": 0.0004975656176691896,
      "loss": 0.3961,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.2159380465745926,
      "learning_rate": 0.0004973443101845705,
      "loss": 0.3941,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.2084529846906662,
      "learning_rate": 0.0004971230026999513,
      "loss": 0.3936,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.23583504557609558,
      "learning_rate": 0.0004969016952153321,
      "loss": 0.3967,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.22701483964920044,
      "learning_rate": 0.0004966803877307131,
      "loss": 0.3943,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.22730235755443573,
      "learning_rate": 0.0004964590802460939,
      "loss": 0.395,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.2100510448217392,
      "learning_rate": 0.0004962377727614748,
      "loss": 0.3938,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.206551656126976,
      "learning_rate": 0.0004960164652768557,
      "loss": 0.393,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.23623211681842804,
      "learning_rate": 0.0004957951577922366,
      "loss": 0.3948,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.2406148463487625,
      "learning_rate": 0.0004955738503076174,
      "loss": 0.393,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.4042085111141205,
      "eval_runtime": 129.4038,
      "eval_samples_per_second": 1351.599,
      "eval_steps_per_second": 42.24,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.2362050712108612,
      "learning_rate": 0.0004953525428229983,
      "loss": 0.3933,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.21965329349040985,
      "learning_rate": 0.0004951312353383792,
      "loss": 0.396,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.20998528599739075,
      "learning_rate": 0.00049490992785376,
      "loss": 0.393,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.2154458910226822,
      "learning_rate": 0.0004946886203691409,
      "loss": 0.3935,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.21019494533538818,
      "learning_rate": 0.0004944673128845217,
      "loss": 0.3955,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.21257473528385162,
      "learning_rate": 0.0004942460053999026,
      "loss": 0.3934,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.2116396278142929,
      "learning_rate": 0.0004940246979152835,
      "loss": 0.3923,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.21008241176605225,
      "learning_rate": 0.0004938033904306644,
      "loss": 0.3935,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.19853322207927704,
      "learning_rate": 0.0004935820829460452,
      "loss": 0.3925,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.2245294153690338,
      "learning_rate": 0.0004933607754614261,
      "loss": 0.3903,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.21071387827396393,
      "learning_rate": 0.000493139467976807,
      "loss": 0.3908,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.2240295261144638,
      "learning_rate": 0.0004929181604921879,
      "loss": 0.393,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.19144384562969208,
      "learning_rate": 0.0004926968530075687,
      "loss": 0.3922,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.20726534724235535,
      "learning_rate": 0.0004924755455229495,
      "loss": 0.3899,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.19124126434326172,
      "learning_rate": 0.0004922542380383305,
      "loss": 0.3903,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.19144468009471893,
      "learning_rate": 0.0004920329305537113,
      "loss": 0.3904,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.20296768844127655,
      "learning_rate": 0.0004918116230690922,
      "loss": 0.3923,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.22189581394195557,
      "learning_rate": 0.0004915903155844731,
      "loss": 0.3915,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.19991223514080048,
      "learning_rate": 0.000491369008099854,
      "loss": 0.3892,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.1942604035139084,
      "learning_rate": 0.0004911477006152348,
      "loss": 0.3888,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.3989320695400238,
      "eval_runtime": 129.7889,
      "eval_samples_per_second": 1347.589,
      "eval_steps_per_second": 42.115,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.1881447732448578,
      "learning_rate": 0.0004909263931306157,
      "loss": 0.3907,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.2056901454925537,
      "learning_rate": 0.0004907050856459966,
      "loss": 0.389,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.18597450852394104,
      "learning_rate": 0.0004904837781613775,
      "loss": 0.3905,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.18433256447315216,
      "learning_rate": 0.0004902624706767583,
      "loss": 0.3886,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.17826113104820251,
      "learning_rate": 0.0004900411631921391,
      "loss": 0.3899,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.20835722982883453,
      "learning_rate": 0.00048981985570752,
      "loss": 0.387,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.2078513503074646,
      "learning_rate": 0.0004895985482229009,
      "loss": 0.3856,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.20793695747852325,
      "learning_rate": 0.0004893772407382818,
      "loss": 0.3887,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.1901252120733261,
      "learning_rate": 0.0004891559332536626,
      "loss": 0.385,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.19774967432022095,
      "learning_rate": 0.0004889346257690435,
      "loss": 0.3897,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.2077690213918686,
      "learning_rate": 0.0004887133182844244,
      "loss": 0.384,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.20165103673934937,
      "learning_rate": 0.0004884920107998053,
      "loss": 0.389,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.2236262857913971,
      "learning_rate": 0.00048827070331518616,
      "loss": 0.3864,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.22870999574661255,
      "learning_rate": 0.000488049395830567,
      "loss": 0.3864,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.19966977834701538,
      "learning_rate": 0.0004878280883459479,
      "loss": 0.386,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.19477136433124542,
      "learning_rate": 0.00048760678086132874,
      "loss": 0.3876,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.19011758267879486,
      "learning_rate": 0.00048738547337670964,
      "loss": 0.3859,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.18914693593978882,
      "learning_rate": 0.0004871641658920905,
      "loss": 0.3836,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.18694724142551422,
      "learning_rate": 0.0004869428584074714,
      "loss": 0.3856,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.20071658492088318,
      "learning_rate": 0.00048672155092285217,
      "loss": 0.3861,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.3946227431297302,
      "eval_runtime": 129.6551,
      "eval_samples_per_second": 1348.979,
      "eval_steps_per_second": 42.158,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.17124024033546448,
      "learning_rate": 0.00048650024343823307,
      "loss": 0.3852,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.1896018385887146,
      "learning_rate": 0.00048627893595361396,
      "loss": 0.385,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.18038363754749298,
      "learning_rate": 0.0004860576284689948,
      "loss": 0.3853,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.19226975739002228,
      "learning_rate": 0.0004858363209843757,
      "loss": 0.3848,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.2232610136270523,
      "learning_rate": 0.00048561501349975655,
      "loss": 0.3834,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.1964004784822464,
      "learning_rate": 0.00048539370601513744,
      "loss": 0.3825,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.18499279022216797,
      "learning_rate": 0.0004851723985305183,
      "loss": 0.3845,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.1676335632801056,
      "learning_rate": 0.0004849510910458992,
      "loss": 0.3826,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.1678188294172287,
      "learning_rate": 0.0004847297835612801,
      "loss": 0.3843,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.18113461136817932,
      "learning_rate": 0.0004845084760766609,
      "loss": 0.3832,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.18180134892463684,
      "learning_rate": 0.0004842871685920418,
      "loss": 0.3842,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.21017718315124512,
      "learning_rate": 0.00048406586110742267,
      "loss": 0.3831,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.18265527486801147,
      "learning_rate": 0.00048384455362280356,
      "loss": 0.3861,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.18049681186676025,
      "learning_rate": 0.0004836232461381844,
      "loss": 0.3824,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.17153987288475037,
      "learning_rate": 0.0004834019386535653,
      "loss": 0.382,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.2061903327703476,
      "learning_rate": 0.0004831806311689461,
      "loss": 0.3812,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.1843198537826538,
      "learning_rate": 0.000482959323684327,
      "loss": 0.3832,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.18098336458206177,
      "learning_rate": 0.0004827380161997079,
      "loss": 0.3847,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.1978389322757721,
      "learning_rate": 0.00048251670871508873,
      "loss": 0.3825,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.17670072615146637,
      "learning_rate": 0.00048229540123046963,
      "loss": 0.3835,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.392031729221344,
      "eval_runtime": 130.0601,
      "eval_samples_per_second": 1344.778,
      "eval_steps_per_second": 42.027,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.21365931630134583,
      "learning_rate": 0.00048207409374585047,
      "loss": 0.3816,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.188947856426239,
      "learning_rate": 0.00048185278626123137,
      "loss": 0.3837,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.1914193332195282,
      "learning_rate": 0.0004816314787766122,
      "loss": 0.3802,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.18944349884986877,
      "learning_rate": 0.0004814101712919931,
      "loss": 0.3826,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.18240560591220856,
      "learning_rate": 0.00048118886380737395,
      "loss": 0.3814,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.170697882771492,
      "learning_rate": 0.00048096755632275485,
      "loss": 0.3831,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.17507220804691315,
      "learning_rate": 0.00048074624883813575,
      "loss": 0.381,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.18415199220180511,
      "learning_rate": 0.0004805249413535166,
      "loss": 0.3817,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.16262854635715485,
      "learning_rate": 0.0004803036338688975,
      "loss": 0.3832,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.16510426998138428,
      "learning_rate": 0.00048008232638427833,
      "loss": 0.3815,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.20927608013153076,
      "learning_rate": 0.00047986101889965923,
      "loss": 0.384,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.17764097452163696,
      "learning_rate": 0.00047963971141504007,
      "loss": 0.3803,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.17684027552604675,
      "learning_rate": 0.0004794184039304209,
      "loss": 0.382,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.1781674325466156,
      "learning_rate": 0.00047919709644580176,
      "loss": 0.3818,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.17820729315280914,
      "learning_rate": 0.00047897578896118265,
      "loss": 0.3825,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.1732993870973587,
      "learning_rate": 0.00047875448147656355,
      "loss": 0.3811,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.17513060569763184,
      "learning_rate": 0.0004785331739919444,
      "loss": 0.3796,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.20308473706245422,
      "learning_rate": 0.0004783118665073253,
      "loss": 0.3816,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.17997170984745026,
      "learning_rate": 0.00047809055902270614,
      "loss": 0.382,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.1718747466802597,
      "learning_rate": 0.00047786925153808703,
      "loss": 0.3798,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.390117347240448,
      "eval_runtime": 129.2304,
      "eval_samples_per_second": 1353.412,
      "eval_steps_per_second": 42.297,
      "step": 30000
    },
    {
      "epoch": 1.2239006241486572,
      "grad_norm": 0.18282683193683624,
      "learning_rate": 0.0004776479440534679,
      "loss": 0.3793,
      "step": 30100
    },
    {
      "epoch": 1.2279667391790514,
      "grad_norm": 0.19238057732582092,
      "learning_rate": 0.0004774266365688488,
      "loss": 0.3805,
      "step": 30200
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.18958482146263123,
      "learning_rate": 0.00047720532908422967,
      "loss": 0.3777,
      "step": 30300
    },
    {
      "epoch": 1.2360989692398399,
      "grad_norm": 0.1643638014793396,
      "learning_rate": 0.0004769840215996105,
      "loss": 0.3827,
      "step": 30400
    },
    {
      "epoch": 1.240165084270234,
      "grad_norm": 0.17425067722797394,
      "learning_rate": 0.0004767627141149914,
      "loss": 0.3804,
      "step": 30500
    },
    {
      "epoch": 1.2442311993006283,
      "grad_norm": 0.1772625893354416,
      "learning_rate": 0.00047654140663037225,
      "loss": 0.3796,
      "step": 30600
    },
    {
      "epoch": 1.2482973143310225,
      "grad_norm": 0.18113282322883606,
      "learning_rate": 0.00047632009914575315,
      "loss": 0.3782,
      "step": 30700
    },
    {
      "epoch": 1.2523634293614165,
      "grad_norm": 0.182744562625885,
      "learning_rate": 0.000476098791661134,
      "loss": 0.3823,
      "step": 30800
    },
    {
      "epoch": 1.256429544391811,
      "grad_norm": 0.17713408172130585,
      "learning_rate": 0.0004758774841765149,
      "loss": 0.3809,
      "step": 30900
    },
    {
      "epoch": 1.260495659422205,
      "grad_norm": 0.1633019745349884,
      "learning_rate": 0.0004756561766918957,
      "loss": 0.3784,
      "step": 31000
    },
    {
      "epoch": 1.2645617744525992,
      "grad_norm": 0.16829867660999298,
      "learning_rate": 0.0004754348692072766,
      "loss": 0.3806,
      "step": 31100
    },
    {
      "epoch": 1.2686278894829934,
      "grad_norm": 0.17781582474708557,
      "learning_rate": 0.0004752135617226575,
      "loss": 0.3789,
      "step": 31200
    },
    {
      "epoch": 1.2726940045133877,
      "grad_norm": 0.16799651086330414,
      "learning_rate": 0.0004749922542380383,
      "loss": 0.3774,
      "step": 31300
    },
    {
      "epoch": 1.2767601195437819,
      "grad_norm": 0.17409995198249817,
      "learning_rate": 0.0004747709467534192,
      "loss": 0.3806,
      "step": 31400
    },
    {
      "epoch": 1.280826234574176,
      "grad_norm": 0.1597445011138916,
      "learning_rate": 0.00047454963926880006,
      "loss": 0.3766,
      "step": 31500
    },
    {
      "epoch": 1.2848923496045703,
      "grad_norm": 0.17295849323272705,
      "learning_rate": 0.00047432833178418096,
      "loss": 0.3784,
      "step": 31600
    },
    {
      "epoch": 1.2889584646349646,
      "grad_norm": 0.18094860017299652,
      "learning_rate": 0.0004741070242995618,
      "loss": 0.3784,
      "step": 31700
    },
    {
      "epoch": 1.2930245796653588,
      "grad_norm": 0.19771508872509003,
      "learning_rate": 0.0004738857168149427,
      "loss": 0.3756,
      "step": 31800
    },
    {
      "epoch": 1.297090694695753,
      "grad_norm": 0.17952121794223785,
      "learning_rate": 0.00047366440933032354,
      "loss": 0.3807,
      "step": 31900
    },
    {
      "epoch": 1.3011568097261472,
      "grad_norm": 0.18210859596729279,
      "learning_rate": 0.00047344310184570444,
      "loss": 0.3796,
      "step": 32000
    },
    {
      "epoch": 1.3011568097261472,
      "eval_loss": 0.3882320523262024,
      "eval_runtime": 128.5744,
      "eval_samples_per_second": 1360.317,
      "eval_steps_per_second": 42.512,
      "step": 32000
    },
    {
      "epoch": 1.3052229247565412,
      "grad_norm": 0.18713556230068207,
      "learning_rate": 0.00047322179436108533,
      "loss": 0.3781,
      "step": 32100
    },
    {
      "epoch": 1.3092890397869357,
      "grad_norm": 0.16332168877124786,
      "learning_rate": 0.0004730004868764662,
      "loss": 0.3781,
      "step": 32200
    },
    {
      "epoch": 1.3133551548173297,
      "grad_norm": 0.16333697736263275,
      "learning_rate": 0.0004727791793918471,
      "loss": 0.3808,
      "step": 32300
    },
    {
      "epoch": 1.3174212698477241,
      "grad_norm": 0.1838030368089676,
      "learning_rate": 0.0004725578719072279,
      "loss": 0.3782,
      "step": 32400
    },
    {
      "epoch": 1.3214873848781181,
      "grad_norm": 0.161000594496727,
      "learning_rate": 0.0004723365644226088,
      "loss": 0.3762,
      "step": 32500
    },
    {
      "epoch": 1.3255534999085123,
      "grad_norm": 0.175962895154953,
      "learning_rate": 0.00047211525693798966,
      "loss": 0.3772,
      "step": 32600
    },
    {
      "epoch": 1.3296196149389066,
      "grad_norm": 0.16691571474075317,
      "learning_rate": 0.0004718939494533705,
      "loss": 0.3763,
      "step": 32700
    },
    {
      "epoch": 1.3336857299693008,
      "grad_norm": 0.18440215289592743,
      "learning_rate": 0.00047167264196875134,
      "loss": 0.3767,
      "step": 32800
    },
    {
      "epoch": 1.337751844999695,
      "grad_norm": 0.18991735577583313,
      "learning_rate": 0.00047145133448413224,
      "loss": 0.3779,
      "step": 32900
    },
    {
      "epoch": 1.3418179600300892,
      "grad_norm": 0.20680265128612518,
      "learning_rate": 0.00047123002699951314,
      "loss": 0.3791,
      "step": 33000
    },
    {
      "epoch": 1.3458840750604835,
      "grad_norm": 0.17591778934001923,
      "learning_rate": 0.000471008719514894,
      "loss": 0.3782,
      "step": 33100
    },
    {
      "epoch": 1.3499501900908777,
      "grad_norm": 0.16101068258285522,
      "learning_rate": 0.0004707874120302749,
      "loss": 0.3808,
      "step": 33200
    },
    {
      "epoch": 1.354016305121272,
      "grad_norm": 0.17213338613510132,
      "learning_rate": 0.0004705661045456557,
      "loss": 0.3755,
      "step": 33300
    },
    {
      "epoch": 1.3580824201516661,
      "grad_norm": 0.17457877099514008,
      "learning_rate": 0.0004703447970610366,
      "loss": 0.3784,
      "step": 33400
    },
    {
      "epoch": 1.3621485351820604,
      "grad_norm": 0.17830415070056915,
      "learning_rate": 0.00047012348957641746,
      "loss": 0.3752,
      "step": 33500
    },
    {
      "epoch": 1.3662146502124546,
      "grad_norm": 0.17990422248840332,
      "learning_rate": 0.00046990218209179836,
      "loss": 0.3797,
      "step": 33600
    },
    {
      "epoch": 1.3702807652428488,
      "grad_norm": 0.17103064060211182,
      "learning_rate": 0.00046968087460717926,
      "loss": 0.376,
      "step": 33700
    },
    {
      "epoch": 1.3743468802732428,
      "grad_norm": 0.1838916689157486,
      "learning_rate": 0.0004694595671225601,
      "loss": 0.3778,
      "step": 33800
    },
    {
      "epoch": 1.3784129953036373,
      "grad_norm": 0.18024355173110962,
      "learning_rate": 0.000469238259637941,
      "loss": 0.3756,
      "step": 33900
    },
    {
      "epoch": 1.3824791103340313,
      "grad_norm": 0.1886271983385086,
      "learning_rate": 0.00046901695215332184,
      "loss": 0.3781,
      "step": 34000
    },
    {
      "epoch": 1.3824791103340313,
      "eval_loss": 0.3863961100578308,
      "eval_runtime": 128.7416,
      "eval_samples_per_second": 1358.551,
      "eval_steps_per_second": 42.457,
      "step": 34000
    },
    {
      "epoch": 1.3865452253644255,
      "grad_norm": 0.17850492894649506,
      "learning_rate": 0.00046879564466870274,
      "loss": 0.3767,
      "step": 34100
    },
    {
      "epoch": 1.3906113403948197,
      "grad_norm": 0.17400094866752625,
      "learning_rate": 0.0004685743371840836,
      "loss": 0.3763,
      "step": 34200
    },
    {
      "epoch": 1.394677455425214,
      "grad_norm": 0.17501454055309296,
      "learning_rate": 0.0004683530296994645,
      "loss": 0.3777,
      "step": 34300
    },
    {
      "epoch": 1.3987435704556082,
      "grad_norm": 0.19422617554664612,
      "learning_rate": 0.00046813172221484527,
      "loss": 0.3781,
      "step": 34400
    },
    {
      "epoch": 1.4028096854860024,
      "grad_norm": 0.17945384979248047,
      "learning_rate": 0.00046791041473022617,
      "loss": 0.3767,
      "step": 34500
    },
    {
      "epoch": 1.4068758005163966,
      "grad_norm": 0.18051578104496002,
      "learning_rate": 0.00046768910724560706,
      "loss": 0.3744,
      "step": 34600
    },
    {
      "epoch": 1.4109419155467908,
      "grad_norm": 0.1819063127040863,
      "learning_rate": 0.0004674677997609879,
      "loss": 0.3749,
      "step": 34700
    },
    {
      "epoch": 1.415008030577185,
      "grad_norm": 0.15687309205532074,
      "learning_rate": 0.0004672464922763688,
      "loss": 0.3761,
      "step": 34800
    },
    {
      "epoch": 1.4190741456075793,
      "grad_norm": 0.16164511442184448,
      "learning_rate": 0.00046702518479174965,
      "loss": 0.3754,
      "step": 34900
    },
    {
      "epoch": 1.4231402606379735,
      "grad_norm": 0.18609465658664703,
      "learning_rate": 0.00046680387730713054,
      "loss": 0.3774,
      "step": 35000
    },
    {
      "epoch": 1.4272063756683677,
      "grad_norm": 0.17465056478977203,
      "learning_rate": 0.0004665825698225114,
      "loss": 0.3766,
      "step": 35100
    },
    {
      "epoch": 1.431272490698762,
      "grad_norm": 0.1690293848514557,
      "learning_rate": 0.0004663612623378923,
      "loss": 0.3772,
      "step": 35200
    },
    {
      "epoch": 1.435338605729156,
      "grad_norm": 0.16696199774742126,
      "learning_rate": 0.0004661399548532731,
      "loss": 0.3757,
      "step": 35300
    },
    {
      "epoch": 1.4394047207595504,
      "grad_norm": 0.1657029688358307,
      "learning_rate": 0.000465918647368654,
      "loss": 0.3767,
      "step": 35400
    },
    {
      "epoch": 1.4434708357899444,
      "grad_norm": 0.2022552639245987,
      "learning_rate": 0.0004656973398840349,
      "loss": 0.374,
      "step": 35500
    },
    {
      "epoch": 1.4475369508203388,
      "grad_norm": 0.17035847902297974,
      "learning_rate": 0.00046547603239941576,
      "loss": 0.3772,
      "step": 35600
    },
    {
      "epoch": 1.4516030658507328,
      "grad_norm": 0.17150625586509705,
      "learning_rate": 0.00046525472491479666,
      "loss": 0.3766,
      "step": 35700
    },
    {
      "epoch": 1.455669180881127,
      "grad_norm": 0.18413327634334564,
      "learning_rate": 0.0004650334174301775,
      "loss": 0.3758,
      "step": 35800
    },
    {
      "epoch": 1.4597352959115213,
      "grad_norm": 0.1704845130443573,
      "learning_rate": 0.0004648121099455584,
      "loss": 0.3759,
      "step": 35900
    },
    {
      "epoch": 1.4638014109419155,
      "grad_norm": 0.1930253803730011,
      "learning_rate": 0.00046459080246093925,
      "loss": 0.3776,
      "step": 36000
    },
    {
      "epoch": 1.4638014109419155,
      "eval_loss": 0.38492509722709656,
      "eval_runtime": 129.6542,
      "eval_samples_per_second": 1348.988,
      "eval_steps_per_second": 42.158,
      "step": 36000
    },
    {
      "epoch": 1.4678675259723097,
      "grad_norm": 0.18089616298675537,
      "learning_rate": 0.0004643694949763201,
      "loss": 0.3788,
      "step": 36100
    },
    {
      "epoch": 1.471933641002704,
      "grad_norm": 0.16339969635009766,
      "learning_rate": 0.00046414818749170093,
      "loss": 0.3752,
      "step": 36200
    },
    {
      "epoch": 1.4759997560330982,
      "grad_norm": 0.16005076467990875,
      "learning_rate": 0.00046392688000708183,
      "loss": 0.3761,
      "step": 36300
    },
    {
      "epoch": 1.4800658710634924,
      "grad_norm": 0.16331550478935242,
      "learning_rate": 0.0004637055725224627,
      "loss": 0.3759,
      "step": 36400
    },
    {
      "epoch": 1.4841319860938866,
      "grad_norm": 0.15114809572696686,
      "learning_rate": 0.00046348426503784357,
      "loss": 0.3758,
      "step": 36500
    },
    {
      "epoch": 1.4881981011242809,
      "grad_norm": 0.1669405847787857,
      "learning_rate": 0.00046326295755322447,
      "loss": 0.3771,
      "step": 36600
    },
    {
      "epoch": 1.492264216154675,
      "grad_norm": 0.18979360163211823,
      "learning_rate": 0.0004630416500686053,
      "loss": 0.3735,
      "step": 36700
    },
    {
      "epoch": 1.4963303311850693,
      "grad_norm": 0.16254229843616486,
      "learning_rate": 0.0004628203425839862,
      "loss": 0.3773,
      "step": 36800
    },
    {
      "epoch": 1.5003964462154635,
      "grad_norm": 0.17483536899089813,
      "learning_rate": 0.00046259903509936705,
      "loss": 0.377,
      "step": 36900
    },
    {
      "epoch": 1.5044625612458575,
      "grad_norm": 0.1789037138223648,
      "learning_rate": 0.00046237772761474795,
      "loss": 0.3753,
      "step": 37000
    },
    {
      "epoch": 1.508528676276252,
      "grad_norm": 0.16860507428646088,
      "learning_rate": 0.00046215642013012885,
      "loss": 0.3737,
      "step": 37100
    },
    {
      "epoch": 1.512594791306646,
      "grad_norm": 0.1870347261428833,
      "learning_rate": 0.0004619351126455097,
      "loss": 0.3755,
      "step": 37200
    },
    {
      "epoch": 1.5166609063370404,
      "grad_norm": 0.17191331088542938,
      "learning_rate": 0.0004617138051608906,
      "loss": 0.3745,
      "step": 37300
    },
    {
      "epoch": 1.5207270213674344,
      "grad_norm": 0.180195614695549,
      "learning_rate": 0.00046149249767627143,
      "loss": 0.3748,
      "step": 37400
    },
    {
      "epoch": 1.5247931363978287,
      "grad_norm": 0.19140948355197906,
      "learning_rate": 0.0004612711901916523,
      "loss": 0.3736,
      "step": 37500
    },
    {
      "epoch": 1.5288592514282229,
      "grad_norm": 0.1396617889404297,
      "learning_rate": 0.00046104988270703317,
      "loss": 0.3739,
      "step": 37600
    },
    {
      "epoch": 1.532925366458617,
      "grad_norm": 0.1719769388437271,
      "learning_rate": 0.00046082857522241407,
      "loss": 0.3731,
      "step": 37700
    },
    {
      "epoch": 1.5369914814890113,
      "grad_norm": 0.1898922473192215,
      "learning_rate": 0.00046060726773779486,
      "loss": 0.3717,
      "step": 37800
    },
    {
      "epoch": 1.5410575965194055,
      "grad_norm": 0.18339644372463226,
      "learning_rate": 0.00046038596025317575,
      "loss": 0.3725,
      "step": 37900
    },
    {
      "epoch": 1.5451237115497998,
      "grad_norm": 0.16520503163337708,
      "learning_rate": 0.00046016465276855665,
      "loss": 0.3753,
      "step": 38000
    },
    {
      "epoch": 1.5451237115497998,
      "eval_loss": 0.3833494186401367,
      "eval_runtime": 130.1539,
      "eval_samples_per_second": 1343.809,
      "eval_steps_per_second": 41.996,
      "step": 38000
    },
    {
      "epoch": 1.549189826580194,
      "grad_norm": 0.18689905107021332,
      "learning_rate": 0.0004599433452839375,
      "loss": 0.3759,
      "step": 38100
    },
    {
      "epoch": 1.5532559416105882,
      "grad_norm": 0.20186014473438263,
      "learning_rate": 0.0004597220377993184,
      "loss": 0.3746,
      "step": 38200
    },
    {
      "epoch": 1.5573220566409822,
      "grad_norm": 0.1641329973936081,
      "learning_rate": 0.00045950073031469923,
      "loss": 0.3731,
      "step": 38300
    },
    {
      "epoch": 1.5613881716713767,
      "grad_norm": 0.18269850313663483,
      "learning_rate": 0.00045927942283008013,
      "loss": 0.373,
      "step": 38400
    },
    {
      "epoch": 1.5654542867017707,
      "grad_norm": 0.16694200038909912,
      "learning_rate": 0.000459058115345461,
      "loss": 0.3709,
      "step": 38500
    },
    {
      "epoch": 1.5695204017321651,
      "grad_norm": 0.17409421503543854,
      "learning_rate": 0.00045883680786084187,
      "loss": 0.3736,
      "step": 38600
    },
    {
      "epoch": 1.5735865167625591,
      "grad_norm": 0.18620899319648743,
      "learning_rate": 0.0004586155003762227,
      "loss": 0.3728,
      "step": 38700
    },
    {
      "epoch": 1.5776526317929536,
      "grad_norm": 0.15527263283729553,
      "learning_rate": 0.0004583941928916036,
      "loss": 0.3751,
      "step": 38800
    },
    {
      "epoch": 1.5817187468233476,
      "grad_norm": 0.16904914379119873,
      "learning_rate": 0.0004581728854069845,
      "loss": 0.3732,
      "step": 38900
    },
    {
      "epoch": 1.5857848618537418,
      "grad_norm": 0.17006699740886688,
      "learning_rate": 0.00045795157792236535,
      "loss": 0.375,
      "step": 39000
    },
    {
      "epoch": 1.589850976884136,
      "grad_norm": 0.15427429974079132,
      "learning_rate": 0.00045773027043774625,
      "loss": 0.3739,
      "step": 39100
    },
    {
      "epoch": 1.5939170919145302,
      "grad_norm": 0.1731628030538559,
      "learning_rate": 0.0004575089629531271,
      "loss": 0.3753,
      "step": 39200
    },
    {
      "epoch": 1.5979832069449245,
      "grad_norm": 0.17025329172611237,
      "learning_rate": 0.000457287655468508,
      "loss": 0.3725,
      "step": 39300
    },
    {
      "epoch": 1.6020493219753187,
      "grad_norm": 0.16645242273807526,
      "learning_rate": 0.0004570663479838888,
      "loss": 0.3725,
      "step": 39400
    },
    {
      "epoch": 1.606115437005713,
      "grad_norm": 0.16971290111541748,
      "learning_rate": 0.0004568450404992697,
      "loss": 0.3726,
      "step": 39500
    },
    {
      "epoch": 1.6101815520361071,
      "grad_norm": 0.1794947236776352,
      "learning_rate": 0.0004566237330146505,
      "loss": 0.3706,
      "step": 39600
    },
    {
      "epoch": 1.6142476670665014,
      "grad_norm": 0.18071357905864716,
      "learning_rate": 0.0004564024255300314,
      "loss": 0.3735,
      "step": 39700
    },
    {
      "epoch": 1.6183137820968954,
      "grad_norm": 0.20060741901397705,
      "learning_rate": 0.0004561811180454123,
      "loss": 0.3711,
      "step": 39800
    },
    {
      "epoch": 1.6223798971272898,
      "grad_norm": 0.1506413072347641,
      "learning_rate": 0.00045595981056079316,
      "loss": 0.3743,
      "step": 39900
    },
    {
      "epoch": 1.6264460121576838,
      "grad_norm": 0.18336929380893707,
      "learning_rate": 0.00045573850307617405,
      "loss": 0.3735,
      "step": 40000
    },
    {
      "epoch": 1.6264460121576838,
      "eval_loss": 0.3818749189376831,
      "eval_runtime": 130.1771,
      "eval_samples_per_second": 1343.57,
      "eval_steps_per_second": 41.989,
      "step": 40000
    },
    {
      "epoch": 1.6305121271880783,
      "grad_norm": 0.16826264560222626,
      "learning_rate": 0.0004555171955915549,
      "loss": 0.3767,
      "step": 40100
    },
    {
      "epoch": 1.6345782422184723,
      "grad_norm": 0.1877373307943344,
      "learning_rate": 0.0004552958881069358,
      "loss": 0.3702,
      "step": 40200
    },
    {
      "epoch": 1.6386443572488667,
      "grad_norm": 0.17343325912952423,
      "learning_rate": 0.00045507458062231664,
      "loss": 0.3755,
      "step": 40300
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.19001416862010956,
      "learning_rate": 0.00045485327313769754,
      "loss": 0.3722,
      "step": 40400
    },
    {
      "epoch": 1.6467765873096551,
      "grad_norm": 0.17280270159244537,
      "learning_rate": 0.0004546319656530784,
      "loss": 0.3749,
      "step": 40500
    },
    {
      "epoch": 1.6508427023400492,
      "grad_norm": 0.18519280850887299,
      "learning_rate": 0.0004544106581684593,
      "loss": 0.3712,
      "step": 40600
    },
    {
      "epoch": 1.6549088173704434,
      "grad_norm": 0.17511354386806488,
      "learning_rate": 0.0004541893506838402,
      "loss": 0.3735,
      "step": 40700
    },
    {
      "epoch": 1.6589749324008376,
      "grad_norm": 0.22277633845806122,
      "learning_rate": 0.000453968043199221,
      "loss": 0.3717,
      "step": 40800
    },
    {
      "epoch": 1.6630410474312318,
      "grad_norm": 0.1828911155462265,
      "learning_rate": 0.0004537467357146019,
      "loss": 0.372,
      "step": 40900
    },
    {
      "epoch": 1.667107162461626,
      "grad_norm": 0.16268813610076904,
      "learning_rate": 0.00045352542822998276,
      "loss": 0.3723,
      "step": 41000
    },
    {
      "epoch": 1.6711732774920203,
      "grad_norm": 0.17785272002220154,
      "learning_rate": 0.0004533041207453636,
      "loss": 0.3711,
      "step": 41100
    },
    {
      "epoch": 1.6752393925224145,
      "grad_norm": 0.16053181886672974,
      "learning_rate": 0.00045308281326074444,
      "loss": 0.3733,
      "step": 41200
    },
    {
      "epoch": 1.6793055075528087,
      "grad_norm": 0.19720973074436188,
      "learning_rate": 0.00045286150577612534,
      "loss": 0.3727,
      "step": 41300
    },
    {
      "epoch": 1.683371622583203,
      "grad_norm": 0.19007857143878937,
      "learning_rate": 0.00045264019829150624,
      "loss": 0.3735,
      "step": 41400
    },
    {
      "epoch": 1.687437737613597,
      "grad_norm": 0.17370620369911194,
      "learning_rate": 0.0004524188908068871,
      "loss": 0.3732,
      "step": 41500
    },
    {
      "epoch": 1.6915038526439914,
      "grad_norm": 0.17362812161445618,
      "learning_rate": 0.000452197583322268,
      "loss": 0.3742,
      "step": 41600
    },
    {
      "epoch": 1.6955699676743854,
      "grad_norm": 0.17114119231700897,
      "learning_rate": 0.0004519762758376488,
      "loss": 0.3722,
      "step": 41700
    },
    {
      "epoch": 1.6996360827047798,
      "grad_norm": 0.1793321669101715,
      "learning_rate": 0.0004517549683530297,
      "loss": 0.3713,
      "step": 41800
    },
    {
      "epoch": 1.7037021977351738,
      "grad_norm": 0.15894578397274017,
      "learning_rate": 0.00045153366086841056,
      "loss": 0.372,
      "step": 41900
    },
    {
      "epoch": 1.7077683127655683,
      "grad_norm": 0.16730698943138123,
      "learning_rate": 0.00045131235338379146,
      "loss": 0.3706,
      "step": 42000
    },
    {
      "epoch": 1.7077683127655683,
      "eval_loss": 0.3806500732898712,
      "eval_runtime": 129.6057,
      "eval_samples_per_second": 1349.493,
      "eval_steps_per_second": 42.174,
      "step": 42000
    },
    {
      "epoch": 1.7118344277959623,
      "grad_norm": 0.187590554356575,
      "learning_rate": 0.0004510910458991723,
      "loss": 0.3693,
      "step": 42100
    },
    {
      "epoch": 1.7159005428263565,
      "grad_norm": 0.17877553403377533,
      "learning_rate": 0.0004508697384145532,
      "loss": 0.3706,
      "step": 42200
    },
    {
      "epoch": 1.7199666578567507,
      "grad_norm": 0.19808514416217804,
      "learning_rate": 0.0004506484309299341,
      "loss": 0.3736,
      "step": 42300
    },
    {
      "epoch": 1.724032772887145,
      "grad_norm": 0.1677982211112976,
      "learning_rate": 0.00045042712344531494,
      "loss": 0.3687,
      "step": 42400
    },
    {
      "epoch": 1.7280988879175392,
      "grad_norm": 0.17974883317947388,
      "learning_rate": 0.00045020581596069584,
      "loss": 0.3721,
      "step": 42500
    },
    {
      "epoch": 1.7321650029479334,
      "grad_norm": 0.15914307534694672,
      "learning_rate": 0.0004499845084760767,
      "loss": 0.3736,
      "step": 42600
    },
    {
      "epoch": 1.7362311179783276,
      "grad_norm": 0.1673821657896042,
      "learning_rate": 0.0004497632009914576,
      "loss": 0.3702,
      "step": 42700
    },
    {
      "epoch": 1.7402972330087219,
      "grad_norm": 0.17250794172286987,
      "learning_rate": 0.00044954189350683837,
      "loss": 0.3704,
      "step": 42800
    },
    {
      "epoch": 1.744363348039116,
      "grad_norm": 0.18270225822925568,
      "learning_rate": 0.00044932058602221926,
      "loss": 0.3731,
      "step": 42900
    },
    {
      "epoch": 1.74842946306951,
      "grad_norm": 0.18066208064556122,
      "learning_rate": 0.0004490992785376001,
      "loss": 0.3722,
      "step": 43000
    },
    {
      "epoch": 1.7524955780999045,
      "grad_norm": 0.16855360567569733,
      "learning_rate": 0.000448877971052981,
      "loss": 0.3703,
      "step": 43100
    },
    {
      "epoch": 1.7565616931302985,
      "grad_norm": 0.20579324662685394,
      "learning_rate": 0.0004486566635683619,
      "loss": 0.3699,
      "step": 43200
    },
    {
      "epoch": 1.760627808160693,
      "grad_norm": 0.15569791197776794,
      "learning_rate": 0.00044843535608374274,
      "loss": 0.3709,
      "step": 43300
    },
    {
      "epoch": 1.764693923191087,
      "grad_norm": 0.1725226193666458,
      "learning_rate": 0.00044821404859912364,
      "loss": 0.369,
      "step": 43400
    },
    {
      "epoch": 1.7687600382214814,
      "grad_norm": 0.19191758334636688,
      "learning_rate": 0.0004479927411145045,
      "loss": 0.3701,
      "step": 43500
    },
    {
      "epoch": 1.7728261532518754,
      "grad_norm": 0.18442369997501373,
      "learning_rate": 0.0004477714336298854,
      "loss": 0.3741,
      "step": 43600
    },
    {
      "epoch": 1.7768922682822699,
      "grad_norm": 0.17605745792388916,
      "learning_rate": 0.0004475501261452662,
      "loss": 0.3719,
      "step": 43700
    },
    {
      "epoch": 1.7809583833126639,
      "grad_norm": 0.1713484227657318,
      "learning_rate": 0.0004473288186606471,
      "loss": 0.371,
      "step": 43800
    },
    {
      "epoch": 1.785024498343058,
      "grad_norm": 0.18618595600128174,
      "learning_rate": 0.00044710751117602797,
      "loss": 0.3709,
      "step": 43900
    },
    {
      "epoch": 1.7890906133734523,
      "grad_norm": 0.17851607501506805,
      "learning_rate": 0.00044688620369140886,
      "loss": 0.3714,
      "step": 44000
    },
    {
      "epoch": 1.7890906133734523,
      "eval_loss": 0.3798410892486572,
      "eval_runtime": 128.4031,
      "eval_samples_per_second": 1362.132,
      "eval_steps_per_second": 42.569,
      "step": 44000
    },
    {
      "epoch": 1.7931567284038465,
      "grad_norm": 0.1728041172027588,
      "learning_rate": 0.00044666489620678976,
      "loss": 0.372,
      "step": 44100
    },
    {
      "epoch": 1.7972228434342408,
      "grad_norm": 0.16304603219032288,
      "learning_rate": 0.0004464435887221706,
      "loss": 0.3714,
      "step": 44200
    },
    {
      "epoch": 1.801288958464635,
      "grad_norm": 0.16252413392066956,
      "learning_rate": 0.0004462222812375515,
      "loss": 0.3697,
      "step": 44300
    },
    {
      "epoch": 1.8053550734950292,
      "grad_norm": 0.18680651485919952,
      "learning_rate": 0.00044600097375293234,
      "loss": 0.3705,
      "step": 44400
    },
    {
      "epoch": 1.8094211885254232,
      "grad_norm": 0.21628107130527496,
      "learning_rate": 0.0004457796662683132,
      "loss": 0.3703,
      "step": 44500
    },
    {
      "epoch": 1.8134873035558177,
      "grad_norm": 0.17230774462223053,
      "learning_rate": 0.00044555835878369403,
      "loss": 0.3698,
      "step": 44600
    },
    {
      "epoch": 1.8175534185862117,
      "grad_norm": 0.19011859595775604,
      "learning_rate": 0.00044533705129907493,
      "loss": 0.3701,
      "step": 44700
    },
    {
      "epoch": 1.8216195336166061,
      "grad_norm": 0.18483559787273407,
      "learning_rate": 0.00044511574381445577,
      "loss": 0.3717,
      "step": 44800
    },
    {
      "epoch": 1.8256856486470001,
      "grad_norm": 0.21243777871131897,
      "learning_rate": 0.00044489443632983667,
      "loss": 0.3688,
      "step": 44900
    },
    {
      "epoch": 1.8297517636773946,
      "grad_norm": 0.16321536898612976,
      "learning_rate": 0.00044467312884521757,
      "loss": 0.3707,
      "step": 45000
    },
    {
      "epoch": 1.8338178787077886,
      "grad_norm": 0.16954940557479858,
      "learning_rate": 0.0004444518213605984,
      "loss": 0.3694,
      "step": 45100
    },
    {
      "epoch": 1.837883993738183,
      "grad_norm": 0.18987853825092316,
      "learning_rate": 0.0004442305138759793,
      "loss": 0.3711,
      "step": 45200
    },
    {
      "epoch": 1.841950108768577,
      "grad_norm": 0.20003677904605865,
      "learning_rate": 0.00044400920639136015,
      "loss": 0.3695,
      "step": 45300
    },
    {
      "epoch": 1.8460162237989712,
      "grad_norm": 0.19513675570487976,
      "learning_rate": 0.00044378789890674105,
      "loss": 0.3675,
      "step": 45400
    },
    {
      "epoch": 1.8500823388293655,
      "grad_norm": 0.17915086448192596,
      "learning_rate": 0.0004435665914221219,
      "loss": 0.3717,
      "step": 45500
    },
    {
      "epoch": 1.8541484538597597,
      "grad_norm": 0.1531165987253189,
      "learning_rate": 0.0004433452839375028,
      "loss": 0.3689,
      "step": 45600
    },
    {
      "epoch": 1.858214568890154,
      "grad_norm": 0.15685543417930603,
      "learning_rate": 0.0004431239764528837,
      "loss": 0.3714,
      "step": 45700
    },
    {
      "epoch": 1.8622806839205481,
      "grad_norm": 0.17248082160949707,
      "learning_rate": 0.00044290266896826453,
      "loss": 0.3699,
      "step": 45800
    },
    {
      "epoch": 1.8663467989509424,
      "grad_norm": 0.2019512802362442,
      "learning_rate": 0.0004426813614836454,
      "loss": 0.3721,
      "step": 45900
    },
    {
      "epoch": 1.8704129139813366,
      "grad_norm": 0.18367090821266174,
      "learning_rate": 0.00044246005399902627,
      "loss": 0.3674,
      "step": 46000
    },
    {
      "epoch": 1.8704129139813366,
      "eval_loss": 0.3795565664768219,
      "eval_runtime": 129.0828,
      "eval_samples_per_second": 1354.959,
      "eval_steps_per_second": 42.345,
      "step": 46000
    },
    {
      "epoch": 1.8744790290117308,
      "grad_norm": 0.17009325325489044,
      "learning_rate": 0.00044223874651440717,
      "loss": 0.3715,
      "step": 46100
    },
    {
      "epoch": 1.8785451440421248,
      "grad_norm": 0.19183781743049622,
      "learning_rate": 0.00044201743902978795,
      "loss": 0.3692,
      "step": 46200
    },
    {
      "epoch": 1.8826112590725192,
      "grad_norm": 0.1916862577199936,
      "learning_rate": 0.00044179613154516885,
      "loss": 0.3713,
      "step": 46300
    },
    {
      "epoch": 1.8866773741029133,
      "grad_norm": 0.17810702323913574,
      "learning_rate": 0.0004415748240605497,
      "loss": 0.3697,
      "step": 46400
    },
    {
      "epoch": 1.8907434891333077,
      "grad_norm": 0.20800207555294037,
      "learning_rate": 0.0004413535165759306,
      "loss": 0.3686,
      "step": 46500
    },
    {
      "epoch": 1.8948096041637017,
      "grad_norm": 0.19182813167572021,
      "learning_rate": 0.0004411322090913115,
      "loss": 0.3695,
      "step": 46600
    },
    {
      "epoch": 1.8988757191940961,
      "grad_norm": 0.22718656063079834,
      "learning_rate": 0.00044091090160669233,
      "loss": 0.3708,
      "step": 46700
    },
    {
      "epoch": 1.9029418342244901,
      "grad_norm": 0.1972312182188034,
      "learning_rate": 0.00044068959412207323,
      "loss": 0.3701,
      "step": 46800
    },
    {
      "epoch": 1.9070079492548844,
      "grad_norm": 0.19165867567062378,
      "learning_rate": 0.00044046828663745407,
      "loss": 0.3699,
      "step": 46900
    },
    {
      "epoch": 1.9110740642852786,
      "grad_norm": 0.19688834249973297,
      "learning_rate": 0.00044024697915283497,
      "loss": 0.372,
      "step": 47000
    },
    {
      "epoch": 1.9151401793156728,
      "grad_norm": 0.17334958910942078,
      "learning_rate": 0.0004400256716682158,
      "loss": 0.3715,
      "step": 47100
    },
    {
      "epoch": 1.919206294346067,
      "grad_norm": 0.18509791791439056,
      "learning_rate": 0.0004398043641835967,
      "loss": 0.3705,
      "step": 47200
    },
    {
      "epoch": 1.9232724093764613,
      "grad_norm": 0.21609754860401154,
      "learning_rate": 0.00043958305669897755,
      "loss": 0.3692,
      "step": 47300
    },
    {
      "epoch": 1.9273385244068555,
      "grad_norm": 0.1819249838590622,
      "learning_rate": 0.00043936174921435845,
      "loss": 0.3695,
      "step": 47400
    },
    {
      "epoch": 1.9314046394372497,
      "grad_norm": 0.18050983548164368,
      "learning_rate": 0.00043914044172973935,
      "loss": 0.3724,
      "step": 47500
    },
    {
      "epoch": 1.935470754467644,
      "grad_norm": 0.1820131242275238,
      "learning_rate": 0.0004389191342451202,
      "loss": 0.3677,
      "step": 47600
    },
    {
      "epoch": 1.939536869498038,
      "grad_norm": 0.18224631249904633,
      "learning_rate": 0.0004386978267605011,
      "loss": 0.3684,
      "step": 47700
    },
    {
      "epoch": 1.9436029845284324,
      "grad_norm": 0.1997593641281128,
      "learning_rate": 0.00043847651927588193,
      "loss": 0.37,
      "step": 47800
    },
    {
      "epoch": 1.9476690995588264,
      "grad_norm": 0.28570884466171265,
      "learning_rate": 0.0004382552117912628,
      "loss": 0.3717,
      "step": 47900
    },
    {
      "epoch": 1.9517352145892208,
      "grad_norm": 0.27941688895225525,
      "learning_rate": 0.0004380339043066436,
      "loss": 0.3687,
      "step": 48000
    },
    {
      "epoch": 1.9517352145892208,
      "eval_loss": 0.3772081434726715,
      "eval_runtime": 129.7478,
      "eval_samples_per_second": 1348.016,
      "eval_steps_per_second": 42.128,
      "step": 48000
    },
    {
      "epoch": 1.9558013296196148,
      "grad_norm": 0.17904658615589142,
      "learning_rate": 0.0004378125968220245,
      "loss": 0.3678,
      "step": 48100
    },
    {
      "epoch": 1.9598674446500093,
      "grad_norm": 0.169743612408638,
      "learning_rate": 0.00043759128933740536,
      "loss": 0.3707,
      "step": 48200
    },
    {
      "epoch": 1.9639335596804033,
      "grad_norm": 0.1789119839668274,
      "learning_rate": 0.00043736998185278626,
      "loss": 0.3686,
      "step": 48300
    },
    {
      "epoch": 1.9679996747107977,
      "grad_norm": 0.17665472626686096,
      "learning_rate": 0.00043714867436816715,
      "loss": 0.3678,
      "step": 48400
    },
    {
      "epoch": 1.9720657897411917,
      "grad_norm": 0.20917363464832306,
      "learning_rate": 0.000436927366883548,
      "loss": 0.3689,
      "step": 48500
    },
    {
      "epoch": 1.976131904771586,
      "grad_norm": 0.1817702203989029,
      "learning_rate": 0.0004367060593989289,
      "loss": 0.3707,
      "step": 48600
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 0.17579904198646545,
      "learning_rate": 0.00043648475191430974,
      "loss": 0.3693,
      "step": 48700
    },
    {
      "epoch": 1.9842641348323744,
      "grad_norm": 0.19732536375522614,
      "learning_rate": 0.00043626344442969063,
      "loss": 0.3706,
      "step": 48800
    },
    {
      "epoch": 1.9883302498627686,
      "grad_norm": 0.19947873055934906,
      "learning_rate": 0.0004360421369450715,
      "loss": 0.366,
      "step": 48900
    },
    {
      "epoch": 1.9923963648931629,
      "grad_norm": 0.18596002459526062,
      "learning_rate": 0.0004358208294604524,
      "loss": 0.37,
      "step": 49000
    },
    {
      "epoch": 1.996462479923557,
      "grad_norm": 0.20962823927402496,
      "learning_rate": 0.00043559952197583327,
      "loss": 0.367,
      "step": 49100
    },
    {
      "epoch": 2.000528594953951,
      "grad_norm": 0.189094677567482,
      "learning_rate": 0.0004353782144912141,
      "loss": 0.3664,
      "step": 49200
    },
    {
      "epoch": 2.0045947099843455,
      "grad_norm": 0.17373640835285187,
      "learning_rate": 0.000435156907006595,
      "loss": 0.365,
      "step": 49300
    },
    {
      "epoch": 2.0086608250147395,
      "grad_norm": 0.19203446805477142,
      "learning_rate": 0.00043493559952197586,
      "loss": 0.3637,
      "step": 49400
    },
    {
      "epoch": 2.012726940045134,
      "grad_norm": 0.20528644323349,
      "learning_rate": 0.00043471429203735675,
      "loss": 0.3644,
      "step": 49500
    },
    {
      "epoch": 2.016793055075528,
      "grad_norm": 0.17322729527950287,
      "learning_rate": 0.00043449298455273754,
      "loss": 0.3621,
      "step": 49600
    },
    {
      "epoch": 2.0208591701059224,
      "grad_norm": 0.20070777833461761,
      "learning_rate": 0.00043427167706811844,
      "loss": 0.3651,
      "step": 49700
    },
    {
      "epoch": 2.0249252851363164,
      "grad_norm": 0.18885298073291779,
      "learning_rate": 0.0004340503695834993,
      "loss": 0.3633,
      "step": 49800
    },
    {
      "epoch": 2.028991400166711,
      "grad_norm": 0.19066765904426575,
      "learning_rate": 0.0004338290620988802,
      "loss": 0.3642,
      "step": 49900
    },
    {
      "epoch": 2.033057515197105,
      "grad_norm": 0.19110217690467834,
      "learning_rate": 0.0004336077546142611,
      "loss": 0.3658,
      "step": 50000
    },
    {
      "epoch": 2.033057515197105,
      "eval_loss": 0.37649548053741455,
      "eval_runtime": 130.9513,
      "eval_samples_per_second": 1335.626,
      "eval_steps_per_second": 41.741,
      "step": 50000
    },
    {
      "epoch": 2.0371236302274993,
      "grad_norm": 0.20817412436008453,
      "learning_rate": 0.0004333864471296419,
      "loss": 0.367,
      "step": 50100
    },
    {
      "epoch": 2.0411897452578933,
      "grad_norm": 0.19224418699741364,
      "learning_rate": 0.0004331651396450228,
      "loss": 0.3638,
      "step": 50200
    },
    {
      "epoch": 2.0452558602882878,
      "grad_norm": 0.1791851669549942,
      "learning_rate": 0.00043294383216040366,
      "loss": 0.3642,
      "step": 50300
    },
    {
      "epoch": 2.0493219753186818,
      "grad_norm": 0.207665354013443,
      "learning_rate": 0.00043272252467578456,
      "loss": 0.3631,
      "step": 50400
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.21432113647460938,
      "learning_rate": 0.0004325012171911654,
      "loss": 0.367,
      "step": 50500
    },
    {
      "epoch": 2.05745420537947,
      "grad_norm": 0.17636115849018097,
      "learning_rate": 0.0004322799097065463,
      "loss": 0.3648,
      "step": 50600
    },
    {
      "epoch": 2.061520320409864,
      "grad_norm": 0.194972425699234,
      "learning_rate": 0.00043205860222192714,
      "loss": 0.3639,
      "step": 50700
    },
    {
      "epoch": 2.0655864354402587,
      "grad_norm": 0.17414695024490356,
      "learning_rate": 0.00043183729473730804,
      "loss": 0.3631,
      "step": 50800
    },
    {
      "epoch": 2.0696525504706527,
      "grad_norm": 0.2066553235054016,
      "learning_rate": 0.00043161598725268894,
      "loss": 0.3662,
      "step": 50900
    },
    {
      "epoch": 2.073718665501047,
      "grad_norm": 0.2173992544412613,
      "learning_rate": 0.0004313946797680698,
      "loss": 0.3642,
      "step": 51000
    },
    {
      "epoch": 2.077784780531441,
      "grad_norm": 0.19350279867649078,
      "learning_rate": 0.0004311733722834507,
      "loss": 0.3648,
      "step": 51100
    },
    {
      "epoch": 2.0818508955618356,
      "grad_norm": 0.1872224509716034,
      "learning_rate": 0.00043095206479883147,
      "loss": 0.3643,
      "step": 51200
    },
    {
      "epoch": 2.0859170105922296,
      "grad_norm": 0.21243639290332794,
      "learning_rate": 0.00043073075731421236,
      "loss": 0.3645,
      "step": 51300
    },
    {
      "epoch": 2.089983125622624,
      "grad_norm": 0.19274546205997467,
      "learning_rate": 0.0004305094498295932,
      "loss": 0.3652,
      "step": 51400
    },
    {
      "epoch": 2.094049240653018,
      "grad_norm": 0.20218423008918762,
      "learning_rate": 0.0004302881423449741,
      "loss": 0.366,
      "step": 51500
    },
    {
      "epoch": 2.0981153556834125,
      "grad_norm": 0.17855386435985565,
      "learning_rate": 0.00043006683486035495,
      "loss": 0.3654,
      "step": 51600
    },
    {
      "epoch": 2.1021814707138065,
      "grad_norm": 0.20506185293197632,
      "learning_rate": 0.00042984552737573584,
      "loss": 0.3658,
      "step": 51700
    },
    {
      "epoch": 2.106247585744201,
      "grad_norm": 0.16409450769424438,
      "learning_rate": 0.00042962421989111674,
      "loss": 0.3624,
      "step": 51800
    },
    {
      "epoch": 2.110313700774595,
      "grad_norm": 0.20925012230873108,
      "learning_rate": 0.0004294029124064976,
      "loss": 0.3659,
      "step": 51900
    },
    {
      "epoch": 2.1143798158049893,
      "grad_norm": 0.20650775730609894,
      "learning_rate": 0.0004291816049218785,
      "loss": 0.3647,
      "step": 52000
    },
    {
      "epoch": 2.1143798158049893,
      "eval_loss": 0.3766775131225586,
      "eval_runtime": 130.2893,
      "eval_samples_per_second": 1342.412,
      "eval_steps_per_second": 41.953,
      "step": 52000
    },
    {
      "epoch": 2.1184459308353834,
      "grad_norm": 0.20496468245983124,
      "learning_rate": 0.0004289602974372593,
      "loss": 0.3647,
      "step": 52100
    },
    {
      "epoch": 2.1225120458657774,
      "grad_norm": 0.2153676301240921,
      "learning_rate": 0.0004287389899526402,
      "loss": 0.367,
      "step": 52200
    },
    {
      "epoch": 2.126578160896172,
      "grad_norm": 0.18730106949806213,
      "learning_rate": 0.00042851768246802106,
      "loss": 0.3663,
      "step": 52300
    },
    {
      "epoch": 2.130644275926566,
      "grad_norm": 0.20351557433605194,
      "learning_rate": 0.00042829637498340196,
      "loss": 0.3653,
      "step": 52400
    },
    {
      "epoch": 2.1347103909569602,
      "grad_norm": 0.2022266536951065,
      "learning_rate": 0.00042807506749878286,
      "loss": 0.3641,
      "step": 52500
    },
    {
      "epoch": 2.1387765059873542,
      "grad_norm": 0.2081456482410431,
      "learning_rate": 0.0004278537600141637,
      "loss": 0.3665,
      "step": 52600
    },
    {
      "epoch": 2.1428426210177487,
      "grad_norm": 0.1891893595457077,
      "learning_rate": 0.0004276324525295446,
      "loss": 0.3653,
      "step": 52700
    },
    {
      "epoch": 2.1469087360481427,
      "grad_norm": 0.20701701939105988,
      "learning_rate": 0.00042741114504492544,
      "loss": 0.3627,
      "step": 52800
    },
    {
      "epoch": 2.150974851078537,
      "grad_norm": 0.2125532627105713,
      "learning_rate": 0.0004271898375603063,
      "loss": 0.3657,
      "step": 52900
    },
    {
      "epoch": 2.155040966108931,
      "grad_norm": 0.1900097131729126,
      "learning_rate": 0.00042696853007568713,
      "loss": 0.3656,
      "step": 53000
    },
    {
      "epoch": 2.1591070811393256,
      "grad_norm": 0.21399131417274475,
      "learning_rate": 0.000426747222591068,
      "loss": 0.3634,
      "step": 53100
    },
    {
      "epoch": 2.1631731961697196,
      "grad_norm": 0.18365667760372162,
      "learning_rate": 0.00042652591510644887,
      "loss": 0.362,
      "step": 53200
    },
    {
      "epoch": 2.167239311200114,
      "grad_norm": 0.20475313067436218,
      "learning_rate": 0.00042630460762182977,
      "loss": 0.3655,
      "step": 53300
    },
    {
      "epoch": 2.171305426230508,
      "grad_norm": 0.1792307049036026,
      "learning_rate": 0.00042608330013721066,
      "loss": 0.3656,
      "step": 53400
    },
    {
      "epoch": 2.175371541260902,
      "grad_norm": 0.1767684817314148,
      "learning_rate": 0.0004258619926525915,
      "loss": 0.3632,
      "step": 53500
    },
    {
      "epoch": 2.1794376562912965,
      "grad_norm": 0.21808399260044098,
      "learning_rate": 0.0004256406851679724,
      "loss": 0.3637,
      "step": 53600
    },
    {
      "epoch": 2.1835037713216905,
      "grad_norm": 0.20763559639453888,
      "learning_rate": 0.00042541937768335325,
      "loss": 0.3624,
      "step": 53700
    },
    {
      "epoch": 2.187569886352085,
      "grad_norm": 0.17011792957782745,
      "learning_rate": 0.00042519807019873415,
      "loss": 0.3644,
      "step": 53800
    },
    {
      "epoch": 2.191636001382479,
      "grad_norm": 0.21704380214214325,
      "learning_rate": 0.000424976762714115,
      "loss": 0.3664,
      "step": 53900
    },
    {
      "epoch": 2.1957021164128734,
      "grad_norm": 0.20549103617668152,
      "learning_rate": 0.0004247554552294959,
      "loss": 0.366,
      "step": 54000
    },
    {
      "epoch": 2.1957021164128734,
      "eval_loss": 0.3752453625202179,
      "eval_runtime": 129.2628,
      "eval_samples_per_second": 1353.073,
      "eval_steps_per_second": 42.286,
      "step": 54000
    },
    {
      "epoch": 2.1997682314432674,
      "grad_norm": 0.1828790158033371,
      "learning_rate": 0.00042453414774487673,
      "loss": 0.3639,
      "step": 54100
    },
    {
      "epoch": 2.203834346473662,
      "grad_norm": 0.17839565873146057,
      "learning_rate": 0.0004243128402602576,
      "loss": 0.3641,
      "step": 54200
    },
    {
      "epoch": 2.207900461504056,
      "grad_norm": 0.1980467289686203,
      "learning_rate": 0.0004240915327756385,
      "loss": 0.3652,
      "step": 54300
    },
    {
      "epoch": 2.2119665765344503,
      "grad_norm": 0.19203370809555054,
      "learning_rate": 0.00042387022529101937,
      "loss": 0.3633,
      "step": 54400
    },
    {
      "epoch": 2.2160326915648443,
      "grad_norm": 0.18270283937454224,
      "learning_rate": 0.00042364891780640026,
      "loss": 0.3649,
      "step": 54500
    },
    {
      "epoch": 2.2200988065952387,
      "grad_norm": 0.19764885306358337,
      "learning_rate": 0.00042342761032178105,
      "loss": 0.365,
      "step": 54600
    },
    {
      "epoch": 2.2241649216256327,
      "grad_norm": 0.2111460566520691,
      "learning_rate": 0.00042320630283716195,
      "loss": 0.3663,
      "step": 54700
    },
    {
      "epoch": 2.228231036656027,
      "grad_norm": 0.20072978734970093,
      "learning_rate": 0.0004229849953525428,
      "loss": 0.364,
      "step": 54800
    },
    {
      "epoch": 2.232297151686421,
      "grad_norm": 0.17569728195667267,
      "learning_rate": 0.0004227636878679237,
      "loss": 0.3667,
      "step": 54900
    },
    {
      "epoch": 2.2363632667168156,
      "grad_norm": 0.20418447256088257,
      "learning_rate": 0.00042254238038330453,
      "loss": 0.3655,
      "step": 55000
    },
    {
      "epoch": 2.2404293817472096,
      "grad_norm": 0.19725604355335236,
      "learning_rate": 0.00042232107289868543,
      "loss": 0.3631,
      "step": 55100
    },
    {
      "epoch": 2.2444954967776036,
      "grad_norm": 0.1949615180492401,
      "learning_rate": 0.00042209976541406633,
      "loss": 0.3631,
      "step": 55200
    },
    {
      "epoch": 2.248561611807998,
      "grad_norm": 0.18892063200473785,
      "learning_rate": 0.00042187845792944717,
      "loss": 0.3624,
      "step": 55300
    },
    {
      "epoch": 2.252627726838392,
      "grad_norm": 0.2876112759113312,
      "learning_rate": 0.00042165715044482807,
      "loss": 0.3645,
      "step": 55400
    },
    {
      "epoch": 2.2566938418687865,
      "grad_norm": 0.24870429933071136,
      "learning_rate": 0.0004214358429602089,
      "loss": 0.3653,
      "step": 55500
    },
    {
      "epoch": 2.2607599568991805,
      "grad_norm": 0.19862322509288788,
      "learning_rate": 0.0004212145354755898,
      "loss": 0.3636,
      "step": 55600
    },
    {
      "epoch": 2.264826071929575,
      "grad_norm": 0.21138447523117065,
      "learning_rate": 0.00042099322799097065,
      "loss": 0.3643,
      "step": 55700
    },
    {
      "epoch": 2.268892186959969,
      "grad_norm": 0.18127252161502838,
      "learning_rate": 0.00042077192050635155,
      "loss": 0.3653,
      "step": 55800
    },
    {
      "epoch": 2.2729583019903634,
      "grad_norm": 0.2037583738565445,
      "learning_rate": 0.00042055061302173245,
      "loss": 0.3649,
      "step": 55900
    },
    {
      "epoch": 2.2770244170207574,
      "grad_norm": 0.19472169876098633,
      "learning_rate": 0.0004203293055371133,
      "loss": 0.3653,
      "step": 56000
    },
    {
      "epoch": 2.2770244170207574,
      "eval_loss": 0.37491002678871155,
      "eval_runtime": 129.4229,
      "eval_samples_per_second": 1351.399,
      "eval_steps_per_second": 42.234,
      "step": 56000
    },
    {
      "epoch": 2.281090532051152,
      "grad_norm": 0.1875505894422531,
      "learning_rate": 0.0004201079980524942,
      "loss": 0.3657,
      "step": 56100
    },
    {
      "epoch": 2.285156647081546,
      "grad_norm": 0.21371746063232422,
      "learning_rate": 0.00041988669056787503,
      "loss": 0.3639,
      "step": 56200
    },
    {
      "epoch": 2.2892227621119403,
      "grad_norm": 0.196388840675354,
      "learning_rate": 0.0004196653830832559,
      "loss": 0.3629,
      "step": 56300
    },
    {
      "epoch": 2.2932888771423343,
      "grad_norm": 0.22341866791248322,
      "learning_rate": 0.0004194440755986367,
      "loss": 0.3636,
      "step": 56400
    },
    {
      "epoch": 2.2973549921727288,
      "grad_norm": 0.22135716676712036,
      "learning_rate": 0.0004192227681140176,
      "loss": 0.3656,
      "step": 56500
    },
    {
      "epoch": 2.3014211072031228,
      "grad_norm": 0.20962665975093842,
      "learning_rate": 0.00041900146062939846,
      "loss": 0.3661,
      "step": 56600
    },
    {
      "epoch": 2.305487222233517,
      "grad_norm": 0.22430667281150818,
      "learning_rate": 0.00041878015314477935,
      "loss": 0.3645,
      "step": 56700
    },
    {
      "epoch": 2.309553337263911,
      "grad_norm": 0.21407021582126617,
      "learning_rate": 0.00041855884566016025,
      "loss": 0.3634,
      "step": 56800
    },
    {
      "epoch": 2.313619452294305,
      "grad_norm": 0.19966267049312592,
      "learning_rate": 0.0004183375381755411,
      "loss": 0.3642,
      "step": 56900
    },
    {
      "epoch": 2.3176855673246997,
      "grad_norm": 0.20801497995853424,
      "learning_rate": 0.000418116230690922,
      "loss": 0.3662,
      "step": 57000
    },
    {
      "epoch": 2.3217516823550937,
      "grad_norm": 0.20708636939525604,
      "learning_rate": 0.00041789492320630284,
      "loss": 0.3644,
      "step": 57100
    },
    {
      "epoch": 2.325817797385488,
      "grad_norm": 0.23131242394447327,
      "learning_rate": 0.00041767361572168373,
      "loss": 0.3656,
      "step": 57200
    },
    {
      "epoch": 2.329883912415882,
      "grad_norm": 0.2175079733133316,
      "learning_rate": 0.0004174523082370646,
      "loss": 0.3672,
      "step": 57300
    },
    {
      "epoch": 2.3339500274462766,
      "grad_norm": 0.18470759689807892,
      "learning_rate": 0.0004172310007524455,
      "loss": 0.3614,
      "step": 57400
    },
    {
      "epoch": 2.3380161424766706,
      "grad_norm": 0.22119292616844177,
      "learning_rate": 0.0004170096932678263,
      "loss": 0.3654,
      "step": 57500
    },
    {
      "epoch": 2.342082257507065,
      "grad_norm": 0.22828786075115204,
      "learning_rate": 0.0004167883857832072,
      "loss": 0.3654,
      "step": 57600
    },
    {
      "epoch": 2.346148372537459,
      "grad_norm": 0.24143418669700623,
      "learning_rate": 0.0004165670782985881,
      "loss": 0.3641,
      "step": 57700
    },
    {
      "epoch": 2.3502144875678534,
      "grad_norm": 0.18504071235656738,
      "learning_rate": 0.00041634577081396895,
      "loss": 0.3645,
      "step": 57800
    },
    {
      "epoch": 2.3542806025982475,
      "grad_norm": 0.20140092074871063,
      "learning_rate": 0.00041612446332934985,
      "loss": 0.3613,
      "step": 57900
    },
    {
      "epoch": 2.358346717628642,
      "grad_norm": 0.22063800692558289,
      "learning_rate": 0.00041590315584473064,
      "loss": 0.3626,
      "step": 58000
    },
    {
      "epoch": 2.358346717628642,
      "eval_loss": 0.3734843134880066,
      "eval_runtime": 129.7384,
      "eval_samples_per_second": 1348.113,
      "eval_steps_per_second": 42.131,
      "step": 58000
    },
    {
      "epoch": 2.362412832659036,
      "grad_norm": 0.20010226964950562,
      "learning_rate": 0.00041568184836011154,
      "loss": 0.3661,
      "step": 58100
    },
    {
      "epoch": 2.36647894768943,
      "grad_norm": 0.2362033724784851,
      "learning_rate": 0.0004154605408754924,
      "loss": 0.3622,
      "step": 58200
    },
    {
      "epoch": 2.3705450627198243,
      "grad_norm": 0.199960857629776,
      "learning_rate": 0.0004152392333908733,
      "loss": 0.3654,
      "step": 58300
    },
    {
      "epoch": 2.374611177750219,
      "grad_norm": 0.18409065902233124,
      "learning_rate": 0.0004150179259062541,
      "loss": 0.3623,
      "step": 58400
    },
    {
      "epoch": 2.378677292780613,
      "grad_norm": 0.20696313679218292,
      "learning_rate": 0.000414796618421635,
      "loss": 0.3675,
      "step": 58500
    },
    {
      "epoch": 2.382743407811007,
      "grad_norm": 0.22253373265266418,
      "learning_rate": 0.0004145753109370159,
      "loss": 0.3648,
      "step": 58600
    },
    {
      "epoch": 2.3868095228414012,
      "grad_norm": 0.23713579773902893,
      "learning_rate": 0.00041435400345239676,
      "loss": 0.3608,
      "step": 58700
    },
    {
      "epoch": 2.3908756378717952,
      "grad_norm": 0.23142708837985992,
      "learning_rate": 0.00041413269596777766,
      "loss": 0.3675,
      "step": 58800
    },
    {
      "epoch": 2.3949417529021897,
      "grad_norm": 0.2163032442331314,
      "learning_rate": 0.0004139113884831585,
      "loss": 0.3642,
      "step": 58900
    },
    {
      "epoch": 2.3990078679325837,
      "grad_norm": 0.18269965052604675,
      "learning_rate": 0.0004136900809985394,
      "loss": 0.3636,
      "step": 59000
    },
    {
      "epoch": 2.403073982962978,
      "grad_norm": 0.1976199746131897,
      "learning_rate": 0.00041346877351392024,
      "loss": 0.363,
      "step": 59100
    },
    {
      "epoch": 2.407140097993372,
      "grad_norm": 0.2108323723077774,
      "learning_rate": 0.00041324746602930114,
      "loss": 0.365,
      "step": 59200
    },
    {
      "epoch": 2.4112062130237666,
      "grad_norm": 0.20765170454978943,
      "learning_rate": 0.000413026158544682,
      "loss": 0.3636,
      "step": 59300
    },
    {
      "epoch": 2.4152723280541606,
      "grad_norm": 0.21028807759284973,
      "learning_rate": 0.0004128048510600629,
      "loss": 0.3638,
      "step": 59400
    },
    {
      "epoch": 2.419338443084555,
      "grad_norm": 0.21375884115695953,
      "learning_rate": 0.0004125835435754438,
      "loss": 0.3638,
      "step": 59500
    },
    {
      "epoch": 2.423404558114949,
      "grad_norm": 0.22148601710796356,
      "learning_rate": 0.0004123622360908246,
      "loss": 0.3643,
      "step": 59600
    },
    {
      "epoch": 2.4274706731453435,
      "grad_norm": 0.23686687648296356,
      "learning_rate": 0.00041214092860620546,
      "loss": 0.3637,
      "step": 59700
    },
    {
      "epoch": 2.4315367881757375,
      "grad_norm": 0.2030973583459854,
      "learning_rate": 0.0004119196211215863,
      "loss": 0.3629,
      "step": 59800
    },
    {
      "epoch": 2.4356029032061315,
      "grad_norm": 0.19675388932228088,
      "learning_rate": 0.0004116983136369672,
      "loss": 0.3625,
      "step": 59900
    },
    {
      "epoch": 2.439669018236526,
      "grad_norm": 0.22773848474025726,
      "learning_rate": 0.00041147700615234804,
      "loss": 0.3637,
      "step": 60000
    },
    {
      "epoch": 2.439669018236526,
      "eval_loss": 0.373001366853714,
      "eval_runtime": 129.9469,
      "eval_samples_per_second": 1345.95,
      "eval_steps_per_second": 42.063,
      "step": 60000
    },
    {
      "epoch": 2.44373513326692,
      "grad_norm": 0.23279015719890594,
      "learning_rate": 0.00041125569866772894,
      "loss": 0.3619,
      "step": 60100
    },
    {
      "epoch": 2.4478012482973144,
      "grad_norm": 0.21551382541656494,
      "learning_rate": 0.00041103439118310984,
      "loss": 0.3658,
      "step": 60200
    },
    {
      "epoch": 2.4518673633277084,
      "grad_norm": 0.19858895242214203,
      "learning_rate": 0.0004108130836984907,
      "loss": 0.3623,
      "step": 60300
    },
    {
      "epoch": 2.455933478358103,
      "grad_norm": 0.23652324080467224,
      "learning_rate": 0.0004105917762138716,
      "loss": 0.3629,
      "step": 60400
    },
    {
      "epoch": 2.459999593388497,
      "grad_norm": 0.25926196575164795,
      "learning_rate": 0.0004103704687292524,
      "loss": 0.3629,
      "step": 60500
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 0.2175762802362442,
      "learning_rate": 0.0004101491612446333,
      "loss": 0.364,
      "step": 60600
    },
    {
      "epoch": 2.4681318234492853,
      "grad_norm": 0.21339482069015503,
      "learning_rate": 0.00040992785376001416,
      "loss": 0.3626,
      "step": 60700
    },
    {
      "epoch": 2.4721979384796797,
      "grad_norm": 0.22928646206855774,
      "learning_rate": 0.00040970654627539506,
      "loss": 0.3629,
      "step": 60800
    },
    {
      "epoch": 2.4762640535100737,
      "grad_norm": 0.24651557207107544,
      "learning_rate": 0.0004094852387907759,
      "loss": 0.3627,
      "step": 60900
    },
    {
      "epoch": 2.480330168540468,
      "grad_norm": 0.29420679807662964,
      "learning_rate": 0.0004092639313061568,
      "loss": 0.3621,
      "step": 61000
    },
    {
      "epoch": 2.484396283570862,
      "grad_norm": 0.24496838450431824,
      "learning_rate": 0.0004090426238215377,
      "loss": 0.365,
      "step": 61100
    },
    {
      "epoch": 2.4884623986012566,
      "grad_norm": 0.2287568897008896,
      "learning_rate": 0.00040882131633691854,
      "loss": 0.3634,
      "step": 61200
    },
    {
      "epoch": 2.4925285136316506,
      "grad_norm": 0.2232978641986847,
      "learning_rate": 0.00040860000885229944,
      "loss": 0.364,
      "step": 61300
    },
    {
      "epoch": 2.496594628662045,
      "grad_norm": 0.1900332272052765,
      "learning_rate": 0.00040837870136768023,
      "loss": 0.3634,
      "step": 61400
    },
    {
      "epoch": 2.500660743692439,
      "grad_norm": 0.2332664579153061,
      "learning_rate": 0.0004081573938830611,
      "loss": 0.3626,
      "step": 61500
    },
    {
      "epoch": 2.504726858722833,
      "grad_norm": 0.22076420485973358,
      "learning_rate": 0.00040793608639844197,
      "loss": 0.3638,
      "step": 61600
    },
    {
      "epoch": 2.5087929737532275,
      "grad_norm": 0.20820823311805725,
      "learning_rate": 0.00040771477891382287,
      "loss": 0.3622,
      "step": 61700
    },
    {
      "epoch": 2.512859088783622,
      "grad_norm": 0.1748781055212021,
      "learning_rate": 0.0004074934714292037,
      "loss": 0.3628,
      "step": 61800
    },
    {
      "epoch": 2.516925203814016,
      "grad_norm": 0.1988530158996582,
      "learning_rate": 0.0004072721639445846,
      "loss": 0.3625,
      "step": 61900
    },
    {
      "epoch": 2.52099131884441,
      "grad_norm": 0.2096220850944519,
      "learning_rate": 0.0004070508564599655,
      "loss": 0.3628,
      "step": 62000
    },
    {
      "epoch": 2.52099131884441,
      "eval_loss": 0.3730391263961792,
      "eval_runtime": 130.6835,
      "eval_samples_per_second": 1338.363,
      "eval_steps_per_second": 41.826,
      "step": 62000
    },
    {
      "epoch": 2.5250574338748044,
      "grad_norm": 0.1957101970911026,
      "learning_rate": 0.00040682954897534635,
      "loss": 0.3637,
      "step": 62100
    },
    {
      "epoch": 2.5291235489051984,
      "grad_norm": 0.20232628285884857,
      "learning_rate": 0.00040660824149072724,
      "loss": 0.3624,
      "step": 62200
    },
    {
      "epoch": 2.533189663935593,
      "grad_norm": 0.23020446300506592,
      "learning_rate": 0.0004063869340061081,
      "loss": 0.3639,
      "step": 62300
    },
    {
      "epoch": 2.537255778965987,
      "grad_norm": 0.2293911576271057,
      "learning_rate": 0.000406165626521489,
      "loss": 0.3654,
      "step": 62400
    },
    {
      "epoch": 2.5413218939963813,
      "grad_norm": 0.2013021558523178,
      "learning_rate": 0.00040594431903686983,
      "loss": 0.3629,
      "step": 62500
    },
    {
      "epoch": 2.5453880090267753,
      "grad_norm": 0.207792729139328,
      "learning_rate": 0.0004057230115522507,
      "loss": 0.363,
      "step": 62600
    },
    {
      "epoch": 2.5494541240571698,
      "grad_norm": 0.20351405441761017,
      "learning_rate": 0.00040550170406763157,
      "loss": 0.3632,
      "step": 62700
    },
    {
      "epoch": 2.5535202390875638,
      "grad_norm": 0.1905018538236618,
      "learning_rate": 0.00040528039658301246,
      "loss": 0.3631,
      "step": 62800
    },
    {
      "epoch": 2.5575863541179578,
      "grad_norm": 0.24596372246742249,
      "learning_rate": 0.00040505908909839336,
      "loss": 0.3639,
      "step": 62900
    },
    {
      "epoch": 2.561652469148352,
      "grad_norm": 0.2132834792137146,
      "learning_rate": 0.00040483778161377415,
      "loss": 0.3644,
      "step": 63000
    },
    {
      "epoch": 2.5657185841787467,
      "grad_norm": 0.2622873783111572,
      "learning_rate": 0.00040461647412915505,
      "loss": 0.3615,
      "step": 63100
    },
    {
      "epoch": 2.5697846992091407,
      "grad_norm": 0.22048716247081757,
      "learning_rate": 0.0004043951666445359,
      "loss": 0.3626,
      "step": 63200
    },
    {
      "epoch": 2.5738508142395347,
      "grad_norm": 0.22352422773838043,
      "learning_rate": 0.0004041738591599168,
      "loss": 0.362,
      "step": 63300
    },
    {
      "epoch": 2.577916929269929,
      "grad_norm": 0.2052323967218399,
      "learning_rate": 0.00040395255167529763,
      "loss": 0.3641,
      "step": 63400
    },
    {
      "epoch": 2.581983044300323,
      "grad_norm": 0.21766985952854156,
      "learning_rate": 0.00040373124419067853,
      "loss": 0.3622,
      "step": 63500
    },
    {
      "epoch": 2.5860491593307176,
      "grad_norm": 0.22121912240982056,
      "learning_rate": 0.00040350993670605937,
      "loss": 0.3629,
      "step": 63600
    },
    {
      "epoch": 2.5901152743611116,
      "grad_norm": 0.2173127979040146,
      "learning_rate": 0.00040328862922144027,
      "loss": 0.3615,
      "step": 63700
    },
    {
      "epoch": 2.594181389391506,
      "grad_norm": 0.24322056770324707,
      "learning_rate": 0.00040306732173682117,
      "loss": 0.3643,
      "step": 63800
    },
    {
      "epoch": 2.5982475044219,
      "grad_norm": 0.211806982755661,
      "learning_rate": 0.000402846014252202,
      "loss": 0.3649,
      "step": 63900
    },
    {
      "epoch": 2.6023136194522944,
      "grad_norm": 0.1834513396024704,
      "learning_rate": 0.0004026247067675829,
      "loss": 0.3616,
      "step": 64000
    },
    {
      "epoch": 2.6023136194522944,
      "eval_loss": 0.3725435435771942,
      "eval_runtime": 129.6217,
      "eval_samples_per_second": 1349.326,
      "eval_steps_per_second": 42.169,
      "step": 64000
    },
    {
      "epoch": 2.6063797344826884,
      "grad_norm": 0.21157506108283997,
      "learning_rate": 0.00040240339928296375,
      "loss": 0.3631,
      "step": 64100
    },
    {
      "epoch": 2.6104458495130825,
      "grad_norm": 0.21845600008964539,
      "learning_rate": 0.00040218209179834465,
      "loss": 0.3632,
      "step": 64200
    },
    {
      "epoch": 2.614511964543477,
      "grad_norm": 0.21404680609703064,
      "learning_rate": 0.0004019607843137255,
      "loss": 0.3628,
      "step": 64300
    },
    {
      "epoch": 2.6185780795738713,
      "grad_norm": 0.21361979842185974,
      "learning_rate": 0.0004017394768291064,
      "loss": 0.3628,
      "step": 64400
    },
    {
      "epoch": 2.6226441946042653,
      "grad_norm": 0.2268761843442917,
      "learning_rate": 0.0004015181693444873,
      "loss": 0.3637,
      "step": 64500
    },
    {
      "epoch": 2.6267103096346593,
      "grad_norm": 0.2448561042547226,
      "learning_rate": 0.00040129686185986813,
      "loss": 0.3636,
      "step": 64600
    },
    {
      "epoch": 2.630776424665054,
      "grad_norm": 0.21544668078422546,
      "learning_rate": 0.00040107555437524897,
      "loss": 0.3646,
      "step": 64700
    },
    {
      "epoch": 2.6348425396954482,
      "grad_norm": 0.2328132688999176,
      "learning_rate": 0.0004008542468906298,
      "loss": 0.3604,
      "step": 64800
    },
    {
      "epoch": 2.6389086547258422,
      "grad_norm": 0.21903665363788605,
      "learning_rate": 0.0004006329394060107,
      "loss": 0.3604,
      "step": 64900
    },
    {
      "epoch": 2.6429747697562362,
      "grad_norm": 0.22775177657604218,
      "learning_rate": 0.00040041163192139156,
      "loss": 0.3625,
      "step": 65000
    },
    {
      "epoch": 2.6470408847866307,
      "grad_norm": 0.22167830169200897,
      "learning_rate": 0.00040019032443677245,
      "loss": 0.3629,
      "step": 65100
    },
    {
      "epoch": 2.6511069998170247,
      "grad_norm": 0.27244147658348083,
      "learning_rate": 0.0003999690169521533,
      "loss": 0.3634,
      "step": 65200
    },
    {
      "epoch": 2.655173114847419,
      "grad_norm": 0.19813846051692963,
      "learning_rate": 0.0003997477094675342,
      "loss": 0.363,
      "step": 65300
    },
    {
      "epoch": 2.659239229877813,
      "grad_norm": 0.20629137754440308,
      "learning_rate": 0.0003995264019829151,
      "loss": 0.363,
      "step": 65400
    },
    {
      "epoch": 2.6633053449082076,
      "grad_norm": 0.1982228308916092,
      "learning_rate": 0.00039930509449829593,
      "loss": 0.3638,
      "step": 65500
    },
    {
      "epoch": 2.6673714599386016,
      "grad_norm": 0.2096640020608902,
      "learning_rate": 0.00039908378701367683,
      "loss": 0.3614,
      "step": 65600
    },
    {
      "epoch": 2.671437574968996,
      "grad_norm": 0.2273455262184143,
      "learning_rate": 0.0003988624795290577,
      "loss": 0.3615,
      "step": 65700
    },
    {
      "epoch": 2.67550368999939,
      "grad_norm": 0.23321960866451263,
      "learning_rate": 0.00039864117204443857,
      "loss": 0.3636,
      "step": 65800
    },
    {
      "epoch": 2.679569805029784,
      "grad_norm": 0.2419043928384781,
      "learning_rate": 0.0003984198645598194,
      "loss": 0.3606,
      "step": 65900
    },
    {
      "epoch": 2.6836359200601785,
      "grad_norm": 0.22093936800956726,
      "learning_rate": 0.0003981985570752003,
      "loss": 0.364,
      "step": 66000
    },
    {
      "epoch": 2.6836359200601785,
      "eval_loss": 0.37187105417251587,
      "eval_runtime": 129.2484,
      "eval_samples_per_second": 1353.224,
      "eval_steps_per_second": 42.291,
      "step": 66000
    },
    {
      "epoch": 2.687702035090573,
      "grad_norm": 0.2359757274389267,
      "learning_rate": 0.00039797724959058116,
      "loss": 0.3625,
      "step": 66100
    },
    {
      "epoch": 2.691768150120967,
      "grad_norm": 0.2619248330593109,
      "learning_rate": 0.00039775594210596205,
      "loss": 0.3633,
      "step": 66200
    },
    {
      "epoch": 2.695834265151361,
      "grad_norm": 0.1905684769153595,
      "learning_rate": 0.00039753463462134295,
      "loss": 0.3608,
      "step": 66300
    },
    {
      "epoch": 2.6999003801817554,
      "grad_norm": 0.22587677836418152,
      "learning_rate": 0.00039731332713672374,
      "loss": 0.3623,
      "step": 66400
    },
    {
      "epoch": 2.70396649521215,
      "grad_norm": 0.23976066708564758,
      "learning_rate": 0.00039709201965210464,
      "loss": 0.3634,
      "step": 66500
    },
    {
      "epoch": 2.708032610242544,
      "grad_norm": 0.21984629333019257,
      "learning_rate": 0.0003968707121674855,
      "loss": 0.3617,
      "step": 66600
    },
    {
      "epoch": 2.712098725272938,
      "grad_norm": 0.20084984600543976,
      "learning_rate": 0.0003966494046828664,
      "loss": 0.3621,
      "step": 66700
    },
    {
      "epoch": 2.7161648403033323,
      "grad_norm": 0.2181382030248642,
      "learning_rate": 0.0003964280971982472,
      "loss": 0.3621,
      "step": 66800
    },
    {
      "epoch": 2.7202309553337263,
      "grad_norm": 0.2425534427165985,
      "learning_rate": 0.0003962067897136281,
      "loss": 0.3626,
      "step": 66900
    },
    {
      "epoch": 2.7242970703641207,
      "grad_norm": 0.24024832248687744,
      "learning_rate": 0.00039598548222900896,
      "loss": 0.3621,
      "step": 67000
    },
    {
      "epoch": 2.7283631853945147,
      "grad_norm": 0.24228069186210632,
      "learning_rate": 0.00039576417474438986,
      "loss": 0.3604,
      "step": 67100
    },
    {
      "epoch": 2.732429300424909,
      "grad_norm": 0.20339007675647736,
      "learning_rate": 0.00039554286725977075,
      "loss": 0.3624,
      "step": 67200
    },
    {
      "epoch": 2.736495415455303,
      "grad_norm": 0.27938029170036316,
      "learning_rate": 0.0003953215597751516,
      "loss": 0.3625,
      "step": 67300
    },
    {
      "epoch": 2.7405615304856976,
      "grad_norm": 0.2710152566432953,
      "learning_rate": 0.0003951002522905325,
      "loss": 0.3623,
      "step": 67400
    },
    {
      "epoch": 2.7446276455160916,
      "grad_norm": 0.2834514081478119,
      "learning_rate": 0.00039487894480591334,
      "loss": 0.3644,
      "step": 67500
    },
    {
      "epoch": 2.7486937605464856,
      "grad_norm": 0.23644205927848816,
      "learning_rate": 0.00039465763732129424,
      "loss": 0.3639,
      "step": 67600
    },
    {
      "epoch": 2.75275987557688,
      "grad_norm": 0.2290220856666565,
      "learning_rate": 0.0003944363298366751,
      "loss": 0.362,
      "step": 67700
    },
    {
      "epoch": 2.7568259906072745,
      "grad_norm": 0.24085381627082825,
      "learning_rate": 0.000394215022352056,
      "loss": 0.3626,
      "step": 67800
    },
    {
      "epoch": 2.7608921056376685,
      "grad_norm": 0.2746323049068451,
      "learning_rate": 0.0003939937148674369,
      "loss": 0.3618,
      "step": 67900
    },
    {
      "epoch": 2.7649582206680625,
      "grad_norm": 0.2453032284975052,
      "learning_rate": 0.0003937724073828177,
      "loss": 0.3631,
      "step": 68000
    },
    {
      "epoch": 2.7649582206680625,
      "eval_loss": 0.37273821234703064,
      "eval_runtime": 129.2912,
      "eval_samples_per_second": 1352.776,
      "eval_steps_per_second": 42.277,
      "step": 68000
    },
    {
      "epoch": 2.769024335698457,
      "grad_norm": 0.2389104962348938,
      "learning_rate": 0.00039355109989819856,
      "loss": 0.3619,
      "step": 68100
    },
    {
      "epoch": 2.773090450728851,
      "grad_norm": 0.26346537470817566,
      "learning_rate": 0.0003933297924135794,
      "loss": 0.3623,
      "step": 68200
    },
    {
      "epoch": 2.7771565657592454,
      "grad_norm": 0.22975707054138184,
      "learning_rate": 0.0003931084849289603,
      "loss": 0.3586,
      "step": 68300
    },
    {
      "epoch": 2.7812226807896394,
      "grad_norm": 0.21371760964393616,
      "learning_rate": 0.00039288717744434114,
      "loss": 0.3603,
      "step": 68400
    },
    {
      "epoch": 2.785288795820034,
      "grad_norm": 0.26299047470092773,
      "learning_rate": 0.00039266586995972204,
      "loss": 0.3626,
      "step": 68500
    },
    {
      "epoch": 2.789354910850428,
      "grad_norm": 0.2888469398021698,
      "learning_rate": 0.0003924445624751029,
      "loss": 0.3637,
      "step": 68600
    },
    {
      "epoch": 2.7934210258808223,
      "grad_norm": 0.2524645924568176,
      "learning_rate": 0.0003922232549904838,
      "loss": 0.3624,
      "step": 68700
    },
    {
      "epoch": 2.7974871409112163,
      "grad_norm": 0.19789905846118927,
      "learning_rate": 0.0003920019475058647,
      "loss": 0.3623,
      "step": 68800
    },
    {
      "epoch": 2.8015532559416108,
      "grad_norm": 0.23030945658683777,
      "learning_rate": 0.0003917806400212455,
      "loss": 0.364,
      "step": 68900
    },
    {
      "epoch": 2.8056193709720048,
      "grad_norm": 0.24221445620059967,
      "learning_rate": 0.0003915593325366264,
      "loss": 0.3624,
      "step": 69000
    },
    {
      "epoch": 2.809685486002399,
      "grad_norm": 0.2028610110282898,
      "learning_rate": 0.00039133802505200726,
      "loss": 0.3614,
      "step": 69100
    },
    {
      "epoch": 2.813751601032793,
      "grad_norm": 0.27564048767089844,
      "learning_rate": 0.00039111671756738816,
      "loss": 0.3631,
      "step": 69200
    },
    {
      "epoch": 2.817817716063187,
      "grad_norm": 0.2558842599391937,
      "learning_rate": 0.000390895410082769,
      "loss": 0.3631,
      "step": 69300
    },
    {
      "epoch": 2.8218838310935817,
      "grad_norm": 0.24395698308944702,
      "learning_rate": 0.0003906741025981499,
      "loss": 0.3624,
      "step": 69400
    },
    {
      "epoch": 2.825949946123976,
      "grad_norm": 0.2327449917793274,
      "learning_rate": 0.00039045279511353074,
      "loss": 0.3608,
      "step": 69500
    },
    {
      "epoch": 2.83001606115437,
      "grad_norm": 0.251459002494812,
      "learning_rate": 0.00039023148762891164,
      "loss": 0.3604,
      "step": 69600
    },
    {
      "epoch": 2.834082176184764,
      "grad_norm": 0.2337745726108551,
      "learning_rate": 0.00039001018014429254,
      "loss": 0.3631,
      "step": 69700
    },
    {
      "epoch": 2.8381482912151585,
      "grad_norm": 0.22511713206768036,
      "learning_rate": 0.0003897888726596733,
      "loss": 0.362,
      "step": 69800
    },
    {
      "epoch": 2.8422144062455525,
      "grad_norm": 0.24319259822368622,
      "learning_rate": 0.0003895675651750542,
      "loss": 0.362,
      "step": 69900
    },
    {
      "epoch": 2.846280521275947,
      "grad_norm": 0.22215032577514648,
      "learning_rate": 0.00038934625769043507,
      "loss": 0.3594,
      "step": 70000
    },
    {
      "epoch": 2.846280521275947,
      "eval_loss": 0.3713698983192444,
      "eval_runtime": 130.0573,
      "eval_samples_per_second": 1344.808,
      "eval_steps_per_second": 42.028,
      "step": 70000
    },
    {
      "epoch": 2.850346636306341,
      "grad_norm": 0.23705756664276123,
      "learning_rate": 0.00038912495020581596,
      "loss": 0.3634,
      "step": 70100
    },
    {
      "epoch": 2.8544127513367354,
      "grad_norm": 0.26161298155784607,
      "learning_rate": 0.0003889036427211968,
      "loss": 0.3616,
      "step": 70200
    },
    {
      "epoch": 2.8584788663671294,
      "grad_norm": 0.2209606170654297,
      "learning_rate": 0.0003886823352365777,
      "loss": 0.3618,
      "step": 70300
    },
    {
      "epoch": 2.862544981397524,
      "grad_norm": 0.22121082246303558,
      "learning_rate": 0.00038846102775195855,
      "loss": 0.3601,
      "step": 70400
    },
    {
      "epoch": 2.866611096427918,
      "grad_norm": 0.2239806056022644,
      "learning_rate": 0.00038823972026733944,
      "loss": 0.362,
      "step": 70500
    },
    {
      "epoch": 2.870677211458312,
      "grad_norm": 0.2431797832250595,
      "learning_rate": 0.00038801841278272034,
      "loss": 0.3641,
      "step": 70600
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 0.24284352362155914,
      "learning_rate": 0.0003877971052981012,
      "loss": 0.3612,
      "step": 70700
    },
    {
      "epoch": 2.878809441519101,
      "grad_norm": 0.22523309290409088,
      "learning_rate": 0.0003875757978134821,
      "loss": 0.3631,
      "step": 70800
    },
    {
      "epoch": 2.882875556549495,
      "grad_norm": 0.2701159417629242,
      "learning_rate": 0.0003873544903288629,
      "loss": 0.3604,
      "step": 70900
    },
    {
      "epoch": 2.886941671579889,
      "grad_norm": 0.2570861876010895,
      "learning_rate": 0.0003871331828442438,
      "loss": 0.3638,
      "step": 71000
    },
    {
      "epoch": 2.8910077866102832,
      "grad_norm": 0.25722360610961914,
      "learning_rate": 0.00038691187535962467,
      "loss": 0.36,
      "step": 71100
    },
    {
      "epoch": 2.8950739016406777,
      "grad_norm": 0.23388080298900604,
      "learning_rate": 0.00038669056787500556,
      "loss": 0.3617,
      "step": 71200
    },
    {
      "epoch": 2.8991400166710717,
      "grad_norm": 0.21617084741592407,
      "learning_rate": 0.00038646926039038646,
      "loss": 0.3618,
      "step": 71300
    },
    {
      "epoch": 2.9032061317014657,
      "grad_norm": 0.28993216156959534,
      "learning_rate": 0.0003862479529057673,
      "loss": 0.3604,
      "step": 71400
    },
    {
      "epoch": 2.90727224673186,
      "grad_norm": 0.26250338554382324,
      "learning_rate": 0.00038602664542114815,
      "loss": 0.3633,
      "step": 71500
    },
    {
      "epoch": 2.911338361762254,
      "grad_norm": 0.26172590255737305,
      "learning_rate": 0.000385805337936529,
      "loss": 0.3623,
      "step": 71600
    },
    {
      "epoch": 2.9154044767926486,
      "grad_norm": 0.22967982292175293,
      "learning_rate": 0.0003855840304519099,
      "loss": 0.3597,
      "step": 71700
    },
    {
      "epoch": 2.9194705918230426,
      "grad_norm": 0.25656139850616455,
      "learning_rate": 0.00038536272296729073,
      "loss": 0.3609,
      "step": 71800
    },
    {
      "epoch": 2.923536706853437,
      "grad_norm": 0.29415619373321533,
      "learning_rate": 0.00038514141548267163,
      "loss": 0.3615,
      "step": 71900
    },
    {
      "epoch": 2.927602821883831,
      "grad_norm": 0.2524060010910034,
      "learning_rate": 0.00038492010799805247,
      "loss": 0.3619,
      "step": 72000
    },
    {
      "epoch": 2.927602821883831,
      "eval_loss": 0.3709810972213745,
      "eval_runtime": 129.6867,
      "eval_samples_per_second": 1348.65,
      "eval_steps_per_second": 42.148,
      "step": 72000
    },
    {
      "epoch": 2.9316689369142255,
      "grad_norm": 0.2683619558811188,
      "learning_rate": 0.00038469880051343337,
      "loss": 0.3595,
      "step": 72100
    },
    {
      "epoch": 2.9357350519446195,
      "grad_norm": 0.2914734184741974,
      "learning_rate": 0.00038447749302881427,
      "loss": 0.3608,
      "step": 72200
    },
    {
      "epoch": 2.9398011669750135,
      "grad_norm": 0.23777714371681213,
      "learning_rate": 0.0003842561855441951,
      "loss": 0.36,
      "step": 72300
    },
    {
      "epoch": 2.943867282005408,
      "grad_norm": 0.2812325656414032,
      "learning_rate": 0.000384034878059576,
      "loss": 0.3612,
      "step": 72400
    },
    {
      "epoch": 2.9479333970358024,
      "grad_norm": 0.35108110308647156,
      "learning_rate": 0.00038381357057495685,
      "loss": 0.3586,
      "step": 72500
    },
    {
      "epoch": 2.9519995120661964,
      "grad_norm": 0.2562907040119171,
      "learning_rate": 0.00038359226309033775,
      "loss": 0.3613,
      "step": 72600
    },
    {
      "epoch": 2.9560656270965904,
      "grad_norm": 0.24215275049209595,
      "learning_rate": 0.0003833709556057186,
      "loss": 0.361,
      "step": 72700
    },
    {
      "epoch": 2.960131742126985,
      "grad_norm": 0.26652052998542786,
      "learning_rate": 0.0003831496481210995,
      "loss": 0.3612,
      "step": 72800
    },
    {
      "epoch": 2.964197857157379,
      "grad_norm": 0.2919328808784485,
      "learning_rate": 0.00038292834063648033,
      "loss": 0.3608,
      "step": 72900
    },
    {
      "epoch": 2.9682639721877733,
      "grad_norm": 0.2512626647949219,
      "learning_rate": 0.00038270703315186123,
      "loss": 0.361,
      "step": 73000
    },
    {
      "epoch": 2.9723300872181673,
      "grad_norm": 0.26972734928131104,
      "learning_rate": 0.0003824857256672421,
      "loss": 0.3614,
      "step": 73100
    },
    {
      "epoch": 2.9763962022485617,
      "grad_norm": 0.20823992788791656,
      "learning_rate": 0.0003822644181826229,
      "loss": 0.3599,
      "step": 73200
    },
    {
      "epoch": 2.9804623172789557,
      "grad_norm": 0.24820198118686676,
      "learning_rate": 0.0003820431106980038,
      "loss": 0.3602,
      "step": 73300
    },
    {
      "epoch": 2.98452843230935,
      "grad_norm": 0.28716570138931274,
      "learning_rate": 0.00038182180321338465,
      "loss": 0.3615,
      "step": 73400
    },
    {
      "epoch": 2.988594547339744,
      "grad_norm": 0.23660366237163544,
      "learning_rate": 0.00038160049572876555,
      "loss": 0.3607,
      "step": 73500
    },
    {
      "epoch": 2.9926606623701386,
      "grad_norm": 0.25928857922554016,
      "learning_rate": 0.0003813791882441464,
      "loss": 0.3606,
      "step": 73600
    },
    {
      "epoch": 2.9967267774005326,
      "grad_norm": 0.2819688320159912,
      "learning_rate": 0.0003811578807595273,
      "loss": 0.359,
      "step": 73700
    },
    {
      "epoch": 3.000792892430927,
      "grad_norm": 0.24100051820278168,
      "learning_rate": 0.00038093657327490813,
      "loss": 0.361,
      "step": 73800
    },
    {
      "epoch": 3.004859007461321,
      "grad_norm": 0.25717324018478394,
      "learning_rate": 0.00038071526579028903,
      "loss": 0.356,
      "step": 73900
    },
    {
      "epoch": 3.0089251224917155,
      "grad_norm": 0.26326557993888855,
      "learning_rate": 0.00038049395830566993,
      "loss": 0.3551,
      "step": 74000
    },
    {
      "epoch": 3.0089251224917155,
      "eval_loss": 0.37005001306533813,
      "eval_runtime": 129.6622,
      "eval_samples_per_second": 1348.905,
      "eval_steps_per_second": 42.156,
      "step": 74000
    },
    {
      "epoch": 3.0129912375221095,
      "grad_norm": 0.2434237152338028,
      "learning_rate": 0.00038027265082105077,
      "loss": 0.3565,
      "step": 74100
    },
    {
      "epoch": 3.0170573525525035,
      "grad_norm": 0.28328779339790344,
      "learning_rate": 0.00038005134333643167,
      "loss": 0.3576,
      "step": 74200
    },
    {
      "epoch": 3.021123467582898,
      "grad_norm": 0.2645643949508667,
      "learning_rate": 0.0003798300358518125,
      "loss": 0.3562,
      "step": 74300
    },
    {
      "epoch": 3.025189582613292,
      "grad_norm": 0.24542219936847687,
      "learning_rate": 0.0003796087283671934,
      "loss": 0.3556,
      "step": 74400
    },
    {
      "epoch": 3.0292556976436864,
      "grad_norm": 0.3096906840801239,
      "learning_rate": 0.00037938742088257425,
      "loss": 0.3558,
      "step": 74500
    },
    {
      "epoch": 3.0333218126740804,
      "grad_norm": 0.24613754451274872,
      "learning_rate": 0.00037916611339795515,
      "loss": 0.356,
      "step": 74600
    },
    {
      "epoch": 3.037387927704475,
      "grad_norm": 0.3401792645454407,
      "learning_rate": 0.00037894480591333605,
      "loss": 0.3565,
      "step": 74700
    },
    {
      "epoch": 3.041454042734869,
      "grad_norm": 0.24462108314037323,
      "learning_rate": 0.00037872349842871684,
      "loss": 0.3541,
      "step": 74800
    },
    {
      "epoch": 3.0455201577652633,
      "grad_norm": 0.27998435497283936,
      "learning_rate": 0.00037850219094409773,
      "loss": 0.3584,
      "step": 74900
    },
    {
      "epoch": 3.0495862727956573,
      "grad_norm": 0.36009061336517334,
      "learning_rate": 0.0003782808834594786,
      "loss": 0.356,
      "step": 75000
    },
    {
      "epoch": 3.0536523878260518,
      "grad_norm": 0.2655039131641388,
      "learning_rate": 0.0003780595759748595,
      "loss": 0.3555,
      "step": 75100
    },
    {
      "epoch": 3.0577185028564458,
      "grad_norm": 0.26711976528167725,
      "learning_rate": 0.0003778382684902403,
      "loss": 0.3559,
      "step": 75200
    },
    {
      "epoch": 3.06178461788684,
      "grad_norm": 0.256606787443161,
      "learning_rate": 0.0003776169610056212,
      "loss": 0.3577,
      "step": 75300
    },
    {
      "epoch": 3.065850732917234,
      "grad_norm": 0.2913854718208313,
      "learning_rate": 0.00037739565352100206,
      "loss": 0.3553,
      "step": 75400
    },
    {
      "epoch": 3.0699168479476286,
      "grad_norm": 0.22732651233673096,
      "learning_rate": 0.00037717434603638296,
      "loss": 0.3566,
      "step": 75500
    },
    {
      "epoch": 3.0739829629780226,
      "grad_norm": 0.2642591893672943,
      "learning_rate": 0.00037695303855176385,
      "loss": 0.3554,
      "step": 75600
    },
    {
      "epoch": 3.0780490780084167,
      "grad_norm": 0.254913330078125,
      "learning_rate": 0.0003767317310671447,
      "loss": 0.3574,
      "step": 75700
    },
    {
      "epoch": 3.082115193038811,
      "grad_norm": 0.27042028307914734,
      "learning_rate": 0.0003765104235825256,
      "loss": 0.3563,
      "step": 75800
    },
    {
      "epoch": 3.086181308069205,
      "grad_norm": 0.2550118565559387,
      "learning_rate": 0.00037628911609790644,
      "loss": 0.3559,
      "step": 75900
    },
    {
      "epoch": 3.0902474230995995,
      "grad_norm": 0.24676541984081268,
      "learning_rate": 0.00037606780861328733,
      "loss": 0.3589,
      "step": 76000
    },
    {
      "epoch": 3.0902474230995995,
      "eval_loss": 0.36950474977493286,
      "eval_runtime": 129.1234,
      "eval_samples_per_second": 1354.534,
      "eval_steps_per_second": 42.332,
      "step": 76000
    },
    {
      "epoch": 3.0943745298554495,
      "grad_norm": 0.21771791577339172,
      "learning_rate": 0.0003758465011286682,
      "loss": 0.3542,
      "step": 76100
    },
    {
      "epoch": 3.098440644885844,
      "grad_norm": 0.23509374260902405,
      "learning_rate": 0.0003756251936440491,
      "loss": 0.3577,
      "step": 76200
    },
    {
      "epoch": 3.102506759916238,
      "grad_norm": 0.3075208067893982,
      "learning_rate": 0.0003754038861594299,
      "loss": 0.3564,
      "step": 76300
    },
    {
      "epoch": 3.1065728749466324,
      "grad_norm": 0.2689468264579773,
      "learning_rate": 0.0003751825786748108,
      "loss": 0.3583,
      "step": 76400
    },
    {
      "epoch": 3.1106389899770264,
      "grad_norm": 0.23345445096492767,
      "learning_rate": 0.00037496127119019166,
      "loss": 0.3558,
      "step": 76500
    },
    {
      "epoch": 3.114705105007421,
      "grad_norm": 0.23108921945095062,
      "learning_rate": 0.0003747399637055725,
      "loss": 0.3575,
      "step": 76600
    },
    {
      "epoch": 3.118771220037815,
      "grad_norm": 0.27876269817352295,
      "learning_rate": 0.0003745186562209534,
      "loss": 0.3559,
      "step": 76700
    },
    {
      "epoch": 3.1228373350682093,
      "grad_norm": 0.2414642870426178,
      "learning_rate": 0.00037429734873633424,
      "loss": 0.3578,
      "step": 76800
    },
    {
      "epoch": 3.1269034500986033,
      "grad_norm": 0.30903366208076477,
      "learning_rate": 0.00037407604125171514,
      "loss": 0.3582,
      "step": 76900
    },
    {
      "epoch": 3.1309695651289973,
      "grad_norm": 0.2199459820985794,
      "learning_rate": 0.000373854733767096,
      "loss": 0.3584,
      "step": 77000
    },
    {
      "epoch": 3.1350356801593917,
      "grad_norm": 0.28422045707702637,
      "learning_rate": 0.0003736334262824769,
      "loss": 0.3574,
      "step": 77100
    },
    {
      "epoch": 3.1391017951897857,
      "grad_norm": 0.25629881024360657,
      "learning_rate": 0.0003734121187978577,
      "loss": 0.359,
      "step": 77200
    },
    {
      "epoch": 3.14316791022018,
      "grad_norm": 0.2453068345785141,
      "learning_rate": 0.0003731908113132386,
      "loss": 0.3566,
      "step": 77300
    },
    {
      "epoch": 3.147234025250574,
      "grad_norm": 0.25595709681510925,
      "learning_rate": 0.0003729695038286195,
      "loss": 0.3573,
      "step": 77400
    },
    {
      "epoch": 3.1513001402809686,
      "grad_norm": 0.25835826992988586,
      "learning_rate": 0.00037274819634400036,
      "loss": 0.3575,
      "step": 77500
    },
    {
      "epoch": 3.1553662553113626,
      "grad_norm": 0.29747113585472107,
      "learning_rate": 0.00037252688885938126,
      "loss": 0.3562,
      "step": 77600
    },
    {
      "epoch": 3.159432370341757,
      "grad_norm": 0.2655724585056305,
      "learning_rate": 0.0003723055813747621,
      "loss": 0.3579,
      "step": 77700
    },
    {
      "epoch": 3.163498485372151,
      "grad_norm": 0.24204839766025543,
      "learning_rate": 0.000372084273890143,
      "loss": 0.3569,
      "step": 77800
    },
    {
      "epoch": 3.1675646004025455,
      "grad_norm": 0.3040449321269989,
      "learning_rate": 0.00037186296640552384,
      "loss": 0.3597,
      "step": 77900
    },
    {
      "epoch": 3.1716307154329395,
      "grad_norm": 0.2810501754283905,
      "learning_rate": 0.00037164165892090474,
      "loss": 0.3581,
      "step": 78000
    },
    {
      "epoch": 3.1716307154329395,
      "eval_loss": 0.36931732296943665,
      "eval_runtime": 129.3229,
      "eval_samples_per_second": 1352.444,
      "eval_steps_per_second": 42.266,
      "step": 78000
    },
    {
      "epoch": 3.175696830463334,
      "grad_norm": 0.27426397800445557,
      "learning_rate": 0.0003714203514362856,
      "loss": 0.3587,
      "step": 78100
    },
    {
      "epoch": 3.179762945493728,
      "grad_norm": 0.2711125910282135,
      "learning_rate": 0.0003711990439516664,
      "loss": 0.3577,
      "step": 78200
    },
    {
      "epoch": 3.1838290605241224,
      "grad_norm": 0.2932054102420807,
      "learning_rate": 0.0003709777364670473,
      "loss": 0.3578,
      "step": 78300
    },
    {
      "epoch": 3.1878951755545164,
      "grad_norm": 0.2725035846233368,
      "learning_rate": 0.00037075642898242817,
      "loss": 0.3584,
      "step": 78400
    },
    {
      "epoch": 3.191961290584911,
      "grad_norm": 0.2585741877555847,
      "learning_rate": 0.00037053512149780906,
      "loss": 0.3557,
      "step": 78500
    },
    {
      "epoch": 3.196027405615305,
      "grad_norm": 0.22863876819610596,
      "learning_rate": 0.0003703138140131899,
      "loss": 0.3583,
      "step": 78600
    },
    {
      "epoch": 3.200093520645699,
      "grad_norm": 0.30934688448905945,
      "learning_rate": 0.0003700925065285708,
      "loss": 0.3564,
      "step": 78700
    },
    {
      "epoch": 3.2041596356760933,
      "grad_norm": 0.29569104313850403,
      "learning_rate": 0.00036987119904395165,
      "loss": 0.3563,
      "step": 78800
    },
    {
      "epoch": 3.2082257507064873,
      "grad_norm": 0.24849942326545715,
      "learning_rate": 0.00036964989155933254,
      "loss": 0.3586,
      "step": 78900
    },
    {
      "epoch": 3.2122918657368817,
      "grad_norm": 0.23217478394508362,
      "learning_rate": 0.00036942858407471344,
      "loss": 0.3584,
      "step": 79000
    },
    {
      "epoch": 3.2163579807672757,
      "grad_norm": 0.2474520206451416,
      "learning_rate": 0.0003692072765900943,
      "loss": 0.3571,
      "step": 79100
    },
    {
      "epoch": 3.22042409579767,
      "grad_norm": 0.2120019495487213,
      "learning_rate": 0.0003689859691054752,
      "loss": 0.3565,
      "step": 79200
    },
    {
      "epoch": 3.224490210828064,
      "grad_norm": 0.27321141958236694,
      "learning_rate": 0.000368764661620856,
      "loss": 0.3571,
      "step": 79300
    },
    {
      "epoch": 3.2285563258584586,
      "grad_norm": 0.2527376711368561,
      "learning_rate": 0.0003685433541362369,
      "loss": 0.3564,
      "step": 79400
    },
    {
      "epoch": 3.2326224408888526,
      "grad_norm": 0.24288120865821838,
      "learning_rate": 0.00036832204665161776,
      "loss": 0.357,
      "step": 79500
    },
    {
      "epoch": 3.236688555919247,
      "grad_norm": 0.25298160314559937,
      "learning_rate": 0.00036810073916699866,
      "loss": 0.3572,
      "step": 79600
    },
    {
      "epoch": 3.240754670949641,
      "grad_norm": 0.2505098879337311,
      "learning_rate": 0.0003678794316823795,
      "loss": 0.3561,
      "step": 79700
    },
    {
      "epoch": 3.2448207859800355,
      "grad_norm": 0.2258906364440918,
      "learning_rate": 0.0003676581241977604,
      "loss": 0.3567,
      "step": 79800
    },
    {
      "epoch": 3.2488869010104295,
      "grad_norm": 0.274145245552063,
      "learning_rate": 0.00036743681671314125,
      "loss": 0.3582,
      "step": 79900
    },
    {
      "epoch": 3.252953016040824,
      "grad_norm": 0.23948970437049866,
      "learning_rate": 0.0003672155092285221,
      "loss": 0.3573,
      "step": 80000
    },
    {
      "epoch": 3.252953016040824,
      "eval_loss": 0.3680137097835541,
      "eval_runtime": 127.8527,
      "eval_samples_per_second": 1367.996,
      "eval_steps_per_second": 42.752,
      "step": 80000
    },
    {
      "epoch": 3.257019131071218,
      "grad_norm": 0.25638818740844727,
      "learning_rate": 0.000366994201743903,
      "loss": 0.3555,
      "step": 80100
    },
    {
      "epoch": 3.2610852461016124,
      "grad_norm": 0.2355981469154358,
      "learning_rate": 0.00036677289425928383,
      "loss": 0.3577,
      "step": 80200
    },
    {
      "epoch": 3.2651513611320064,
      "grad_norm": 0.2503892779350281,
      "learning_rate": 0.0003665515867746647,
      "loss": 0.3565,
      "step": 80300
    },
    {
      "epoch": 3.2692174761624004,
      "grad_norm": 0.24704048037528992,
      "learning_rate": 0.00036633027929004557,
      "loss": 0.3589,
      "step": 80400
    },
    {
      "epoch": 3.273283591192795,
      "grad_norm": 0.24602091312408447,
      "learning_rate": 0.00036610897180542647,
      "loss": 0.3577,
      "step": 80500
    },
    {
      "epoch": 3.277349706223189,
      "grad_norm": 0.2375621646642685,
      "learning_rate": 0.0003658876643208073,
      "loss": 0.3571,
      "step": 80600
    },
    {
      "epoch": 3.2814158212535833,
      "grad_norm": 0.26467224955558777,
      "learning_rate": 0.0003656663568361882,
      "loss": 0.3577,
      "step": 80700
    },
    {
      "epoch": 3.2854819362839773,
      "grad_norm": 0.278272807598114,
      "learning_rate": 0.0003654450493515691,
      "loss": 0.3588,
      "step": 80800
    },
    {
      "epoch": 3.289548051314372,
      "grad_norm": 0.2713513970375061,
      "learning_rate": 0.00036522374186694995,
      "loss": 0.3572,
      "step": 80900
    },
    {
      "epoch": 3.293614166344766,
      "grad_norm": 0.30134251713752747,
      "learning_rate": 0.00036500243438233085,
      "loss": 0.3596,
      "step": 81000
    },
    {
      "epoch": 3.2976802813751602,
      "grad_norm": 0.3290872871875763,
      "learning_rate": 0.0003647811268977117,
      "loss": 0.3574,
      "step": 81100
    },
    {
      "epoch": 3.3017463964055542,
      "grad_norm": 0.257154643535614,
      "learning_rate": 0.0003645598194130926,
      "loss": 0.3598,
      "step": 81200
    },
    {
      "epoch": 3.3058125114359487,
      "grad_norm": 0.32742130756378174,
      "learning_rate": 0.00036433851192847343,
      "loss": 0.356,
      "step": 81300
    },
    {
      "epoch": 3.3098786264663427,
      "grad_norm": 0.25961416959762573,
      "learning_rate": 0.0003641172044438543,
      "loss": 0.359,
      "step": 81400
    },
    {
      "epoch": 3.313944741496737,
      "grad_norm": 0.2661507725715637,
      "learning_rate": 0.00036389589695923517,
      "loss": 0.3569,
      "step": 81500
    },
    {
      "epoch": 3.318010856527131,
      "grad_norm": 0.2534615099430084,
      "learning_rate": 0.000363674589474616,
      "loss": 0.3574,
      "step": 81600
    },
    {
      "epoch": 3.322076971557525,
      "grad_norm": 0.25694048404693604,
      "learning_rate": 0.0003634532819899969,
      "loss": 0.3573,
      "step": 81700
    },
    {
      "epoch": 3.3261430865879196,
      "grad_norm": 0.2665044069290161,
      "learning_rate": 0.00036323197450537775,
      "loss": 0.3574,
      "step": 81800
    },
    {
      "epoch": 3.330209201618314,
      "grad_norm": 0.27508610486984253,
      "learning_rate": 0.00036301066702075865,
      "loss": 0.3577,
      "step": 81900
    },
    {
      "epoch": 3.334275316648708,
      "grad_norm": 0.2882462441921234,
      "learning_rate": 0.0003627893595361395,
      "loss": 0.3557,
      "step": 82000
    },
    {
      "epoch": 3.334275316648708,
      "eval_loss": 0.3680188059806824,
      "eval_runtime": 128.0392,
      "eval_samples_per_second": 1366.003,
      "eval_steps_per_second": 42.69,
      "step": 82000
    },
    {
      "epoch": 3.338341431679102,
      "grad_norm": 0.2680377662181854,
      "learning_rate": 0.0003625680520515204,
      "loss": 0.3576,
      "step": 82100
    },
    {
      "epoch": 3.3424075467094965,
      "grad_norm": 0.25379514694213867,
      "learning_rate": 0.00036234674456690123,
      "loss": 0.3554,
      "step": 82200
    },
    {
      "epoch": 3.3464736617398905,
      "grad_norm": 0.3041890561580658,
      "learning_rate": 0.00036212543708228213,
      "loss": 0.3567,
      "step": 82300
    },
    {
      "epoch": 3.350539776770285,
      "grad_norm": 0.24033501744270325,
      "learning_rate": 0.000361904129597663,
      "loss": 0.3583,
      "step": 82400
    },
    {
      "epoch": 3.354605891800679,
      "grad_norm": 0.2867376208305359,
      "learning_rate": 0.00036168282211304387,
      "loss": 0.3567,
      "step": 82500
    },
    {
      "epoch": 3.3586720068310734,
      "grad_norm": 0.24874919652938843,
      "learning_rate": 0.00036146151462842477,
      "loss": 0.3574,
      "step": 82600
    },
    {
      "epoch": 3.3627381218614674,
      "grad_norm": 0.2565075755119324,
      "learning_rate": 0.0003612402071438056,
      "loss": 0.3593,
      "step": 82700
    },
    {
      "epoch": 3.366804236891862,
      "grad_norm": 0.259565144777298,
      "learning_rate": 0.0003610188996591865,
      "loss": 0.3564,
      "step": 82800
    },
    {
      "epoch": 3.370870351922256,
      "grad_norm": 0.26635080575942993,
      "learning_rate": 0.00036079759217456735,
      "loss": 0.3585,
      "step": 82900
    },
    {
      "epoch": 3.3749364669526503,
      "grad_norm": 0.2717045247554779,
      "learning_rate": 0.00036057628468994825,
      "loss": 0.3584,
      "step": 83000
    },
    {
      "epoch": 3.3790025819830443,
      "grad_norm": 0.29043933749198914,
      "learning_rate": 0.0003603549772053291,
      "loss": 0.3568,
      "step": 83100
    },
    {
      "epoch": 3.3830686970134387,
      "grad_norm": 0.25076067447662354,
      "learning_rate": 0.00036013366972071,
      "loss": 0.3551,
      "step": 83200
    },
    {
      "epoch": 3.3871348120438327,
      "grad_norm": 0.2563551068305969,
      "learning_rate": 0.00035991236223609083,
      "loss": 0.3574,
      "step": 83300
    },
    {
      "epoch": 3.3912009270742267,
      "grad_norm": 0.2683212459087372,
      "learning_rate": 0.0003596910547514717,
      "loss": 0.3552,
      "step": 83400
    },
    {
      "epoch": 3.395267042104621,
      "grad_norm": 0.26027005910873413,
      "learning_rate": 0.0003594697472668526,
      "loss": 0.3577,
      "step": 83500
    },
    {
      "epoch": 3.399333157135015,
      "grad_norm": 0.2730962038040161,
      "learning_rate": 0.0003592484397822334,
      "loss": 0.3553,
      "step": 83600
    },
    {
      "epoch": 3.4033992721654096,
      "grad_norm": 0.302511066198349,
      "learning_rate": 0.0003590271322976143,
      "loss": 0.3568,
      "step": 83700
    },
    {
      "epoch": 3.4074653871958036,
      "grad_norm": 0.3102746307849884,
      "learning_rate": 0.00035880582481299516,
      "loss": 0.3579,
      "step": 83800
    },
    {
      "epoch": 3.411531502226198,
      "grad_norm": 0.26980340480804443,
      "learning_rate": 0.00035858451732837605,
      "loss": 0.3567,
      "step": 83900
    },
    {
      "epoch": 3.415597617256592,
      "grad_norm": 0.2671577036380768,
      "learning_rate": 0.0003583632098437569,
      "loss": 0.3577,
      "step": 84000
    },
    {
      "epoch": 3.415597617256592,
      "eval_loss": 0.3679240047931671,
      "eval_runtime": 128.5548,
      "eval_samples_per_second": 1360.524,
      "eval_steps_per_second": 42.519,
      "step": 84000
    },
    {
      "epoch": 3.4196637322869865,
      "grad_norm": 0.2594910264015198,
      "learning_rate": 0.0003581419023591378,
      "loss": 0.3562,
      "step": 84100
    },
    {
      "epoch": 3.4237298473173805,
      "grad_norm": 0.28473788499832153,
      "learning_rate": 0.0003579205948745187,
      "loss": 0.3557,
      "step": 84200
    },
    {
      "epoch": 3.427795962347775,
      "grad_norm": 0.263135701417923,
      "learning_rate": 0.00035769928738989954,
      "loss": 0.3565,
      "step": 84300
    },
    {
      "epoch": 3.431862077378169,
      "grad_norm": 0.2749077379703522,
      "learning_rate": 0.00035747797990528043,
      "loss": 0.3558,
      "step": 84400
    },
    {
      "epoch": 3.4359281924085634,
      "grad_norm": 0.26109835505485535,
      "learning_rate": 0.0003572566724206613,
      "loss": 0.356,
      "step": 84500
    },
    {
      "epoch": 3.4399943074389574,
      "grad_norm": 0.29650044441223145,
      "learning_rate": 0.0003570353649360422,
      "loss": 0.3576,
      "step": 84600
    },
    {
      "epoch": 3.444060422469352,
      "grad_norm": 0.2711218595504761,
      "learning_rate": 0.000356814057451423,
      "loss": 0.356,
      "step": 84700
    },
    {
      "epoch": 3.448126537499746,
      "grad_norm": 0.2947142422199249,
      "learning_rate": 0.0003565927499668039,
      "loss": 0.3568,
      "step": 84800
    },
    {
      "epoch": 3.4521926525301403,
      "grad_norm": 0.24648648500442505,
      "learning_rate": 0.00035637144248218476,
      "loss": 0.354,
      "step": 84900
    },
    {
      "epoch": 3.4562587675605343,
      "grad_norm": 0.26236894726753235,
      "learning_rate": 0.0003561501349975656,
      "loss": 0.3585,
      "step": 85000
    },
    {
      "epoch": 3.4603248825909283,
      "grad_norm": 0.2667173147201538,
      "learning_rate": 0.0003559288275129465,
      "loss": 0.357,
      "step": 85100
    },
    {
      "epoch": 3.4643909976213227,
      "grad_norm": 0.2678104043006897,
      "learning_rate": 0.00035570752002832734,
      "loss": 0.3571,
      "step": 85200
    },
    {
      "epoch": 3.4684571126517167,
      "grad_norm": 0.30512508749961853,
      "learning_rate": 0.00035548621254370824,
      "loss": 0.3559,
      "step": 85300
    },
    {
      "epoch": 3.472523227682111,
      "grad_norm": 0.26849332451820374,
      "learning_rate": 0.0003552649050590891,
      "loss": 0.3558,
      "step": 85400
    },
    {
      "epoch": 3.476589342712505,
      "grad_norm": 0.2822352349758148,
      "learning_rate": 0.00035504359757447,
      "loss": 0.3578,
      "step": 85500
    },
    {
      "epoch": 3.4806554577428996,
      "grad_norm": 0.2963075637817383,
      "learning_rate": 0.0003548222900898508,
      "loss": 0.3604,
      "step": 85600
    },
    {
      "epoch": 3.4847215727732936,
      "grad_norm": 0.26593056321144104,
      "learning_rate": 0.0003546009826052317,
      "loss": 0.3579,
      "step": 85700
    },
    {
      "epoch": 3.488787687803688,
      "grad_norm": 0.3157825469970703,
      "learning_rate": 0.00035437967512061256,
      "loss": 0.355,
      "step": 85800
    },
    {
      "epoch": 3.492853802834082,
      "grad_norm": 0.2676750123500824,
      "learning_rate": 0.00035415836763599346,
      "loss": 0.3572,
      "step": 85900
    },
    {
      "epoch": 3.4969199178644765,
      "grad_norm": 0.32890939712524414,
      "learning_rate": 0.00035393706015137436,
      "loss": 0.3555,
      "step": 86000
    },
    {
      "epoch": 3.4969199178644765,
      "eval_loss": 0.36719831824302673,
      "eval_runtime": 128.4258,
      "eval_samples_per_second": 1361.892,
      "eval_steps_per_second": 42.562,
      "step": 86000
    },
    {
      "epoch": 3.5009860328948705,
      "grad_norm": 0.22575701773166656,
      "learning_rate": 0.0003537157526667552,
      "loss": 0.357,
      "step": 86100
    },
    {
      "epoch": 3.505052147925265,
      "grad_norm": 0.27310308814048767,
      "learning_rate": 0.0003534944451821361,
      "loss": 0.3562,
      "step": 86200
    },
    {
      "epoch": 3.509118262955659,
      "grad_norm": 0.2346159815788269,
      "learning_rate": 0.00035327313769751694,
      "loss": 0.3561,
      "step": 86300
    },
    {
      "epoch": 3.513184377986053,
      "grad_norm": 0.28985899686813354,
      "learning_rate": 0.00035305183021289784,
      "loss": 0.3599,
      "step": 86400
    },
    {
      "epoch": 3.5172504930164474,
      "grad_norm": 0.29041337966918945,
      "learning_rate": 0.0003528305227282787,
      "loss": 0.3577,
      "step": 86500
    },
    {
      "epoch": 3.521316608046842,
      "grad_norm": 0.30959784984588623,
      "learning_rate": 0.0003526092152436595,
      "loss": 0.3584,
      "step": 86600
    },
    {
      "epoch": 3.525382723077236,
      "grad_norm": 0.2792827785015106,
      "learning_rate": 0.0003523879077590404,
      "loss": 0.359,
      "step": 86700
    },
    {
      "epoch": 3.52944883810763,
      "grad_norm": 0.3469741642475128,
      "learning_rate": 0.00035216660027442126,
      "loss": 0.358,
      "step": 86800
    },
    {
      "epoch": 3.5335149531380243,
      "grad_norm": 0.3328489363193512,
      "learning_rate": 0.00035194529278980216,
      "loss": 0.354,
      "step": 86900
    },
    {
      "epoch": 3.5375810681684183,
      "grad_norm": 0.3148952126502991,
      "learning_rate": 0.000351723985305183,
      "loss": 0.3566,
      "step": 87000
    },
    {
      "epoch": 3.5416471831988128,
      "grad_norm": 0.25936946272850037,
      "learning_rate": 0.0003515026778205639,
      "loss": 0.3561,
      "step": 87100
    },
    {
      "epoch": 3.545713298229207,
      "grad_norm": 0.3033035397529602,
      "learning_rate": 0.00035128137033594474,
      "loss": 0.3569,
      "step": 87200
    },
    {
      "epoch": 3.5497794132596012,
      "grad_norm": 0.24832600355148315,
      "learning_rate": 0.00035106006285132564,
      "loss": 0.3561,
      "step": 87300
    },
    {
      "epoch": 3.5538455282899952,
      "grad_norm": 0.2841162383556366,
      "learning_rate": 0.0003508387553667065,
      "loss": 0.3567,
      "step": 87400
    },
    {
      "epoch": 3.5579116433203897,
      "grad_norm": 0.2822803556919098,
      "learning_rate": 0.0003506174478820874,
      "loss": 0.356,
      "step": 87500
    },
    {
      "epoch": 3.5619777583507837,
      "grad_norm": 0.29022344946861267,
      "learning_rate": 0.0003503961403974683,
      "loss": 0.3574,
      "step": 87600
    },
    {
      "epoch": 3.566043873381178,
      "grad_norm": 0.2528838515281677,
      "learning_rate": 0.0003501748329128491,
      "loss": 0.3567,
      "step": 87700
    },
    {
      "epoch": 3.570109988411572,
      "grad_norm": 0.24658863246440887,
      "learning_rate": 0.00034995352542823,
      "loss": 0.3558,
      "step": 87800
    },
    {
      "epoch": 3.5741761034419666,
      "grad_norm": 0.31197813153266907,
      "learning_rate": 0.00034973221794361086,
      "loss": 0.3577,
      "step": 87900
    },
    {
      "epoch": 3.5782422184723606,
      "grad_norm": 0.2889537513256073,
      "learning_rate": 0.00034951091045899176,
      "loss": 0.3563,
      "step": 88000
    },
    {
      "epoch": 3.5782422184723606,
      "eval_loss": 0.36682799458503723,
      "eval_runtime": 128.9392,
      "eval_samples_per_second": 1356.469,
      "eval_steps_per_second": 42.392,
      "step": 88000
    },
    {
      "epoch": 3.5823083335027546,
      "grad_norm": 0.28295913338661194,
      "learning_rate": 0.0003492896029743726,
      "loss": 0.3571,
      "step": 88100
    },
    {
      "epoch": 3.586374448533149,
      "grad_norm": 0.3040946424007416,
      "learning_rate": 0.0003490682954897535,
      "loss": 0.3561,
      "step": 88200
    },
    {
      "epoch": 3.5904405635635435,
      "grad_norm": 0.2695482671260834,
      "learning_rate": 0.0003488469880051343,
      "loss": 0.3582,
      "step": 88300
    },
    {
      "epoch": 3.5945066785939375,
      "grad_norm": 0.26090285181999207,
      "learning_rate": 0.0003486256805205152,
      "loss": 0.3588,
      "step": 88400
    },
    {
      "epoch": 3.5985727936243315,
      "grad_norm": 0.26254746317863464,
      "learning_rate": 0.0003484043730358961,
      "loss": 0.3568,
      "step": 88500
    },
    {
      "epoch": 3.602638908654726,
      "grad_norm": 0.273506224155426,
      "learning_rate": 0.00034818306555127693,
      "loss": 0.3578,
      "step": 88600
    },
    {
      "epoch": 3.60670502368512,
      "grad_norm": 0.28076034784317017,
      "learning_rate": 0.0003479617580666578,
      "loss": 0.3576,
      "step": 88700
    },
    {
      "epoch": 3.6107711387155144,
      "grad_norm": 0.2583775520324707,
      "learning_rate": 0.00034774045058203867,
      "loss": 0.3574,
      "step": 88800
    },
    {
      "epoch": 3.6148372537459084,
      "grad_norm": 0.263168066740036,
      "learning_rate": 0.00034751914309741957,
      "loss": 0.355,
      "step": 88900
    },
    {
      "epoch": 3.618903368776303,
      "grad_norm": 0.2534199357032776,
      "learning_rate": 0.0003472978356128004,
      "loss": 0.3568,
      "step": 89000
    },
    {
      "epoch": 3.622969483806697,
      "grad_norm": 0.26043781638145447,
      "learning_rate": 0.0003470765281281813,
      "loss": 0.3591,
      "step": 89100
    },
    {
      "epoch": 3.6270355988370913,
      "grad_norm": 0.29075390100479126,
      "learning_rate": 0.00034685522064356215,
      "loss": 0.3557,
      "step": 89200
    },
    {
      "epoch": 3.6311017138674853,
      "grad_norm": 0.30588191747665405,
      "learning_rate": 0.00034663391315894305,
      "loss": 0.3566,
      "step": 89300
    },
    {
      "epoch": 3.6351678288978793,
      "grad_norm": 0.31818029284477234,
      "learning_rate": 0.00034641260567432394,
      "loss": 0.3565,
      "step": 89400
    },
    {
      "epoch": 3.6392339439282737,
      "grad_norm": 0.31030234694480896,
      "learning_rate": 0.0003461912981897048,
      "loss": 0.3576,
      "step": 89500
    },
    {
      "epoch": 3.643300058958668,
      "grad_norm": 0.2582477927207947,
      "learning_rate": 0.0003459699907050857,
      "loss": 0.3549,
      "step": 89600
    },
    {
      "epoch": 3.647366173989062,
      "grad_norm": 0.31017816066741943,
      "learning_rate": 0.00034574868322046653,
      "loss": 0.3549,
      "step": 89700
    },
    {
      "epoch": 3.651432289019456,
      "grad_norm": 0.2831823527812958,
      "learning_rate": 0.0003455273757358474,
      "loss": 0.3564,
      "step": 89800
    },
    {
      "epoch": 3.6554984040498506,
      "grad_norm": 0.2944544553756714,
      "learning_rate": 0.00034530606825122827,
      "loss": 0.3563,
      "step": 89900
    },
    {
      "epoch": 3.659564519080245,
      "grad_norm": 0.3306729197502136,
      "learning_rate": 0.0003450847607666091,
      "loss": 0.355,
      "step": 90000
    },
    {
      "epoch": 3.659564519080245,
      "eval_loss": 0.3666899502277374,
      "eval_runtime": 128.6415,
      "eval_samples_per_second": 1359.608,
      "eval_steps_per_second": 42.49,
      "step": 90000
    },
    {
      "epoch": 3.663630634110639,
      "grad_norm": 0.3051551878452301,
      "learning_rate": 0.00034486345328198995,
      "loss": 0.3553,
      "step": 90100
    },
    {
      "epoch": 3.667696749141033,
      "grad_norm": 0.25400376319885254,
      "learning_rate": 0.00034464214579737085,
      "loss": 0.3599,
      "step": 90200
    },
    {
      "epoch": 3.6717628641714275,
      "grad_norm": 0.2508017420768738,
      "learning_rate": 0.00034442083831275175,
      "loss": 0.3555,
      "step": 90300
    },
    {
      "epoch": 3.6758289792018215,
      "grad_norm": 0.2772660553455353,
      "learning_rate": 0.0003441995308281326,
      "loss": 0.3556,
      "step": 90400
    },
    {
      "epoch": 3.679895094232216,
      "grad_norm": 0.3276309072971344,
      "learning_rate": 0.0003439782233435135,
      "loss": 0.3565,
      "step": 90500
    },
    {
      "epoch": 3.68396120926261,
      "grad_norm": 0.25692081451416016,
      "learning_rate": 0.00034375691585889433,
      "loss": 0.357,
      "step": 90600
    },
    {
      "epoch": 3.6880273242930044,
      "grad_norm": 0.25788596272468567,
      "learning_rate": 0.00034353560837427523,
      "loss": 0.3564,
      "step": 90700
    },
    {
      "epoch": 3.6920934393233984,
      "grad_norm": 0.3380633592605591,
      "learning_rate": 0.00034331430088965607,
      "loss": 0.3564,
      "step": 90800
    },
    {
      "epoch": 3.696159554353793,
      "grad_norm": 0.29884788393974304,
      "learning_rate": 0.00034309299340503697,
      "loss": 0.3583,
      "step": 90900
    },
    {
      "epoch": 3.700225669384187,
      "grad_norm": 0.2984226644039154,
      "learning_rate": 0.00034287168592041787,
      "loss": 0.3557,
      "step": 91000
    },
    {
      "epoch": 3.704291784414581,
      "grad_norm": 0.31932035088539124,
      "learning_rate": 0.0003426503784357987,
      "loss": 0.3553,
      "step": 91100
    },
    {
      "epoch": 3.7083578994449753,
      "grad_norm": 0.29091328382492065,
      "learning_rate": 0.0003424290709511796,
      "loss": 0.3547,
      "step": 91200
    },
    {
      "epoch": 3.7124240144753697,
      "grad_norm": 0.28609615564346313,
      "learning_rate": 0.00034220776346656045,
      "loss": 0.3558,
      "step": 91300
    },
    {
      "epoch": 3.7164901295057637,
      "grad_norm": 0.3053485155105591,
      "learning_rate": 0.00034198645598194135,
      "loss": 0.3587,
      "step": 91400
    },
    {
      "epoch": 3.7205562445361577,
      "grad_norm": 0.28430113196372986,
      "learning_rate": 0.0003417651484973222,
      "loss": 0.3555,
      "step": 91500
    },
    {
      "epoch": 3.724622359566552,
      "grad_norm": 0.2905352711677551,
      "learning_rate": 0.0003415438410127031,
      "loss": 0.3582,
      "step": 91600
    },
    {
      "epoch": 3.728688474596946,
      "grad_norm": 0.3105684220790863,
      "learning_rate": 0.0003413225335280839,
      "loss": 0.3549,
      "step": 91700
    },
    {
      "epoch": 3.7327545896273406,
      "grad_norm": 0.28871607780456543,
      "learning_rate": 0.0003411012260434648,
      "loss": 0.3576,
      "step": 91800
    },
    {
      "epoch": 3.7368207046577346,
      "grad_norm": 0.3670612573623657,
      "learning_rate": 0.00034087991855884567,
      "loss": 0.3555,
      "step": 91900
    },
    {
      "epoch": 3.740886819688129,
      "grad_norm": 0.26638177037239075,
      "learning_rate": 0.0003406586110742265,
      "loss": 0.3571,
      "step": 92000
    },
    {
      "epoch": 3.740886819688129,
      "eval_loss": 0.3663181960582733,
      "eval_runtime": 131.525,
      "eval_samples_per_second": 1329.8,
      "eval_steps_per_second": 41.559,
      "step": 92000
    },
    {
      "epoch": 3.744952934718523,
      "grad_norm": 0.2657901644706726,
      "learning_rate": 0.0003404373035896074,
      "loss": 0.3556,
      "step": 92100
    },
    {
      "epoch": 3.7490190497489175,
      "grad_norm": 0.27675479650497437,
      "learning_rate": 0.00034021599610498826,
      "loss": 0.3553,
      "step": 92200
    },
    {
      "epoch": 3.7530851647793115,
      "grad_norm": 0.29180577397346497,
      "learning_rate": 0.00033999468862036915,
      "loss": 0.3564,
      "step": 92300
    },
    {
      "epoch": 3.757151279809706,
      "grad_norm": 0.26146289706230164,
      "learning_rate": 0.00033977338113575,
      "loss": 0.3565,
      "step": 92400
    },
    {
      "epoch": 3.7612173948401,
      "grad_norm": 0.26848721504211426,
      "learning_rate": 0.0003395520736511309,
      "loss": 0.3556,
      "step": 92500
    },
    {
      "epoch": 3.7652835098704944,
      "grad_norm": 0.3092047870159149,
      "learning_rate": 0.00033933076616651174,
      "loss": 0.3552,
      "step": 92600
    },
    {
      "epoch": 3.7693496249008884,
      "grad_norm": 0.24618974328041077,
      "learning_rate": 0.00033910945868189263,
      "loss": 0.3571,
      "step": 92700
    },
    {
      "epoch": 3.7734157399312824,
      "grad_norm": 0.2869081199169159,
      "learning_rate": 0.00033888815119727353,
      "loss": 0.3567,
      "step": 92800
    },
    {
      "epoch": 3.777481854961677,
      "grad_norm": 0.30299413204193115,
      "learning_rate": 0.0003386668437126544,
      "loss": 0.3559,
      "step": 92900
    },
    {
      "epoch": 3.7815479699920713,
      "grad_norm": 0.26917892694473267,
      "learning_rate": 0.00033844553622803527,
      "loss": 0.3552,
      "step": 93000
    },
    {
      "epoch": 3.7856140850224653,
      "grad_norm": 0.285204142332077,
      "learning_rate": 0.0003382242287434161,
      "loss": 0.3554,
      "step": 93100
    },
    {
      "epoch": 3.7896802000528593,
      "grad_norm": 0.3271617591381073,
      "learning_rate": 0.000338002921258797,
      "loss": 0.3585,
      "step": 93200
    },
    {
      "epoch": 3.7937463150832538,
      "grad_norm": 0.32422390580177307,
      "learning_rate": 0.00033778161377417786,
      "loss": 0.3568,
      "step": 93300
    },
    {
      "epoch": 3.7978124301136478,
      "grad_norm": 0.2817090153694153,
      "learning_rate": 0.0003375603062895587,
      "loss": 0.3556,
      "step": 93400
    },
    {
      "epoch": 3.801878545144042,
      "grad_norm": 0.30250829458236694,
      "learning_rate": 0.00033733899880493954,
      "loss": 0.3562,
      "step": 93500
    },
    {
      "epoch": 3.8059446601744362,
      "grad_norm": 0.30214452743530273,
      "learning_rate": 0.00033711769132032044,
      "loss": 0.3567,
      "step": 93600
    },
    {
      "epoch": 3.8100107752048307,
      "grad_norm": 0.26539647579193115,
      "learning_rate": 0.00033689638383570134,
      "loss": 0.3541,
      "step": 93700
    },
    {
      "epoch": 3.8140768902352247,
      "grad_norm": 0.2638445496559143,
      "learning_rate": 0.0003366750763510822,
      "loss": 0.3562,
      "step": 93800
    },
    {
      "epoch": 3.818143005265619,
      "grad_norm": 0.33360451459884644,
      "learning_rate": 0.0003364537688664631,
      "loss": 0.3576,
      "step": 93900
    },
    {
      "epoch": 3.822209120296013,
      "grad_norm": 0.2700575590133667,
      "learning_rate": 0.0003362324613818439,
      "loss": 0.3535,
      "step": 94000
    },
    {
      "epoch": 3.822209120296013,
      "eval_loss": 0.36507654190063477,
      "eval_runtime": 129.9469,
      "eval_samples_per_second": 1345.95,
      "eval_steps_per_second": 42.063,
      "step": 94000
    },
    {
      "epoch": 3.826275235326407,
      "grad_norm": 0.2503879964351654,
      "learning_rate": 0.0003360111538972248,
      "loss": 0.3565,
      "step": 94100
    },
    {
      "epoch": 3.8303413503568016,
      "grad_norm": 0.2854170799255371,
      "learning_rate": 0.00033578984641260566,
      "loss": 0.356,
      "step": 94200
    },
    {
      "epoch": 3.834407465387196,
      "grad_norm": 0.2996121644973755,
      "learning_rate": 0.00033556853892798656,
      "loss": 0.3544,
      "step": 94300
    },
    {
      "epoch": 3.83847358041759,
      "grad_norm": 0.26398417353630066,
      "learning_rate": 0.00033534723144336745,
      "loss": 0.3525,
      "step": 94400
    },
    {
      "epoch": 3.842539695447984,
      "grad_norm": 0.28943949937820435,
      "learning_rate": 0.0003351259239587483,
      "loss": 0.3568,
      "step": 94500
    },
    {
      "epoch": 3.8466058104783785,
      "grad_norm": 0.28109580278396606,
      "learning_rate": 0.0003349046164741292,
      "loss": 0.3545,
      "step": 94600
    },
    {
      "epoch": 3.850671925508773,
      "grad_norm": 0.30704551935195923,
      "learning_rate": 0.00033468330898951004,
      "loss": 0.3591,
      "step": 94700
    },
    {
      "epoch": 3.854738040539167,
      "grad_norm": 0.28558072447776794,
      "learning_rate": 0.00033446200150489094,
      "loss": 0.3536,
      "step": 94800
    },
    {
      "epoch": 3.858804155569561,
      "grad_norm": 0.2617025077342987,
      "learning_rate": 0.0003342406940202718,
      "loss": 0.3546,
      "step": 94900
    },
    {
      "epoch": 3.8628702705999554,
      "grad_norm": 0.3218385875225067,
      "learning_rate": 0.0003340193865356527,
      "loss": 0.3558,
      "step": 95000
    },
    {
      "epoch": 3.8669363856303494,
      "grad_norm": 0.4392712712287903,
      "learning_rate": 0.00033379807905103346,
      "loss": 0.3568,
      "step": 95100
    },
    {
      "epoch": 3.871002500660744,
      "grad_norm": 0.3482480049133301,
      "learning_rate": 0.00033357677156641436,
      "loss": 0.354,
      "step": 95200
    },
    {
      "epoch": 3.875068615691138,
      "grad_norm": 0.3044796288013458,
      "learning_rate": 0.00033335546408179526,
      "loss": 0.3536,
      "step": 95300
    },
    {
      "epoch": 3.8791347307215323,
      "grad_norm": 0.2901495099067688,
      "learning_rate": 0.0003331341565971761,
      "loss": 0.3527,
      "step": 95400
    },
    {
      "epoch": 3.8832008457519263,
      "grad_norm": 0.295122355222702,
      "learning_rate": 0.000332912849112557,
      "loss": 0.356,
      "step": 95500
    },
    {
      "epoch": 3.8872669607823207,
      "grad_norm": 0.2850984036922455,
      "learning_rate": 0.00033269154162793784,
      "loss": 0.3554,
      "step": 95600
    },
    {
      "epoch": 3.8913330758127147,
      "grad_norm": 0.265293687582016,
      "learning_rate": 0.00033247023414331874,
      "loss": 0.3548,
      "step": 95700
    },
    {
      "epoch": 3.8953991908431087,
      "grad_norm": 0.2996788024902344,
      "learning_rate": 0.0003322489266586996,
      "loss": 0.3549,
      "step": 95800
    },
    {
      "epoch": 3.899465305873503,
      "grad_norm": 0.26268482208251953,
      "learning_rate": 0.0003320276191740805,
      "loss": 0.3535,
      "step": 95900
    },
    {
      "epoch": 3.9035314209038976,
      "grad_norm": 0.2760375440120697,
      "learning_rate": 0.0003318063116894613,
      "loss": 0.3554,
      "step": 96000
    },
    {
      "epoch": 3.9035314209038976,
      "eval_loss": 0.36517760157585144,
      "eval_runtime": 129.9127,
      "eval_samples_per_second": 1346.304,
      "eval_steps_per_second": 42.074,
      "step": 96000
    },
    {
      "epoch": 3.9075975359342916,
      "grad_norm": 0.29498714208602905,
      "learning_rate": 0.0003315850042048422,
      "loss": 0.3549,
      "step": 96100
    },
    {
      "epoch": 3.9116636509646856,
      "grad_norm": 0.31832584738731384,
      "learning_rate": 0.0003313636967202231,
      "loss": 0.3557,
      "step": 96200
    },
    {
      "epoch": 3.91572976599508,
      "grad_norm": 0.2738988995552063,
      "learning_rate": 0.00033114238923560396,
      "loss": 0.3524,
      "step": 96300
    },
    {
      "epoch": 3.919795881025474,
      "grad_norm": 0.27652570605278015,
      "learning_rate": 0.00033092108175098486,
      "loss": 0.3542,
      "step": 96400
    },
    {
      "epoch": 3.9238619960558685,
      "grad_norm": 0.312551885843277,
      "learning_rate": 0.0003306997742663657,
      "loss": 0.3564,
      "step": 96500
    },
    {
      "epoch": 3.9279281110862625,
      "grad_norm": 0.27584218978881836,
      "learning_rate": 0.0003304784667817466,
      "loss": 0.3544,
      "step": 96600
    },
    {
      "epoch": 3.931994226116657,
      "grad_norm": 0.3069539964199066,
      "learning_rate": 0.00033025715929712744,
      "loss": 0.3542,
      "step": 96700
    },
    {
      "epoch": 3.936060341147051,
      "grad_norm": 0.2858259379863739,
      "learning_rate": 0.0003300358518125083,
      "loss": 0.3551,
      "step": 96800
    },
    {
      "epoch": 3.9401264561774454,
      "grad_norm": 0.2679052948951721,
      "learning_rate": 0.00032981454432788913,
      "loss": 0.3554,
      "step": 96900
    },
    {
      "epoch": 3.9441925712078394,
      "grad_norm": 0.2808164358139038,
      "learning_rate": 0.00032959323684327,
      "loss": 0.3522,
      "step": 97000
    },
    {
      "epoch": 3.948258686238234,
      "grad_norm": 0.29935580492019653,
      "learning_rate": 0.0003293719293586509,
      "loss": 0.3563,
      "step": 97100
    },
    {
      "epoch": 3.952324801268628,
      "grad_norm": 0.2675425708293915,
      "learning_rate": 0.00032915062187403177,
      "loss": 0.357,
      "step": 97200
    },
    {
      "epoch": 3.9563909162990223,
      "grad_norm": 0.30710235238075256,
      "learning_rate": 0.00032892931438941266,
      "loss": 0.356,
      "step": 97300
    },
    {
      "epoch": 3.9604570313294163,
      "grad_norm": 0.3039710819721222,
      "learning_rate": 0.0003287080069047935,
      "loss": 0.3553,
      "step": 97400
    },
    {
      "epoch": 3.9645231463598103,
      "grad_norm": 0.28256818652153015,
      "learning_rate": 0.0003284866994201744,
      "loss": 0.3546,
      "step": 97500
    },
    {
      "epoch": 3.9685892613902047,
      "grad_norm": 0.2642754316329956,
      "learning_rate": 0.00032826539193555525,
      "loss": 0.3554,
      "step": 97600
    },
    {
      "epoch": 3.972655376420599,
      "grad_norm": 0.3109501898288727,
      "learning_rate": 0.00032804408445093614,
      "loss": 0.3571,
      "step": 97700
    },
    {
      "epoch": 3.976721491450993,
      "grad_norm": 0.300586462020874,
      "learning_rate": 0.00032782277696631704,
      "loss": 0.3548,
      "step": 97800
    },
    {
      "epoch": 3.980787606481387,
      "grad_norm": 0.3087998330593109,
      "learning_rate": 0.0003276014694816979,
      "loss": 0.3541,
      "step": 97900
    },
    {
      "epoch": 3.9848537215117816,
      "grad_norm": 0.3044021725654602,
      "learning_rate": 0.0003273801619970788,
      "loss": 0.3562,
      "step": 98000
    },
    {
      "epoch": 3.9848537215117816,
      "eval_loss": 0.3652006983757019,
      "eval_runtime": 131.1663,
      "eval_samples_per_second": 1333.437,
      "eval_steps_per_second": 41.672,
      "step": 98000
    },
    {
      "epoch": 3.9889198365421756,
      "grad_norm": 0.328983873128891,
      "learning_rate": 0.0003271588545124596,
      "loss": 0.3548,
      "step": 98100
    },
    {
      "epoch": 3.99298595157257,
      "grad_norm": 0.3126116693019867,
      "learning_rate": 0.0003269375470278405,
      "loss": 0.3555,
      "step": 98200
    },
    {
      "epoch": 3.997052066602964,
      "grad_norm": 0.2635726034641266,
      "learning_rate": 0.00032671623954322137,
      "loss": 0.3543,
      "step": 98300
    },
    {
      "epoch": 4.001118181633358,
      "grad_norm": 0.27430978417396545,
      "learning_rate": 0.00032649493205860226,
      "loss": 0.3538,
      "step": 98400
    },
    {
      "epoch": 4.005184296663753,
      "grad_norm": 0.2797199785709381,
      "learning_rate": 0.00032627362457398305,
      "loss": 0.3505,
      "step": 98500
    },
    {
      "epoch": 4.009250411694147,
      "grad_norm": 0.3380684554576874,
      "learning_rate": 0.00032605231708936395,
      "loss": 0.3496,
      "step": 98600
    },
    {
      "epoch": 4.013316526724541,
      "grad_norm": 0.3251490890979767,
      "learning_rate": 0.00032583100960474485,
      "loss": 0.3487,
      "step": 98700
    },
    {
      "epoch": 4.017382641754935,
      "grad_norm": 0.2675744593143463,
      "learning_rate": 0.0003256097021201257,
      "loss": 0.3538,
      "step": 98800
    },
    {
      "epoch": 4.02144875678533,
      "grad_norm": 0.2754659652709961,
      "learning_rate": 0.0003253883946355066,
      "loss": 0.3495,
      "step": 98900
    },
    {
      "epoch": 4.025514871815724,
      "grad_norm": 0.27840086817741394,
      "learning_rate": 0.00032516708715088743,
      "loss": 0.3489,
      "step": 99000
    },
    {
      "epoch": 4.029580986846118,
      "grad_norm": 0.2841302454471588,
      "learning_rate": 0.00032494577966626833,
      "loss": 0.3517,
      "step": 99100
    },
    {
      "epoch": 4.033647101876512,
      "grad_norm": 0.34165245294570923,
      "learning_rate": 0.00032472447218164917,
      "loss": 0.3505,
      "step": 99200
    },
    {
      "epoch": 4.037713216906906,
      "grad_norm": 0.48190417885780334,
      "learning_rate": 0.00032450316469703007,
      "loss": 0.3493,
      "step": 99300
    },
    {
      "epoch": 4.041779331937301,
      "grad_norm": 0.3187110126018524,
      "learning_rate": 0.0003242818572124109,
      "loss": 0.3536,
      "step": 99400
    },
    {
      "epoch": 4.045845446967695,
      "grad_norm": 0.33754435181617737,
      "learning_rate": 0.0003240605497277918,
      "loss": 0.3524,
      "step": 99500
    },
    {
      "epoch": 4.049911561998089,
      "grad_norm": 0.2758408486843109,
      "learning_rate": 0.0003238392422431727,
      "loss": 0.3502,
      "step": 99600
    },
    {
      "epoch": 4.053977677028483,
      "grad_norm": 0.30288001894950867,
      "learning_rate": 0.00032361793475855355,
      "loss": 0.3527,
      "step": 99700
    },
    {
      "epoch": 4.058043792058878,
      "grad_norm": 0.3202880322933197,
      "learning_rate": 0.00032339662727393445,
      "loss": 0.3499,
      "step": 99800
    },
    {
      "epoch": 4.062109907089272,
      "grad_norm": 0.32649004459381104,
      "learning_rate": 0.0003231753197893153,
      "loss": 0.3517,
      "step": 99900
    },
    {
      "epoch": 4.066176022119666,
      "grad_norm": 0.26730218529701233,
      "learning_rate": 0.0003229540123046962,
      "loss": 0.3521,
      "step": 100000
    },
    {
      "epoch": 4.066176022119666,
      "eval_loss": 0.3643819987773895,
      "eval_runtime": 130.2972,
      "eval_samples_per_second": 1342.331,
      "eval_steps_per_second": 41.95,
      "step": 100000
    },
    {
      "epoch": 4.07024213715006,
      "grad_norm": 0.39045003056526184,
      "learning_rate": 0.000322732704820077,
      "loss": 0.3499,
      "step": 100100
    },
    {
      "epoch": 4.074308252180455,
      "grad_norm": 0.265706330537796,
      "learning_rate": 0.0003225113973354579,
      "loss": 0.3494,
      "step": 100200
    },
    {
      "epoch": 4.078374367210849,
      "grad_norm": 0.3380136787891388,
      "learning_rate": 0.0003222900898508387,
      "loss": 0.3517,
      "step": 100300
    },
    {
      "epoch": 4.082440482241243,
      "grad_norm": 0.27470558881759644,
      "learning_rate": 0.0003220687823662196,
      "loss": 0.3528,
      "step": 100400
    },
    {
      "epoch": 4.086506597271637,
      "grad_norm": 0.26081418991088867,
      "learning_rate": 0.0003218474748816005,
      "loss": 0.3513,
      "step": 100500
    },
    {
      "epoch": 4.0905727123020315,
      "grad_norm": 0.2734392583370209,
      "learning_rate": 0.00032162616739698135,
      "loss": 0.351,
      "step": 100600
    },
    {
      "epoch": 4.0946388273324255,
      "grad_norm": 0.309369295835495,
      "learning_rate": 0.00032140485991236225,
      "loss": 0.3522,
      "step": 100700
    },
    {
      "epoch": 4.0987049423628195,
      "grad_norm": 0.2990829646587372,
      "learning_rate": 0.0003211835524277431,
      "loss": 0.3504,
      "step": 100800
    },
    {
      "epoch": 4.1027710573932135,
      "grad_norm": 0.3086282014846802,
      "learning_rate": 0.000320962244943124,
      "loss": 0.3505,
      "step": 100900
    },
    {
      "epoch": 4.1068371724236075,
      "grad_norm": 0.3163546621799469,
      "learning_rate": 0.00032074093745850484,
      "loss": 0.352,
      "step": 101000
    },
    {
      "epoch": 4.110903287454002,
      "grad_norm": 0.3130427896976471,
      "learning_rate": 0.00032051962997388573,
      "loss": 0.3528,
      "step": 101100
    },
    {
      "epoch": 4.114969402484396,
      "grad_norm": 0.3481176793575287,
      "learning_rate": 0.0003202983224892666,
      "loss": 0.3499,
      "step": 101200
    },
    {
      "epoch": 4.11903551751479,
      "grad_norm": 0.29791775345802307,
      "learning_rate": 0.00032007701500464747,
      "loss": 0.3504,
      "step": 101300
    },
    {
      "epoch": 4.123101632545184,
      "grad_norm": 0.3217977285385132,
      "learning_rate": 0.00031985570752002837,
      "loss": 0.3514,
      "step": 101400
    },
    {
      "epoch": 4.127167747575579,
      "grad_norm": 0.28026092052459717,
      "learning_rate": 0.0003196344000354092,
      "loss": 0.3515,
      "step": 101500
    },
    {
      "epoch": 4.131233862605973,
      "grad_norm": 0.33783629536628723,
      "learning_rate": 0.0003194130925507901,
      "loss": 0.3512,
      "step": 101600
    },
    {
      "epoch": 4.135299977636367,
      "grad_norm": 0.3017934262752533,
      "learning_rate": 0.00031919178506617095,
      "loss": 0.3501,
      "step": 101700
    },
    {
      "epoch": 4.139366092666761,
      "grad_norm": 0.27796196937561035,
      "learning_rate": 0.0003189704775815518,
      "loss": 0.353,
      "step": 101800
    },
    {
      "epoch": 4.143432207697156,
      "grad_norm": 0.31518757343292236,
      "learning_rate": 0.00031874917009693264,
      "loss": 0.352,
      "step": 101900
    },
    {
      "epoch": 4.14749832272755,
      "grad_norm": 0.3165661096572876,
      "learning_rate": 0.00031852786261231354,
      "loss": 0.3498,
      "step": 102000
    },
    {
      "epoch": 4.14749832272755,
      "eval_loss": 0.36384880542755127,
      "eval_runtime": 130.6782,
      "eval_samples_per_second": 1338.418,
      "eval_steps_per_second": 41.828,
      "step": 102000
    },
    {
      "epoch": 4.151564437757944,
      "grad_norm": 0.322576105594635,
      "learning_rate": 0.00031830655512769443,
      "loss": 0.3519,
      "step": 102100
    },
    {
      "epoch": 4.155630552788338,
      "grad_norm": 0.28420886397361755,
      "learning_rate": 0.0003180852476430753,
      "loss": 0.3521,
      "step": 102200
    },
    {
      "epoch": 4.159696667818732,
      "grad_norm": 0.3752056062221527,
      "learning_rate": 0.0003178639401584562,
      "loss": 0.3504,
      "step": 102300
    },
    {
      "epoch": 4.163762782849127,
      "grad_norm": 0.2819570302963257,
      "learning_rate": 0.000317642632673837,
      "loss": 0.3504,
      "step": 102400
    },
    {
      "epoch": 4.167828897879521,
      "grad_norm": 0.30629342794418335,
      "learning_rate": 0.0003174213251892179,
      "loss": 0.3501,
      "step": 102500
    },
    {
      "epoch": 4.171895012909915,
      "grad_norm": 0.32528871297836304,
      "learning_rate": 0.00031720001770459876,
      "loss": 0.3503,
      "step": 102600
    },
    {
      "epoch": 4.175961127940309,
      "grad_norm": 0.35355237126350403,
      "learning_rate": 0.00031697871021997966,
      "loss": 0.3498,
      "step": 102700
    },
    {
      "epoch": 4.180027242970704,
      "grad_norm": 0.2650398015975952,
      "learning_rate": 0.0003167574027353605,
      "loss": 0.3507,
      "step": 102800
    },
    {
      "epoch": 4.184093358001098,
      "grad_norm": 0.270354300737381,
      "learning_rate": 0.0003165360952507414,
      "loss": 0.3529,
      "step": 102900
    },
    {
      "epoch": 4.188159473031492,
      "grad_norm": 0.32839399576187134,
      "learning_rate": 0.0003163147877661223,
      "loss": 0.3504,
      "step": 103000
    },
    {
      "epoch": 4.192225588061886,
      "grad_norm": 0.29122981429100037,
      "learning_rate": 0.00031609348028150314,
      "loss": 0.3539,
      "step": 103100
    },
    {
      "epoch": 4.196291703092281,
      "grad_norm": 0.3240492641925812,
      "learning_rate": 0.00031587217279688403,
      "loss": 0.3521,
      "step": 103200
    },
    {
      "epoch": 4.200357818122675,
      "grad_norm": 0.2754482626914978,
      "learning_rate": 0.0003156508653122649,
      "loss": 0.3486,
      "step": 103300
    },
    {
      "epoch": 4.204423933153069,
      "grad_norm": 0.3160744309425354,
      "learning_rate": 0.0003154295578276458,
      "loss": 0.3503,
      "step": 103400
    },
    {
      "epoch": 4.208490048183463,
      "grad_norm": 0.2874707281589508,
      "learning_rate": 0.00031520825034302656,
      "loss": 0.3505,
      "step": 103500
    },
    {
      "epoch": 4.212556163213858,
      "grad_norm": 0.3194707930088043,
      "learning_rate": 0.00031498694285840746,
      "loss": 0.3502,
      "step": 103600
    },
    {
      "epoch": 4.216622278244252,
      "grad_norm": 0.3631812632083893,
      "learning_rate": 0.0003147656353737883,
      "loss": 0.3506,
      "step": 103700
    },
    {
      "epoch": 4.220688393274646,
      "grad_norm": 0.3608229458332062,
      "learning_rate": 0.0003145443278891692,
      "loss": 0.351,
      "step": 103800
    },
    {
      "epoch": 4.22475450830504,
      "grad_norm": 0.27594098448753357,
      "learning_rate": 0.0003143230204045501,
      "loss": 0.3517,
      "step": 103900
    },
    {
      "epoch": 4.228820623335434,
      "grad_norm": 0.31477686762809753,
      "learning_rate": 0.00031410171291993094,
      "loss": 0.3536,
      "step": 104000
    },
    {
      "epoch": 4.228820623335434,
      "eval_loss": 0.3627967834472656,
      "eval_runtime": 129.5872,
      "eval_samples_per_second": 1349.686,
      "eval_steps_per_second": 42.18,
      "step": 104000
    },
    {
      "epoch": 4.232886738365829,
      "grad_norm": 0.3179701268672943,
      "learning_rate": 0.00031388040543531184,
      "loss": 0.3522,
      "step": 104100
    },
    {
      "epoch": 4.236952853396223,
      "grad_norm": 0.3331955075263977,
      "learning_rate": 0.0003136590979506927,
      "loss": 0.353,
      "step": 104200
    },
    {
      "epoch": 4.241018968426617,
      "grad_norm": 0.28882068395614624,
      "learning_rate": 0.0003134377904660736,
      "loss": 0.3523,
      "step": 104300
    },
    {
      "epoch": 4.245085083457011,
      "grad_norm": 0.30853477120399475,
      "learning_rate": 0.0003132164829814544,
      "loss": 0.3523,
      "step": 104400
    },
    {
      "epoch": 4.2491511984874055,
      "grad_norm": 0.2768811583518982,
      "learning_rate": 0.0003129951754968353,
      "loss": 0.3508,
      "step": 104500
    },
    {
      "epoch": 4.2532173135177995,
      "grad_norm": 0.3064699172973633,
      "learning_rate": 0.00031277386801221616,
      "loss": 0.3532,
      "step": 104600
    },
    {
      "epoch": 4.2572834285481935,
      "grad_norm": 0.3360990285873413,
      "learning_rate": 0.00031255256052759706,
      "loss": 0.3521,
      "step": 104700
    },
    {
      "epoch": 4.2613495435785875,
      "grad_norm": 0.31280916929244995,
      "learning_rate": 0.00031233125304297796,
      "loss": 0.3501,
      "step": 104800
    },
    {
      "epoch": 4.265415658608982,
      "grad_norm": 0.30298998951911926,
      "learning_rate": 0.0003121099455583588,
      "loss": 0.3502,
      "step": 104900
    },
    {
      "epoch": 4.269481773639376,
      "grad_norm": 0.2884793281555176,
      "learning_rate": 0.0003118886380737397,
      "loss": 0.3531,
      "step": 105000
    },
    {
      "epoch": 4.27354788866977,
      "grad_norm": 0.34907811880111694,
      "learning_rate": 0.00031166733058912054,
      "loss": 0.3521,
      "step": 105100
    },
    {
      "epoch": 4.277614003700164,
      "grad_norm": 0.3017675280570984,
      "learning_rate": 0.0003114460231045014,
      "loss": 0.3513,
      "step": 105200
    },
    {
      "epoch": 4.281680118730559,
      "grad_norm": 0.3118022382259369,
      "learning_rate": 0.00031122471561988223,
      "loss": 0.3516,
      "step": 105300
    },
    {
      "epoch": 4.285746233760953,
      "grad_norm": 0.29986050724983215,
      "learning_rate": 0.0003110034081352631,
      "loss": 0.3497,
      "step": 105400
    },
    {
      "epoch": 4.289812348791347,
      "grad_norm": 0.3146778643131256,
      "learning_rate": 0.000310782100650644,
      "loss": 0.349,
      "step": 105500
    },
    {
      "epoch": 4.293878463821741,
      "grad_norm": 0.2803697884082794,
      "learning_rate": 0.00031056079316602487,
      "loss": 0.35,
      "step": 105600
    },
    {
      "epoch": 4.297944578852135,
      "grad_norm": 0.4064933657646179,
      "learning_rate": 0.00031033948568140576,
      "loss": 0.3512,
      "step": 105700
    },
    {
      "epoch": 4.30201069388253,
      "grad_norm": 0.3427734673023224,
      "learning_rate": 0.0003101181781967866,
      "loss": 0.3521,
      "step": 105800
    },
    {
      "epoch": 4.306076808912924,
      "grad_norm": 0.29136714339256287,
      "learning_rate": 0.0003098968707121675,
      "loss": 0.3525,
      "step": 105900
    },
    {
      "epoch": 4.310142923943318,
      "grad_norm": 0.32927078008651733,
      "learning_rate": 0.00030967556322754835,
      "loss": 0.3526,
      "step": 106000
    },
    {
      "epoch": 4.310142923943318,
      "eval_loss": 0.3632955253124237,
      "eval_runtime": 129.8236,
      "eval_samples_per_second": 1347.228,
      "eval_steps_per_second": 42.103,
      "step": 106000
    },
    {
      "epoch": 4.314209038973712,
      "grad_norm": 0.3318363428115845,
      "learning_rate": 0.00030945425574292924,
      "loss": 0.3518,
      "step": 106100
    },
    {
      "epoch": 4.318275154004107,
      "grad_norm": 0.3017255961894989,
      "learning_rate": 0.0003092329482583101,
      "loss": 0.352,
      "step": 106200
    },
    {
      "epoch": 4.322341269034501,
      "grad_norm": 0.27899521589279175,
      "learning_rate": 0.000309011640773691,
      "loss": 0.3494,
      "step": 106300
    },
    {
      "epoch": 4.326407384064895,
      "grad_norm": 0.3285743296146393,
      "learning_rate": 0.0003087903332890719,
      "loss": 0.3484,
      "step": 106400
    },
    {
      "epoch": 4.330473499095289,
      "grad_norm": 0.331453800201416,
      "learning_rate": 0.0003085690258044527,
      "loss": 0.3508,
      "step": 106500
    },
    {
      "epoch": 4.334539614125684,
      "grad_norm": 0.3189202845096588,
      "learning_rate": 0.0003083477183198336,
      "loss": 0.3494,
      "step": 106600
    },
    {
      "epoch": 4.338605729156078,
      "grad_norm": 0.26253142952919006,
      "learning_rate": 0.00030812641083521446,
      "loss": 0.3526,
      "step": 106700
    },
    {
      "epoch": 4.342671844186472,
      "grad_norm": 0.3176216185092926,
      "learning_rate": 0.00030790510335059536,
      "loss": 0.3533,
      "step": 106800
    },
    {
      "epoch": 4.346737959216866,
      "grad_norm": 0.31003379821777344,
      "learning_rate": 0.00030768379586597615,
      "loss": 0.3534,
      "step": 106900
    },
    {
      "epoch": 4.350804074247261,
      "grad_norm": 0.30696502327919006,
      "learning_rate": 0.00030746248838135705,
      "loss": 0.3525,
      "step": 107000
    },
    {
      "epoch": 4.354870189277655,
      "grad_norm": 0.332356721162796,
      "learning_rate": 0.0003072411808967379,
      "loss": 0.3544,
      "step": 107100
    },
    {
      "epoch": 4.358936304308049,
      "grad_norm": 0.3328434228897095,
      "learning_rate": 0.0003070198734121188,
      "loss": 0.3527,
      "step": 107200
    },
    {
      "epoch": 4.363002419338443,
      "grad_norm": 0.2951268255710602,
      "learning_rate": 0.0003067985659274997,
      "loss": 0.3515,
      "step": 107300
    },
    {
      "epoch": 4.367068534368837,
      "grad_norm": 0.31448954343795776,
      "learning_rate": 0.00030657725844288053,
      "loss": 0.3537,
      "step": 107400
    },
    {
      "epoch": 4.371134649399232,
      "grad_norm": 0.3826836347579956,
      "learning_rate": 0.0003063559509582614,
      "loss": 0.3537,
      "step": 107500
    },
    {
      "epoch": 4.375200764429626,
      "grad_norm": 0.28066498041152954,
      "learning_rate": 0.00030613464347364227,
      "loss": 0.3514,
      "step": 107600
    },
    {
      "epoch": 4.37926687946002,
      "grad_norm": 0.31716856360435486,
      "learning_rate": 0.00030591333598902317,
      "loss": 0.3496,
      "step": 107700
    },
    {
      "epoch": 4.383332994490414,
      "grad_norm": 0.29596614837646484,
      "learning_rate": 0.000305692028504404,
      "loss": 0.3513,
      "step": 107800
    },
    {
      "epoch": 4.387399109520809,
      "grad_norm": 0.2670065462589264,
      "learning_rate": 0.0003054707210197849,
      "loss": 0.3519,
      "step": 107900
    },
    {
      "epoch": 4.391465224551203,
      "grad_norm": 0.34445104002952576,
      "learning_rate": 0.00030524941353516575,
      "loss": 0.3507,
      "step": 108000
    },
    {
      "epoch": 4.391465224551203,
      "eval_loss": 0.3623727262020111,
      "eval_runtime": 130.9497,
      "eval_samples_per_second": 1335.643,
      "eval_steps_per_second": 41.741,
      "step": 108000
    },
    {
      "epoch": 4.395531339581597,
      "grad_norm": 0.3668009638786316,
      "learning_rate": 0.00030502810605054665,
      "loss": 0.3508,
      "step": 108100
    },
    {
      "epoch": 4.399597454611991,
      "grad_norm": 0.3611549139022827,
      "learning_rate": 0.00030480679856592755,
      "loss": 0.3518,
      "step": 108200
    },
    {
      "epoch": 4.403663569642386,
      "grad_norm": 0.3260423243045807,
      "learning_rate": 0.0003045854910813084,
      "loss": 0.3519,
      "step": 108300
    },
    {
      "epoch": 4.40772968467278,
      "grad_norm": 0.2717045843601227,
      "learning_rate": 0.0003043641835966893,
      "loss": 0.3515,
      "step": 108400
    },
    {
      "epoch": 4.411795799703174,
      "grad_norm": 0.2847558856010437,
      "learning_rate": 0.00030414287611207013,
      "loss": 0.352,
      "step": 108500
    },
    {
      "epoch": 4.415861914733568,
      "grad_norm": 0.303141713142395,
      "learning_rate": 0.00030392156862745097,
      "loss": 0.3505,
      "step": 108600
    },
    {
      "epoch": 4.4199280297639625,
      "grad_norm": 0.3270286023616791,
      "learning_rate": 0.0003037002611428318,
      "loss": 0.3515,
      "step": 108700
    },
    {
      "epoch": 4.4239941447943565,
      "grad_norm": 0.38991332054138184,
      "learning_rate": 0.0003034789536582127,
      "loss": 0.3518,
      "step": 108800
    },
    {
      "epoch": 4.4280602598247505,
      "grad_norm": 0.32200267910957336,
      "learning_rate": 0.00030325764617359356,
      "loss": 0.3514,
      "step": 108900
    },
    {
      "epoch": 4.4321263748551445,
      "grad_norm": 0.31835636496543884,
      "learning_rate": 0.00030303633868897445,
      "loss": 0.352,
      "step": 109000
    },
    {
      "epoch": 4.4361924898855385,
      "grad_norm": 0.2900804281234741,
      "learning_rate": 0.00030281503120435535,
      "loss": 0.3534,
      "step": 109100
    },
    {
      "epoch": 4.440258604915933,
      "grad_norm": 0.316383421421051,
      "learning_rate": 0.0003025937237197362,
      "loss": 0.3509,
      "step": 109200
    },
    {
      "epoch": 4.444324719946327,
      "grad_norm": 0.27746590971946716,
      "learning_rate": 0.0003023724162351171,
      "loss": 0.352,
      "step": 109300
    },
    {
      "epoch": 4.448390834976721,
      "grad_norm": 0.32614246010780334,
      "learning_rate": 0.00030215110875049793,
      "loss": 0.35,
      "step": 109400
    },
    {
      "epoch": 4.452456950007115,
      "grad_norm": 0.35454773902893066,
      "learning_rate": 0.00030192980126587883,
      "loss": 0.3498,
      "step": 109500
    },
    {
      "epoch": 4.45652306503751,
      "grad_norm": 0.3459216058254242,
      "learning_rate": 0.0003017084937812597,
      "loss": 0.3518,
      "step": 109600
    },
    {
      "epoch": 4.460589180067904,
      "grad_norm": 0.35239848494529724,
      "learning_rate": 0.00030148718629664057,
      "loss": 0.3494,
      "step": 109700
    },
    {
      "epoch": 4.464655295098298,
      "grad_norm": 0.32331016659736633,
      "learning_rate": 0.00030126587881202147,
      "loss": 0.3502,
      "step": 109800
    },
    {
      "epoch": 4.468721410128692,
      "grad_norm": 0.2878569960594177,
      "learning_rate": 0.0003010445713274023,
      "loss": 0.3511,
      "step": 109900
    },
    {
      "epoch": 4.472787525159086,
      "grad_norm": 0.31412434577941895,
      "learning_rate": 0.0003008232638427832,
      "loss": 0.3516,
      "step": 110000
    },
    {
      "epoch": 4.472787525159086,
      "eval_loss": 0.36223992705345154,
      "eval_runtime": 130.646,
      "eval_samples_per_second": 1338.747,
      "eval_steps_per_second": 41.838,
      "step": 110000
    },
    {
      "epoch": 4.476853640189481,
      "grad_norm": 0.3011798560619354,
      "learning_rate": 0.00030060195635816405,
      "loss": 0.3503,
      "step": 110100
    },
    {
      "epoch": 4.480919755219875,
      "grad_norm": 0.3255597651004791,
      "learning_rate": 0.00030038064887354495,
      "loss": 0.3538,
      "step": 110200
    },
    {
      "epoch": 4.484985870250269,
      "grad_norm": 0.29508399963378906,
      "learning_rate": 0.00030015934138892574,
      "loss": 0.3522,
      "step": 110300
    },
    {
      "epoch": 4.489051985280663,
      "grad_norm": 0.3457852602005005,
      "learning_rate": 0.00029993803390430664,
      "loss": 0.3512,
      "step": 110400
    },
    {
      "epoch": 4.493118100311058,
      "grad_norm": 0.4111732840538025,
      "learning_rate": 0.0002997167264196875,
      "loss": 0.3524,
      "step": 110500
    },
    {
      "epoch": 4.497184215341452,
      "grad_norm": 0.3126806616783142,
      "learning_rate": 0.0002994954189350684,
      "loss": 0.3519,
      "step": 110600
    },
    {
      "epoch": 4.501250330371846,
      "grad_norm": 0.3518052399158478,
      "learning_rate": 0.0002992741114504493,
      "loss": 0.3525,
      "step": 110700
    },
    {
      "epoch": 4.50531644540224,
      "grad_norm": 0.38624995946884155,
      "learning_rate": 0.0002990528039658301,
      "loss": 0.3491,
      "step": 110800
    },
    {
      "epoch": 4.509382560432635,
      "grad_norm": 0.34930360317230225,
      "learning_rate": 0.000298831496481211,
      "loss": 0.3503,
      "step": 110900
    },
    {
      "epoch": 4.513448675463029,
      "grad_norm": 0.3094730079174042,
      "learning_rate": 0.00029861018899659186,
      "loss": 0.3517,
      "step": 111000
    },
    {
      "epoch": 4.517514790493423,
      "grad_norm": 0.30480584502220154,
      "learning_rate": 0.00029838888151197275,
      "loss": 0.3523,
      "step": 111100
    },
    {
      "epoch": 4.521580905523817,
      "grad_norm": 0.34319090843200684,
      "learning_rate": 0.0002981675740273536,
      "loss": 0.3493,
      "step": 111200
    },
    {
      "epoch": 4.525647020554212,
      "grad_norm": 0.2887651026248932,
      "learning_rate": 0.0002979462665427345,
      "loss": 0.3515,
      "step": 111300
    },
    {
      "epoch": 4.529713135584606,
      "grad_norm": 0.2938188910484314,
      "learning_rate": 0.00029772495905811534,
      "loss": 0.3497,
      "step": 111400
    },
    {
      "epoch": 4.533779250615,
      "grad_norm": 0.31123605370521545,
      "learning_rate": 0.00029750365157349624,
      "loss": 0.3518,
      "step": 111500
    },
    {
      "epoch": 4.537845365645394,
      "grad_norm": 0.30498164892196655,
      "learning_rate": 0.00029728234408887713,
      "loss": 0.3511,
      "step": 111600
    },
    {
      "epoch": 4.541911480675788,
      "grad_norm": 0.30291956663131714,
      "learning_rate": 0.000297061036604258,
      "loss": 0.3518,
      "step": 111700
    },
    {
      "epoch": 4.545977595706183,
      "grad_norm": 0.29854536056518555,
      "learning_rate": 0.0002968397291196389,
      "loss": 0.3503,
      "step": 111800
    },
    {
      "epoch": 4.550043710736577,
      "grad_norm": 0.28720369935035706,
      "learning_rate": 0.00029661842163501966,
      "loss": 0.3511,
      "step": 111900
    },
    {
      "epoch": 4.554109825766971,
      "grad_norm": 0.30657854676246643,
      "learning_rate": 0.00029639711415040056,
      "loss": 0.3506,
      "step": 112000
    },
    {
      "epoch": 4.554109825766971,
      "eval_loss": 0.3617372512817383,
      "eval_runtime": 130.2027,
      "eval_samples_per_second": 1343.306,
      "eval_steps_per_second": 41.981,
      "step": 112000
    },
    {
      "epoch": 4.558196271372517,
      "grad_norm": 0.358183890581131,
      "learning_rate": 0.0002961758066657814,
      "loss": 0.3522,
      "step": 112100
    },
    {
      "epoch": 4.562262386402911,
      "grad_norm": 0.3110891282558441,
      "learning_rate": 0.0002959544991811623,
      "loss": 0.3517,
      "step": 112200
    },
    {
      "epoch": 4.566328501433306,
      "grad_norm": 0.28574562072753906,
      "learning_rate": 0.00029573319169654314,
      "loss": 0.3526,
      "step": 112300
    },
    {
      "epoch": 4.5703946164637,
      "grad_norm": 0.35261034965515137,
      "learning_rate": 0.00029551188421192404,
      "loss": 0.348,
      "step": 112400
    },
    {
      "epoch": 4.574460731494094,
      "grad_norm": 0.3933770954608917,
      "learning_rate": 0.00029529057672730494,
      "loss": 0.3483,
      "step": 112500
    },
    {
      "epoch": 4.578526846524488,
      "grad_norm": 0.3587404191493988,
      "learning_rate": 0.0002950692692426858,
      "loss": 0.3514,
      "step": 112600
    },
    {
      "epoch": 4.582592961554882,
      "grad_norm": 0.3475402891635895,
      "learning_rate": 0.0002948479617580667,
      "loss": 0.352,
      "step": 112700
    },
    {
      "epoch": 4.586659076585277,
      "grad_norm": 0.3451210856437683,
      "learning_rate": 0.0002946266542734475,
      "loss": 0.3521,
      "step": 112800
    },
    {
      "epoch": 4.590725191615671,
      "grad_norm": 0.3259825110435486,
      "learning_rate": 0.0002944053467888284,
      "loss": 0.3508,
      "step": 112900
    },
    {
      "epoch": 4.594791306646065,
      "grad_norm": 0.3007763624191284,
      "learning_rate": 0.00029418403930420926,
      "loss": 0.3514,
      "step": 113000
    },
    {
      "epoch": 4.59885742167646,
      "grad_norm": 0.4569994807243347,
      "learning_rate": 0.00029396273181959016,
      "loss": 0.3497,
      "step": 113100
    },
    {
      "epoch": 4.602923536706854,
      "grad_norm": 0.32986748218536377,
      "learning_rate": 0.00029374142433497106,
      "loss": 0.3504,
      "step": 113200
    },
    {
      "epoch": 4.606989651737248,
      "grad_norm": 0.32669106125831604,
      "learning_rate": 0.0002935201168503519,
      "loss": 0.3499,
      "step": 113300
    },
    {
      "epoch": 4.611055766767642,
      "grad_norm": 0.3461970090866089,
      "learning_rate": 0.0002932988093657328,
      "loss": 0.3506,
      "step": 113400
    },
    {
      "epoch": 4.615121881798036,
      "grad_norm": 0.3133908808231354,
      "learning_rate": 0.00029307750188111364,
      "loss": 0.3515,
      "step": 113500
    },
    {
      "epoch": 4.619187996828431,
      "grad_norm": 0.3199079930782318,
      "learning_rate": 0.0002928561943964945,
      "loss": 0.3518,
      "step": 113600
    },
    {
      "epoch": 4.623254111858825,
      "grad_norm": 0.3183455765247345,
      "learning_rate": 0.0002926348869118753,
      "loss": 0.351,
      "step": 113700
    },
    {
      "epoch": 4.627320226889219,
      "grad_norm": 0.3312700688838959,
      "learning_rate": 0.0002924135794272562,
      "loss": 0.3497,
      "step": 113800
    },
    {
      "epoch": 4.631386341919613,
      "grad_norm": 0.339079350233078,
      "learning_rate": 0.00029219227194263707,
      "loss": 0.3501,
      "step": 113900
    },
    {
      "epoch": 4.6354524569500075,
      "grad_norm": 0.3552071154117584,
      "learning_rate": 0.00029197096445801796,
      "loss": 0.3525,
      "step": 114000
    },
    {
      "epoch": 4.6354524569500075,
      "eval_loss": 0.3618219196796417,
      "eval_runtime": 125.932,
      "eval_samples_per_second": 1388.861,
      "eval_steps_per_second": 43.404,
      "step": 114000
    },
    {
      "epoch": 4.6395185719804015,
      "grad_norm": 0.27942129969596863,
      "learning_rate": 0.00029174965697339886,
      "loss": 0.3499,
      "step": 114100
    },
    {
      "epoch": 4.6435846870107955,
      "grad_norm": 0.2992585599422455,
      "learning_rate": 0.0002915283494887797,
      "loss": 0.3525,
      "step": 114200
    },
    {
      "epoch": 4.6476508020411895,
      "grad_norm": 0.3520433306694031,
      "learning_rate": 0.0002913070420041606,
      "loss": 0.3512,
      "step": 114300
    },
    {
      "epoch": 4.6517169170715835,
      "grad_norm": 0.3756228983402252,
      "learning_rate": 0.00029108573451954144,
      "loss": 0.3512,
      "step": 114400
    },
    {
      "epoch": 4.655783032101978,
      "grad_norm": 0.3116941452026367,
      "learning_rate": 0.00029086442703492234,
      "loss": 0.3492,
      "step": 114500
    },
    {
      "epoch": 4.659849147132372,
      "grad_norm": 0.4009225368499756,
      "learning_rate": 0.0002906431195503032,
      "loss": 0.3514,
      "step": 114600
    },
    {
      "epoch": 4.663915262162766,
      "grad_norm": 0.35623839497566223,
      "learning_rate": 0.0002904218120656841,
      "loss": 0.3486,
      "step": 114700
    },
    {
      "epoch": 4.66798137719316,
      "grad_norm": 0.29009997844696045,
      "learning_rate": 0.0002902005045810649,
      "loss": 0.3523,
      "step": 114800
    },
    {
      "epoch": 4.672047492223555,
      "grad_norm": 0.3654971420764923,
      "learning_rate": 0.0002899791970964458,
      "loss": 0.3494,
      "step": 114900
    },
    {
      "epoch": 4.676113607253949,
      "grad_norm": 0.3216528594493866,
      "learning_rate": 0.0002897578896118267,
      "loss": 0.3489,
      "step": 115000
    },
    {
      "epoch": 4.680179722284343,
      "grad_norm": 0.39085420966148376,
      "learning_rate": 0.00028953658212720756,
      "loss": 0.3473,
      "step": 115100
    },
    {
      "epoch": 4.684245837314737,
      "grad_norm": 0.31615519523620605,
      "learning_rate": 0.00028931527464258846,
      "loss": 0.3505,
      "step": 115200
    },
    {
      "epoch": 4.688311952345132,
      "grad_norm": 0.37589725852012634,
      "learning_rate": 0.00028909396715796925,
      "loss": 0.3496,
      "step": 115300
    },
    {
      "epoch": 4.692378067375526,
      "grad_norm": 0.4945947229862213,
      "learning_rate": 0.00028887265967335015,
      "loss": 0.3511,
      "step": 115400
    },
    {
      "epoch": 4.69644418240592,
      "grad_norm": 0.3495705723762512,
      "learning_rate": 0.000288651352188731,
      "loss": 0.3507,
      "step": 115500
    },
    {
      "epoch": 4.700510297436314,
      "grad_norm": 0.39717039465904236,
      "learning_rate": 0.0002884300447041119,
      "loss": 0.3517,
      "step": 115600
    },
    {
      "epoch": 4.704576412466709,
      "grad_norm": 0.3689662516117096,
      "learning_rate": 0.00028820873721949273,
      "loss": 0.3497,
      "step": 115700
    },
    {
      "epoch": 4.708642527497103,
      "grad_norm": 0.3687822222709656,
      "learning_rate": 0.00028798742973487363,
      "loss": 0.3496,
      "step": 115800
    },
    {
      "epoch": 4.712708642527497,
      "grad_norm": 0.4202622175216675,
      "learning_rate": 0.0002877661222502545,
      "loss": 0.3501,
      "step": 115900
    },
    {
      "epoch": 4.716774757557891,
      "grad_norm": 0.45895808935165405,
      "learning_rate": 0.00028754481476563537,
      "loss": 0.3516,
      "step": 116000
    },
    {
      "epoch": 4.716774757557891,
      "eval_loss": 0.3614359200000763,
      "eval_runtime": 124.3402,
      "eval_samples_per_second": 1406.64,
      "eval_steps_per_second": 43.96,
      "step": 116000
    },
    {
      "epoch": 4.720840872588285,
      "grad_norm": 0.3437325060367584,
      "learning_rate": 0.00028732350728101627,
      "loss": 0.3504,
      "step": 116100
    },
    {
      "epoch": 4.72490698761868,
      "grad_norm": 0.32053807377815247,
      "learning_rate": 0.0002871021997963971,
      "loss": 0.3492,
      "step": 116200
    },
    {
      "epoch": 4.728973102649074,
      "grad_norm": 0.4071277379989624,
      "learning_rate": 0.000286880892311778,
      "loss": 0.3494,
      "step": 116300
    },
    {
      "epoch": 4.733039217679468,
      "grad_norm": 0.33451709151268005,
      "learning_rate": 0.00028665958482715885,
      "loss": 0.3519,
      "step": 116400
    },
    {
      "epoch": 4.737105332709862,
      "grad_norm": 0.3290881812572479,
      "learning_rate": 0.00028643827734253975,
      "loss": 0.3495,
      "step": 116500
    },
    {
      "epoch": 4.741171447740257,
      "grad_norm": 0.3685685992240906,
      "learning_rate": 0.00028621696985792064,
      "loss": 0.35,
      "step": 116600
    },
    {
      "epoch": 4.745237562770651,
      "grad_norm": 0.2983976900577545,
      "learning_rate": 0.0002859956623733015,
      "loss": 0.3505,
      "step": 116700
    },
    {
      "epoch": 4.749303677801045,
      "grad_norm": 0.3284975588321686,
      "learning_rate": 0.0002857743548886824,
      "loss": 0.3518,
      "step": 116800
    },
    {
      "epoch": 4.753369792831439,
      "grad_norm": 0.3175507187843323,
      "learning_rate": 0.00028555304740406323,
      "loss": 0.3492,
      "step": 116900
    },
    {
      "epoch": 4.757435907861834,
      "grad_norm": 0.362850546836853,
      "learning_rate": 0.00028533173991944407,
      "loss": 0.3515,
      "step": 117000
    },
    {
      "epoch": 4.761502022892228,
      "grad_norm": 0.3493860960006714,
      "learning_rate": 0.0002851104324348249,
      "loss": 0.3516,
      "step": 117100
    },
    {
      "epoch": 4.765568137922622,
      "grad_norm": 0.4200255274772644,
      "learning_rate": 0.0002848891249502058,
      "loss": 0.349,
      "step": 117200
    },
    {
      "epoch": 4.769634252953016,
      "grad_norm": 0.40444448590278625,
      "learning_rate": 0.00028466781746558665,
      "loss": 0.3498,
      "step": 117300
    },
    {
      "epoch": 4.773700367983411,
      "grad_norm": 0.3567560911178589,
      "learning_rate": 0.00028444650998096755,
      "loss": 0.3513,
      "step": 117400
    },
    {
      "epoch": 4.777766483013805,
      "grad_norm": 0.3158004879951477,
      "learning_rate": 0.00028422520249634845,
      "loss": 0.3505,
      "step": 117500
    },
    {
      "epoch": 4.781832598044199,
      "grad_norm": 0.35929247736930847,
      "learning_rate": 0.0002840038950117293,
      "loss": 0.3507,
      "step": 117600
    },
    {
      "epoch": 4.785898713074593,
      "grad_norm": 0.37405896186828613,
      "learning_rate": 0.0002837825875271102,
      "loss": 0.3509,
      "step": 117700
    },
    {
      "epoch": 4.789964828104987,
      "grad_norm": 0.3579918444156647,
      "learning_rate": 0.00028356128004249103,
      "loss": 0.3495,
      "step": 117800
    },
    {
      "epoch": 4.794030943135382,
      "grad_norm": 0.3146759867668152,
      "learning_rate": 0.00028333997255787193,
      "loss": 0.3503,
      "step": 117900
    },
    {
      "epoch": 4.798097058165776,
      "grad_norm": 0.32781803607940674,
      "learning_rate": 0.00028311866507325277,
      "loss": 0.3522,
      "step": 118000
    },
    {
      "epoch": 4.798097058165776,
      "eval_loss": 0.36026743054389954,
      "eval_runtime": 126.5908,
      "eval_samples_per_second": 1381.633,
      "eval_steps_per_second": 43.179,
      "step": 118000
    },
    {
      "epoch": 4.80216317319617,
      "grad_norm": 0.31490325927734375,
      "learning_rate": 0.00028289735758863367,
      "loss": 0.3521,
      "step": 118100
    },
    {
      "epoch": 4.806229288226564,
      "grad_norm": 0.34609660506248474,
      "learning_rate": 0.0002826760501040145,
      "loss": 0.3508,
      "step": 118200
    },
    {
      "epoch": 4.8102954032569585,
      "grad_norm": 0.319720059633255,
      "learning_rate": 0.0002824547426193954,
      "loss": 0.3497,
      "step": 118300
    },
    {
      "epoch": 4.8143615182873525,
      "grad_norm": 0.4341469407081604,
      "learning_rate": 0.0002822334351347763,
      "loss": 0.3501,
      "step": 118400
    },
    {
      "epoch": 4.8184276333177465,
      "grad_norm": 0.3969724774360657,
      "learning_rate": 0.00028201212765015715,
      "loss": 0.3483,
      "step": 118500
    },
    {
      "epoch": 4.8224937483481405,
      "grad_norm": 0.3610675036907196,
      "learning_rate": 0.00028179082016553805,
      "loss": 0.3488,
      "step": 118600
    },
    {
      "epoch": 4.8265598633785345,
      "grad_norm": 0.33786168694496155,
      "learning_rate": 0.00028156951268091884,
      "loss": 0.3495,
      "step": 118700
    },
    {
      "epoch": 4.830625978408929,
      "grad_norm": 0.3482894003391266,
      "learning_rate": 0.00028134820519629973,
      "loss": 0.3502,
      "step": 118800
    },
    {
      "epoch": 4.834692093439323,
      "grad_norm": 0.3701978325843811,
      "learning_rate": 0.0002811268977116806,
      "loss": 0.3508,
      "step": 118900
    },
    {
      "epoch": 4.838758208469717,
      "grad_norm": 0.3692965805530548,
      "learning_rate": 0.0002809055902270615,
      "loss": 0.35,
      "step": 119000
    },
    {
      "epoch": 4.842824323500112,
      "grad_norm": 0.35223549604415894,
      "learning_rate": 0.0002806842827424423,
      "loss": 0.3489,
      "step": 119100
    },
    {
      "epoch": 4.846890438530506,
      "grad_norm": 0.34438735246658325,
      "learning_rate": 0.0002804629752578232,
      "loss": 0.3499,
      "step": 119200
    },
    {
      "epoch": 4.8509565535609,
      "grad_norm": 0.2985449731349945,
      "learning_rate": 0.0002802416677732041,
      "loss": 0.3483,
      "step": 119300
    },
    {
      "epoch": 4.855022668591294,
      "grad_norm": 0.4947647750377655,
      "learning_rate": 0.00028002036028858496,
      "loss": 0.3492,
      "step": 119400
    },
    {
      "epoch": 4.859088783621688,
      "grad_norm": 0.33611369132995605,
      "learning_rate": 0.00027979905280396585,
      "loss": 0.3501,
      "step": 119500
    },
    {
      "epoch": 4.863154898652083,
      "grad_norm": 0.3951173722743988,
      "learning_rate": 0.0002795777453193467,
      "loss": 0.3516,
      "step": 119600
    },
    {
      "epoch": 4.867221013682477,
      "grad_norm": 0.39684468507766724,
      "learning_rate": 0.0002793564378347276,
      "loss": 0.3489,
      "step": 119700
    },
    {
      "epoch": 4.871287128712871,
      "grad_norm": 0.3460996150970459,
      "learning_rate": 0.00027913513035010844,
      "loss": 0.3497,
      "step": 119800
    },
    {
      "epoch": 4.875353243743265,
      "grad_norm": 0.32461267709732056,
      "learning_rate": 0.00027891382286548933,
      "loss": 0.3512,
      "step": 119900
    },
    {
      "epoch": 4.87941935877366,
      "grad_norm": 0.43844708800315857,
      "learning_rate": 0.0002786925153808702,
      "loss": 0.3495,
      "step": 120000
    },
    {
      "epoch": 4.87941935877366,
      "eval_loss": 0.3603034019470215,
      "eval_runtime": 126.0924,
      "eval_samples_per_second": 1387.094,
      "eval_steps_per_second": 43.349,
      "step": 120000
    },
    {
      "epoch": 4.883485473804054,
      "grad_norm": 0.35719063878059387,
      "learning_rate": 0.0002784712078962511,
      "loss": 0.3514,
      "step": 120100
    },
    {
      "epoch": 4.887551588834448,
      "grad_norm": 0.34109237790107727,
      "learning_rate": 0.00027824990041163197,
      "loss": 0.3485,
      "step": 120200
    },
    {
      "epoch": 4.891617703864842,
      "grad_norm": 0.40465298295021057,
      "learning_rate": 0.0002780285929270128,
      "loss": 0.35,
      "step": 120300
    },
    {
      "epoch": 4.895683818895236,
      "grad_norm": 0.3273538053035736,
      "learning_rate": 0.00027780728544239366,
      "loss": 0.3494,
      "step": 120400
    },
    {
      "epoch": 4.899749933925631,
      "grad_norm": 0.34084591269493103,
      "learning_rate": 0.0002775859779577745,
      "loss": 0.3503,
      "step": 120500
    },
    {
      "epoch": 4.903816048956025,
      "grad_norm": 0.30633625388145447,
      "learning_rate": 0.0002773646704731554,
      "loss": 0.3492,
      "step": 120600
    },
    {
      "epoch": 4.907882163986419,
      "grad_norm": 0.33541539311408997,
      "learning_rate": 0.00027714336298853624,
      "loss": 0.3501,
      "step": 120700
    },
    {
      "epoch": 4.911948279016814,
      "grad_norm": 0.3346199691295624,
      "learning_rate": 0.00027692205550391714,
      "loss": 0.3514,
      "step": 120800
    },
    {
      "epoch": 4.916014394047208,
      "grad_norm": 0.2503313720226288,
      "learning_rate": 0.00027670074801929804,
      "loss": 0.3511,
      "step": 120900
    },
    {
      "epoch": 4.920080509077602,
      "grad_norm": 0.35755205154418945,
      "learning_rate": 0.0002764794405346789,
      "loss": 0.3488,
      "step": 121000
    },
    {
      "epoch": 4.924146624107996,
      "grad_norm": 0.35058170557022095,
      "learning_rate": 0.0002762581330500598,
      "loss": 0.3517,
      "step": 121100
    },
    {
      "epoch": 4.92821273913839,
      "grad_norm": 0.37404653429985046,
      "learning_rate": 0.0002760368255654406,
      "loss": 0.3475,
      "step": 121200
    },
    {
      "epoch": 4.932278854168785,
      "grad_norm": 0.3622976541519165,
      "learning_rate": 0.0002758155180808215,
      "loss": 0.3525,
      "step": 121300
    },
    {
      "epoch": 4.936344969199179,
      "grad_norm": 0.37547382712364197,
      "learning_rate": 0.00027559421059620236,
      "loss": 0.349,
      "step": 121400
    },
    {
      "epoch": 4.940411084229573,
      "grad_norm": 0.33960989117622375,
      "learning_rate": 0.00027537290311158326,
      "loss": 0.3498,
      "step": 121500
    },
    {
      "epoch": 4.944477199259967,
      "grad_norm": 0.37003329396247864,
      "learning_rate": 0.0002751515956269641,
      "loss": 0.3502,
      "step": 121600
    },
    {
      "epoch": 4.948543314290362,
      "grad_norm": 0.36219167709350586,
      "learning_rate": 0.000274930288142345,
      "loss": 0.3486,
      "step": 121700
    },
    {
      "epoch": 4.952609429320756,
      "grad_norm": 0.33096808195114136,
      "learning_rate": 0.0002747089806577259,
      "loss": 0.3473,
      "step": 121800
    },
    {
      "epoch": 4.95667554435115,
      "grad_norm": 0.3681633770465851,
      "learning_rate": 0.00027448767317310674,
      "loss": 0.3497,
      "step": 121900
    },
    {
      "epoch": 4.960741659381544,
      "grad_norm": 0.428010493516922,
      "learning_rate": 0.00027426636568848764,
      "loss": 0.3502,
      "step": 122000
    },
    {
      "epoch": 4.960741659381544,
      "eval_loss": 0.3599940836429596,
      "eval_runtime": 124.9532,
      "eval_samples_per_second": 1399.74,
      "eval_steps_per_second": 43.744,
      "step": 122000
    },
    {
      "epoch": 4.964807774411938,
      "grad_norm": 0.39008814096450806,
      "learning_rate": 0.0002740450582038684,
      "loss": 0.3502,
      "step": 122100
    },
    {
      "epoch": 4.9688738894423325,
      "grad_norm": 0.3433423638343811,
      "learning_rate": 0.0002738237507192493,
      "loss": 0.3507,
      "step": 122200
    },
    {
      "epoch": 4.9729400044727265,
      "grad_norm": 0.3646329939365387,
      "learning_rate": 0.00027360244323463016,
      "loss": 0.3505,
      "step": 122300
    },
    {
      "epoch": 4.9770061195031206,
      "grad_norm": 0.36493414640426636,
      "learning_rate": 0.00027338113575001106,
      "loss": 0.3504,
      "step": 122400
    },
    {
      "epoch": 4.981072234533515,
      "grad_norm": 0.39166393876075745,
      "learning_rate": 0.0002731598282653919,
      "loss": 0.35,
      "step": 122500
    },
    {
      "epoch": 4.985138349563909,
      "grad_norm": 0.32259392738342285,
      "learning_rate": 0.0002729385207807728,
      "loss": 0.3497,
      "step": 122600
    },
    {
      "epoch": 4.9892044645943034,
      "grad_norm": 0.4251098930835724,
      "learning_rate": 0.0002727172132961537,
      "loss": 0.3495,
      "step": 122700
    },
    {
      "epoch": 4.9932705796246974,
      "grad_norm": 0.3726933002471924,
      "learning_rate": 0.00027249590581153454,
      "loss": 0.3504,
      "step": 122800
    },
    {
      "epoch": 4.9973366946550914,
      "grad_norm": 0.3251478970050812,
      "learning_rate": 0.00027227459832691544,
      "loss": 0.3503,
      "step": 122900
    },
    {
      "epoch": 5.001402809685486,
      "grad_norm": 0.36744701862335205,
      "learning_rate": 0.0002720532908422963,
      "loss": 0.348,
      "step": 123000
    },
    {
      "epoch": 5.00546892471588,
      "grad_norm": 0.3372737765312195,
      "learning_rate": 0.0002718319833576772,
      "loss": 0.3452,
      "step": 123100
    },
    {
      "epoch": 5.009535039746274,
      "grad_norm": 0.4009368419647217,
      "learning_rate": 0.000271610675873058,
      "loss": 0.3427,
      "step": 123200
    },
    {
      "epoch": 5.013601154776668,
      "grad_norm": 0.33301830291748047,
      "learning_rate": 0.0002713893683884389,
      "loss": 0.3448,
      "step": 123300
    },
    {
      "epoch": 5.017667269807063,
      "grad_norm": 0.38140949606895447,
      "learning_rate": 0.00027116806090381976,
      "loss": 0.3457,
      "step": 123400
    },
    {
      "epoch": 5.021733384837457,
      "grad_norm": 0.33609578013420105,
      "learning_rate": 0.00027094675341920066,
      "loss": 0.344,
      "step": 123500
    },
    {
      "epoch": 5.025799499867851,
      "grad_norm": 0.42545637488365173,
      "learning_rate": 0.00027072544593458156,
      "loss": 0.3447,
      "step": 123600
    },
    {
      "epoch": 5.029865614898245,
      "grad_norm": 0.32814520597457886,
      "learning_rate": 0.00027050413844996235,
      "loss": 0.3436,
      "step": 123700
    },
    {
      "epoch": 5.033931729928639,
      "grad_norm": 0.2901352345943451,
      "learning_rate": 0.00027028283096534325,
      "loss": 0.3455,
      "step": 123800
    },
    {
      "epoch": 5.037997844959034,
      "grad_norm": 0.48842743039131165,
      "learning_rate": 0.0002700615234807241,
      "loss": 0.344,
      "step": 123900
    },
    {
      "epoch": 5.042063959989428,
      "grad_norm": 0.3560587763786316,
      "learning_rate": 0.000269840215996105,
      "loss": 0.3434,
      "step": 124000
    },
    {
      "epoch": 5.042063959989428,
      "eval_loss": 0.3603958189487457,
      "eval_runtime": 126.0035,
      "eval_samples_per_second": 1388.072,
      "eval_steps_per_second": 43.38,
      "step": 124000
    },
    {
      "epoch": 5.046130075019822,
      "grad_norm": 0.34485822916030884,
      "learning_rate": 0.00026961890851148583,
      "loss": 0.3467,
      "step": 124100
    },
    {
      "epoch": 5.050196190050216,
      "grad_norm": 0.30682194232940674,
      "learning_rate": 0.0002693976010268667,
      "loss": 0.3438,
      "step": 124200
    },
    {
      "epoch": 5.054262305080611,
      "grad_norm": 0.5164896249771118,
      "learning_rate": 0.0002691762935422476,
      "loss": 0.344,
      "step": 124300
    },
    {
      "epoch": 5.058328420111005,
      "grad_norm": 0.3870127499103546,
      "learning_rate": 0.00026895498605762847,
      "loss": 0.3456,
      "step": 124400
    },
    {
      "epoch": 5.062394535141399,
      "grad_norm": 0.3232841491699219,
      "learning_rate": 0.00026873367857300936,
      "loss": 0.3442,
      "step": 124500
    },
    {
      "epoch": 5.066460650171793,
      "grad_norm": 0.4175574779510498,
      "learning_rate": 0.0002685123710883902,
      "loss": 0.3445,
      "step": 124600
    },
    {
      "epoch": 5.070526765202188,
      "grad_norm": 0.46461135149002075,
      "learning_rate": 0.0002682910636037711,
      "loss": 0.3475,
      "step": 124700
    },
    {
      "epoch": 5.074592880232582,
      "grad_norm": 0.3744092881679535,
      "learning_rate": 0.00026806975611915195,
      "loss": 0.3447,
      "step": 124800
    },
    {
      "epoch": 5.078658995262976,
      "grad_norm": 0.3486146926879883,
      "learning_rate": 0.00026784844863453284,
      "loss": 0.3465,
      "step": 124900
    },
    {
      "epoch": 5.08272511029337,
      "grad_norm": 0.4199627637863159,
      "learning_rate": 0.0002676271411499137,
      "loss": 0.345,
      "step": 125000
    },
    {
      "epoch": 5.086791225323765,
      "grad_norm": 0.43147099018096924,
      "learning_rate": 0.0002674058336652946,
      "loss": 0.3464,
      "step": 125100
    },
    {
      "epoch": 5.090857340354159,
      "grad_norm": 0.3273734450340271,
      "learning_rate": 0.0002671845261806755,
      "loss": 0.3435,
      "step": 125200
    },
    {
      "epoch": 5.094923455384553,
      "grad_norm": 0.33127108216285706,
      "learning_rate": 0.0002669632186960563,
      "loss": 0.3457,
      "step": 125300
    },
    {
      "epoch": 5.098989570414947,
      "grad_norm": 0.3202652633190155,
      "learning_rate": 0.00026674191121143717,
      "loss": 0.3441,
      "step": 125400
    },
    {
      "epoch": 5.103055685445341,
      "grad_norm": 0.37673676013946533,
      "learning_rate": 0.000266520603726818,
      "loss": 0.3447,
      "step": 125500
    },
    {
      "epoch": 5.107121800475736,
      "grad_norm": 0.6167500019073486,
      "learning_rate": 0.0002662992962421989,
      "loss": 0.3448,
      "step": 125600
    },
    {
      "epoch": 5.11118791550613,
      "grad_norm": 0.3751652240753174,
      "learning_rate": 0.00026607798875757975,
      "loss": 0.3424,
      "step": 125700
    },
    {
      "epoch": 5.115254030536524,
      "grad_norm": 0.3917889893054962,
      "learning_rate": 0.00026585668127296065,
      "loss": 0.3461,
      "step": 125800
    },
    {
      "epoch": 5.119320145566918,
      "grad_norm": 0.4253363609313965,
      "learning_rate": 0.0002656353737883415,
      "loss": 0.3443,
      "step": 125900
    },
    {
      "epoch": 5.123386260597313,
      "grad_norm": 0.36192166805267334,
      "learning_rate": 0.0002654140663037224,
      "loss": 0.3473,
      "step": 126000
    },
    {
      "epoch": 5.123386260597313,
      "eval_loss": 0.35942748188972473,
      "eval_runtime": 124.8332,
      "eval_samples_per_second": 1401.086,
      "eval_steps_per_second": 43.786,
      "step": 126000
    },
    {
      "epoch": 5.127452375627707,
      "grad_norm": 0.3977525532245636,
      "learning_rate": 0.0002651927588191033,
      "loss": 0.3448,
      "step": 126100
    },
    {
      "epoch": 5.131518490658101,
      "grad_norm": 0.32518237829208374,
      "learning_rate": 0.00026497145133448413,
      "loss": 0.3443,
      "step": 126200
    },
    {
      "epoch": 5.135584605688495,
      "grad_norm": 0.4189142882823944,
      "learning_rate": 0.00026475014384986503,
      "loss": 0.3459,
      "step": 126300
    },
    {
      "epoch": 5.1396507207188895,
      "grad_norm": 0.4188169836997986,
      "learning_rate": 0.00026452883636524587,
      "loss": 0.3465,
      "step": 126400
    },
    {
      "epoch": 5.1437168357492835,
      "grad_norm": 0.34713420271873474,
      "learning_rate": 0.00026430752888062677,
      "loss": 0.349,
      "step": 126500
    },
    {
      "epoch": 5.1477829507796775,
      "grad_norm": 0.34592998027801514,
      "learning_rate": 0.0002640862213960076,
      "loss": 0.3448,
      "step": 126600
    },
    {
      "epoch": 5.1518490658100715,
      "grad_norm": 0.3628484904766083,
      "learning_rate": 0.0002638649139113885,
      "loss": 0.3458,
      "step": 126700
    },
    {
      "epoch": 5.155915180840466,
      "grad_norm": 0.3095307946205139,
      "learning_rate": 0.00026364360642676935,
      "loss": 0.3447,
      "step": 126800
    },
    {
      "epoch": 5.15998129587086,
      "grad_norm": 0.3144362270832062,
      "learning_rate": 0.00026342229894215025,
      "loss": 0.3465,
      "step": 126900
    },
    {
      "epoch": 5.164047410901254,
      "grad_norm": 0.33357974886894226,
      "learning_rate": 0.00026320099145753115,
      "loss": 0.3465,
      "step": 127000
    },
    {
      "epoch": 5.168113525931648,
      "grad_norm": 0.4250325858592987,
      "learning_rate": 0.00026297968397291194,
      "loss": 0.3459,
      "step": 127100
    },
    {
      "epoch": 5.172179640962042,
      "grad_norm": 0.40792277455329895,
      "learning_rate": 0.00026275837648829283,
      "loss": 0.3453,
      "step": 127200
    },
    {
      "epoch": 5.176245755992437,
      "grad_norm": 0.3888883590698242,
      "learning_rate": 0.0002625370690036737,
      "loss": 0.3461,
      "step": 127300
    },
    {
      "epoch": 5.180311871022831,
      "grad_norm": 0.3422808349132538,
      "learning_rate": 0.0002623157615190546,
      "loss": 0.3443,
      "step": 127400
    },
    {
      "epoch": 5.184377986053225,
      "grad_norm": 0.37383463978767395,
      "learning_rate": 0.0002620944540344354,
      "loss": 0.3439,
      "step": 127500
    },
    {
      "epoch": 5.188444101083619,
      "grad_norm": 0.3597581088542938,
      "learning_rate": 0.0002618731465498163,
      "loss": 0.3458,
      "step": 127600
    },
    {
      "epoch": 5.192510216114014,
      "grad_norm": 0.3601435124874115,
      "learning_rate": 0.00026165183906519716,
      "loss": 0.3428,
      "step": 127700
    },
    {
      "epoch": 5.196576331144408,
      "grad_norm": 0.3978559076786041,
      "learning_rate": 0.00026143053158057805,
      "loss": 0.346,
      "step": 127800
    },
    {
      "epoch": 5.200642446174802,
      "grad_norm": 0.36459434032440186,
      "learning_rate": 0.00026120922409595895,
      "loss": 0.3476,
      "step": 127900
    },
    {
      "epoch": 5.204708561205196,
      "grad_norm": 0.31204697489738464,
      "learning_rate": 0.0002609879166113398,
      "loss": 0.3475,
      "step": 128000
    },
    {
      "epoch": 5.204708561205196,
      "eval_loss": 0.358755886554718,
      "eval_runtime": 123.8852,
      "eval_samples_per_second": 1411.806,
      "eval_steps_per_second": 44.121,
      "step": 128000
    },
    {
      "epoch": 5.208774676235591,
      "grad_norm": 0.4960921108722687,
      "learning_rate": 0.0002607666091267207,
      "loss": 0.3471,
      "step": 128100
    },
    {
      "epoch": 5.212840791265985,
      "grad_norm": 0.35743147134780884,
      "learning_rate": 0.00026054530164210154,
      "loss": 0.3438,
      "step": 128200
    },
    {
      "epoch": 5.216906906296379,
      "grad_norm": 0.7006939649581909,
      "learning_rate": 0.00026032399415748243,
      "loss": 0.344,
      "step": 128300
    },
    {
      "epoch": 5.220973021326773,
      "grad_norm": 0.38327375054359436,
      "learning_rate": 0.0002601026866728633,
      "loss": 0.3479,
      "step": 128400
    },
    {
      "epoch": 5.225039136357168,
      "grad_norm": 0.35204461216926575,
      "learning_rate": 0.00025988137918824417,
      "loss": 0.3447,
      "step": 128500
    },
    {
      "epoch": 5.229105251387562,
      "grad_norm": 0.3555503785610199,
      "learning_rate": 0.00025966007170362507,
      "loss": 0.3443,
      "step": 128600
    },
    {
      "epoch": 5.233171366417956,
      "grad_norm": 0.3774033784866333,
      "learning_rate": 0.0002594387642190059,
      "loss": 0.3446,
      "step": 128700
    },
    {
      "epoch": 5.23723748144835,
      "grad_norm": 0.32469820976257324,
      "learning_rate": 0.00025921745673438676,
      "loss": 0.3458,
      "step": 128800
    },
    {
      "epoch": 5.241303596478744,
      "grad_norm": 0.4377467632293701,
      "learning_rate": 0.0002589961492497676,
      "loss": 0.3454,
      "step": 128900
    },
    {
      "epoch": 5.245369711509139,
      "grad_norm": 0.39847707748413086,
      "learning_rate": 0.0002587748417651485,
      "loss": 0.3439,
      "step": 129000
    },
    {
      "epoch": 5.249435826539533,
      "grad_norm": 0.33326372504234314,
      "learning_rate": 0.00025855353428052934,
      "loss": 0.3489,
      "step": 129100
    },
    {
      "epoch": 5.253501941569927,
      "grad_norm": 0.311612993478775,
      "learning_rate": 0.00025833222679591024,
      "loss": 0.3443,
      "step": 129200
    },
    {
      "epoch": 5.257568056600321,
      "grad_norm": 0.343648225069046,
      "learning_rate": 0.0002581109193112911,
      "loss": 0.3442,
      "step": 129300
    },
    {
      "epoch": 5.261634171630716,
      "grad_norm": 0.29837000370025635,
      "learning_rate": 0.000257889611826672,
      "loss": 0.3457,
      "step": 129400
    },
    {
      "epoch": 5.26570028666111,
      "grad_norm": 0.3310271203517914,
      "learning_rate": 0.0002576683043420529,
      "loss": 0.3457,
      "step": 129500
    },
    {
      "epoch": 5.269766401691504,
      "grad_norm": 0.37061214447021484,
      "learning_rate": 0.0002574469968574337,
      "loss": 0.3464,
      "step": 129600
    },
    {
      "epoch": 5.273832516721898,
      "grad_norm": 0.37820345163345337,
      "learning_rate": 0.0002572256893728146,
      "loss": 0.3462,
      "step": 129700
    },
    {
      "epoch": 5.277898631752293,
      "grad_norm": 0.36369264125823975,
      "learning_rate": 0.00025700438188819546,
      "loss": 0.3462,
      "step": 129800
    },
    {
      "epoch": 5.281964746782687,
      "grad_norm": 0.3948875963687897,
      "learning_rate": 0.00025678307440357636,
      "loss": 0.3429,
      "step": 129900
    },
    {
      "epoch": 5.286030861813081,
      "grad_norm": 0.5374556183815002,
      "learning_rate": 0.0002565617669189572,
      "loss": 0.3459,
      "step": 130000
    },
    {
      "epoch": 5.286030861813081,
      "eval_loss": 0.3580332100391388,
      "eval_runtime": 123.5833,
      "eval_samples_per_second": 1415.256,
      "eval_steps_per_second": 44.229,
      "step": 130000
    },
    {
      "epoch": 5.290096976843475,
      "grad_norm": 0.3997034430503845,
      "learning_rate": 0.0002563404594343381,
      "loss": 0.3483,
      "step": 130100
    },
    {
      "epoch": 5.29416309187387,
      "grad_norm": 0.37811318039894104,
      "learning_rate": 0.00025611915194971894,
      "loss": 0.3457,
      "step": 130200
    },
    {
      "epoch": 5.298229206904264,
      "grad_norm": 0.38577800989151,
      "learning_rate": 0.00025589784446509984,
      "loss": 0.3458,
      "step": 130300
    },
    {
      "epoch": 5.302295321934658,
      "grad_norm": 0.3654080927371979,
      "learning_rate": 0.00025567653698048073,
      "loss": 0.3456,
      "step": 130400
    },
    {
      "epoch": 5.306361436965052,
      "grad_norm": 0.398628830909729,
      "learning_rate": 0.0002554552294958615,
      "loss": 0.3457,
      "step": 130500
    },
    {
      "epoch": 5.310427551995446,
      "grad_norm": 0.40605810284614563,
      "learning_rate": 0.0002552339220112424,
      "loss": 0.3489,
      "step": 130600
    },
    {
      "epoch": 5.3144936670258405,
      "grad_norm": 0.36939510703086853,
      "learning_rate": 0.00025501261452662326,
      "loss": 0.3448,
      "step": 130700
    },
    {
      "epoch": 5.3185597820562345,
      "grad_norm": 0.37845852971076965,
      "learning_rate": 0.00025479130704200416,
      "loss": 0.3445,
      "step": 130800
    },
    {
      "epoch": 5.3226258970866285,
      "grad_norm": 0.35857322812080383,
      "learning_rate": 0.000254569999557385,
      "loss": 0.3481,
      "step": 130900
    },
    {
      "epoch": 5.3266920121170225,
      "grad_norm": 0.3452625274658203,
      "learning_rate": 0.0002543486920727659,
      "loss": 0.3456,
      "step": 131000
    },
    {
      "epoch": 5.330758127147417,
      "grad_norm": 0.33389729261398315,
      "learning_rate": 0.00025412738458814674,
      "loss": 0.3444,
      "step": 131100
    },
    {
      "epoch": 5.334824242177811,
      "grad_norm": 0.39328086376190186,
      "learning_rate": 0.00025390607710352764,
      "loss": 0.3449,
      "step": 131200
    },
    {
      "epoch": 5.338890357208205,
      "grad_norm": 0.43219709396362305,
      "learning_rate": 0.00025368476961890854,
      "loss": 0.3468,
      "step": 131300
    },
    {
      "epoch": 5.342956472238599,
      "grad_norm": 0.39771631360054016,
      "learning_rate": 0.0002534634621342894,
      "loss": 0.3458,
      "step": 131400
    },
    {
      "epoch": 5.347022587268993,
      "grad_norm": 0.31270304322242737,
      "learning_rate": 0.0002532421546496703,
      "loss": 0.3465,
      "step": 131500
    },
    {
      "epoch": 5.351088702299388,
      "grad_norm": 0.3176242411136627,
      "learning_rate": 0.0002530208471650511,
      "loss": 0.3461,
      "step": 131600
    },
    {
      "epoch": 5.355154817329782,
      "grad_norm": 0.3326743543148041,
      "learning_rate": 0.000252799539680432,
      "loss": 0.3442,
      "step": 131700
    },
    {
      "epoch": 5.359220932360176,
      "grad_norm": 0.3613528907299042,
      "learning_rate": 0.00025257823219581286,
      "loss": 0.3451,
      "step": 131800
    },
    {
      "epoch": 5.36328704739057,
      "grad_norm": 0.37243905663490295,
      "learning_rate": 0.00025235692471119376,
      "loss": 0.3472,
      "step": 131900
    },
    {
      "epoch": 5.367353162420965,
      "grad_norm": 0.35093167424201965,
      "learning_rate": 0.00025213561722657466,
      "loss": 0.3453,
      "step": 132000
    },
    {
      "epoch": 5.367353162420965,
      "eval_loss": 0.3577975928783417,
      "eval_runtime": 123.8556,
      "eval_samples_per_second": 1412.144,
      "eval_steps_per_second": 44.132,
      "step": 132000
    },
    {
      "epoch": 5.371419277451359,
      "grad_norm": 0.3381825387477875,
      "learning_rate": 0.0002519143097419555,
      "loss": 0.3455,
      "step": 132100
    },
    {
      "epoch": 5.375485392481753,
      "grad_norm": 0.34889882802963257,
      "learning_rate": 0.00025169300225733634,
      "loss": 0.3454,
      "step": 132200
    },
    {
      "epoch": 5.379551507512147,
      "grad_norm": 0.32472896575927734,
      "learning_rate": 0.0002514716947727172,
      "loss": 0.344,
      "step": 132300
    },
    {
      "epoch": 5.383617622542542,
      "grad_norm": 0.3630579710006714,
      "learning_rate": 0.0002512503872880981,
      "loss": 0.3461,
      "step": 132400
    },
    {
      "epoch": 5.387683737572936,
      "grad_norm": 0.3540344536304474,
      "learning_rate": 0.00025102907980347893,
      "loss": 0.3445,
      "step": 132500
    },
    {
      "epoch": 5.39174985260333,
      "grad_norm": 0.345755934715271,
      "learning_rate": 0.0002508077723188598,
      "loss": 0.348,
      "step": 132600
    },
    {
      "epoch": 5.395815967633724,
      "grad_norm": 0.3211040794849396,
      "learning_rate": 0.00025058646483424067,
      "loss": 0.3479,
      "step": 132700
    },
    {
      "epoch": 5.399882082664119,
      "grad_norm": 0.35784485936164856,
      "learning_rate": 0.00025036515734962157,
      "loss": 0.3439,
      "step": 132800
    },
    {
      "epoch": 5.403948197694513,
      "grad_norm": 0.33863139152526855,
      "learning_rate": 0.00025014384986500246,
      "loss": 0.3449,
      "step": 132900
    },
    {
      "epoch": 5.408014312724907,
      "grad_norm": 0.3631916642189026,
      "learning_rate": 0.0002499225423803833,
      "loss": 0.3467,
      "step": 133000
    },
    {
      "epoch": 5.412080427755301,
      "grad_norm": 0.3435957133769989,
      "learning_rate": 0.0002497012348957642,
      "loss": 0.3454,
      "step": 133100
    },
    {
      "epoch": 5.416146542785695,
      "grad_norm": 0.3866950273513794,
      "learning_rate": 0.00024947992741114505,
      "loss": 0.3466,
      "step": 133200
    },
    {
      "epoch": 5.42021265781609,
      "grad_norm": 0.44247308373451233,
      "learning_rate": 0.00024925861992652594,
      "loss": 0.3481,
      "step": 133300
    },
    {
      "epoch": 5.424278772846484,
      "grad_norm": 0.3387641906738281,
      "learning_rate": 0.0002490373124419068,
      "loss": 0.3461,
      "step": 133400
    },
    {
      "epoch": 5.428344887876878,
      "grad_norm": 0.30766382813453674,
      "learning_rate": 0.00024881600495728763,
      "loss": 0.3452,
      "step": 133500
    },
    {
      "epoch": 5.432411002907272,
      "grad_norm": 0.3456375300884247,
      "learning_rate": 0.0002485946974726685,
      "loss": 0.3468,
      "step": 133600
    },
    {
      "epoch": 5.436477117937667,
      "grad_norm": 0.4143087565898895,
      "learning_rate": 0.0002483733899880494,
      "loss": 0.3458,
      "step": 133700
    },
    {
      "epoch": 5.440543232968061,
      "grad_norm": 0.42072001099586487,
      "learning_rate": 0.00024815208250343027,
      "loss": 0.3457,
      "step": 133800
    },
    {
      "epoch": 5.444609347998455,
      "grad_norm": 0.38199442625045776,
      "learning_rate": 0.00024793077501881116,
      "loss": 0.3468,
      "step": 133900
    },
    {
      "epoch": 5.448675463028849,
      "grad_norm": 0.3574877083301544,
      "learning_rate": 0.000247709467534192,
      "loss": 0.3436,
      "step": 134000
    },
    {
      "epoch": 5.448675463028849,
      "eval_loss": 0.35769572854042053,
      "eval_runtime": 123.7477,
      "eval_samples_per_second": 1413.376,
      "eval_steps_per_second": 44.171,
      "step": 134000
    },
    {
      "epoch": 5.452741578059244,
      "grad_norm": 0.42330458760261536,
      "learning_rate": 0.0002474881600495729,
      "loss": 0.3456,
      "step": 134100
    },
    {
      "epoch": 5.456807693089638,
      "grad_norm": 0.3167305588722229,
      "learning_rate": 0.00024726685256495375,
      "loss": 0.3449,
      "step": 134200
    },
    {
      "epoch": 5.460873808120032,
      "grad_norm": 0.4071134328842163,
      "learning_rate": 0.0002470455450803346,
      "loss": 0.3435,
      "step": 134300
    },
    {
      "epoch": 5.464939923150426,
      "grad_norm": 0.3500064015388489,
      "learning_rate": 0.0002468242375957155,
      "loss": 0.3454,
      "step": 134400
    },
    {
      "epoch": 5.4690060381808205,
      "grad_norm": 0.4169484078884125,
      "learning_rate": 0.00024660293011109633,
      "loss": 0.3447,
      "step": 134500
    },
    {
      "epoch": 5.4730721532112145,
      "grad_norm": 0.38059598207473755,
      "learning_rate": 0.00024638162262647723,
      "loss": 0.3454,
      "step": 134600
    },
    {
      "epoch": 5.4771382682416085,
      "grad_norm": 0.4228130280971527,
      "learning_rate": 0.0002461603151418581,
      "loss": 0.3453,
      "step": 134700
    },
    {
      "epoch": 5.4812043832720025,
      "grad_norm": 0.34332209825515747,
      "learning_rate": 0.00024593900765723897,
      "loss": 0.3465,
      "step": 134800
    },
    {
      "epoch": 5.4852704983023965,
      "grad_norm": 0.39802536368370056,
      "learning_rate": 0.00024571770017261987,
      "loss": 0.3423,
      "step": 134900
    },
    {
      "epoch": 5.489336613332791,
      "grad_norm": 0.36341989040374756,
      "learning_rate": 0.0002454963926880007,
      "loss": 0.345,
      "step": 135000
    },
    {
      "epoch": 5.493402728363185,
      "grad_norm": 0.32328739762306213,
      "learning_rate": 0.00024527508520338155,
      "loss": 0.3454,
      "step": 135100
    },
    {
      "epoch": 5.497468843393579,
      "grad_norm": 0.38189297914505005,
      "learning_rate": 0.00024505377771876245,
      "loss": 0.3453,
      "step": 135200
    },
    {
      "epoch": 5.501534958423973,
      "grad_norm": 0.38977062702178955,
      "learning_rate": 0.0002448324702341433,
      "loss": 0.3445,
      "step": 135300
    },
    {
      "epoch": 5.505601073454368,
      "grad_norm": 0.4608229398727417,
      "learning_rate": 0.0002446111627495242,
      "loss": 0.3461,
      "step": 135400
    },
    {
      "epoch": 5.509667188484762,
      "grad_norm": 0.3695306181907654,
      "learning_rate": 0.0002443898552649051,
      "loss": 0.345,
      "step": 135500
    },
    {
      "epoch": 5.513733303515156,
      "grad_norm": 0.4417053461074829,
      "learning_rate": 0.00024416854778028593,
      "loss": 0.3472,
      "step": 135600
    },
    {
      "epoch": 5.51779941854555,
      "grad_norm": 0.3840407431125641,
      "learning_rate": 0.0002439472402956668,
      "loss": 0.3457,
      "step": 135700
    },
    {
      "epoch": 5.521865533575945,
      "grad_norm": 0.30751344561576843,
      "learning_rate": 0.00024372593281104767,
      "loss": 0.3428,
      "step": 135800
    },
    {
      "epoch": 5.525931648606339,
      "grad_norm": 0.5279318690299988,
      "learning_rate": 0.00024350462532642857,
      "loss": 0.3445,
      "step": 135900
    },
    {
      "epoch": 5.529997763636733,
      "grad_norm": 0.38606807589530945,
      "learning_rate": 0.0002432833178418094,
      "loss": 0.3444,
      "step": 136000
    },
    {
      "epoch": 5.529997763636733,
      "eval_loss": 0.35681337118148804,
      "eval_runtime": 124.0613,
      "eval_samples_per_second": 1409.803,
      "eval_steps_per_second": 44.059,
      "step": 136000
    },
    {
      "epoch": 5.534063878667127,
      "grad_norm": 0.3868032395839691,
      "learning_rate": 0.00024306201035719028,
      "loss": 0.3449,
      "step": 136100
    },
    {
      "epoch": 5.538129993697522,
      "grad_norm": 0.43768778443336487,
      "learning_rate": 0.00024284070287257115,
      "loss": 0.3442,
      "step": 136200
    },
    {
      "epoch": 5.542196108727916,
      "grad_norm": 0.43922507762908936,
      "learning_rate": 0.00024261939538795202,
      "loss": 0.3462,
      "step": 136300
    },
    {
      "epoch": 5.54626222375831,
      "grad_norm": 0.42595475912094116,
      "learning_rate": 0.0002423980879033329,
      "loss": 0.3469,
      "step": 136400
    },
    {
      "epoch": 5.550328338788704,
      "grad_norm": 0.4240778386592865,
      "learning_rate": 0.00024217678041871376,
      "loss": 0.3458,
      "step": 136500
    },
    {
      "epoch": 5.554394453819098,
      "grad_norm": 0.36972805857658386,
      "learning_rate": 0.00024195547293409463,
      "loss": 0.3448,
      "step": 136600
    },
    {
      "epoch": 5.558460568849493,
      "grad_norm": 0.4091133177280426,
      "learning_rate": 0.00024173416544947553,
      "loss": 0.3452,
      "step": 136700
    },
    {
      "epoch": 5.562526683879887,
      "grad_norm": 0.3672623038291931,
      "learning_rate": 0.00024151285796485637,
      "loss": 0.3434,
      "step": 136800
    },
    {
      "epoch": 5.566592798910281,
      "grad_norm": 0.3622516393661499,
      "learning_rate": 0.00024129155048023724,
      "loss": 0.3448,
      "step": 136900
    },
    {
      "epoch": 5.570658913940675,
      "grad_norm": 0.2986188530921936,
      "learning_rate": 0.00024107024299561811,
      "loss": 0.347,
      "step": 137000
    },
    {
      "epoch": 5.57472502897107,
      "grad_norm": 0.47281235456466675,
      "learning_rate": 0.00024084893551099898,
      "loss": 0.3462,
      "step": 137100
    },
    {
      "epoch": 5.578791144001464,
      "grad_norm": 0.32271599769592285,
      "learning_rate": 0.00024062762802637985,
      "loss": 0.3455,
      "step": 137200
    },
    {
      "epoch": 5.582857259031858,
      "grad_norm": 0.3255758285522461,
      "learning_rate": 0.00024040632054176073,
      "loss": 0.345,
      "step": 137300
    },
    {
      "epoch": 5.586923374062252,
      "grad_norm": 0.3085145354270935,
      "learning_rate": 0.0002401850130571416,
      "loss": 0.3429,
      "step": 137400
    },
    {
      "epoch": 5.590989489092647,
      "grad_norm": 0.4433077275753021,
      "learning_rate": 0.00023996370557252247,
      "loss": 0.344,
      "step": 137500
    },
    {
      "epoch": 5.595055604123041,
      "grad_norm": 0.3676488995552063,
      "learning_rate": 0.00023974239808790336,
      "loss": 0.3459,
      "step": 137600
    },
    {
      "epoch": 5.599121719153435,
      "grad_norm": 0.45175933837890625,
      "learning_rate": 0.0002395210906032842,
      "loss": 0.3441,
      "step": 137700
    },
    {
      "epoch": 5.603187834183829,
      "grad_norm": 0.4106251001358032,
      "learning_rate": 0.00023929978311866508,
      "loss": 0.3466,
      "step": 137800
    },
    {
      "epoch": 5.607253949214224,
      "grad_norm": 0.4181596338748932,
      "learning_rate": 0.00023907847563404595,
      "loss": 0.3451,
      "step": 137900
    },
    {
      "epoch": 5.611320064244618,
      "grad_norm": 0.3577176332473755,
      "learning_rate": 0.00023885716814942682,
      "loss": 0.347,
      "step": 138000
    },
    {
      "epoch": 5.611320064244618,
      "eval_loss": 0.3570328950881958,
      "eval_runtime": 124.1493,
      "eval_samples_per_second": 1408.804,
      "eval_steps_per_second": 44.028,
      "step": 138000
    },
    {
      "epoch": 5.615386179275012,
      "grad_norm": 0.3632320165634155,
      "learning_rate": 0.0002386358606648077,
      "loss": 0.3431,
      "step": 138100
    },
    {
      "epoch": 5.619452294305406,
      "grad_norm": 0.32837188243865967,
      "learning_rate": 0.00023841455318018856,
      "loss": 0.3451,
      "step": 138200
    },
    {
      "epoch": 5.6235184093358,
      "grad_norm": 0.31422045826911926,
      "learning_rate": 0.00023819324569556943,
      "loss": 0.3449,
      "step": 138300
    },
    {
      "epoch": 5.627584524366195,
      "grad_norm": 0.3542941212654114,
      "learning_rate": 0.00023797193821095032,
      "loss": 0.3457,
      "step": 138400
    },
    {
      "epoch": 5.631650639396589,
      "grad_norm": 0.45750248432159424,
      "learning_rate": 0.00023775063072633117,
      "loss": 0.3462,
      "step": 138500
    },
    {
      "epoch": 5.635716754426983,
      "grad_norm": 0.45208364725112915,
      "learning_rate": 0.00023752932324171204,
      "loss": 0.3468,
      "step": 138600
    },
    {
      "epoch": 5.639782869457377,
      "grad_norm": 0.45403581857681274,
      "learning_rate": 0.0002373080157570929,
      "loss": 0.3461,
      "step": 138700
    },
    {
      "epoch": 5.6438489844877715,
      "grad_norm": 0.3951908349990845,
      "learning_rate": 0.00023708670827247378,
      "loss": 0.344,
      "step": 138800
    },
    {
      "epoch": 5.6479150995181655,
      "grad_norm": 0.3458983600139618,
      "learning_rate": 0.00023686540078785465,
      "loss": 0.3457,
      "step": 138900
    },
    {
      "epoch": 5.6519812145485595,
      "grad_norm": 0.38286179304122925,
      "learning_rate": 0.00023664409330323552,
      "loss": 0.3448,
      "step": 139000
    },
    {
      "epoch": 5.6560473295789535,
      "grad_norm": 0.3492826223373413,
      "learning_rate": 0.0002364227858186164,
      "loss": 0.3448,
      "step": 139100
    },
    {
      "epoch": 5.6601134446093475,
      "grad_norm": 0.43968063592910767,
      "learning_rate": 0.00023620147833399726,
      "loss": 0.3467,
      "step": 139200
    },
    {
      "epoch": 5.664179559639742,
      "grad_norm": 0.33320820331573486,
      "learning_rate": 0.00023598017084937813,
      "loss": 0.3452,
      "step": 139300
    },
    {
      "epoch": 5.668245674670136,
      "grad_norm": 0.38986146450042725,
      "learning_rate": 0.000235758863364759,
      "loss": 0.3466,
      "step": 139400
    },
    {
      "epoch": 5.67231178970053,
      "grad_norm": 0.4170995354652405,
      "learning_rate": 0.00023553755588013987,
      "loss": 0.3456,
      "step": 139500
    },
    {
      "epoch": 5.676377904730925,
      "grad_norm": 0.403483122587204,
      "learning_rate": 0.00023531624839552074,
      "loss": 0.3442,
      "step": 139600
    },
    {
      "epoch": 5.680444019761319,
      "grad_norm": 0.33804136514663696,
      "learning_rate": 0.0002350949409109016,
      "loss": 0.3441,
      "step": 139700
    },
    {
      "epoch": 5.684510134791713,
      "grad_norm": 0.3990759551525116,
      "learning_rate": 0.00023487363342628248,
      "loss": 0.345,
      "step": 139800
    },
    {
      "epoch": 5.688576249822107,
      "grad_norm": 0.318244069814682,
      "learning_rate": 0.00023465232594166335,
      "loss": 0.344,
      "step": 139900
    },
    {
      "epoch": 5.692642364852501,
      "grad_norm": 0.3832554519176483,
      "learning_rate": 0.00023443101845704422,
      "loss": 0.3433,
      "step": 140000
    },
    {
      "epoch": 5.692642364852501,
      "eval_loss": 0.3561268150806427,
      "eval_runtime": 124.0514,
      "eval_samples_per_second": 1409.916,
      "eval_steps_per_second": 44.062,
      "step": 140000
    },
    {
      "epoch": 5.696708479882896,
      "grad_norm": 0.35088208317756653,
      "learning_rate": 0.00023420971097242512,
      "loss": 0.345,
      "step": 140100
    },
    {
      "epoch": 5.70077459491329,
      "grad_norm": 0.37339574098587036,
      "learning_rate": 0.00023398840348780596,
      "loss": 0.3433,
      "step": 140200
    },
    {
      "epoch": 5.704840709943684,
      "grad_norm": 0.34212276339530945,
      "learning_rate": 0.00023376709600318683,
      "loss": 0.3426,
      "step": 140300
    },
    {
      "epoch": 5.708906824974078,
      "grad_norm": 0.3560720980167389,
      "learning_rate": 0.0002335457885185677,
      "loss": 0.3441,
      "step": 140400
    },
    {
      "epoch": 5.712972940004473,
      "grad_norm": 0.2971588671207428,
      "learning_rate": 0.00023332448103394857,
      "loss": 0.3462,
      "step": 140500
    },
    {
      "epoch": 5.717039055034867,
      "grad_norm": 0.38966259360313416,
      "learning_rate": 0.00023310317354932944,
      "loss": 0.3447,
      "step": 140600
    },
    {
      "epoch": 5.721105170065261,
      "grad_norm": 0.44558313488960266,
      "learning_rate": 0.0002328818660647103,
      "loss": 0.3459,
      "step": 140700
    },
    {
      "epoch": 5.725171285095655,
      "grad_norm": 0.4003075957298279,
      "learning_rate": 0.00023266055858009118,
      "loss": 0.3445,
      "step": 140800
    },
    {
      "epoch": 5.729237400126049,
      "grad_norm": 0.30487802624702454,
      "learning_rate": 0.00023243925109547205,
      "loss": 0.344,
      "step": 140900
    },
    {
      "epoch": 5.733303515156444,
      "grad_norm": 0.4777294397354126,
      "learning_rate": 0.00023221794361085292,
      "loss": 0.3455,
      "step": 141000
    },
    {
      "epoch": 5.737369630186838,
      "grad_norm": 0.3632223308086395,
      "learning_rate": 0.0002319966361262338,
      "loss": 0.3433,
      "step": 141100
    },
    {
      "epoch": 5.741435745217232,
      "grad_norm": 0.41831111907958984,
      "learning_rate": 0.00023177532864161466,
      "loss": 0.3452,
      "step": 141200
    },
    {
      "epoch": 5.745501860247627,
      "grad_norm": 0.40969106554985046,
      "learning_rate": 0.00023155402115699553,
      "loss": 0.3471,
      "step": 141300
    },
    {
      "epoch": 5.749567975278021,
      "grad_norm": 0.3946518003940582,
      "learning_rate": 0.0002313327136723764,
      "loss": 0.3462,
      "step": 141400
    },
    {
      "epoch": 5.753634090308415,
      "grad_norm": 0.42729514837265015,
      "learning_rate": 0.00023111140618775727,
      "loss": 0.3459,
      "step": 141500
    },
    {
      "epoch": 5.757700205338809,
      "grad_norm": 0.37957578897476196,
      "learning_rate": 0.00023089009870313814,
      "loss": 0.3431,
      "step": 141600
    },
    {
      "epoch": 5.761766320369203,
      "grad_norm": 0.41756516695022583,
      "learning_rate": 0.00023066879121851901,
      "loss": 0.3482,
      "step": 141700
    },
    {
      "epoch": 5.765832435399598,
      "grad_norm": 0.3264721930027008,
      "learning_rate": 0.00023044748373389989,
      "loss": 0.346,
      "step": 141800
    },
    {
      "epoch": 5.769898550429992,
      "grad_norm": 0.4120030999183655,
      "learning_rate": 0.00023022617624928076,
      "loss": 0.3452,
      "step": 141900
    },
    {
      "epoch": 5.773964665460386,
      "grad_norm": 0.36688509583473206,
      "learning_rate": 0.00023000486876466163,
      "loss": 0.3453,
      "step": 142000
    },
    {
      "epoch": 5.773964665460386,
      "eval_loss": 0.3555772602558136,
      "eval_runtime": 123.4971,
      "eval_samples_per_second": 1416.244,
      "eval_steps_per_second": 44.26,
      "step": 142000
    },
    {
      "epoch": 5.77803078049078,
      "grad_norm": 0.35651010274887085,
      "learning_rate": 0.0002297835612800425,
      "loss": 0.344,
      "step": 142100
    },
    {
      "epoch": 5.782096895521175,
      "grad_norm": 0.38628116250038147,
      "learning_rate": 0.00022956225379542337,
      "loss": 0.3453,
      "step": 142200
    },
    {
      "epoch": 5.786163010551569,
      "grad_norm": 0.4339727759361267,
      "learning_rate": 0.00022934094631080424,
      "loss": 0.3468,
      "step": 142300
    },
    {
      "epoch": 5.790229125581963,
      "grad_norm": 0.44566604495048523,
      "learning_rate": 0.0002291196388261851,
      "loss": 0.3442,
      "step": 142400
    },
    {
      "epoch": 5.794295240612357,
      "grad_norm": 0.49883151054382324,
      "learning_rate": 0.00022889833134156598,
      "loss": 0.3438,
      "step": 142500
    },
    {
      "epoch": 5.798361355642751,
      "grad_norm": 0.32216209173202515,
      "learning_rate": 0.00022867702385694685,
      "loss": 0.3445,
      "step": 142600
    },
    {
      "epoch": 5.802427470673146,
      "grad_norm": 0.36367297172546387,
      "learning_rate": 0.00022845571637232772,
      "loss": 0.3455,
      "step": 142700
    },
    {
      "epoch": 5.80649358570354,
      "grad_norm": 0.41568151116371155,
      "learning_rate": 0.0002282344088877086,
      "loss": 0.3436,
      "step": 142800
    },
    {
      "epoch": 5.810559700733934,
      "grad_norm": 0.3644644618034363,
      "learning_rate": 0.00022801310140308946,
      "loss": 0.3465,
      "step": 142900
    },
    {
      "epoch": 5.8146258157643285,
      "grad_norm": 0.37036964297294617,
      "learning_rate": 0.00022779179391847033,
      "loss": 0.3449,
      "step": 143000
    },
    {
      "epoch": 5.8186919307947225,
      "grad_norm": 0.4186825156211853,
      "learning_rate": 0.0002275704864338512,
      "loss": 0.3449,
      "step": 143100
    },
    {
      "epoch": 5.8227580458251165,
      "grad_norm": 0.3784298300743103,
      "learning_rate": 0.00022734917894923207,
      "loss": 0.3448,
      "step": 143200
    },
    {
      "epoch": 5.8268241608555105,
      "grad_norm": 0.37523677945137024,
      "learning_rate": 0.00022712787146461294,
      "loss": 0.3436,
      "step": 143300
    },
    {
      "epoch": 5.8308902758859045,
      "grad_norm": 0.3916275203227997,
      "learning_rate": 0.0002269065639799938,
      "loss": 0.3449,
      "step": 143400
    },
    {
      "epoch": 5.834956390916299,
      "grad_norm": 0.32890743017196655,
      "learning_rate": 0.00022668525649537468,
      "loss": 0.3443,
      "step": 143500
    },
    {
      "epoch": 5.839022505946693,
      "grad_norm": 0.36454829573631287,
      "learning_rate": 0.00022646394901075555,
      "loss": 0.3448,
      "step": 143600
    },
    {
      "epoch": 5.843088620977087,
      "grad_norm": 0.3634330630302429,
      "learning_rate": 0.00022624264152613642,
      "loss": 0.3457,
      "step": 143700
    },
    {
      "epoch": 5.847154736007481,
      "grad_norm": 0.38712644577026367,
      "learning_rate": 0.0002260213340415173,
      "loss": 0.3433,
      "step": 143800
    },
    {
      "epoch": 5.851220851037876,
      "grad_norm": 0.44611218571662903,
      "learning_rate": 0.00022580002655689816,
      "loss": 0.345,
      "step": 143900
    },
    {
      "epoch": 5.85528696606827,
      "grad_norm": 0.38085660338401794,
      "learning_rate": 0.00022557871907227903,
      "loss": 0.3451,
      "step": 144000
    },
    {
      "epoch": 5.85528696606827,
      "eval_loss": 0.3556186258792877,
      "eval_runtime": 123.7892,
      "eval_samples_per_second": 1412.902,
      "eval_steps_per_second": 44.156,
      "step": 144000
    },
    {
      "epoch": 5.859353081098664,
      "grad_norm": 0.4186689555644989,
      "learning_rate": 0.0002253574115876599,
      "loss": 0.3421,
      "step": 144100
    },
    {
      "epoch": 5.863419196129058,
      "grad_norm": 0.433419793844223,
      "learning_rate": 0.00022513610410304077,
      "loss": 0.3443,
      "step": 144200
    },
    {
      "epoch": 5.867485311159452,
      "grad_norm": 0.36464765667915344,
      "learning_rate": 0.00022491479661842164,
      "loss": 0.3468,
      "step": 144300
    },
    {
      "epoch": 5.871551426189847,
      "grad_norm": 0.33207449316978455,
      "learning_rate": 0.0002246934891338025,
      "loss": 0.3435,
      "step": 144400
    },
    {
      "epoch": 5.875617541220241,
      "grad_norm": 0.40949127078056335,
      "learning_rate": 0.00022447218164918338,
      "loss": 0.3433,
      "step": 144500
    },
    {
      "epoch": 5.879683656250635,
      "grad_norm": 0.4593583047389984,
      "learning_rate": 0.00022425087416456425,
      "loss": 0.3444,
      "step": 144600
    },
    {
      "epoch": 5.883749771281029,
      "grad_norm": 0.3414561152458191,
      "learning_rate": 0.00022402956667994512,
      "loss": 0.343,
      "step": 144700
    },
    {
      "epoch": 5.887815886311424,
      "grad_norm": 0.3373042643070221,
      "learning_rate": 0.000223808259195326,
      "loss": 0.3441,
      "step": 144800
    },
    {
      "epoch": 5.891882001341818,
      "grad_norm": 0.42712315917015076,
      "learning_rate": 0.00022358695171070686,
      "loss": 0.3423,
      "step": 144900
    },
    {
      "epoch": 5.895948116372212,
      "grad_norm": 0.3859424293041229,
      "learning_rate": 0.00022336564422608773,
      "loss": 0.3464,
      "step": 145000
    },
    {
      "epoch": 5.900014231402606,
      "grad_norm": 0.39269372820854187,
      "learning_rate": 0.0002231443367414686,
      "loss": 0.3442,
      "step": 145100
    },
    {
      "epoch": 5.904080346433001,
      "grad_norm": 0.3584790527820587,
      "learning_rate": 0.00022292302925684945,
      "loss": 0.3452,
      "step": 145200
    },
    {
      "epoch": 5.908146461463395,
      "grad_norm": 0.39488720893859863,
      "learning_rate": 0.00022270172177223034,
      "loss": 0.346,
      "step": 145300
    },
    {
      "epoch": 5.912212576493789,
      "grad_norm": 0.35181814432144165,
      "learning_rate": 0.0002224804142876112,
      "loss": 0.3439,
      "step": 145400
    },
    {
      "epoch": 5.916278691524183,
      "grad_norm": 0.6200050711631775,
      "learning_rate": 0.00022225910680299208,
      "loss": 0.3437,
      "step": 145500
    },
    {
      "epoch": 5.920344806554578,
      "grad_norm": 0.40365365147590637,
      "learning_rate": 0.00022203779931837295,
      "loss": 0.3454,
      "step": 145600
    },
    {
      "epoch": 5.924410921584972,
      "grad_norm": 0.34001752734184265,
      "learning_rate": 0.00022181649183375382,
      "loss": 0.345,
      "step": 145700
    },
    {
      "epoch": 5.928477036615366,
      "grad_norm": 0.40024620294570923,
      "learning_rate": 0.0002215951843491347,
      "loss": 0.3444,
      "step": 145800
    },
    {
      "epoch": 5.93254315164576,
      "grad_norm": 0.37846726179122925,
      "learning_rate": 0.00022137387686451556,
      "loss": 0.3457,
      "step": 145900
    },
    {
      "epoch": 5.936609266676154,
      "grad_norm": 0.29057204723358154,
      "learning_rate": 0.00022115256937989643,
      "loss": 0.3454,
      "step": 146000
    },
    {
      "epoch": 5.936609266676154,
      "eval_loss": 0.35473746061325073,
      "eval_runtime": 124.3949,
      "eval_samples_per_second": 1406.022,
      "eval_steps_per_second": 43.941,
      "step": 146000
    },
    {
      "epoch": 5.9406957122817,
      "grad_norm": 0.37035250663757324,
      "learning_rate": 0.0002209312618952773,
      "loss": 0.3437,
      "step": 146100
    },
    {
      "epoch": 5.944761827312095,
      "grad_norm": 0.44693130254745483,
      "learning_rate": 0.00022070995441065817,
      "loss": 0.3447,
      "step": 146200
    },
    {
      "epoch": 5.948827942342489,
      "grad_norm": 0.5025772452354431,
      "learning_rate": 0.00022048864692603905,
      "loss": 0.3457,
      "step": 146300
    },
    {
      "epoch": 5.952894057372883,
      "grad_norm": 0.36350712180137634,
      "learning_rate": 0.00022026733944141992,
      "loss": 0.345,
      "step": 146400
    },
    {
      "epoch": 5.956960172403277,
      "grad_norm": 0.3954467177391052,
      "learning_rate": 0.00022004603195680079,
      "loss": 0.3438,
      "step": 146500
    },
    {
      "epoch": 5.961026287433672,
      "grad_norm": 0.37946030497550964,
      "learning_rate": 0.00021982472447218166,
      "loss": 0.3436,
      "step": 146600
    },
    {
      "epoch": 5.965092402464066,
      "grad_norm": 0.5090915560722351,
      "learning_rate": 0.00021960341698756253,
      "loss": 0.3446,
      "step": 146700
    },
    {
      "epoch": 5.96915851749446,
      "grad_norm": 0.3495389223098755,
      "learning_rate": 0.0002193821095029434,
      "loss": 0.3459,
      "step": 146800
    },
    {
      "epoch": 5.973224632524854,
      "grad_norm": 0.33891162276268005,
      "learning_rate": 0.00021916080201832424,
      "loss": 0.3452,
      "step": 146900
    },
    {
      "epoch": 5.977290747555248,
      "grad_norm": 0.30196118354797363,
      "learning_rate": 0.00021893949453370514,
      "loss": 0.3453,
      "step": 147000
    },
    {
      "epoch": 5.981356862585643,
      "grad_norm": 0.3826434016227722,
      "learning_rate": 0.000218718187049086,
      "loss": 0.3437,
      "step": 147100
    },
    {
      "epoch": 5.985422977616037,
      "grad_norm": 0.343673974275589,
      "learning_rate": 0.00021849687956446688,
      "loss": 0.345,
      "step": 147200
    },
    {
      "epoch": 5.989489092646431,
      "grad_norm": 0.3700564205646515,
      "learning_rate": 0.00021827557207984775,
      "loss": 0.3435,
      "step": 147300
    },
    {
      "epoch": 5.993555207676825,
      "grad_norm": 0.3322713077068329,
      "learning_rate": 0.00021805426459522862,
      "loss": 0.3453,
      "step": 147400
    },
    {
      "epoch": 5.99762132270722,
      "grad_norm": 0.48294591903686523,
      "learning_rate": 0.0002178329571106095,
      "loss": 0.3455,
      "step": 147500
    },
    {
      "epoch": 6.001687437737614,
      "grad_norm": 0.37492457032203674,
      "learning_rate": 0.00021761164962599036,
      "loss": 0.3401,
      "step": 147600
    },
    {
      "epoch": 6.005753552768008,
      "grad_norm": 0.35315823554992676,
      "learning_rate": 0.00021739034214137123,
      "loss": 0.3373,
      "step": 147700
    },
    {
      "epoch": 6.009819667798402,
      "grad_norm": 0.38426342606544495,
      "learning_rate": 0.00021716903465675207,
      "loss": 0.3381,
      "step": 147800
    },
    {
      "epoch": 6.013885782828797,
      "grad_norm": 0.3989998400211334,
      "learning_rate": 0.00021694772717213297,
      "loss": 0.3372,
      "step": 147900
    },
    {
      "epoch": 6.017951897859191,
      "grad_norm": 0.37945306301116943,
      "learning_rate": 0.00021672641968751384,
      "loss": 0.3373,
      "step": 148000
    },
    {
      "epoch": 6.017951897859191,
      "eval_loss": 0.3551079034805298,
      "eval_runtime": 128.0,
      "eval_samples_per_second": 1366.421,
      "eval_steps_per_second": 42.703,
      "step": 148000
    },
    {
      "epoch": 6.022018012889585,
      "grad_norm": 0.3305889368057251,
      "learning_rate": 0.0002165051122028947,
      "loss": 0.3381,
      "step": 148100
    },
    {
      "epoch": 6.026084127919979,
      "grad_norm": 0.34205538034439087,
      "learning_rate": 0.00021628380471827558,
      "loss": 0.3383,
      "step": 148200
    },
    {
      "epoch": 6.0301502429503735,
      "grad_norm": 0.4262988865375519,
      "learning_rate": 0.00021606249723365645,
      "loss": 0.3397,
      "step": 148300
    },
    {
      "epoch": 6.0342163579807675,
      "grad_norm": 0.34363847970962524,
      "learning_rate": 0.00021584118974903732,
      "loss": 0.3384,
      "step": 148400
    },
    {
      "epoch": 6.0382824730111615,
      "grad_norm": 0.3951219320297241,
      "learning_rate": 0.0002156198822644182,
      "loss": 0.3374,
      "step": 148500
    },
    {
      "epoch": 6.0423485880415555,
      "grad_norm": 0.42931368947029114,
      "learning_rate": 0.00021539857477979903,
      "loss": 0.3386,
      "step": 148600
    },
    {
      "epoch": 6.0464147030719495,
      "grad_norm": 0.40636736154556274,
      "learning_rate": 0.00021517726729517993,
      "loss": 0.3391,
      "step": 148700
    },
    {
      "epoch": 6.050480818102344,
      "grad_norm": 0.4609908163547516,
      "learning_rate": 0.0002149559598105608,
      "loss": 0.3373,
      "step": 148800
    },
    {
      "epoch": 6.054546933132738,
      "grad_norm": 0.338826984167099,
      "learning_rate": 0.00021473465232594167,
      "loss": 0.3386,
      "step": 148900
    },
    {
      "epoch": 6.058613048163132,
      "grad_norm": 0.42668616771698,
      "learning_rate": 0.00021451334484132254,
      "loss": 0.3402,
      "step": 149000
    },
    {
      "epoch": 6.062679163193526,
      "grad_norm": 0.4642893671989441,
      "learning_rate": 0.0002142920373567034,
      "loss": 0.34,
      "step": 149100
    },
    {
      "epoch": 6.066745278223921,
      "grad_norm": 0.3743238151073456,
      "learning_rate": 0.00021407072987208428,
      "loss": 0.3391,
      "step": 149200
    },
    {
      "epoch": 6.070811393254315,
      "grad_norm": 0.30695515871047974,
      "learning_rate": 0.00021384942238746515,
      "loss": 0.3401,
      "step": 149300
    },
    {
      "epoch": 6.074877508284709,
      "grad_norm": 0.3976142406463623,
      "learning_rate": 0.00021362811490284602,
      "loss": 0.3419,
      "step": 149400
    },
    {
      "epoch": 6.078943623315103,
      "grad_norm": 0.3775976896286011,
      "learning_rate": 0.00021340680741822687,
      "loss": 0.3382,
      "step": 149500
    },
    {
      "epoch": 6.083009738345498,
      "grad_norm": 0.4264048933982849,
      "learning_rate": 0.00021318549993360776,
      "loss": 0.3376,
      "step": 149600
    },
    {
      "epoch": 6.087075853375892,
      "grad_norm": 0.36499351263046265,
      "learning_rate": 0.00021296419244898863,
      "loss": 0.3379,
      "step": 149700
    },
    {
      "epoch": 6.091141968406286,
      "grad_norm": 0.36557909846305847,
      "learning_rate": 0.0002127428849643695,
      "loss": 0.3383,
      "step": 149800
    },
    {
      "epoch": 6.09520808343668,
      "grad_norm": 0.3861640691757202,
      "learning_rate": 0.00021252157747975037,
      "loss": 0.3378,
      "step": 149900
    },
    {
      "epoch": 6.099274198467075,
      "grad_norm": 0.42205971479415894,
      "learning_rate": 0.00021230026999513124,
      "loss": 0.3402,
      "step": 150000
    },
    {
      "epoch": 6.099274198467075,
      "eval_loss": 0.35458436608314514,
      "eval_runtime": 126.0968,
      "eval_samples_per_second": 1387.046,
      "eval_steps_per_second": 43.348,
      "step": 150000
    },
    {
      "epoch": 6.103340313497469,
      "grad_norm": 0.3776094317436218,
      "learning_rate": 0.0002120789625105121,
      "loss": 0.3407,
      "step": 150100
    },
    {
      "epoch": 6.107406428527863,
      "grad_norm": 0.39075177907943726,
      "learning_rate": 0.00021185765502589298,
      "loss": 0.3389,
      "step": 150200
    },
    {
      "epoch": 6.111472543558257,
      "grad_norm": 0.3793122470378876,
      "learning_rate": 0.00021163634754127383,
      "loss": 0.3399,
      "step": 150300
    },
    {
      "epoch": 6.115538658588651,
      "grad_norm": 0.4086973965167999,
      "learning_rate": 0.00021141504005665472,
      "loss": 0.3399,
      "step": 150400
    },
    {
      "epoch": 6.119604773619046,
      "grad_norm": 0.4308047294616699,
      "learning_rate": 0.0002111937325720356,
      "loss": 0.3369,
      "step": 150500
    },
    {
      "epoch": 6.12367088864944,
      "grad_norm": 0.3342204988002777,
      "learning_rate": 0.00021097242508741646,
      "loss": 0.3391,
      "step": 150600
    },
    {
      "epoch": 6.127737003679834,
      "grad_norm": 0.4109378159046173,
      "learning_rate": 0.00021075111760279733,
      "loss": 0.3396,
      "step": 150700
    },
    {
      "epoch": 6.131803118710228,
      "grad_norm": 0.5324372053146362,
      "learning_rate": 0.0002105298101181782,
      "loss": 0.338,
      "step": 150800
    },
    {
      "epoch": 6.135869233740623,
      "grad_norm": 0.3628065288066864,
      "learning_rate": 0.00021030850263355908,
      "loss": 0.3393,
      "step": 150900
    },
    {
      "epoch": 6.139935348771017,
      "grad_norm": 0.4186322093009949,
      "learning_rate": 0.00021008719514893995,
      "loss": 0.3389,
      "step": 151000
    },
    {
      "epoch": 6.144001463801411,
      "grad_norm": 0.3574480414390564,
      "learning_rate": 0.0002098658876643208,
      "loss": 0.3396,
      "step": 151100
    },
    {
      "epoch": 6.148067578831805,
      "grad_norm": 0.42033320665359497,
      "learning_rate": 0.00020964458017970166,
      "loss": 0.3376,
      "step": 151200
    },
    {
      "epoch": 6.1521336938622,
      "grad_norm": 0.4060303270816803,
      "learning_rate": 0.00020942327269508256,
      "loss": 0.3407,
      "step": 151300
    },
    {
      "epoch": 6.156199808892594,
      "grad_norm": 0.3934040367603302,
      "learning_rate": 0.00020920196521046343,
      "loss": 0.3401,
      "step": 151400
    },
    {
      "epoch": 6.160265923922988,
      "grad_norm": 0.3946874439716339,
      "learning_rate": 0.0002089806577258443,
      "loss": 0.3401,
      "step": 151500
    },
    {
      "epoch": 6.164332038953382,
      "grad_norm": 0.3379581868648529,
      "learning_rate": 0.00020875935024122517,
      "loss": 0.3398,
      "step": 151600
    },
    {
      "epoch": 6.168398153983776,
      "grad_norm": 0.45193198323249817,
      "learning_rate": 0.00020853804275660604,
      "loss": 0.3383,
      "step": 151700
    },
    {
      "epoch": 6.172464269014171,
      "grad_norm": 0.404808908700943,
      "learning_rate": 0.0002083167352719869,
      "loss": 0.3394,
      "step": 151800
    },
    {
      "epoch": 6.176530384044565,
      "grad_norm": 0.4676874279975891,
      "learning_rate": 0.00020809542778736778,
      "loss": 0.3383,
      "step": 151900
    },
    {
      "epoch": 6.180596499074959,
      "grad_norm": 0.4236204922199249,
      "learning_rate": 0.00020787412030274862,
      "loss": 0.3403,
      "step": 152000
    },
    {
      "epoch": 6.180596499074959,
      "eval_loss": 0.3543519973754883,
      "eval_runtime": 126.5083,
      "eval_samples_per_second": 1382.534,
      "eval_steps_per_second": 43.207,
      "step": 152000
    },
    {
      "epoch": 6.184662614105353,
      "grad_norm": 0.41492220759391785,
      "learning_rate": 0.00020765281281812952,
      "loss": 0.3417,
      "step": 152100
    },
    {
      "epoch": 6.188728729135748,
      "grad_norm": 0.5339069366455078,
      "learning_rate": 0.0002074315053335104,
      "loss": 0.3403,
      "step": 152200
    },
    {
      "epoch": 6.192794844166142,
      "grad_norm": 0.4006120562553406,
      "learning_rate": 0.00020721019784889126,
      "loss": 0.34,
      "step": 152300
    },
    {
      "epoch": 6.196860959196536,
      "grad_norm": 0.42094147205352783,
      "learning_rate": 0.00020698889036427213,
      "loss": 0.3401,
      "step": 152400
    },
    {
      "epoch": 6.20092707422693,
      "grad_norm": 0.3985922932624817,
      "learning_rate": 0.000206767582879653,
      "loss": 0.3414,
      "step": 152500
    },
    {
      "epoch": 6.2049931892573245,
      "grad_norm": 0.41614651679992676,
      "learning_rate": 0.00020654627539503387,
      "loss": 0.3386,
      "step": 152600
    },
    {
      "epoch": 6.2090593042877185,
      "grad_norm": 0.5674446225166321,
      "learning_rate": 0.00020632496791041474,
      "loss": 0.34,
      "step": 152700
    },
    {
      "epoch": 6.2131254193181125,
      "grad_norm": 0.3814350962638855,
      "learning_rate": 0.00020610366042579558,
      "loss": 0.3407,
      "step": 152800
    },
    {
      "epoch": 6.2171915343485065,
      "grad_norm": 0.3717033863067627,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.3403,
      "step": 152900
    },
    {
      "epoch": 6.221257649378901,
      "grad_norm": 0.4676632881164551,
      "learning_rate": 0.00020566104545655735,
      "loss": 0.3401,
      "step": 153000
    },
    {
      "epoch": 6.225323764409295,
      "grad_norm": 0.3317337930202484,
      "learning_rate": 0.00020543973797193822,
      "loss": 0.3417,
      "step": 153100
    },
    {
      "epoch": 6.229389879439689,
      "grad_norm": 0.404456228017807,
      "learning_rate": 0.0002052184304873191,
      "loss": 0.3382,
      "step": 153200
    },
    {
      "epoch": 6.233455994470083,
      "grad_norm": 0.4141864478588104,
      "learning_rate": 0.00020499712300269996,
      "loss": 0.3377,
      "step": 153300
    },
    {
      "epoch": 6.237522109500477,
      "grad_norm": 0.372050404548645,
      "learning_rate": 0.00020477581551808083,
      "loss": 0.3405,
      "step": 153400
    },
    {
      "epoch": 6.241588224530872,
      "grad_norm": 0.40667757391929626,
      "learning_rate": 0.0002045545080334617,
      "loss": 0.3395,
      "step": 153500
    },
    {
      "epoch": 6.245654339561266,
      "grad_norm": 0.5220646262168884,
      "learning_rate": 0.00020433320054884257,
      "loss": 0.3407,
      "step": 153600
    },
    {
      "epoch": 6.24972045459166,
      "grad_norm": 0.4730057120323181,
      "learning_rate": 0.00020411189306422341,
      "loss": 0.3396,
      "step": 153700
    },
    {
      "epoch": 6.253786569622054,
      "grad_norm": 0.3718308210372925,
      "learning_rate": 0.0002038905855796043,
      "loss": 0.3411,
      "step": 153800
    },
    {
      "epoch": 6.257852684652449,
      "grad_norm": 0.3777623474597931,
      "learning_rate": 0.00020366927809498518,
      "loss": 0.341,
      "step": 153900
    },
    {
      "epoch": 6.261918799682843,
      "grad_norm": 0.5130682587623596,
      "learning_rate": 0.00020344797061036605,
      "loss": 0.3392,
      "step": 154000
    },
    {
      "epoch": 6.261918799682843,
      "eval_loss": 0.3535216152667999,
      "eval_runtime": 126.0591,
      "eval_samples_per_second": 1387.461,
      "eval_steps_per_second": 43.361,
      "step": 154000
    },
    {
      "epoch": 6.265984914713237,
      "grad_norm": 0.4414253234863281,
      "learning_rate": 0.00020322666312574692,
      "loss": 0.3366,
      "step": 154100
    },
    {
      "epoch": 6.270051029743631,
      "grad_norm": 0.40903377532958984,
      "learning_rate": 0.0002030053556411278,
      "loss": 0.3385,
      "step": 154200
    },
    {
      "epoch": 6.274117144774026,
      "grad_norm": 0.36723119020462036,
      "learning_rate": 0.00020278404815650866,
      "loss": 0.3398,
      "step": 154300
    },
    {
      "epoch": 6.27818325980442,
      "grad_norm": 0.4658234119415283,
      "learning_rate": 0.00020256274067188953,
      "loss": 0.3396,
      "step": 154400
    },
    {
      "epoch": 6.282249374834814,
      "grad_norm": 0.39248618483543396,
      "learning_rate": 0.00020234143318727038,
      "loss": 0.34,
      "step": 154500
    },
    {
      "epoch": 6.286315489865208,
      "grad_norm": 0.43886640667915344,
      "learning_rate": 0.00020212012570265125,
      "loss": 0.3395,
      "step": 154600
    },
    {
      "epoch": 6.290381604895602,
      "grad_norm": 0.3649056553840637,
      "learning_rate": 0.00020189881821803214,
      "loss": 0.3409,
      "step": 154700
    },
    {
      "epoch": 6.294447719925997,
      "grad_norm": 0.374214768409729,
      "learning_rate": 0.00020167751073341301,
      "loss": 0.3375,
      "step": 154800
    },
    {
      "epoch": 6.298513834956391,
      "grad_norm": 0.422191858291626,
      "learning_rate": 0.00020145620324879388,
      "loss": 0.3372,
      "step": 154900
    },
    {
      "epoch": 6.302579949986785,
      "grad_norm": 0.4238251745700836,
      "learning_rate": 0.00020123489576417475,
      "loss": 0.3405,
      "step": 155000
    },
    {
      "epoch": 6.306646065017179,
      "grad_norm": 0.3782389461994171,
      "learning_rate": 0.00020101358827955562,
      "loss": 0.3403,
      "step": 155100
    },
    {
      "epoch": 6.310712180047574,
      "grad_norm": 0.42268455028533936,
      "learning_rate": 0.0002007922807949365,
      "loss": 0.3406,
      "step": 155200
    },
    {
      "epoch": 6.314778295077968,
      "grad_norm": 0.3656464219093323,
      "learning_rate": 0.00020057097331031736,
      "loss": 0.34,
      "step": 155300
    },
    {
      "epoch": 6.318844410108362,
      "grad_norm": 0.3513002395629883,
      "learning_rate": 0.0002003496658256982,
      "loss": 0.3422,
      "step": 155400
    },
    {
      "epoch": 6.322910525138756,
      "grad_norm": 0.32356780767440796,
      "learning_rate": 0.0002001283583410791,
      "loss": 0.3397,
      "step": 155500
    },
    {
      "epoch": 6.326976640169151,
      "grad_norm": 0.4139741361141205,
      "learning_rate": 0.00019990705085645998,
      "loss": 0.3405,
      "step": 155600
    },
    {
      "epoch": 6.331042755199545,
      "grad_norm": 0.48148778080940247,
      "learning_rate": 0.00019968574337184085,
      "loss": 0.3378,
      "step": 155700
    },
    {
      "epoch": 6.335108870229939,
      "grad_norm": 0.35972073674201965,
      "learning_rate": 0.00019946443588722172,
      "loss": 0.3399,
      "step": 155800
    },
    {
      "epoch": 6.339174985260333,
      "grad_norm": 0.36841094493865967,
      "learning_rate": 0.00019924312840260259,
      "loss": 0.3388,
      "step": 155900
    },
    {
      "epoch": 6.343241100290728,
      "grad_norm": 0.3873131275177002,
      "learning_rate": 0.00019902182091798346,
      "loss": 0.3391,
      "step": 156000
    },
    {
      "epoch": 6.343241100290728,
      "eval_loss": 0.3538185954093933,
      "eval_runtime": 127.1855,
      "eval_samples_per_second": 1375.172,
      "eval_steps_per_second": 42.977,
      "step": 156000
    },
    {
      "epoch": 6.347307215321122,
      "grad_norm": 0.45979243516921997,
      "learning_rate": 0.00019880051343336433,
      "loss": 0.34,
      "step": 156100
    },
    {
      "epoch": 6.351373330351516,
      "grad_norm": 0.4906807541847229,
      "learning_rate": 0.00019857920594874517,
      "loss": 0.3397,
      "step": 156200
    },
    {
      "epoch": 6.35543944538191,
      "grad_norm": 0.5000171065330505,
      "learning_rate": 0.00019835789846412604,
      "loss": 0.3383,
      "step": 156300
    },
    {
      "epoch": 6.359505560412304,
      "grad_norm": 0.39166951179504395,
      "learning_rate": 0.00019813659097950694,
      "loss": 0.3397,
      "step": 156400
    },
    {
      "epoch": 6.3635716754426985,
      "grad_norm": 0.4076615571975708,
      "learning_rate": 0.0001979152834948878,
      "loss": 0.3404,
      "step": 156500
    },
    {
      "epoch": 6.3676377904730925,
      "grad_norm": 0.3750418424606323,
      "learning_rate": 0.00019769397601026868,
      "loss": 0.339,
      "step": 156600
    },
    {
      "epoch": 6.3717039055034865,
      "grad_norm": 0.45050299167633057,
      "learning_rate": 0.00019747266852564955,
      "loss": 0.34,
      "step": 156700
    },
    {
      "epoch": 6.3757700205338805,
      "grad_norm": 0.3935316801071167,
      "learning_rate": 0.00019725136104103042,
      "loss": 0.3405,
      "step": 156800
    },
    {
      "epoch": 6.379836135564275,
      "grad_norm": 0.3819226324558258,
      "learning_rate": 0.0001970300535564113,
      "loss": 0.3398,
      "step": 156900
    },
    {
      "epoch": 6.383902250594669,
      "grad_norm": 0.37348294258117676,
      "learning_rate": 0.00019680874607179213,
      "loss": 0.3374,
      "step": 157000
    },
    {
      "epoch": 6.387968365625063,
      "grad_norm": 0.37587013840675354,
      "learning_rate": 0.000196587438587173,
      "loss": 0.3402,
      "step": 157100
    },
    {
      "epoch": 6.392034480655457,
      "grad_norm": 0.4198053479194641,
      "learning_rate": 0.00019636613110255387,
      "loss": 0.3373,
      "step": 157200
    },
    {
      "epoch": 6.396100595685852,
      "grad_norm": 0.3224387466907501,
      "learning_rate": 0.00019614482361793477,
      "loss": 0.3394,
      "step": 157300
    },
    {
      "epoch": 6.400166710716246,
      "grad_norm": 0.37223899364471436,
      "learning_rate": 0.00019592351613331564,
      "loss": 0.3394,
      "step": 157400
    },
    {
      "epoch": 6.40423282574664,
      "grad_norm": 0.3834315240383148,
      "learning_rate": 0.0001957022086486965,
      "loss": 0.3409,
      "step": 157500
    },
    {
      "epoch": 6.408298940777034,
      "grad_norm": 0.4508207440376282,
      "learning_rate": 0.00019548090116407738,
      "loss": 0.3395,
      "step": 157600
    },
    {
      "epoch": 6.412365055807429,
      "grad_norm": 0.4322592318058014,
      "learning_rate": 0.00019525959367945825,
      "loss": 0.3392,
      "step": 157700
    },
    {
      "epoch": 6.416431170837823,
      "grad_norm": 0.4034178853034973,
      "learning_rate": 0.00019503828619483912,
      "loss": 0.3416,
      "step": 157800
    },
    {
      "epoch": 6.420497285868217,
      "grad_norm": 0.3965562880039215,
      "learning_rate": 0.00019481697871021996,
      "loss": 0.3397,
      "step": 157900
    },
    {
      "epoch": 6.424563400898611,
      "grad_norm": 0.41994887590408325,
      "learning_rate": 0.00019459567122560083,
      "loss": 0.3392,
      "step": 158000
    },
    {
      "epoch": 6.424563400898611,
      "eval_loss": 0.35271891951560974,
      "eval_runtime": 126.5024,
      "eval_samples_per_second": 1382.599,
      "eval_steps_per_second": 43.209,
      "step": 158000
    },
    {
      "epoch": 6.428629515929005,
      "grad_norm": 0.5044577121734619,
      "learning_rate": 0.00019437436374098173,
      "loss": 0.3418,
      "step": 158100
    },
    {
      "epoch": 6.4326956309594,
      "grad_norm": 0.4196588397026062,
      "learning_rate": 0.0001941530562563626,
      "loss": 0.3396,
      "step": 158200
    },
    {
      "epoch": 6.436761745989794,
      "grad_norm": 0.4078710079193115,
      "learning_rate": 0.00019393174877174347,
      "loss": 0.3399,
      "step": 158300
    },
    {
      "epoch": 6.440827861020188,
      "grad_norm": 0.4610026776790619,
      "learning_rate": 0.00019371044128712434,
      "loss": 0.3414,
      "step": 158400
    },
    {
      "epoch": 6.444893976050582,
      "grad_norm": 0.3876093327999115,
      "learning_rate": 0.0001934891338025052,
      "loss": 0.3396,
      "step": 158500
    },
    {
      "epoch": 6.448960091080977,
      "grad_norm": 0.407044380903244,
      "learning_rate": 0.00019326782631788608,
      "loss": 0.3389,
      "step": 158600
    },
    {
      "epoch": 6.453026206111371,
      "grad_norm": 0.42983201146125793,
      "learning_rate": 0.00019304651883326693,
      "loss": 0.3386,
      "step": 158700
    },
    {
      "epoch": 6.457092321141765,
      "grad_norm": 0.45895305275917053,
      "learning_rate": 0.0001928252113486478,
      "loss": 0.3407,
      "step": 158800
    },
    {
      "epoch": 6.461158436172159,
      "grad_norm": 0.3992968201637268,
      "learning_rate": 0.00019260390386402867,
      "loss": 0.338,
      "step": 158900
    },
    {
      "epoch": 6.465224551202554,
      "grad_norm": 0.6999927759170532,
      "learning_rate": 0.00019238259637940956,
      "loss": 0.3392,
      "step": 159000
    },
    {
      "epoch": 6.469290666232948,
      "grad_norm": 0.42091280221939087,
      "learning_rate": 0.00019216128889479043,
      "loss": 0.3413,
      "step": 159100
    },
    {
      "epoch": 6.473356781263342,
      "grad_norm": 0.45971646904945374,
      "learning_rate": 0.0001919399814101713,
      "loss": 0.34,
      "step": 159200
    },
    {
      "epoch": 6.477422896293736,
      "grad_norm": 0.5245580673217773,
      "learning_rate": 0.00019171867392555217,
      "loss": 0.3404,
      "step": 159300
    },
    {
      "epoch": 6.481489011324131,
      "grad_norm": 0.4691382348537445,
      "learning_rate": 0.00019149736644093304,
      "loss": 0.3376,
      "step": 159400
    },
    {
      "epoch": 6.485555126354525,
      "grad_norm": 0.4507228434085846,
      "learning_rate": 0.00019127605895631391,
      "loss": 0.3396,
      "step": 159500
    },
    {
      "epoch": 6.489621241384919,
      "grad_norm": 0.3527947962284088,
      "learning_rate": 0.00019105475147169476,
      "loss": 0.3407,
      "step": 159600
    },
    {
      "epoch": 6.493687356415313,
      "grad_norm": 0.36703693866729736,
      "learning_rate": 0.00019083344398707563,
      "loss": 0.3414,
      "step": 159700
    },
    {
      "epoch": 6.497753471445707,
      "grad_norm": 0.3866591453552246,
      "learning_rate": 0.00019061213650245652,
      "loss": 0.3368,
      "step": 159800
    },
    {
      "epoch": 6.501819586476102,
      "grad_norm": 0.4569072425365448,
      "learning_rate": 0.0001903908290178374,
      "loss": 0.3395,
      "step": 159900
    },
    {
      "epoch": 6.505885701506496,
      "grad_norm": 0.40647000074386597,
      "learning_rate": 0.00019016952153321827,
      "loss": 0.3416,
      "step": 160000
    },
    {
      "epoch": 6.505885701506496,
      "eval_loss": 0.3519556522369385,
      "eval_runtime": 126.6015,
      "eval_samples_per_second": 1381.516,
      "eval_steps_per_second": 43.175,
      "step": 160000
    },
    {
      "epoch": 6.50995181653689,
      "grad_norm": 0.49515897035598755,
      "learning_rate": 0.00018994821404859914,
      "loss": 0.3402,
      "step": 160100
    },
    {
      "epoch": 6.514017931567284,
      "grad_norm": 0.5008775591850281,
      "learning_rate": 0.00018972690656398,
      "loss": 0.3382,
      "step": 160200
    },
    {
      "epoch": 6.518084046597679,
      "grad_norm": 0.4146471619606018,
      "learning_rate": 0.00018950559907936088,
      "loss": 0.3399,
      "step": 160300
    },
    {
      "epoch": 6.522150161628073,
      "grad_norm": 0.36688125133514404,
      "learning_rate": 0.00018928429159474172,
      "loss": 0.3396,
      "step": 160400
    },
    {
      "epoch": 6.526216276658467,
      "grad_norm": 0.37277522683143616,
      "learning_rate": 0.0001890629841101226,
      "loss": 0.3396,
      "step": 160500
    },
    {
      "epoch": 6.530282391688861,
      "grad_norm": 0.41657036542892456,
      "learning_rate": 0.00018884167662550346,
      "loss": 0.3414,
      "step": 160600
    },
    {
      "epoch": 6.534348506719255,
      "grad_norm": 0.47329631447792053,
      "learning_rate": 0.00018862036914088436,
      "loss": 0.3386,
      "step": 160700
    },
    {
      "epoch": 6.5384146217496495,
      "grad_norm": 0.4956232011318207,
      "learning_rate": 0.00018839906165626523,
      "loss": 0.3423,
      "step": 160800
    },
    {
      "epoch": 6.5424807367800435,
      "grad_norm": 0.5777643322944641,
      "learning_rate": 0.0001881777541716461,
      "loss": 0.3388,
      "step": 160900
    },
    {
      "epoch": 6.5465468518104375,
      "grad_norm": 0.4206259846687317,
      "learning_rate": 0.00018795644668702697,
      "loss": 0.3392,
      "step": 161000
    },
    {
      "epoch": 6.550612966840832,
      "grad_norm": 0.3977620303630829,
      "learning_rate": 0.00018773513920240784,
      "loss": 0.3389,
      "step": 161100
    },
    {
      "epoch": 6.554679081871226,
      "grad_norm": 0.42262032628059387,
      "learning_rate": 0.0001875138317177887,
      "loss": 0.3378,
      "step": 161200
    },
    {
      "epoch": 6.55874519690162,
      "grad_norm": 0.3979010581970215,
      "learning_rate": 0.00018729252423316955,
      "loss": 0.3404,
      "step": 161300
    },
    {
      "epoch": 6.562811311932014,
      "grad_norm": 0.3987349569797516,
      "learning_rate": 0.00018707121674855042,
      "loss": 0.3391,
      "step": 161400
    },
    {
      "epoch": 6.566877426962408,
      "grad_norm": 0.4196007251739502,
      "learning_rate": 0.00018684990926393132,
      "loss": 0.3389,
      "step": 161500
    },
    {
      "epoch": 6.570943541992803,
      "grad_norm": 0.38784852623939514,
      "learning_rate": 0.0001866286017793122,
      "loss": 0.3396,
      "step": 161600
    },
    {
      "epoch": 6.575009657023197,
      "grad_norm": 0.4095611870288849,
      "learning_rate": 0.00018640729429469306,
      "loss": 0.3396,
      "step": 161700
    },
    {
      "epoch": 6.579075772053591,
      "grad_norm": 0.4037568271160126,
      "learning_rate": 0.00018618598681007393,
      "loss": 0.3397,
      "step": 161800
    },
    {
      "epoch": 6.583141887083985,
      "grad_norm": 0.4879194498062134,
      "learning_rate": 0.0001859646793254548,
      "loss": 0.3396,
      "step": 161900
    },
    {
      "epoch": 6.58720800211438,
      "grad_norm": 0.3051319420337677,
      "learning_rate": 0.00018574337184083567,
      "loss": 0.3404,
      "step": 162000
    },
    {
      "epoch": 6.58720800211438,
      "eval_loss": 0.35167911648750305,
      "eval_runtime": 126.176,
      "eval_samples_per_second": 1386.175,
      "eval_steps_per_second": 43.32,
      "step": 162000
    },
    {
      "epoch": 6.591274117144774,
      "grad_norm": 0.4350743889808655,
      "learning_rate": 0.0001855220643562165,
      "loss": 0.3395,
      "step": 162100
    },
    {
      "epoch": 6.595340232175168,
      "grad_norm": 0.43381115794181824,
      "learning_rate": 0.00018530075687159738,
      "loss": 0.3396,
      "step": 162200
    },
    {
      "epoch": 6.599406347205562,
      "grad_norm": 0.41482114791870117,
      "learning_rate": 0.00018507944938697825,
      "loss": 0.338,
      "step": 162300
    },
    {
      "epoch": 6.603472462235956,
      "grad_norm": 0.41402873396873474,
      "learning_rate": 0.00018485814190235915,
      "loss": 0.3388,
      "step": 162400
    },
    {
      "epoch": 6.607538577266351,
      "grad_norm": 0.37531617283821106,
      "learning_rate": 0.00018463683441774002,
      "loss": 0.3376,
      "step": 162500
    },
    {
      "epoch": 6.611604692296745,
      "grad_norm": 0.3744167983531952,
      "learning_rate": 0.0001844155269331209,
      "loss": 0.3414,
      "step": 162600
    },
    {
      "epoch": 6.615670807327139,
      "grad_norm": 0.39435988664627075,
      "learning_rate": 0.00018419421944850176,
      "loss": 0.3356,
      "step": 162700
    },
    {
      "epoch": 6.619736922357534,
      "grad_norm": 0.4210664629936218,
      "learning_rate": 0.00018397291196388263,
      "loss": 0.34,
      "step": 162800
    },
    {
      "epoch": 6.623803037387928,
      "grad_norm": 0.4302188754081726,
      "learning_rate": 0.00018375160447926347,
      "loss": 0.3417,
      "step": 162900
    },
    {
      "epoch": 6.627869152418322,
      "grad_norm": 0.3677595853805542,
      "learning_rate": 0.00018353029699464434,
      "loss": 0.3388,
      "step": 163000
    },
    {
      "epoch": 6.631935267448716,
      "grad_norm": 0.3491867482662201,
      "learning_rate": 0.00018330898951002522,
      "loss": 0.3391,
      "step": 163100
    },
    {
      "epoch": 6.63600138247911,
      "grad_norm": 0.3972572088241577,
      "learning_rate": 0.0001830876820254061,
      "loss": 0.3391,
      "step": 163200
    },
    {
      "epoch": 6.640067497509505,
      "grad_norm": 0.45085179805755615,
      "learning_rate": 0.00018286637454078698,
      "loss": 0.338,
      "step": 163300
    },
    {
      "epoch": 6.644133612539899,
      "grad_norm": 0.4265331029891968,
      "learning_rate": 0.00018264506705616785,
      "loss": 0.3382,
      "step": 163400
    },
    {
      "epoch": 6.648199727570293,
      "grad_norm": 0.571918785572052,
      "learning_rate": 0.00018242375957154872,
      "loss": 0.3396,
      "step": 163500
    },
    {
      "epoch": 6.652265842600687,
      "grad_norm": 0.5009956955909729,
      "learning_rate": 0.0001822024520869296,
      "loss": 0.3402,
      "step": 163600
    },
    {
      "epoch": 6.656331957631082,
      "grad_norm": 0.4412713348865509,
      "learning_rate": 0.00018198114460231046,
      "loss": 0.3389,
      "step": 163700
    },
    {
      "epoch": 6.660398072661476,
      "grad_norm": 0.39672255516052246,
      "learning_rate": 0.0001817598371176913,
      "loss": 0.3377,
      "step": 163800
    },
    {
      "epoch": 6.66446418769187,
      "grad_norm": 0.41769352555274963,
      "learning_rate": 0.00018153852963307218,
      "loss": 0.3392,
      "step": 163900
    },
    {
      "epoch": 6.668530302722264,
      "grad_norm": 0.4700969159603119,
      "learning_rate": 0.00018131722214845305,
      "loss": 0.3386,
      "step": 164000
    },
    {
      "epoch": 6.668530302722264,
      "eval_loss": 0.3509289026260376,
      "eval_runtime": 125.7435,
      "eval_samples_per_second": 1390.943,
      "eval_steps_per_second": 43.469,
      "step": 164000
    },
    {
      "epoch": 6.672596417752658,
      "grad_norm": 0.426990807056427,
      "learning_rate": 0.00018109591466383394,
      "loss": 0.3403,
      "step": 164100
    },
    {
      "epoch": 6.676662532783053,
      "grad_norm": 0.3965558409690857,
      "learning_rate": 0.00018087460717921481,
      "loss": 0.3392,
      "step": 164200
    },
    {
      "epoch": 6.680728647813447,
      "grad_norm": 0.3478468954563141,
      "learning_rate": 0.00018065329969459568,
      "loss": 0.3406,
      "step": 164300
    },
    {
      "epoch": 6.684794762843841,
      "grad_norm": 0.42521947622299194,
      "learning_rate": 0.00018043199220997656,
      "loss": 0.3393,
      "step": 164400
    },
    {
      "epoch": 6.6888608778742356,
      "grad_norm": 0.43149125576019287,
      "learning_rate": 0.00018021068472535743,
      "loss": 0.3377,
      "step": 164500
    },
    {
      "epoch": 6.69292699290463,
      "grad_norm": 0.4700995683670044,
      "learning_rate": 0.00017998937724073827,
      "loss": 0.3411,
      "step": 164600
    },
    {
      "epoch": 6.696993107935024,
      "grad_norm": 0.4624398350715637,
      "learning_rate": 0.00017976806975611914,
      "loss": 0.3394,
      "step": 164700
    },
    {
      "epoch": 6.701059222965418,
      "grad_norm": 0.43447357416152954,
      "learning_rate": 0.0001795467622715,
      "loss": 0.34,
      "step": 164800
    },
    {
      "epoch": 6.705125337995812,
      "grad_norm": 0.5858570337295532,
      "learning_rate": 0.0001793254547868809,
      "loss": 0.3378,
      "step": 164900
    },
    {
      "epoch": 6.7091914530262065,
      "grad_norm": 0.49635663628578186,
      "learning_rate": 0.00017910414730226178,
      "loss": 0.3393,
      "step": 165000
    },
    {
      "epoch": 6.7132575680566005,
      "grad_norm": 0.4132986068725586,
      "learning_rate": 0.00017888283981764265,
      "loss": 0.3391,
      "step": 165100
    },
    {
      "epoch": 6.7173236830869945,
      "grad_norm": 0.4264891743659973,
      "learning_rate": 0.00017866153233302352,
      "loss": 0.3409,
      "step": 165200
    },
    {
      "epoch": 6.7213897981173885,
      "grad_norm": 0.3799542784690857,
      "learning_rate": 0.0001784402248484044,
      "loss": 0.3378,
      "step": 165300
    },
    {
      "epoch": 6.725455913147783,
      "grad_norm": 0.45027947425842285,
      "learning_rate": 0.00017821891736378526,
      "loss": 0.3405,
      "step": 165400
    },
    {
      "epoch": 6.729522028178177,
      "grad_norm": 0.3911781907081604,
      "learning_rate": 0.0001779976098791661,
      "loss": 0.3397,
      "step": 165500
    },
    {
      "epoch": 6.733588143208571,
      "grad_norm": 0.39204704761505127,
      "learning_rate": 0.00017777630239454697,
      "loss": 0.3386,
      "step": 165600
    },
    {
      "epoch": 6.737654258238965,
      "grad_norm": 0.41726043820381165,
      "learning_rate": 0.00017755499490992784,
      "loss": 0.3369,
      "step": 165700
    },
    {
      "epoch": 6.741720373269359,
      "grad_norm": 0.5917525887489319,
      "learning_rate": 0.00017733368742530874,
      "loss": 0.3381,
      "step": 165800
    },
    {
      "epoch": 6.745786488299754,
      "grad_norm": 0.37555602192878723,
      "learning_rate": 0.0001771123799406896,
      "loss": 0.3385,
      "step": 165900
    },
    {
      "epoch": 6.749852603330148,
      "grad_norm": 0.35539335012435913,
      "learning_rate": 0.00017689107245607048,
      "loss": 0.338,
      "step": 166000
    },
    {
      "epoch": 6.749852603330148,
      "eval_loss": 0.35103124380111694,
      "eval_runtime": 126.0633,
      "eval_samples_per_second": 1387.414,
      "eval_steps_per_second": 43.359,
      "step": 166000
    },
    {
      "epoch": 6.753918718360542,
      "grad_norm": 0.554754912853241,
      "learning_rate": 0.00017666976497145135,
      "loss": 0.3392,
      "step": 166100
    },
    {
      "epoch": 6.757984833390936,
      "grad_norm": 0.3935275971889496,
      "learning_rate": 0.00017644845748683222,
      "loss": 0.3392,
      "step": 166200
    },
    {
      "epoch": 6.762050948421331,
      "grad_norm": 0.4698728919029236,
      "learning_rate": 0.00017622715000221306,
      "loss": 0.3393,
      "step": 166300
    },
    {
      "epoch": 6.766117063451725,
      "grad_norm": 0.45349499583244324,
      "learning_rate": 0.00017600584251759393,
      "loss": 0.3393,
      "step": 166400
    },
    {
      "epoch": 6.770183178482119,
      "grad_norm": 0.36103665828704834,
      "learning_rate": 0.0001757845350329748,
      "loss": 0.3393,
      "step": 166500
    },
    {
      "epoch": 6.774249293512513,
      "grad_norm": 0.4090997874736786,
      "learning_rate": 0.00017556322754835567,
      "loss": 0.3396,
      "step": 166600
    },
    {
      "epoch": 6.778315408542908,
      "grad_norm": 0.4540553689002991,
      "learning_rate": 0.00017534192006373657,
      "loss": 0.3399,
      "step": 166700
    },
    {
      "epoch": 6.782381523573302,
      "grad_norm": 0.4033125042915344,
      "learning_rate": 0.00017512061257911744,
      "loss": 0.34,
      "step": 166800
    },
    {
      "epoch": 6.786447638603696,
      "grad_norm": 0.42521798610687256,
      "learning_rate": 0.0001748993050944983,
      "loss": 0.3403,
      "step": 166900
    },
    {
      "epoch": 6.79051375363409,
      "grad_norm": 0.3756462335586548,
      "learning_rate": 0.00017467799760987918,
      "loss": 0.3361,
      "step": 167000
    },
    {
      "epoch": 6.794579868664485,
      "grad_norm": 0.41741347312927246,
      "learning_rate": 0.00017445669012526005,
      "loss": 0.3387,
      "step": 167100
    },
    {
      "epoch": 6.798645983694879,
      "grad_norm": 0.37008607387542725,
      "learning_rate": 0.0001742353826406409,
      "loss": 0.3376,
      "step": 167200
    },
    {
      "epoch": 6.802712098725273,
      "grad_norm": 0.4943530559539795,
      "learning_rate": 0.00017401407515602176,
      "loss": 0.3365,
      "step": 167300
    },
    {
      "epoch": 6.806778213755667,
      "grad_norm": 0.4019904136657715,
      "learning_rate": 0.00017379276767140263,
      "loss": 0.3392,
      "step": 167400
    },
    {
      "epoch": 6.810844328786061,
      "grad_norm": 0.3701924681663513,
      "learning_rate": 0.00017357146018678353,
      "loss": 0.3389,
      "step": 167500
    },
    {
      "epoch": 6.814910443816456,
      "grad_norm": 0.46291598677635193,
      "learning_rate": 0.0001733501527021644,
      "loss": 0.3374,
      "step": 167600
    },
    {
      "epoch": 6.81897655884685,
      "grad_norm": 0.4395466446876526,
      "learning_rate": 0.00017312884521754527,
      "loss": 0.3405,
      "step": 167700
    },
    {
      "epoch": 6.823042673877244,
      "grad_norm": 0.4247595965862274,
      "learning_rate": 0.00017290753773292614,
      "loss": 0.3385,
      "step": 167800
    },
    {
      "epoch": 6.827108788907638,
      "grad_norm": 0.3905039131641388,
      "learning_rate": 0.000172686230248307,
      "loss": 0.3383,
      "step": 167900
    },
    {
      "epoch": 6.831174903938033,
      "grad_norm": 0.4124200642108917,
      "learning_rate": 0.00017246492276368786,
      "loss": 0.3387,
      "step": 168000
    },
    {
      "epoch": 6.831174903938033,
      "eval_loss": 0.35073161125183105,
      "eval_runtime": 126.3485,
      "eval_samples_per_second": 1384.282,
      "eval_steps_per_second": 43.261,
      "step": 168000
    },
    {
      "epoch": 6.835241018968427,
      "grad_norm": 0.44423699378967285,
      "learning_rate": 0.00017224361527906873,
      "loss": 0.34,
      "step": 168100
    },
    {
      "epoch": 6.839307133998821,
      "grad_norm": 0.4106358289718628,
      "learning_rate": 0.0001720223077944496,
      "loss": 0.3401,
      "step": 168200
    },
    {
      "epoch": 6.843373249029215,
      "grad_norm": 0.431235671043396,
      "learning_rate": 0.00017180100030983047,
      "loss": 0.3379,
      "step": 168300
    },
    {
      "epoch": 6.84743936405961,
      "grad_norm": 0.4796627461910248,
      "learning_rate": 0.00017157969282521136,
      "loss": 0.3389,
      "step": 168400
    },
    {
      "epoch": 6.851505479090004,
      "grad_norm": 0.41885241866111755,
      "learning_rate": 0.00017135838534059223,
      "loss": 0.3387,
      "step": 168500
    },
    {
      "epoch": 6.855571594120398,
      "grad_norm": 0.526445746421814,
      "learning_rate": 0.0001711370778559731,
      "loss": 0.3383,
      "step": 168600
    },
    {
      "epoch": 6.859637709150792,
      "grad_norm": 0.38240188360214233,
      "learning_rate": 0.00017091577037135397,
      "loss": 0.3384,
      "step": 168700
    },
    {
      "epoch": 6.8637038241811865,
      "grad_norm": 0.5480665564537048,
      "learning_rate": 0.00017069446288673482,
      "loss": 0.337,
      "step": 168800
    },
    {
      "epoch": 6.8677699392115805,
      "grad_norm": 0.42985397577285767,
      "learning_rate": 0.0001704731554021157,
      "loss": 0.3386,
      "step": 168900
    },
    {
      "epoch": 6.8718360542419745,
      "grad_norm": 0.39357250928878784,
      "learning_rate": 0.00017025184791749656,
      "loss": 0.3381,
      "step": 169000
    },
    {
      "epoch": 6.8759021692723685,
      "grad_norm": 0.43938735127449036,
      "learning_rate": 0.00017003054043287743,
      "loss": 0.3404,
      "step": 169100
    },
    {
      "epoch": 6.8799682843027625,
      "grad_norm": 0.387095183134079,
      "learning_rate": 0.00016980923294825833,
      "loss": 0.3369,
      "step": 169200
    },
    {
      "epoch": 6.884034399333157,
      "grad_norm": 0.41644150018692017,
      "learning_rate": 0.0001695879254636392,
      "loss": 0.3388,
      "step": 169300
    },
    {
      "epoch": 6.888100514363551,
      "grad_norm": 0.4122072458267212,
      "learning_rate": 0.00016936661797902007,
      "loss": 0.3392,
      "step": 169400
    },
    {
      "epoch": 6.892166629393945,
      "grad_norm": 0.4018213450908661,
      "learning_rate": 0.00016914531049440094,
      "loss": 0.336,
      "step": 169500
    },
    {
      "epoch": 6.896232744424339,
      "grad_norm": 0.39058947563171387,
      "learning_rate": 0.0001689240030097818,
      "loss": 0.3408,
      "step": 169600
    },
    {
      "epoch": 6.900298859454734,
      "grad_norm": 0.40123283863067627,
      "learning_rate": 0.00016870269552516265,
      "loss": 0.3397,
      "step": 169700
    },
    {
      "epoch": 6.904364974485128,
      "grad_norm": 0.4843495786190033,
      "learning_rate": 0.00016848138804054352,
      "loss": 0.3375,
      "step": 169800
    },
    {
      "epoch": 6.908431089515522,
      "grad_norm": 0.4558810293674469,
      "learning_rate": 0.0001682600805559244,
      "loss": 0.3392,
      "step": 169900
    },
    {
      "epoch": 6.912497204545916,
      "grad_norm": 0.34350940585136414,
      "learning_rate": 0.00016803877307130526,
      "loss": 0.3398,
      "step": 170000
    },
    {
      "epoch": 6.912497204545916,
      "eval_loss": 0.34994375705718994,
      "eval_runtime": 126.2478,
      "eval_samples_per_second": 1385.386,
      "eval_steps_per_second": 43.296,
      "step": 170000
    },
    {
      "epoch": 6.91656331957631,
      "grad_norm": 0.38114720582962036,
      "learning_rate": 0.00016781746558668616,
      "loss": 0.3396,
      "step": 170100
    },
    {
      "epoch": 6.920629434606705,
      "grad_norm": 0.48283249139785767,
      "learning_rate": 0.00016759615810206703,
      "loss": 0.339,
      "step": 170200
    },
    {
      "epoch": 6.924695549637099,
      "grad_norm": 0.4589236080646515,
      "learning_rate": 0.0001673748506174479,
      "loss": 0.3388,
      "step": 170300
    },
    {
      "epoch": 6.928761664667493,
      "grad_norm": 0.516103208065033,
      "learning_rate": 0.00016715354313282877,
      "loss": 0.3402,
      "step": 170400
    },
    {
      "epoch": 6.932827779697888,
      "grad_norm": 0.4507831633090973,
      "learning_rate": 0.0001669322356482096,
      "loss": 0.3371,
      "step": 170500
    },
    {
      "epoch": 6.936893894728282,
      "grad_norm": 0.5002267360687256,
      "learning_rate": 0.00016671092816359048,
      "loss": 0.338,
      "step": 170600
    },
    {
      "epoch": 6.940960009758676,
      "grad_norm": 0.39849138259887695,
      "learning_rate": 0.00016648962067897135,
      "loss": 0.3384,
      "step": 170700
    },
    {
      "epoch": 6.94502612478907,
      "grad_norm": 0.40720829367637634,
      "learning_rate": 0.00016626831319435222,
      "loss": 0.3368,
      "step": 170800
    },
    {
      "epoch": 6.949092239819464,
      "grad_norm": 0.37037771940231323,
      "learning_rate": 0.00016604700570973312,
      "loss": 0.3393,
      "step": 170900
    },
    {
      "epoch": 6.953158354849859,
      "grad_norm": 0.45923444628715515,
      "learning_rate": 0.000165825698225114,
      "loss": 0.3365,
      "step": 171000
    },
    {
      "epoch": 6.957224469880253,
      "grad_norm": 0.3969111144542694,
      "learning_rate": 0.00016560439074049486,
      "loss": 0.3385,
      "step": 171100
    },
    {
      "epoch": 6.961290584910647,
      "grad_norm": 0.4108291566371918,
      "learning_rate": 0.00016538308325587573,
      "loss": 0.3361,
      "step": 171200
    },
    {
      "epoch": 6.965356699941041,
      "grad_norm": 0.4498031735420227,
      "learning_rate": 0.0001651617757712566,
      "loss": 0.3376,
      "step": 171300
    },
    {
      "epoch": 6.969422814971436,
      "grad_norm": 0.3682646155357361,
      "learning_rate": 0.00016494046828663744,
      "loss": 0.3385,
      "step": 171400
    },
    {
      "epoch": 6.97348893000183,
      "grad_norm": 0.5354673266410828,
      "learning_rate": 0.00016471916080201831,
      "loss": 0.3406,
      "step": 171500
    },
    {
      "epoch": 6.977555045032224,
      "grad_norm": 0.38978034257888794,
      "learning_rate": 0.00016449785331739918,
      "loss": 0.3383,
      "step": 171600
    },
    {
      "epoch": 6.981621160062618,
      "grad_norm": 0.42107200622558594,
      "learning_rate": 0.00016427654583278005,
      "loss": 0.3384,
      "step": 171700
    },
    {
      "epoch": 6.985687275093012,
      "grad_norm": 0.4625535011291504,
      "learning_rate": 0.00016405523834816095,
      "loss": 0.3392,
      "step": 171800
    },
    {
      "epoch": 6.989753390123407,
      "grad_norm": 0.4499794542789459,
      "learning_rate": 0.00016383393086354182,
      "loss": 0.339,
      "step": 171900
    },
    {
      "epoch": 6.993819505153801,
      "grad_norm": 0.43475964665412903,
      "learning_rate": 0.0001636126233789227,
      "loss": 0.3383,
      "step": 172000
    },
    {
      "epoch": 6.993819505153801,
      "eval_loss": 0.34990257024765015,
      "eval_runtime": 126.5331,
      "eval_samples_per_second": 1382.263,
      "eval_steps_per_second": 43.198,
      "step": 172000
    },
    {
      "epoch": 6.997905950759347,
      "grad_norm": 0.4148673415184021,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3379,
      "step": 172100
    },
    {
      "epoch": 7.001972065789741,
      "grad_norm": 0.4321401119232178,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3362,
      "step": 172200
    },
    {
      "epoch": 7.006038180820135,
      "grad_norm": 0.35190922021865845,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.3322,
      "step": 172300
    },
    {
      "epoch": 7.01010429585053,
      "grad_norm": 0.4614059329032898,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3312,
      "step": 172400
    },
    {
      "epoch": 7.014170410880924,
      "grad_norm": 0.5112466216087341,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3325,
      "step": 172500
    },
    {
      "epoch": 7.018236525911318,
      "grad_norm": 0.5377261638641357,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.3313,
      "step": 172600
    },
    {
      "epoch": 7.022302640941712,
      "grad_norm": 0.44399189949035645,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.3323,
      "step": 172700
    },
    {
      "epoch": 7.026368755972107,
      "grad_norm": 0.4089808464050293,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.3317,
      "step": 172800
    },
    {
      "epoch": 7.030434871002501,
      "grad_norm": 0.44941550493240356,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.3321,
      "step": 172900
    },
    {
      "epoch": 7.034500986032895,
      "grad_norm": 0.4597875475883484,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3315,
      "step": 173000
    },
    {
      "epoch": 7.038567101063289,
      "grad_norm": 0.5961710214614868,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3314,
      "step": 173100
    },
    {
      "epoch": 7.042633216093683,
      "grad_norm": 0.4174606204032898,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3314,
      "step": 173200
    },
    {
      "epoch": 7.046699331124078,
      "grad_norm": 0.39179518818855286,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.3318,
      "step": 173300
    },
    {
      "epoch": 7.050765446154472,
      "grad_norm": 0.47377821803092957,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3308,
      "step": 173400
    },
    {
      "epoch": 7.054831561184866,
      "grad_norm": 0.4745512902736664,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3334,
      "step": 173500
    },
    {
      "epoch": 7.05889767621526,
      "grad_norm": 0.40729647874832153,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3318,
      "step": 173600
    },
    {
      "epoch": 7.062963791245655,
      "grad_norm": 0.5432425737380981,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.3314,
      "step": 173700
    },
    {
      "epoch": 7.067029906276049,
      "grad_norm": 0.5079689621925354,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3322,
      "step": 173800
    },
    {
      "epoch": 7.071096021306443,
      "grad_norm": 0.3937710225582123,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.332,
      "step": 173900
    },
    {
      "epoch": 7.075162136336837,
      "grad_norm": 0.43437010049819946,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3308,
      "step": 174000
    },
    {
      "epoch": 7.075162136336837,
      "eval_loss": 0.34976404905319214,
      "eval_runtime": 127.6047,
      "eval_samples_per_second": 1370.655,
      "eval_steps_per_second": 42.835,
      "step": 174000
    },
    {
      "epoch": 7.079248581942383,
      "grad_norm": 0.495552659034729,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.3319,
      "step": 174100
    },
    {
      "epoch": 7.083314696972777,
      "grad_norm": 0.4127717614173889,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.332,
      "step": 174200
    },
    {
      "epoch": 7.087380812003172,
      "grad_norm": 0.43346288800239563,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.3323,
      "step": 174300
    },
    {
      "epoch": 7.091446927033566,
      "grad_norm": 0.5768290758132935,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.3321,
      "step": 174400
    },
    {
      "epoch": 7.09551304206396,
      "grad_norm": 0.4754849374294281,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3316,
      "step": 174500
    },
    {
      "epoch": 7.099579157094354,
      "grad_norm": 0.4515082538127899,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.3337,
      "step": 174600
    },
    {
      "epoch": 7.103645272124749,
      "grad_norm": 0.664928674697876,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3342,
      "step": 174700
    },
    {
      "epoch": 7.107711387155143,
      "grad_norm": 0.48928114771842957,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.3339,
      "step": 174800
    },
    {
      "epoch": 7.111777502185537,
      "grad_norm": 0.4951951503753662,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3324,
      "step": 174900
    },
    {
      "epoch": 7.115843617215931,
      "grad_norm": 0.4361659288406372,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3327,
      "step": 175000
    },
    {
      "epoch": 7.119909732246326,
      "grad_norm": 0.4556160867214203,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.3316,
      "step": 175100
    },
    {
      "epoch": 7.12397584727672,
      "grad_norm": 0.47222602367401123,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.333,
      "step": 175200
    },
    {
      "epoch": 7.128041962307114,
      "grad_norm": 0.38351982831954956,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3327,
      "step": 175300
    },
    {
      "epoch": 7.132108077337508,
      "grad_norm": 0.4120239317417145,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3326,
      "step": 175400
    },
    {
      "epoch": 7.1361741923679025,
      "grad_norm": 0.39476826786994934,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3334,
      "step": 175500
    },
    {
      "epoch": 7.1402403073982965,
      "grad_norm": 0.5090122818946838,
      "learning_rate": 0.000155645553932634,
      "loss": 0.3323,
      "step": 175600
    },
    {
      "epoch": 7.1443064224286905,
      "grad_norm": 0.5133472681045532,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3302,
      "step": 175700
    },
    {
      "epoch": 7.1483725374590845,
      "grad_norm": 0.5309394598007202,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3331,
      "step": 175800
    },
    {
      "epoch": 7.1524386524894785,
      "grad_norm": 0.4382978081703186,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3326,
      "step": 175900
    },
    {
      "epoch": 7.156504767519873,
      "grad_norm": 0.44941389560699463,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.3337,
      "step": 176000
    },
    {
      "epoch": 7.156504767519873,
      "eval_loss": 0.3493121862411499,
      "eval_runtime": 130.2629,
      "eval_samples_per_second": 1342.685,
      "eval_steps_per_second": 41.961,
      "step": 176000
    },
    {
      "epoch": 7.160570882550267,
      "grad_norm": 0.5181141495704651,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.3344,
      "step": 176100
    },
    {
      "epoch": 7.164636997580661,
      "grad_norm": 0.4535287618637085,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3331,
      "step": 176200
    },
    {
      "epoch": 7.168703112611055,
      "grad_norm": 0.43400880694389343,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.332,
      "step": 176300
    },
    {
      "epoch": 7.17276922764145,
      "grad_norm": 0.46901050209999084,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3335,
      "step": 176400
    },
    {
      "epoch": 7.176835342671844,
      "grad_norm": 0.4449775516986847,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3337,
      "step": 176500
    },
    {
      "epoch": 7.180901457702238,
      "grad_norm": 0.467428982257843,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3304,
      "step": 176600
    },
    {
      "epoch": 7.184967572732632,
      "grad_norm": 0.44131454825401306,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.3306,
      "step": 176700
    },
    {
      "epoch": 7.189033687763027,
      "grad_norm": 0.4227769672870636,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3337,
      "step": 176800
    },
    {
      "epoch": 7.193099802793421,
      "grad_norm": 0.44677504897117615,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3323,
      "step": 176900
    },
    {
      "epoch": 7.197165917823815,
      "grad_norm": 0.47251713275909424,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3335,
      "step": 177000
    },
    {
      "epoch": 7.201232032854209,
      "grad_norm": 0.4042479395866394,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3335,
      "step": 177100
    },
    {
      "epoch": 7.205298147884603,
      "grad_norm": 0.5153693556785583,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3316,
      "step": 177200
    },
    {
      "epoch": 7.209364262914998,
      "grad_norm": 0.4241965711116791,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.3319,
      "step": 177300
    },
    {
      "epoch": 7.213430377945392,
      "grad_norm": 0.5058999061584473,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.333,
      "step": 177400
    },
    {
      "epoch": 7.217496492975786,
      "grad_norm": 0.473728746175766,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.3332,
      "step": 177500
    },
    {
      "epoch": 7.22156260800618,
      "grad_norm": 0.4143159091472626,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3321,
      "step": 177600
    },
    {
      "epoch": 7.225628723036575,
      "grad_norm": 0.49777206778526306,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3323,
      "step": 177700
    },
    {
      "epoch": 7.229694838066969,
      "grad_norm": 0.5208525657653809,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.3339,
      "step": 177800
    },
    {
      "epoch": 7.233760953097363,
      "grad_norm": 0.5735823512077332,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3336,
      "step": 177900
    },
    {
      "epoch": 7.237827068127757,
      "grad_norm": 0.4457143247127533,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.331,
      "step": 178000
    },
    {
      "epoch": 7.237827068127757,
      "eval_loss": 0.3490104377269745,
      "eval_runtime": 129.3168,
      "eval_samples_per_second": 1352.508,
      "eval_steps_per_second": 42.268,
      "step": 178000
    },
    {
      "epoch": 7.241893183158152,
      "grad_norm": 0.4401785433292389,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3326,
      "step": 178100
    },
    {
      "epoch": 7.245959298188546,
      "grad_norm": 0.4614684581756592,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3326,
      "step": 178200
    },
    {
      "epoch": 7.25002541321894,
      "grad_norm": 0.40230509638786316,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3329,
      "step": 178300
    },
    {
      "epoch": 7.254091528249334,
      "grad_norm": 0.4275696575641632,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.3326,
      "step": 178400
    },
    {
      "epoch": 7.258157643279729,
      "grad_norm": 0.5114951133728027,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3324,
      "step": 178500
    },
    {
      "epoch": 7.262223758310123,
      "grad_norm": 0.4959214925765991,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3326,
      "step": 178600
    },
    {
      "epoch": 7.266289873340517,
      "grad_norm": 0.3822629153728485,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3317,
      "step": 178700
    },
    {
      "epoch": 7.270355988370911,
      "grad_norm": 0.49613693356513977,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3333,
      "step": 178800
    },
    {
      "epoch": 7.274422103401305,
      "grad_norm": 0.4080497920513153,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3332,
      "step": 178900
    },
    {
      "epoch": 7.2784882184317,
      "grad_norm": 0.41947728395462036,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3314,
      "step": 179000
    },
    {
      "epoch": 7.282554333462094,
      "grad_norm": 0.45853209495544434,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.3323,
      "step": 179100
    },
    {
      "epoch": 7.286620448492488,
      "grad_norm": 0.41916754841804504,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3313,
      "step": 179200
    },
    {
      "epoch": 7.290686563522882,
      "grad_norm": 0.4229002296924591,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.3316,
      "step": 179300
    },
    {
      "epoch": 7.294752678553277,
      "grad_norm": 0.4689241945743561,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3324,
      "step": 179400
    },
    {
      "epoch": 7.298818793583671,
      "grad_norm": 0.44783714413642883,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3343,
      "step": 179500
    },
    {
      "epoch": 7.302884908614065,
      "grad_norm": 0.4487576186656952,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3347,
      "step": 179600
    },
    {
      "epoch": 7.306951023644459,
      "grad_norm": 0.4241475462913513,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.3322,
      "step": 179700
    },
    {
      "epoch": 7.3110171386748535,
      "grad_norm": 0.4755220413208008,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.3324,
      "step": 179800
    },
    {
      "epoch": 7.3150832537052475,
      "grad_norm": 0.47680768370628357,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3321,
      "step": 179900
    },
    {
      "epoch": 7.3191493687356415,
      "grad_norm": 0.5415316820144653,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3326,
      "step": 180000
    },
    {
      "epoch": 7.3191493687356415,
      "eval_loss": 0.34841039776802063,
      "eval_runtime": 126.9427,
      "eval_samples_per_second": 1377.802,
      "eval_steps_per_second": 43.059,
      "step": 180000
    },
    {
      "epoch": 7.3232154837660355,
      "grad_norm": 0.5509771704673767,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3326,
      "step": 180100
    },
    {
      "epoch": 7.32728159879643,
      "grad_norm": 0.4392068386077881,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.3314,
      "step": 180200
    },
    {
      "epoch": 7.331347713826824,
      "grad_norm": 0.44206368923187256,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3316,
      "step": 180300
    },
    {
      "epoch": 7.335413828857218,
      "grad_norm": 0.38033270835876465,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.3316,
      "step": 180400
    },
    {
      "epoch": 7.339479943887612,
      "grad_norm": 0.6557217240333557,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3323,
      "step": 180500
    },
    {
      "epoch": 7.343546058918006,
      "grad_norm": 0.47426655888557434,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.3316,
      "step": 180600
    },
    {
      "epoch": 7.347612173948401,
      "grad_norm": 0.4212554395198822,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3335,
      "step": 180700
    },
    {
      "epoch": 7.351678288978795,
      "grad_norm": 0.4971635937690735,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.332,
      "step": 180800
    },
    {
      "epoch": 7.355744404009189,
      "grad_norm": 0.4613158106803894,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3322,
      "step": 180900
    },
    {
      "epoch": 7.359810519039583,
      "grad_norm": 0.45065152645111084,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3325,
      "step": 181000
    },
    {
      "epoch": 7.363876634069978,
      "grad_norm": 0.5266472101211548,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3329,
      "step": 181100
    },
    {
      "epoch": 7.367942749100372,
      "grad_norm": 0.5145872831344604,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3322,
      "step": 181200
    },
    {
      "epoch": 7.372008864130766,
      "grad_norm": 0.42919108271598816,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3332,
      "step": 181300
    },
    {
      "epoch": 7.37607497916116,
      "grad_norm": 0.45254334807395935,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3327,
      "step": 181400
    },
    {
      "epoch": 7.380141094191555,
      "grad_norm": 0.4926385283470154,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.332,
      "step": 181500
    },
    {
      "epoch": 7.384207209221949,
      "grad_norm": 0.506097137928009,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3319,
      "step": 181600
    },
    {
      "epoch": 7.388273324252343,
      "grad_norm": 0.4687735438346863,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.331,
      "step": 181700
    },
    {
      "epoch": 7.392339439282737,
      "grad_norm": 0.4595071077346802,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3336,
      "step": 181800
    },
    {
      "epoch": 7.396405554313132,
      "grad_norm": 0.44148313999176025,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3328,
      "step": 181900
    },
    {
      "epoch": 7.400471669343526,
      "grad_norm": 0.42588961124420166,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3319,
      "step": 182000
    },
    {
      "epoch": 7.400471669343526,
      "eval_loss": 0.3482653498649597,
      "eval_runtime": 126.4433,
      "eval_samples_per_second": 1383.244,
      "eval_steps_per_second": 43.229,
      "step": 182000
    },
    {
      "epoch": 7.40453778437392,
      "grad_norm": 0.41569507122039795,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3323,
      "step": 182100
    },
    {
      "epoch": 7.408603899404314,
      "grad_norm": 0.467573881149292,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.3336,
      "step": 182200
    },
    {
      "epoch": 7.412670014434708,
      "grad_norm": 0.49291154742240906,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.3323,
      "step": 182300
    },
    {
      "epoch": 7.416736129465103,
      "grad_norm": 0.5952827334403992,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3344,
      "step": 182400
    },
    {
      "epoch": 7.420802244495497,
      "grad_norm": 0.4884698987007141,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3348,
      "step": 182500
    },
    {
      "epoch": 7.424868359525891,
      "grad_norm": 0.4304814338684082,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.3316,
      "step": 182600
    },
    {
      "epoch": 7.428934474556285,
      "grad_norm": 0.4770663380622864,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3352,
      "step": 182700
    },
    {
      "epoch": 7.43300058958668,
      "grad_norm": 0.4343459904193878,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3335,
      "step": 182800
    },
    {
      "epoch": 7.437066704617074,
      "grad_norm": 0.48526376485824585,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.3328,
      "step": 182900
    },
    {
      "epoch": 7.441132819647468,
      "grad_norm": 0.44791626930236816,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3322,
      "step": 183000
    },
    {
      "epoch": 7.445198934677862,
      "grad_norm": 0.4418412744998932,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3326,
      "step": 183100
    },
    {
      "epoch": 7.449265049708257,
      "grad_norm": 0.41981157660484314,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.332,
      "step": 183200
    },
    {
      "epoch": 7.453331164738651,
      "grad_norm": 0.43050509691238403,
      "learning_rate": 0.000138604877616961,
      "loss": 0.3331,
      "step": 183300
    },
    {
      "epoch": 7.457397279769045,
      "grad_norm": 0.43502604961395264,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.3315,
      "step": 183400
    },
    {
      "epoch": 7.461463394799439,
      "grad_norm": 0.5282630324363708,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3328,
      "step": 183500
    },
    {
      "epoch": 7.4655295098298335,
      "grad_norm": 0.4441937804222107,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.3325,
      "step": 183600
    },
    {
      "epoch": 7.4695956248602275,
      "grad_norm": 0.5190988183021545,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3323,
      "step": 183700
    },
    {
      "epoch": 7.4736617398906215,
      "grad_norm": 0.38891276717185974,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.3332,
      "step": 183800
    },
    {
      "epoch": 7.4777278549210155,
      "grad_norm": 0.5262218117713928,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3321,
      "step": 183900
    },
    {
      "epoch": 7.4817939699514096,
      "grad_norm": 0.5521668791770935,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.3339,
      "step": 184000
    },
    {
      "epoch": 7.4817939699514096,
      "eval_loss": 0.3475985825061798,
      "eval_runtime": 126.6299,
      "eval_samples_per_second": 1381.206,
      "eval_steps_per_second": 43.165,
      "step": 184000
    },
    {
      "epoch": 7.485860084981804,
      "grad_norm": 0.4660305380821228,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3333,
      "step": 184100
    },
    {
      "epoch": 7.489926200012198,
      "grad_norm": 0.4422151744365692,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.334,
      "step": 184200
    },
    {
      "epoch": 7.4939923150425924,
      "grad_norm": 0.4532954692840576,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.3325,
      "step": 184300
    },
    {
      "epoch": 7.4980584300729864,
      "grad_norm": 0.4653748869895935,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3318,
      "step": 184400
    },
    {
      "epoch": 7.502124545103381,
      "grad_norm": 0.4723074436187744,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3331,
      "step": 184500
    },
    {
      "epoch": 7.506190660133775,
      "grad_norm": 0.50058513879776,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.3316,
      "step": 184600
    },
    {
      "epoch": 7.510256775164169,
      "grad_norm": 0.4851846694946289,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3326,
      "step": 184700
    },
    {
      "epoch": 7.514322890194563,
      "grad_norm": 0.4679775834083557,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.3309,
      "step": 184800
    },
    {
      "epoch": 7.518389005224957,
      "grad_norm": 0.462704598903656,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.3337,
      "step": 184900
    },
    {
      "epoch": 7.522455120255352,
      "grad_norm": 0.4170942008495331,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3328,
      "step": 185000
    },
    {
      "epoch": 7.526521235285746,
      "grad_norm": 0.42583805322647095,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3318,
      "step": 185100
    },
    {
      "epoch": 7.53058735031614,
      "grad_norm": 0.3964866101741791,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3332,
      "step": 185200
    },
    {
      "epoch": 7.534653465346535,
      "grad_norm": 0.40789005160331726,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3322,
      "step": 185300
    },
    {
      "epoch": 7.538719580376929,
      "grad_norm": 0.4434050917625427,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.3342,
      "step": 185400
    },
    {
      "epoch": 7.542785695407323,
      "grad_norm": 0.5828545689582825,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.3306,
      "step": 185500
    },
    {
      "epoch": 7.546851810437717,
      "grad_norm": 0.44618985056877136,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.333,
      "step": 185600
    },
    {
      "epoch": 7.550917925468111,
      "grad_norm": 0.41296201944351196,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3334,
      "step": 185700
    },
    {
      "epoch": 7.554984040498506,
      "grad_norm": 0.4735080897808075,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3317,
      "step": 185800
    },
    {
      "epoch": 7.5590501555289,
      "grad_norm": 0.4907601475715637,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.332,
      "step": 185900
    },
    {
      "epoch": 7.563116270559294,
      "grad_norm": 0.47742724418640137,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.333,
      "step": 186000
    },
    {
      "epoch": 7.563116270559294,
      "eval_loss": 0.34665411710739136,
      "eval_runtime": 127.6835,
      "eval_samples_per_second": 1369.809,
      "eval_steps_per_second": 42.809,
      "step": 186000
    },
    {
      "epoch": 7.567182385589688,
      "grad_norm": 0.3774340748786926,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3322,
      "step": 186100
    },
    {
      "epoch": 7.571248500620083,
      "grad_norm": 0.5050178170204163,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.3326,
      "step": 186200
    },
    {
      "epoch": 7.575314615650477,
      "grad_norm": 0.5102182626724243,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3322,
      "step": 186300
    },
    {
      "epoch": 7.579380730680871,
      "grad_norm": 0.50390625,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3319,
      "step": 186400
    },
    {
      "epoch": 7.583446845711265,
      "grad_norm": 0.40198588371276855,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.3312,
      "step": 186500
    },
    {
      "epoch": 7.587512960741659,
      "grad_norm": 0.530411422252655,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3324,
      "step": 186600
    },
    {
      "epoch": 7.591579075772054,
      "grad_norm": 0.45921581983566284,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.3329,
      "step": 186700
    },
    {
      "epoch": 7.595645190802448,
      "grad_norm": 0.46304547786712646,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3317,
      "step": 186800
    },
    {
      "epoch": 7.599711305832842,
      "grad_norm": 0.49830907583236694,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.3336,
      "step": 186900
    },
    {
      "epoch": 7.603777420863237,
      "grad_norm": 0.4518308639526367,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3324,
      "step": 187000
    },
    {
      "epoch": 7.607843535893631,
      "grad_norm": 0.49443355202674866,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3319,
      "step": 187100
    },
    {
      "epoch": 7.611909650924025,
      "grad_norm": 0.5026328563690186,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.3323,
      "step": 187200
    },
    {
      "epoch": 7.615975765954419,
      "grad_norm": 0.46075406670570374,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.3314,
      "step": 187300
    },
    {
      "epoch": 7.620041880984813,
      "grad_norm": 0.5250958800315857,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.3336,
      "step": 187400
    },
    {
      "epoch": 7.624107996015208,
      "grad_norm": 0.5712089538574219,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.3326,
      "step": 187500
    },
    {
      "epoch": 7.628174111045602,
      "grad_norm": 0.4635211229324341,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.3315,
      "step": 187600
    },
    {
      "epoch": 7.632240226075996,
      "grad_norm": 0.47561830282211304,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3305,
      "step": 187700
    },
    {
      "epoch": 7.63630634110639,
      "grad_norm": 0.5887807607650757,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3326,
      "step": 187800
    },
    {
      "epoch": 7.6403724561367845,
      "grad_norm": 0.44738322496414185,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3305,
      "step": 187900
    },
    {
      "epoch": 7.6444385711671785,
      "grad_norm": 0.4369392693042755,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.331,
      "step": 188000
    },
    {
      "epoch": 7.6444385711671785,
      "eval_loss": 0.34621840715408325,
      "eval_runtime": 128.4452,
      "eval_samples_per_second": 1361.686,
      "eval_steps_per_second": 42.555,
      "step": 188000
    },
    {
      "epoch": 7.6485046861975725,
      "grad_norm": 0.526229202747345,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.331,
      "step": 188100
    },
    {
      "epoch": 7.6525708012279665,
      "grad_norm": 0.4529339373111725,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3306,
      "step": 188200
    },
    {
      "epoch": 7.6566369162583605,
      "grad_norm": 0.4900050759315491,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3324,
      "step": 188300
    },
    {
      "epoch": 7.660703031288755,
      "grad_norm": 0.4685312807559967,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3316,
      "step": 188400
    },
    {
      "epoch": 7.664769146319149,
      "grad_norm": 0.43863147497177124,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3339,
      "step": 188500
    },
    {
      "epoch": 7.668835261349543,
      "grad_norm": 0.46891993284225464,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.3331,
      "step": 188600
    },
    {
      "epoch": 7.672901376379937,
      "grad_norm": 0.5356045365333557,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3301,
      "step": 188700
    },
    {
      "epoch": 7.676967491410332,
      "grad_norm": 0.5237608551979065,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.334,
      "step": 188800
    },
    {
      "epoch": 7.681033606440726,
      "grad_norm": 0.44707682728767395,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.3314,
      "step": 188900
    },
    {
      "epoch": 7.68509972147112,
      "grad_norm": 0.5328066945075989,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3321,
      "step": 189000
    },
    {
      "epoch": 7.689165836501514,
      "grad_norm": 0.4760228395462036,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.3322,
      "step": 189100
    },
    {
      "epoch": 7.693231951531909,
      "grad_norm": 0.4435715079307556,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.33,
      "step": 189200
    },
    {
      "epoch": 7.697298066562303,
      "grad_norm": 0.5167717933654785,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.3317,
      "step": 189300
    },
    {
      "epoch": 7.701364181592697,
      "grad_norm": 0.527046263217926,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.332,
      "step": 189400
    },
    {
      "epoch": 7.705430296623091,
      "grad_norm": 0.5940955281257629,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3317,
      "step": 189500
    },
    {
      "epoch": 7.709496411653486,
      "grad_norm": 0.4543037414550781,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.3338,
      "step": 189600
    },
    {
      "epoch": 7.71356252668388,
      "grad_norm": 0.5242272019386292,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3317,
      "step": 189700
    },
    {
      "epoch": 7.717628641714274,
      "grad_norm": 0.429906964302063,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.3311,
      "step": 189800
    },
    {
      "epoch": 7.721694756744668,
      "grad_norm": 0.4340096712112427,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3338,
      "step": 189900
    },
    {
      "epoch": 7.725760871775062,
      "grad_norm": 0.6027680039405823,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.3328,
      "step": 190000
    },
    {
      "epoch": 7.725760871775062,
      "eval_loss": 0.34610843658447266,
      "eval_runtime": 128.8142,
      "eval_samples_per_second": 1357.785,
      "eval_steps_per_second": 42.433,
      "step": 190000
    },
    {
      "epoch": 7.729826986805457,
      "grad_norm": 0.48457595705986023,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3318,
      "step": 190100
    },
    {
      "epoch": 7.733893101835851,
      "grad_norm": 0.4737374484539032,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3325,
      "step": 190200
    },
    {
      "epoch": 7.737959216866245,
      "grad_norm": 0.5097429752349854,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.3321,
      "step": 190300
    },
    {
      "epoch": 7.742025331896639,
      "grad_norm": 0.4476849138736725,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.331,
      "step": 190400
    },
    {
      "epoch": 7.746091446927034,
      "grad_norm": 0.4932100772857666,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3322,
      "step": 190500
    },
    {
      "epoch": 7.750157561957428,
      "grad_norm": 0.4332277774810791,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.3328,
      "step": 190600
    },
    {
      "epoch": 7.754223676987822,
      "grad_norm": 0.6102733612060547,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3303,
      "step": 190700
    },
    {
      "epoch": 7.758289792018216,
      "grad_norm": 0.49802687764167786,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3312,
      "step": 190800
    },
    {
      "epoch": 7.762355907048611,
      "grad_norm": 0.517408549785614,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.3327,
      "step": 190900
    },
    {
      "epoch": 7.766422022079005,
      "grad_norm": 0.44206514954566956,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3299,
      "step": 191000
    },
    {
      "epoch": 7.770488137109399,
      "grad_norm": 0.4509017765522003,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3309,
      "step": 191100
    },
    {
      "epoch": 7.774554252139793,
      "grad_norm": 0.4486711323261261,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3321,
      "step": 191200
    },
    {
      "epoch": 7.778620367170188,
      "grad_norm": 0.5079540610313416,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3318,
      "step": 191300
    },
    {
      "epoch": 7.782686482200582,
      "grad_norm": 0.5220973491668701,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.3328,
      "step": 191400
    },
    {
      "epoch": 7.786752597230976,
      "grad_norm": 0.5266324281692505,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3325,
      "step": 191500
    },
    {
      "epoch": 7.79081871226137,
      "grad_norm": 0.41281652450561523,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3314,
      "step": 191600
    },
    {
      "epoch": 7.794884827291764,
      "grad_norm": 0.45075568556785583,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3308,
      "step": 191700
    },
    {
      "epoch": 7.798950942322159,
      "grad_norm": 0.408548504114151,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.331,
      "step": 191800
    },
    {
      "epoch": 7.803017057352553,
      "grad_norm": 0.4743092358112335,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3307,
      "step": 191900
    },
    {
      "epoch": 7.807083172382947,
      "grad_norm": 0.44971728324890137,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3312,
      "step": 192000
    },
    {
      "epoch": 7.807083172382947,
      "eval_loss": 0.34511399269104004,
      "eval_runtime": 128.3042,
      "eval_samples_per_second": 1363.183,
      "eval_steps_per_second": 42.602,
      "step": 192000
    },
    {
      "epoch": 7.811149287413341,
      "grad_norm": 0.5172213315963745,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.334,
      "step": 192100
    },
    {
      "epoch": 7.8152154024437355,
      "grad_norm": 0.4707685112953186,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.3318,
      "step": 192200
    },
    {
      "epoch": 7.8192815174741295,
      "grad_norm": 0.64336097240448,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3299,
      "step": 192300
    },
    {
      "epoch": 7.8233476325045235,
      "grad_norm": 0.5011361241340637,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.3301,
      "step": 192400
    },
    {
      "epoch": 7.8274137475349175,
      "grad_norm": 0.4282893240451813,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.3303,
      "step": 192500
    },
    {
      "epoch": 7.8314798625653115,
      "grad_norm": 0.5130149126052856,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.3321,
      "step": 192600
    },
    {
      "epoch": 7.835545977595706,
      "grad_norm": 0.5107054710388184,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3323,
      "step": 192700
    },
    {
      "epoch": 7.8396120926261,
      "grad_norm": 0.45253974199295044,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.3309,
      "step": 192800
    },
    {
      "epoch": 7.843678207656494,
      "grad_norm": 0.5040562748908997,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.3302,
      "step": 192900
    },
    {
      "epoch": 7.847744322686889,
      "grad_norm": 0.48498305678367615,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.3304,
      "step": 193000
    },
    {
      "epoch": 7.851810437717283,
      "grad_norm": 0.4530718922615051,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.332,
      "step": 193100
    },
    {
      "epoch": 7.855876552747677,
      "grad_norm": 0.4848901629447937,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3316,
      "step": 193200
    },
    {
      "epoch": 7.859942667778071,
      "grad_norm": 0.4699254333972931,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.3312,
      "step": 193300
    },
    {
      "epoch": 7.864008782808465,
      "grad_norm": 0.4873843789100647,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.3305,
      "step": 193400
    },
    {
      "epoch": 7.86807489783886,
      "grad_norm": 0.4078584611415863,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3324,
      "step": 193500
    },
    {
      "epoch": 7.872141012869254,
      "grad_norm": 0.4154438376426697,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3309,
      "step": 193600
    },
    {
      "epoch": 7.876207127899648,
      "grad_norm": 0.44067826867103577,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3299,
      "step": 193700
    },
    {
      "epoch": 7.880273242930042,
      "grad_norm": 0.5266014933586121,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3322,
      "step": 193800
    },
    {
      "epoch": 7.884339357960437,
      "grad_norm": 0.4015795886516571,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3301,
      "step": 193900
    },
    {
      "epoch": 7.888405472990831,
      "grad_norm": 0.47636130452156067,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3312,
      "step": 194000
    },
    {
      "epoch": 7.888405472990831,
      "eval_loss": 0.3448604643344879,
      "eval_runtime": 128.405,
      "eval_samples_per_second": 1362.112,
      "eval_steps_per_second": 42.568,
      "step": 194000
    },
    {
      "epoch": 7.892471588021225,
      "grad_norm": 0.5025016665458679,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3312,
      "step": 194100
    },
    {
      "epoch": 7.896537703051619,
      "grad_norm": 0.44306039810180664,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.33,
      "step": 194200
    },
    {
      "epoch": 7.900603818082013,
      "grad_norm": 0.5341640114784241,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3288,
      "step": 194300
    },
    {
      "epoch": 7.904669933112408,
      "grad_norm": 0.4523947238922119,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3322,
      "step": 194400
    },
    {
      "epoch": 7.908736048142802,
      "grad_norm": 0.5013975501060486,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3312,
      "step": 194500
    },
    {
      "epoch": 7.912802163173196,
      "grad_norm": 0.6417236924171448,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.3315,
      "step": 194600
    },
    {
      "epoch": 7.916868278203591,
      "grad_norm": 0.542608380317688,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.3298,
      "step": 194700
    },
    {
      "epoch": 7.920934393233985,
      "grad_norm": 0.48770397901535034,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3319,
      "step": 194800
    },
    {
      "epoch": 7.925000508264379,
      "grad_norm": 0.44639480113983154,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3308,
      "step": 194900
    },
    {
      "epoch": 7.929066623294773,
      "grad_norm": 0.52614825963974,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.333,
      "step": 195000
    },
    {
      "epoch": 7.933132738325167,
      "grad_norm": 0.4378468692302704,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.3299,
      "step": 195100
    },
    {
      "epoch": 7.937198853355562,
      "grad_norm": 0.4380294382572174,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.3316,
      "step": 195200
    },
    {
      "epoch": 7.941264968385956,
      "grad_norm": 0.4644795060157776,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.3293,
      "step": 195300
    },
    {
      "epoch": 7.94533108341635,
      "grad_norm": 0.47574490308761597,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3303,
      "step": 195400
    },
    {
      "epoch": 7.949397198446744,
      "grad_norm": 0.508347749710083,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3324,
      "step": 195500
    },
    {
      "epoch": 7.953463313477139,
      "grad_norm": 0.6643854379653931,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.3324,
      "step": 195600
    },
    {
      "epoch": 7.957529428507533,
      "grad_norm": 0.5235344171524048,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.3294,
      "step": 195700
    },
    {
      "epoch": 7.961595543537927,
      "grad_norm": 0.5900211334228516,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.3301,
      "step": 195800
    },
    {
      "epoch": 7.965661658568321,
      "grad_norm": 0.5101400017738342,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.3298,
      "step": 195900
    },
    {
      "epoch": 7.969727773598715,
      "grad_norm": 0.5255962610244751,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3336,
      "step": 196000
    },
    {
      "epoch": 7.969727773598715,
      "eval_loss": 0.34397152066230774,
      "eval_runtime": 128.4882,
      "eval_samples_per_second": 1361.23,
      "eval_steps_per_second": 42.541,
      "step": 196000
    },
    {
      "epoch": 7.9737938886291095,
      "grad_norm": 0.47846394777297974,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.33,
      "step": 196100
    },
    {
      "epoch": 7.9778600036595035,
      "grad_norm": 0.47881028056144714,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3314,
      "step": 196200
    },
    {
      "epoch": 7.9819261186898975,
      "grad_norm": 0.5459492802619934,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3308,
      "step": 196300
    },
    {
      "epoch": 7.985992233720292,
      "grad_norm": 0.5122057199478149,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3313,
      "step": 196400
    },
    {
      "epoch": 7.990058348750686,
      "grad_norm": 0.47346389293670654,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3327,
      "step": 196500
    },
    {
      "epoch": 7.99412446378108,
      "grad_norm": 0.4886418581008911,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.331,
      "step": 196600
    },
    {
      "epoch": 7.998190578811474,
      "grad_norm": 0.5716721415519714,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.3288,
      "step": 196700
    },
    {
      "epoch": 8.002256693841868,
      "grad_norm": 0.5228555798530579,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3269,
      "step": 196800
    },
    {
      "epoch": 8.006322808872262,
      "grad_norm": 0.47397327423095703,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.3216,
      "step": 196900
    },
    {
      "epoch": 8.010388923902656,
      "grad_norm": 0.49805116653442383,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3228,
      "step": 197000
    },
    {
      "epoch": 8.014455038933052,
      "grad_norm": 0.5143176317214966,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3214,
      "step": 197100
    },
    {
      "epoch": 8.018521153963446,
      "grad_norm": 0.6215352416038513,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.3216,
      "step": 197200
    },
    {
      "epoch": 8.02258726899384,
      "grad_norm": 0.5214052796363831,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.3237,
      "step": 197300
    },
    {
      "epoch": 8.026653384024234,
      "grad_norm": 0.49088403582572937,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.3229,
      "step": 197400
    },
    {
      "epoch": 8.030719499054628,
      "grad_norm": 0.5262519121170044,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3241,
      "step": 197500
    },
    {
      "epoch": 8.034785614085022,
      "grad_norm": 0.5190030932426453,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.3213,
      "step": 197600
    },
    {
      "epoch": 8.038851729115416,
      "grad_norm": 0.5084043145179749,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.3247,
      "step": 197700
    },
    {
      "epoch": 8.04291784414581,
      "grad_norm": 0.599636971950531,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.324,
      "step": 197800
    },
    {
      "epoch": 8.046983959176204,
      "grad_norm": 0.5603830218315125,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3233,
      "step": 197900
    },
    {
      "epoch": 8.0510500742066,
      "grad_norm": 0.49542224407196045,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3227,
      "step": 198000
    },
    {
      "epoch": 8.0510500742066,
      "eval_loss": 0.3446522355079651,
      "eval_runtime": 128.8142,
      "eval_samples_per_second": 1357.785,
      "eval_steps_per_second": 42.433,
      "step": 198000
    },
    {
      "epoch": 8.055116189236994,
      "grad_norm": 0.49794697761535645,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3238,
      "step": 198100
    },
    {
      "epoch": 8.059182304267388,
      "grad_norm": 0.5987069606781006,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3224,
      "step": 198200
    },
    {
      "epoch": 8.063248419297782,
      "grad_norm": 0.4845798909664154,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.3235,
      "step": 198300
    },
    {
      "epoch": 8.067314534328176,
      "grad_norm": 0.5430120825767517,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3227,
      "step": 198400
    },
    {
      "epoch": 8.07138064935857,
      "grad_norm": 0.45241254568099976,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.3237,
      "step": 198500
    },
    {
      "epoch": 8.075446764388964,
      "grad_norm": 0.5594605803489685,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3214,
      "step": 198600
    },
    {
      "epoch": 8.079512879419358,
      "grad_norm": 0.49489495158195496,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3233,
      "step": 198700
    },
    {
      "epoch": 8.083578994449754,
      "grad_norm": 0.4682264029979706,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3255,
      "step": 198800
    },
    {
      "epoch": 8.087645109480148,
      "grad_norm": 0.5718285441398621,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.3233,
      "step": 198900
    },
    {
      "epoch": 8.091711224510542,
      "grad_norm": 0.5480676889419556,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3232,
      "step": 199000
    },
    {
      "epoch": 8.095777339540936,
      "grad_norm": 0.5623394846916199,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3252,
      "step": 199100
    },
    {
      "epoch": 8.09984345457133,
      "grad_norm": 0.5348929166793823,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.3242,
      "step": 199200
    },
    {
      "epoch": 8.103909569601724,
      "grad_norm": 0.5859165787696838,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.3235,
      "step": 199300
    },
    {
      "epoch": 8.107975684632118,
      "grad_norm": 0.6809841394424438,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3235,
      "step": 199400
    },
    {
      "epoch": 8.112041799662512,
      "grad_norm": 0.49967795610427856,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3244,
      "step": 199500
    },
    {
      "epoch": 8.116107914692906,
      "grad_norm": 0.5062916874885559,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.3243,
      "step": 199600
    },
    {
      "epoch": 8.120174029723302,
      "grad_norm": 0.5162121653556824,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3232,
      "step": 199700
    },
    {
      "epoch": 8.124240144753696,
      "grad_norm": 0.5030049085617065,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.322,
      "step": 199800
    },
    {
      "epoch": 8.12830625978409,
      "grad_norm": 0.5617239475250244,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3251,
      "step": 199900
    },
    {
      "epoch": 8.132372374814484,
      "grad_norm": 0.471958190202713,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3245,
      "step": 200000
    },
    {
      "epoch": 8.132372374814484,
      "eval_loss": 0.34375983476638794,
      "eval_runtime": 128.5662,
      "eval_samples_per_second": 1360.405,
      "eval_steps_per_second": 42.515,
      "step": 200000
    },
    {
      "epoch": 8.136438489844878,
      "grad_norm": 0.5204257965087891,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.3238,
      "step": 200100
    },
    {
      "epoch": 8.140504604875272,
      "grad_norm": 0.4953624904155731,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.3245,
      "step": 200200
    },
    {
      "epoch": 8.144570719905666,
      "grad_norm": 0.47763320803642273,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.3237,
      "step": 200300
    },
    {
      "epoch": 8.14863683493606,
      "grad_norm": 0.5449253916740417,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.3251,
      "step": 200400
    },
    {
      "epoch": 8.152702949966455,
      "grad_norm": 0.5838944315910339,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3245,
      "step": 200500
    },
    {
      "epoch": 8.15676906499685,
      "grad_norm": 0.47053566575050354,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3243,
      "step": 200600
    },
    {
      "epoch": 8.160835180027243,
      "grad_norm": 0.5018200278282166,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3236,
      "step": 200700
    },
    {
      "epoch": 8.164901295057637,
      "grad_norm": 0.4513404369354248,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.3241,
      "step": 200800
    },
    {
      "epoch": 8.168967410088031,
      "grad_norm": 0.5585017204284668,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.3233,
      "step": 200900
    },
    {
      "epoch": 8.173033525118425,
      "grad_norm": 0.6154435276985168,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3254,
      "step": 201000
    },
    {
      "epoch": 8.17709964014882,
      "grad_norm": 0.592434287071228,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3243,
      "step": 201100
    },
    {
      "epoch": 8.181165755179213,
      "grad_norm": 0.5539119839668274,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.322,
      "step": 201200
    },
    {
      "epoch": 8.185231870209607,
      "grad_norm": 0.5255270600318909,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3241,
      "step": 201300
    },
    {
      "epoch": 8.189297985240003,
      "grad_norm": 0.48493391275405884,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3229,
      "step": 201400
    },
    {
      "epoch": 8.193364100270397,
      "grad_norm": 0.5901690721511841,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.3262,
      "step": 201500
    },
    {
      "epoch": 8.197430215300791,
      "grad_norm": 0.5339503288269043,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.325,
      "step": 201600
    },
    {
      "epoch": 8.201496330331185,
      "grad_norm": 0.488558292388916,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3238,
      "step": 201700
    },
    {
      "epoch": 8.20556244536158,
      "grad_norm": 0.5500580072402954,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.325,
      "step": 201800
    },
    {
      "epoch": 8.209628560391973,
      "grad_norm": 0.5283405780792236,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3243,
      "step": 201900
    },
    {
      "epoch": 8.213694675422367,
      "grad_norm": 0.5093289613723755,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3246,
      "step": 202000
    },
    {
      "epoch": 8.213694675422367,
      "eval_loss": 0.3437112867832184,
      "eval_runtime": 128.366,
      "eval_samples_per_second": 1362.526,
      "eval_steps_per_second": 42.581,
      "step": 202000
    },
    {
      "epoch": 8.217760790452761,
      "grad_norm": 0.5077066421508789,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.3232,
      "step": 202100
    },
    {
      "epoch": 8.221826905483157,
      "grad_norm": 0.57794189453125,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3244,
      "step": 202200
    },
    {
      "epoch": 8.225893020513551,
      "grad_norm": 0.5119087100028992,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.3239,
      "step": 202300
    },
    {
      "epoch": 8.229959135543945,
      "grad_norm": 0.7594048380851746,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.3244,
      "step": 202400
    },
    {
      "epoch": 8.234025250574339,
      "grad_norm": 0.5250563621520996,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3253,
      "step": 202500
    },
    {
      "epoch": 8.238091365604733,
      "grad_norm": 0.5550490021705627,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3237,
      "step": 202600
    },
    {
      "epoch": 8.242157480635127,
      "grad_norm": 0.4629041254520416,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.3248,
      "step": 202700
    },
    {
      "epoch": 8.246223595665521,
      "grad_norm": 0.7495657801628113,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3237,
      "step": 202800
    },
    {
      "epoch": 8.250289710695915,
      "grad_norm": 0.6286096572875977,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3257,
      "step": 202900
    },
    {
      "epoch": 8.254355825726309,
      "grad_norm": 0.5589398741722107,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3249,
      "step": 203000
    },
    {
      "epoch": 8.258421940756705,
      "grad_norm": 0.564067542552948,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3238,
      "step": 203100
    },
    {
      "epoch": 8.262488055787099,
      "grad_norm": 0.5758890509605408,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.3235,
      "step": 203200
    },
    {
      "epoch": 8.266554170817493,
      "grad_norm": 0.5669216513633728,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3257,
      "step": 203300
    },
    {
      "epoch": 8.270620285847887,
      "grad_norm": 0.5258713364601135,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.324,
      "step": 203400
    },
    {
      "epoch": 8.27468640087828,
      "grad_norm": 0.5545690655708313,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.3258,
      "step": 203500
    },
    {
      "epoch": 8.278752515908675,
      "grad_norm": 0.5316355228424072,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.3254,
      "step": 203600
    },
    {
      "epoch": 8.282818630939069,
      "grad_norm": 0.6426582932472229,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3228,
      "step": 203700
    },
    {
      "epoch": 8.286884745969463,
      "grad_norm": 0.5450250506401062,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.3242,
      "step": 203800
    },
    {
      "epoch": 8.290950860999857,
      "grad_norm": 0.5171481370925903,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.3233,
      "step": 203900
    },
    {
      "epoch": 8.295016976030253,
      "grad_norm": 0.5269017219543457,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3232,
      "step": 204000
    },
    {
      "epoch": 8.295016976030253,
      "eval_loss": 0.34260302782058716,
      "eval_runtime": 127.0207,
      "eval_samples_per_second": 1376.957,
      "eval_steps_per_second": 43.032,
      "step": 204000
    },
    {
      "epoch": 8.299083091060647,
      "grad_norm": 0.5820372700691223,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.3246,
      "step": 204100
    },
    {
      "epoch": 8.30314920609104,
      "grad_norm": 0.626911461353302,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.324,
      "step": 204200
    },
    {
      "epoch": 8.307215321121435,
      "grad_norm": 0.5453372597694397,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.3245,
      "step": 204300
    },
    {
      "epoch": 8.311281436151829,
      "grad_norm": 0.5949531197547913,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3252,
      "step": 204400
    },
    {
      "epoch": 8.315347551182223,
      "grad_norm": 0.6789676547050476,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.3239,
      "step": 204500
    },
    {
      "epoch": 8.319413666212617,
      "grad_norm": 0.5290845632553101,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.325,
      "step": 204600
    },
    {
      "epoch": 8.32347978124301,
      "grad_norm": 0.5420092344284058,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.325,
      "step": 204700
    },
    {
      "epoch": 8.327545896273406,
      "grad_norm": 0.5121186971664429,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3231,
      "step": 204800
    },
    {
      "epoch": 8.3316120113038,
      "grad_norm": 0.5489424467086792,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.3233,
      "step": 204900
    },
    {
      "epoch": 8.335678126334194,
      "grad_norm": 0.5243133902549744,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.3228,
      "step": 205000
    },
    {
      "epoch": 8.339744241364588,
      "grad_norm": 0.5176642537117004,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.3243,
      "step": 205100
    },
    {
      "epoch": 8.343810356394982,
      "grad_norm": 0.5234748721122742,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.3242,
      "step": 205200
    },
    {
      "epoch": 8.347876471425376,
      "grad_norm": 0.6520861983299255,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3242,
      "step": 205300
    },
    {
      "epoch": 8.35194258645577,
      "grad_norm": 0.557511031627655,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3239,
      "step": 205400
    },
    {
      "epoch": 8.356008701486164,
      "grad_norm": 0.5909185409545898,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.3239,
      "step": 205500
    },
    {
      "epoch": 8.360074816516558,
      "grad_norm": 0.5531463027000427,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3251,
      "step": 205600
    },
    {
      "epoch": 8.364140931546954,
      "grad_norm": 0.5929852724075317,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3242,
      "step": 205700
    },
    {
      "epoch": 8.368207046577348,
      "grad_norm": 0.5578016042709351,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3246,
      "step": 205800
    },
    {
      "epoch": 8.372273161607742,
      "grad_norm": 0.5246683955192566,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3242,
      "step": 205900
    },
    {
      "epoch": 8.376339276638136,
      "grad_norm": 0.48611441254615784,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3251,
      "step": 206000
    },
    {
      "epoch": 8.376339276638136,
      "eval_loss": 0.34227925539016724,
      "eval_runtime": 126.5111,
      "eval_samples_per_second": 1382.503,
      "eval_steps_per_second": 43.206,
      "step": 206000
    },
    {
      "epoch": 8.38040539166853,
      "grad_norm": 0.5668878555297852,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3244,
      "step": 206100
    },
    {
      "epoch": 8.384471506698924,
      "grad_norm": 0.624036967754364,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.3255,
      "step": 206200
    },
    {
      "epoch": 8.388537621729318,
      "grad_norm": 0.5523011088371277,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.3244,
      "step": 206300
    },
    {
      "epoch": 8.392603736759712,
      "grad_norm": 0.5406026244163513,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.3268,
      "step": 206400
    },
    {
      "epoch": 8.396669851790108,
      "grad_norm": 0.5107204914093018,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3242,
      "step": 206500
    },
    {
      "epoch": 8.400735966820502,
      "grad_norm": 0.5211673378944397,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.3245,
      "step": 206600
    },
    {
      "epoch": 8.404802081850896,
      "grad_norm": 0.5510312914848328,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.3255,
      "step": 206700
    },
    {
      "epoch": 8.40886819688129,
      "grad_norm": 0.5190000534057617,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.324,
      "step": 206800
    },
    {
      "epoch": 8.412934311911684,
      "grad_norm": 0.5621674656867981,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.3248,
      "step": 206900
    },
    {
      "epoch": 8.417000426942078,
      "grad_norm": 0.5758163928985596,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3238,
      "step": 207000
    },
    {
      "epoch": 8.421066541972472,
      "grad_norm": 0.5582753419876099,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3214,
      "step": 207100
    },
    {
      "epoch": 8.425132657002866,
      "grad_norm": 0.5166999101638794,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3233,
      "step": 207200
    },
    {
      "epoch": 8.42919877203326,
      "grad_norm": 0.5458462834358215,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3237,
      "step": 207300
    },
    {
      "epoch": 8.433264887063656,
      "grad_norm": 0.5979138016700745,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3248,
      "step": 207400
    },
    {
      "epoch": 8.43733100209405,
      "grad_norm": 0.49479663372039795,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3239,
      "step": 207500
    },
    {
      "epoch": 8.441397117124444,
      "grad_norm": 0.5263182520866394,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3224,
      "step": 207600
    },
    {
      "epoch": 8.445463232154838,
      "grad_norm": 0.5617986917495728,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3238,
      "step": 207700
    },
    {
      "epoch": 8.449529347185232,
      "grad_norm": 0.551766574382782,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3217,
      "step": 207800
    },
    {
      "epoch": 8.453595462215626,
      "grad_norm": 0.583624541759491,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3228,
      "step": 207900
    },
    {
      "epoch": 8.45766157724602,
      "grad_norm": 0.6500180959701538,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.3247,
      "step": 208000
    },
    {
      "epoch": 8.45766157724602,
      "eval_loss": 0.3421495854854584,
      "eval_runtime": 127.4776,
      "eval_samples_per_second": 1372.021,
      "eval_steps_per_second": 42.878,
      "step": 208000
    },
    {
      "epoch": 8.461727692276414,
      "grad_norm": 0.5393113493919373,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.3235,
      "step": 208100
    },
    {
      "epoch": 8.46579380730681,
      "grad_norm": 0.6555855870246887,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.3238,
      "step": 208200
    },
    {
      "epoch": 8.469859922337204,
      "grad_norm": 0.5034067630767822,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.322,
      "step": 208300
    },
    {
      "epoch": 8.473926037367598,
      "grad_norm": 0.583141565322876,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3247,
      "step": 208400
    },
    {
      "epoch": 8.477992152397992,
      "grad_norm": 0.5393138527870178,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.3241,
      "step": 208500
    },
    {
      "epoch": 8.482058267428386,
      "grad_norm": 0.5153028964996338,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.3236,
      "step": 208600
    },
    {
      "epoch": 8.48612438245878,
      "grad_norm": 0.5780594944953918,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3234,
      "step": 208700
    },
    {
      "epoch": 8.490190497489174,
      "grad_norm": 0.4635453522205353,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.3224,
      "step": 208800
    },
    {
      "epoch": 8.494256612519568,
      "grad_norm": 0.6226675510406494,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.3229,
      "step": 208900
    },
    {
      "epoch": 8.498322727549962,
      "grad_norm": 0.5919828414916992,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3216,
      "step": 209000
    },
    {
      "epoch": 8.502388842580357,
      "grad_norm": 0.6164571046829224,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.3229,
      "step": 209100
    },
    {
      "epoch": 8.506454957610751,
      "grad_norm": 0.4962732195854187,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.3248,
      "step": 209200
    },
    {
      "epoch": 8.510521072641145,
      "grad_norm": 0.4889764189720154,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.3238,
      "step": 209300
    },
    {
      "epoch": 8.51458718767154,
      "grad_norm": 0.6220820546150208,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.3234,
      "step": 209400
    },
    {
      "epoch": 8.518653302701933,
      "grad_norm": 0.5550642013549805,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.3247,
      "step": 209500
    },
    {
      "epoch": 8.522719417732327,
      "grad_norm": 0.6811287999153137,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.3222,
      "step": 209600
    },
    {
      "epoch": 8.526785532762721,
      "grad_norm": 0.5853649377822876,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.323,
      "step": 209700
    },
    {
      "epoch": 8.530851647793115,
      "grad_norm": 0.5843417644500732,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.3229,
      "step": 209800
    },
    {
      "epoch": 8.534917762823511,
      "grad_norm": 0.5419776439666748,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3231,
      "step": 209900
    },
    {
      "epoch": 8.538983877853905,
      "grad_norm": 0.5569376945495605,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3246,
      "step": 210000
    },
    {
      "epoch": 8.538983877853905,
      "eval_loss": 0.3412133753299713,
      "eval_runtime": 127.5484,
      "eval_samples_per_second": 1371.26,
      "eval_steps_per_second": 42.854,
      "step": 210000
    },
    {
      "epoch": 8.5430499928843,
      "grad_norm": 0.6166926026344299,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.3249,
      "step": 210100
    },
    {
      "epoch": 8.547116107914693,
      "grad_norm": 0.5434672832489014,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.3255,
      "step": 210200
    },
    {
      "epoch": 8.551182222945087,
      "grad_norm": 0.5110474824905396,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.324,
      "step": 210300
    },
    {
      "epoch": 8.555248337975481,
      "grad_norm": 0.5570275783538818,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3251,
      "step": 210400
    },
    {
      "epoch": 8.559314453005875,
      "grad_norm": 0.6107083559036255,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3228,
      "step": 210500
    },
    {
      "epoch": 8.56338056803627,
      "grad_norm": 0.5306973457336426,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.3239,
      "step": 210600
    },
    {
      "epoch": 8.567446683066663,
      "grad_norm": 0.6323567032814026,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3246,
      "step": 210700
    },
    {
      "epoch": 8.571512798097059,
      "grad_norm": 0.6171587705612183,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.3236,
      "step": 210800
    },
    {
      "epoch": 8.575578913127453,
      "grad_norm": 0.5125892162322998,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3237,
      "step": 210900
    },
    {
      "epoch": 8.579645028157847,
      "grad_norm": 0.6072330474853516,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.3251,
      "step": 211000
    },
    {
      "epoch": 8.583711143188241,
      "grad_norm": 0.5564266443252563,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3242,
      "step": 211100
    },
    {
      "epoch": 8.587777258218635,
      "grad_norm": 0.811286449432373,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3216,
      "step": 211200
    },
    {
      "epoch": 8.591843373249029,
      "grad_norm": 0.5422736406326294,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3226,
      "step": 211300
    },
    {
      "epoch": 8.595909488279423,
      "grad_norm": 0.5348929166793823,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3245,
      "step": 211400
    },
    {
      "epoch": 8.599975603309817,
      "grad_norm": 0.5345761179924011,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3246,
      "step": 211500
    },
    {
      "epoch": 8.604041718340213,
      "grad_norm": 0.7471492290496826,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.3244,
      "step": 211600
    },
    {
      "epoch": 8.608107833370607,
      "grad_norm": 0.6813713312149048,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.3239,
      "step": 211700
    },
    {
      "epoch": 8.612173948401,
      "grad_norm": 0.6093704700469971,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3218,
      "step": 211800
    },
    {
      "epoch": 8.616240063431395,
      "grad_norm": 0.5344207882881165,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.3217,
      "step": 211900
    },
    {
      "epoch": 8.620306178461789,
      "grad_norm": 0.5960833430290222,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3222,
      "step": 212000
    },
    {
      "epoch": 8.620306178461789,
      "eval_loss": 0.3405842185020447,
      "eval_runtime": 127.1534,
      "eval_samples_per_second": 1375.52,
      "eval_steps_per_second": 42.987,
      "step": 212000
    },
    {
      "epoch": 8.624372293492183,
      "grad_norm": 0.5859869718551636,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3234,
      "step": 212100
    },
    {
      "epoch": 8.628438408522577,
      "grad_norm": 0.5581748485565186,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.3215,
      "step": 212200
    },
    {
      "epoch": 8.63250452355297,
      "grad_norm": 0.5640069246292114,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3225,
      "step": 212300
    },
    {
      "epoch": 8.636570638583365,
      "grad_norm": 0.6007125377655029,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.324,
      "step": 212400
    },
    {
      "epoch": 8.64063675361376,
      "grad_norm": 0.6444980502128601,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3243,
      "step": 212500
    },
    {
      "epoch": 8.644702868644154,
      "grad_norm": 0.6598495841026306,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.3224,
      "step": 212600
    },
    {
      "epoch": 8.648768983674548,
      "grad_norm": 0.7659025192260742,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3234,
      "step": 212700
    },
    {
      "epoch": 8.652835098704942,
      "grad_norm": 0.5342002511024475,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.3231,
      "step": 212800
    },
    {
      "epoch": 8.656901213735336,
      "grad_norm": 0.6131137013435364,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3231,
      "step": 212900
    },
    {
      "epoch": 8.66096732876573,
      "grad_norm": 0.6125653386116028,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.3224,
      "step": 213000
    },
    {
      "epoch": 8.665033443796125,
      "grad_norm": 0.557657778263092,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3207,
      "step": 213100
    },
    {
      "epoch": 8.669099558826519,
      "grad_norm": 0.6038690805435181,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.3221,
      "step": 213200
    },
    {
      "epoch": 8.673165673856914,
      "grad_norm": 0.558090329170227,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.3218,
      "step": 213300
    },
    {
      "epoch": 8.677231788887308,
      "grad_norm": 0.6171888709068298,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.323,
      "step": 213400
    },
    {
      "epoch": 8.681297903917702,
      "grad_norm": 0.5344562530517578,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3229,
      "step": 213500
    },
    {
      "epoch": 8.685364018948096,
      "grad_norm": 0.6412453651428223,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3246,
      "step": 213600
    },
    {
      "epoch": 8.68943013397849,
      "grad_norm": 0.617914617061615,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3205,
      "step": 213700
    },
    {
      "epoch": 8.693496249008884,
      "grad_norm": 0.5446550846099854,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3217,
      "step": 213800
    },
    {
      "epoch": 8.697562364039278,
      "grad_norm": 0.7223069071769714,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.3225,
      "step": 213900
    },
    {
      "epoch": 8.701628479069672,
      "grad_norm": 0.4841431975364685,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.3221,
      "step": 214000
    },
    {
      "epoch": 8.701628479069672,
      "eval_loss": 0.3397650122642517,
      "eval_runtime": 127.0185,
      "eval_samples_per_second": 1376.98,
      "eval_steps_per_second": 43.033,
      "step": 214000
    },
    {
      "epoch": 8.705694594100066,
      "grad_norm": 0.6130407452583313,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.3211,
      "step": 214100
    },
    {
      "epoch": 8.709760709130462,
      "grad_norm": 0.5254526138305664,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.3222,
      "step": 214200
    },
    {
      "epoch": 8.713826824160856,
      "grad_norm": 0.5809773206710815,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.3222,
      "step": 214300
    },
    {
      "epoch": 8.71789293919125,
      "grad_norm": 0.5569446086883545,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3231,
      "step": 214400
    },
    {
      "epoch": 8.721959054221644,
      "grad_norm": 0.5395902395248413,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3219,
      "step": 214500
    },
    {
      "epoch": 8.726025169252038,
      "grad_norm": 0.5680211782455444,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.323,
      "step": 214600
    },
    {
      "epoch": 8.730091284282432,
      "grad_norm": 0.5740039944648743,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.3209,
      "step": 214700
    },
    {
      "epoch": 8.734157399312826,
      "grad_norm": 0.6461465358734131,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3234,
      "step": 214800
    },
    {
      "epoch": 8.73822351434322,
      "grad_norm": 0.5582561492919922,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.323,
      "step": 214900
    },
    {
      "epoch": 8.742289629373616,
      "grad_norm": 0.5619703531265259,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3239,
      "step": 215000
    },
    {
      "epoch": 8.74635574440401,
      "grad_norm": 0.5708910226821899,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.323,
      "step": 215100
    },
    {
      "epoch": 8.750421859434404,
      "grad_norm": 0.5987485647201538,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.3254,
      "step": 215200
    },
    {
      "epoch": 8.754487974464798,
      "grad_norm": 0.505443811416626,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3213,
      "step": 215300
    },
    {
      "epoch": 8.758554089495192,
      "grad_norm": 0.4859630763530731,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.323,
      "step": 215400
    },
    {
      "epoch": 8.762620204525586,
      "grad_norm": 0.5804499387741089,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3212,
      "step": 215500
    },
    {
      "epoch": 8.76668631955598,
      "grad_norm": 0.6254487633705139,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.3233,
      "step": 215600
    },
    {
      "epoch": 8.770752434586374,
      "grad_norm": 0.6927347779273987,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3218,
      "step": 215700
    },
    {
      "epoch": 8.774818549616768,
      "grad_norm": 0.6208152770996094,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3227,
      "step": 215800
    },
    {
      "epoch": 8.778884664647164,
      "grad_norm": 0.5335691571235657,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.3225,
      "step": 215900
    },
    {
      "epoch": 8.782950779677558,
      "grad_norm": 0.537154495716095,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.3215,
      "step": 216000
    },
    {
      "epoch": 8.782950779677558,
      "eval_loss": 0.33943676948547363,
      "eval_runtime": 127.6791,
      "eval_samples_per_second": 1369.856,
      "eval_steps_per_second": 42.81,
      "step": 216000
    },
    {
      "epoch": 8.787016894707952,
      "grad_norm": 0.6480246186256409,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3219,
      "step": 216100
    },
    {
      "epoch": 8.791083009738346,
      "grad_norm": 0.5095362067222595,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.3219,
      "step": 216200
    },
    {
      "epoch": 8.79514912476874,
      "grad_norm": 0.670664370059967,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.322,
      "step": 216300
    },
    {
      "epoch": 8.799215239799134,
      "grad_norm": 0.6284443140029907,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.3207,
      "step": 216400
    },
    {
      "epoch": 8.803281354829528,
      "grad_norm": 0.6830998063087463,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.3234,
      "step": 216500
    },
    {
      "epoch": 8.807347469859922,
      "grad_norm": 0.5587319731712341,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3215,
      "step": 216600
    },
    {
      "epoch": 8.811413584890317,
      "grad_norm": 0.5783663392066956,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.3227,
      "step": 216700
    },
    {
      "epoch": 8.815479699920711,
      "grad_norm": 0.6255548596382141,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.3208,
      "step": 216800
    },
    {
      "epoch": 8.819545814951105,
      "grad_norm": 0.7001367211341858,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3228,
      "step": 216900
    },
    {
      "epoch": 8.8236119299815,
      "grad_norm": 0.603217601776123,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.3229,
      "step": 217000
    },
    {
      "epoch": 8.827678045011893,
      "grad_norm": 0.696137011051178,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3226,
      "step": 217100
    },
    {
      "epoch": 8.831744160042287,
      "grad_norm": 0.6409090161323547,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.321,
      "step": 217200
    },
    {
      "epoch": 8.835810275072681,
      "grad_norm": 0.5889882445335388,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3224,
      "step": 217300
    },
    {
      "epoch": 8.839876390103075,
      "grad_norm": 0.5817132592201233,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.3228,
      "step": 217400
    },
    {
      "epoch": 8.84394250513347,
      "grad_norm": 0.5540623664855957,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3212,
      "step": 217500
    },
    {
      "epoch": 8.848008620163865,
      "grad_norm": 0.6287691593170166,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3212,
      "step": 217600
    },
    {
      "epoch": 8.85207473519426,
      "grad_norm": 0.7023006677627563,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3227,
      "step": 217700
    },
    {
      "epoch": 8.856140850224653,
      "grad_norm": 0.6986900568008423,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.3212,
      "step": 217800
    },
    {
      "epoch": 8.860206965255047,
      "grad_norm": 0.5827776193618774,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3216,
      "step": 217900
    },
    {
      "epoch": 8.864273080285441,
      "grad_norm": 0.5652654767036438,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3221,
      "step": 218000
    },
    {
      "epoch": 8.864273080285441,
      "eval_loss": 0.3387526571750641,
      "eval_runtime": 126.9802,
      "eval_samples_per_second": 1377.396,
      "eval_steps_per_second": 43.046,
      "step": 218000
    },
    {
      "epoch": 8.868339195315835,
      "grad_norm": 0.5782860517501831,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.321,
      "step": 218100
    },
    {
      "epoch": 8.87240531034623,
      "grad_norm": 0.6643894910812378,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.3222,
      "step": 218200
    },
    {
      "epoch": 8.876471425376623,
      "grad_norm": 0.6524621248245239,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3215,
      "step": 218300
    },
    {
      "epoch": 8.880537540407019,
      "grad_norm": 0.6189484000205994,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3224,
      "step": 218400
    },
    {
      "epoch": 8.884603655437413,
      "grad_norm": 0.6589392423629761,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.322,
      "step": 218500
    },
    {
      "epoch": 8.888669770467807,
      "grad_norm": 0.5608350038528442,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3216,
      "step": 218600
    },
    {
      "epoch": 8.892735885498201,
      "grad_norm": 0.728456974029541,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3216,
      "step": 218700
    },
    {
      "epoch": 8.896802000528595,
      "grad_norm": 0.7575768828392029,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3215,
      "step": 218800
    },
    {
      "epoch": 8.900868115558989,
      "grad_norm": 0.679964542388916,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3196,
      "step": 218900
    },
    {
      "epoch": 8.904934230589383,
      "grad_norm": 0.5656831860542297,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3206,
      "step": 219000
    },
    {
      "epoch": 8.909000345619777,
      "grad_norm": 0.6619282960891724,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3213,
      "step": 219100
    },
    {
      "epoch": 8.913066460650171,
      "grad_norm": 0.5578778982162476,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3212,
      "step": 219200
    },
    {
      "epoch": 8.917132575680567,
      "grad_norm": 0.605099081993103,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3227,
      "step": 219300
    },
    {
      "epoch": 8.92119869071096,
      "grad_norm": 0.5971964597702026,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3194,
      "step": 219400
    },
    {
      "epoch": 8.925264805741355,
      "grad_norm": 0.66092848777771,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3221,
      "step": 219500
    },
    {
      "epoch": 8.929330920771749,
      "grad_norm": 0.6217513084411621,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.321,
      "step": 219600
    },
    {
      "epoch": 8.933397035802143,
      "grad_norm": 0.6736869215965271,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.321,
      "step": 219700
    },
    {
      "epoch": 8.937463150832537,
      "grad_norm": 0.7073030471801758,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.3215,
      "step": 219800
    },
    {
      "epoch": 8.94152926586293,
      "grad_norm": 0.7819175124168396,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.322,
      "step": 219900
    },
    {
      "epoch": 8.945595380893325,
      "grad_norm": 0.6446282267570496,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.3211,
      "step": 220000
    },
    {
      "epoch": 8.945595380893325,
      "eval_loss": 0.3381209671497345,
      "eval_runtime": 127.1938,
      "eval_samples_per_second": 1375.083,
      "eval_steps_per_second": 42.974,
      "step": 220000
    },
    {
      "epoch": 8.94966149592372,
      "grad_norm": 0.5601576566696167,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3218,
      "step": 220100
    },
    {
      "epoch": 8.953727610954115,
      "grad_norm": 0.6557216644287109,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.321,
      "step": 220200
    },
    {
      "epoch": 8.957793725984509,
      "grad_norm": 0.5943346619606018,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.3211,
      "step": 220300
    },
    {
      "epoch": 8.961859841014903,
      "grad_norm": 0.5978757739067078,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.319,
      "step": 220400
    },
    {
      "epoch": 8.965925956045297,
      "grad_norm": 0.6372796297073364,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.3209,
      "step": 220500
    },
    {
      "epoch": 8.96999207107569,
      "grad_norm": 0.5412796139717102,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.3213,
      "step": 220600
    },
    {
      "epoch": 8.974058186106085,
      "grad_norm": 0.5778251886367798,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.3208,
      "step": 220700
    },
    {
      "epoch": 8.978124301136479,
      "grad_norm": 0.5966966152191162,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.321,
      "step": 220800
    },
    {
      "epoch": 8.982190416166873,
      "grad_norm": 0.6112499237060547,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3214,
      "step": 220900
    },
    {
      "epoch": 8.986256531197267,
      "grad_norm": 0.6235182285308838,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.3197,
      "step": 221000
    },
    {
      "epoch": 8.990322646227662,
      "grad_norm": 0.6266288161277771,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.3209,
      "step": 221100
    },
    {
      "epoch": 8.994388761258056,
      "grad_norm": 0.6633028388023376,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3232,
      "step": 221200
    },
    {
      "epoch": 8.99845487628845,
      "grad_norm": 0.5896857380867004,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.3202,
      "step": 221300
    },
    {
      "epoch": 9.002520991318844,
      "grad_norm": 0.6137574911117554,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3155,
      "step": 221400
    },
    {
      "epoch": 9.006587106349238,
      "grad_norm": 0.7237056493759155,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.3145,
      "step": 221500
    },
    {
      "epoch": 9.010653221379632,
      "grad_norm": 0.7926182746887207,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3124,
      "step": 221600
    },
    {
      "epoch": 9.014719336410026,
      "grad_norm": 0.5996559262275696,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3115,
      "step": 221700
    },
    {
      "epoch": 9.01878545144042,
      "grad_norm": 0.7252402901649475,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.3124,
      "step": 221800
    },
    {
      "epoch": 9.022851566470816,
      "grad_norm": 0.6979733109474182,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.312,
      "step": 221900
    },
    {
      "epoch": 9.02691768150121,
      "grad_norm": 0.6069324016571045,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3134,
      "step": 222000
    },
    {
      "epoch": 9.02691768150121,
      "eval_loss": 0.33846497535705566,
      "eval_runtime": 127.2942,
      "eval_samples_per_second": 1373.999,
      "eval_steps_per_second": 42.94,
      "step": 222000
    },
    {
      "epoch": 9.030983796531604,
      "grad_norm": 0.6384845972061157,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3129,
      "step": 222100
    },
    {
      "epoch": 9.035049911561998,
      "grad_norm": 0.71611487865448,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.3138,
      "step": 222200
    },
    {
      "epoch": 9.039116026592392,
      "grad_norm": 0.7667897939682007,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3131,
      "step": 222300
    },
    {
      "epoch": 9.043182141622786,
      "grad_norm": 0.6299424171447754,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3131,
      "step": 222400
    },
    {
      "epoch": 9.04724825665318,
      "grad_norm": 0.6524081230163574,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.3126,
      "step": 222500
    },
    {
      "epoch": 9.051314371683574,
      "grad_norm": 0.5182570219039917,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.312,
      "step": 222600
    },
    {
      "epoch": 9.05538048671397,
      "grad_norm": 0.6782135963439941,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.312,
      "step": 222700
    },
    {
      "epoch": 9.059446601744364,
      "grad_norm": 0.61101895570755,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.3113,
      "step": 222800
    },
    {
      "epoch": 9.063512716774758,
      "grad_norm": 0.6578423380851746,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3127,
      "step": 222900
    },
    {
      "epoch": 9.067578831805152,
      "grad_norm": 0.6478095054626465,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.3111,
      "step": 223000
    },
    {
      "epoch": 9.071644946835546,
      "grad_norm": 0.5884467959403992,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.3134,
      "step": 223100
    },
    {
      "epoch": 9.07571106186594,
      "grad_norm": 0.5871527194976807,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3122,
      "step": 223200
    },
    {
      "epoch": 9.079777176896334,
      "grad_norm": 0.6086544990539551,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.311,
      "step": 223300
    },
    {
      "epoch": 9.083843291926728,
      "grad_norm": 0.6008301973342896,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.312,
      "step": 223400
    },
    {
      "epoch": 9.087909406957122,
      "grad_norm": 0.6686609983444214,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3136,
      "step": 223500
    },
    {
      "epoch": 9.091975521987518,
      "grad_norm": 0.6679925322532654,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.3136,
      "step": 223600
    },
    {
      "epoch": 9.096041637017912,
      "grad_norm": 0.7191415429115295,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.3134,
      "step": 223700
    },
    {
      "epoch": 9.100107752048306,
      "grad_norm": 0.660784900188446,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3129,
      "step": 223800
    },
    {
      "epoch": 9.1041738670787,
      "grad_norm": 0.6954125165939331,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.3131,
      "step": 223900
    },
    {
      "epoch": 9.108239982109094,
      "grad_norm": 0.6690242290496826,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.3107,
      "step": 224000
    },
    {
      "epoch": 9.108239982109094,
      "eval_loss": 0.3386496901512146,
      "eval_runtime": 127.0449,
      "eval_samples_per_second": 1376.694,
      "eval_steps_per_second": 43.024,
      "step": 224000
    },
    {
      "epoch": 9.112306097139488,
      "grad_norm": 0.6529504060745239,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.314,
      "step": 224100
    },
    {
      "epoch": 9.116372212169882,
      "grad_norm": 0.6808754801750183,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.3128,
      "step": 224200
    },
    {
      "epoch": 9.120438327200276,
      "grad_norm": 0.7217174768447876,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.3127,
      "step": 224300
    },
    {
      "epoch": 9.124504442230672,
      "grad_norm": 0.6552751660346985,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.3149,
      "step": 224400
    },
    {
      "epoch": 9.128570557261066,
      "grad_norm": 0.7504804134368896,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3113,
      "step": 224500
    },
    {
      "epoch": 9.13263667229146,
      "grad_norm": 0.6681226491928101,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3124,
      "step": 224600
    },
    {
      "epoch": 9.136702787321854,
      "grad_norm": 0.6205503344535828,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3153,
      "step": 224700
    },
    {
      "epoch": 9.140768902352248,
      "grad_norm": 0.7557538747787476,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3123,
      "step": 224800
    },
    {
      "epoch": 9.144835017382642,
      "grad_norm": 0.6429170966148376,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3124,
      "step": 224900
    },
    {
      "epoch": 9.148901132413036,
      "grad_norm": 0.6968826055526733,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3132,
      "step": 225000
    },
    {
      "epoch": 9.15296724744343,
      "grad_norm": 0.6240599155426025,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3119,
      "step": 225100
    },
    {
      "epoch": 9.157033362473824,
      "grad_norm": 0.7175944447517395,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.3144,
      "step": 225200
    },
    {
      "epoch": 9.16109947750422,
      "grad_norm": 0.7548755407333374,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.3128,
      "step": 225300
    },
    {
      "epoch": 9.165165592534613,
      "grad_norm": 0.7076322436332703,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3135,
      "step": 225400
    },
    {
      "epoch": 9.169231707565007,
      "grad_norm": 0.7967637777328491,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3126,
      "step": 225500
    },
    {
      "epoch": 9.173297822595401,
      "grad_norm": 0.6704093217849731,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3132,
      "step": 225600
    },
    {
      "epoch": 9.177363937625795,
      "grad_norm": 0.6644327640533447,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.313,
      "step": 225700
    },
    {
      "epoch": 9.18143005265619,
      "grad_norm": 0.7889590263366699,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3126,
      "step": 225800
    },
    {
      "epoch": 9.185496167686583,
      "grad_norm": 0.7472402453422546,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3128,
      "step": 225900
    },
    {
      "epoch": 9.189562282716977,
      "grad_norm": 0.6980783343315125,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3124,
      "step": 226000
    },
    {
      "epoch": 9.189562282716977,
      "eval_loss": 0.33786189556121826,
      "eval_runtime": 127.4421,
      "eval_samples_per_second": 1372.404,
      "eval_steps_per_second": 42.89,
      "step": 226000
    },
    {
      "epoch": 9.193628397747371,
      "grad_norm": 0.5754213929176331,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.3125,
      "step": 226100
    },
    {
      "epoch": 9.197694512777767,
      "grad_norm": 0.7255051136016846,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3119,
      "step": 226200
    },
    {
      "epoch": 9.201760627808161,
      "grad_norm": 0.6993198990821838,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3137,
      "step": 226300
    },
    {
      "epoch": 9.205826742838555,
      "grad_norm": 0.7610759139060974,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3136,
      "step": 226400
    },
    {
      "epoch": 9.20989285786895,
      "grad_norm": 0.6402687430381775,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.3136,
      "step": 226500
    },
    {
      "epoch": 9.213958972899343,
      "grad_norm": 0.5983253121376038,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.3137,
      "step": 226600
    },
    {
      "epoch": 9.218025087929737,
      "grad_norm": 0.6741856336593628,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3139,
      "step": 226700
    },
    {
      "epoch": 9.222091202960131,
      "grad_norm": 0.6411849856376648,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3127,
      "step": 226800
    },
    {
      "epoch": 9.226157317990525,
      "grad_norm": 0.6996499300003052,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3121,
      "step": 226900
    },
    {
      "epoch": 9.230223433020921,
      "grad_norm": 0.6636986136436462,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3126,
      "step": 227000
    },
    {
      "epoch": 9.234289548051315,
      "grad_norm": 0.6115657687187195,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3134,
      "step": 227100
    },
    {
      "epoch": 9.238355663081709,
      "grad_norm": 0.7075088620185852,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.3113,
      "step": 227200
    },
    {
      "epoch": 9.242421778112103,
      "grad_norm": 0.7112990021705627,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3126,
      "step": 227300
    },
    {
      "epoch": 9.246487893142497,
      "grad_norm": 0.7442012429237366,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3124,
      "step": 227400
    },
    {
      "epoch": 9.250554008172891,
      "grad_norm": 0.696053147315979,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3104,
      "step": 227500
    },
    {
      "epoch": 9.254620123203285,
      "grad_norm": 0.6215163469314575,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3109,
      "step": 227600
    },
    {
      "epoch": 9.258686238233679,
      "grad_norm": 0.7251837253570557,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.3114,
      "step": 227700
    },
    {
      "epoch": 9.262752353264073,
      "grad_norm": 0.7310634255409241,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.3121,
      "step": 227800
    },
    {
      "epoch": 9.266818468294469,
      "grad_norm": 0.6260347962379456,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.3125,
      "step": 227900
    },
    {
      "epoch": 9.270884583324863,
      "grad_norm": 0.6229439377784729,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3119,
      "step": 228000
    },
    {
      "epoch": 9.270884583324863,
      "eval_loss": 0.3371616005897522,
      "eval_runtime": 127.6308,
      "eval_samples_per_second": 1370.375,
      "eval_steps_per_second": 42.827,
      "step": 228000
    },
    {
      "epoch": 9.274950698355257,
      "grad_norm": 0.6199151873588562,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.3114,
      "step": 228100
    },
    {
      "epoch": 9.27901681338565,
      "grad_norm": 0.7616070508956909,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.3119,
      "step": 228200
    },
    {
      "epoch": 9.283082928416045,
      "grad_norm": 0.70289146900177,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3116,
      "step": 228300
    },
    {
      "epoch": 9.287149043446439,
      "grad_norm": 0.6388289928436279,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3121,
      "step": 228400
    },
    {
      "epoch": 9.291215158476833,
      "grad_norm": 0.7737831473350525,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3135,
      "step": 228500
    },
    {
      "epoch": 9.295281273507227,
      "grad_norm": 0.869051456451416,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.3134,
      "step": 228600
    },
    {
      "epoch": 9.299347388537623,
      "grad_norm": 0.8583710789680481,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.3126,
      "step": 228700
    },
    {
      "epoch": 9.303413503568017,
      "grad_norm": 0.6832916140556335,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3117,
      "step": 228800
    },
    {
      "epoch": 9.30747961859841,
      "grad_norm": 0.6987820863723755,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3123,
      "step": 228900
    },
    {
      "epoch": 9.311545733628805,
      "grad_norm": 0.7182493805885315,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3119,
      "step": 229000
    },
    {
      "epoch": 9.315611848659199,
      "grad_norm": 0.7184663414955139,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.3125,
      "step": 229100
    },
    {
      "epoch": 9.319677963689593,
      "grad_norm": 0.6656771898269653,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3122,
      "step": 229200
    },
    {
      "epoch": 9.323744078719987,
      "grad_norm": 0.6034292578697205,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3119,
      "step": 229300
    },
    {
      "epoch": 9.32781019375038,
      "grad_norm": 0.6593844890594482,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3118,
      "step": 229400
    },
    {
      "epoch": 9.331876308780775,
      "grad_norm": 0.6914507150650024,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3125,
      "step": 229500
    },
    {
      "epoch": 9.33594242381117,
      "grad_norm": 0.709423840045929,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.3125,
      "step": 229600
    },
    {
      "epoch": 9.340008538841564,
      "grad_norm": 0.7126486897468567,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3117,
      "step": 229700
    },
    {
      "epoch": 9.344074653871958,
      "grad_norm": 0.8350082039833069,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3129,
      "step": 229800
    },
    {
      "epoch": 9.348140768902352,
      "grad_norm": 0.6806018948554993,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3126,
      "step": 229900
    },
    {
      "epoch": 9.352206883932746,
      "grad_norm": 0.6443451046943665,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.312,
      "step": 230000
    },
    {
      "epoch": 9.352206883932746,
      "eval_loss": 0.3367210328578949,
      "eval_runtime": 127.164,
      "eval_samples_per_second": 1375.405,
      "eval_steps_per_second": 42.984,
      "step": 230000
    },
    {
      "epoch": 9.35627299896314,
      "grad_norm": 0.612070620059967,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.3119,
      "step": 230100
    },
    {
      "epoch": 9.360339113993534,
      "grad_norm": 0.7192531824111938,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.3144,
      "step": 230200
    },
    {
      "epoch": 9.364405229023928,
      "grad_norm": 0.6275273561477661,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.3128,
      "step": 230300
    },
    {
      "epoch": 9.368471344054324,
      "grad_norm": 0.6847225427627563,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.3115,
      "step": 230400
    },
    {
      "epoch": 9.372537459084718,
      "grad_norm": 0.6583683490753174,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3123,
      "step": 230500
    },
    {
      "epoch": 9.376603574115112,
      "grad_norm": 0.6856487989425659,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3117,
      "step": 230600
    },
    {
      "epoch": 9.380669689145506,
      "grad_norm": 0.7057330012321472,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.3143,
      "step": 230700
    },
    {
      "epoch": 9.3847358041759,
      "grad_norm": 0.640206515789032,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.3136,
      "step": 230800
    },
    {
      "epoch": 9.388801919206294,
      "grad_norm": 0.7101894617080688,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.312,
      "step": 230900
    },
    {
      "epoch": 9.392868034236688,
      "grad_norm": 0.7871745824813843,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.3116,
      "step": 231000
    },
    {
      "epoch": 9.396934149267082,
      "grad_norm": 0.7535586357116699,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3132,
      "step": 231100
    },
    {
      "epoch": 9.401000264297476,
      "grad_norm": 0.8194005489349365,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3108,
      "step": 231200
    },
    {
      "epoch": 9.405066379327872,
      "grad_norm": 0.6197431087493896,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3148,
      "step": 231300
    },
    {
      "epoch": 9.409132494358266,
      "grad_norm": 0.76697838306427,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3151,
      "step": 231400
    },
    {
      "epoch": 9.41319860938866,
      "grad_norm": 0.6763172745704651,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3122,
      "step": 231500
    },
    {
      "epoch": 9.417264724419054,
      "grad_norm": 0.666410505771637,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3128,
      "step": 231600
    },
    {
      "epoch": 9.421330839449448,
      "grad_norm": 0.6880193948745728,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.3129,
      "step": 231700
    },
    {
      "epoch": 9.425396954479842,
      "grad_norm": 0.7140603065490723,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.3132,
      "step": 231800
    },
    {
      "epoch": 9.429463069510236,
      "grad_norm": 0.7634943723678589,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3123,
      "step": 231900
    },
    {
      "epoch": 9.43352918454063,
      "grad_norm": 0.7499096393585205,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.313,
      "step": 232000
    },
    {
      "epoch": 9.43352918454063,
      "eval_loss": 0.33626246452331543,
      "eval_runtime": 127.3764,
      "eval_samples_per_second": 1373.111,
      "eval_steps_per_second": 42.912,
      "step": 232000
    },
    {
      "epoch": 9.437595299571026,
      "grad_norm": 0.69697505235672,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3129,
      "step": 232100
    },
    {
      "epoch": 9.44166141460142,
      "grad_norm": 0.7450972199440002,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3101,
      "step": 232200
    },
    {
      "epoch": 9.445727529631814,
      "grad_norm": 0.8029825687408447,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3123,
      "step": 232300
    },
    {
      "epoch": 9.449793644662208,
      "grad_norm": 0.7998786568641663,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.3111,
      "step": 232400
    },
    {
      "epoch": 9.453859759692602,
      "grad_norm": 0.5971388220787048,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.3118,
      "step": 232500
    },
    {
      "epoch": 9.457925874722996,
      "grad_norm": 0.7490916848182678,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3119,
      "step": 232600
    },
    {
      "epoch": 9.46199198975339,
      "grad_norm": 0.7331640124320984,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3112,
      "step": 232700
    },
    {
      "epoch": 9.466058104783784,
      "grad_norm": 0.7015441060066223,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.3111,
      "step": 232800
    },
    {
      "epoch": 9.470124219814178,
      "grad_norm": 0.6648662686347961,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3118,
      "step": 232900
    },
    {
      "epoch": 9.474190334844574,
      "grad_norm": 0.7024414539337158,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3115,
      "step": 233000
    },
    {
      "epoch": 9.478256449874968,
      "grad_norm": 0.6886618137359619,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.313,
      "step": 233100
    },
    {
      "epoch": 9.482322564905362,
      "grad_norm": 0.7002299427986145,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.3124,
      "step": 233200
    },
    {
      "epoch": 9.486388679935756,
      "grad_norm": 0.6993972659111023,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.3112,
      "step": 233300
    },
    {
      "epoch": 9.49045479496615,
      "grad_norm": 0.7138878703117371,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3115,
      "step": 233400
    },
    {
      "epoch": 9.494520909996544,
      "grad_norm": 0.7153612971305847,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3113,
      "step": 233500
    },
    {
      "epoch": 9.498587025026938,
      "grad_norm": 0.8135942220687866,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3118,
      "step": 233600
    },
    {
      "epoch": 9.502653140057332,
      "grad_norm": 0.7078922390937805,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.3115,
      "step": 233700
    },
    {
      "epoch": 9.506719255087727,
      "grad_norm": 0.6943656802177429,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3107,
      "step": 233800
    },
    {
      "epoch": 9.510785370118121,
      "grad_norm": 0.7846773266792297,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3119,
      "step": 233900
    },
    {
      "epoch": 9.514851485148515,
      "grad_norm": 0.6738925576210022,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.3103,
      "step": 234000
    },
    {
      "epoch": 9.514851485148515,
      "eval_loss": 0.33566775918006897,
      "eval_runtime": 127.5323,
      "eval_samples_per_second": 1371.433,
      "eval_steps_per_second": 42.86,
      "step": 234000
    },
    {
      "epoch": 9.51891760017891,
      "grad_norm": 0.7556460499763489,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.311,
      "step": 234100
    },
    {
      "epoch": 9.522983715209303,
      "grad_norm": 0.745613157749176,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.312,
      "step": 234200
    },
    {
      "epoch": 9.527049830239697,
      "grad_norm": 0.6214727759361267,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3103,
      "step": 234300
    },
    {
      "epoch": 9.531115945270091,
      "grad_norm": 0.6499789953231812,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3103,
      "step": 234400
    },
    {
      "epoch": 9.535182060300485,
      "grad_norm": 0.7024068832397461,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3127,
      "step": 234500
    },
    {
      "epoch": 9.53924817533088,
      "grad_norm": 0.6654329299926758,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3135,
      "step": 234600
    },
    {
      "epoch": 9.543314290361275,
      "grad_norm": 0.6713343858718872,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3123,
      "step": 234700
    },
    {
      "epoch": 9.547380405391669,
      "grad_norm": 0.6441388130187988,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.3093,
      "step": 234800
    },
    {
      "epoch": 9.551446520422063,
      "grad_norm": 0.758901059627533,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.3131,
      "step": 234900
    },
    {
      "epoch": 9.555512635452457,
      "grad_norm": 0.6802515983581543,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.3109,
      "step": 235000
    },
    {
      "epoch": 9.559578750482851,
      "grad_norm": 0.6740262508392334,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3089,
      "step": 235100
    },
    {
      "epoch": 9.563644865513245,
      "grad_norm": 0.7825621962547302,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3116,
      "step": 235200
    },
    {
      "epoch": 9.567710980543639,
      "grad_norm": 0.8078304529190063,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3115,
      "step": 235300
    },
    {
      "epoch": 9.571777095574033,
      "grad_norm": 0.7159298062324524,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3122,
      "step": 235400
    },
    {
      "epoch": 9.575843210604429,
      "grad_norm": 0.7226790189743042,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.3115,
      "step": 235500
    },
    {
      "epoch": 9.579909325634823,
      "grad_norm": 0.7224997878074646,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3121,
      "step": 235600
    },
    {
      "epoch": 9.583975440665217,
      "grad_norm": 0.7370895147323608,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.312,
      "step": 235700
    },
    {
      "epoch": 9.588041555695611,
      "grad_norm": 0.7338639497756958,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.3131,
      "step": 235800
    },
    {
      "epoch": 9.592107670726005,
      "grad_norm": 0.7129561901092529,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.3104,
      "step": 235900
    },
    {
      "epoch": 9.596173785756399,
      "grad_norm": 0.7250131964683533,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.3102,
      "step": 236000
    },
    {
      "epoch": 9.596173785756399,
      "eval_loss": 0.3348785936832428,
      "eval_runtime": 127.1384,
      "eval_samples_per_second": 1375.682,
      "eval_steps_per_second": 42.993,
      "step": 236000
    },
    {
      "epoch": 9.600239900786793,
      "grad_norm": 0.7106778621673584,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3113,
      "step": 236100
    },
    {
      "epoch": 9.604306015817187,
      "grad_norm": 0.772644579410553,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3099,
      "step": 236200
    },
    {
      "epoch": 9.608372130847581,
      "grad_norm": 0.7058257460594177,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.3107,
      "step": 236300
    },
    {
      "epoch": 9.612438245877977,
      "grad_norm": 0.8078759908676147,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3129,
      "step": 236400
    },
    {
      "epoch": 9.61650436090837,
      "grad_norm": 0.6597693562507629,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.3108,
      "step": 236500
    },
    {
      "epoch": 9.620570475938765,
      "grad_norm": 0.7273709774017334,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3107,
      "step": 236600
    },
    {
      "epoch": 9.624636590969159,
      "grad_norm": 0.7114716172218323,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3107,
      "step": 236700
    },
    {
      "epoch": 9.628702705999553,
      "grad_norm": 0.6604816317558289,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.3094,
      "step": 236800
    },
    {
      "epoch": 9.632768821029947,
      "grad_norm": 0.6830112934112549,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3107,
      "step": 236900
    },
    {
      "epoch": 9.63683493606034,
      "grad_norm": 0.7371301651000977,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.3115,
      "step": 237000
    },
    {
      "epoch": 9.640901051090735,
      "grad_norm": 0.6558812260627747,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3107,
      "step": 237100
    },
    {
      "epoch": 9.64496716612113,
      "grad_norm": 0.718369722366333,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.3093,
      "step": 237200
    },
    {
      "epoch": 9.649033281151524,
      "grad_norm": 0.6712531447410583,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3107,
      "step": 237300
    },
    {
      "epoch": 9.653099396181918,
      "grad_norm": 0.7881459593772888,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.3113,
      "step": 237400
    },
    {
      "epoch": 9.657165511212312,
      "grad_norm": 0.7777525186538696,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.311,
      "step": 237500
    },
    {
      "epoch": 9.661231626242706,
      "grad_norm": 0.6850930452346802,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3126,
      "step": 237600
    },
    {
      "epoch": 9.6652977412731,
      "grad_norm": 0.6990208029747009,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.3121,
      "step": 237700
    },
    {
      "epoch": 9.669363856303494,
      "grad_norm": 0.8068549036979675,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.3118,
      "step": 237800
    },
    {
      "epoch": 9.673429971333888,
      "grad_norm": 0.6828927993774414,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3122,
      "step": 237900
    },
    {
      "epoch": 9.677496086364282,
      "grad_norm": 0.782289445400238,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3108,
      "step": 238000
    },
    {
      "epoch": 9.677496086364282,
      "eval_loss": 0.33431771397590637,
      "eval_runtime": 127.2559,
      "eval_samples_per_second": 1374.412,
      "eval_steps_per_second": 42.953,
      "step": 238000
    },
    {
      "epoch": 9.681562201394678,
      "grad_norm": 0.7263115644454956,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.3105,
      "step": 238100
    },
    {
      "epoch": 9.685628316425072,
      "grad_norm": 0.659762442111969,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3098,
      "step": 238200
    },
    {
      "epoch": 9.689694431455466,
      "grad_norm": 0.7144806981086731,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3088,
      "step": 238300
    },
    {
      "epoch": 9.69376054648586,
      "grad_norm": 0.7011730074882507,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.3115,
      "step": 238400
    },
    {
      "epoch": 9.697826661516254,
      "grad_norm": 0.7225289940834045,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3098,
      "step": 238500
    },
    {
      "epoch": 9.701892776546648,
      "grad_norm": 0.823784351348877,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.3109,
      "step": 238600
    },
    {
      "epoch": 9.705958891577042,
      "grad_norm": 0.7289155721664429,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3109,
      "step": 238700
    },
    {
      "epoch": 9.710025006607436,
      "grad_norm": 0.6860247254371643,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3103,
      "step": 238800
    },
    {
      "epoch": 9.714091121637832,
      "grad_norm": 0.7280960083007812,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3097,
      "step": 238900
    },
    {
      "epoch": 9.718157236668226,
      "grad_norm": 0.6839437484741211,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.31,
      "step": 239000
    },
    {
      "epoch": 9.72222335169862,
      "grad_norm": 0.6982918381690979,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.3099,
      "step": 239100
    },
    {
      "epoch": 9.726289466729014,
      "grad_norm": 0.7969576716423035,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3083,
      "step": 239200
    },
    {
      "epoch": 9.730355581759408,
      "grad_norm": 0.7346013188362122,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3103,
      "step": 239300
    },
    {
      "epoch": 9.734421696789802,
      "grad_norm": 0.6356726288795471,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.3108,
      "step": 239400
    },
    {
      "epoch": 9.738487811820196,
      "grad_norm": 0.8027147054672241,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3103,
      "step": 239500
    },
    {
      "epoch": 9.74255392685059,
      "grad_norm": 0.8218768835067749,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3112,
      "step": 239600
    },
    {
      "epoch": 9.746620041880984,
      "grad_norm": 0.7023612260818481,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3094,
      "step": 239700
    },
    {
      "epoch": 9.75068615691138,
      "grad_norm": 0.7755769491195679,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3112,
      "step": 239800
    },
    {
      "epoch": 9.754752271941774,
      "grad_norm": 0.7022380828857422,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.3081,
      "step": 239900
    },
    {
      "epoch": 9.758818386972168,
      "grad_norm": 0.7893637418746948,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3102,
      "step": 240000
    },
    {
      "epoch": 9.758818386972168,
      "eval_loss": 0.33379754424095154,
      "eval_runtime": 127.1418,
      "eval_samples_per_second": 1375.645,
      "eval_steps_per_second": 42.991,
      "step": 240000
    },
    {
      "epoch": 9.762884502002562,
      "grad_norm": 0.8729926943778992,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.3102,
      "step": 240100
    },
    {
      "epoch": 9.766950617032956,
      "grad_norm": 0.7647495269775391,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.3108,
      "step": 240200
    },
    {
      "epoch": 9.77101673206335,
      "grad_norm": 0.7224856019020081,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.3115,
      "step": 240300
    },
    {
      "epoch": 9.775082847093744,
      "grad_norm": 0.725078284740448,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.309,
      "step": 240400
    },
    {
      "epoch": 9.779148962124138,
      "grad_norm": 0.7083726525306702,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.3086,
      "step": 240500
    },
    {
      "epoch": 9.783215077154534,
      "grad_norm": 0.727623701095581,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3098,
      "step": 240600
    },
    {
      "epoch": 9.787281192184928,
      "grad_norm": 0.7974910736083984,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3101,
      "step": 240700
    },
    {
      "epoch": 9.791347307215322,
      "grad_norm": 0.7012469172477722,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3109,
      "step": 240800
    },
    {
      "epoch": 9.795413422245716,
      "grad_norm": 0.7126168608665466,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.3088,
      "step": 240900
    },
    {
      "epoch": 9.79947953727611,
      "grad_norm": 0.8337075710296631,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3105,
      "step": 241000
    },
    {
      "epoch": 9.803545652306504,
      "grad_norm": 0.7372950911521912,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3114,
      "step": 241100
    },
    {
      "epoch": 9.807611767336898,
      "grad_norm": 0.6560496091842651,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3099,
      "step": 241200
    },
    {
      "epoch": 9.811677882367292,
      "grad_norm": 0.7143036723136902,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.3121,
      "step": 241300
    },
    {
      "epoch": 9.815743997397686,
      "grad_norm": 0.8997418284416199,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.3111,
      "step": 241400
    },
    {
      "epoch": 9.81981011242808,
      "grad_norm": 0.725128710269928,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3085,
      "step": 241500
    },
    {
      "epoch": 9.823876227458475,
      "grad_norm": 0.7681103944778442,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.3111,
      "step": 241600
    },
    {
      "epoch": 9.82794234248887,
      "grad_norm": 0.7345095276832581,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3095,
      "step": 241700
    },
    {
      "epoch": 9.832008457519263,
      "grad_norm": 0.7817251086235046,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3081,
      "step": 241800
    },
    {
      "epoch": 9.836074572549657,
      "grad_norm": 0.8132858872413635,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.3084,
      "step": 241900
    },
    {
      "epoch": 9.840140687580051,
      "grad_norm": 0.7240779399871826,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3074,
      "step": 242000
    },
    {
      "epoch": 9.840140687580051,
      "eval_loss": 0.33333852887153625,
      "eval_runtime": 127.1643,
      "eval_samples_per_second": 1375.401,
      "eval_steps_per_second": 42.984,
      "step": 242000
    },
    {
      "epoch": 9.844206802610445,
      "grad_norm": 0.6964262127876282,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3084,
      "step": 242100
    },
    {
      "epoch": 9.84827291764084,
      "grad_norm": 0.8086745142936707,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3106,
      "step": 242200
    },
    {
      "epoch": 9.852339032671233,
      "grad_norm": 0.6964948773384094,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.3101,
      "step": 242300
    },
    {
      "epoch": 9.85640514770163,
      "grad_norm": 0.6567678451538086,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.3094,
      "step": 242400
    },
    {
      "epoch": 9.860471262732023,
      "grad_norm": 0.7427359819412231,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.3094,
      "step": 242500
    },
    {
      "epoch": 9.864537377762417,
      "grad_norm": 0.7482128143310547,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3096,
      "step": 242600
    },
    {
      "epoch": 9.868603492792811,
      "grad_norm": 0.772397518157959,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3087,
      "step": 242700
    },
    {
      "epoch": 9.872669607823205,
      "grad_norm": 0.6929910778999329,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3102,
      "step": 242800
    },
    {
      "epoch": 9.8767357228536,
      "grad_norm": 0.6950594186782837,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.3083,
      "step": 242900
    },
    {
      "epoch": 9.880801837883993,
      "grad_norm": 0.7524927854537964,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3079,
      "step": 243000
    },
    {
      "epoch": 9.884867952914387,
      "grad_norm": 0.7088013887405396,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.3083,
      "step": 243100
    },
    {
      "epoch": 9.888934067944781,
      "grad_norm": 0.6992640495300293,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.3093,
      "step": 243200
    },
    {
      "epoch": 9.893000182975177,
      "grad_norm": 0.9344055652618408,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3109,
      "step": 243300
    },
    {
      "epoch": 9.897066298005571,
      "grad_norm": 0.7138438820838928,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3086,
      "step": 243400
    },
    {
      "epoch": 9.901132413035965,
      "grad_norm": 0.7402417659759521,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.3087,
      "step": 243500
    },
    {
      "epoch": 9.905198528066359,
      "grad_norm": 0.7716963291168213,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.309,
      "step": 243600
    },
    {
      "epoch": 9.909264643096753,
      "grad_norm": 0.6841555833816528,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3086,
      "step": 243700
    },
    {
      "epoch": 9.913330758127147,
      "grad_norm": 0.7643001079559326,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3086,
      "step": 243800
    },
    {
      "epoch": 9.917396873157541,
      "grad_norm": 0.7807003259658813,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3075,
      "step": 243900
    },
    {
      "epoch": 9.921462988187935,
      "grad_norm": 0.7055999636650085,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3076,
      "step": 244000
    },
    {
      "epoch": 9.921462988187935,
      "eval_loss": 0.3329470455646515,
      "eval_runtime": 126.9826,
      "eval_samples_per_second": 1377.37,
      "eval_steps_per_second": 43.045,
      "step": 244000
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
