{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500.0,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 4.1762,
      "step": 500
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.1799,
      "step": 1000
    },
    {
      "epoch": 0.015,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 3e-06,
      "loss": 1.7478,
      "step": 1500
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.9999990463256836,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.4181,
      "step": 2000
    },
    {
      "epoch": 0.025,
      "grad_norm": 2.999999761581421,
      "learning_rate": 5e-06,
      "loss": 1.196,
      "step": 2500
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 6e-06,
      "loss": 1.067,
      "step": 3000
    },
    {
      "epoch": 0.035,
      "grad_norm": 2.999999523162842,
      "learning_rate": 7e-06,
      "loss": 0.9855,
      "step": 3500
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.9275,
      "step": 4000
    },
    {
      "epoch": 0.045,
      "grad_norm": 2.9999990463256836,
      "learning_rate": 9e-06,
      "loss": 0.884,
      "step": 4500
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9999990463256836,
      "learning_rate": 1e-05,
      "loss": 0.8491,
      "step": 5000
    },
    {
      "epoch": 0.055,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 9.947368421052632e-06,
      "loss": 0.8203,
      "step": 5500
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.9999988079071045,
      "learning_rate": 9.894736842105264e-06,
      "loss": 0.7986,
      "step": 6000
    },
    {
      "epoch": 0.065,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 9.842105263157896e-06,
      "loss": 0.7829,
      "step": 6500
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 9.789473684210527e-06,
      "loss": 0.7669,
      "step": 7000
    },
    {
      "epoch": 0.075,
      "grad_norm": 2.678645372390747,
      "learning_rate": 9.736842105263159e-06,
      "loss": 0.7555,
      "step": 7500
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.3448216915130615,
      "learning_rate": 9.68421052631579e-06,
      "loss": 0.7458,
      "step": 8000
    },
    {
      "epoch": 0.085,
      "grad_norm": 2.9999992847442627,
      "learning_rate": 9.631578947368422e-06,
      "loss": 0.7382,
      "step": 8500
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1468491554260254,
      "learning_rate": 9.578947368421054e-06,
      "loss": 0.7293,
      "step": 9000
    },
    {
      "epoch": 0.095,
      "grad_norm": 2.491119146347046,
      "learning_rate": 9.526315789473684e-06,
      "loss": 0.7241,
      "step": 9500
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1382603645324707,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.7171,
      "step": 10000
    },
    {
      "epoch": 0.105,
      "grad_norm": 2.7290589809417725,
      "learning_rate": 9.421052631578949e-06,
      "loss": 0.7117,
      "step": 10500
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8128224611282349,
      "learning_rate": 9.36842105263158e-06,
      "loss": 0.7055,
      "step": 11000
    },
    {
      "epoch": 0.115,
      "grad_norm": 2.0062742233276367,
      "learning_rate": 9.315789473684212e-06,
      "loss": 0.7002,
      "step": 11500
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7937958240509033,
      "learning_rate": 9.263157894736842e-06,
      "loss": 0.6959,
      "step": 12000
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.7906596660614014,
      "learning_rate": 9.210526315789474e-06,
      "loss": 0.6922,
      "step": 12500
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9111814498901367,
      "learning_rate": 9.157894736842105e-06,
      "loss": 0.6887,
      "step": 13000
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.6486444473266602,
      "learning_rate": 9.105263157894739e-06,
      "loss": 0.6848,
      "step": 13500
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8208680152893066,
      "learning_rate": 9.05263157894737e-06,
      "loss": 0.6812,
      "step": 14000
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.8850961923599243,
      "learning_rate": 9e-06,
      "loss": 0.6777,
      "step": 14500
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8055524826049805,
      "learning_rate": 8.947368421052632e-06,
      "loss": 0.6756,
      "step": 15000
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.866477131843567,
      "learning_rate": 8.894736842105264e-06,
      "loss": 0.6728,
      "step": 15500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7320753335952759,
      "learning_rate": 8.842105263157895e-06,
      "loss": 0.6689,
      "step": 16000
    },
    {
      "epoch": 0.165,
      "grad_norm": 2.225961208343506,
      "learning_rate": 8.789473684210527e-06,
      "loss": 0.6665,
      "step": 16500
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7094805240631104,
      "learning_rate": 8.736842105263158e-06,
      "loss": 0.6633,
      "step": 17000
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.5849789381027222,
      "learning_rate": 8.68421052631579e-06,
      "loss": 0.6616,
      "step": 17500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.6315374374389648,
      "learning_rate": 8.631578947368422e-06,
      "loss": 0.6592,
      "step": 18000
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.9290660619735718,
      "learning_rate": 8.578947368421053e-06,
      "loss": 0.6561,
      "step": 18500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6378397941589355,
      "learning_rate": 8.526315789473685e-06,
      "loss": 0.6538,
      "step": 19000
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.6726726293563843,
      "learning_rate": 8.473684210526317e-06,
      "loss": 0.6532,
      "step": 19500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6258020401000977,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.6504,
      "step": 20000
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.5458879470825195,
      "learning_rate": 8.36842105263158e-06,
      "loss": 0.6487,
      "step": 20500
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6152812242507935,
      "learning_rate": 8.315789473684212e-06,
      "loss": 0.6468,
      "step": 21000
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.5480180978775024,
      "learning_rate": 8.263157894736843e-06,
      "loss": 0.6452,
      "step": 21500
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.7686344385147095,
      "learning_rate": 8.210526315789475e-06,
      "loss": 0.6433,
      "step": 22000
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.8028342723846436,
      "learning_rate": 8.157894736842106e-06,
      "loss": 0.6411,
      "step": 22500
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.5669625997543335,
      "learning_rate": 8.105263157894736e-06,
      "loss": 0.6402,
      "step": 23000
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.5758839845657349,
      "learning_rate": 8.052631578947368e-06,
      "loss": 0.6395,
      "step": 23500
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6303731203079224,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6372,
      "step": 24000
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.7064006328582764,
      "learning_rate": 7.947368421052633e-06,
      "loss": 0.6353,
      "step": 24500
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.6687686443328857,
      "learning_rate": 7.894736842105265e-06,
      "loss": 0.633,
      "step": 25000
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.7773189544677734,
      "learning_rate": 7.842105263157895e-06,
      "loss": 0.6315,
      "step": 25500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.5314821004867554,
      "learning_rate": 7.789473684210526e-06,
      "loss": 0.6311,
      "step": 26000
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.5364866256713867,
      "learning_rate": 7.736842105263158e-06,
      "loss": 0.6292,
      "step": 26500
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.550708293914795,
      "learning_rate": 7.68421052631579e-06,
      "loss": 0.6288,
      "step": 27000
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.6951881647109985,
      "learning_rate": 7.631578947368423e-06,
      "loss": 0.6266,
      "step": 27500
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.64950430393219,
      "learning_rate": 7.578947368421054e-06,
      "loss": 0.626,
      "step": 28000
    },
    {
      "epoch": 0.285,
      "grad_norm": 1.5290273427963257,
      "learning_rate": 7.526315789473685e-06,
      "loss": 0.6242,
      "step": 28500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.645395040512085,
      "learning_rate": 7.473684210526316e-06,
      "loss": 0.6235,
      "step": 29000
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.6485028266906738,
      "learning_rate": 7.421052631578948e-06,
      "loss": 0.6213,
      "step": 29500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.6629512310028076,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.6212,
      "step": 30000
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.6748111248016357,
      "learning_rate": 7.315789473684212e-06,
      "loss": 0.6204,
      "step": 30500
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.6135673522949219,
      "learning_rate": 7.263157894736843e-06,
      "loss": 0.6195,
      "step": 31000
    },
    {
      "epoch": 0.315,
      "grad_norm": 1.63493812084198,
      "learning_rate": 7.210526315789474e-06,
      "loss": 0.6178,
      "step": 31500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5284446477890015,
      "learning_rate": 7.157894736842106e-06,
      "loss": 0.6165,
      "step": 32000
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.6513550281524658,
      "learning_rate": 7.1052631578947375e-06,
      "loss": 0.6145,
      "step": 32500
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.577966332435608,
      "learning_rate": 7.052631578947369e-06,
      "loss": 0.6146,
      "step": 33000
    },
    {
      "epoch": 0.335,
      "grad_norm": 1.4218087196350098,
      "learning_rate": 7e-06,
      "loss": 0.6126,
      "step": 33500
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.5809911489486694,
      "learning_rate": 6.947368421052632e-06,
      "loss": 0.6128,
      "step": 34000
    },
    {
      "epoch": 0.345,
      "grad_norm": 1.613329529762268,
      "learning_rate": 6.894736842105264e-06,
      "loss": 0.6129,
      "step": 34500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.5386065244674683,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.6111,
      "step": 35000
    },
    {
      "epoch": 0.355,
      "grad_norm": 1.495213508605957,
      "learning_rate": 6.789473684210527e-06,
      "loss": 0.6109,
      "step": 35500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.4342691898345947,
      "learning_rate": 6.736842105263158e-06,
      "loss": 0.6096,
      "step": 36000
    },
    {
      "epoch": 0.365,
      "grad_norm": 1.6469911336898804,
      "learning_rate": 6.68421052631579e-06,
      "loss": 0.6089,
      "step": 36500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.5625715255737305,
      "learning_rate": 6.631578947368421e-06,
      "loss": 0.6083,
      "step": 37000
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.6599345207214355,
      "learning_rate": 6.578947368421054e-06,
      "loss": 0.6074,
      "step": 37500
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.457706093788147,
      "learning_rate": 6.526315789473685e-06,
      "loss": 0.6063,
      "step": 38000
    },
    {
      "epoch": 0.385,
      "grad_norm": 1.6415448188781738,
      "learning_rate": 6.473684210526316e-06,
      "loss": 0.6066,
      "step": 38500
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.5362635850906372,
      "learning_rate": 6.421052631578948e-06,
      "loss": 0.6042,
      "step": 39000
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.536444902420044,
      "learning_rate": 6.3684210526315795e-06,
      "loss": 0.6028,
      "step": 39500
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7234035730361938,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.6025,
      "step": 40000
    },
    {
      "epoch": 0.405,
      "grad_norm": 1.6161444187164307,
      "learning_rate": 6.263157894736842e-06,
      "loss": 0.6024,
      "step": 40500
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5399640798568726,
      "learning_rate": 6.2105263157894745e-06,
      "loss": 0.6022,
      "step": 41000
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.494818925857544,
      "learning_rate": 6.157894736842106e-06,
      "loss": 0.6017,
      "step": 41500
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3677834272384644,
      "learning_rate": 6.105263157894738e-06,
      "loss": 0.6013,
      "step": 42000
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.4796830415725708,
      "learning_rate": 6.0526315789473685e-06,
      "loss": 0.6003,
      "step": 42500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.483909010887146,
      "learning_rate": 6e-06,
      "loss": 0.5994,
      "step": 43000
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.4838910102844238,
      "learning_rate": 5.947368421052632e-06,
      "loss": 0.5991,
      "step": 43500
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.564988613128662,
      "learning_rate": 5.8947368421052634e-06,
      "loss": 0.5971,
      "step": 44000
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.5961319208145142,
      "learning_rate": 5.842105263157896e-06,
      "loss": 0.5984,
      "step": 44500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5002244710922241,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.5964,
      "step": 45000
    },
    {
      "epoch": 0.455,
      "grad_norm": 1.5998239517211914,
      "learning_rate": 5.736842105263158e-06,
      "loss": 0.596,
      "step": 45500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6138511896133423,
      "learning_rate": 5.68421052631579e-06,
      "loss": 0.5963,
      "step": 46000
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.5764700174331665,
      "learning_rate": 5.631578947368422e-06,
      "loss": 0.5957,
      "step": 46500
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4157145023345947,
      "learning_rate": 5.578947368421052e-06,
      "loss": 0.5948,
      "step": 47000
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.758280873298645,
      "learning_rate": 5.526315789473685e-06,
      "loss": 0.5935,
      "step": 47500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4970325231552124,
      "learning_rate": 5.4736842105263165e-06,
      "loss": 0.5933,
      "step": 48000
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.4901721477508545,
      "learning_rate": 5.421052631578948e-06,
      "loss": 0.5933,
      "step": 48500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6186491250991821,
      "learning_rate": 5.36842105263158e-06,
      "loss": 0.5926,
      "step": 49000
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.478362798690796,
      "learning_rate": 5.315789473684211e-06,
      "loss": 0.5915,
      "step": 49500
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.583175778388977,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.5915,
      "step": 50000
    },
    {
      "epoch": 0.505,
      "grad_norm": 1.5778400897979736,
      "learning_rate": 5.210526315789474e-06,
      "loss": 0.5901,
      "step": 50500
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6490163803100586,
      "learning_rate": 5.157894736842106e-06,
      "loss": 0.5903,
      "step": 51000
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.5722193717956543,
      "learning_rate": 5.105263157894738e-06,
      "loss": 0.5906,
      "step": 51500
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5142319202423096,
      "learning_rate": 5.052631578947369e-06,
      "loss": 0.5894,
      "step": 52000
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.5486221313476562,
      "learning_rate": 5e-06,
      "loss": 0.5885,
      "step": 52500
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5557247400283813,
      "learning_rate": 4.947368421052632e-06,
      "loss": 0.5891,
      "step": 53000
    },
    {
      "epoch": 0.535,
      "grad_norm": 1.452317237854004,
      "learning_rate": 4.894736842105264e-06,
      "loss": 0.5886,
      "step": 53500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6799073219299316,
      "learning_rate": 4.842105263157895e-06,
      "loss": 0.5881,
      "step": 54000
    },
    {
      "epoch": 0.545,
      "grad_norm": 1.4216036796569824,
      "learning_rate": 4.789473684210527e-06,
      "loss": 0.5873,
      "step": 54500
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4858418703079224,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.586,
      "step": 55000
    },
    {
      "epoch": 0.555,
      "grad_norm": 1.6052552461624146,
      "learning_rate": 4.68421052631579e-06,
      "loss": 0.5859,
      "step": 55500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7726719379425049,
      "learning_rate": 4.631578947368421e-06,
      "loss": 0.5858,
      "step": 56000
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.5236539840698242,
      "learning_rate": 4.578947368421053e-06,
      "loss": 0.5853,
      "step": 56500
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5911364555358887,
      "learning_rate": 4.526315789473685e-06,
      "loss": 0.5846,
      "step": 57000
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.7131426334381104,
      "learning_rate": 4.473684210526316e-06,
      "loss": 0.5847,
      "step": 57500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6133977174758911,
      "learning_rate": 4.4210526315789476e-06,
      "loss": 0.5842,
      "step": 58000
    },
    {
      "epoch": 0.585,
      "grad_norm": 1.710585594177246,
      "learning_rate": 4.368421052631579e-06,
      "loss": 0.583,
      "step": 58500
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.497800350189209,
      "learning_rate": 4.315789473684211e-06,
      "loss": 0.5834,
      "step": 59000
    },
    {
      "epoch": 0.595,
      "grad_norm": 1.5264322757720947,
      "learning_rate": 4.2631578947368425e-06,
      "loss": 0.5826,
      "step": 59500
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.511018991470337,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.5818,
      "step": 60000
    },
    {
      "epoch": 0.605,
      "grad_norm": 1.5962971448898315,
      "learning_rate": 4.157894736842106e-06,
      "loss": 0.5818,
      "step": 60500
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5385212898254395,
      "learning_rate": 4.105263157894737e-06,
      "loss": 0.5818,
      "step": 61000
    },
    {
      "epoch": 0.615,
      "grad_norm": 1.5719531774520874,
      "learning_rate": 4.052631578947368e-06,
      "loss": 0.5808,
      "step": 61500
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4733827114105225,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.5807,
      "step": 62000
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.4895135164260864,
      "learning_rate": 3.947368421052632e-06,
      "loss": 0.5812,
      "step": 62500
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.5872238874435425,
      "learning_rate": 3.894736842105263e-06,
      "loss": 0.5801,
      "step": 63000
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.6256425380706787,
      "learning_rate": 3.842105263157895e-06,
      "loss": 0.5791,
      "step": 63500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5481003522872925,
      "learning_rate": 3.789473684210527e-06,
      "loss": 0.5798,
      "step": 64000
    },
    {
      "epoch": 0.645,
      "grad_norm": 1.4985018968582153,
      "learning_rate": 3.736842105263158e-06,
      "loss": 0.579,
      "step": 64500
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6815872192382812,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.5796,
      "step": 65000
    },
    {
      "epoch": 0.655,
      "grad_norm": 1.6054891347885132,
      "learning_rate": 3.6315789473684217e-06,
      "loss": 0.5782,
      "step": 65500
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.501973271369934,
      "learning_rate": 3.578947368421053e-06,
      "loss": 0.579,
      "step": 66000
    },
    {
      "epoch": 0.665,
      "grad_norm": 1.6306300163269043,
      "learning_rate": 3.5263157894736846e-06,
      "loss": 0.5782,
      "step": 66500
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6354858875274658,
      "learning_rate": 3.473684210526316e-06,
      "loss": 0.5768,
      "step": 67000
    },
    {
      "epoch": 0.675,
      "grad_norm": 1.4912545680999756,
      "learning_rate": 3.421052631578948e-06,
      "loss": 0.5774,
      "step": 67500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6330370903015137,
      "learning_rate": 3.368421052631579e-06,
      "loss": 0.5775,
      "step": 68000
    },
    {
      "epoch": 0.685,
      "grad_norm": 1.6081428527832031,
      "learning_rate": 3.3157894736842107e-06,
      "loss": 0.5763,
      "step": 68500
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.927711009979248,
      "learning_rate": 3.2631578947368423e-06,
      "loss": 0.5766,
      "step": 69000
    },
    {
      "epoch": 0.695,
      "grad_norm": 1.5336347818374634,
      "learning_rate": 3.210526315789474e-06,
      "loss": 0.5762,
      "step": 69500
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6059569120407104,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.5757,
      "step": 70000
    },
    {
      "epoch": 0.705,
      "grad_norm": 1.6471468210220337,
      "learning_rate": 3.1052631578947372e-06,
      "loss": 0.5755,
      "step": 70500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4677096605300903,
      "learning_rate": 3.052631578947369e-06,
      "loss": 0.5752,
      "step": 71000
    },
    {
      "epoch": 0.715,
      "grad_norm": 1.5444599390029907,
      "learning_rate": 3e-06,
      "loss": 0.575,
      "step": 71500
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.5857393741607666,
      "learning_rate": 2.9473684210526317e-06,
      "loss": 0.5745,
      "step": 72000
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.4885385036468506,
      "learning_rate": 2.8947368421052634e-06,
      "loss": 0.5741,
      "step": 72500
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4614838361740112,
      "learning_rate": 2.842105263157895e-06,
      "loss": 0.5746,
      "step": 73000
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.6902186870574951,
      "learning_rate": 2.789473684210526e-06,
      "loss": 0.5737,
      "step": 73500
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.5123213529586792,
      "learning_rate": 2.7368421052631583e-06,
      "loss": 0.5738,
      "step": 74000
    },
    {
      "epoch": 0.745,
      "grad_norm": 1.7418227195739746,
      "learning_rate": 2.68421052631579e-06,
      "loss": 0.5734,
      "step": 74500
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6833611726760864,
      "learning_rate": 2.631578947368421e-06,
      "loss": 0.5735,
      "step": 75000
    },
    {
      "epoch": 0.755,
      "grad_norm": 1.5364303588867188,
      "learning_rate": 2.578947368421053e-06,
      "loss": 0.5724,
      "step": 75500
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6179031133651733,
      "learning_rate": 2.5263157894736844e-06,
      "loss": 0.5725,
      "step": 76000
    },
    {
      "epoch": 0.765,
      "grad_norm": 1.5911672115325928,
      "learning_rate": 2.473684210526316e-06,
      "loss": 0.5718,
      "step": 76500
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6654958724975586,
      "learning_rate": 2.4210526315789477e-06,
      "loss": 0.5723,
      "step": 77000
    },
    {
      "epoch": 0.775,
      "grad_norm": 1.6740808486938477,
      "learning_rate": 2.368421052631579e-06,
      "loss": 0.5713,
      "step": 77500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6843746900558472,
      "learning_rate": 2.3157894736842105e-06,
      "loss": 0.5716,
      "step": 78000
    },
    {
      "epoch": 0.785,
      "grad_norm": 1.7037535905838013,
      "learning_rate": 2.2631578947368426e-06,
      "loss": 0.5713,
      "step": 78500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.586748480796814,
      "learning_rate": 2.2105263157894738e-06,
      "loss": 0.5704,
      "step": 79000
    },
    {
      "epoch": 0.795,
      "grad_norm": 1.7209386825561523,
      "learning_rate": 2.1578947368421054e-06,
      "loss": 0.5708,
      "step": 79500
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5113213062286377,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.571,
      "step": 80000
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.6722943782806396,
      "learning_rate": 2.0526315789473687e-06,
      "loss": 0.5705,
      "step": 80500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5490000247955322,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.57,
      "step": 81000
    },
    {
      "epoch": 0.815,
      "grad_norm": 1.515134334564209,
      "learning_rate": 1.9473684210526315e-06,
      "loss": 0.5701,
      "step": 81500
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6551461219787598,
      "learning_rate": 1.8947368421052634e-06,
      "loss": 0.5699,
      "step": 82000
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.6077278852462769,
      "learning_rate": 1.8421052631578948e-06,
      "loss": 0.5694,
      "step": 82500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6534669399261475,
      "learning_rate": 1.7894736842105265e-06,
      "loss": 0.5697,
      "step": 83000
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.6307661533355713,
      "learning_rate": 1.736842105263158e-06,
      "loss": 0.569,
      "step": 83500
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5530495643615723,
      "learning_rate": 1.6842105263157895e-06,
      "loss": 0.5684,
      "step": 84000
    },
    {
      "epoch": 0.845,
      "grad_norm": 1.576720118522644,
      "learning_rate": 1.6315789473684212e-06,
      "loss": 0.5705,
      "step": 84500
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5643130540847778,
      "learning_rate": 1.5789473684210526e-06,
      "loss": 0.5688,
      "step": 85000
    },
    {
      "epoch": 0.855,
      "grad_norm": 1.6726198196411133,
      "learning_rate": 1.5263157894736844e-06,
      "loss": 0.5682,
      "step": 85500
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.5293582677841187,
      "learning_rate": 1.4736842105263159e-06,
      "loss": 0.5672,
      "step": 86000
    },
    {
      "epoch": 0.865,
      "grad_norm": 1.5981786251068115,
      "learning_rate": 1.4210526315789475e-06,
      "loss": 0.5677,
      "step": 86500
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.5962426662445068,
      "learning_rate": 1.3684210526315791e-06,
      "loss": 0.5682,
      "step": 87000
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.6765506267547607,
      "learning_rate": 1.3157894736842106e-06,
      "loss": 0.5682,
      "step": 87500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.567162275314331,
      "learning_rate": 1.2631578947368422e-06,
      "loss": 0.5677,
      "step": 88000
    },
    {
      "epoch": 0.885,
      "grad_norm": 1.55657958984375,
      "learning_rate": 1.2105263157894738e-06,
      "loss": 0.5681,
      "step": 88500
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.709093451499939,
      "learning_rate": 1.1578947368421053e-06,
      "loss": 0.5676,
      "step": 89000
    },
    {
      "epoch": 0.895,
      "grad_norm": 1.5661870241165161,
      "learning_rate": 1.1052631578947369e-06,
      "loss": 0.5669,
      "step": 89500
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6753804683685303,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.567,
      "step": 90000
    },
    {
      "epoch": 0.905,
      "grad_norm": 1.5028425455093384,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.5674,
      "step": 90500
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.540960669517517,
      "learning_rate": 9.473684210526317e-07,
      "loss": 0.5664,
      "step": 91000
    },
    {
      "epoch": 0.915,
      "grad_norm": 1.6259727478027344,
      "learning_rate": 8.947368421052632e-07,
      "loss": 0.5668,
      "step": 91500
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6900945901870728,
      "learning_rate": 8.421052631578948e-07,
      "loss": 0.5674,
      "step": 92000
    },
    {
      "epoch": 0.925,
      "grad_norm": 1.5187616348266602,
      "learning_rate": 7.894736842105263e-07,
      "loss": 0.566,
      "step": 92500
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.6322925090789795,
      "learning_rate": 7.368421052631579e-07,
      "loss": 0.5657,
      "step": 93000
    },
    {
      "epoch": 0.935,
      "grad_norm": 1.5006790161132812,
      "learning_rate": 6.842105263157896e-07,
      "loss": 0.5664,
      "step": 93500
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6559193134307861,
      "learning_rate": 6.315789473684211e-07,
      "loss": 0.5656,
      "step": 94000
    },
    {
      "epoch": 0.945,
      "grad_norm": 1.5456594228744507,
      "learning_rate": 5.789473684210526e-07,
      "loss": 0.566,
      "step": 94500
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.5295203924179077,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.566,
      "step": 95000
    },
    {
      "epoch": 0.955,
      "grad_norm": 1.6590657234191895,
      "learning_rate": 4.7368421052631585e-07,
      "loss": 0.5656,
      "step": 95500
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.701460361480713,
      "learning_rate": 4.210526315789474e-07,
      "loss": 0.5648,
      "step": 96000
    },
    {
      "epoch": 0.965,
      "grad_norm": 1.5950783491134644,
      "learning_rate": 3.6842105263157896e-07,
      "loss": 0.5644,
      "step": 96500
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5919713973999023,
      "learning_rate": 3.1578947368421055e-07,
      "loss": 0.5657,
      "step": 97000
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.5533229112625122,
      "learning_rate": 2.6315789473684213e-07,
      "loss": 0.5653,
      "step": 97500
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6860448122024536,
      "learning_rate": 2.105263157894737e-07,
      "loss": 0.5655,
      "step": 98000
    },
    {
      "epoch": 0.985,
      "grad_norm": 1.7279529571533203,
      "learning_rate": 1.5789473684210527e-07,
      "loss": 0.5646,
      "step": 98500
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.5281978845596313,
      "learning_rate": 1.0526315789473685e-07,
      "loss": 0.5653,
      "step": 99000
    },
    {
      "epoch": 0.995,
      "grad_norm": 1.4984816312789917,
      "learning_rate": 5.263157894736842e-08,
      "loss": 0.5643,
      "step": 99500
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7235689163208008,
      "learning_rate": 0.0,
      "loss": 0.564,
      "step": 100000
    },
    {
      "epoch": 1.0,
      "step": 100000,
      "total_flos": 2.5134480203784154e+17,
      "train_loss": 0.6540513952636718,
      "train_runtime": 200253.1604,
      "train_samples_per_second": 63.919,
      "train_steps_per_second": 0.499
    }
  ],
  "logging_steps": 500,
  "max_steps": 100000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5134480203784154e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
