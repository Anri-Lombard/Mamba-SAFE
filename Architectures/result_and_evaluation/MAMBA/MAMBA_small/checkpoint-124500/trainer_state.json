{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.00558,
  "eval_steps": 500.0,
  "global_step": 124500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 4.960024833679199,
      "learning_rate": 2.5e-05,
      "loss": 1.865,
      "step": 500
    },
    {
      "epoch": 0.008,
      "grad_norm": 2.400972843170166,
      "learning_rate": 5e-05,
      "loss": 0.7147,
      "step": 1000
    },
    {
      "epoch": 0.012,
      "grad_norm": 1.7662913799285889,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.6047,
      "step": 1500
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.2926127910614014,
      "learning_rate": 0.0001,
      "loss": 0.5985,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1482712030410767,
      "learning_rate": 9.959349593495935e-05,
      "loss": 0.5625,
      "step": 2500
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.9207621812820435,
      "learning_rate": 9.91869918699187e-05,
      "loss": 0.5414,
      "step": 3000
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.7265150547027588,
      "learning_rate": 9.878048780487805e-05,
      "loss": 0.5292,
      "step": 3500
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.6924359202384949,
      "learning_rate": 9.837398373983741e-05,
      "loss": 0.534,
      "step": 4000
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.9857896566390991,
      "learning_rate": 9.796747967479674e-05,
      "loss": 0.5353,
      "step": 4500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.783294677734375,
      "learning_rate": 9.75609756097561e-05,
      "loss": 0.532,
      "step": 5000
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.8330584764480591,
      "learning_rate": 9.715447154471545e-05,
      "loss": 0.5255,
      "step": 5500
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.515903115272522,
      "learning_rate": 9.674796747967481e-05,
      "loss": 0.5213,
      "step": 6000
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.6565312743186951,
      "learning_rate": 9.634146341463415e-05,
      "loss": 0.499,
      "step": 6500
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.5883319973945618,
      "learning_rate": 9.59349593495935e-05,
      "loss": 0.5332,
      "step": 7000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5908611416816711,
      "learning_rate": 9.552845528455285e-05,
      "loss": 0.5095,
      "step": 7500
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.5806723237037659,
      "learning_rate": 9.51219512195122e-05,
      "loss": 0.5105,
      "step": 8000
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.558377742767334,
      "learning_rate": 9.471544715447155e-05,
      "loss": 0.5074,
      "step": 8500
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.5607608556747437,
      "learning_rate": 9.43089430894309e-05,
      "loss": 0.5031,
      "step": 9000
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.5507816672325134,
      "learning_rate": 9.390243902439024e-05,
      "loss": 0.5148,
      "step": 9500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5829009413719177,
      "learning_rate": 9.349593495934959e-05,
      "loss": 0.5046,
      "step": 10000
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.7820371985435486,
      "learning_rate": 9.308943089430895e-05,
      "loss": 0.502,
      "step": 10500
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.48686668276786804,
      "learning_rate": 9.26829268292683e-05,
      "loss": 0.5132,
      "step": 11000
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.5485315322875977,
      "learning_rate": 9.227642276422765e-05,
      "loss": 0.509,
      "step": 11500
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.42471516132354736,
      "learning_rate": 9.1869918699187e-05,
      "loss": 0.4964,
      "step": 12000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5026395320892334,
      "learning_rate": 9.146341463414635e-05,
      "loss": 0.5036,
      "step": 12500
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.5650496482849121,
      "learning_rate": 9.105691056910569e-05,
      "loss": 0.5052,
      "step": 13000
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.38687682151794434,
      "learning_rate": 9.065040650406505e-05,
      "loss": 0.5255,
      "step": 13500
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.44069069623947144,
      "learning_rate": 9.02439024390244e-05,
      "loss": 0.5156,
      "step": 14000
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.5854188203811646,
      "learning_rate": 8.983739837398374e-05,
      "loss": 0.4956,
      "step": 14500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4291684627532959,
      "learning_rate": 8.943089430894309e-05,
      "loss": 0.4949,
      "step": 15000
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.4431031048297882,
      "learning_rate": 8.902439024390244e-05,
      "loss": 0.4957,
      "step": 15500
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.5908450484275818,
      "learning_rate": 8.86178861788618e-05,
      "loss": 0.4878,
      "step": 16000
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.4023393988609314,
      "learning_rate": 8.821138211382113e-05,
      "loss": 0.5044,
      "step": 16500
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.47602200508117676,
      "learning_rate": 8.78048780487805e-05,
      "loss": 0.4902,
      "step": 17000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5588549375534058,
      "learning_rate": 8.739837398373984e-05,
      "loss": 0.501,
      "step": 17500
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.48446089029312134,
      "learning_rate": 8.699186991869919e-05,
      "loss": 0.5022,
      "step": 18000
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.5241689085960388,
      "learning_rate": 8.658536585365854e-05,
      "loss": 0.498,
      "step": 18500
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.641741156578064,
      "learning_rate": 8.61788617886179e-05,
      "loss": 0.4835,
      "step": 19000
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.3609272241592407,
      "learning_rate": 8.577235772357723e-05,
      "loss": 0.498,
      "step": 19500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.605297327041626,
      "learning_rate": 8.53658536585366e-05,
      "loss": 0.4937,
      "step": 20000
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.5551862716674805,
      "learning_rate": 8.495934959349594e-05,
      "loss": 0.5163,
      "step": 20500
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.4565631151199341,
      "learning_rate": 8.455284552845529e-05,
      "loss": 0.4824,
      "step": 21000
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.5234739184379578,
      "learning_rate": 8.414634146341464e-05,
      "loss": 0.4925,
      "step": 21500
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.4835411608219147,
      "learning_rate": 8.373983739837398e-05,
      "loss": 0.5057,
      "step": 22000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39442959427833557,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.4917,
      "step": 22500
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.41372376680374146,
      "learning_rate": 8.292682926829268e-05,
      "loss": 0.5063,
      "step": 23000
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.4631359577178955,
      "learning_rate": 8.252032520325204e-05,
      "loss": 0.5019,
      "step": 23500
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.3732762336730957,
      "learning_rate": 8.211382113821139e-05,
      "loss": 0.4945,
      "step": 24000
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.3711506128311157,
      "learning_rate": 8.170731707317073e-05,
      "loss": 0.497,
      "step": 24500
    },
    {
      "epoch": 1.001916,
      "grad_norm": 0.5935248136520386,
      "learning_rate": 8.130081300813008e-05,
      "loss": 0.5023,
      "step": 25000
    },
    {
      "epoch": 1.005916,
      "grad_norm": 0.5984943509101868,
      "learning_rate": 8.089430894308944e-05,
      "loss": 0.4825,
      "step": 25500
    },
    {
      "epoch": 1.009916,
      "grad_norm": 0.49021849036216736,
      "learning_rate": 8.048780487804879e-05,
      "loss": 0.5013,
      "step": 26000
    },
    {
      "epoch": 1.013916,
      "grad_norm": 0.38938072323799133,
      "learning_rate": 8.008130081300814e-05,
      "loss": 0.4906,
      "step": 26500
    },
    {
      "epoch": 1.017916,
      "grad_norm": 0.39695748686790466,
      "learning_rate": 7.967479674796748e-05,
      "loss": 0.4858,
      "step": 27000
    },
    {
      "epoch": 1.021916,
      "grad_norm": 0.40677282214164734,
      "learning_rate": 7.926829268292683e-05,
      "loss": 0.4859,
      "step": 27500
    },
    {
      "epoch": 1.025916,
      "grad_norm": 0.48529061675071716,
      "learning_rate": 7.886178861788618e-05,
      "loss": 0.4868,
      "step": 28000
    },
    {
      "epoch": 1.029916,
      "grad_norm": 0.4657718241214752,
      "learning_rate": 7.845528455284553e-05,
      "loss": 0.4905,
      "step": 28500
    },
    {
      "epoch": 1.033916,
      "grad_norm": 0.40348121523857117,
      "learning_rate": 7.804878048780489e-05,
      "loss": 0.4883,
      "step": 29000
    },
    {
      "epoch": 1.037916,
      "grad_norm": 0.3697774410247803,
      "learning_rate": 7.764227642276422e-05,
      "loss": 0.48,
      "step": 29500
    },
    {
      "epoch": 1.041916,
      "grad_norm": 0.44442546367645264,
      "learning_rate": 7.723577235772358e-05,
      "loss": 0.4994,
      "step": 30000
    },
    {
      "epoch": 1.045916,
      "grad_norm": 0.43315181136131287,
      "learning_rate": 7.682926829268293e-05,
      "loss": 0.4834,
      "step": 30500
    },
    {
      "epoch": 1.049916,
      "grad_norm": 0.482632040977478,
      "learning_rate": 7.642276422764229e-05,
      "loss": 0.4874,
      "step": 31000
    },
    {
      "epoch": 1.053916,
      "grad_norm": 0.5561473369598389,
      "learning_rate": 7.601626016260162e-05,
      "loss": 0.4813,
      "step": 31500
    },
    {
      "epoch": 1.057916,
      "grad_norm": 0.36674442887306213,
      "learning_rate": 7.560975609756099e-05,
      "loss": 0.4838,
      "step": 32000
    },
    {
      "epoch": 1.061916,
      "grad_norm": 0.35288479924201965,
      "learning_rate": 7.520325203252033e-05,
      "loss": 0.4932,
      "step": 32500
    },
    {
      "epoch": 1.065916,
      "grad_norm": 0.46157899498939514,
      "learning_rate": 7.479674796747968e-05,
      "loss": 0.4745,
      "step": 33000
    },
    {
      "epoch": 1.069916,
      "grad_norm": 0.3878422975540161,
      "learning_rate": 7.439024390243903e-05,
      "loss": 0.4907,
      "step": 33500
    },
    {
      "epoch": 1.073916,
      "grad_norm": 0.48631343245506287,
      "learning_rate": 7.398373983739838e-05,
      "loss": 0.4872,
      "step": 34000
    },
    {
      "epoch": 1.077916,
      "grad_norm": 0.6231423020362854,
      "learning_rate": 7.357723577235772e-05,
      "loss": 0.4772,
      "step": 34500
    },
    {
      "epoch": 1.081916,
      "grad_norm": 0.5789133906364441,
      "learning_rate": 7.317073170731707e-05,
      "loss": 0.4968,
      "step": 35000
    },
    {
      "epoch": 1.085916,
      "grad_norm": 0.4685439169406891,
      "learning_rate": 7.276422764227643e-05,
      "loss": 0.4834,
      "step": 35500
    },
    {
      "epoch": 1.089916,
      "grad_norm": 0.35889431834220886,
      "learning_rate": 7.235772357723578e-05,
      "loss": 0.4992,
      "step": 36000
    },
    {
      "epoch": 1.093916,
      "grad_norm": 0.33978915214538574,
      "learning_rate": 7.195121951219513e-05,
      "loss": 0.4949,
      "step": 36500
    },
    {
      "epoch": 1.0979160000000001,
      "grad_norm": 0.4555857181549072,
      "learning_rate": 7.154471544715447e-05,
      "loss": 0.5069,
      "step": 37000
    },
    {
      "epoch": 1.1019160000000001,
      "grad_norm": 0.4927152991294861,
      "learning_rate": 7.113821138211383e-05,
      "loss": 0.4902,
      "step": 37500
    },
    {
      "epoch": 1.105916,
      "grad_norm": 0.40764328837394714,
      "learning_rate": 7.073170731707317e-05,
      "loss": 0.5079,
      "step": 38000
    },
    {
      "epoch": 1.109916,
      "grad_norm": 0.4389142394065857,
      "learning_rate": 7.032520325203253e-05,
      "loss": 0.4764,
      "step": 38500
    },
    {
      "epoch": 1.113916,
      "grad_norm": 0.3797808885574341,
      "learning_rate": 6.991869918699188e-05,
      "loss": 0.4848,
      "step": 39000
    },
    {
      "epoch": 1.117916,
      "grad_norm": 0.6123422384262085,
      "learning_rate": 6.951219512195122e-05,
      "loss": 0.4797,
      "step": 39500
    },
    {
      "epoch": 1.121916,
      "grad_norm": 0.37371695041656494,
      "learning_rate": 6.910569105691057e-05,
      "loss": 0.4958,
      "step": 40000
    },
    {
      "epoch": 1.125916,
      "grad_norm": 0.36569565534591675,
      "learning_rate": 6.869918699186992e-05,
      "loss": 0.4932,
      "step": 40500
    },
    {
      "epoch": 1.129916,
      "grad_norm": 0.40457624197006226,
      "learning_rate": 6.829268292682928e-05,
      "loss": 0.4846,
      "step": 41000
    },
    {
      "epoch": 1.133916,
      "grad_norm": 0.4175867438316345,
      "learning_rate": 6.788617886178861e-05,
      "loss": 0.4877,
      "step": 41500
    },
    {
      "epoch": 1.137916,
      "grad_norm": 0.42906808853149414,
      "learning_rate": 6.747967479674798e-05,
      "loss": 0.4859,
      "step": 42000
    },
    {
      "epoch": 1.141916,
      "grad_norm": 0.7273266911506653,
      "learning_rate": 6.707317073170732e-05,
      "loss": 0.491,
      "step": 42500
    },
    {
      "epoch": 1.145916,
      "grad_norm": 0.46342790126800537,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.4844,
      "step": 43000
    },
    {
      "epoch": 1.149916,
      "grad_norm": 0.40589022636413574,
      "learning_rate": 6.626016260162602e-05,
      "loss": 0.4741,
      "step": 43500
    },
    {
      "epoch": 1.153916,
      "grad_norm": 0.32183533906936646,
      "learning_rate": 6.585365853658538e-05,
      "loss": 0.49,
      "step": 44000
    },
    {
      "epoch": 1.157916,
      "grad_norm": 0.43155819177627563,
      "learning_rate": 6.544715447154471e-05,
      "loss": 0.4752,
      "step": 44500
    },
    {
      "epoch": 1.161916,
      "grad_norm": 0.39469119906425476,
      "learning_rate": 6.504065040650407e-05,
      "loss": 0.4834,
      "step": 45000
    },
    {
      "epoch": 1.165916,
      "grad_norm": 0.43475139141082764,
      "learning_rate": 6.463414634146342e-05,
      "loss": 0.481,
      "step": 45500
    },
    {
      "epoch": 1.169916,
      "grad_norm": 0.39400768280029297,
      "learning_rate": 6.422764227642277e-05,
      "loss": 0.4805,
      "step": 46000
    },
    {
      "epoch": 1.173916,
      "grad_norm": 0.4614434540271759,
      "learning_rate": 6.382113821138212e-05,
      "loss": 0.4865,
      "step": 46500
    },
    {
      "epoch": 1.177916,
      "grad_norm": 0.49500349164009094,
      "learning_rate": 6.341463414634146e-05,
      "loss": 0.4914,
      "step": 47000
    },
    {
      "epoch": 1.181916,
      "grad_norm": 0.34599289298057556,
      "learning_rate": 6.300813008130082e-05,
      "loss": 0.4778,
      "step": 47500
    },
    {
      "epoch": 1.185916,
      "grad_norm": 0.5474764704704285,
      "learning_rate": 6.260162601626016e-05,
      "loss": 0.4806,
      "step": 48000
    },
    {
      "epoch": 1.189916,
      "grad_norm": 0.5105851292610168,
      "learning_rate": 6.219512195121952e-05,
      "loss": 0.491,
      "step": 48500
    },
    {
      "epoch": 1.193916,
      "grad_norm": 0.40655550360679626,
      "learning_rate": 6.178861788617887e-05,
      "loss": 0.4876,
      "step": 49000
    },
    {
      "epoch": 1.197916,
      "grad_norm": 0.3576386868953705,
      "learning_rate": 6.138211382113821e-05,
      "loss": 0.4906,
      "step": 49500
    },
    {
      "epoch": 2.003832,
      "grad_norm": 0.4082720875740051,
      "learning_rate": 6.097560975609756e-05,
      "loss": 0.4647,
      "step": 50000
    },
    {
      "epoch": 2.007832,
      "grad_norm": 0.4905134439468384,
      "learning_rate": 6.0569105691056915e-05,
      "loss": 0.4662,
      "step": 50500
    },
    {
      "epoch": 2.011832,
      "grad_norm": 0.41290682554244995,
      "learning_rate": 6.016260162601627e-05,
      "loss": 0.4759,
      "step": 51000
    },
    {
      "epoch": 2.015832,
      "grad_norm": 0.384033739566803,
      "learning_rate": 5.975609756097561e-05,
      "loss": 0.4793,
      "step": 51500
    },
    {
      "epoch": 2.019832,
      "grad_norm": 0.39650246500968933,
      "learning_rate": 5.9349593495934964e-05,
      "loss": 0.4754,
      "step": 52000
    },
    {
      "epoch": 2.023832,
      "grad_norm": 0.39702048897743225,
      "learning_rate": 5.894308943089432e-05,
      "loss": 0.4903,
      "step": 52500
    },
    {
      "epoch": 2.027832,
      "grad_norm": 0.4555402398109436,
      "learning_rate": 5.853658536585366e-05,
      "loss": 0.4642,
      "step": 53000
    },
    {
      "epoch": 2.031832,
      "grad_norm": 0.401202917098999,
      "learning_rate": 5.813008130081301e-05,
      "loss": 0.4731,
      "step": 53500
    },
    {
      "epoch": 2.035832,
      "grad_norm": 0.6223105788230896,
      "learning_rate": 5.772357723577236e-05,
      "loss": 0.4704,
      "step": 54000
    },
    {
      "epoch": 2.039832,
      "grad_norm": 0.5296815633773804,
      "learning_rate": 5.731707317073171e-05,
      "loss": 0.4844,
      "step": 54500
    },
    {
      "epoch": 2.043832,
      "grad_norm": 0.5565192699432373,
      "learning_rate": 5.6910569105691056e-05,
      "loss": 0.4867,
      "step": 55000
    },
    {
      "epoch": 2.047832,
      "grad_norm": 0.43650272488594055,
      "learning_rate": 5.650406504065041e-05,
      "loss": 0.4658,
      "step": 55500
    },
    {
      "epoch": 2.051832,
      "grad_norm": 0.39786601066589355,
      "learning_rate": 5.6097560975609764e-05,
      "loss": 0.4735,
      "step": 56000
    },
    {
      "epoch": 2.055832,
      "grad_norm": 0.3649964928627014,
      "learning_rate": 5.5691056910569105e-05,
      "loss": 0.4709,
      "step": 56500
    },
    {
      "epoch": 2.059832,
      "grad_norm": 0.433866411447525,
      "learning_rate": 5.528455284552846e-05,
      "loss": 0.4794,
      "step": 57000
    },
    {
      "epoch": 2.063832,
      "grad_norm": 0.4930129945278168,
      "learning_rate": 5.487804878048781e-05,
      "loss": 0.483,
      "step": 57500
    },
    {
      "epoch": 2.067832,
      "grad_norm": 0.45121103525161743,
      "learning_rate": 5.4471544715447154e-05,
      "loss": 0.4854,
      "step": 58000
    },
    {
      "epoch": 2.071832,
      "grad_norm": 0.41704320907592773,
      "learning_rate": 5.406504065040651e-05,
      "loss": 0.4695,
      "step": 58500
    },
    {
      "epoch": 2.075832,
      "grad_norm": 0.5234065055847168,
      "learning_rate": 5.365853658536586e-05,
      "loss": 0.4683,
      "step": 59000
    },
    {
      "epoch": 2.079832,
      "grad_norm": 0.3938803970813751,
      "learning_rate": 5.32520325203252e-05,
      "loss": 0.4941,
      "step": 59500
    },
    {
      "epoch": 2.083832,
      "grad_norm": 0.40545153617858887,
      "learning_rate": 5.284552845528456e-05,
      "loss": 0.4916,
      "step": 60000
    },
    {
      "epoch": 2.087832,
      "grad_norm": 0.38368475437164307,
      "learning_rate": 5.2439024390243904e-05,
      "loss": 0.4876,
      "step": 60500
    },
    {
      "epoch": 2.091832,
      "grad_norm": 0.4868125915527344,
      "learning_rate": 5.203252032520326e-05,
      "loss": 0.4832,
      "step": 61000
    },
    {
      "epoch": 2.095832,
      "grad_norm": 0.49788710474967957,
      "learning_rate": 5.16260162601626e-05,
      "loss": 0.4768,
      "step": 61500
    },
    {
      "epoch": 2.099832,
      "grad_norm": 0.5628216862678528,
      "learning_rate": 5.121951219512195e-05,
      "loss": 0.4773,
      "step": 62000
    },
    {
      "epoch": 2.103832,
      "grad_norm": 0.4735965430736542,
      "learning_rate": 5.081300813008131e-05,
      "loss": 0.4704,
      "step": 62500
    },
    {
      "epoch": 2.107832,
      "grad_norm": 0.5189282894134521,
      "learning_rate": 5.040650406504065e-05,
      "loss": 0.4794,
      "step": 63000
    },
    {
      "epoch": 2.111832,
      "grad_norm": 0.5347498655319214,
      "learning_rate": 5e-05,
      "loss": 0.4815,
      "step": 63500
    },
    {
      "epoch": 2.115832,
      "grad_norm": 0.45163416862487793,
      "learning_rate": 4.959349593495935e-05,
      "loss": 0.487,
      "step": 64000
    },
    {
      "epoch": 2.119832,
      "grad_norm": 0.44413241744041443,
      "learning_rate": 4.9186991869918704e-05,
      "loss": 0.4726,
      "step": 64500
    },
    {
      "epoch": 2.123832,
      "grad_norm": 0.4972092807292938,
      "learning_rate": 4.878048780487805e-05,
      "loss": 0.488,
      "step": 65000
    },
    {
      "epoch": 2.127832,
      "grad_norm": 0.6078209280967712,
      "learning_rate": 4.8373983739837406e-05,
      "loss": 0.4957,
      "step": 65500
    },
    {
      "epoch": 2.131832,
      "grad_norm": 0.426407128572464,
      "learning_rate": 4.796747967479675e-05,
      "loss": 0.4807,
      "step": 66000
    },
    {
      "epoch": 2.135832,
      "grad_norm": 0.3841527998447418,
      "learning_rate": 4.75609756097561e-05,
      "loss": 0.4891,
      "step": 66500
    },
    {
      "epoch": 2.139832,
      "grad_norm": 0.4186706840991974,
      "learning_rate": 4.715447154471545e-05,
      "loss": 0.4712,
      "step": 67000
    },
    {
      "epoch": 2.143832,
      "grad_norm": 0.4408230483531952,
      "learning_rate": 4.6747967479674795e-05,
      "loss": 0.475,
      "step": 67500
    },
    {
      "epoch": 2.147832,
      "grad_norm": 0.34970006346702576,
      "learning_rate": 4.634146341463415e-05,
      "loss": 0.4841,
      "step": 68000
    },
    {
      "epoch": 2.151832,
      "grad_norm": 0.41306543350219727,
      "learning_rate": 4.59349593495935e-05,
      "loss": 0.4768,
      "step": 68500
    },
    {
      "epoch": 2.155832,
      "grad_norm": 0.39924687147140503,
      "learning_rate": 4.5528455284552844e-05,
      "loss": 0.4809,
      "step": 69000
    },
    {
      "epoch": 2.159832,
      "grad_norm": 0.7369326949119568,
      "learning_rate": 4.51219512195122e-05,
      "loss": 0.4653,
      "step": 69500
    },
    {
      "epoch": 2.163832,
      "grad_norm": 0.40588194131851196,
      "learning_rate": 4.4715447154471546e-05,
      "loss": 0.4842,
      "step": 70000
    },
    {
      "epoch": 2.167832,
      "grad_norm": 0.32737529277801514,
      "learning_rate": 4.43089430894309e-05,
      "loss": 0.4779,
      "step": 70500
    },
    {
      "epoch": 2.171832,
      "grad_norm": 0.4322737753391266,
      "learning_rate": 4.390243902439025e-05,
      "loss": 0.476,
      "step": 71000
    },
    {
      "epoch": 2.1758319999999998,
      "grad_norm": 0.3125886619091034,
      "learning_rate": 4.3495934959349595e-05,
      "loss": 0.4888,
      "step": 71500
    },
    {
      "epoch": 2.179832,
      "grad_norm": 0.49951171875,
      "learning_rate": 4.308943089430895e-05,
      "loss": 0.4873,
      "step": 72000
    },
    {
      "epoch": 2.1838319999999998,
      "grad_norm": 0.3776392936706543,
      "learning_rate": 4.26829268292683e-05,
      "loss": 0.4829,
      "step": 72500
    },
    {
      "epoch": 2.187832,
      "grad_norm": 0.38575291633605957,
      "learning_rate": 4.2276422764227644e-05,
      "loss": 0.4796,
      "step": 73000
    },
    {
      "epoch": 2.191832,
      "grad_norm": 0.5585387945175171,
      "learning_rate": 4.186991869918699e-05,
      "loss": 0.4854,
      "step": 73500
    },
    {
      "epoch": 2.1958320000000002,
      "grad_norm": 0.4239269495010376,
      "learning_rate": 4.146341463414634e-05,
      "loss": 0.4751,
      "step": 74000
    },
    {
      "epoch": 3.001748,
      "grad_norm": 0.5710251927375793,
      "learning_rate": 4.105691056910569e-05,
      "loss": 0.4821,
      "step": 74500
    },
    {
      "epoch": 3.005748,
      "grad_norm": 0.40755656361579895,
      "learning_rate": 4.065040650406504e-05,
      "loss": 0.4635,
      "step": 75000
    },
    {
      "epoch": 3.009748,
      "grad_norm": 0.45445671677589417,
      "learning_rate": 4.0243902439024395e-05,
      "loss": 0.4544,
      "step": 75500
    },
    {
      "epoch": 3.013748,
      "grad_norm": 0.41308891773223877,
      "learning_rate": 3.983739837398374e-05,
      "loss": 0.4663,
      "step": 76000
    },
    {
      "epoch": 3.017748,
      "grad_norm": 0.4981704652309418,
      "learning_rate": 3.943089430894309e-05,
      "loss": 0.462,
      "step": 76500
    },
    {
      "epoch": 3.021748,
      "grad_norm": 0.4644067585468292,
      "learning_rate": 3.9024390243902444e-05,
      "loss": 0.4689,
      "step": 77000
    },
    {
      "epoch": 3.025748,
      "grad_norm": 0.3977459967136383,
      "learning_rate": 3.861788617886179e-05,
      "loss": 0.4736,
      "step": 77500
    },
    {
      "epoch": 3.029748,
      "grad_norm": 0.35043808817863464,
      "learning_rate": 3.8211382113821145e-05,
      "loss": 0.4696,
      "step": 78000
    },
    {
      "epoch": 3.033748,
      "grad_norm": 0.39882633090019226,
      "learning_rate": 3.780487804878049e-05,
      "loss": 0.4848,
      "step": 78500
    },
    {
      "epoch": 3.037748,
      "grad_norm": 0.4242912232875824,
      "learning_rate": 3.739837398373984e-05,
      "loss": 0.4734,
      "step": 79000
    },
    {
      "epoch": 3.041748,
      "grad_norm": 0.39482465386390686,
      "learning_rate": 3.699186991869919e-05,
      "loss": 0.4844,
      "step": 79500
    },
    {
      "epoch": 3.045748,
      "grad_norm": 0.41654831171035767,
      "learning_rate": 3.6585365853658535e-05,
      "loss": 0.4629,
      "step": 80000
    },
    {
      "epoch": 3.049748,
      "grad_norm": 0.43297749757766724,
      "learning_rate": 3.617886178861789e-05,
      "loss": 0.4597,
      "step": 80500
    },
    {
      "epoch": 3.053748,
      "grad_norm": 0.39599743485450745,
      "learning_rate": 3.577235772357724e-05,
      "loss": 0.48,
      "step": 81000
    },
    {
      "epoch": 3.057748,
      "grad_norm": 0.4086383283138275,
      "learning_rate": 3.5365853658536584e-05,
      "loss": 0.4609,
      "step": 81500
    },
    {
      "epoch": 3.061748,
      "grad_norm": 0.3704492449760437,
      "learning_rate": 3.495934959349594e-05,
      "loss": 0.487,
      "step": 82000
    },
    {
      "epoch": 3.065748,
      "grad_norm": 0.5060901641845703,
      "learning_rate": 3.4552845528455286e-05,
      "loss": 0.4709,
      "step": 82500
    },
    {
      "epoch": 3.069748,
      "grad_norm": 0.4217990040779114,
      "learning_rate": 3.414634146341464e-05,
      "loss": 0.471,
      "step": 83000
    },
    {
      "epoch": 3.073748,
      "grad_norm": 0.4434802532196045,
      "learning_rate": 3.373983739837399e-05,
      "loss": 0.4847,
      "step": 83500
    },
    {
      "epoch": 3.077748,
      "grad_norm": 0.5056825280189514,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.4804,
      "step": 84000
    },
    {
      "epoch": 3.081748,
      "grad_norm": 0.3322124481201172,
      "learning_rate": 3.292682926829269e-05,
      "loss": 0.4725,
      "step": 84500
    },
    {
      "epoch": 3.085748,
      "grad_norm": 0.5885105133056641,
      "learning_rate": 3.2520325203252037e-05,
      "loss": 0.4866,
      "step": 85000
    },
    {
      "epoch": 3.089748,
      "grad_norm": 0.34091508388519287,
      "learning_rate": 3.2113821138211384e-05,
      "loss": 0.471,
      "step": 85500
    },
    {
      "epoch": 3.093748,
      "grad_norm": 0.3961472511291504,
      "learning_rate": 3.170731707317073e-05,
      "loss": 0.4903,
      "step": 86000
    },
    {
      "epoch": 3.097748,
      "grad_norm": 0.49488577246665955,
      "learning_rate": 3.130081300813008e-05,
      "loss": 0.4797,
      "step": 86500
    },
    {
      "epoch": 3.101748,
      "grad_norm": 0.3564399480819702,
      "learning_rate": 3.089430894308943e-05,
      "loss": 0.4865,
      "step": 87000
    },
    {
      "epoch": 3.105748,
      "grad_norm": 0.3244035840034485,
      "learning_rate": 3.048780487804878e-05,
      "loss": 0.4745,
      "step": 87500
    },
    {
      "epoch": 3.109748,
      "grad_norm": 0.3558276891708374,
      "learning_rate": 3.0081300813008135e-05,
      "loss": 0.4666,
      "step": 88000
    },
    {
      "epoch": 3.113748,
      "grad_norm": 0.562125027179718,
      "learning_rate": 2.9674796747967482e-05,
      "loss": 0.4709,
      "step": 88500
    },
    {
      "epoch": 3.117748,
      "grad_norm": 0.5180830359458923,
      "learning_rate": 2.926829268292683e-05,
      "loss": 0.4697,
      "step": 89000
    },
    {
      "epoch": 3.121748,
      "grad_norm": 0.3506547510623932,
      "learning_rate": 2.886178861788618e-05,
      "loss": 0.4734,
      "step": 89500
    },
    {
      "epoch": 3.125748,
      "grad_norm": 0.4667527377605438,
      "learning_rate": 2.8455284552845528e-05,
      "loss": 0.4776,
      "step": 90000
    },
    {
      "epoch": 3.129748,
      "grad_norm": 0.36551132798194885,
      "learning_rate": 2.8048780487804882e-05,
      "loss": 0.4692,
      "step": 90500
    },
    {
      "epoch": 3.133748,
      "grad_norm": 0.3657795190811157,
      "learning_rate": 2.764227642276423e-05,
      "loss": 0.4739,
      "step": 91000
    },
    {
      "epoch": 3.137748,
      "grad_norm": 0.4468729496002197,
      "learning_rate": 2.7235772357723577e-05,
      "loss": 0.4695,
      "step": 91500
    },
    {
      "epoch": 3.141748,
      "grad_norm": 0.45179322361946106,
      "learning_rate": 2.682926829268293e-05,
      "loss": 0.4765,
      "step": 92000
    },
    {
      "epoch": 3.145748,
      "grad_norm": 0.4440004229545593,
      "learning_rate": 2.642276422764228e-05,
      "loss": 0.4666,
      "step": 92500
    },
    {
      "epoch": 3.1497479999999998,
      "grad_norm": 0.4273991882801056,
      "learning_rate": 2.601626016260163e-05,
      "loss": 0.4686,
      "step": 93000
    },
    {
      "epoch": 3.153748,
      "grad_norm": 0.441211462020874,
      "learning_rate": 2.5609756097560977e-05,
      "loss": 0.4735,
      "step": 93500
    },
    {
      "epoch": 3.1577479999999998,
      "grad_norm": 0.5859072208404541,
      "learning_rate": 2.5203252032520324e-05,
      "loss": 0.4821,
      "step": 94000
    },
    {
      "epoch": 3.1617480000000002,
      "grad_norm": 0.3982680141925812,
      "learning_rate": 2.4796747967479675e-05,
      "loss": 0.4779,
      "step": 94500
    },
    {
      "epoch": 3.165748,
      "grad_norm": 0.381024569272995,
      "learning_rate": 2.4390243902439026e-05,
      "loss": 0.4707,
      "step": 95000
    },
    {
      "epoch": 3.1697480000000002,
      "grad_norm": 0.48844558000564575,
      "learning_rate": 2.3983739837398377e-05,
      "loss": 0.4802,
      "step": 95500
    },
    {
      "epoch": 3.173748,
      "grad_norm": 0.38899287581443787,
      "learning_rate": 2.3577235772357724e-05,
      "loss": 0.4791,
      "step": 96000
    },
    {
      "epoch": 3.177748,
      "grad_norm": 0.36652931571006775,
      "learning_rate": 2.3170731707317075e-05,
      "loss": 0.4714,
      "step": 96500
    },
    {
      "epoch": 3.181748,
      "grad_norm": 0.4347041845321655,
      "learning_rate": 2.2764227642276422e-05,
      "loss": 0.4687,
      "step": 97000
    },
    {
      "epoch": 3.185748,
      "grad_norm": 0.6114968061447144,
      "learning_rate": 2.2357723577235773e-05,
      "loss": 0.4854,
      "step": 97500
    },
    {
      "epoch": 3.189748,
      "grad_norm": 0.5861392617225647,
      "learning_rate": 2.1951219512195124e-05,
      "loss": 0.476,
      "step": 98000
    },
    {
      "epoch": 3.193748,
      "grad_norm": 0.5500346422195435,
      "learning_rate": 2.1544715447154475e-05,
      "loss": 0.481,
      "step": 98500
    },
    {
      "epoch": 3.197748,
      "grad_norm": 0.47615644335746765,
      "learning_rate": 2.1138211382113822e-05,
      "loss": 0.4731,
      "step": 99000
    },
    {
      "epoch": 4.003664,
      "grad_norm": 0.5077232122421265,
      "learning_rate": 2.073170731707317e-05,
      "loss": 0.4664,
      "step": 99500
    },
    {
      "epoch": 4.007664,
      "grad_norm": 0.4315498173236847,
      "learning_rate": 2.032520325203252e-05,
      "loss": 0.4723,
      "step": 100000
    },
    {
      "epoch": 4.011664,
      "grad_norm": 0.5039910078048706,
      "learning_rate": 1.991869918699187e-05,
      "loss": 0.4652,
      "step": 100500
    },
    {
      "epoch": 4.015664,
      "grad_norm": 0.36890295147895813,
      "learning_rate": 1.9512195121951222e-05,
      "loss": 0.4635,
      "step": 101000
    },
    {
      "epoch": 4.019664,
      "grad_norm": 0.43817734718322754,
      "learning_rate": 1.9105691056910573e-05,
      "loss": 0.4687,
      "step": 101500
    },
    {
      "epoch": 4.023664,
      "grad_norm": 0.40367281436920166,
      "learning_rate": 1.869918699186992e-05,
      "loss": 0.4564,
      "step": 102000
    },
    {
      "epoch": 4.027664,
      "grad_norm": 0.4479118883609772,
      "learning_rate": 1.8292682926829268e-05,
      "loss": 0.4712,
      "step": 102500
    },
    {
      "epoch": 4.031664,
      "grad_norm": 0.35251426696777344,
      "learning_rate": 1.788617886178862e-05,
      "loss": 0.4657,
      "step": 103000
    },
    {
      "epoch": 4.035664,
      "grad_norm": 0.49848076701164246,
      "learning_rate": 1.747967479674797e-05,
      "loss": 0.4624,
      "step": 103500
    },
    {
      "epoch": 4.039664,
      "grad_norm": 0.5025275945663452,
      "learning_rate": 1.707317073170732e-05,
      "loss": 0.4696,
      "step": 104000
    },
    {
      "epoch": 4.043664,
      "grad_norm": 0.3827810287475586,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.4674,
      "step": 104500
    },
    {
      "epoch": 4.047664,
      "grad_norm": 0.6311251521110535,
      "learning_rate": 1.6260162601626018e-05,
      "loss": 0.483,
      "step": 105000
    },
    {
      "epoch": 4.051664,
      "grad_norm": 0.465049684047699,
      "learning_rate": 1.5853658536585366e-05,
      "loss": 0.4624,
      "step": 105500
    },
    {
      "epoch": 4.055664,
      "grad_norm": 0.6205571293830872,
      "learning_rate": 1.5447154471544717e-05,
      "loss": 0.4663,
      "step": 106000
    },
    {
      "epoch": 4.059664,
      "grad_norm": 0.5015729665756226,
      "learning_rate": 1.5040650406504067e-05,
      "loss": 0.4612,
      "step": 106500
    },
    {
      "epoch": 4.063664,
      "grad_norm": 0.43195632100105286,
      "learning_rate": 1.4634146341463415e-05,
      "loss": 0.4675,
      "step": 107000
    },
    {
      "epoch": 4.067664,
      "grad_norm": 0.43173032999038696,
      "learning_rate": 1.4227642276422764e-05,
      "loss": 0.4704,
      "step": 107500
    },
    {
      "epoch": 4.071664,
      "grad_norm": 0.4089665710926056,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 0.4779,
      "step": 108000
    },
    {
      "epoch": 4.075664,
      "grad_norm": 0.4250248968601227,
      "learning_rate": 1.3414634146341466e-05,
      "loss": 0.4559,
      "step": 108500
    },
    {
      "epoch": 4.079664,
      "grad_norm": 0.562275767326355,
      "learning_rate": 1.3008130081300815e-05,
      "loss": 0.4795,
      "step": 109000
    },
    {
      "epoch": 4.083664,
      "grad_norm": 0.5398656129837036,
      "learning_rate": 1.2601626016260162e-05,
      "loss": 0.4698,
      "step": 109500
    },
    {
      "epoch": 4.087664,
      "grad_norm": 0.6155350208282471,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 0.4776,
      "step": 110000
    },
    {
      "epoch": 4.091664,
      "grad_norm": 0.39953216910362244,
      "learning_rate": 1.1788617886178862e-05,
      "loss": 0.4672,
      "step": 110500
    },
    {
      "epoch": 4.095664,
      "grad_norm": 0.32090598344802856,
      "learning_rate": 1.1382113821138211e-05,
      "loss": 0.4728,
      "step": 111000
    },
    {
      "epoch": 4.099664,
      "grad_norm": 0.4616434574127197,
      "learning_rate": 1.0975609756097562e-05,
      "loss": 0.4762,
      "step": 111500
    },
    {
      "epoch": 4.103664,
      "grad_norm": 0.4140365719795227,
      "learning_rate": 1.0569105691056911e-05,
      "loss": 0.4715,
      "step": 112000
    },
    {
      "epoch": 4.107664,
      "grad_norm": 0.4561558961868286,
      "learning_rate": 1.016260162601626e-05,
      "loss": 0.4695,
      "step": 112500
    },
    {
      "epoch": 4.111664,
      "grad_norm": 0.6005977988243103,
      "learning_rate": 9.756097560975611e-06,
      "loss": 0.4665,
      "step": 113000
    },
    {
      "epoch": 4.115664,
      "grad_norm": 0.6490839123725891,
      "learning_rate": 9.34959349593496e-06,
      "loss": 0.4775,
      "step": 113500
    },
    {
      "epoch": 4.119664,
      "grad_norm": 0.4484056234359741,
      "learning_rate": 8.94308943089431e-06,
      "loss": 0.4772,
      "step": 114000
    },
    {
      "epoch": 4.123664,
      "grad_norm": 0.44678470492362976,
      "learning_rate": 8.53658536585366e-06,
      "loss": 0.4715,
      "step": 114500
    },
    {
      "epoch": 4.127664,
      "grad_norm": 0.44380316138267517,
      "learning_rate": 8.130081300813009e-06,
      "loss": 0.4701,
      "step": 115000
    },
    {
      "epoch": 4.131664,
      "grad_norm": 0.37410083413124084,
      "learning_rate": 7.723577235772358e-06,
      "loss": 0.4861,
      "step": 115500
    },
    {
      "epoch": 4.135664,
      "grad_norm": 0.49858206510543823,
      "learning_rate": 7.317073170731707e-06,
      "loss": 0.4822,
      "step": 116000
    },
    {
      "epoch": 4.139664,
      "grad_norm": 0.3458191752433777,
      "learning_rate": 6.910569105691057e-06,
      "loss": 0.4665,
      "step": 116500
    },
    {
      "epoch": 4.143664,
      "grad_norm": 0.3857012391090393,
      "learning_rate": 6.504065040650407e-06,
      "loss": 0.478,
      "step": 117000
    },
    {
      "epoch": 4.147664,
      "grad_norm": 0.542568027973175,
      "learning_rate": 6.0975609756097564e-06,
      "loss": 0.4654,
      "step": 117500
    },
    {
      "epoch": 4.151664,
      "grad_norm": 0.4740148186683655,
      "learning_rate": 5.6910569105691056e-06,
      "loss": 0.4822,
      "step": 118000
    },
    {
      "epoch": 4.155664,
      "grad_norm": 0.43815878033638,
      "learning_rate": 5.2845528455284555e-06,
      "loss": 0.4768,
      "step": 118500
    },
    {
      "epoch": 4.159664,
      "grad_norm": 0.40265893936157227,
      "learning_rate": 4.8780487804878055e-06,
      "loss": 0.4612,
      "step": 119000
    },
    {
      "epoch": 4.163664,
      "grad_norm": 0.5417737364768982,
      "learning_rate": 4.471544715447155e-06,
      "loss": 0.4759,
      "step": 119500
    },
    {
      "epoch": 4.167664,
      "grad_norm": 0.54416424036026,
      "learning_rate": 4.0650406504065046e-06,
      "loss": 0.4759,
      "step": 120000
    },
    {
      "epoch": 4.171664,
      "grad_norm": 0.4665563702583313,
      "learning_rate": 3.6585365853658537e-06,
      "loss": 0.4756,
      "step": 120500
    },
    {
      "epoch": 4.175664,
      "grad_norm": 0.4632738530635834,
      "learning_rate": 3.2520325203252037e-06,
      "loss": 0.472,
      "step": 121000
    },
    {
      "epoch": 4.179664,
      "grad_norm": 0.40591955184936523,
      "learning_rate": 2.8455284552845528e-06,
      "loss": 0.4694,
      "step": 121500
    },
    {
      "epoch": 4.183664,
      "grad_norm": 0.3349924087524414,
      "learning_rate": 2.4390243902439027e-06,
      "loss": 0.4744,
      "step": 122000
    },
    {
      "epoch": 4.187664,
      "grad_norm": 0.553372323513031,
      "learning_rate": 2.0325203252032523e-06,
      "loss": 0.4792,
      "step": 122500
    },
    {
      "epoch": 4.191664,
      "grad_norm": 0.4027407765388489,
      "learning_rate": 1.6260162601626018e-06,
      "loss": 0.4685,
      "step": 123000
    },
    {
      "epoch": 4.195664,
      "grad_norm": 0.5743288993835449,
      "learning_rate": 1.2195121951219514e-06,
      "loss": 0.4808,
      "step": 123500
    },
    {
      "epoch": 5.00158,
      "grad_norm": 0.4874162971973419,
      "learning_rate": 8.130081300813009e-07,
      "loss": 0.4703,
      "step": 124000
    },
    {
      "epoch": 5.00558,
      "grad_norm": 0.36212289333343506,
      "learning_rate": 4.0650406504065046e-07,
      "loss": 0.4706,
      "step": 124500
    }
  ],
  "logging_steps": 500,
  "max_steps": 125000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
