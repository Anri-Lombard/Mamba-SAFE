{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.99,
  "eval_steps": 500.0,
  "global_step": 49500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.9999998807907104,
      "learning_rate": 3e-07,
      "loss": 7.451,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9999995231628418,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 4.4594,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9999995827674866,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 1.3969,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.999999463558197,
      "learning_rate": 8.999999999999999e-05,
      "loss": 1.0951,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.999999463558197,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.9558,
      "step": 400
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9999991059303284,
      "learning_rate": 0.00015,
      "loss": 0.8738,
      "step": 500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.944880485534668,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.8106,
      "step": 600
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7252345681190491,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.7704,
      "step": 700
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8409436345100403,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.7449,
      "step": 800
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5759493112564087,
      "learning_rate": 0.00027,
      "loss": 0.7278,
      "step": 900
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6476426720619202,
      "learning_rate": 0.0003,
      "loss": 0.7134,
      "step": 1000
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6401355266571045,
      "learning_rate": 0.00033,
      "loss": 0.7024,
      "step": 1100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5393744111061096,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.6929,
      "step": 1200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.501778781414032,
      "learning_rate": 0.00039,
      "loss": 0.6846,
      "step": 1300
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4871653616428375,
      "learning_rate": 0.00041999999999999996,
      "loss": 0.6796,
      "step": 1400
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5430411100387573,
      "learning_rate": 0.00045,
      "loss": 0.6758,
      "step": 1500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4666881859302521,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.6686,
      "step": 1600
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4331216514110565,
      "learning_rate": 0.0005099999999999999,
      "loss": 0.6686,
      "step": 1700
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47517022490501404,
      "learning_rate": 0.00054,
      "loss": 0.6632,
      "step": 1800
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4521549642086029,
      "learning_rate": 0.00057,
      "loss": 0.6606,
      "step": 1900
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3462315797805786,
      "learning_rate": 0.0006,
      "loss": 0.66,
      "step": 2000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49406698346138,
      "learning_rate": 0.00059875,
      "loss": 0.6544,
      "step": 2100
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4051116704940796,
      "learning_rate": 0.0005974999999999999,
      "loss": 0.652,
      "step": 2200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3750220835208893,
      "learning_rate": 0.00059625,
      "loss": 0.6464,
      "step": 2300
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39987725019454956,
      "learning_rate": 0.0005949999999999999,
      "loss": 0.6432,
      "step": 2400
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3860606849193573,
      "learning_rate": 0.00059375,
      "loss": 0.6381,
      "step": 2500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38911813497543335,
      "learning_rate": 0.0005924999999999999,
      "loss": 0.6352,
      "step": 2600
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.34925439953804016,
      "learning_rate": 0.00059125,
      "loss": 0.633,
      "step": 2700
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36358755826950073,
      "learning_rate": 0.0005899999999999999,
      "loss": 0.6305,
      "step": 2800
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.37694281339645386,
      "learning_rate": 0.00058875,
      "loss": 0.6263,
      "step": 2900
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.33404773473739624,
      "learning_rate": 0.0005874999999999999,
      "loss": 0.6275,
      "step": 3000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39550256729125977,
      "learning_rate": 0.00058625,
      "loss": 0.6224,
      "step": 3100
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36549603939056396,
      "learning_rate": 0.0005849999999999999,
      "loss": 0.6239,
      "step": 3200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.33458393812179565,
      "learning_rate": 0.00058375,
      "loss": 0.6192,
      "step": 3300
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.32264676690101624,
      "learning_rate": 0.0005824999999999999,
      "loss": 0.6174,
      "step": 3400
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39387983083724976,
      "learning_rate": 0.00058125,
      "loss": 0.6191,
      "step": 3500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4240017831325531,
      "learning_rate": 0.00058,
      "loss": 0.6174,
      "step": 3600
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.319786012172699,
      "learning_rate": 0.00057875,
      "loss": 0.6136,
      "step": 3700
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3301392197608948,
      "learning_rate": 0.0005775,
      "loss": 0.6117,
      "step": 3800
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.29510697722435,
      "learning_rate": 0.0005762499999999999,
      "loss": 0.6109,
      "step": 3900
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.28051167726516724,
      "learning_rate": 0.000575,
      "loss": 0.6107,
      "step": 4000
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3252968192100525,
      "learning_rate": 0.0005737499999999999,
      "loss": 0.6086,
      "step": 4100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.31106096506118774,
      "learning_rate": 0.0005725,
      "loss": 0.6078,
      "step": 4200
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.25168517231941223,
      "learning_rate": 0.0005712499999999999,
      "loss": 0.6068,
      "step": 4300
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2729000747203827,
      "learning_rate": 0.00057,
      "loss": 0.6029,
      "step": 4400
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.26204004883766174,
      "learning_rate": 0.0005687499999999999,
      "loss": 0.5988,
      "step": 4500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3105420470237732,
      "learning_rate": 0.0005675,
      "loss": 0.6037,
      "step": 4600
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.284507691860199,
      "learning_rate": 0.0005662499999999999,
      "loss": 0.6018,
      "step": 4700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.36377277970314026,
      "learning_rate": 0.000565,
      "loss": 0.599,
      "step": 4800
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.22607842087745667,
      "learning_rate": 0.0005637499999999999,
      "loss": 0.5981,
      "step": 4900
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2699972987174988,
      "learning_rate": 0.0005625,
      "loss": 0.5991,
      "step": 5000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.24892255663871765,
      "learning_rate": 0.00056125,
      "loss": 0.5961,
      "step": 5100
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.24865937232971191,
      "learning_rate": 0.00056,
      "loss": 0.5938,
      "step": 5200
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25773414969444275,
      "learning_rate": 0.00055875,
      "loss": 0.5945,
      "step": 5300
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.31104034185409546,
      "learning_rate": 0.0005574999999999999,
      "loss": 0.598,
      "step": 5400
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2522292137145996,
      "learning_rate": 0.00055625,
      "loss": 0.5915,
      "step": 5500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24207007884979248,
      "learning_rate": 0.0005549999999999999,
      "loss": 0.5935,
      "step": 5600
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2524230480194092,
      "learning_rate": 0.00055375,
      "loss": 0.5923,
      "step": 5700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23828557133674622,
      "learning_rate": 0.0005524999999999999,
      "loss": 0.5924,
      "step": 5800
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22087866067886353,
      "learning_rate": 0.0005512499999999999,
      "loss": 0.5887,
      "step": 5900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2552672326564789,
      "learning_rate": 0.0005499999999999999,
      "loss": 0.5891,
      "step": 6000
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2204262912273407,
      "learning_rate": 0.00054875,
      "loss": 0.5909,
      "step": 6100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24714744091033936,
      "learning_rate": 0.0005474999999999999,
      "loss": 0.5897,
      "step": 6200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2517971396446228,
      "learning_rate": 0.00054625,
      "loss": 0.5859,
      "step": 6300
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.29646408557891846,
      "learning_rate": 0.0005449999999999999,
      "loss": 0.5875,
      "step": 6400
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3128494322299957,
      "learning_rate": 0.00054375,
      "loss": 0.586,
      "step": 6500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2801361382007599,
      "learning_rate": 0.0005424999999999999,
      "loss": 0.5839,
      "step": 6600
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.23784662783145905,
      "learning_rate": 0.00054125,
      "loss": 0.5827,
      "step": 6700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.223814457654953,
      "learning_rate": 0.00054,
      "loss": 0.5846,
      "step": 6800
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2402195781469345,
      "learning_rate": 0.00053875,
      "loss": 0.583,
      "step": 6900
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.23233471810817719,
      "learning_rate": 0.0005375,
      "loss": 0.5824,
      "step": 7000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.22844363749027252,
      "learning_rate": 0.0005362499999999999,
      "loss": 0.5839,
      "step": 7100
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.19332945346832275,
      "learning_rate": 0.000535,
      "loss": 0.579,
      "step": 7200
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2172909826040268,
      "learning_rate": 0.0005337499999999999,
      "loss": 0.5781,
      "step": 7300
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.24218806624412537,
      "learning_rate": 0.0005324999999999999,
      "loss": 0.5819,
      "step": 7400
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.25203678011894226,
      "learning_rate": 0.0005312499999999999,
      "loss": 0.5801,
      "step": 7500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2743436098098755,
      "learning_rate": 0.00053,
      "loss": 0.5813,
      "step": 7600
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22453708946704865,
      "learning_rate": 0.0005287499999999999,
      "loss": 0.5804,
      "step": 7700
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21776549518108368,
      "learning_rate": 0.0005275,
      "loss": 0.577,
      "step": 7800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2159332036972046,
      "learning_rate": 0.0005262499999999999,
      "loss": 0.5771,
      "step": 7900
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.20483136177062988,
      "learning_rate": 0.000525,
      "loss": 0.5749,
      "step": 8000
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21406053006649017,
      "learning_rate": 0.0005237499999999999,
      "loss": 0.5773,
      "step": 8100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.23178112506866455,
      "learning_rate": 0.0005225,
      "loss": 0.5752,
      "step": 8200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21566587686538696,
      "learning_rate": 0.00052125,
      "loss": 0.5767,
      "step": 8300
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.22922305762767792,
      "learning_rate": 0.00052,
      "loss": 0.5725,
      "step": 8400
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.20386329293251038,
      "learning_rate": 0.00051875,
      "loss": 0.5736,
      "step": 8500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.19678230583667755,
      "learning_rate": 0.0005175,
      "loss": 0.5726,
      "step": 8600
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21948277950286865,
      "learning_rate": 0.00051625,
      "loss": 0.5732,
      "step": 8700
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.18808956444263458,
      "learning_rate": 0.0005149999999999999,
      "loss": 0.5721,
      "step": 8800
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.20205630362033844,
      "learning_rate": 0.0005137499999999999,
      "loss": 0.5712,
      "step": 8900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.22878357768058777,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.5705,
      "step": 9000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.21454261243343353,
      "learning_rate": 0.00051125,
      "loss": 0.5713,
      "step": 9100
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.20583248138427734,
      "learning_rate": 0.0005099999999999999,
      "loss": 0.571,
      "step": 9200
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.19077996909618378,
      "learning_rate": 0.00050875,
      "loss": 0.5723,
      "step": 9300
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.18588317930698395,
      "learning_rate": 0.0005074999999999999,
      "loss": 0.5707,
      "step": 9400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.24080611765384674,
      "learning_rate": 0.00050625,
      "loss": 0.5715,
      "step": 9500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2295856475830078,
      "learning_rate": 0.0005049999999999999,
      "loss": 0.5718,
      "step": 9600
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.24248792231082916,
      "learning_rate": 0.00050375,
      "loss": 0.5678,
      "step": 9700
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.19444796442985535,
      "learning_rate": 0.0005025,
      "loss": 0.5698,
      "step": 9800
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1871981918811798,
      "learning_rate": 0.00050125,
      "loss": 0.5698,
      "step": 9900
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2564579248428345,
      "learning_rate": 0.0005,
      "loss": 0.5696,
      "step": 10000
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.18905489146709442,
      "learning_rate": 0.00049875,
      "loss": 0.5676,
      "step": 10100
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1857227236032486,
      "learning_rate": 0.0004975,
      "loss": 0.5689,
      "step": 10200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19794751703739166,
      "learning_rate": 0.00049625,
      "loss": 0.5662,
      "step": 10300
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19305507838726044,
      "learning_rate": 0.0004949999999999999,
      "loss": 0.5667,
      "step": 10400
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.18718332052230835,
      "learning_rate": 0.0004937499999999999,
      "loss": 0.5657,
      "step": 10500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.18754789233207703,
      "learning_rate": 0.0004925,
      "loss": 0.5663,
      "step": 10600
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.23998016119003296,
      "learning_rate": 0.0004912499999999999,
      "loss": 0.5647,
      "step": 10700
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19311833381652832,
      "learning_rate": 0.00049,
      "loss": 0.5661,
      "step": 10800
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1943899691104889,
      "learning_rate": 0.0004887499999999999,
      "loss": 0.5631,
      "step": 10900
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.2796873152256012,
      "learning_rate": 0.0004875,
      "loss": 0.5631,
      "step": 11000
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18441997468471527,
      "learning_rate": 0.00048625,
      "loss": 0.5627,
      "step": 11100
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.21591681241989136,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.5635,
      "step": 11200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.20325876772403717,
      "learning_rate": 0.00048374999999999997,
      "loss": 0.5627,
      "step": 11300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.18600350618362427,
      "learning_rate": 0.00048249999999999996,
      "loss": 0.5606,
      "step": 11400
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1884867399930954,
      "learning_rate": 0.00048124999999999996,
      "loss": 0.5607,
      "step": 11500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.18573595583438873,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.5611,
      "step": 11600
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.19285038113594055,
      "learning_rate": 0.00047875,
      "loss": 0.5603,
      "step": 11700
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2123555690050125,
      "learning_rate": 0.00047749999999999995,
      "loss": 0.5601,
      "step": 11800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18561139702796936,
      "learning_rate": 0.00047624999999999995,
      "loss": 0.5617,
      "step": 11900
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1920803338289261,
      "learning_rate": 0.00047499999999999994,
      "loss": 0.559,
      "step": 12000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1815309077501297,
      "learning_rate": 0.00047374999999999994,
      "loss": 0.5618,
      "step": 12100
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1752280294895172,
      "learning_rate": 0.00047249999999999994,
      "loss": 0.5584,
      "step": 12200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1931849718093872,
      "learning_rate": 0.00047124999999999993,
      "loss": 0.5584,
      "step": 12300
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.16413338482379913,
      "learning_rate": 0.00046999999999999993,
      "loss": 0.5597,
      "step": 12400
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18294057250022888,
      "learning_rate": 0.00046875,
      "loss": 0.5602,
      "step": 12500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.17461299896240234,
      "learning_rate": 0.0004675,
      "loss": 0.5584,
      "step": 12600
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.20427951216697693,
      "learning_rate": 0.00046625,
      "loss": 0.5605,
      "step": 12700
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1881406158208847,
      "learning_rate": 0.00046499999999999997,
      "loss": 0.5587,
      "step": 12800
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19809271395206451,
      "learning_rate": 0.00046374999999999997,
      "loss": 0.5581,
      "step": 12900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.16864658892154694,
      "learning_rate": 0.00046249999999999997,
      "loss": 0.5595,
      "step": 13000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.15384794771671295,
      "learning_rate": 0.00046124999999999996,
      "loss": 0.5562,
      "step": 13100
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.166550874710083,
      "learning_rate": 0.00046,
      "loss": 0.5549,
      "step": 13200
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17954711616039276,
      "learning_rate": 0.0004587499999999999,
      "loss": 0.5581,
      "step": 13300
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.16505369544029236,
      "learning_rate": 0.00045749999999999995,
      "loss": 0.5571,
      "step": 13400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.18198789656162262,
      "learning_rate": 0.00045624999999999995,
      "loss": 0.5578,
      "step": 13500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.15616898238658905,
      "learning_rate": 0.00045499999999999995,
      "loss": 0.5568,
      "step": 13600
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.15881438553333282,
      "learning_rate": 0.00045374999999999994,
      "loss": 0.5556,
      "step": 13700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16735965013504028,
      "learning_rate": 0.00045249999999999994,
      "loss": 0.5564,
      "step": 13800
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1885513961315155,
      "learning_rate": 0.00045124999999999994,
      "loss": 0.5557,
      "step": 13900
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1632748246192932,
      "learning_rate": 0.00045,
      "loss": 0.5542,
      "step": 14000
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.17035678029060364,
      "learning_rate": 0.00044875,
      "loss": 0.5523,
      "step": 14100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16509293019771576,
      "learning_rate": 0.0004475,
      "loss": 0.5548,
      "step": 14200
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.15573906898498535,
      "learning_rate": 0.00044625,
      "loss": 0.5551,
      "step": 14300
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2185675948858261,
      "learning_rate": 0.000445,
      "loss": 0.5529,
      "step": 14400
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.18576087057590485,
      "learning_rate": 0.00044374999999999997,
      "loss": 0.5525,
      "step": 14500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.16399231553077698,
      "learning_rate": 0.00044249999999999997,
      "loss": 0.5546,
      "step": 14600
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.16204482316970825,
      "learning_rate": 0.00044125,
      "loss": 0.5533,
      "step": 14700
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.18423151969909668,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.5528,
      "step": 14800
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1505601555109024,
      "learning_rate": 0.00043874999999999996,
      "loss": 0.5526,
      "step": 14900
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.17917229235172272,
      "learning_rate": 0.00043749999999999995,
      "loss": 0.5526,
      "step": 15000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19408151507377625,
      "learning_rate": 0.00043624999999999995,
      "loss": 0.553,
      "step": 15100
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1702834963798523,
      "learning_rate": 0.00043499999999999995,
      "loss": 0.5524,
      "step": 15200
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.16718852519989014,
      "learning_rate": 0.00043374999999999995,
      "loss": 0.5528,
      "step": 15300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17019544541835785,
      "learning_rate": 0.00043249999999999994,
      "loss": 0.5516,
      "step": 15400
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.15624377131462097,
      "learning_rate": 0.00043124999999999994,
      "loss": 0.5501,
      "step": 15500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.16995327174663544,
      "learning_rate": 0.00043,
      "loss": 0.551,
      "step": 15600
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.16945865750312805,
      "learning_rate": 0.00042875,
      "loss": 0.551,
      "step": 15700
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1776658594608307,
      "learning_rate": 0.0004275,
      "loss": 0.5494,
      "step": 15800
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.16152524948120117,
      "learning_rate": 0.00042625,
      "loss": 0.5519,
      "step": 15900
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1688661426305771,
      "learning_rate": 0.000425,
      "loss": 0.5501,
      "step": 16000
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.16908042132854462,
      "learning_rate": 0.00042375,
      "loss": 0.5495,
      "step": 16100
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1670452505350113,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.548,
      "step": 16200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17481431365013123,
      "learning_rate": 0.0004212499999999999,
      "loss": 0.5484,
      "step": 16300
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.19800406694412231,
      "learning_rate": 0.00041999999999999996,
      "loss": 0.5488,
      "step": 16400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18967153131961823,
      "learning_rate": 0.00041874999999999996,
      "loss": 0.5517,
      "step": 16500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.156248077750206,
      "learning_rate": 0.00041749999999999996,
      "loss": 0.5502,
      "step": 16600
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1511278748512268,
      "learning_rate": 0.00041624999999999995,
      "loss": 0.5475,
      "step": 16700
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1748475730419159,
      "learning_rate": 0.00041499999999999995,
      "loss": 0.548,
      "step": 16800
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.16953779757022858,
      "learning_rate": 0.00041374999999999995,
      "loss": 0.5496,
      "step": 16900
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1515938639640808,
      "learning_rate": 0.00041249999999999994,
      "loss": 0.5465,
      "step": 17000
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.16088128089904785,
      "learning_rate": 0.00041125,
      "loss": 0.5486,
      "step": 17100
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.190119206905365,
      "learning_rate": 0.00041,
      "loss": 0.547,
      "step": 17200
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16228002309799194,
      "learning_rate": 0.00040875,
      "loss": 0.5485,
      "step": 17300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.15293332934379578,
      "learning_rate": 0.0004075,
      "loss": 0.5466,
      "step": 17400
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.15503300726413727,
      "learning_rate": 0.00040625,
      "loss": 0.5456,
      "step": 17500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1977371722459793,
      "learning_rate": 0.000405,
      "loss": 0.5486,
      "step": 17600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1439007818698883,
      "learning_rate": 0.00040375,
      "loss": 0.5473,
      "step": 17700
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.15734879672527313,
      "learning_rate": 0.0004024999999999999,
      "loss": 0.5473,
      "step": 17800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17222441732883453,
      "learning_rate": 0.0004012499999999999,
      "loss": 0.5454,
      "step": 17900
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1528080552816391,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.545,
      "step": 18000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.15439632534980774,
      "learning_rate": 0.00039874999999999996,
      "loss": 0.5463,
      "step": 18100
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1602291762828827,
      "learning_rate": 0.00039749999999999996,
      "loss": 0.5454,
      "step": 18200
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14402155578136444,
      "learning_rate": 0.00039624999999999996,
      "loss": 0.5442,
      "step": 18300
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17328834533691406,
      "learning_rate": 0.00039499999999999995,
      "loss": 0.5434,
      "step": 18400
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.15245449542999268,
      "learning_rate": 0.00039374999999999995,
      "loss": 0.5456,
      "step": 18500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1623067706823349,
      "learning_rate": 0.00039249999999999995,
      "loss": 0.5447,
      "step": 18600
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.16209565103054047,
      "learning_rate": 0.00039125,
      "loss": 0.5431,
      "step": 18700
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15121349692344666,
      "learning_rate": 0.00039,
      "loss": 0.5431,
      "step": 18800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1470954418182373,
      "learning_rate": 0.00038875,
      "loss": 0.5448,
      "step": 18900
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15210406482219696,
      "learning_rate": 0.0003875,
      "loss": 0.5435,
      "step": 19000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1798943430185318,
      "learning_rate": 0.00038625,
      "loss": 0.5442,
      "step": 19100
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15674811601638794,
      "learning_rate": 0.000385,
      "loss": 0.5442,
      "step": 19200
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1490243524312973,
      "learning_rate": 0.0003837499999999999,
      "loss": 0.5441,
      "step": 19300
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.175029918551445,
      "learning_rate": 0.0003824999999999999,
      "loss": 0.5444,
      "step": 19400
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.146587535738945,
      "learning_rate": 0.00038124999999999997,
      "loss": 0.5435,
      "step": 19500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1467600017786026,
      "learning_rate": 0.00037999999999999997,
      "loss": 0.5415,
      "step": 19600
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16493815183639526,
      "learning_rate": 0.00037874999999999996,
      "loss": 0.5439,
      "step": 19700
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15178555250167847,
      "learning_rate": 0.00037749999999999996,
      "loss": 0.5423,
      "step": 19800
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15238381922245026,
      "learning_rate": 0.00037624999999999996,
      "loss": 0.5439,
      "step": 19900
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.16063229739665985,
      "learning_rate": 0.00037499999999999995,
      "loss": 0.5431,
      "step": 20000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15542738139629364,
      "learning_rate": 0.00037374999999999995,
      "loss": 0.541,
      "step": 20100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1452520787715912,
      "learning_rate": 0.0003725,
      "loss": 0.5417,
      "step": 20200
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16199235618114471,
      "learning_rate": 0.00037125,
      "loss": 0.5414,
      "step": 20300
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1664072871208191,
      "learning_rate": 0.00037,
      "loss": 0.5429,
      "step": 20400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.14299564063549042,
      "learning_rate": 0.00036875,
      "loss": 0.5415,
      "step": 20500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.17249339818954468,
      "learning_rate": 0.0003675,
      "loss": 0.5409,
      "step": 20600
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1522884964942932,
      "learning_rate": 0.00036625,
      "loss": 0.5429,
      "step": 20700
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16724079847335815,
      "learning_rate": 0.00036499999999999993,
      "loss": 0.5414,
      "step": 20800
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16622059047222137,
      "learning_rate": 0.0003637499999999999,
      "loss": 0.5397,
      "step": 20900
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1828378438949585,
      "learning_rate": 0.0003624999999999999,
      "loss": 0.539,
      "step": 21000
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.14987941086292267,
      "learning_rate": 0.00036124999999999997,
      "loss": 0.5386,
      "step": 21100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16019342839717865,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.54,
      "step": 21200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15107886493206024,
      "learning_rate": 0.00035874999999999997,
      "loss": 0.5403,
      "step": 21300
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16399383544921875,
      "learning_rate": 0.00035749999999999996,
      "loss": 0.5408,
      "step": 21400
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15594594180583954,
      "learning_rate": 0.00035624999999999996,
      "loss": 0.5389,
      "step": 21500
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15751278400421143,
      "learning_rate": 0.00035499999999999996,
      "loss": 0.5385,
      "step": 21600
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14612044394016266,
      "learning_rate": 0.00035374999999999995,
      "loss": 0.5384,
      "step": 21700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17120984196662903,
      "learning_rate": 0.0003525,
      "loss": 0.5406,
      "step": 21800
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14786751568317413,
      "learning_rate": 0.00035125,
      "loss": 0.5411,
      "step": 21900
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14514991641044617,
      "learning_rate": 0.00035,
      "loss": 0.5394,
      "step": 22000
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.15241239964962006,
      "learning_rate": 0.00034875,
      "loss": 0.539,
      "step": 22100
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16364076733589172,
      "learning_rate": 0.0003475,
      "loss": 0.5385,
      "step": 22200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.14141640067100525,
      "learning_rate": 0.00034624999999999993,
      "loss": 0.5379,
      "step": 22300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16879893839359283,
      "learning_rate": 0.00034499999999999993,
      "loss": 0.5394,
      "step": 22400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1469927281141281,
      "learning_rate": 0.0003437499999999999,
      "loss": 0.5384,
      "step": 22500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16057798266410828,
      "learning_rate": 0.0003425,
      "loss": 0.5365,
      "step": 22600
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1554989516735077,
      "learning_rate": 0.00034125,
      "loss": 0.5395,
      "step": 22700
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1456567645072937,
      "learning_rate": 0.00033999999999999997,
      "loss": 0.5379,
      "step": 22800
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1903681755065918,
      "learning_rate": 0.00033874999999999997,
      "loss": 0.5358,
      "step": 22900
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1680455505847931,
      "learning_rate": 0.00033749999999999996,
      "loss": 0.5375,
      "step": 23000
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.16498751938343048,
      "learning_rate": 0.00033624999999999996,
      "loss": 0.5377,
      "step": 23100
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.13933224976062775,
      "learning_rate": 0.00033499999999999996,
      "loss": 0.5373,
      "step": 23200
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1506299376487732,
      "learning_rate": 0.00033375,
      "loss": 0.5392,
      "step": 23300
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.14601962268352509,
      "learning_rate": 0.0003325,
      "loss": 0.5337,
      "step": 23400
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.15133243799209595,
      "learning_rate": 0.00033125,
      "loss": 0.5379,
      "step": 23500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.17723028361797333,
      "learning_rate": 0.00033,
      "loss": 0.5362,
      "step": 23600
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.15022480487823486,
      "learning_rate": 0.00032875,
      "loss": 0.5365,
      "step": 23700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15720027685165405,
      "learning_rate": 0.00032749999999999994,
      "loss": 0.5359,
      "step": 23800
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17050255835056305,
      "learning_rate": 0.00032624999999999993,
      "loss": 0.5354,
      "step": 23900
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.14660052955150604,
      "learning_rate": 0.00032499999999999993,
      "loss": 0.5367,
      "step": 24000
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15414243936538696,
      "learning_rate": 0.00032374999999999993,
      "loss": 0.5361,
      "step": 24100
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.16580361127853394,
      "learning_rate": 0.0003225,
      "loss": 0.533,
      "step": 24200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.14366832375526428,
      "learning_rate": 0.00032125,
      "loss": 0.5341,
      "step": 24300
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1609508991241455,
      "learning_rate": 0.00031999999999999997,
      "loss": 0.536,
      "step": 24400
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16949981451034546,
      "learning_rate": 0.00031874999999999997,
      "loss": 0.5346,
      "step": 24500
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15653109550476074,
      "learning_rate": 0.00031749999999999997,
      "loss": 0.5357,
      "step": 24600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16193756461143494,
      "learning_rate": 0.00031624999999999996,
      "loss": 0.5339,
      "step": 24700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15149050951004028,
      "learning_rate": 0.00031499999999999996,
      "loss": 0.5339,
      "step": 24800
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.14813381433486938,
      "learning_rate": 0.00031375,
      "loss": 0.533,
      "step": 24900
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16025304794311523,
      "learning_rate": 0.0003125,
      "loss": 0.5358,
      "step": 25000
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.18186596035957336,
      "learning_rate": 0.00031125,
      "loss": 0.5333,
      "step": 25100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.13722442090511322,
      "learning_rate": 0.00031,
      "loss": 0.5316,
      "step": 25200
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1359734833240509,
      "learning_rate": 0.00030874999999999994,
      "loss": 0.5338,
      "step": 25300
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1677868664264679,
      "learning_rate": 0.00030749999999999994,
      "loss": 0.5316,
      "step": 25400
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.16486197710037231,
      "learning_rate": 0.00030624999999999994,
      "loss": 0.5335,
      "step": 25500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.14088569581508636,
      "learning_rate": 0.00030499999999999993,
      "loss": 0.5332,
      "step": 25600
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.18923814594745636,
      "learning_rate": 0.00030375,
      "loss": 0.5334,
      "step": 25700
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17033688724040985,
      "learning_rate": 0.0003025,
      "loss": 0.5341,
      "step": 25800
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.15201686322689056,
      "learning_rate": 0.00030125,
      "loss": 0.5348,
      "step": 25900
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.15791083872318268,
      "learning_rate": 0.0003,
      "loss": 0.5312,
      "step": 26000
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.15243175625801086,
      "learning_rate": 0.00029874999999999997,
      "loss": 0.5336,
      "step": 26100
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17316706478595734,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.5341,
      "step": 26200
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.14726628363132477,
      "learning_rate": 0.00029624999999999996,
      "loss": 0.5302,
      "step": 26300
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1675747036933899,
      "learning_rate": 0.00029499999999999996,
      "loss": 0.5328,
      "step": 26400
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.15485771000385284,
      "learning_rate": 0.00029374999999999996,
      "loss": 0.5312,
      "step": 26500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.16853874921798706,
      "learning_rate": 0.00029249999999999995,
      "loss": 0.5308,
      "step": 26600
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.14651760458946228,
      "learning_rate": 0.00029124999999999995,
      "loss": 0.5317,
      "step": 26700
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1575239598751068,
      "learning_rate": 0.00029,
      "loss": 0.5343,
      "step": 26800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15424631536006927,
      "learning_rate": 0.00028875,
      "loss": 0.5314,
      "step": 26900
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15225327014923096,
      "learning_rate": 0.0002875,
      "loss": 0.5323,
      "step": 27000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13896963000297546,
      "learning_rate": 0.00028625,
      "loss": 0.5326,
      "step": 27100
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1621425449848175,
      "learning_rate": 0.000285,
      "loss": 0.5295,
      "step": 27200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.2168661653995514,
      "learning_rate": 0.00028375,
      "loss": 0.5306,
      "step": 27300
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1500488668680191,
      "learning_rate": 0.0002825,
      "loss": 0.5309,
      "step": 27400
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.163065105676651,
      "learning_rate": 0.00028125,
      "loss": 0.5318,
      "step": 27500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.15847660601139069,
      "learning_rate": 0.00028,
      "loss": 0.5301,
      "step": 27600
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.15464986860752106,
      "learning_rate": 0.00027874999999999997,
      "loss": 0.5307,
      "step": 27700
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15518774092197418,
      "learning_rate": 0.00027749999999999997,
      "loss": 0.5315,
      "step": 27800
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14600835740566254,
      "learning_rate": 0.00027624999999999997,
      "loss": 0.5304,
      "step": 27900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16546989977359772,
      "learning_rate": 0.00027499999999999996,
      "loss": 0.5297,
      "step": 28000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1488810032606125,
      "learning_rate": 0.00027374999999999996,
      "loss": 0.5291,
      "step": 28100
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1647113561630249,
      "learning_rate": 0.00027249999999999996,
      "loss": 0.5298,
      "step": 28200
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13284838199615479,
      "learning_rate": 0.00027124999999999995,
      "loss": 0.5285,
      "step": 28300
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16004709899425507,
      "learning_rate": 0.00027,
      "loss": 0.5317,
      "step": 28400
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.15536993741989136,
      "learning_rate": 0.00026875,
      "loss": 0.5296,
      "step": 28500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.18179485201835632,
      "learning_rate": 0.0002675,
      "loss": 0.5282,
      "step": 28600
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.18206174671649933,
      "learning_rate": 0.00026624999999999994,
      "loss": 0.5305,
      "step": 28700
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.17017678916454315,
      "learning_rate": 0.000265,
      "loss": 0.5276,
      "step": 28800
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14324280619621277,
      "learning_rate": 0.00026375,
      "loss": 0.5294,
      "step": 28900
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14390653371810913,
      "learning_rate": 0.0002625,
      "loss": 0.529,
      "step": 29000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.16126196086406708,
      "learning_rate": 0.00026125,
      "loss": 0.5285,
      "step": 29100
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1850145161151886,
      "learning_rate": 0.00026,
      "loss": 0.5286,
      "step": 29200
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15297181904315948,
      "learning_rate": 0.00025875,
      "loss": 0.5293,
      "step": 29300
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15742596983909607,
      "learning_rate": 0.00025749999999999997,
      "loss": 0.5249,
      "step": 29400
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17518433928489685,
      "learning_rate": 0.00025624999999999997,
      "loss": 0.5266,
      "step": 29500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.16605834662914276,
      "learning_rate": 0.00025499999999999996,
      "loss": 0.529,
      "step": 29600
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15528523921966553,
      "learning_rate": 0.00025374999999999996,
      "loss": 0.5289,
      "step": 29700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15358059108257294,
      "learning_rate": 0.00025249999999999996,
      "loss": 0.5264,
      "step": 29800
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15768015384674072,
      "learning_rate": 0.00025125,
      "loss": 0.529,
      "step": 29900
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.14986814558506012,
      "learning_rate": 0.00025,
      "loss": 0.5274,
      "step": 30000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15020786225795746,
      "learning_rate": 0.00024875,
      "loss": 0.5278,
      "step": 30100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16732865571975708,
      "learning_rate": 0.00024749999999999994,
      "loss": 0.5249,
      "step": 30200
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.16136816143989563,
      "learning_rate": 0.00024625,
      "loss": 0.5273,
      "step": 30300
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1607580929994583,
      "learning_rate": 0.000245,
      "loss": 0.5275,
      "step": 30400
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15931309759616852,
      "learning_rate": 0.00024375,
      "loss": 0.5273,
      "step": 30500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.14732642471790314,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.5276,
      "step": 30600
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15486422181129456,
      "learning_rate": 0.00024124999999999998,
      "loss": 0.5273,
      "step": 30700
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15523824095726013,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.5263,
      "step": 30800
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16162757575511932,
      "learning_rate": 0.00023874999999999998,
      "loss": 0.5252,
      "step": 30900
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.18206702172756195,
      "learning_rate": 0.00023749999999999997,
      "loss": 0.5287,
      "step": 31000
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1710791438817978,
      "learning_rate": 0.00023624999999999997,
      "loss": 0.5225,
      "step": 31100
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15263758599758148,
      "learning_rate": 0.00023499999999999997,
      "loss": 0.5247,
      "step": 31200
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14994065463542938,
      "learning_rate": 0.00023375,
      "loss": 0.526,
      "step": 31300
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15897518396377563,
      "learning_rate": 0.00023249999999999999,
      "loss": 0.5263,
      "step": 31400
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.163519024848938,
      "learning_rate": 0.00023124999999999998,
      "loss": 0.5275,
      "step": 31500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1547478884458542,
      "learning_rate": 0.00023,
      "loss": 0.5269,
      "step": 31600
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17545200884342194,
      "learning_rate": 0.00022874999999999998,
      "loss": 0.5242,
      "step": 31700
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1714669167995453,
      "learning_rate": 0.00022749999999999997,
      "loss": 0.5242,
      "step": 31800
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15404456853866577,
      "learning_rate": 0.00022624999999999997,
      "loss": 0.5248,
      "step": 31900
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15391111373901367,
      "learning_rate": 0.000225,
      "loss": 0.5235,
      "step": 32000
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1554870754480362,
      "learning_rate": 0.00022375,
      "loss": 0.5235,
      "step": 32100
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17829567193984985,
      "learning_rate": 0.0002225,
      "loss": 0.524,
      "step": 32200
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.168076753616333,
      "learning_rate": 0.00022124999999999998,
      "loss": 0.5241,
      "step": 32300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18573413789272308,
      "learning_rate": 0.00021999999999999995,
      "loss": 0.5238,
      "step": 32400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1522878110408783,
      "learning_rate": 0.00021874999999999998,
      "loss": 0.5233,
      "step": 32500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.15385495126247406,
      "learning_rate": 0.00021749999999999997,
      "loss": 0.5246,
      "step": 32600
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16448937356472015,
      "learning_rate": 0.00021624999999999997,
      "loss": 0.5243,
      "step": 32700
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15862078964710236,
      "learning_rate": 0.000215,
      "loss": 0.5234,
      "step": 32800
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1755508929491043,
      "learning_rate": 0.00021375,
      "loss": 0.5231,
      "step": 32900
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.19216524064540863,
      "learning_rate": 0.0002125,
      "loss": 0.523,
      "step": 33000
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16500288248062134,
      "learning_rate": 0.00021124999999999998,
      "loss": 0.5232,
      "step": 33100
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1717834770679474,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5216,
      "step": 33200
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1625923216342926,
      "learning_rate": 0.00020874999999999998,
      "loss": 0.5209,
      "step": 33300
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16131286323070526,
      "learning_rate": 0.00020749999999999998,
      "loss": 0.5235,
      "step": 33400
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1513754427433014,
      "learning_rate": 0.00020624999999999997,
      "loss": 0.5199,
      "step": 33500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16311879456043243,
      "learning_rate": 0.000205,
      "loss": 0.5246,
      "step": 33600
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.18021179735660553,
      "learning_rate": 0.00020375,
      "loss": 0.5222,
      "step": 33700
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15681709349155426,
      "learning_rate": 0.0002025,
      "loss": 0.5218,
      "step": 33800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1613706350326538,
      "learning_rate": 0.00020124999999999996,
      "loss": 0.5219,
      "step": 33900
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14752410352230072,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.521,
      "step": 34000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15464887022972107,
      "learning_rate": 0.00019874999999999998,
      "loss": 0.5229,
      "step": 34100
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15392912924289703,
      "learning_rate": 0.00019749999999999998,
      "loss": 0.5211,
      "step": 34200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15432138741016388,
      "learning_rate": 0.00019624999999999997,
      "loss": 0.521,
      "step": 34300
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.17568251490592957,
      "learning_rate": 0.000195,
      "loss": 0.5228,
      "step": 34400
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.16914387047290802,
      "learning_rate": 0.00019375,
      "loss": 0.523,
      "step": 34500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.17745520174503326,
      "learning_rate": 0.0001925,
      "loss": 0.5216,
      "step": 34600
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.16576708853244781,
      "learning_rate": 0.00019124999999999996,
      "loss": 0.5219,
      "step": 34700
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.17924365401268005,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.5203,
      "step": 34800
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1594392955303192,
      "learning_rate": 0.00018874999999999998,
      "loss": 0.5219,
      "step": 34900
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.15490137040615082,
      "learning_rate": 0.00018749999999999998,
      "loss": 0.5207,
      "step": 35000
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.17458437383174896,
      "learning_rate": 0.00018625,
      "loss": 0.5202,
      "step": 35100
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.17780879139900208,
      "learning_rate": 0.000185,
      "loss": 0.5209,
      "step": 35200
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16082756221294403,
      "learning_rate": 0.00018375,
      "loss": 0.5202,
      "step": 35300
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16356560587882996,
      "learning_rate": 0.00018249999999999996,
      "loss": 0.5214,
      "step": 35400
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1601230651140213,
      "learning_rate": 0.00018124999999999996,
      "loss": 0.5216,
      "step": 35500
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16868752241134644,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.5203,
      "step": 35600
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.19214944541454315,
      "learning_rate": 0.00017874999999999998,
      "loss": 0.5212,
      "step": 35700
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.15806841850280762,
      "learning_rate": 0.00017749999999999998,
      "loss": 0.5191,
      "step": 35800
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1854977160692215,
      "learning_rate": 0.00017625,
      "loss": 0.5202,
      "step": 35900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.15769913792610168,
      "learning_rate": 0.000175,
      "loss": 0.5199,
      "step": 36000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.15295270085334778,
      "learning_rate": 0.00017375,
      "loss": 0.5199,
      "step": 36100
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.16245388984680176,
      "learning_rate": 0.00017249999999999996,
      "loss": 0.519,
      "step": 36200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.15921738743782043,
      "learning_rate": 0.00017125,
      "loss": 0.5184,
      "step": 36300
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.17303989827632904,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.52,
      "step": 36400
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.16443324089050293,
      "learning_rate": 0.00016874999999999998,
      "loss": 0.5212,
      "step": 36500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.15696270763874054,
      "learning_rate": 0.00016749999999999998,
      "loss": 0.5183,
      "step": 36600
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.18721328675746918,
      "learning_rate": 0.00016625,
      "loss": 0.5183,
      "step": 36700
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.16880229115486145,
      "learning_rate": 0.000165,
      "loss": 0.5204,
      "step": 36800
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.16261030733585358,
      "learning_rate": 0.00016374999999999997,
      "loss": 0.5213,
      "step": 36900
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1679053157567978,
      "learning_rate": 0.00016249999999999997,
      "loss": 0.5199,
      "step": 37000
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.15949437022209167,
      "learning_rate": 0.00016125,
      "loss": 0.5202,
      "step": 37100
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.16579760611057281,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.5179,
      "step": 37200
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.17971408367156982,
      "learning_rate": 0.00015874999999999998,
      "loss": 0.5166,
      "step": 37300
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.17668351531028748,
      "learning_rate": 0.00015749999999999998,
      "loss": 0.5182,
      "step": 37400
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.17302405834197998,
      "learning_rate": 0.00015625,
      "loss": 0.5166,
      "step": 37500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1536431759595871,
      "learning_rate": 0.000155,
      "loss": 0.516,
      "step": 37600
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1544598489999771,
      "learning_rate": 0.00015374999999999997,
      "loss": 0.5161,
      "step": 37700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.16968460381031036,
      "learning_rate": 0.00015249999999999997,
      "loss": 0.5181,
      "step": 37800
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18007872998714447,
      "learning_rate": 0.00015125,
      "loss": 0.5165,
      "step": 37900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1528742015361786,
      "learning_rate": 0.00015,
      "loss": 0.5176,
      "step": 38000
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18342019617557526,
      "learning_rate": 0.00014874999999999998,
      "loss": 0.5173,
      "step": 38100
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.20049630105495453,
      "learning_rate": 0.00014749999999999998,
      "loss": 0.5149,
      "step": 38200
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.15819098055362701,
      "learning_rate": 0.00014624999999999998,
      "loss": 0.5174,
      "step": 38300
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.16242215037345886,
      "learning_rate": 0.000145,
      "loss": 0.5173,
      "step": 38400
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.17514102160930634,
      "learning_rate": 0.00014375,
      "loss": 0.5176,
      "step": 38500
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.16802850365638733,
      "learning_rate": 0.0001425,
      "loss": 0.5162,
      "step": 38600
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.17525385320186615,
      "learning_rate": 0.00014125,
      "loss": 0.5165,
      "step": 38700
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16828691959381104,
      "learning_rate": 0.00014,
      "loss": 0.5161,
      "step": 38800
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16544175148010254,
      "learning_rate": 0.00013874999999999998,
      "loss": 0.5154,
      "step": 38900
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.15206113457679749,
      "learning_rate": 0.00013749999999999998,
      "loss": 0.5147,
      "step": 39000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16198036074638367,
      "learning_rate": 0.00013624999999999998,
      "loss": 0.5137,
      "step": 39100
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1851789355278015,
      "learning_rate": 0.000135,
      "loss": 0.5149,
      "step": 39200
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.17270946502685547,
      "learning_rate": 0.00013375,
      "loss": 0.5153,
      "step": 39300
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.17073965072631836,
      "learning_rate": 0.0001325,
      "loss": 0.5145,
      "step": 39400
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.17686444520950317,
      "learning_rate": 0.00013125,
      "loss": 0.5147,
      "step": 39500
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1663798838853836,
      "learning_rate": 0.00013,
      "loss": 0.5152,
      "step": 39600
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.17190790176391602,
      "learning_rate": 0.00012874999999999999,
      "loss": 0.5152,
      "step": 39700
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.15507611632347107,
      "learning_rate": 0.00012749999999999998,
      "loss": 0.5132,
      "step": 39800
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1666446179151535,
      "learning_rate": 0.00012624999999999998,
      "loss": 0.5152,
      "step": 39900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.19541841745376587,
      "learning_rate": 0.000125,
      "loss": 0.5133,
      "step": 40000
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1621585339307785,
      "learning_rate": 0.00012374999999999997,
      "loss": 0.514,
      "step": 40100
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.19500689208507538,
      "learning_rate": 0.0001225,
      "loss": 0.5163,
      "step": 40200
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.16739694774150848,
      "learning_rate": 0.00012124999999999999,
      "loss": 0.5121,
      "step": 40300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.16303448379039764,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.5135,
      "step": 40400
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1825377345085144,
      "learning_rate": 0.00011874999999999999,
      "loss": 0.5133,
      "step": 40500
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2034584879875183,
      "learning_rate": 0.00011749999999999998,
      "loss": 0.515,
      "step": 40600
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.16410064697265625,
      "learning_rate": 0.00011624999999999999,
      "loss": 0.5133,
      "step": 40700
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.16403937339782715,
      "learning_rate": 0.000115,
      "loss": 0.5148,
      "step": 40800
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.17285895347595215,
      "learning_rate": 0.00011374999999999999,
      "loss": 0.5137,
      "step": 40900
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.16079260408878326,
      "learning_rate": 0.0001125,
      "loss": 0.5125,
      "step": 41000
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.16820545494556427,
      "learning_rate": 0.00011125,
      "loss": 0.512,
      "step": 41100
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.17475667595863342,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.5153,
      "step": 41200
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.17901089787483215,
      "learning_rate": 0.00010874999999999999,
      "loss": 0.5124,
      "step": 41300
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.16450150310993195,
      "learning_rate": 0.0001075,
      "loss": 0.5132,
      "step": 41400
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1751900017261505,
      "learning_rate": 0.00010625,
      "loss": 0.5123,
      "step": 41500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.17301473021507263,
      "learning_rate": 0.00010499999999999999,
      "loss": 0.5125,
      "step": 41600
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.15906408429145813,
      "learning_rate": 0.00010374999999999999,
      "loss": 0.5137,
      "step": 41700
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.18830907344818115,
      "learning_rate": 0.0001025,
      "loss": 0.5126,
      "step": 41800
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.161417156457901,
      "learning_rate": 0.00010125,
      "loss": 0.5132,
      "step": 41900
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.16967442631721497,
      "learning_rate": 9.999999999999999e-05,
      "loss": 0.5132,
      "step": 42000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.16397421061992645,
      "learning_rate": 9.874999999999999e-05,
      "loss": 0.5135,
      "step": 42100
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.18015934526920319,
      "learning_rate": 9.75e-05,
      "loss": 0.5123,
      "step": 42200
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17876079678535461,
      "learning_rate": 9.625e-05,
      "loss": 0.5116,
      "step": 42300
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17068348824977875,
      "learning_rate": 9.499999999999999e-05,
      "loss": 0.5126,
      "step": 42400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17711490392684937,
      "learning_rate": 9.374999999999999e-05,
      "loss": 0.5112,
      "step": 42500
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.183384969830513,
      "learning_rate": 9.25e-05,
      "loss": 0.5105,
      "step": 42600
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.18452566862106323,
      "learning_rate": 9.124999999999998e-05,
      "loss": 0.5099,
      "step": 42700
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1599094122648239,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.5115,
      "step": 42800
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1847347617149353,
      "learning_rate": 8.874999999999999e-05,
      "loss": 0.5102,
      "step": 42900
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.16655555367469788,
      "learning_rate": 8.75e-05,
      "loss": 0.5112,
      "step": 43000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.16660632193088531,
      "learning_rate": 8.624999999999998e-05,
      "loss": 0.5107,
      "step": 43100
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.18105442821979523,
      "learning_rate": 8.499999999999999e-05,
      "loss": 0.5102,
      "step": 43200
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.19437295198440552,
      "learning_rate": 8.374999999999999e-05,
      "loss": 0.5108,
      "step": 43300
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.19182491302490234,
      "learning_rate": 8.25e-05,
      "loss": 0.51,
      "step": 43400
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.17677506804466248,
      "learning_rate": 8.124999999999998e-05,
      "loss": 0.5114,
      "step": 43500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.17105181515216827,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.509,
      "step": 43600
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.18965066969394684,
      "learning_rate": 7.874999999999999e-05,
      "loss": 0.5088,
      "step": 43700
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1610604226589203,
      "learning_rate": 7.75e-05,
      "loss": 0.5085,
      "step": 43800
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.17757047712802887,
      "learning_rate": 7.624999999999998e-05,
      "loss": 0.5119,
      "step": 43900
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1753089278936386,
      "learning_rate": 7.5e-05,
      "loss": 0.5079,
      "step": 44000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.17266987264156342,
      "learning_rate": 7.374999999999999e-05,
      "loss": 0.5104,
      "step": 44100
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.160091832280159,
      "learning_rate": 7.25e-05,
      "loss": 0.51,
      "step": 44200
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1743633896112442,
      "learning_rate": 7.125e-05,
      "loss": 0.5098,
      "step": 44300
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1823396235704422,
      "learning_rate": 7e-05,
      "loss": 0.5098,
      "step": 44400
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.17844301462173462,
      "learning_rate": 6.874999999999999e-05,
      "loss": 0.5094,
      "step": 44500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1818496137857437,
      "learning_rate": 6.75e-05,
      "loss": 0.5101,
      "step": 44600
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.17278851568698883,
      "learning_rate": 6.625e-05,
      "loss": 0.5077,
      "step": 44700
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.186203271150589,
      "learning_rate": 6.5e-05,
      "loss": 0.5069,
      "step": 44800
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.16905340552330017,
      "learning_rate": 6.374999999999999e-05,
      "loss": 0.5077,
      "step": 44900
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.18311643600463867,
      "learning_rate": 6.25e-05,
      "loss": 0.5092,
      "step": 45000
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1831393837928772,
      "learning_rate": 6.125e-05,
      "loss": 0.5065,
      "step": 45100
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.17063063383102417,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 0.5094,
      "step": 45200
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1907946765422821,
      "learning_rate": 5.874999999999999e-05,
      "loss": 0.5078,
      "step": 45300
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.17695395648479462,
      "learning_rate": 5.75e-05,
      "loss": 0.506,
      "step": 45400
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.18845000863075256,
      "learning_rate": 5.625e-05,
      "loss": 0.5065,
      "step": 45500
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.2059989720582962,
      "learning_rate": 5.499999999999999e-05,
      "loss": 0.5062,
      "step": 45600
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1717715561389923,
      "learning_rate": 5.375e-05,
      "loss": 0.5093,
      "step": 45700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.18531939387321472,
      "learning_rate": 5.2499999999999995e-05,
      "loss": 0.5053,
      "step": 45800
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.18172304332256317,
      "learning_rate": 5.125e-05,
      "loss": 0.5078,
      "step": 45900
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.18104815483093262,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.5066,
      "step": 46000
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.18160586059093475,
      "learning_rate": 4.875e-05,
      "loss": 0.5065,
      "step": 46100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17891794443130493,
      "learning_rate": 4.7499999999999996e-05,
      "loss": 0.507,
      "step": 46200
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.18890051543712616,
      "learning_rate": 4.625e-05,
      "loss": 0.5066,
      "step": 46300
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.16332636773586273,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.5086,
      "step": 46400
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1688103973865509,
      "learning_rate": 4.375e-05,
      "loss": 0.5064,
      "step": 46500
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.17328843474388123,
      "learning_rate": 4.2499999999999996e-05,
      "loss": 0.5051,
      "step": 46600
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.16850124299526215,
      "learning_rate": 4.125e-05,
      "loss": 0.5064,
      "step": 46700
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18208669126033783,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.5074,
      "step": 46800
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18101143836975098,
      "learning_rate": 3.875e-05,
      "loss": 0.5072,
      "step": 46900
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.16427041590213776,
      "learning_rate": 3.75e-05,
      "loss": 0.5035,
      "step": 47000
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.19300521910190582,
      "learning_rate": 3.625e-05,
      "loss": 0.5042,
      "step": 47100
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.19079384207725525,
      "learning_rate": 3.5e-05,
      "loss": 0.5062,
      "step": 47200
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1716838777065277,
      "learning_rate": 3.375e-05,
      "loss": 0.5057,
      "step": 47300
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.16764222085475922,
      "learning_rate": 3.25e-05,
      "loss": 0.5069,
      "step": 47400
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.18893620371818542,
      "learning_rate": 3.125e-05,
      "loss": 0.5053,
      "step": 47500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1831495761871338,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.5055,
      "step": 47600
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.16272175312042236,
      "learning_rate": 2.875e-05,
      "loss": 0.5052,
      "step": 47700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2060438096523285,
      "learning_rate": 2.7499999999999994e-05,
      "loss": 0.5053,
      "step": 47800
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1719157099723816,
      "learning_rate": 2.6249999999999998e-05,
      "loss": 0.5035,
      "step": 47900
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.17218348383903503,
      "learning_rate": 2.4999999999999998e-05,
      "loss": 0.505,
      "step": 48000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.20351117849349976,
      "learning_rate": 2.3749999999999998e-05,
      "loss": 0.5045,
      "step": 48100
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.16786159574985504,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.5051,
      "step": 48200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.17108260095119476,
      "learning_rate": 2.1249999999999998e-05,
      "loss": 0.5037,
      "step": 48300
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.17025677859783173,
      "learning_rate": 1.9999999999999998e-05,
      "loss": 0.5064,
      "step": 48400
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1795332133769989,
      "learning_rate": 1.875e-05,
      "loss": 0.505,
      "step": 48500
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.18071283400058746,
      "learning_rate": 1.75e-05,
      "loss": 0.5058,
      "step": 48600
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.17186017334461212,
      "learning_rate": 1.625e-05,
      "loss": 0.5041,
      "step": 48700
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.188351109623909,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 0.505,
      "step": 48800
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.20082758367061615,
      "learning_rate": 1.3749999999999997e-05,
      "loss": 0.5037,
      "step": 48900
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.18418361246585846,
      "learning_rate": 1.2499999999999999e-05,
      "loss": 0.5045,
      "step": 49000
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.17665986716747284,
      "learning_rate": 1.1249999999999999e-05,
      "loss": 0.502,
      "step": 49100
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.186859592795372,
      "learning_rate": 9.999999999999999e-06,
      "loss": 0.5025,
      "step": 49200
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1845160722732544,
      "learning_rate": 8.75e-06,
      "loss": 0.5047,
      "step": 49300
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.18239672482013702,
      "learning_rate": 7.499999999999999e-06,
      "loss": 0.5044,
      "step": 49400
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.17136500775814056,
      "learning_rate": 6.2499999999999995e-06,
      "loss": 0.5043,
      "step": 49500
    }
  ],
  "logging_steps": 100,
  "max_steps": 50000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
