{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.98,
  "eval_steps": 500.0,
  "global_step": 49000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.9999999403953552,
      "learning_rate": 3e-07,
      "loss": 7.7149,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9999996423721313,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 3.0902,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.9999996423721313,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 1.1482,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9999994039535522,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.9389,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9999994039535522,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.8393,
      "step": 400
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9999991655349731,
      "learning_rate": 0.00015,
      "loss": 0.7901,
      "step": 500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9183399081230164,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.7529,
      "step": 600
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6646637320518494,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.7273,
      "step": 700
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6734290719032288,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.7123,
      "step": 800
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5929961800575256,
      "learning_rate": 0.00027,
      "loss": 0.7019,
      "step": 900
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5651207566261292,
      "learning_rate": 0.0003,
      "loss": 0.692,
      "step": 1000
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.542600691318512,
      "learning_rate": 0.00033,
      "loss": 0.6839,
      "step": 1100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5634654760360718,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.6768,
      "step": 1200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48897749185562134,
      "learning_rate": 0.00039,
      "loss": 0.6713,
      "step": 1300
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5086365938186646,
      "learning_rate": 0.00041999999999999996,
      "loss": 0.6671,
      "step": 1400
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5039659142494202,
      "learning_rate": 0.00045,
      "loss": 0.6655,
      "step": 1500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4387805759906769,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.6576,
      "step": 1600
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4710763990879059,
      "learning_rate": 0.0005099999999999999,
      "loss": 0.6579,
      "step": 1700
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42323869466781616,
      "learning_rate": 0.00054,
      "loss": 0.6536,
      "step": 1800
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44468727707862854,
      "learning_rate": 0.00057,
      "loss": 0.6523,
      "step": 1900
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3483792543411255,
      "learning_rate": 0.0006,
      "loss": 0.6509,
      "step": 2000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.43379345536231995,
      "learning_rate": 0.00059875,
      "loss": 0.6453,
      "step": 2100
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.39522111415863037,
      "learning_rate": 0.0005974999999999999,
      "loss": 0.6447,
      "step": 2200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35172730684280396,
      "learning_rate": 0.00059625,
      "loss": 0.6389,
      "step": 2300
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37912803888320923,
      "learning_rate": 0.0005949999999999999,
      "loss": 0.6361,
      "step": 2400
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37069132924079895,
      "learning_rate": 0.00059375,
      "loss": 0.6307,
      "step": 2500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3595714569091797,
      "learning_rate": 0.0005924999999999999,
      "loss": 0.6268,
      "step": 2600
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.370639443397522,
      "learning_rate": 0.00059125,
      "loss": 0.6251,
      "step": 2700
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3681213855743408,
      "learning_rate": 0.0005899999999999999,
      "loss": 0.6241,
      "step": 2800
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3277145326137543,
      "learning_rate": 0.00058875,
      "loss": 0.6199,
      "step": 2900
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3038904070854187,
      "learning_rate": 0.0005874999999999999,
      "loss": 0.62,
      "step": 3000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3177693784236908,
      "learning_rate": 0.00058625,
      "loss": 0.6146,
      "step": 3100
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.30000269412994385,
      "learning_rate": 0.0005849999999999999,
      "loss": 0.6172,
      "step": 3200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3148914873600006,
      "learning_rate": 0.00058375,
      "loss": 0.6132,
      "step": 3300
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.30167433619499207,
      "learning_rate": 0.0005824999999999999,
      "loss": 0.6095,
      "step": 3400
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.32276061177253723,
      "learning_rate": 0.00058125,
      "loss": 0.6116,
      "step": 3500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.34856829047203064,
      "learning_rate": 0.00058,
      "loss": 0.6103,
      "step": 3600
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2808755934238434,
      "learning_rate": 0.00057875,
      "loss": 0.6063,
      "step": 3700
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.33793148398399353,
      "learning_rate": 0.0005775,
      "loss": 0.6052,
      "step": 3800
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2883327305316925,
      "learning_rate": 0.0005762499999999999,
      "loss": 0.6029,
      "step": 3900
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.27774500846862793,
      "learning_rate": 0.000575,
      "loss": 0.6035,
      "step": 4000
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.29443806409835815,
      "learning_rate": 0.0005737499999999999,
      "loss": 0.6015,
      "step": 4100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2808004319667816,
      "learning_rate": 0.0005725,
      "loss": 0.6006,
      "step": 4200
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.23015837371349335,
      "learning_rate": 0.0005712499999999999,
      "loss": 0.5999,
      "step": 4300
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.27180224657058716,
      "learning_rate": 0.00057,
      "loss": 0.5961,
      "step": 4400
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.26053711771965027,
      "learning_rate": 0.0005687499999999999,
      "loss": 0.5929,
      "step": 4500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3055889904499054,
      "learning_rate": 0.0005675,
      "loss": 0.5977,
      "step": 4600
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.24635209143161774,
      "learning_rate": 0.0005662499999999999,
      "loss": 0.5947,
      "step": 4700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3759849965572357,
      "learning_rate": 0.000565,
      "loss": 0.5926,
      "step": 4800
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2211908996105194,
      "learning_rate": 0.0005637499999999999,
      "loss": 0.5926,
      "step": 4900
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2664828598499298,
      "learning_rate": 0.0005625,
      "loss": 0.5923,
      "step": 5000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.24056468904018402,
      "learning_rate": 0.00056125,
      "loss": 0.5901,
      "step": 5100
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.23485210537910461,
      "learning_rate": 0.00056,
      "loss": 0.5881,
      "step": 5200
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24315550923347473,
      "learning_rate": 0.00055875,
      "loss": 0.5883,
      "step": 5300
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.31420013308525085,
      "learning_rate": 0.0005574999999999999,
      "loss": 0.5922,
      "step": 5400
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2617959678173065,
      "learning_rate": 0.00055625,
      "loss": 0.5854,
      "step": 5500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22027809917926788,
      "learning_rate": 0.0005549999999999999,
      "loss": 0.587,
      "step": 5600
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25091877579689026,
      "learning_rate": 0.00055375,
      "loss": 0.5856,
      "step": 5700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2161446213722229,
      "learning_rate": 0.0005524999999999999,
      "loss": 0.5866,
      "step": 5800
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2191164642572403,
      "learning_rate": 0.0005512499999999999,
      "loss": 0.5837,
      "step": 5900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2205417901277542,
      "learning_rate": 0.0005499999999999999,
      "loss": 0.5828,
      "step": 6000
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.20763954520225525,
      "learning_rate": 0.00054875,
      "loss": 0.5847,
      "step": 6100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.21962742507457733,
      "learning_rate": 0.0005474999999999999,
      "loss": 0.5835,
      "step": 6200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26277825236320496,
      "learning_rate": 0.00054625,
      "loss": 0.5803,
      "step": 6300
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.280793696641922,
      "learning_rate": 0.0005449999999999999,
      "loss": 0.5813,
      "step": 6400
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26185858249664307,
      "learning_rate": 0.00054375,
      "loss": 0.5791,
      "step": 6500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2785000801086426,
      "learning_rate": 0.0005424999999999999,
      "loss": 0.5775,
      "step": 6600
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.23235781490802765,
      "learning_rate": 0.00054125,
      "loss": 0.5768,
      "step": 6700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.20405417680740356,
      "learning_rate": 0.00054,
      "loss": 0.5778,
      "step": 6800
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.21742026507854462,
      "learning_rate": 0.00053875,
      "loss": 0.5767,
      "step": 6900
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.24286238849163055,
      "learning_rate": 0.0005375,
      "loss": 0.576,
      "step": 7000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.20514430105686188,
      "learning_rate": 0.0005362499999999999,
      "loss": 0.5783,
      "step": 7100
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.19047856330871582,
      "learning_rate": 0.000535,
      "loss": 0.5737,
      "step": 7200
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1980115920305252,
      "learning_rate": 0.0005337499999999999,
      "loss": 0.5722,
      "step": 7300
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2539622187614441,
      "learning_rate": 0.0005324999999999999,
      "loss": 0.5748,
      "step": 7400
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22852317988872528,
      "learning_rate": 0.0005312499999999999,
      "loss": 0.573,
      "step": 7500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.24362368881702423,
      "learning_rate": 0.00053,
      "loss": 0.5752,
      "step": 7600
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20829059183597565,
      "learning_rate": 0.0005287499999999999,
      "loss": 0.574,
      "step": 7700
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.1861027032136917,
      "learning_rate": 0.0005275,
      "loss": 0.5704,
      "step": 7800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2078886181116104,
      "learning_rate": 0.0005262499999999999,
      "loss": 0.571,
      "step": 7900
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21009063720703125,
      "learning_rate": 0.000525,
      "loss": 0.5699,
      "step": 8000
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.1969696581363678,
      "learning_rate": 0.0005237499999999999,
      "loss": 0.5715,
      "step": 8100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21890029311180115,
      "learning_rate": 0.0005225,
      "loss": 0.5689,
      "step": 8200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1943117082118988,
      "learning_rate": 0.00052125,
      "loss": 0.5705,
      "step": 8300
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2014453411102295,
      "learning_rate": 0.00052,
      "loss": 0.5674,
      "step": 8400
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.19114628434181213,
      "learning_rate": 0.00051875,
      "loss": 0.5688,
      "step": 8500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.19006799161434174,
      "learning_rate": 0.0005175,
      "loss": 0.566,
      "step": 8600
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1965414434671402,
      "learning_rate": 0.00051625,
      "loss": 0.5674,
      "step": 8700
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.17427098751068115,
      "learning_rate": 0.0005149999999999999,
      "loss": 0.5665,
      "step": 8800
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.18092291057109833,
      "learning_rate": 0.0005137499999999999,
      "loss": 0.5656,
      "step": 8900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.21481384336948395,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.5642,
      "step": 9000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.22110481560230255,
      "learning_rate": 0.00051125,
      "loss": 0.5658,
      "step": 9100
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.19313612580299377,
      "learning_rate": 0.0005099999999999999,
      "loss": 0.565,
      "step": 9200
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.1696128100156784,
      "learning_rate": 0.00050875,
      "loss": 0.5666,
      "step": 9300
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.18036364018917084,
      "learning_rate": 0.0005074999999999999,
      "loss": 0.5651,
      "step": 9400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21801909804344177,
      "learning_rate": 0.00050625,
      "loss": 0.5656,
      "step": 9500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2115265429019928,
      "learning_rate": 0.0005049999999999999,
      "loss": 0.566,
      "step": 9600
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20286740362644196,
      "learning_rate": 0.00050375,
      "loss": 0.5624,
      "step": 9700
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.16899552941322327,
      "learning_rate": 0.0005025,
      "loss": 0.5637,
      "step": 9800
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1767389476299286,
      "learning_rate": 0.00050125,
      "loss": 0.5634,
      "step": 9900
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2284432202577591,
      "learning_rate": 0.0005,
      "loss": 0.5634,
      "step": 10000
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.18773795664310455,
      "learning_rate": 0.00049875,
      "loss": 0.5619,
      "step": 10100
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.17490960657596588,
      "learning_rate": 0.0004975,
      "loss": 0.562,
      "step": 10200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.15701240301132202,
      "learning_rate": 0.00049625,
      "loss": 0.5602,
      "step": 10300
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19842743873596191,
      "learning_rate": 0.0004949999999999999,
      "loss": 0.5607,
      "step": 10400
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.17695631086826324,
      "learning_rate": 0.0004937499999999999,
      "loss": 0.5595,
      "step": 10500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.18272000551223755,
      "learning_rate": 0.0004925,
      "loss": 0.5604,
      "step": 10600
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.22697454690933228,
      "learning_rate": 0.0004912499999999999,
      "loss": 0.5593,
      "step": 10700
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.17613142728805542,
      "learning_rate": 0.00049,
      "loss": 0.5598,
      "step": 10800
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.21089564263820648,
      "learning_rate": 0.0004887499999999999,
      "loss": 0.5574,
      "step": 10900
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.23747602105140686,
      "learning_rate": 0.0004875,
      "loss": 0.5577,
      "step": 11000
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18843233585357666,
      "learning_rate": 0.00048625,
      "loss": 0.5571,
      "step": 11100
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.21105876564979553,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.5576,
      "step": 11200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.17763710021972656,
      "learning_rate": 0.00048374999999999997,
      "loss": 0.5569,
      "step": 11300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1607203334569931,
      "learning_rate": 0.00048249999999999996,
      "loss": 0.5552,
      "step": 11400
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.16359107196331024,
      "learning_rate": 0.00048124999999999996,
      "loss": 0.5546,
      "step": 11500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.16859795153141022,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.5552,
      "step": 11600
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.18242549896240234,
      "learning_rate": 0.00047875,
      "loss": 0.5547,
      "step": 11700
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20630647242069244,
      "learning_rate": 0.00047749999999999995,
      "loss": 0.5547,
      "step": 11800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.17117807269096375,
      "learning_rate": 0.00047624999999999995,
      "loss": 0.5563,
      "step": 11900
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16650952398777008,
      "learning_rate": 0.00047499999999999994,
      "loss": 0.5534,
      "step": 12000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16761361062526703,
      "learning_rate": 0.00047374999999999994,
      "loss": 0.5566,
      "step": 12100
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.17649246752262115,
      "learning_rate": 0.00047249999999999994,
      "loss": 0.5536,
      "step": 12200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18871402740478516,
      "learning_rate": 0.00047124999999999993,
      "loss": 0.5519,
      "step": 12300
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.15789631009101868,
      "learning_rate": 0.00046999999999999993,
      "loss": 0.5534,
      "step": 12400
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.17910759150981903,
      "learning_rate": 0.00046875,
      "loss": 0.5548,
      "step": 12500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1637234389781952,
      "learning_rate": 0.0004675,
      "loss": 0.553,
      "step": 12600
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18926961719989777,
      "learning_rate": 0.00046625,
      "loss": 0.5543,
      "step": 12700
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19755819439888,
      "learning_rate": 0.00046499999999999997,
      "loss": 0.5524,
      "step": 12800
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.17976482212543488,
      "learning_rate": 0.00046374999999999997,
      "loss": 0.5522,
      "step": 12900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.16044744849205017,
      "learning_rate": 0.00046249999999999997,
      "loss": 0.5532,
      "step": 13000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.14197516441345215,
      "learning_rate": 0.00046124999999999996,
      "loss": 0.5503,
      "step": 13100
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.15135368704795837,
      "learning_rate": 0.00046,
      "loss": 0.5497,
      "step": 13200
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17164254188537598,
      "learning_rate": 0.0004587499999999999,
      "loss": 0.5521,
      "step": 13300
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.15336573123931885,
      "learning_rate": 0.00045749999999999995,
      "loss": 0.5514,
      "step": 13400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.16076146066188812,
      "learning_rate": 0.00045624999999999995,
      "loss": 0.5517,
      "step": 13500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.18394799530506134,
      "learning_rate": 0.00045499999999999995,
      "loss": 0.5512,
      "step": 13600
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.14305754005908966,
      "learning_rate": 0.00045374999999999994,
      "loss": 0.5494,
      "step": 13700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.170973002910614,
      "learning_rate": 0.00045249999999999994,
      "loss": 0.5504,
      "step": 13800
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16785641014575958,
      "learning_rate": 0.00045124999999999994,
      "loss": 0.5508,
      "step": 13900
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.15083295106887817,
      "learning_rate": 0.00045,
      "loss": 0.5483,
      "step": 14000
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1430879533290863,
      "learning_rate": 0.00044875,
      "loss": 0.5463,
      "step": 14100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.15267376601696014,
      "learning_rate": 0.0004475,
      "loss": 0.5489,
      "step": 14200
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13650837540626526,
      "learning_rate": 0.00044625,
      "loss": 0.5489,
      "step": 14300
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.208187535405159,
      "learning_rate": 0.000445,
      "loss": 0.5469,
      "step": 14400
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.16515763103961945,
      "learning_rate": 0.00044374999999999997,
      "loss": 0.5469,
      "step": 14500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.15371356904506683,
      "learning_rate": 0.00044249999999999997,
      "loss": 0.548,
      "step": 14600
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.152592271566391,
      "learning_rate": 0.00044125,
      "loss": 0.5479,
      "step": 14700
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.16128051280975342,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.5471,
      "step": 14800
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1436835527420044,
      "learning_rate": 0.00043874999999999996,
      "loss": 0.547,
      "step": 14900
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1623651385307312,
      "learning_rate": 0.00043749999999999995,
      "loss": 0.5471,
      "step": 15000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.17361801862716675,
      "learning_rate": 0.00043624999999999995,
      "loss": 0.548,
      "step": 15100
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1578129231929779,
      "learning_rate": 0.00043499999999999995,
      "loss": 0.5469,
      "step": 15200
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.15448588132858276,
      "learning_rate": 0.00043374999999999995,
      "loss": 0.5464,
      "step": 15300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1525939553976059,
      "learning_rate": 0.00043249999999999994,
      "loss": 0.5455,
      "step": 15400
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.14180056750774384,
      "learning_rate": 0.00043124999999999994,
      "loss": 0.5444,
      "step": 15500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.16036012768745422,
      "learning_rate": 0.00043,
      "loss": 0.5453,
      "step": 15600
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.14492420852184296,
      "learning_rate": 0.00042875,
      "loss": 0.545,
      "step": 15700
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.16192536056041718,
      "learning_rate": 0.0004275,
      "loss": 0.5441,
      "step": 15800
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.16624630987644196,
      "learning_rate": 0.00042625,
      "loss": 0.5452,
      "step": 15900
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.14258623123168945,
      "learning_rate": 0.000425,
      "loss": 0.5444,
      "step": 16000
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.15091902017593384,
      "learning_rate": 0.00042375,
      "loss": 0.5435,
      "step": 16100
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.15179724991321564,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.5426,
      "step": 16200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1527579426765442,
      "learning_rate": 0.0004212499999999999,
      "loss": 0.5434,
      "step": 16300
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17785730957984924,
      "learning_rate": 0.00041999999999999996,
      "loss": 0.5431,
      "step": 16400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17286573350429535,
      "learning_rate": 0.00041874999999999996,
      "loss": 0.5458,
      "step": 16500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.149659663438797,
      "learning_rate": 0.00041749999999999996,
      "loss": 0.5448,
      "step": 16600
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.13236665725708008,
      "learning_rate": 0.00041624999999999995,
      "loss": 0.5416,
      "step": 16700
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17147599160671234,
      "learning_rate": 0.00041499999999999995,
      "loss": 0.5422,
      "step": 16800
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.16264568269252777,
      "learning_rate": 0.00041374999999999995,
      "loss": 0.5441,
      "step": 16900
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14372572302818298,
      "learning_rate": 0.00041249999999999994,
      "loss": 0.5402,
      "step": 17000
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.15476234257221222,
      "learning_rate": 0.00041125,
      "loss": 0.5431,
      "step": 17100
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.16216261684894562,
      "learning_rate": 0.00041,
      "loss": 0.5415,
      "step": 17200
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1482221484184265,
      "learning_rate": 0.00040875,
      "loss": 0.5428,
      "step": 17300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.14323022961616516,
      "learning_rate": 0.0004075,
      "loss": 0.5403,
      "step": 17400
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.14006713032722473,
      "learning_rate": 0.00040625,
      "loss": 0.5402,
      "step": 17500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16263197362422943,
      "learning_rate": 0.000405,
      "loss": 0.5432,
      "step": 17600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.13164709508419037,
      "learning_rate": 0.00040375,
      "loss": 0.542,
      "step": 17700
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.14096736907958984,
      "learning_rate": 0.0004024999999999999,
      "loss": 0.5419,
      "step": 17800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1548910290002823,
      "learning_rate": 0.0004012499999999999,
      "loss": 0.5402,
      "step": 17900
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.16136007010936737,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.5391,
      "step": 18000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13963161408901215,
      "learning_rate": 0.00039874999999999996,
      "loss": 0.5412,
      "step": 18100
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.14382502436637878,
      "learning_rate": 0.00039749999999999996,
      "loss": 0.5401,
      "step": 18200
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14115417003631592,
      "learning_rate": 0.00039624999999999996,
      "loss": 0.5383,
      "step": 18300
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.16533434391021729,
      "learning_rate": 0.00039499999999999995,
      "loss": 0.5377,
      "step": 18400
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14551416039466858,
      "learning_rate": 0.00039374999999999995,
      "loss": 0.5398,
      "step": 18500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1482279896736145,
      "learning_rate": 0.00039249999999999995,
      "loss": 0.5388,
      "step": 18600
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1582440584897995,
      "learning_rate": 0.00039125,
      "loss": 0.5374,
      "step": 18700
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13696572184562683,
      "learning_rate": 0.00039,
      "loss": 0.5372,
      "step": 18800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13209964334964752,
      "learning_rate": 0.00038875,
      "loss": 0.5381,
      "step": 18900
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13363952934741974,
      "learning_rate": 0.0003875,
      "loss": 0.5377,
      "step": 19000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1395338773727417,
      "learning_rate": 0.00038625,
      "loss": 0.5371,
      "step": 19100
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.137356236577034,
      "learning_rate": 0.000385,
      "loss": 0.538,
      "step": 19200
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16382242739200592,
      "learning_rate": 0.0003837499999999999,
      "loss": 0.5387,
      "step": 19300
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.15361584722995758,
      "learning_rate": 0.0003824999999999999,
      "loss": 0.5385,
      "step": 19400
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.14325366914272308,
      "learning_rate": 0.00038124999999999997,
      "loss": 0.5377,
      "step": 19500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.14089232683181763,
      "learning_rate": 0.00037999999999999997,
      "loss": 0.5357,
      "step": 19600
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.15446951985359192,
      "learning_rate": 0.00037874999999999996,
      "loss": 0.5375,
      "step": 19700
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.14066408574581146,
      "learning_rate": 0.00037749999999999996,
      "loss": 0.5365,
      "step": 19800
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.14126552641391754,
      "learning_rate": 0.00037624999999999996,
      "loss": 0.5381,
      "step": 19900
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.14690253138542175,
      "learning_rate": 0.00037499999999999995,
      "loss": 0.5371,
      "step": 20000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13937358558177948,
      "learning_rate": 0.00037374999999999995,
      "loss": 0.5352,
      "step": 20100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13607127964496613,
      "learning_rate": 0.0003725,
      "loss": 0.5363,
      "step": 20200
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12885567545890808,
      "learning_rate": 0.00037125,
      "loss": 0.5358,
      "step": 20300
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1632109135389328,
      "learning_rate": 0.00037,
      "loss": 0.5366,
      "step": 20400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.13325002789497375,
      "learning_rate": 0.00036875,
      "loss": 0.5359,
      "step": 20500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.15327130258083344,
      "learning_rate": 0.0003675,
      "loss": 0.536,
      "step": 20600
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.13756228983402252,
      "learning_rate": 0.00036625,
      "loss": 0.5368,
      "step": 20700
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16726486384868622,
      "learning_rate": 0.00036499999999999993,
      "loss": 0.5363,
      "step": 20800
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13731713593006134,
      "learning_rate": 0.0003637499999999999,
      "loss": 0.5342,
      "step": 20900
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17105919122695923,
      "learning_rate": 0.0003624999999999999,
      "loss": 0.5336,
      "step": 21000
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.12906180322170258,
      "learning_rate": 0.00036124999999999997,
      "loss": 0.5331,
      "step": 21100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.15654432773590088,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.5343,
      "step": 21200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14265751838684082,
      "learning_rate": 0.00035874999999999997,
      "loss": 0.5347,
      "step": 21300
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15034791827201843,
      "learning_rate": 0.00035749999999999996,
      "loss": 0.535,
      "step": 21400
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15397265553474426,
      "learning_rate": 0.00035624999999999996,
      "loss": 0.5334,
      "step": 21500
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14279356598854065,
      "learning_rate": 0.00035499999999999996,
      "loss": 0.533,
      "step": 21600
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.15751415491104126,
      "learning_rate": 0.00035374999999999995,
      "loss": 0.5322,
      "step": 21700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.15293312072753906,
      "learning_rate": 0.0003525,
      "loss": 0.5342,
      "step": 21800
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13836553692817688,
      "learning_rate": 0.00035125,
      "loss": 0.535,
      "step": 21900
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1753852367401123,
      "learning_rate": 0.00035,
      "loss": 0.534,
      "step": 22000
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1759723573923111,
      "learning_rate": 0.00034875,
      "loss": 0.5332,
      "step": 22100
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1461423933506012,
      "learning_rate": 0.0003475,
      "loss": 0.5328,
      "step": 22200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1291106790304184,
      "learning_rate": 0.00034624999999999993,
      "loss": 0.5325,
      "step": 22300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1592276692390442,
      "learning_rate": 0.00034499999999999993,
      "loss": 0.5335,
      "step": 22400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.13662266731262207,
      "learning_rate": 0.0003437499999999999,
      "loss": 0.5324,
      "step": 22500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1422397643327713,
      "learning_rate": 0.0003425,
      "loss": 0.5309,
      "step": 22600
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1490134447813034,
      "learning_rate": 0.00034125,
      "loss": 0.5345,
      "step": 22700
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12900346517562866,
      "learning_rate": 0.00033999999999999997,
      "loss": 0.5325,
      "step": 22800
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.17909200489521027,
      "learning_rate": 0.00033874999999999997,
      "loss": 0.5304,
      "step": 22900
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.15632975101470947,
      "learning_rate": 0.00033749999999999996,
      "loss": 0.5321,
      "step": 23000
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14780662953853607,
      "learning_rate": 0.00033624999999999996,
      "loss": 0.5328,
      "step": 23100
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.15335863828659058,
      "learning_rate": 0.00033499999999999996,
      "loss": 0.5315,
      "step": 23200
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.139568492770195,
      "learning_rate": 0.00033375,
      "loss": 0.5335,
      "step": 23300
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12816551327705383,
      "learning_rate": 0.0003325,
      "loss": 0.5286,
      "step": 23400
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1449306160211563,
      "learning_rate": 0.00033125,
      "loss": 0.5326,
      "step": 23500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.13741345703601837,
      "learning_rate": 0.00033,
      "loss": 0.5306,
      "step": 23600
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.13193725049495697,
      "learning_rate": 0.00032875,
      "loss": 0.5306,
      "step": 23700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.13842321932315826,
      "learning_rate": 0.00032749999999999994,
      "loss": 0.5308,
      "step": 23800
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15765361487865448,
      "learning_rate": 0.00032624999999999993,
      "loss": 0.5296,
      "step": 23900
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12396689504384995,
      "learning_rate": 0.00032499999999999993,
      "loss": 0.5313,
      "step": 24000
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1555822491645813,
      "learning_rate": 0.00032374999999999993,
      "loss": 0.53,
      "step": 24100
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15107229351997375,
      "learning_rate": 0.0003225,
      "loss": 0.5283,
      "step": 24200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1315537840127945,
      "learning_rate": 0.00032125,
      "loss": 0.5284,
      "step": 24300
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15104109048843384,
      "learning_rate": 0.00031999999999999997,
      "loss": 0.53,
      "step": 24400
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1493077576160431,
      "learning_rate": 0.00031874999999999997,
      "loss": 0.5285,
      "step": 24500
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.14482490718364716,
      "learning_rate": 0.00031749999999999997,
      "loss": 0.5299,
      "step": 24600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1473633348941803,
      "learning_rate": 0.00031624999999999996,
      "loss": 0.5281,
      "step": 24700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1312521994113922,
      "learning_rate": 0.00031499999999999996,
      "loss": 0.5285,
      "step": 24800
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.14642608165740967,
      "learning_rate": 0.00031375,
      "loss": 0.5273,
      "step": 24900
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1477876603603363,
      "learning_rate": 0.0003125,
      "loss": 0.5304,
      "step": 25000
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1663030982017517,
      "learning_rate": 0.00031125,
      "loss": 0.5273,
      "step": 25100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1280185431241989,
      "learning_rate": 0.00031,
      "loss": 0.5261,
      "step": 25200
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12159347534179688,
      "learning_rate": 0.00030874999999999994,
      "loss": 0.528,
      "step": 25300
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.148703470826149,
      "learning_rate": 0.00030749999999999994,
      "loss": 0.526,
      "step": 25400
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.16121064126491547,
      "learning_rate": 0.00030624999999999994,
      "loss": 0.5283,
      "step": 25500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1218736320734024,
      "learning_rate": 0.00030499999999999993,
      "loss": 0.5281,
      "step": 25600
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.18371310830116272,
      "learning_rate": 0.00030375,
      "loss": 0.5276,
      "step": 25700
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1509314477443695,
      "learning_rate": 0.0003025,
      "loss": 0.5285,
      "step": 25800
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1410604864358902,
      "learning_rate": 0.00030125,
      "loss": 0.5292,
      "step": 25900
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14221172034740448,
      "learning_rate": 0.0003,
      "loss": 0.5259,
      "step": 26000
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1297268271446228,
      "learning_rate": 0.00029874999999999997,
      "loss": 0.5275,
      "step": 26100
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1548008769750595,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.5285,
      "step": 26200
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.13430987298488617,
      "learning_rate": 0.00029624999999999996,
      "loss": 0.525,
      "step": 26300
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.14100053906440735,
      "learning_rate": 0.00029499999999999996,
      "loss": 0.5272,
      "step": 26400
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1453208029270172,
      "learning_rate": 0.00029374999999999996,
      "loss": 0.5259,
      "step": 26500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.14568296074867249,
      "learning_rate": 0.00029249999999999995,
      "loss": 0.5251,
      "step": 26600
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.13389910757541656,
      "learning_rate": 0.00029124999999999995,
      "loss": 0.5261,
      "step": 26700
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15482144057750702,
      "learning_rate": 0.00029,
      "loss": 0.5282,
      "step": 26800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13874082267284393,
      "learning_rate": 0.00028875,
      "loss": 0.526,
      "step": 26900
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13045582175254822,
      "learning_rate": 0.0002875,
      "loss": 0.5272,
      "step": 27000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1232289969921112,
      "learning_rate": 0.00028625,
      "loss": 0.5274,
      "step": 27100
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15633679926395416,
      "learning_rate": 0.000285,
      "loss": 0.5244,
      "step": 27200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1437477320432663,
      "learning_rate": 0.00028375,
      "loss": 0.5252,
      "step": 27300
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12911389768123627,
      "learning_rate": 0.0002825,
      "loss": 0.5247,
      "step": 27400
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.14514382183551788,
      "learning_rate": 0.00028125,
      "loss": 0.5267,
      "step": 27500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.14749827980995178,
      "learning_rate": 0.00028,
      "loss": 0.5252,
      "step": 27600
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13201458752155304,
      "learning_rate": 0.00027874999999999997,
      "loss": 0.5247,
      "step": 27700
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13761377334594727,
      "learning_rate": 0.00027749999999999997,
      "loss": 0.5261,
      "step": 27800
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13121451437473297,
      "learning_rate": 0.00027624999999999997,
      "loss": 0.5247,
      "step": 27900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1474570780992508,
      "learning_rate": 0.00027499999999999996,
      "loss": 0.5246,
      "step": 28000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13020232319831848,
      "learning_rate": 0.00027374999999999996,
      "loss": 0.5233,
      "step": 28100
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14837974309921265,
      "learning_rate": 0.00027249999999999996,
      "loss": 0.5242,
      "step": 28200
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13066405057907104,
      "learning_rate": 0.00027124999999999995,
      "loss": 0.5231,
      "step": 28300
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14591731131076813,
      "learning_rate": 0.00027,
      "loss": 0.5259,
      "step": 28400
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14684173464775085,
      "learning_rate": 0.00026875,
      "loss": 0.5244,
      "step": 28500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16780740022659302,
      "learning_rate": 0.0002675,
      "loss": 0.5232,
      "step": 28600
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.15777502954006195,
      "learning_rate": 0.00026624999999999994,
      "loss": 0.525,
      "step": 28700
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.15407304465770721,
      "learning_rate": 0.000265,
      "loss": 0.5222,
      "step": 28800
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12743353843688965,
      "learning_rate": 0.00026375,
      "loss": 0.5236,
      "step": 28900
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1221926212310791,
      "learning_rate": 0.0002625,
      "loss": 0.5238,
      "step": 29000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14086373150348663,
      "learning_rate": 0.00026125,
      "loss": 0.523,
      "step": 29100
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.16735418140888214,
      "learning_rate": 0.00026,
      "loss": 0.5226,
      "step": 29200
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1338580846786499,
      "learning_rate": 0.00025875,
      "loss": 0.5232,
      "step": 29300
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1356685906648636,
      "learning_rate": 0.00025749999999999997,
      "loss": 0.5191,
      "step": 29400
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17135357856750488,
      "learning_rate": 0.00025624999999999997,
      "loss": 0.5213,
      "step": 29500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15973469614982605,
      "learning_rate": 0.00025499999999999996,
      "loss": 0.5235,
      "step": 29600
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1347244828939438,
      "learning_rate": 0.00025374999999999996,
      "loss": 0.5237,
      "step": 29700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1357438564300537,
      "learning_rate": 0.00025249999999999996,
      "loss": 0.5213,
      "step": 29800
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.14666734635829926,
      "learning_rate": 0.00025125,
      "loss": 0.5233,
      "step": 29900
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.13878598809242249,
      "learning_rate": 0.00025,
      "loss": 0.5214,
      "step": 30000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.13911010324954987,
      "learning_rate": 0.00024875,
      "loss": 0.5229,
      "step": 30100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.13755396008491516,
      "learning_rate": 0.00024749999999999994,
      "loss": 0.5196,
      "step": 30200
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1414528638124466,
      "learning_rate": 0.00024625,
      "loss": 0.5214,
      "step": 30300
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.14531554281711578,
      "learning_rate": 0.000245,
      "loss": 0.5221,
      "step": 30400
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15481792390346527,
      "learning_rate": 0.00024375,
      "loss": 0.5214,
      "step": 30500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.13246683776378632,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.5217,
      "step": 30600
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.14449374377727509,
      "learning_rate": 0.00024124999999999998,
      "loss": 0.5223,
      "step": 30700
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.139584019780159,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.5209,
      "step": 30800
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.13188673555850983,
      "learning_rate": 0.00023874999999999998,
      "loss": 0.52,
      "step": 30900
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15951396524906158,
      "learning_rate": 0.00023749999999999997,
      "loss": 0.5233,
      "step": 31000
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16626061499118805,
      "learning_rate": 0.00023624999999999997,
      "loss": 0.5167,
      "step": 31100
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.13742950558662415,
      "learning_rate": 0.00023499999999999997,
      "loss": 0.5194,
      "step": 31200
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.13052566349506378,
      "learning_rate": 0.00023375,
      "loss": 0.5211,
      "step": 31300
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.13917016983032227,
      "learning_rate": 0.00023249999999999999,
      "loss": 0.5208,
      "step": 31400
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14350594580173492,
      "learning_rate": 0.00023124999999999998,
      "loss": 0.5223,
      "step": 31500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14876976609230042,
      "learning_rate": 0.00023,
      "loss": 0.5214,
      "step": 31600
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16822880506515503,
      "learning_rate": 0.00022874999999999998,
      "loss": 0.5189,
      "step": 31700
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15047524869441986,
      "learning_rate": 0.00022749999999999997,
      "loss": 0.5184,
      "step": 31800
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.13710851967334747,
      "learning_rate": 0.00022624999999999997,
      "loss": 0.519,
      "step": 31900
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1402706652879715,
      "learning_rate": 0.000225,
      "loss": 0.5179,
      "step": 32000
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.14908476173877716,
      "learning_rate": 0.00022375,
      "loss": 0.5182,
      "step": 32100
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15613096952438354,
      "learning_rate": 0.0002225,
      "loss": 0.5186,
      "step": 32200
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.13928483426570892,
      "learning_rate": 0.00022124999999999998,
      "loss": 0.5189,
      "step": 32300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16996188461780548,
      "learning_rate": 0.00021999999999999995,
      "loss": 0.5187,
      "step": 32400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12898851931095123,
      "learning_rate": 0.00021874999999999998,
      "loss": 0.5184,
      "step": 32500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.13967296481132507,
      "learning_rate": 0.00021749999999999997,
      "loss": 0.5193,
      "step": 32600
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14001569151878357,
      "learning_rate": 0.00021624999999999997,
      "loss": 0.5192,
      "step": 32700
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15031009912490845,
      "learning_rate": 0.000215,
      "loss": 0.5176,
      "step": 32800
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.14289678633213043,
      "learning_rate": 0.00021375,
      "loss": 0.5181,
      "step": 32900
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16889047622680664,
      "learning_rate": 0.0002125,
      "loss": 0.5177,
      "step": 33000
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.14616353809833527,
      "learning_rate": 0.00021124999999999998,
      "loss": 0.5181,
      "step": 33100
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15274210274219513,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5154,
      "step": 33200
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14406472444534302,
      "learning_rate": 0.00020874999999999998,
      "loss": 0.5158,
      "step": 33300
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14270170032978058,
      "learning_rate": 0.00020749999999999998,
      "loss": 0.5181,
      "step": 33400
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13667961955070496,
      "learning_rate": 0.00020624999999999997,
      "loss": 0.5152,
      "step": 33500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15374024212360382,
      "learning_rate": 0.000205,
      "loss": 0.5188,
      "step": 33600
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16840246319770813,
      "learning_rate": 0.00020375,
      "loss": 0.5165,
      "step": 33700
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14074347913265228,
      "learning_rate": 0.0002025,
      "loss": 0.5163,
      "step": 33800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14189521968364716,
      "learning_rate": 0.00020124999999999996,
      "loss": 0.5164,
      "step": 33900
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13211801648139954,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.5157,
      "step": 34000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13180196285247803,
      "learning_rate": 0.00019874999999999998,
      "loss": 0.5178,
      "step": 34100
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14942672848701477,
      "learning_rate": 0.00019749999999999998,
      "loss": 0.5157,
      "step": 34200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.13720129430294037,
      "learning_rate": 0.00019624999999999997,
      "loss": 0.5156,
      "step": 34300
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15954144299030304,
      "learning_rate": 0.000195,
      "loss": 0.5173,
      "step": 34400
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.14651545882225037,
      "learning_rate": 0.00019375,
      "loss": 0.5171,
      "step": 34500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15960103273391724,
      "learning_rate": 0.0001925,
      "loss": 0.5154,
      "step": 34600
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.144427090883255,
      "learning_rate": 0.00019124999999999996,
      "loss": 0.5161,
      "step": 34700
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1537337601184845,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.5151,
      "step": 34800
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13599008321762085,
      "learning_rate": 0.00018874999999999998,
      "loss": 0.5165,
      "step": 34900
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1340043842792511,
      "learning_rate": 0.00018749999999999998,
      "loss": 0.5158,
      "step": 35000
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.15125030279159546,
      "learning_rate": 0.00018625,
      "loss": 0.5148,
      "step": 35100
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.16799741983413696,
      "learning_rate": 0.000185,
      "loss": 0.5159,
      "step": 35200
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1470693200826645,
      "learning_rate": 0.00018375,
      "loss": 0.5148,
      "step": 35300
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14012408256530762,
      "learning_rate": 0.00018249999999999996,
      "loss": 0.5159,
      "step": 35400
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.137546569108963,
      "learning_rate": 0.00018124999999999996,
      "loss": 0.5154,
      "step": 35500
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1619078814983368,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.5145,
      "step": 35600
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.17043590545654297,
      "learning_rate": 0.00017874999999999998,
      "loss": 0.5155,
      "step": 35700
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1376906782388687,
      "learning_rate": 0.00017749999999999998,
      "loss": 0.5137,
      "step": 35800
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.16538187861442566,
      "learning_rate": 0.00017625,
      "loss": 0.5145,
      "step": 35900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13679282367229462,
      "learning_rate": 0.000175,
      "loss": 0.5148,
      "step": 36000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12569905817508698,
      "learning_rate": 0.00017375,
      "loss": 0.5145,
      "step": 36100
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.132583349943161,
      "learning_rate": 0.00017249999999999996,
      "loss": 0.5134,
      "step": 36200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14333182573318481,
      "learning_rate": 0.00017125,
      "loss": 0.513,
      "step": 36300
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14865507185459137,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.5145,
      "step": 36400
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13746769726276398,
      "learning_rate": 0.00016874999999999998,
      "loss": 0.5153,
      "step": 36500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13640649616718292,
      "learning_rate": 0.00016749999999999998,
      "loss": 0.5127,
      "step": 36600
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.17682921886444092,
      "learning_rate": 0.00016625,
      "loss": 0.5132,
      "step": 36700
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.15011227130889893,
      "learning_rate": 0.000165,
      "loss": 0.5152,
      "step": 36800
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.13915346562862396,
      "learning_rate": 0.00016374999999999997,
      "loss": 0.5152,
      "step": 36900
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.14400231838226318,
      "learning_rate": 0.00016249999999999997,
      "loss": 0.5144,
      "step": 37000
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1344749927520752,
      "learning_rate": 0.00016125,
      "loss": 0.5147,
      "step": 37100
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.15645478665828705,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.5129,
      "step": 37200
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14766620099544525,
      "learning_rate": 0.00015874999999999998,
      "loss": 0.5111,
      "step": 37300
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1538010537624359,
      "learning_rate": 0.00015749999999999998,
      "loss": 0.5126,
      "step": 37400
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1484609991312027,
      "learning_rate": 0.00015625,
      "loss": 0.5112,
      "step": 37500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.13418911397457123,
      "learning_rate": 0.000155,
      "loss": 0.5108,
      "step": 37600
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1399993747472763,
      "learning_rate": 0.00015374999999999997,
      "loss": 0.5111,
      "step": 37700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14079482853412628,
      "learning_rate": 0.00015249999999999997,
      "loss": 0.5131,
      "step": 37800
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.16588041186332703,
      "learning_rate": 0.00015125,
      "loss": 0.5109,
      "step": 37900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14099855720996857,
      "learning_rate": 0.00015,
      "loss": 0.5123,
      "step": 38000
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1743609607219696,
      "learning_rate": 0.00014874999999999998,
      "loss": 0.5116,
      "step": 38100
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.16451336443424225,
      "learning_rate": 0.00014749999999999998,
      "loss": 0.5088,
      "step": 38200
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13720843195915222,
      "learning_rate": 0.00014624999999999998,
      "loss": 0.5118,
      "step": 38300
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1487577110528946,
      "learning_rate": 0.000145,
      "loss": 0.5119,
      "step": 38400
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1450984627008438,
      "learning_rate": 0.00014375,
      "loss": 0.5121,
      "step": 38500
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13693535327911377,
      "learning_rate": 0.0001425,
      "loss": 0.5105,
      "step": 38600
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1488511860370636,
      "learning_rate": 0.00014125,
      "loss": 0.511,
      "step": 38700
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1526651233434677,
      "learning_rate": 0.00014,
      "loss": 0.511,
      "step": 38800
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.14884546399116516,
      "learning_rate": 0.00013874999999999998,
      "loss": 0.51,
      "step": 38900
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.13060376048088074,
      "learning_rate": 0.00013749999999999998,
      "loss": 0.509,
      "step": 39000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1452925056219101,
      "learning_rate": 0.00013624999999999998,
      "loss": 0.5084,
      "step": 39100
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.15927749872207642,
      "learning_rate": 0.000135,
      "loss": 0.5094,
      "step": 39200
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.149019256234169,
      "learning_rate": 0.00013375,
      "loss": 0.5097,
      "step": 39300
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1420188695192337,
      "learning_rate": 0.0001325,
      "loss": 0.5094,
      "step": 39400
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.15871784090995789,
      "learning_rate": 0.00013125,
      "loss": 0.5096,
      "step": 39500
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.14915519952774048,
      "learning_rate": 0.00013,
      "loss": 0.5099,
      "step": 39600
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.14273205399513245,
      "learning_rate": 0.00012874999999999999,
      "loss": 0.51,
      "step": 39700
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13725821673870087,
      "learning_rate": 0.00012749999999999998,
      "loss": 0.508,
      "step": 39800
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.15179593861103058,
      "learning_rate": 0.00012624999999999998,
      "loss": 0.5093,
      "step": 39900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1696965992450714,
      "learning_rate": 0.000125,
      "loss": 0.5082,
      "step": 40000
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.15040984749794006,
      "learning_rate": 0.00012374999999999997,
      "loss": 0.5088,
      "step": 40100
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.17405007779598236,
      "learning_rate": 0.0001225,
      "loss": 0.5111,
      "step": 40200
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13896074891090393,
      "learning_rate": 0.00012124999999999999,
      "loss": 0.5067,
      "step": 40300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1520242691040039,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.5079,
      "step": 40400
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.14923033118247986,
      "learning_rate": 0.00011874999999999999,
      "loss": 0.5075,
      "step": 40500
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1684836894273758,
      "learning_rate": 0.00011749999999999998,
      "loss": 0.5097,
      "step": 40600
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1385142058134079,
      "learning_rate": 0.00011624999999999999,
      "loss": 0.5081,
      "step": 40700
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13871817290782928,
      "learning_rate": 0.000115,
      "loss": 0.5087,
      "step": 40800
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.15210282802581787,
      "learning_rate": 0.00011374999999999999,
      "loss": 0.5087,
      "step": 40900
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.14317522943019867,
      "learning_rate": 0.0001125,
      "loss": 0.5072,
      "step": 41000
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.14388857781887054,
      "learning_rate": 0.00011125,
      "loss": 0.5069,
      "step": 41100
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1410052478313446,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.5098,
      "step": 41200
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.16612838208675385,
      "learning_rate": 0.00010874999999999999,
      "loss": 0.5071,
      "step": 41300
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14931486546993256,
      "learning_rate": 0.0001075,
      "loss": 0.5078,
      "step": 41400
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.15712115168571472,
      "learning_rate": 0.00010625,
      "loss": 0.5069,
      "step": 41500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.15280213952064514,
      "learning_rate": 0.00010499999999999999,
      "loss": 0.5069,
      "step": 41600
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1420232206583023,
      "learning_rate": 0.00010374999999999999,
      "loss": 0.5081,
      "step": 41700
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.17114780843257904,
      "learning_rate": 0.0001025,
      "loss": 0.5071,
      "step": 41800
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1474299281835556,
      "learning_rate": 0.00010125,
      "loss": 0.508,
      "step": 41900
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14840182662010193,
      "learning_rate": 9.999999999999999e-05,
      "loss": 0.5078,
      "step": 42000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14183388650417328,
      "learning_rate": 9.874999999999999e-05,
      "loss": 0.5082,
      "step": 42100
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.15942788124084473,
      "learning_rate": 9.75e-05,
      "loss": 0.5069,
      "step": 42200
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1538318544626236,
      "learning_rate": 9.625e-05,
      "loss": 0.5064,
      "step": 42300
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1540789157152176,
      "learning_rate": 9.499999999999999e-05,
      "loss": 0.5071,
      "step": 42400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.14805392920970917,
      "learning_rate": 9.374999999999999e-05,
      "loss": 0.5057,
      "step": 42500
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.16233603656291962,
      "learning_rate": 9.25e-05,
      "loss": 0.505,
      "step": 42600
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.15844640135765076,
      "learning_rate": 9.124999999999998e-05,
      "loss": 0.5048,
      "step": 42700
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.14397607743740082,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.5063,
      "step": 42800
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.15241754055023193,
      "learning_rate": 8.874999999999999e-05,
      "loss": 0.5043,
      "step": 42900
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.14198626577854156,
      "learning_rate": 8.75e-05,
      "loss": 0.506,
      "step": 43000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.16100461781024933,
      "learning_rate": 8.624999999999998e-05,
      "loss": 0.505,
      "step": 43100
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.15430913865566254,
      "learning_rate": 8.499999999999999e-05,
      "loss": 0.5049,
      "step": 43200
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1579626351594925,
      "learning_rate": 8.374999999999999e-05,
      "loss": 0.5055,
      "step": 43300
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.16931065917015076,
      "learning_rate": 8.25e-05,
      "loss": 0.5047,
      "step": 43400
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.14931349456310272,
      "learning_rate": 8.124999999999998e-05,
      "loss": 0.5057,
      "step": 43500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.14959856867790222,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.5039,
      "step": 43600
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1695094257593155,
      "learning_rate": 7.874999999999999e-05,
      "loss": 0.5034,
      "step": 43700
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1561087816953659,
      "learning_rate": 7.75e-05,
      "loss": 0.5031,
      "step": 43800
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1610541045665741,
      "learning_rate": 7.624999999999998e-05,
      "loss": 0.5063,
      "step": 43900
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1551256775856018,
      "learning_rate": 7.5e-05,
      "loss": 0.5024,
      "step": 44000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15426881611347198,
      "learning_rate": 7.374999999999999e-05,
      "loss": 0.5047,
      "step": 44100
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.13993649184703827,
      "learning_rate": 7.25e-05,
      "loss": 0.5044,
      "step": 44200
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1485981047153473,
      "learning_rate": 7.125e-05,
      "loss": 0.5041,
      "step": 44300
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15322749316692352,
      "learning_rate": 7e-05,
      "loss": 0.5038,
      "step": 44400
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1451522409915924,
      "learning_rate": 6.874999999999999e-05,
      "loss": 0.5041,
      "step": 44500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15680240094661713,
      "learning_rate": 6.75e-05,
      "loss": 0.5047,
      "step": 44600
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15100914239883423,
      "learning_rate": 6.625e-05,
      "loss": 0.5024,
      "step": 44700
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1504315435886383,
      "learning_rate": 6.5e-05,
      "loss": 0.5013,
      "step": 44800
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14038382470607758,
      "learning_rate": 6.374999999999999e-05,
      "loss": 0.5029,
      "step": 44900
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.15203525125980377,
      "learning_rate": 6.25e-05,
      "loss": 0.504,
      "step": 45000
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14584392309188843,
      "learning_rate": 6.125e-05,
      "loss": 0.5011,
      "step": 45100
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14145296812057495,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 0.5041,
      "step": 45200
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.17456069588661194,
      "learning_rate": 5.874999999999999e-05,
      "loss": 0.5025,
      "step": 45300
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.14859992265701294,
      "learning_rate": 5.75e-05,
      "loss": 0.5005,
      "step": 45400
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.15988782048225403,
      "learning_rate": 5.625e-05,
      "loss": 0.5011,
      "step": 45500
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1728377789258957,
      "learning_rate": 5.499999999999999e-05,
      "loss": 0.5004,
      "step": 45600
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1526160091161728,
      "learning_rate": 5.375e-05,
      "loss": 0.5038,
      "step": 45700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15078312158584595,
      "learning_rate": 5.2499999999999995e-05,
      "loss": 0.4998,
      "step": 45800
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15730957686901093,
      "learning_rate": 5.125e-05,
      "loss": 0.5025,
      "step": 45900
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1493447721004486,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.5015,
      "step": 46000
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15155558288097382,
      "learning_rate": 4.875e-05,
      "loss": 0.5015,
      "step": 46100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.16092872619628906,
      "learning_rate": 4.7499999999999996e-05,
      "loss": 0.5007,
      "step": 46200
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1683172732591629,
      "learning_rate": 4.625e-05,
      "loss": 0.5014,
      "step": 46300
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14415386319160461,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.503,
      "step": 46400
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14389361441135406,
      "learning_rate": 4.375e-05,
      "loss": 0.5011,
      "step": 46500
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.15030352771282196,
      "learning_rate": 4.2499999999999996e-05,
      "loss": 0.4999,
      "step": 46600
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1383788138628006,
      "learning_rate": 4.125e-05,
      "loss": 0.5008,
      "step": 46700
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1585526168346405,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.502,
      "step": 46800
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1544516384601593,
      "learning_rate": 3.875e-05,
      "loss": 0.5023,
      "step": 46900
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1433245837688446,
      "learning_rate": 3.75e-05,
      "loss": 0.4984,
      "step": 47000
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.17438776791095734,
      "learning_rate": 3.625e-05,
      "loss": 0.4987,
      "step": 47100
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.16971495747566223,
      "learning_rate": 3.5e-05,
      "loss": 0.5008,
      "step": 47200
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.14411510527133942,
      "learning_rate": 3.375e-05,
      "loss": 0.5003,
      "step": 47300
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.14948274195194244,
      "learning_rate": 3.25e-05,
      "loss": 0.5014,
      "step": 47400
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1634325534105301,
      "learning_rate": 3.125e-05,
      "loss": 0.5001,
      "step": 47500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.15340785682201385,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.5002,
      "step": 47600
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.14088501036167145,
      "learning_rate": 2.875e-05,
      "loss": 0.4995,
      "step": 47700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.17792753875255585,
      "learning_rate": 2.7499999999999994e-05,
      "loss": 0.4999,
      "step": 47800
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.14399203658103943,
      "learning_rate": 2.6249999999999998e-05,
      "loss": 0.4977,
      "step": 47900
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.14740824699401855,
      "learning_rate": 2.4999999999999998e-05,
      "loss": 0.4994,
      "step": 48000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1747850626707077,
      "learning_rate": 2.3749999999999998e-05,
      "loss": 0.4991,
      "step": 48100
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1431027352809906,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.4996,
      "step": 48200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.14755697548389435,
      "learning_rate": 2.1249999999999998e-05,
      "loss": 0.4978,
      "step": 48300
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.14428581297397614,
      "learning_rate": 1.9999999999999998e-05,
      "loss": 0.5013,
      "step": 48400
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.15224412083625793,
      "learning_rate": 1.875e-05,
      "loss": 0.4997,
      "step": 48500
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1543455421924591,
      "learning_rate": 1.75e-05,
      "loss": 0.4998,
      "step": 48600
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.14474914968013763,
      "learning_rate": 1.625e-05,
      "loss": 0.4986,
      "step": 48700
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1595010608434677,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 0.4998,
      "step": 48800
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.17068232595920563,
      "learning_rate": 1.3749999999999997e-05,
      "loss": 0.4983,
      "step": 48900
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.15686534345149994,
      "learning_rate": 1.2499999999999999e-05,
      "loss": 0.4988,
      "step": 49000
    }
  ],
  "logging_steps": 100,
  "max_steps": 50000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
