{
  "best_metric": 0.33809950947761536,
  "best_model_checkpoint": "/scratch/lmbanr001/HYBRID_20M_dropout_little/checkpoint-244000",
  "epoch": 9.999939008274545,
  "eval_steps": 2000,
  "global_step": 245930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.06611503039421e-05,
      "grad_norm": 19.19866943359375,
      "learning_rate": 2.5000000000000002e-08,
      "loss": 7.6875,
      "step": 1
    },
    {
      "epoch": 0.00406611503039421,
      "grad_norm": 12.13292121887207,
      "learning_rate": 2.5e-06,
      "loss": 6.8465,
      "step": 100
    },
    {
      "epoch": 0.00813223006078842,
      "grad_norm": 2.8739562034606934,
      "learning_rate": 5e-06,
      "loss": 3.4741,
      "step": 200
    },
    {
      "epoch": 0.01219834509118263,
      "grad_norm": 1.7225146293640137,
      "learning_rate": 7.5e-06,
      "loss": 1.7682,
      "step": 300
    },
    {
      "epoch": 0.01626446012157684,
      "grad_norm": 1.7597618103027344,
      "learning_rate": 1e-05,
      "loss": 1.2238,
      "step": 400
    },
    {
      "epoch": 0.02033057515197105,
      "grad_norm": 1.6617400646209717,
      "learning_rate": 1.25e-05,
      "loss": 1.0318,
      "step": 500
    },
    {
      "epoch": 0.02439669018236526,
      "grad_norm": 2.2520751953125,
      "learning_rate": 1.5e-05,
      "loss": 0.9176,
      "step": 600
    },
    {
      "epoch": 0.02846280521275947,
      "grad_norm": 2.1158294677734375,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.8546,
      "step": 700
    },
    {
      "epoch": 0.03252892024315368,
      "grad_norm": 2.8739571571350098,
      "learning_rate": 2e-05,
      "loss": 0.8014,
      "step": 800
    },
    {
      "epoch": 0.03659503527354789,
      "grad_norm": 2.3958098888397217,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.7595,
      "step": 900
    },
    {
      "epoch": 0.0406611503039421,
      "grad_norm": 2.376513957977295,
      "learning_rate": 2.5e-05,
      "loss": 0.7339,
      "step": 1000
    },
    {
      "epoch": 0.04472726533433631,
      "grad_norm": 2.8032219409942627,
      "learning_rate": 2.75e-05,
      "loss": 0.7005,
      "step": 1100
    },
    {
      "epoch": 0.04879338036473052,
      "grad_norm": 2.4173848628997803,
      "learning_rate": 3e-05,
      "loss": 0.6733,
      "step": 1200
    },
    {
      "epoch": 0.05285949539512473,
      "grad_norm": 2.283473253250122,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.6476,
      "step": 1300
    },
    {
      "epoch": 0.05692561042551894,
      "grad_norm": 2.8959898948669434,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.6246,
      "step": 1400
    },
    {
      "epoch": 0.06099172545591315,
      "grad_norm": 2.3752686977386475,
      "learning_rate": 3.75e-05,
      "loss": 0.6081,
      "step": 1500
    },
    {
      "epoch": 0.06505784048630736,
      "grad_norm": 2.726748466491699,
      "learning_rate": 4e-05,
      "loss": 0.5932,
      "step": 1600
    },
    {
      "epoch": 0.06912395551670157,
      "grad_norm": 2.5397298336029053,
      "learning_rate": 4.25e-05,
      "loss": 0.582,
      "step": 1700
    },
    {
      "epoch": 0.07319007054709578,
      "grad_norm": 2.4338016510009766,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.5677,
      "step": 1800
    },
    {
      "epoch": 0.07725618557748999,
      "grad_norm": 2.0493388175964355,
      "learning_rate": 4.75e-05,
      "loss": 0.5537,
      "step": 1900
    },
    {
      "epoch": 0.0813223006078842,
      "grad_norm": 2.2615554332733154,
      "learning_rate": 5e-05,
      "loss": 0.5474,
      "step": 2000
    },
    {
      "epoch": 0.0813223006078842,
      "eval_loss": 0.5482079982757568,
      "eval_runtime": 118.0565,
      "eval_samples_per_second": 1481.511,
      "eval_steps_per_second": 46.3,
      "step": 2000
    },
    {
      "epoch": 0.08538841563827841,
      "grad_norm": 2.2465920448303223,
      "learning_rate": 5.25e-05,
      "loss": 0.5407,
      "step": 2100
    },
    {
      "epoch": 0.08945453066867262,
      "grad_norm": 2.1187636852264404,
      "learning_rate": 5.5e-05,
      "loss": 0.5345,
      "step": 2200
    },
    {
      "epoch": 0.09352064569906683,
      "grad_norm": 1.9057575464248657,
      "learning_rate": 5.75e-05,
      "loss": 0.5249,
      "step": 2300
    },
    {
      "epoch": 0.09758676072946104,
      "grad_norm": 2.045314311981201,
      "learning_rate": 6e-05,
      "loss": 0.5228,
      "step": 2400
    },
    {
      "epoch": 0.10165287575985525,
      "grad_norm": 2.1380791664123535,
      "learning_rate": 6.25e-05,
      "loss": 0.518,
      "step": 2500
    },
    {
      "epoch": 0.10571899079024946,
      "grad_norm": 1.5491701364517212,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.5123,
      "step": 2600
    },
    {
      "epoch": 0.10978510582064367,
      "grad_norm": 1.6293399333953857,
      "learning_rate": 6.75e-05,
      "loss": 0.5053,
      "step": 2700
    },
    {
      "epoch": 0.11385122085103788,
      "grad_norm": 1.6943943500518799,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.5039,
      "step": 2800
    },
    {
      "epoch": 0.11791733588143209,
      "grad_norm": 1.6293436288833618,
      "learning_rate": 7.25e-05,
      "loss": 0.5006,
      "step": 2900
    },
    {
      "epoch": 0.1219834509118263,
      "grad_norm": 1.772432804107666,
      "learning_rate": 7.5e-05,
      "loss": 0.4983,
      "step": 3000
    },
    {
      "epoch": 0.1260495659422205,
      "grad_norm": 1.5961449146270752,
      "learning_rate": 7.75e-05,
      "loss": 0.4963,
      "step": 3100
    },
    {
      "epoch": 0.13011568097261472,
      "grad_norm": 1.5411007404327393,
      "learning_rate": 8e-05,
      "loss": 0.4922,
      "step": 3200
    },
    {
      "epoch": 0.13418179600300892,
      "grad_norm": 1.679436445236206,
      "learning_rate": 8.25e-05,
      "loss": 0.4889,
      "step": 3300
    },
    {
      "epoch": 0.13824791103340314,
      "grad_norm": 1.3749586343765259,
      "learning_rate": 8.5e-05,
      "loss": 0.4852,
      "step": 3400
    },
    {
      "epoch": 0.14231402606379734,
      "grad_norm": 1.4081202745437622,
      "learning_rate": 8.75e-05,
      "loss": 0.4876,
      "step": 3500
    },
    {
      "epoch": 0.14638014109419156,
      "grad_norm": 1.2682831287384033,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.4817,
      "step": 3600
    },
    {
      "epoch": 0.15044625612458576,
      "grad_norm": 1.3495103120803833,
      "learning_rate": 9.25e-05,
      "loss": 0.4783,
      "step": 3700
    },
    {
      "epoch": 0.15451237115497998,
      "grad_norm": 1.295061707496643,
      "learning_rate": 9.5e-05,
      "loss": 0.4756,
      "step": 3800
    },
    {
      "epoch": 0.15857848618537418,
      "grad_norm": 1.3725918531417847,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.476,
      "step": 3900
    },
    {
      "epoch": 0.1626446012157684,
      "grad_norm": 1.1238267421722412,
      "learning_rate": 0.0001,
      "loss": 0.4734,
      "step": 4000
    },
    {
      "epoch": 0.1626446012157684,
      "eval_loss": 0.4811060130596161,
      "eval_runtime": 114.3115,
      "eval_samples_per_second": 1530.048,
      "eval_steps_per_second": 47.817,
      "step": 4000
    },
    {
      "epoch": 0.1667107162461626,
      "grad_norm": 1.0453020334243774,
      "learning_rate": 0.0001025,
      "loss": 0.4693,
      "step": 4100
    },
    {
      "epoch": 0.17077683127655682,
      "grad_norm": 1.1560330390930176,
      "learning_rate": 0.000105,
      "loss": 0.47,
      "step": 4200
    },
    {
      "epoch": 0.17484294630695102,
      "grad_norm": 1.2091820240020752,
      "learning_rate": 0.0001075,
      "loss": 0.4688,
      "step": 4300
    },
    {
      "epoch": 0.17890906133734524,
      "grad_norm": 1.1008329391479492,
      "learning_rate": 0.00011,
      "loss": 0.4666,
      "step": 4400
    },
    {
      "epoch": 0.18297517636773944,
      "grad_norm": 1.0886597633361816,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.4658,
      "step": 4500
    },
    {
      "epoch": 0.18704129139813366,
      "grad_norm": 1.1560369729995728,
      "learning_rate": 0.000115,
      "loss": 0.4616,
      "step": 4600
    },
    {
      "epoch": 0.19110740642852786,
      "grad_norm": 0.997018039226532,
      "learning_rate": 0.0001175,
      "loss": 0.458,
      "step": 4700
    },
    {
      "epoch": 0.19517352145892208,
      "grad_norm": 1.156999945640564,
      "learning_rate": 0.00012,
      "loss": 0.4605,
      "step": 4800
    },
    {
      "epoch": 0.19923963648931628,
      "grad_norm": 1.0977706909179688,
      "learning_rate": 0.0001225,
      "loss": 0.4603,
      "step": 4900
    },
    {
      "epoch": 0.2033057515197105,
      "grad_norm": 0.9089022278785706,
      "learning_rate": 0.000125,
      "loss": 0.4605,
      "step": 5000
    },
    {
      "epoch": 0.2073718665501047,
      "grad_norm": 0.9344677329063416,
      "learning_rate": 0.0001275,
      "loss": 0.4564,
      "step": 5100
    },
    {
      "epoch": 0.21143798158049892,
      "grad_norm": 0.8714014887809753,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.4546,
      "step": 5200
    },
    {
      "epoch": 0.21550409661089312,
      "grad_norm": 1.0398658514022827,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.4513,
      "step": 5300
    },
    {
      "epoch": 0.21957021164128734,
      "grad_norm": 0.8924747705459595,
      "learning_rate": 0.000135,
      "loss": 0.451,
      "step": 5400
    },
    {
      "epoch": 0.22363632667168154,
      "grad_norm": 0.881177544593811,
      "learning_rate": 0.0001375,
      "loss": 0.4519,
      "step": 5500
    },
    {
      "epoch": 0.22770244170207576,
      "grad_norm": 0.8388054370880127,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4496,
      "step": 5600
    },
    {
      "epoch": 0.23176855673246996,
      "grad_norm": 0.8737215995788574,
      "learning_rate": 0.0001425,
      "loss": 0.4498,
      "step": 5700
    },
    {
      "epoch": 0.23583467176286418,
      "grad_norm": 0.8417418003082275,
      "learning_rate": 0.000145,
      "loss": 0.4498,
      "step": 5800
    },
    {
      "epoch": 0.23990078679325838,
      "grad_norm": 0.8357123136520386,
      "learning_rate": 0.0001475,
      "loss": 0.4456,
      "step": 5900
    },
    {
      "epoch": 0.2439669018236526,
      "grad_norm": 0.9743384718894958,
      "learning_rate": 0.00015,
      "loss": 0.446,
      "step": 6000
    },
    {
      "epoch": 0.2439669018236526,
      "eval_loss": 0.4552033543586731,
      "eval_runtime": 114.2544,
      "eval_samples_per_second": 1530.812,
      "eval_steps_per_second": 47.841,
      "step": 6000
    },
    {
      "epoch": 0.2480330168540468,
      "grad_norm": 0.9115117788314819,
      "learning_rate": 0.0001525,
      "loss": 0.4449,
      "step": 6100
    },
    {
      "epoch": 0.252099131884441,
      "grad_norm": 0.8262845873832703,
      "learning_rate": 0.000155,
      "loss": 0.4463,
      "step": 6200
    },
    {
      "epoch": 0.2561652469148352,
      "grad_norm": 0.7308909893035889,
      "learning_rate": 0.0001575,
      "loss": 0.4438,
      "step": 6300
    },
    {
      "epoch": 0.26023136194522944,
      "grad_norm": 1.0401254892349243,
      "learning_rate": 0.00016,
      "loss": 0.444,
      "step": 6400
    },
    {
      "epoch": 0.2642974769756236,
      "grad_norm": 0.7032508254051208,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.4443,
      "step": 6500
    },
    {
      "epoch": 0.26836359200601784,
      "grad_norm": 0.7022764086723328,
      "learning_rate": 0.000165,
      "loss": 0.4456,
      "step": 6600
    },
    {
      "epoch": 0.27242970703641206,
      "grad_norm": 0.7126561999320984,
      "learning_rate": 0.0001675,
      "loss": 0.439,
      "step": 6700
    },
    {
      "epoch": 0.2764958220668063,
      "grad_norm": 0.9049745798110962,
      "learning_rate": 0.00017,
      "loss": 0.4398,
      "step": 6800
    },
    {
      "epoch": 0.28056193709720045,
      "grad_norm": 0.7370297908782959,
      "learning_rate": 0.0001725,
      "loss": 0.4391,
      "step": 6900
    },
    {
      "epoch": 0.2846280521275947,
      "grad_norm": 0.6840314269065857,
      "learning_rate": 0.000175,
      "loss": 0.4397,
      "step": 7000
    },
    {
      "epoch": 0.2886941671579889,
      "grad_norm": 0.6928408741950989,
      "learning_rate": 0.0001775,
      "loss": 0.4405,
      "step": 7100
    },
    {
      "epoch": 0.2927602821883831,
      "grad_norm": 0.6302298307418823,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4386,
      "step": 7200
    },
    {
      "epoch": 0.2968263972187773,
      "grad_norm": 0.6771236062049866,
      "learning_rate": 0.0001825,
      "loss": 0.437,
      "step": 7300
    },
    {
      "epoch": 0.3008925122491715,
      "grad_norm": 0.6350134611129761,
      "learning_rate": 0.000185,
      "loss": 0.4382,
      "step": 7400
    },
    {
      "epoch": 0.30495862727956574,
      "grad_norm": 0.6536184549331665,
      "learning_rate": 0.0001875,
      "loss": 0.4359,
      "step": 7500
    },
    {
      "epoch": 0.30902474230995997,
      "grad_norm": 0.6160851120948792,
      "learning_rate": 0.00019,
      "loss": 0.4358,
      "step": 7600
    },
    {
      "epoch": 0.31309085734035413,
      "grad_norm": 0.6789439916610718,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.4344,
      "step": 7700
    },
    {
      "epoch": 0.31715697237074836,
      "grad_norm": 0.6732255816459656,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.4349,
      "step": 7800
    },
    {
      "epoch": 0.3212230874011426,
      "grad_norm": 0.7112408876419067,
      "learning_rate": 0.0001975,
      "loss": 0.4352,
      "step": 7900
    },
    {
      "epoch": 0.3252892024315368,
      "grad_norm": 0.612125039100647,
      "learning_rate": 0.0002,
      "loss": 0.4361,
      "step": 8000
    },
    {
      "epoch": 0.3252892024315368,
      "eval_loss": 0.44283223152160645,
      "eval_runtime": 114.38,
      "eval_samples_per_second": 1529.131,
      "eval_steps_per_second": 47.788,
      "step": 8000
    },
    {
      "epoch": 0.329355317461931,
      "grad_norm": 0.6626138687133789,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.4364,
      "step": 8100
    },
    {
      "epoch": 0.3334214324923252,
      "grad_norm": 0.5936586856842041,
      "learning_rate": 0.000205,
      "loss": 0.4367,
      "step": 8200
    },
    {
      "epoch": 0.3374875475227194,
      "grad_norm": 0.652188241481781,
      "learning_rate": 0.0002075,
      "loss": 0.4314,
      "step": 8300
    },
    {
      "epoch": 0.34155366255311365,
      "grad_norm": 0.5847192406654358,
      "learning_rate": 0.00021,
      "loss": 0.4328,
      "step": 8400
    },
    {
      "epoch": 0.3456197775835078,
      "grad_norm": 0.5789293646812439,
      "learning_rate": 0.0002125,
      "loss": 0.4305,
      "step": 8500
    },
    {
      "epoch": 0.34968589261390204,
      "grad_norm": 0.5847208499908447,
      "learning_rate": 0.000215,
      "loss": 0.4299,
      "step": 8600
    },
    {
      "epoch": 0.35375200764429626,
      "grad_norm": 0.6508879065513611,
      "learning_rate": 0.0002175,
      "loss": 0.4312,
      "step": 8700
    },
    {
      "epoch": 0.3578181226746905,
      "grad_norm": 0.5505008101463318,
      "learning_rate": 0.00022,
      "loss": 0.4299,
      "step": 8800
    },
    {
      "epoch": 0.36188423770508465,
      "grad_norm": 0.5524857640266418,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.4283,
      "step": 8900
    },
    {
      "epoch": 0.3659503527354789,
      "grad_norm": 0.5990288853645325,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.4274,
      "step": 9000
    },
    {
      "epoch": 0.3700164677658731,
      "grad_norm": 0.5520330667495728,
      "learning_rate": 0.0002275,
      "loss": 0.431,
      "step": 9100
    },
    {
      "epoch": 0.3740825827962673,
      "grad_norm": 0.48466745018959045,
      "learning_rate": 0.00023,
      "loss": 0.4286,
      "step": 9200
    },
    {
      "epoch": 0.3781486978266615,
      "grad_norm": 0.5233660936355591,
      "learning_rate": 0.0002325,
      "loss": 0.4292,
      "step": 9300
    },
    {
      "epoch": 0.3822148128570557,
      "grad_norm": 0.5394457578659058,
      "learning_rate": 0.000235,
      "loss": 0.4278,
      "step": 9400
    },
    {
      "epoch": 0.38628092788744994,
      "grad_norm": 0.48795294761657715,
      "learning_rate": 0.0002375,
      "loss": 0.4245,
      "step": 9500
    },
    {
      "epoch": 0.39034704291784417,
      "grad_norm": 0.5479927659034729,
      "learning_rate": 0.00024,
      "loss": 0.4271,
      "step": 9600
    },
    {
      "epoch": 0.39441315794823834,
      "grad_norm": 0.5975185632705688,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.4248,
      "step": 9700
    },
    {
      "epoch": 0.39847927297863256,
      "grad_norm": 0.486613929271698,
      "learning_rate": 0.000245,
      "loss": 0.424,
      "step": 9800
    },
    {
      "epoch": 0.4025453880090268,
      "grad_norm": 0.46277645230293274,
      "learning_rate": 0.0002475,
      "loss": 0.4295,
      "step": 9900
    },
    {
      "epoch": 0.406611503039421,
      "grad_norm": 0.5446270704269409,
      "learning_rate": 0.00025,
      "loss": 0.4266,
      "step": 10000
    },
    {
      "epoch": 0.406611503039421,
      "eval_loss": 0.43588852882385254,
      "eval_runtime": 115.364,
      "eval_samples_per_second": 1516.088,
      "eval_steps_per_second": 47.38,
      "step": 10000
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.4750821590423584,
      "learning_rate": 0.0002525,
      "loss": 0.4269,
      "step": 10100
    },
    {
      "epoch": 0.4147437331002094,
      "grad_norm": 0.4903978705406189,
      "learning_rate": 0.000255,
      "loss": 0.4281,
      "step": 10200
    },
    {
      "epoch": 0.4188098481306036,
      "grad_norm": 0.5071595907211304,
      "learning_rate": 0.0002575,
      "loss": 0.4279,
      "step": 10300
    },
    {
      "epoch": 0.42287596316099785,
      "grad_norm": 0.4889628291130066,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.4243,
      "step": 10400
    },
    {
      "epoch": 0.426942078191392,
      "grad_norm": 0.4364863932132721,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.4252,
      "step": 10500
    },
    {
      "epoch": 0.43100819322178624,
      "grad_norm": 0.49759697914123535,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.4252,
      "step": 10600
    },
    {
      "epoch": 0.43507430825218046,
      "grad_norm": 0.506494402885437,
      "learning_rate": 0.0002675,
      "loss": 0.4251,
      "step": 10700
    },
    {
      "epoch": 0.4391404232825747,
      "grad_norm": 0.4137466251850128,
      "learning_rate": 0.00027,
      "loss": 0.4234,
      "step": 10800
    },
    {
      "epoch": 0.44320653831296886,
      "grad_norm": 0.4300316274166107,
      "learning_rate": 0.0002725,
      "loss": 0.4239,
      "step": 10900
    },
    {
      "epoch": 0.4472726533433631,
      "grad_norm": 0.4537610709667206,
      "learning_rate": 0.000275,
      "loss": 0.4241,
      "step": 11000
    },
    {
      "epoch": 0.4513387683737573,
      "grad_norm": 0.4100078046321869,
      "learning_rate": 0.0002775,
      "loss": 0.4209,
      "step": 11100
    },
    {
      "epoch": 0.45540488340415153,
      "grad_norm": 0.3993714153766632,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4255,
      "step": 11200
    },
    {
      "epoch": 0.4594709984345457,
      "grad_norm": 0.433430016040802,
      "learning_rate": 0.0002825,
      "loss": 0.4233,
      "step": 11300
    },
    {
      "epoch": 0.4635371134649399,
      "grad_norm": 0.39689740538597107,
      "learning_rate": 0.000285,
      "loss": 0.4208,
      "step": 11400
    },
    {
      "epoch": 0.46760322849533414,
      "grad_norm": 0.4453434646129608,
      "learning_rate": 0.0002875,
      "loss": 0.4225,
      "step": 11500
    },
    {
      "epoch": 0.47166934352572837,
      "grad_norm": 0.3745480477809906,
      "learning_rate": 0.00029,
      "loss": 0.4185,
      "step": 11600
    },
    {
      "epoch": 0.47573545855612254,
      "grad_norm": 0.4014011323451996,
      "learning_rate": 0.0002925,
      "loss": 0.4208,
      "step": 11700
    },
    {
      "epoch": 0.47980157358651676,
      "grad_norm": 0.44006776809692383,
      "learning_rate": 0.000295,
      "loss": 0.419,
      "step": 11800
    },
    {
      "epoch": 0.483867688616911,
      "grad_norm": 0.40986520051956177,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4191,
      "step": 11900
    },
    {
      "epoch": 0.4879338036473052,
      "grad_norm": 0.3907774090766907,
      "learning_rate": 0.0003,
      "loss": 0.4191,
      "step": 12000
    },
    {
      "epoch": 0.4879338036473052,
      "eval_loss": 0.42990589141845703,
      "eval_runtime": 115.1225,
      "eval_samples_per_second": 1519.268,
      "eval_steps_per_second": 47.48,
      "step": 12000
    },
    {
      "epoch": 0.4919999186776994,
      "grad_norm": 0.3849904537200928,
      "learning_rate": 0.0003025,
      "loss": 0.4194,
      "step": 12100
    },
    {
      "epoch": 0.4960660337080936,
      "grad_norm": 0.3354912996292114,
      "learning_rate": 0.000305,
      "loss": 0.415,
      "step": 12200
    },
    {
      "epoch": 0.5001321487384878,
      "grad_norm": 0.37670430541038513,
      "learning_rate": 0.0003075,
      "loss": 0.4201,
      "step": 12300
    },
    {
      "epoch": 0.504198263768882,
      "grad_norm": 0.4008634388446808,
      "learning_rate": 0.00031,
      "loss": 0.4198,
      "step": 12400
    },
    {
      "epoch": 0.5082643787992762,
      "grad_norm": 0.44725126028060913,
      "learning_rate": 0.0003125,
      "loss": 0.4194,
      "step": 12500
    },
    {
      "epoch": 0.5123304938296704,
      "grad_norm": 0.4243372082710266,
      "learning_rate": 0.000315,
      "loss": 0.419,
      "step": 12600
    },
    {
      "epoch": 0.5163966088600647,
      "grad_norm": 0.36304807662963867,
      "learning_rate": 0.0003175,
      "loss": 0.4179,
      "step": 12700
    },
    {
      "epoch": 0.5204627238904589,
      "grad_norm": 0.38324400782585144,
      "learning_rate": 0.00032,
      "loss": 0.4198,
      "step": 12800
    },
    {
      "epoch": 0.5245288389208531,
      "grad_norm": 0.3876791298389435,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4182,
      "step": 12900
    },
    {
      "epoch": 0.5285949539512472,
      "grad_norm": 0.3769877254962921,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.419,
      "step": 13000
    },
    {
      "epoch": 0.5326610689816415,
      "grad_norm": 0.39000850915908813,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4187,
      "step": 13100
    },
    {
      "epoch": 0.5367271840120357,
      "grad_norm": 0.39270156621932983,
      "learning_rate": 0.00033,
      "loss": 0.4173,
      "step": 13200
    },
    {
      "epoch": 0.5407932990424299,
      "grad_norm": 0.3740001618862152,
      "learning_rate": 0.0003325,
      "loss": 0.4159,
      "step": 13300
    },
    {
      "epoch": 0.5448594140728241,
      "grad_norm": 0.3899476230144501,
      "learning_rate": 0.000335,
      "loss": 0.4177,
      "step": 13400
    },
    {
      "epoch": 0.5489255291032183,
      "grad_norm": 0.3702395260334015,
      "learning_rate": 0.0003375,
      "loss": 0.4155,
      "step": 13500
    },
    {
      "epoch": 0.5529916441336126,
      "grad_norm": 0.355283260345459,
      "learning_rate": 0.00034,
      "loss": 0.4158,
      "step": 13600
    },
    {
      "epoch": 0.5570577591640068,
      "grad_norm": 0.34076550602912903,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.4171,
      "step": 13700
    },
    {
      "epoch": 0.5611238741944009,
      "grad_norm": 0.34600362181663513,
      "learning_rate": 0.000345,
      "loss": 0.4173,
      "step": 13800
    },
    {
      "epoch": 0.5651899892247951,
      "grad_norm": 0.3470120429992676,
      "learning_rate": 0.0003475,
      "loss": 0.4171,
      "step": 13900
    },
    {
      "epoch": 0.5692561042551894,
      "grad_norm": 0.3207454979419708,
      "learning_rate": 0.00035,
      "loss": 0.4184,
      "step": 14000
    },
    {
      "epoch": 0.5692561042551894,
      "eval_loss": 0.4247422218322754,
      "eval_runtime": 115.7529,
      "eval_samples_per_second": 1510.994,
      "eval_steps_per_second": 47.221,
      "step": 14000
    },
    {
      "epoch": 0.5733222192855836,
      "grad_norm": 0.3394209146499634,
      "learning_rate": 0.0003525,
      "loss": 0.4169,
      "step": 14100
    },
    {
      "epoch": 0.5773883343159778,
      "grad_norm": 0.36609774827957153,
      "learning_rate": 0.000355,
      "loss": 0.4174,
      "step": 14200
    },
    {
      "epoch": 0.581454449346372,
      "grad_norm": 0.3040808439254761,
      "learning_rate": 0.0003575,
      "loss": 0.4156,
      "step": 14300
    },
    {
      "epoch": 0.5855205643767663,
      "grad_norm": 0.3283648192882538,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4157,
      "step": 14400
    },
    {
      "epoch": 0.5895866794071605,
      "grad_norm": 0.3332371413707733,
      "learning_rate": 0.0003625,
      "loss": 0.4144,
      "step": 14500
    },
    {
      "epoch": 0.5936527944375546,
      "grad_norm": 0.34223929047584534,
      "learning_rate": 0.000365,
      "loss": 0.4158,
      "step": 14600
    },
    {
      "epoch": 0.5977189094679488,
      "grad_norm": 0.32955223321914673,
      "learning_rate": 0.0003675,
      "loss": 0.4165,
      "step": 14700
    },
    {
      "epoch": 0.601785024498343,
      "grad_norm": 0.30982160568237305,
      "learning_rate": 0.00037,
      "loss": 0.4121,
      "step": 14800
    },
    {
      "epoch": 0.6058511395287373,
      "grad_norm": 0.31580308079719543,
      "learning_rate": 0.0003725,
      "loss": 0.4122,
      "step": 14900
    },
    {
      "epoch": 0.6099172545591315,
      "grad_norm": 0.30788376927375793,
      "learning_rate": 0.000375,
      "loss": 0.4144,
      "step": 15000
    },
    {
      "epoch": 0.6139833695895257,
      "grad_norm": 0.3952203392982483,
      "learning_rate": 0.0003775,
      "loss": 0.4123,
      "step": 15100
    },
    {
      "epoch": 0.6180494846199199,
      "grad_norm": 0.3201090693473816,
      "learning_rate": 0.00038,
      "loss": 0.4131,
      "step": 15200
    },
    {
      "epoch": 0.6221155996503142,
      "grad_norm": 0.3368696868419647,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4152,
      "step": 15300
    },
    {
      "epoch": 0.6261817146807083,
      "grad_norm": 0.28609439730644226,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4114,
      "step": 15400
    },
    {
      "epoch": 0.6302478297111025,
      "grad_norm": 0.3080110251903534,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4115,
      "step": 15500
    },
    {
      "epoch": 0.6343139447414967,
      "grad_norm": 0.3163575232028961,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4112,
      "step": 15600
    },
    {
      "epoch": 0.6383800597718909,
      "grad_norm": 0.4071381092071533,
      "learning_rate": 0.0003925,
      "loss": 0.4095,
      "step": 15700
    },
    {
      "epoch": 0.6424461748022852,
      "grad_norm": 0.31107789278030396,
      "learning_rate": 0.000395,
      "loss": 0.4114,
      "step": 15800
    },
    {
      "epoch": 0.6465122898326794,
      "grad_norm": 0.30963343381881714,
      "learning_rate": 0.0003975,
      "loss": 0.4116,
      "step": 15900
    },
    {
      "epoch": 0.6505784048630736,
      "grad_norm": 0.33777573704719543,
      "learning_rate": 0.0004,
      "loss": 0.4121,
      "step": 16000
    },
    {
      "epoch": 0.6505784048630736,
      "eval_loss": 0.42282503843307495,
      "eval_runtime": 115.5417,
      "eval_samples_per_second": 1513.756,
      "eval_steps_per_second": 47.308,
      "step": 16000
    },
    {
      "epoch": 0.6546445198934678,
      "grad_norm": 0.33759331703186035,
      "learning_rate": 0.0004025,
      "loss": 0.4143,
      "step": 16100
    },
    {
      "epoch": 0.658710634923862,
      "grad_norm": 0.27490076422691345,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.4132,
      "step": 16200
    },
    {
      "epoch": 0.6627767499542562,
      "grad_norm": 0.30368903279304504,
      "learning_rate": 0.0004075,
      "loss": 0.4124,
      "step": 16300
    },
    {
      "epoch": 0.6668428649846504,
      "grad_norm": 0.3006623089313507,
      "learning_rate": 0.00041,
      "loss": 0.412,
      "step": 16400
    },
    {
      "epoch": 0.6709089800150446,
      "grad_norm": 0.27515432238578796,
      "learning_rate": 0.0004125,
      "loss": 0.4126,
      "step": 16500
    },
    {
      "epoch": 0.6749750950454388,
      "grad_norm": 0.2777060568332672,
      "learning_rate": 0.000415,
      "loss": 0.4119,
      "step": 16600
    },
    {
      "epoch": 0.6790412100758331,
      "grad_norm": 0.291495144367218,
      "learning_rate": 0.0004175,
      "loss": 0.4106,
      "step": 16700
    },
    {
      "epoch": 0.6831073251062273,
      "grad_norm": 0.2704944312572479,
      "learning_rate": 0.00042,
      "loss": 0.41,
      "step": 16800
    },
    {
      "epoch": 0.6871734401366215,
      "grad_norm": 0.2568066716194153,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4108,
      "step": 16900
    },
    {
      "epoch": 0.6912395551670156,
      "grad_norm": 0.324282169342041,
      "learning_rate": 0.000425,
      "loss": 0.4102,
      "step": 17000
    },
    {
      "epoch": 0.6953056701974099,
      "grad_norm": 0.26665806770324707,
      "learning_rate": 0.0004275,
      "loss": 0.4129,
      "step": 17100
    },
    {
      "epoch": 0.6993717852278041,
      "grad_norm": 0.3017977774143219,
      "learning_rate": 0.00043,
      "loss": 0.4129,
      "step": 17200
    },
    {
      "epoch": 0.7034379002581983,
      "grad_norm": 0.27829596400260925,
      "learning_rate": 0.0004325,
      "loss": 0.4117,
      "step": 17300
    },
    {
      "epoch": 0.7075040152885925,
      "grad_norm": 0.2747747004032135,
      "learning_rate": 0.000435,
      "loss": 0.4111,
      "step": 17400
    },
    {
      "epoch": 0.7115701303189867,
      "grad_norm": 0.28861677646636963,
      "learning_rate": 0.0004375,
      "loss": 0.4085,
      "step": 17500
    },
    {
      "epoch": 0.715636245349381,
      "grad_norm": 0.3031631112098694,
      "learning_rate": 0.00044,
      "loss": 0.4109,
      "step": 17600
    },
    {
      "epoch": 0.7197023603797752,
      "grad_norm": 0.2674330472946167,
      "learning_rate": 0.0004425,
      "loss": 0.4078,
      "step": 17700
    },
    {
      "epoch": 0.7237684754101693,
      "grad_norm": 0.2854030132293701,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4115,
      "step": 17800
    },
    {
      "epoch": 0.7278345904405635,
      "grad_norm": 0.3138562738895416,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4091,
      "step": 17900
    },
    {
      "epoch": 0.7319007054709578,
      "grad_norm": 0.2710529565811157,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4099,
      "step": 18000
    },
    {
      "epoch": 0.7319007054709578,
      "eval_loss": 0.41602832078933716,
      "eval_runtime": 114.4566,
      "eval_samples_per_second": 1528.107,
      "eval_steps_per_second": 47.756,
      "step": 18000
    },
    {
      "epoch": 0.735966820501352,
      "grad_norm": 0.2729651629924774,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4063,
      "step": 18100
    },
    {
      "epoch": 0.7400329355317462,
      "grad_norm": 0.2682195007801056,
      "learning_rate": 0.000455,
      "loss": 0.4095,
      "step": 18200
    },
    {
      "epoch": 0.7440990505621404,
      "grad_norm": 0.24122586846351624,
      "learning_rate": 0.0004575,
      "loss": 0.4079,
      "step": 18300
    },
    {
      "epoch": 0.7481651655925347,
      "grad_norm": 0.26061636209487915,
      "learning_rate": 0.00046,
      "loss": 0.4091,
      "step": 18400
    },
    {
      "epoch": 0.7522312806229289,
      "grad_norm": 0.23798462748527527,
      "learning_rate": 0.0004625,
      "loss": 0.4061,
      "step": 18500
    },
    {
      "epoch": 0.756297395653323,
      "grad_norm": 0.26812419295310974,
      "learning_rate": 0.000465,
      "loss": 0.4073,
      "step": 18600
    },
    {
      "epoch": 0.7603635106837172,
      "grad_norm": 0.2469739019870758,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.4095,
      "step": 18700
    },
    {
      "epoch": 0.7644296257141114,
      "grad_norm": 0.23964785039424896,
      "learning_rate": 0.00047,
      "loss": 0.4089,
      "step": 18800
    },
    {
      "epoch": 0.7684957407445057,
      "grad_norm": 0.23171930015087128,
      "learning_rate": 0.0004725,
      "loss": 0.4089,
      "step": 18900
    },
    {
      "epoch": 0.7725618557748999,
      "grad_norm": 0.23331187665462494,
      "learning_rate": 0.000475,
      "loss": 0.4051,
      "step": 19000
    },
    {
      "epoch": 0.7766279708052941,
      "grad_norm": 0.24047943949699402,
      "learning_rate": 0.0004775,
      "loss": 0.4069,
      "step": 19100
    },
    {
      "epoch": 0.7806940858356883,
      "grad_norm": 0.3073537051677704,
      "learning_rate": 0.00048,
      "loss": 0.4077,
      "step": 19200
    },
    {
      "epoch": 0.7847602008660824,
      "grad_norm": 0.25104475021362305,
      "learning_rate": 0.0004825,
      "loss": 0.4104,
      "step": 19300
    },
    {
      "epoch": 0.7888263158964767,
      "grad_norm": 0.2685813307762146,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.4077,
      "step": 19400
    },
    {
      "epoch": 0.7928924309268709,
      "grad_norm": 0.21908247470855713,
      "learning_rate": 0.0004875,
      "loss": 0.4054,
      "step": 19500
    },
    {
      "epoch": 0.7969585459572651,
      "grad_norm": 0.2635134756565094,
      "learning_rate": 0.00049,
      "loss": 0.4062,
      "step": 19600
    },
    {
      "epoch": 0.8010246609876593,
      "grad_norm": 0.279317170381546,
      "learning_rate": 0.0004925,
      "loss": 0.4051,
      "step": 19700
    },
    {
      "epoch": 0.8050907760180536,
      "grad_norm": 0.2287137657403946,
      "learning_rate": 0.000495,
      "loss": 0.4065,
      "step": 19800
    },
    {
      "epoch": 0.8091568910484478,
      "grad_norm": 0.23354190587997437,
      "learning_rate": 0.0004975,
      "loss": 0.4065,
      "step": 19900
    },
    {
      "epoch": 0.813223006078842,
      "grad_norm": 0.23355546593666077,
      "learning_rate": 0.0005,
      "loss": 0.4064,
      "step": 20000
    },
    {
      "epoch": 0.813223006078842,
      "eval_loss": 0.41507044434547424,
      "eval_runtime": 114.7097,
      "eval_samples_per_second": 1524.736,
      "eval_steps_per_second": 47.651,
      "step": 20000
    },
    {
      "epoch": 0.8172891211092361,
      "grad_norm": 0.23486267030239105,
      "learning_rate": 0.0004997786925153809,
      "loss": 0.4071,
      "step": 20100
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.23395879566669464,
      "learning_rate": 0.0004995573850307618,
      "loss": 0.4078,
      "step": 20200
    },
    {
      "epoch": 0.8254213511700246,
      "grad_norm": 0.2357521951198578,
      "learning_rate": 0.0004993360775461426,
      "loss": 0.4023,
      "step": 20300
    },
    {
      "epoch": 0.8294874662004188,
      "grad_norm": 0.20861957967281342,
      "learning_rate": 0.0004991147700615235,
      "loss": 0.405,
      "step": 20400
    },
    {
      "epoch": 0.833553581230813,
      "grad_norm": 0.22703975439071655,
      "learning_rate": 0.0004988934625769043,
      "loss": 0.4033,
      "step": 20500
    },
    {
      "epoch": 0.8376196962612072,
      "grad_norm": 0.20942482352256775,
      "learning_rate": 0.0004986721550922853,
      "loss": 0.4037,
      "step": 20600
    },
    {
      "epoch": 0.8416858112916015,
      "grad_norm": 0.24516554176807404,
      "learning_rate": 0.0004984508476076661,
      "loss": 0.4051,
      "step": 20700
    },
    {
      "epoch": 0.8457519263219957,
      "grad_norm": 0.22122535109519958,
      "learning_rate": 0.000498229540123047,
      "loss": 0.4052,
      "step": 20800
    },
    {
      "epoch": 0.8498180413523898,
      "grad_norm": 0.22153393924236298,
      "learning_rate": 0.0004980082326384278,
      "loss": 0.4039,
      "step": 20900
    },
    {
      "epoch": 0.853884156382784,
      "grad_norm": 0.20121517777442932,
      "learning_rate": 0.0004977869251538087,
      "loss": 0.4028,
      "step": 21000
    },
    {
      "epoch": 0.8579502714131783,
      "grad_norm": 0.2174122929573059,
      "learning_rate": 0.0004975656176691896,
      "loss": 0.4033,
      "step": 21100
    },
    {
      "epoch": 0.8620163864435725,
      "grad_norm": 0.2276206761598587,
      "learning_rate": 0.0004973443101845705,
      "loss": 0.401,
      "step": 21200
    },
    {
      "epoch": 0.8660825014739667,
      "grad_norm": 0.20975667238235474,
      "learning_rate": 0.0004971230026999513,
      "loss": 0.4009,
      "step": 21300
    },
    {
      "epoch": 0.8701486165043609,
      "grad_norm": 0.21153944730758667,
      "learning_rate": 0.0004969016952153321,
      "loss": 0.4033,
      "step": 21400
    },
    {
      "epoch": 0.8742147315347552,
      "grad_norm": 0.21933691203594208,
      "learning_rate": 0.0004966803877307131,
      "loss": 0.4016,
      "step": 21500
    },
    {
      "epoch": 0.8782808465651494,
      "grad_norm": 0.21472114324569702,
      "learning_rate": 0.0004964590802460939,
      "loss": 0.4014,
      "step": 21600
    },
    {
      "epoch": 0.8823469615955435,
      "grad_norm": 0.21596239507198334,
      "learning_rate": 0.0004962377727614748,
      "loss": 0.4006,
      "step": 21700
    },
    {
      "epoch": 0.8864130766259377,
      "grad_norm": 0.2012123167514801,
      "learning_rate": 0.0004960164652768557,
      "loss": 0.4,
      "step": 21800
    },
    {
      "epoch": 0.8904791916563319,
      "grad_norm": 0.21489907801151276,
      "learning_rate": 0.0004957951577922366,
      "loss": 0.4012,
      "step": 21900
    },
    {
      "epoch": 0.8945453066867262,
      "grad_norm": 0.20549796521663666,
      "learning_rate": 0.0004955738503076174,
      "loss": 0.3995,
      "step": 22000
    },
    {
      "epoch": 0.8945453066867262,
      "eval_loss": 0.41009917855262756,
      "eval_runtime": 114.6806,
      "eval_samples_per_second": 1525.123,
      "eval_steps_per_second": 47.663,
      "step": 22000
    },
    {
      "epoch": 0.8986114217171204,
      "grad_norm": 0.20169606804847717,
      "learning_rate": 0.0004953525428229983,
      "loss": 0.3994,
      "step": 22100
    },
    {
      "epoch": 0.9026775367475146,
      "grad_norm": 0.23003177344799042,
      "learning_rate": 0.0004951312353383792,
      "loss": 0.403,
      "step": 22200
    },
    {
      "epoch": 0.9067436517779088,
      "grad_norm": 0.1925443857908249,
      "learning_rate": 0.00049490992785376,
      "loss": 0.4003,
      "step": 22300
    },
    {
      "epoch": 0.9108097668083031,
      "grad_norm": 0.22941887378692627,
      "learning_rate": 0.0004946886203691409,
      "loss": 0.3998,
      "step": 22400
    },
    {
      "epoch": 0.9148758818386972,
      "grad_norm": 0.21391268074512482,
      "learning_rate": 0.0004944673128845217,
      "loss": 0.4022,
      "step": 22500
    },
    {
      "epoch": 0.9189419968690914,
      "grad_norm": 0.20663103461265564,
      "learning_rate": 0.0004942460053999026,
      "loss": 0.3999,
      "step": 22600
    },
    {
      "epoch": 0.9230081118994856,
      "grad_norm": 0.19990111887454987,
      "learning_rate": 0.0004940246979152835,
      "loss": 0.3986,
      "step": 22700
    },
    {
      "epoch": 0.9270742269298798,
      "grad_norm": 0.21797074377536774,
      "learning_rate": 0.0004938033904306644,
      "loss": 0.4005,
      "step": 22800
    },
    {
      "epoch": 0.9311403419602741,
      "grad_norm": 0.19952081143856049,
      "learning_rate": 0.0004935820829460452,
      "loss": 0.3988,
      "step": 22900
    },
    {
      "epoch": 0.9352064569906683,
      "grad_norm": 0.19952768087387085,
      "learning_rate": 0.0004933607754614261,
      "loss": 0.3976,
      "step": 23000
    },
    {
      "epoch": 0.9392725720210625,
      "grad_norm": 0.22083796560764313,
      "learning_rate": 0.000493139467976807,
      "loss": 0.3972,
      "step": 23100
    },
    {
      "epoch": 0.9433386870514567,
      "grad_norm": 0.21690498292446136,
      "learning_rate": 0.0004929181604921879,
      "loss": 0.3984,
      "step": 23200
    },
    {
      "epoch": 0.9474048020818508,
      "grad_norm": 0.21176166832447052,
      "learning_rate": 0.0004926968530075687,
      "loss": 0.3994,
      "step": 23300
    },
    {
      "epoch": 0.9514709171122451,
      "grad_norm": 0.20995883643627167,
      "learning_rate": 0.0004924755455229495,
      "loss": 0.3968,
      "step": 23400
    },
    {
      "epoch": 0.9555370321426393,
      "grad_norm": 0.18676702678203583,
      "learning_rate": 0.0004922542380383305,
      "loss": 0.3972,
      "step": 23500
    },
    {
      "epoch": 0.9596031471730335,
      "grad_norm": 0.2108858823776245,
      "learning_rate": 0.0004920329305537113,
      "loss": 0.3961,
      "step": 23600
    },
    {
      "epoch": 0.9636692622034277,
      "grad_norm": 0.20143096148967743,
      "learning_rate": 0.0004918116230690922,
      "loss": 0.3985,
      "step": 23700
    },
    {
      "epoch": 0.967735377233822,
      "grad_norm": 0.21045394241809845,
      "learning_rate": 0.0004915903155844731,
      "loss": 0.398,
      "step": 23800
    },
    {
      "epoch": 0.9718014922642162,
      "grad_norm": 0.2080754041671753,
      "learning_rate": 0.000491369008099854,
      "loss": 0.395,
      "step": 23900
    },
    {
      "epoch": 0.9758676072946104,
      "grad_norm": 0.19599857926368713,
      "learning_rate": 0.0004911477006152348,
      "loss": 0.3957,
      "step": 24000
    },
    {
      "epoch": 0.9758676072946104,
      "eval_loss": 0.4053904116153717,
      "eval_runtime": 114.7835,
      "eval_samples_per_second": 1523.756,
      "eval_steps_per_second": 47.62,
      "step": 24000
    },
    {
      "epoch": 0.9799337223250045,
      "grad_norm": 0.19237534701824188,
      "learning_rate": 0.0004909263931306157,
      "loss": 0.397,
      "step": 24100
    },
    {
      "epoch": 0.9839998373553988,
      "grad_norm": 0.21442829072475433,
      "learning_rate": 0.0004907050856459966,
      "loss": 0.3955,
      "step": 24200
    },
    {
      "epoch": 0.988065952385793,
      "grad_norm": 0.1748465895652771,
      "learning_rate": 0.0004904837781613775,
      "loss": 0.3976,
      "step": 24300
    },
    {
      "epoch": 0.9921320674161872,
      "grad_norm": 0.18911339342594147,
      "learning_rate": 0.0004902624706767583,
      "loss": 0.3955,
      "step": 24400
    },
    {
      "epoch": 0.9961981824465814,
      "grad_norm": 0.1808893233537674,
      "learning_rate": 0.0004900411631921391,
      "loss": 0.3959,
      "step": 24500
    },
    {
      "epoch": 1.0002642974769755,
      "grad_norm": 0.2156887799501419,
      "learning_rate": 0.00048981985570752,
      "loss": 0.3937,
      "step": 24600
    },
    {
      "epoch": 1.0043304125073698,
      "grad_norm": 0.19942231476306915,
      "learning_rate": 0.0004895985482229009,
      "loss": 0.3925,
      "step": 24700
    },
    {
      "epoch": 1.008396527537764,
      "grad_norm": 0.20441943407058716,
      "learning_rate": 0.0004893772407382818,
      "loss": 0.3958,
      "step": 24800
    },
    {
      "epoch": 1.0124626425681582,
      "grad_norm": 0.20299358665943146,
      "learning_rate": 0.0004891559332536626,
      "loss": 0.3914,
      "step": 24900
    },
    {
      "epoch": 1.0165287575985524,
      "grad_norm": 0.1944577395915985,
      "learning_rate": 0.0004889346257690435,
      "loss": 0.3957,
      "step": 25000
    },
    {
      "epoch": 1.0205948726289467,
      "grad_norm": 0.21143145859241486,
      "learning_rate": 0.0004887133182844244,
      "loss": 0.3916,
      "step": 25100
    },
    {
      "epoch": 1.0246609876593409,
      "grad_norm": 0.20867140591144562,
      "learning_rate": 0.0004884920107998053,
      "loss": 0.3962,
      "step": 25200
    },
    {
      "epoch": 1.028727102689735,
      "grad_norm": 0.20373675227165222,
      "learning_rate": 0.00048827070331518616,
      "loss": 0.3936,
      "step": 25300
    },
    {
      "epoch": 1.0327932177201293,
      "grad_norm": 0.21514928340911865,
      "learning_rate": 0.000488049395830567,
      "loss": 0.3928,
      "step": 25400
    },
    {
      "epoch": 1.0368593327505236,
      "grad_norm": 0.1897260695695877,
      "learning_rate": 0.0004878280883459479,
      "loss": 0.3935,
      "step": 25500
    },
    {
      "epoch": 1.0409254477809178,
      "grad_norm": 0.20831899344921112,
      "learning_rate": 0.00048760678086132874,
      "loss": 0.3948,
      "step": 25600
    },
    {
      "epoch": 1.044991562811312,
      "grad_norm": 0.18770180642604828,
      "learning_rate": 0.00048738547337670964,
      "loss": 0.393,
      "step": 25700
    },
    {
      "epoch": 1.0490576778417062,
      "grad_norm": 0.18329425156116486,
      "learning_rate": 0.0004871641658920905,
      "loss": 0.3904,
      "step": 25800
    },
    {
      "epoch": 1.0531237928721005,
      "grad_norm": 0.20047630369663239,
      "learning_rate": 0.0004869428584074714,
      "loss": 0.3929,
      "step": 25900
    },
    {
      "epoch": 1.0571899079024947,
      "grad_norm": 0.20178240537643433,
      "learning_rate": 0.00048672155092285217,
      "loss": 0.3934,
      "step": 26000
    },
    {
      "epoch": 1.0571899079024947,
      "eval_loss": 0.4013574719429016,
      "eval_runtime": 114.1563,
      "eval_samples_per_second": 1532.127,
      "eval_steps_per_second": 47.882,
      "step": 26000
    },
    {
      "epoch": 1.0612560229328887,
      "grad_norm": 0.1829809844493866,
      "learning_rate": 0.00048650024343823307,
      "loss": 0.3919,
      "step": 26100
    },
    {
      "epoch": 1.065322137963283,
      "grad_norm": 0.1737442910671234,
      "learning_rate": 0.00048627893595361396,
      "loss": 0.3909,
      "step": 26200
    },
    {
      "epoch": 1.0693882529936771,
      "grad_norm": 0.19208121299743652,
      "learning_rate": 0.0004860576284689948,
      "loss": 0.3911,
      "step": 26300
    },
    {
      "epoch": 1.0734543680240713,
      "grad_norm": 0.19264549016952515,
      "learning_rate": 0.0004858363209843757,
      "loss": 0.3922,
      "step": 26400
    },
    {
      "epoch": 1.0775204830544656,
      "grad_norm": 0.19856759905815125,
      "learning_rate": 0.00048561501349975655,
      "loss": 0.3908,
      "step": 26500
    },
    {
      "epoch": 1.0815865980848598,
      "grad_norm": 0.1924763023853302,
      "learning_rate": 0.00048539370601513744,
      "loss": 0.3891,
      "step": 26600
    },
    {
      "epoch": 1.085652713115254,
      "grad_norm": 0.1867634803056717,
      "learning_rate": 0.0004851723985305183,
      "loss": 0.3905,
      "step": 26700
    },
    {
      "epoch": 1.0897188281456482,
      "grad_norm": 0.1788310706615448,
      "learning_rate": 0.0004849510910458992,
      "loss": 0.3887,
      "step": 26800
    },
    {
      "epoch": 1.0937849431760425,
      "grad_norm": 0.1915632039308548,
      "learning_rate": 0.0004847297835612801,
      "loss": 0.3917,
      "step": 26900
    },
    {
      "epoch": 1.0978510582064367,
      "grad_norm": 0.1805000752210617,
      "learning_rate": 0.0004845084760766609,
      "loss": 0.3896,
      "step": 27000
    },
    {
      "epoch": 1.101917173236831,
      "grad_norm": 0.18276706337928772,
      "learning_rate": 0.0004842871685920418,
      "loss": 0.3909,
      "step": 27100
    },
    {
      "epoch": 1.1059832882672251,
      "grad_norm": 0.19559121131896973,
      "learning_rate": 0.00048406586110742267,
      "loss": 0.3898,
      "step": 27200
    },
    {
      "epoch": 1.1100494032976194,
      "grad_norm": 0.1900382936000824,
      "learning_rate": 0.00048384455362280356,
      "loss": 0.3936,
      "step": 27300
    },
    {
      "epoch": 1.1141155183280136,
      "grad_norm": 0.1768520325422287,
      "learning_rate": 0.0004836232461381844,
      "loss": 0.389,
      "step": 27400
    },
    {
      "epoch": 1.1181816333584078,
      "grad_norm": 0.17729391157627106,
      "learning_rate": 0.0004834019386535653,
      "loss": 0.3882,
      "step": 27500
    },
    {
      "epoch": 1.1222477483888018,
      "grad_norm": 0.21324557065963745,
      "learning_rate": 0.0004831806311689461,
      "loss": 0.3881,
      "step": 27600
    },
    {
      "epoch": 1.126313863419196,
      "grad_norm": 0.18987520039081573,
      "learning_rate": 0.000482959323684327,
      "loss": 0.3904,
      "step": 27700
    },
    {
      "epoch": 1.1303799784495903,
      "grad_norm": 0.19099543988704681,
      "learning_rate": 0.0004827380161997079,
      "loss": 0.3915,
      "step": 27800
    },
    {
      "epoch": 1.1344460934799845,
      "grad_norm": 0.185352623462677,
      "learning_rate": 0.00048251670871508873,
      "loss": 0.3884,
      "step": 27900
    },
    {
      "epoch": 1.1385122085103787,
      "grad_norm": 0.1716231107711792,
      "learning_rate": 0.00048229540123046963,
      "loss": 0.3903,
      "step": 28000
    },
    {
      "epoch": 1.1385122085103787,
      "eval_loss": 0.39894983172416687,
      "eval_runtime": 112.3814,
      "eval_samples_per_second": 1556.324,
      "eval_steps_per_second": 48.638,
      "step": 28000
    },
    {
      "epoch": 1.142578323540773,
      "grad_norm": 0.20383374392986298,
      "learning_rate": 0.00048207409374585047,
      "loss": 0.3891,
      "step": 28100
    },
    {
      "epoch": 1.1466444385711672,
      "grad_norm": 0.1869611293077469,
      "learning_rate": 0.00048185278626123137,
      "loss": 0.3902,
      "step": 28200
    },
    {
      "epoch": 1.1507105536015614,
      "grad_norm": 0.18795308470726013,
      "learning_rate": 0.0004816314787766122,
      "loss": 0.3873,
      "step": 28300
    },
    {
      "epoch": 1.1547766686319556,
      "grad_norm": 0.17276181280612946,
      "learning_rate": 0.0004814101712919931,
      "loss": 0.3896,
      "step": 28400
    },
    {
      "epoch": 1.1588427836623498,
      "grad_norm": 0.17622126638889313,
      "learning_rate": 0.00048118886380737395,
      "loss": 0.388,
      "step": 28500
    },
    {
      "epoch": 1.162908898692744,
      "grad_norm": 0.1715763807296753,
      "learning_rate": 0.00048096755632275485,
      "loss": 0.3898,
      "step": 28600
    },
    {
      "epoch": 1.1669750137231383,
      "grad_norm": 0.1733582466840744,
      "learning_rate": 0.00048074624883813575,
      "loss": 0.387,
      "step": 28700
    },
    {
      "epoch": 1.1710411287535325,
      "grad_norm": 0.1893639862537384,
      "learning_rate": 0.0004805249413535166,
      "loss": 0.388,
      "step": 28800
    },
    {
      "epoch": 1.1751072437839267,
      "grad_norm": 0.1622404307126999,
      "learning_rate": 0.0004803036338688975,
      "loss": 0.3893,
      "step": 28900
    },
    {
      "epoch": 1.179173358814321,
      "grad_norm": 0.17029669880867004,
      "learning_rate": 0.00048008232638427833,
      "loss": 0.3881,
      "step": 29000
    },
    {
      "epoch": 1.183239473844715,
      "grad_norm": 0.18705472350120544,
      "learning_rate": 0.00047986101889965923,
      "loss": 0.3908,
      "step": 29100
    },
    {
      "epoch": 1.1873055888751094,
      "grad_norm": 0.1944507509469986,
      "learning_rate": 0.00047963971141504007,
      "loss": 0.3876,
      "step": 29200
    },
    {
      "epoch": 1.1913717039055034,
      "grad_norm": 0.1654045581817627,
      "learning_rate": 0.0004794184039304209,
      "loss": 0.3892,
      "step": 29300
    },
    {
      "epoch": 1.1954378189358976,
      "grad_norm": 0.17419151961803436,
      "learning_rate": 0.00047919709644580176,
      "loss": 0.3883,
      "step": 29400
    },
    {
      "epoch": 1.1995039339662918,
      "grad_norm": 0.18709313869476318,
      "learning_rate": 0.00047897578896118265,
      "loss": 0.3898,
      "step": 29500
    },
    {
      "epoch": 1.203570048996686,
      "grad_norm": 0.17426255345344543,
      "learning_rate": 0.00047875448147656355,
      "loss": 0.3883,
      "step": 29600
    },
    {
      "epoch": 1.2076361640270803,
      "grad_norm": 0.17559853196144104,
      "learning_rate": 0.0004785331739919444,
      "loss": 0.3858,
      "step": 29700
    },
    {
      "epoch": 1.2117022790574745,
      "grad_norm": 0.22696100175380707,
      "learning_rate": 0.0004783118665073253,
      "loss": 0.388,
      "step": 29800
    },
    {
      "epoch": 1.2157683940878687,
      "grad_norm": 0.17288334667682648,
      "learning_rate": 0.00047809055902270614,
      "loss": 0.3887,
      "step": 29900
    },
    {
      "epoch": 1.219834509118263,
      "grad_norm": 0.17320986092090607,
      "learning_rate": 0.00047786925153808703,
      "loss": 0.3868,
      "step": 30000
    },
    {
      "epoch": 1.219834509118263,
      "eval_loss": 0.3975684940814972,
      "eval_runtime": 114.5417,
      "eval_samples_per_second": 1526.973,
      "eval_steps_per_second": 47.721,
      "step": 30000
    },
    {
      "epoch": 1.2239006241486572,
      "grad_norm": 0.18330956995487213,
      "learning_rate": 0.0004776479440534679,
      "loss": 0.3861,
      "step": 30100
    },
    {
      "epoch": 1.2279667391790514,
      "grad_norm": 0.19141368567943573,
      "learning_rate": 0.0004774266365688488,
      "loss": 0.387,
      "step": 30200
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.18578603863716125,
      "learning_rate": 0.00047720532908422967,
      "loss": 0.3843,
      "step": 30300
    },
    {
      "epoch": 1.2360989692398399,
      "grad_norm": 0.16943709552288055,
      "learning_rate": 0.0004769840215996105,
      "loss": 0.389,
      "step": 30400
    },
    {
      "epoch": 1.240165084270234,
      "grad_norm": 0.174601212143898,
      "learning_rate": 0.0004767627141149914,
      "loss": 0.3863,
      "step": 30500
    },
    {
      "epoch": 1.2442311993006283,
      "grad_norm": 0.19196252524852753,
      "learning_rate": 0.00047654140663037225,
      "loss": 0.3862,
      "step": 30600
    },
    {
      "epoch": 1.2482973143310225,
      "grad_norm": 0.18373489379882812,
      "learning_rate": 0.00047632009914575315,
      "loss": 0.385,
      "step": 30700
    },
    {
      "epoch": 1.2523634293614165,
      "grad_norm": 0.19795401394367218,
      "learning_rate": 0.000476098791661134,
      "loss": 0.388,
      "step": 30800
    },
    {
      "epoch": 1.256429544391811,
      "grad_norm": 0.17174135148525238,
      "learning_rate": 0.0004758774841765149,
      "loss": 0.3876,
      "step": 30900
    },
    {
      "epoch": 1.260495659422205,
      "grad_norm": 0.17286458611488342,
      "learning_rate": 0.0004756561766918957,
      "loss": 0.3854,
      "step": 31000
    },
    {
      "epoch": 1.2645617744525992,
      "grad_norm": 0.1656242460012436,
      "learning_rate": 0.0004754348692072766,
      "loss": 0.3871,
      "step": 31100
    },
    {
      "epoch": 1.2686278894829934,
      "grad_norm": 0.1837512105703354,
      "learning_rate": 0.0004752135617226575,
      "loss": 0.3851,
      "step": 31200
    },
    {
      "epoch": 1.2726940045133877,
      "grad_norm": 0.16999328136444092,
      "learning_rate": 0.0004749922542380383,
      "loss": 0.3849,
      "step": 31300
    },
    {
      "epoch": 1.2767601195437819,
      "grad_norm": 0.16666865348815918,
      "learning_rate": 0.0004747709467534192,
      "loss": 0.3879,
      "step": 31400
    },
    {
      "epoch": 1.280826234574176,
      "grad_norm": 0.1580633968114853,
      "learning_rate": 0.00047454963926880006,
      "loss": 0.3832,
      "step": 31500
    },
    {
      "epoch": 1.2848923496045703,
      "grad_norm": 0.17203180491924286,
      "learning_rate": 0.00047432833178418096,
      "loss": 0.3855,
      "step": 31600
    },
    {
      "epoch": 1.2889584646349646,
      "grad_norm": 0.16532829403877258,
      "learning_rate": 0.0004741070242995618,
      "loss": 0.3853,
      "step": 31700
    },
    {
      "epoch": 1.2930245796653588,
      "grad_norm": 0.18286938965320587,
      "learning_rate": 0.0004738857168149427,
      "loss": 0.3828,
      "step": 31800
    },
    {
      "epoch": 1.297090694695753,
      "grad_norm": 0.19544841349124908,
      "learning_rate": 0.00047366440933032354,
      "loss": 0.3874,
      "step": 31900
    },
    {
      "epoch": 1.3011568097261472,
      "grad_norm": 0.20190289616584778,
      "learning_rate": 0.00047344310184570444,
      "loss": 0.3858,
      "step": 32000
    },
    {
      "epoch": 1.3011568097261472,
      "eval_loss": 0.3957645893096924,
      "eval_runtime": 115.4925,
      "eval_samples_per_second": 1514.401,
      "eval_steps_per_second": 47.328,
      "step": 32000
    },
    {
      "epoch": 1.3052229247565412,
      "grad_norm": 0.1813504993915558,
      "learning_rate": 0.00047322179436108533,
      "loss": 0.385,
      "step": 32100
    },
    {
      "epoch": 1.3092890397869357,
      "grad_norm": 0.1654704213142395,
      "learning_rate": 0.0004730004868764662,
      "loss": 0.3848,
      "step": 32200
    },
    {
      "epoch": 1.3133551548173297,
      "grad_norm": 0.17676550149917603,
      "learning_rate": 0.0004727791793918471,
      "loss": 0.3865,
      "step": 32300
    },
    {
      "epoch": 1.3174212698477241,
      "grad_norm": 0.1873563975095749,
      "learning_rate": 0.0004725578719072279,
      "loss": 0.3848,
      "step": 32400
    },
    {
      "epoch": 1.3214873848781181,
      "grad_norm": 0.1664772778749466,
      "learning_rate": 0.0004723365644226088,
      "loss": 0.3824,
      "step": 32500
    },
    {
      "epoch": 1.3255534999085123,
      "grad_norm": 0.17926634848117828,
      "learning_rate": 0.00047211525693798966,
      "loss": 0.3836,
      "step": 32600
    },
    {
      "epoch": 1.3296196149389066,
      "grad_norm": 0.17668405175209045,
      "learning_rate": 0.0004718939494533705,
      "loss": 0.3832,
      "step": 32700
    },
    {
      "epoch": 1.3336857299693008,
      "grad_norm": 0.16938091814517975,
      "learning_rate": 0.00047167264196875134,
      "loss": 0.3832,
      "step": 32800
    },
    {
      "epoch": 1.337751844999695,
      "grad_norm": 0.1892918199300766,
      "learning_rate": 0.00047145133448413224,
      "loss": 0.3846,
      "step": 32900
    },
    {
      "epoch": 1.3418179600300892,
      "grad_norm": 0.20096762478351593,
      "learning_rate": 0.00047123002699951314,
      "loss": 0.3854,
      "step": 33000
    },
    {
      "epoch": 1.3458840750604835,
      "grad_norm": 0.17960034310817719,
      "learning_rate": 0.000471008719514894,
      "loss": 0.3853,
      "step": 33100
    },
    {
      "epoch": 1.3499501900908777,
      "grad_norm": 0.16205862164497375,
      "learning_rate": 0.0004707874120302749,
      "loss": 0.3872,
      "step": 33200
    },
    {
      "epoch": 1.354016305121272,
      "grad_norm": 0.17130306363105774,
      "learning_rate": 0.0004705661045456557,
      "loss": 0.3821,
      "step": 33300
    },
    {
      "epoch": 1.3580824201516661,
      "grad_norm": 0.1782488077878952,
      "learning_rate": 0.0004703447970610366,
      "loss": 0.3849,
      "step": 33400
    },
    {
      "epoch": 1.3621485351820604,
      "grad_norm": 0.1760033220052719,
      "learning_rate": 0.00047012348957641746,
      "loss": 0.3814,
      "step": 33500
    },
    {
      "epoch": 1.3662146502124546,
      "grad_norm": 0.1864270567893982,
      "learning_rate": 0.00046990218209179836,
      "loss": 0.3858,
      "step": 33600
    },
    {
      "epoch": 1.3702807652428488,
      "grad_norm": 0.17944535613059998,
      "learning_rate": 0.00046968087460717926,
      "loss": 0.3826,
      "step": 33700
    },
    {
      "epoch": 1.3743468802732428,
      "grad_norm": 0.17766104638576508,
      "learning_rate": 0.0004694595671225601,
      "loss": 0.3838,
      "step": 33800
    },
    {
      "epoch": 1.3784129953036373,
      "grad_norm": 0.19442495703697205,
      "learning_rate": 0.000469238259637941,
      "loss": 0.382,
      "step": 33900
    },
    {
      "epoch": 1.3824791103340313,
      "grad_norm": 0.17245729267597198,
      "learning_rate": 0.00046901695215332184,
      "loss": 0.3847,
      "step": 34000
    },
    {
      "epoch": 1.3824791103340313,
      "eval_loss": 0.3924826383590698,
      "eval_runtime": 116.2187,
      "eval_samples_per_second": 1504.939,
      "eval_steps_per_second": 47.032,
      "step": 34000
    },
    {
      "epoch": 1.3865452253644255,
      "grad_norm": 0.18573370575904846,
      "learning_rate": 0.00046879564466870274,
      "loss": 0.3832,
      "step": 34100
    },
    {
      "epoch": 1.3906113403948197,
      "grad_norm": 0.17475056648254395,
      "learning_rate": 0.0004685743371840836,
      "loss": 0.3819,
      "step": 34200
    },
    {
      "epoch": 1.394677455425214,
      "grad_norm": 0.1725671887397766,
      "learning_rate": 0.0004683530296994645,
      "loss": 0.3837,
      "step": 34300
    },
    {
      "epoch": 1.3987435704556082,
      "grad_norm": 0.18432581424713135,
      "learning_rate": 0.00046813172221484527,
      "loss": 0.3841,
      "step": 34400
    },
    {
      "epoch": 1.4028096854860024,
      "grad_norm": 0.1848059594631195,
      "learning_rate": 0.00046791041473022617,
      "loss": 0.3832,
      "step": 34500
    },
    {
      "epoch": 1.4068758005163966,
      "grad_norm": 0.15979331731796265,
      "learning_rate": 0.00046768910724560706,
      "loss": 0.3813,
      "step": 34600
    },
    {
      "epoch": 1.4109419155467908,
      "grad_norm": 0.16482748091220856,
      "learning_rate": 0.0004674677997609879,
      "loss": 0.3814,
      "step": 34700
    },
    {
      "epoch": 1.415008030577185,
      "grad_norm": 0.15983393788337708,
      "learning_rate": 0.0004672464922763688,
      "loss": 0.3826,
      "step": 34800
    },
    {
      "epoch": 1.4190741456075793,
      "grad_norm": 0.17250464856624603,
      "learning_rate": 0.00046702518479174965,
      "loss": 0.3818,
      "step": 34900
    },
    {
      "epoch": 1.4231402606379735,
      "grad_norm": 0.17384563386440277,
      "learning_rate": 0.00046680387730713054,
      "loss": 0.3832,
      "step": 35000
    },
    {
      "epoch": 1.4272063756683677,
      "grad_norm": 0.1702522337436676,
      "learning_rate": 0.0004665825698225114,
      "loss": 0.3837,
      "step": 35100
    },
    {
      "epoch": 1.431272490698762,
      "grad_norm": 0.17123466730117798,
      "learning_rate": 0.0004663612623378923,
      "loss": 0.3834,
      "step": 35200
    },
    {
      "epoch": 1.435338605729156,
      "grad_norm": 0.15870992839336395,
      "learning_rate": 0.0004661399548532731,
      "loss": 0.3829,
      "step": 35300
    },
    {
      "epoch": 1.4394047207595504,
      "grad_norm": 0.16409195959568024,
      "learning_rate": 0.000465918647368654,
      "loss": 0.3837,
      "step": 35400
    },
    {
      "epoch": 1.4434708357899444,
      "grad_norm": 0.20293571054935455,
      "learning_rate": 0.0004656973398840349,
      "loss": 0.3807,
      "step": 35500
    },
    {
      "epoch": 1.4475369508203388,
      "grad_norm": 0.20623518526554108,
      "learning_rate": 0.00046547603239941576,
      "loss": 0.3833,
      "step": 35600
    },
    {
      "epoch": 1.4516030658507328,
      "grad_norm": 0.15931887924671173,
      "learning_rate": 0.00046525472491479666,
      "loss": 0.3836,
      "step": 35700
    },
    {
      "epoch": 1.455669180881127,
      "grad_norm": 0.1792304962873459,
      "learning_rate": 0.0004650334174301775,
      "loss": 0.3824,
      "step": 35800
    },
    {
      "epoch": 1.4597352959115213,
      "grad_norm": 0.16068443655967712,
      "learning_rate": 0.0004648121099455584,
      "loss": 0.3826,
      "step": 35900
    },
    {
      "epoch": 1.4638014109419155,
      "grad_norm": 0.18647240102291107,
      "learning_rate": 0.00046459080246093925,
      "loss": 0.3835,
      "step": 36000
    },
    {
      "epoch": 1.4638014109419155,
      "eval_loss": 0.3909004330635071,
      "eval_runtime": 115.9221,
      "eval_samples_per_second": 1508.789,
      "eval_steps_per_second": 47.152,
      "step": 36000
    },
    {
      "epoch": 1.4678675259723097,
      "grad_norm": 0.17061394453048706,
      "learning_rate": 0.0004643694949763201,
      "loss": 0.3855,
      "step": 36100
    },
    {
      "epoch": 1.471933641002704,
      "grad_norm": 0.17714422941207886,
      "learning_rate": 0.00046414818749170093,
      "loss": 0.3821,
      "step": 36200
    },
    {
      "epoch": 1.4759997560330982,
      "grad_norm": 0.1509789377450943,
      "learning_rate": 0.00046392688000708183,
      "loss": 0.3824,
      "step": 36300
    },
    {
      "epoch": 1.4800658710634924,
      "grad_norm": 0.15617603063583374,
      "learning_rate": 0.0004637055725224627,
      "loss": 0.3821,
      "step": 36400
    },
    {
      "epoch": 1.4841319860938866,
      "grad_norm": 0.16231325268745422,
      "learning_rate": 0.00046348426503784357,
      "loss": 0.382,
      "step": 36500
    },
    {
      "epoch": 1.4881981011242809,
      "grad_norm": 0.17121480405330658,
      "learning_rate": 0.00046326295755322447,
      "loss": 0.3838,
      "step": 36600
    },
    {
      "epoch": 1.492264216154675,
      "grad_norm": 0.18417266011238098,
      "learning_rate": 0.0004630416500686053,
      "loss": 0.3796,
      "step": 36700
    },
    {
      "epoch": 1.4963303311850693,
      "grad_norm": 0.16649752855300903,
      "learning_rate": 0.0004628203425839862,
      "loss": 0.3842,
      "step": 36800
    },
    {
      "epoch": 1.5003964462154635,
      "grad_norm": 0.16628281772136688,
      "learning_rate": 0.00046259903509936705,
      "loss": 0.3836,
      "step": 36900
    },
    {
      "epoch": 1.5044625612458575,
      "grad_norm": 0.16184747219085693,
      "learning_rate": 0.00046237772761474795,
      "loss": 0.3824,
      "step": 37000
    },
    {
      "epoch": 1.508528676276252,
      "grad_norm": 0.15996545553207397,
      "learning_rate": 0.00046215642013012885,
      "loss": 0.3799,
      "step": 37100
    },
    {
      "epoch": 1.512594791306646,
      "grad_norm": 0.18022146821022034,
      "learning_rate": 0.0004619351126455097,
      "loss": 0.3818,
      "step": 37200
    },
    {
      "epoch": 1.5166609063370404,
      "grad_norm": 0.1749478131532669,
      "learning_rate": 0.0004617138051608906,
      "loss": 0.3813,
      "step": 37300
    },
    {
      "epoch": 1.5207270213674344,
      "grad_norm": 0.17124563455581665,
      "learning_rate": 0.00046149249767627143,
      "loss": 0.3813,
      "step": 37400
    },
    {
      "epoch": 1.5247931363978287,
      "grad_norm": 0.16345244646072388,
      "learning_rate": 0.0004612711901916523,
      "loss": 0.3805,
      "step": 37500
    },
    {
      "epoch": 1.5288592514282229,
      "grad_norm": 0.1611843854188919,
      "learning_rate": 0.00046104988270703317,
      "loss": 0.3807,
      "step": 37600
    },
    {
      "epoch": 1.532925366458617,
      "grad_norm": 0.17864425480365753,
      "learning_rate": 0.00046082857522241407,
      "loss": 0.3799,
      "step": 37700
    },
    {
      "epoch": 1.5369914814890113,
      "grad_norm": 0.18464148044586182,
      "learning_rate": 0.00046060726773779486,
      "loss": 0.3796,
      "step": 37800
    },
    {
      "epoch": 1.5410575965194055,
      "grad_norm": 0.17728717625141144,
      "learning_rate": 0.00046038596025317575,
      "loss": 0.379,
      "step": 37900
    },
    {
      "epoch": 1.5451237115497998,
      "grad_norm": 0.18696001172065735,
      "learning_rate": 0.00046016465276855665,
      "loss": 0.381,
      "step": 38000
    },
    {
      "epoch": 1.5451237115497998,
      "eval_loss": 0.3906547427177429,
      "eval_runtime": 115.5535,
      "eval_samples_per_second": 1513.602,
      "eval_steps_per_second": 47.303,
      "step": 38000
    },
    {
      "epoch": 1.549189826580194,
      "grad_norm": 0.17385335266590118,
      "learning_rate": 0.0004599433452839375,
      "loss": 0.3823,
      "step": 38100
    },
    {
      "epoch": 1.5532559416105882,
      "grad_norm": 0.18379798531532288,
      "learning_rate": 0.0004597220377993184,
      "loss": 0.3811,
      "step": 38200
    },
    {
      "epoch": 1.5573220566409822,
      "grad_norm": 0.17844389379024506,
      "learning_rate": 0.00045950073031469923,
      "loss": 0.3801,
      "step": 38300
    },
    {
      "epoch": 1.5613881716713767,
      "grad_norm": 0.17875324189662933,
      "learning_rate": 0.00045927942283008013,
      "loss": 0.3793,
      "step": 38400
    },
    {
      "epoch": 1.5654542867017707,
      "grad_norm": 0.17873841524124146,
      "learning_rate": 0.000459058115345461,
      "loss": 0.3779,
      "step": 38500
    },
    {
      "epoch": 1.5695204017321651,
      "grad_norm": 0.1821201890707016,
      "learning_rate": 0.00045883680786084187,
      "loss": 0.3805,
      "step": 38600
    },
    {
      "epoch": 1.5735865167625591,
      "grad_norm": 0.18491385877132416,
      "learning_rate": 0.0004586155003762227,
      "loss": 0.3783,
      "step": 38700
    },
    {
      "epoch": 1.5776526317929536,
      "grad_norm": 0.16437901556491852,
      "learning_rate": 0.0004583941928916036,
      "loss": 0.3819,
      "step": 38800
    },
    {
      "epoch": 1.5817187468233476,
      "grad_norm": 0.1744845062494278,
      "learning_rate": 0.0004581728854069845,
      "loss": 0.3797,
      "step": 38900
    },
    {
      "epoch": 1.5857848618537418,
      "grad_norm": 0.17442423105239868,
      "learning_rate": 0.00045795157792236535,
      "loss": 0.3809,
      "step": 39000
    },
    {
      "epoch": 1.589850976884136,
      "grad_norm": 0.15942956507205963,
      "learning_rate": 0.00045773027043774625,
      "loss": 0.3803,
      "step": 39100
    },
    {
      "epoch": 1.5939170919145302,
      "grad_norm": 0.19623716175556183,
      "learning_rate": 0.0004575089629531271,
      "loss": 0.3822,
      "step": 39200
    },
    {
      "epoch": 1.5979832069449245,
      "grad_norm": 0.17485640943050385,
      "learning_rate": 0.000457287655468508,
      "loss": 0.3787,
      "step": 39300
    },
    {
      "epoch": 1.6020493219753187,
      "grad_norm": 0.1709727793931961,
      "learning_rate": 0.0004570663479838888,
      "loss": 0.3792,
      "step": 39400
    },
    {
      "epoch": 1.606115437005713,
      "grad_norm": 0.1758188158273697,
      "learning_rate": 0.0004568450404992697,
      "loss": 0.3795,
      "step": 39500
    },
    {
      "epoch": 1.6101815520361071,
      "grad_norm": 0.20043303072452545,
      "learning_rate": 0.0004566237330146505,
      "loss": 0.3774,
      "step": 39600
    },
    {
      "epoch": 1.6142476670665014,
      "grad_norm": 0.1691984087228775,
      "learning_rate": 0.0004564024255300314,
      "loss": 0.3803,
      "step": 39700
    },
    {
      "epoch": 1.6183137820968954,
      "grad_norm": 0.16034239530563354,
      "learning_rate": 0.0004561811180454123,
      "loss": 0.3777,
      "step": 39800
    },
    {
      "epoch": 1.6223798971272898,
      "grad_norm": 0.16791237890720367,
      "learning_rate": 0.00045595981056079316,
      "loss": 0.3808,
      "step": 39900
    },
    {
      "epoch": 1.6264460121576838,
      "grad_norm": 0.1756930649280548,
      "learning_rate": 0.00045573850307617405,
      "loss": 0.3797,
      "step": 40000
    },
    {
      "epoch": 1.6264460121576838,
      "eval_loss": 0.3889232575893402,
      "eval_runtime": 115.2854,
      "eval_samples_per_second": 1517.122,
      "eval_steps_per_second": 47.413,
      "step": 40000
    },
    {
      "epoch": 1.6305121271880783,
      "grad_norm": 0.17818087339401245,
      "learning_rate": 0.0004555171955915549,
      "loss": 0.3824,
      "step": 40100
    },
    {
      "epoch": 1.6345782422184723,
      "grad_norm": 0.20166093111038208,
      "learning_rate": 0.0004552958881069358,
      "loss": 0.3772,
      "step": 40200
    },
    {
      "epoch": 1.6386443572488667,
      "grad_norm": 0.16018906235694885,
      "learning_rate": 0.00045507458062231664,
      "loss": 0.3813,
      "step": 40300
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.18439316749572754,
      "learning_rate": 0.00045485327313769754,
      "loss": 0.3793,
      "step": 40400
    },
    {
      "epoch": 1.6467765873096551,
      "grad_norm": 0.17513728141784668,
      "learning_rate": 0.0004546319656530784,
      "loss": 0.3807,
      "step": 40500
    },
    {
      "epoch": 1.6508427023400492,
      "grad_norm": 0.18624773621559143,
      "learning_rate": 0.0004544106581684593,
      "loss": 0.3774,
      "step": 40600
    },
    {
      "epoch": 1.6549088173704434,
      "grad_norm": 0.17146405577659607,
      "learning_rate": 0.0004541893506838402,
      "loss": 0.3802,
      "step": 40700
    },
    {
      "epoch": 1.6589749324008376,
      "grad_norm": 0.1930227279663086,
      "learning_rate": 0.000453968043199221,
      "loss": 0.3775,
      "step": 40800
    },
    {
      "epoch": 1.6630410474312318,
      "grad_norm": 0.1742599457502365,
      "learning_rate": 0.0004537467357146019,
      "loss": 0.3782,
      "step": 40900
    },
    {
      "epoch": 1.667107162461626,
      "grad_norm": 0.1609693318605423,
      "learning_rate": 0.00045352542822998276,
      "loss": 0.3786,
      "step": 41000
    },
    {
      "epoch": 1.6711732774920203,
      "grad_norm": 0.1753845065832138,
      "learning_rate": 0.0004533041207453636,
      "loss": 0.3782,
      "step": 41100
    },
    {
      "epoch": 1.6752393925224145,
      "grad_norm": 0.15410315990447998,
      "learning_rate": 0.00045308281326074444,
      "loss": 0.3795,
      "step": 41200
    },
    {
      "epoch": 1.6793055075528087,
      "grad_norm": 0.2184939682483673,
      "learning_rate": 0.00045286150577612534,
      "loss": 0.3791,
      "step": 41300
    },
    {
      "epoch": 1.683371622583203,
      "grad_norm": 0.19852180778980255,
      "learning_rate": 0.00045264019829150624,
      "loss": 0.3805,
      "step": 41400
    },
    {
      "epoch": 1.687437737613597,
      "grad_norm": 0.17941871285438538,
      "learning_rate": 0.0004524188908068871,
      "loss": 0.3799,
      "step": 41500
    },
    {
      "epoch": 1.6915038526439914,
      "grad_norm": 0.1540408432483673,
      "learning_rate": 0.000452197583322268,
      "loss": 0.3803,
      "step": 41600
    },
    {
      "epoch": 1.6955699676743854,
      "grad_norm": 0.17024339735507965,
      "learning_rate": 0.0004519762758376488,
      "loss": 0.3789,
      "step": 41700
    },
    {
      "epoch": 1.6996360827047798,
      "grad_norm": 0.17809344828128815,
      "learning_rate": 0.0004517549683530297,
      "loss": 0.3776,
      "step": 41800
    },
    {
      "epoch": 1.7037021977351738,
      "grad_norm": 0.15821973979473114,
      "learning_rate": 0.00045153366086841056,
      "loss": 0.3788,
      "step": 41900
    },
    {
      "epoch": 1.7077683127655683,
      "grad_norm": 0.1800369769334793,
      "learning_rate": 0.00045131235338379146,
      "loss": 0.3774,
      "step": 42000
    },
    {
      "epoch": 1.7077683127655683,
      "eval_loss": 0.3875448703765869,
      "eval_runtime": 115.086,
      "eval_samples_per_second": 1519.75,
      "eval_steps_per_second": 47.495,
      "step": 42000
    },
    {
      "epoch": 1.7118344277959623,
      "grad_norm": 0.17357081174850464,
      "learning_rate": 0.0004510910458991723,
      "loss": 0.3758,
      "step": 42100
    },
    {
      "epoch": 1.7159005428263565,
      "grad_norm": 0.17180213332176208,
      "learning_rate": 0.0004508697384145532,
      "loss": 0.3768,
      "step": 42200
    },
    {
      "epoch": 1.7199666578567507,
      "grad_norm": 0.1892317831516266,
      "learning_rate": 0.0004506484309299341,
      "loss": 0.3794,
      "step": 42300
    },
    {
      "epoch": 1.724032772887145,
      "grad_norm": 0.18469054996967316,
      "learning_rate": 0.00045042712344531494,
      "loss": 0.3756,
      "step": 42400
    },
    {
      "epoch": 1.7280988879175392,
      "grad_norm": 0.18425552546977997,
      "learning_rate": 0.00045020581596069584,
      "loss": 0.3784,
      "step": 42500
    },
    {
      "epoch": 1.7321650029479334,
      "grad_norm": 0.16641700267791748,
      "learning_rate": 0.0004499845084760767,
      "loss": 0.3796,
      "step": 42600
    },
    {
      "epoch": 1.7362311179783276,
      "grad_norm": 0.16741888225078583,
      "learning_rate": 0.0004497632009914576,
      "loss": 0.3772,
      "step": 42700
    },
    {
      "epoch": 1.7402972330087219,
      "grad_norm": 0.17617332935333252,
      "learning_rate": 0.00044954189350683837,
      "loss": 0.3771,
      "step": 42800
    },
    {
      "epoch": 1.744363348039116,
      "grad_norm": 0.17437861859798431,
      "learning_rate": 0.00044932058602221926,
      "loss": 0.3789,
      "step": 42900
    },
    {
      "epoch": 1.74842946306951,
      "grad_norm": 0.16839167475700378,
      "learning_rate": 0.0004490992785376001,
      "loss": 0.3788,
      "step": 43000
    },
    {
      "epoch": 1.7524955780999045,
      "grad_norm": 0.17671582102775574,
      "learning_rate": 0.000448877971052981,
      "loss": 0.377,
      "step": 43100
    },
    {
      "epoch": 1.7565616931302985,
      "grad_norm": 0.21120353043079376,
      "learning_rate": 0.0004486566635683619,
      "loss": 0.3763,
      "step": 43200
    },
    {
      "epoch": 1.760627808160693,
      "grad_norm": 0.15633057057857513,
      "learning_rate": 0.00044843535608374274,
      "loss": 0.3776,
      "step": 43300
    },
    {
      "epoch": 1.764693923191087,
      "grad_norm": 0.16947904229164124,
      "learning_rate": 0.00044821404859912364,
      "loss": 0.3754,
      "step": 43400
    },
    {
      "epoch": 1.7687600382214814,
      "grad_norm": 0.16872185468673706,
      "learning_rate": 0.0004479927411145045,
      "loss": 0.3767,
      "step": 43500
    },
    {
      "epoch": 1.7728261532518754,
      "grad_norm": 0.17414532601833344,
      "learning_rate": 0.0004477714336298854,
      "loss": 0.3796,
      "step": 43600
    },
    {
      "epoch": 1.7768922682822699,
      "grad_norm": 0.16589796543121338,
      "learning_rate": 0.0004475501261452662,
      "loss": 0.3787,
      "step": 43700
    },
    {
      "epoch": 1.7809583833126639,
      "grad_norm": 0.1771773397922516,
      "learning_rate": 0.0004473288186606471,
      "loss": 0.3777,
      "step": 43800
    },
    {
      "epoch": 1.785024498343058,
      "grad_norm": 0.20183178782463074,
      "learning_rate": 0.00044710751117602797,
      "loss": 0.3771,
      "step": 43900
    },
    {
      "epoch": 1.7890906133734523,
      "grad_norm": 0.17087848484516144,
      "learning_rate": 0.00044688620369140886,
      "loss": 0.3781,
      "step": 44000
    },
    {
      "epoch": 1.7890906133734523,
      "eval_loss": 0.3869941234588623,
      "eval_runtime": 115.2911,
      "eval_samples_per_second": 1517.047,
      "eval_steps_per_second": 47.41,
      "step": 44000
    },
    {
      "epoch": 1.7931567284038465,
      "grad_norm": 0.17451657354831696,
      "learning_rate": 0.00044666489620678976,
      "loss": 0.378,
      "step": 44100
    },
    {
      "epoch": 1.7972228434342408,
      "grad_norm": 0.15740181505680084,
      "learning_rate": 0.0004464435887221706,
      "loss": 0.3779,
      "step": 44200
    },
    {
      "epoch": 1.801288958464635,
      "grad_norm": 0.17693687975406647,
      "learning_rate": 0.0004462222812375515,
      "loss": 0.3764,
      "step": 44300
    },
    {
      "epoch": 1.8053550734950292,
      "grad_norm": 0.1870609074831009,
      "learning_rate": 0.00044600097375293234,
      "loss": 0.3774,
      "step": 44400
    },
    {
      "epoch": 1.8094211885254232,
      "grad_norm": 0.19799388945102692,
      "learning_rate": 0.0004457796662683132,
      "loss": 0.3769,
      "step": 44500
    },
    {
      "epoch": 1.8134873035558177,
      "grad_norm": 0.17424780130386353,
      "learning_rate": 0.00044555835878369403,
      "loss": 0.3767,
      "step": 44600
    },
    {
      "epoch": 1.8175534185862117,
      "grad_norm": 0.19934649765491486,
      "learning_rate": 0.00044533705129907493,
      "loss": 0.3767,
      "step": 44700
    },
    {
      "epoch": 1.8216195336166061,
      "grad_norm": 0.1780422031879425,
      "learning_rate": 0.00044511574381445577,
      "loss": 0.3779,
      "step": 44800
    },
    {
      "epoch": 1.8256856486470001,
      "grad_norm": 0.1999199092388153,
      "learning_rate": 0.00044489443632983667,
      "loss": 0.3762,
      "step": 44900
    },
    {
      "epoch": 1.8297517636773946,
      "grad_norm": 0.17805199325084686,
      "learning_rate": 0.00044467312884521757,
      "loss": 0.3772,
      "step": 45000
    },
    {
      "epoch": 1.8338178787077886,
      "grad_norm": 0.17056970298290253,
      "learning_rate": 0.0004444518213605984,
      "loss": 0.3753,
      "step": 45100
    },
    {
      "epoch": 1.837883993738183,
      "grad_norm": 0.1698606163263321,
      "learning_rate": 0.0004442305138759793,
      "loss": 0.3778,
      "step": 45200
    },
    {
      "epoch": 1.841950108768577,
      "grad_norm": 0.21491359174251556,
      "learning_rate": 0.00044400920639136015,
      "loss": 0.3757,
      "step": 45300
    },
    {
      "epoch": 1.8460162237989712,
      "grad_norm": 0.22274640202522278,
      "learning_rate": 0.00044378789890674105,
      "loss": 0.3743,
      "step": 45400
    },
    {
      "epoch": 1.8500823388293655,
      "grad_norm": 0.17469294369220734,
      "learning_rate": 0.0004435665914221219,
      "loss": 0.3784,
      "step": 45500
    },
    {
      "epoch": 1.8541484538597597,
      "grad_norm": 0.16170987486839294,
      "learning_rate": 0.0004433452839375028,
      "loss": 0.3757,
      "step": 45600
    },
    {
      "epoch": 1.858214568890154,
      "grad_norm": 0.15853086113929749,
      "learning_rate": 0.0004431239764528837,
      "loss": 0.3775,
      "step": 45700
    },
    {
      "epoch": 1.8622806839205481,
      "grad_norm": 0.18004421889781952,
      "learning_rate": 0.00044290266896826453,
      "loss": 0.3759,
      "step": 45800
    },
    {
      "epoch": 1.8663467989509424,
      "grad_norm": 0.18464715778827667,
      "learning_rate": 0.0004426813614836454,
      "loss": 0.3787,
      "step": 45900
    },
    {
      "epoch": 1.8704129139813366,
      "grad_norm": 0.1934727430343628,
      "learning_rate": 0.00044246005399902627,
      "loss": 0.3742,
      "step": 46000
    },
    {
      "epoch": 1.8704129139813366,
      "eval_loss": 0.38520070910453796,
      "eval_runtime": 115.8652,
      "eval_samples_per_second": 1509.53,
      "eval_steps_per_second": 47.175,
      "step": 46000
    },
    {
      "epoch": 1.8744790290117308,
      "grad_norm": 0.18797850608825684,
      "learning_rate": 0.00044223874651440717,
      "loss": 0.3771,
      "step": 46100
    },
    {
      "epoch": 1.8785451440421248,
      "grad_norm": 0.1854706108570099,
      "learning_rate": 0.00044201743902978795,
      "loss": 0.3756,
      "step": 46200
    },
    {
      "epoch": 1.8826112590725192,
      "grad_norm": 0.18177787959575653,
      "learning_rate": 0.00044179613154516885,
      "loss": 0.3778,
      "step": 46300
    },
    {
      "epoch": 1.8866773741029133,
      "grad_norm": 0.18214412033557892,
      "learning_rate": 0.0004415748240605497,
      "loss": 0.376,
      "step": 46400
    },
    {
      "epoch": 1.8907434891333077,
      "grad_norm": 0.18869376182556152,
      "learning_rate": 0.0004413535165759306,
      "loss": 0.375,
      "step": 46500
    },
    {
      "epoch": 1.8948096041637017,
      "grad_norm": 0.1870746910572052,
      "learning_rate": 0.0004411322090913115,
      "loss": 0.3761,
      "step": 46600
    },
    {
      "epoch": 1.8988757191940961,
      "grad_norm": 0.1850818693637848,
      "learning_rate": 0.00044091090160669233,
      "loss": 0.3773,
      "step": 46700
    },
    {
      "epoch": 1.9029418342244901,
      "grad_norm": 0.1901049166917801,
      "learning_rate": 0.00044068959412207323,
      "loss": 0.3759,
      "step": 46800
    },
    {
      "epoch": 1.9070079492548844,
      "grad_norm": 0.1838711053133011,
      "learning_rate": 0.00044046828663745407,
      "loss": 0.376,
      "step": 46900
    },
    {
      "epoch": 1.9110740642852786,
      "grad_norm": 0.19131863117218018,
      "learning_rate": 0.00044024697915283497,
      "loss": 0.3777,
      "step": 47000
    },
    {
      "epoch": 1.9151401793156728,
      "grad_norm": 0.17187297344207764,
      "learning_rate": 0.0004400256716682158,
      "loss": 0.3777,
      "step": 47100
    },
    {
      "epoch": 1.919206294346067,
      "grad_norm": 0.1814781278371811,
      "learning_rate": 0.0004398043641835967,
      "loss": 0.3772,
      "step": 47200
    },
    {
      "epoch": 1.9232724093764613,
      "grad_norm": 0.20031331479549408,
      "learning_rate": 0.00043958305669897755,
      "loss": 0.3761,
      "step": 47300
    },
    {
      "epoch": 1.9273385244068555,
      "grad_norm": 0.16807489097118378,
      "learning_rate": 0.00043936174921435845,
      "loss": 0.3756,
      "step": 47400
    },
    {
      "epoch": 1.9314046394372497,
      "grad_norm": 0.18971288204193115,
      "learning_rate": 0.00043914044172973935,
      "loss": 0.3789,
      "step": 47500
    },
    {
      "epoch": 1.935470754467644,
      "grad_norm": 0.17462244629859924,
      "learning_rate": 0.0004389191342451202,
      "loss": 0.3747,
      "step": 47600
    },
    {
      "epoch": 1.939536869498038,
      "grad_norm": 0.17656056582927704,
      "learning_rate": 0.0004386978267605011,
      "loss": 0.3744,
      "step": 47700
    },
    {
      "epoch": 1.9436029845284324,
      "grad_norm": 0.18997591733932495,
      "learning_rate": 0.00043847651927588193,
      "loss": 0.377,
      "step": 47800
    },
    {
      "epoch": 1.9476690995588264,
      "grad_norm": 0.2060728371143341,
      "learning_rate": 0.0004382552117912628,
      "loss": 0.3787,
      "step": 47900
    },
    {
      "epoch": 1.9517352145892208,
      "grad_norm": 0.19439825415611267,
      "learning_rate": 0.0004380339043066436,
      "loss": 0.3753,
      "step": 48000
    },
    {
      "epoch": 1.9517352145892208,
      "eval_loss": 0.3846151530742645,
      "eval_runtime": 116.3788,
      "eval_samples_per_second": 1502.868,
      "eval_steps_per_second": 46.967,
      "step": 48000
    },
    {
      "epoch": 1.9558013296196148,
      "grad_norm": 0.18331016600131989,
      "learning_rate": 0.0004378125968220245,
      "loss": 0.3744,
      "step": 48100
    },
    {
      "epoch": 1.9598674446500093,
      "grad_norm": 0.17013423144817352,
      "learning_rate": 0.00043759128933740536,
      "loss": 0.377,
      "step": 48200
    },
    {
      "epoch": 1.9639335596804033,
      "grad_norm": 0.16550610959529877,
      "learning_rate": 0.00043736998185278626,
      "loss": 0.3751,
      "step": 48300
    },
    {
      "epoch": 1.9679996747107977,
      "grad_norm": 0.18670526146888733,
      "learning_rate": 0.00043714867436816715,
      "loss": 0.374,
      "step": 48400
    },
    {
      "epoch": 1.9720657897411917,
      "grad_norm": 0.2023259848356247,
      "learning_rate": 0.000436927366883548,
      "loss": 0.3754,
      "step": 48500
    },
    {
      "epoch": 1.976131904771586,
      "grad_norm": 0.1769389659166336,
      "learning_rate": 0.0004367060593989289,
      "loss": 0.3773,
      "step": 48600
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 0.16904795169830322,
      "learning_rate": 0.00043648475191430974,
      "loss": 0.3764,
      "step": 48700
    },
    {
      "epoch": 1.9842641348323744,
      "grad_norm": 0.19919195771217346,
      "learning_rate": 0.00043626344442969063,
      "loss": 0.3772,
      "step": 48800
    },
    {
      "epoch": 1.9883302498627686,
      "grad_norm": 0.20455341041088104,
      "learning_rate": 0.0004360421369450715,
      "loss": 0.3721,
      "step": 48900
    },
    {
      "epoch": 1.9923963648931629,
      "grad_norm": 0.19165708124637604,
      "learning_rate": 0.0004358208294604524,
      "loss": 0.3766,
      "step": 49000
    },
    {
      "epoch": 1.996462479923557,
      "grad_norm": 0.18347285687923431,
      "learning_rate": 0.00043559952197583327,
      "loss": 0.3729,
      "step": 49100
    },
    {
      "epoch": 2.000528594953951,
      "grad_norm": 0.17388010025024414,
      "learning_rate": 0.0004353782144912141,
      "loss": 0.3733,
      "step": 49200
    },
    {
      "epoch": 2.0045947099843455,
      "grad_norm": 0.189803346991539,
      "learning_rate": 0.000435156907006595,
      "loss": 0.3729,
      "step": 49300
    },
    {
      "epoch": 2.0086608250147395,
      "grad_norm": 0.2053595334291458,
      "learning_rate": 0.00043493559952197586,
      "loss": 0.3705,
      "step": 49400
    },
    {
      "epoch": 2.012726940045134,
      "grad_norm": 0.18528874218463898,
      "learning_rate": 0.00043471429203735675,
      "loss": 0.3711,
      "step": 49500
    },
    {
      "epoch": 2.016793055075528,
      "grad_norm": 0.17170681059360504,
      "learning_rate": 0.00043449298455273754,
      "loss": 0.3692,
      "step": 49600
    },
    {
      "epoch": 2.0208591701059224,
      "grad_norm": 0.18236155807971954,
      "learning_rate": 0.00043427167706811844,
      "loss": 0.3717,
      "step": 49700
    },
    {
      "epoch": 2.0249252851363164,
      "grad_norm": 0.19177782535552979,
      "learning_rate": 0.0004340503695834993,
      "loss": 0.3709,
      "step": 49800
    },
    {
      "epoch": 2.028991400166711,
      "grad_norm": 0.18937312066555023,
      "learning_rate": 0.0004338290620988802,
      "loss": 0.3713,
      "step": 49900
    },
    {
      "epoch": 2.033057515197105,
      "grad_norm": 0.20015089213848114,
      "learning_rate": 0.0004336077546142611,
      "loss": 0.3728,
      "step": 50000
    },
    {
      "epoch": 2.033057515197105,
      "eval_loss": 0.38417452573776245,
      "eval_runtime": 116.0436,
      "eval_samples_per_second": 1507.21,
      "eval_steps_per_second": 47.103,
      "step": 50000
    },
    {
      "epoch": 2.0371236302274993,
      "grad_norm": 0.18386836349964142,
      "learning_rate": 0.0004333864471296419,
      "loss": 0.3739,
      "step": 50100
    },
    {
      "epoch": 2.0411897452578933,
      "grad_norm": 0.19100818037986755,
      "learning_rate": 0.0004331651396450228,
      "loss": 0.371,
      "step": 50200
    },
    {
      "epoch": 2.0452558602882878,
      "grad_norm": 0.17632050812244415,
      "learning_rate": 0.00043294383216040366,
      "loss": 0.3715,
      "step": 50300
    },
    {
      "epoch": 2.0493219753186818,
      "grad_norm": 0.18814332783222198,
      "learning_rate": 0.00043272252467578456,
      "loss": 0.3708,
      "step": 50400
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.20473110675811768,
      "learning_rate": 0.0004325012171911654,
      "loss": 0.3743,
      "step": 50500
    },
    {
      "epoch": 2.05745420537947,
      "grad_norm": 0.19728556275367737,
      "learning_rate": 0.0004322799097065463,
      "loss": 0.372,
      "step": 50600
    },
    {
      "epoch": 2.061520320409864,
      "grad_norm": 0.1851651668548584,
      "learning_rate": 0.00043205860222192714,
      "loss": 0.3708,
      "step": 50700
    },
    {
      "epoch": 2.0655864354402587,
      "grad_norm": 0.17541326582431793,
      "learning_rate": 0.00043183729473730804,
      "loss": 0.37,
      "step": 50800
    },
    {
      "epoch": 2.0696525504706527,
      "grad_norm": 0.2026171237230301,
      "learning_rate": 0.00043161598725268894,
      "loss": 0.3733,
      "step": 50900
    },
    {
      "epoch": 2.073718665501047,
      "grad_norm": 0.20312988758087158,
      "learning_rate": 0.0004313946797680698,
      "loss": 0.3708,
      "step": 51000
    },
    {
      "epoch": 2.077784780531441,
      "grad_norm": 0.18818460404872894,
      "learning_rate": 0.0004311733722834507,
      "loss": 0.3711,
      "step": 51100
    },
    {
      "epoch": 2.0818508955618356,
      "grad_norm": 0.18708816170692444,
      "learning_rate": 0.00043095206479883147,
      "loss": 0.3722,
      "step": 51200
    },
    {
      "epoch": 2.0859170105922296,
      "grad_norm": 0.22028879821300507,
      "learning_rate": 0.00043073075731421236,
      "loss": 0.3716,
      "step": 51300
    },
    {
      "epoch": 2.089983125622624,
      "grad_norm": 0.1819760948419571,
      "learning_rate": 0.0004305094498295932,
      "loss": 0.3725,
      "step": 51400
    },
    {
      "epoch": 2.094049240653018,
      "grad_norm": 0.19617611169815063,
      "learning_rate": 0.0004302881423449741,
      "loss": 0.3723,
      "step": 51500
    },
    {
      "epoch": 2.0981153556834125,
      "grad_norm": 0.17800268530845642,
      "learning_rate": 0.00043006683486035495,
      "loss": 0.3719,
      "step": 51600
    },
    {
      "epoch": 2.1021814707138065,
      "grad_norm": 0.19028164446353912,
      "learning_rate": 0.00042984552737573584,
      "loss": 0.373,
      "step": 51700
    },
    {
      "epoch": 2.106247585744201,
      "grad_norm": 0.16432324051856995,
      "learning_rate": 0.00042962421989111674,
      "loss": 0.3696,
      "step": 51800
    },
    {
      "epoch": 2.110313700774595,
      "grad_norm": 0.196149542927742,
      "learning_rate": 0.0004294029124064976,
      "loss": 0.3726,
      "step": 51900
    },
    {
      "epoch": 2.1143798158049893,
      "grad_norm": 0.21308909356594086,
      "learning_rate": 0.0004291816049218785,
      "loss": 0.3715,
      "step": 52000
    },
    {
      "epoch": 2.1143798158049893,
      "eval_loss": 0.38311412930488586,
      "eval_runtime": 115.3732,
      "eval_samples_per_second": 1515.967,
      "eval_steps_per_second": 47.377,
      "step": 52000
    },
    {
      "epoch": 2.1184459308353834,
      "grad_norm": 0.1857093870639801,
      "learning_rate": 0.0004289602974372593,
      "loss": 0.3708,
      "step": 52100
    },
    {
      "epoch": 2.1225120458657774,
      "grad_norm": 0.20505249500274658,
      "learning_rate": 0.0004287389899526402,
      "loss": 0.3736,
      "step": 52200
    },
    {
      "epoch": 2.126578160896172,
      "grad_norm": 0.1820889711380005,
      "learning_rate": 0.00042851768246802106,
      "loss": 0.3735,
      "step": 52300
    },
    {
      "epoch": 2.130644275926566,
      "grad_norm": 0.1919415146112442,
      "learning_rate": 0.00042829637498340196,
      "loss": 0.3717,
      "step": 52400
    },
    {
      "epoch": 2.1347103909569602,
      "grad_norm": 0.20405493676662445,
      "learning_rate": 0.00042807506749878286,
      "loss": 0.3709,
      "step": 52500
    },
    {
      "epoch": 2.1387765059873542,
      "grad_norm": 0.18312585353851318,
      "learning_rate": 0.0004278537600141637,
      "loss": 0.3732,
      "step": 52600
    },
    {
      "epoch": 2.1428426210177487,
      "grad_norm": 0.1775583028793335,
      "learning_rate": 0.0004276324525295446,
      "loss": 0.3725,
      "step": 52700
    },
    {
      "epoch": 2.1469087360481427,
      "grad_norm": 0.21921011805534363,
      "learning_rate": 0.00042741114504492544,
      "loss": 0.3689,
      "step": 52800
    },
    {
      "epoch": 2.150974851078537,
      "grad_norm": 0.19482965767383575,
      "learning_rate": 0.0004271898375603063,
      "loss": 0.3727,
      "step": 52900
    },
    {
      "epoch": 2.155040966108931,
      "grad_norm": 0.1779423952102661,
      "learning_rate": 0.00042696853007568713,
      "loss": 0.3728,
      "step": 53000
    },
    {
      "epoch": 2.1591070811393256,
      "grad_norm": 0.20327228307724,
      "learning_rate": 0.000426747222591068,
      "loss": 0.3704,
      "step": 53100
    },
    {
      "epoch": 2.1631731961697196,
      "grad_norm": 0.18285813927650452,
      "learning_rate": 0.00042652591510644887,
      "loss": 0.3685,
      "step": 53200
    },
    {
      "epoch": 2.167239311200114,
      "grad_norm": 0.19274011254310608,
      "learning_rate": 0.00042630460762182977,
      "loss": 0.3722,
      "step": 53300
    },
    {
      "epoch": 2.171305426230508,
      "grad_norm": 0.16744180023670197,
      "learning_rate": 0.00042608330013721066,
      "loss": 0.3727,
      "step": 53400
    },
    {
      "epoch": 2.175371541260902,
      "grad_norm": 0.19649650156497955,
      "learning_rate": 0.0004258619926525915,
      "loss": 0.37,
      "step": 53500
    },
    {
      "epoch": 2.1794376562912965,
      "grad_norm": 0.24595226347446442,
      "learning_rate": 0.0004256406851679724,
      "loss": 0.3708,
      "step": 53600
    },
    {
      "epoch": 2.1835037713216905,
      "grad_norm": 0.19125524163246155,
      "learning_rate": 0.00042541937768335325,
      "loss": 0.3703,
      "step": 53700
    },
    {
      "epoch": 2.187569886352085,
      "grad_norm": 0.181004598736763,
      "learning_rate": 0.00042519807019873415,
      "loss": 0.3713,
      "step": 53800
    },
    {
      "epoch": 2.191636001382479,
      "grad_norm": 0.18290282785892487,
      "learning_rate": 0.000424976762714115,
      "loss": 0.3728,
      "step": 53900
    },
    {
      "epoch": 2.1957021164128734,
      "grad_norm": 0.19070690870285034,
      "learning_rate": 0.0004247554552294959,
      "loss": 0.3722,
      "step": 54000
    },
    {
      "epoch": 2.1957021164128734,
      "eval_loss": 0.382116436958313,
      "eval_runtime": 115.9651,
      "eval_samples_per_second": 1508.229,
      "eval_steps_per_second": 47.135,
      "step": 54000
    },
    {
      "epoch": 2.1997682314432674,
      "grad_norm": 0.19893886148929596,
      "learning_rate": 0.00042453414774487673,
      "loss": 0.3709,
      "step": 54100
    },
    {
      "epoch": 2.203834346473662,
      "grad_norm": 0.18487399816513062,
      "learning_rate": 0.0004243128402602576,
      "loss": 0.3712,
      "step": 54200
    },
    {
      "epoch": 2.207900461504056,
      "grad_norm": 0.1983281373977661,
      "learning_rate": 0.0004240915327756385,
      "loss": 0.3714,
      "step": 54300
    },
    {
      "epoch": 2.2119665765344503,
      "grad_norm": 0.20937544107437134,
      "learning_rate": 0.00042387022529101937,
      "loss": 0.3696,
      "step": 54400
    },
    {
      "epoch": 2.2160326915648443,
      "grad_norm": 0.19052816927433014,
      "learning_rate": 0.00042364891780640026,
      "loss": 0.3707,
      "step": 54500
    },
    {
      "epoch": 2.2200988065952387,
      "grad_norm": 0.18583619594573975,
      "learning_rate": 0.00042342761032178105,
      "loss": 0.3718,
      "step": 54600
    },
    {
      "epoch": 2.2241649216256327,
      "grad_norm": 0.20727375149726868,
      "learning_rate": 0.00042320630283716195,
      "loss": 0.3735,
      "step": 54700
    },
    {
      "epoch": 2.228231036656027,
      "grad_norm": 0.19305378198623657,
      "learning_rate": 0.0004229849953525428,
      "loss": 0.3701,
      "step": 54800
    },
    {
      "epoch": 2.232297151686421,
      "grad_norm": 0.17766526341438293,
      "learning_rate": 0.0004227636878679237,
      "loss": 0.3737,
      "step": 54900
    },
    {
      "epoch": 2.2363632667168156,
      "grad_norm": 0.19403237104415894,
      "learning_rate": 0.00042254238038330453,
      "loss": 0.3732,
      "step": 55000
    },
    {
      "epoch": 2.2404293817472096,
      "grad_norm": 0.21139328181743622,
      "learning_rate": 0.00042232107289868543,
      "loss": 0.3701,
      "step": 55100
    },
    {
      "epoch": 2.2444954967776036,
      "grad_norm": 0.20568536221981049,
      "learning_rate": 0.00042209976541406633,
      "loss": 0.3694,
      "step": 55200
    },
    {
      "epoch": 2.248561611807998,
      "grad_norm": 0.19190074503421783,
      "learning_rate": 0.00042187845792944717,
      "loss": 0.3687,
      "step": 55300
    },
    {
      "epoch": 2.252627726838392,
      "grad_norm": 0.19131501019001007,
      "learning_rate": 0.00042165715044482807,
      "loss": 0.372,
      "step": 55400
    },
    {
      "epoch": 2.2566938418687865,
      "grad_norm": 0.20523633062839508,
      "learning_rate": 0.0004214358429602089,
      "loss": 0.3717,
      "step": 55500
    },
    {
      "epoch": 2.2607599568991805,
      "grad_norm": 0.2314949929714203,
      "learning_rate": 0.0004212145354755898,
      "loss": 0.37,
      "step": 55600
    },
    {
      "epoch": 2.264826071929575,
      "grad_norm": 0.18923158943653107,
      "learning_rate": 0.00042099322799097065,
      "loss": 0.3714,
      "step": 55700
    },
    {
      "epoch": 2.268892186959969,
      "grad_norm": 0.1885201781988144,
      "learning_rate": 0.00042077192050635155,
      "loss": 0.3722,
      "step": 55800
    },
    {
      "epoch": 2.2729583019903634,
      "grad_norm": 0.18836236000061035,
      "learning_rate": 0.00042055061302173245,
      "loss": 0.3717,
      "step": 55900
    },
    {
      "epoch": 2.2770244170207574,
      "grad_norm": 0.2095355987548828,
      "learning_rate": 0.0004203293055371133,
      "loss": 0.3722,
      "step": 56000
    },
    {
      "epoch": 2.2770244170207574,
      "eval_loss": 0.3815976679325104,
      "eval_runtime": 115.6872,
      "eval_samples_per_second": 1511.852,
      "eval_steps_per_second": 47.248,
      "step": 56000
    },
    {
      "epoch": 2.281090532051152,
      "grad_norm": 0.20456792414188385,
      "learning_rate": 0.0004201079980524942,
      "loss": 0.3718,
      "step": 56100
    },
    {
      "epoch": 2.285156647081546,
      "grad_norm": 0.21376648545265198,
      "learning_rate": 0.00041988669056787503,
      "loss": 0.3704,
      "step": 56200
    },
    {
      "epoch": 2.2892227621119403,
      "grad_norm": 0.20134568214416504,
      "learning_rate": 0.0004196653830832559,
      "loss": 0.3697,
      "step": 56300
    },
    {
      "epoch": 2.2932888771423343,
      "grad_norm": 0.20851188898086548,
      "learning_rate": 0.0004194440755986367,
      "loss": 0.3709,
      "step": 56400
    },
    {
      "epoch": 2.2973549921727288,
      "grad_norm": 0.20039768517017365,
      "learning_rate": 0.0004192227681140176,
      "loss": 0.3724,
      "step": 56500
    },
    {
      "epoch": 2.3014211072031228,
      "grad_norm": 0.21543696522712708,
      "learning_rate": 0.00041900146062939846,
      "loss": 0.373,
      "step": 56600
    },
    {
      "epoch": 2.305487222233517,
      "grad_norm": 0.19374623894691467,
      "learning_rate": 0.00041878015314477935,
      "loss": 0.3715,
      "step": 56700
    },
    {
      "epoch": 2.309553337263911,
      "grad_norm": 0.21965770423412323,
      "learning_rate": 0.00041855884566016025,
      "loss": 0.3702,
      "step": 56800
    },
    {
      "epoch": 2.313619452294305,
      "grad_norm": 0.19914090633392334,
      "learning_rate": 0.0004183375381755411,
      "loss": 0.3708,
      "step": 56900
    },
    {
      "epoch": 2.3176855673246997,
      "grad_norm": 0.2008311003446579,
      "learning_rate": 0.000418116230690922,
      "loss": 0.3733,
      "step": 57000
    },
    {
      "epoch": 2.3217516823550937,
      "grad_norm": 0.1842697411775589,
      "learning_rate": 0.00041789492320630284,
      "loss": 0.371,
      "step": 57100
    },
    {
      "epoch": 2.325817797385488,
      "grad_norm": 0.2387673556804657,
      "learning_rate": 0.00041767361572168373,
      "loss": 0.3726,
      "step": 57200
    },
    {
      "epoch": 2.329883912415882,
      "grad_norm": 0.20331627130508423,
      "learning_rate": 0.0004174523082370646,
      "loss": 0.3743,
      "step": 57300
    },
    {
      "epoch": 2.3339500274462766,
      "grad_norm": 0.18198564648628235,
      "learning_rate": 0.0004172310007524455,
      "loss": 0.3678,
      "step": 57400
    },
    {
      "epoch": 2.3380161424766706,
      "grad_norm": 0.19750343263149261,
      "learning_rate": 0.0004170096932678263,
      "loss": 0.3718,
      "step": 57500
    },
    {
      "epoch": 2.342082257507065,
      "grad_norm": 0.22954581677913666,
      "learning_rate": 0.0004167883857832072,
      "loss": 0.3716,
      "step": 57600
    },
    {
      "epoch": 2.346148372537459,
      "grad_norm": 0.20670148730278015,
      "learning_rate": 0.0004165670782985881,
      "loss": 0.371,
      "step": 57700
    },
    {
      "epoch": 2.3502144875678534,
      "grad_norm": 0.1905004382133484,
      "learning_rate": 0.00041634577081396895,
      "loss": 0.3718,
      "step": 57800
    },
    {
      "epoch": 2.3542806025982475,
      "grad_norm": 0.1935940533876419,
      "learning_rate": 0.00041612446332934985,
      "loss": 0.3678,
      "step": 57900
    },
    {
      "epoch": 2.358346717628642,
      "grad_norm": 0.2083207368850708,
      "learning_rate": 0.00041590315584473064,
      "loss": 0.3686,
      "step": 58000
    },
    {
      "epoch": 2.358346717628642,
      "eval_loss": 0.379733681678772,
      "eval_runtime": 116.1034,
      "eval_samples_per_second": 1506.433,
      "eval_steps_per_second": 47.079,
      "step": 58000
    },
    {
      "epoch": 2.362412832659036,
      "grad_norm": 0.20279400050640106,
      "learning_rate": 0.00041568184836011154,
      "loss": 0.3728,
      "step": 58100
    },
    {
      "epoch": 2.36647894768943,
      "grad_norm": 0.19903290271759033,
      "learning_rate": 0.0004154605408754924,
      "loss": 0.3693,
      "step": 58200
    },
    {
      "epoch": 2.3705450627198243,
      "grad_norm": 0.19356802105903625,
      "learning_rate": 0.0004152392333908733,
      "loss": 0.3718,
      "step": 58300
    },
    {
      "epoch": 2.374611177750219,
      "grad_norm": 0.19779466092586517,
      "learning_rate": 0.0004150179259062541,
      "loss": 0.3696,
      "step": 58400
    },
    {
      "epoch": 2.378677292780613,
      "grad_norm": 0.2173301726579666,
      "learning_rate": 0.000414796618421635,
      "loss": 0.3744,
      "step": 58500
    },
    {
      "epoch": 2.382743407811007,
      "grad_norm": 0.1985369473695755,
      "learning_rate": 0.0004145753109370159,
      "loss": 0.3723,
      "step": 58600
    },
    {
      "epoch": 2.3868095228414012,
      "grad_norm": 0.21279627084732056,
      "learning_rate": 0.00041435400345239676,
      "loss": 0.3663,
      "step": 58700
    },
    {
      "epoch": 2.3908756378717952,
      "grad_norm": 0.2150622457265854,
      "learning_rate": 0.00041413269596777766,
      "loss": 0.3739,
      "step": 58800
    },
    {
      "epoch": 2.3949417529021897,
      "grad_norm": 0.23520445823669434,
      "learning_rate": 0.0004139113884831585,
      "loss": 0.3711,
      "step": 58900
    },
    {
      "epoch": 2.3990078679325837,
      "grad_norm": 0.19250120222568512,
      "learning_rate": 0.0004136900809985394,
      "loss": 0.3702,
      "step": 59000
    },
    {
      "epoch": 2.403073982962978,
      "grad_norm": 0.19684681296348572,
      "learning_rate": 0.00041346877351392024,
      "loss": 0.3698,
      "step": 59100
    },
    {
      "epoch": 2.407140097993372,
      "grad_norm": 0.20951668918132782,
      "learning_rate": 0.00041324746602930114,
      "loss": 0.3717,
      "step": 59200
    },
    {
      "epoch": 2.4112062130237666,
      "grad_norm": 0.20251087844371796,
      "learning_rate": 0.000413026158544682,
      "loss": 0.3699,
      "step": 59300
    },
    {
      "epoch": 2.4152723280541606,
      "grad_norm": 0.19746629893779755,
      "learning_rate": 0.0004128048510600629,
      "loss": 0.3701,
      "step": 59400
    },
    {
      "epoch": 2.419338443084555,
      "grad_norm": 0.18342271447181702,
      "learning_rate": 0.0004125835435754438,
      "loss": 0.3697,
      "step": 59500
    },
    {
      "epoch": 2.423404558114949,
      "grad_norm": 0.19516372680664062,
      "learning_rate": 0.0004123622360908246,
      "loss": 0.3719,
      "step": 59600
    },
    {
      "epoch": 2.4274706731453435,
      "grad_norm": 0.20819500088691711,
      "learning_rate": 0.00041214092860620546,
      "loss": 0.37,
      "step": 59700
    },
    {
      "epoch": 2.4315367881757375,
      "grad_norm": 0.19635435938835144,
      "learning_rate": 0.0004119196211215863,
      "loss": 0.3694,
      "step": 59800
    },
    {
      "epoch": 2.4356029032061315,
      "grad_norm": 0.2753678858280182,
      "learning_rate": 0.0004116983136369672,
      "loss": 0.3702,
      "step": 59900
    },
    {
      "epoch": 2.439669018236526,
      "grad_norm": 0.1791457235813141,
      "learning_rate": 0.00041147700615234804,
      "loss": 0.3702,
      "step": 60000
    },
    {
      "epoch": 2.439669018236526,
      "eval_loss": 0.3801264762878418,
      "eval_runtime": 117.1591,
      "eval_samples_per_second": 1492.859,
      "eval_steps_per_second": 46.655,
      "step": 60000
    },
    {
      "epoch": 2.44373513326692,
      "grad_norm": 0.19457481801509857,
      "learning_rate": 0.00041125569866772894,
      "loss": 0.3691,
      "step": 60100
    },
    {
      "epoch": 2.4478012482973144,
      "grad_norm": 0.21961820125579834,
      "learning_rate": 0.00041103439118310984,
      "loss": 0.3722,
      "step": 60200
    },
    {
      "epoch": 2.4518673633277084,
      "grad_norm": 0.18516018986701965,
      "learning_rate": 0.0004108130836984907,
      "loss": 0.3685,
      "step": 60300
    },
    {
      "epoch": 2.455933478358103,
      "grad_norm": 0.215288445353508,
      "learning_rate": 0.0004105917762138716,
      "loss": 0.3694,
      "step": 60400
    },
    {
      "epoch": 2.459999593388497,
      "grad_norm": 0.21754951775074005,
      "learning_rate": 0.0004103704687292524,
      "loss": 0.3695,
      "step": 60500
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 0.20593470335006714,
      "learning_rate": 0.0004101491612446333,
      "loss": 0.3701,
      "step": 60600
    },
    {
      "epoch": 2.4681318234492853,
      "grad_norm": 0.21853163838386536,
      "learning_rate": 0.00040992785376001416,
      "loss": 0.369,
      "step": 60700
    },
    {
      "epoch": 2.4721979384796797,
      "grad_norm": 0.20325590670108795,
      "learning_rate": 0.00040970654627539506,
      "loss": 0.3692,
      "step": 60800
    },
    {
      "epoch": 2.4762640535100737,
      "grad_norm": 0.2211892008781433,
      "learning_rate": 0.0004094852387907759,
      "loss": 0.3698,
      "step": 60900
    },
    {
      "epoch": 2.480330168540468,
      "grad_norm": 0.21970264613628387,
      "learning_rate": 0.0004092639313061568,
      "loss": 0.3681,
      "step": 61000
    },
    {
      "epoch": 2.484396283570862,
      "grad_norm": 0.2193329930305481,
      "learning_rate": 0.0004090426238215377,
      "loss": 0.3712,
      "step": 61100
    },
    {
      "epoch": 2.4884623986012566,
      "grad_norm": 0.19848062098026276,
      "learning_rate": 0.00040882131633691854,
      "loss": 0.3698,
      "step": 61200
    },
    {
      "epoch": 2.4925285136316506,
      "grad_norm": 0.2460699826478958,
      "learning_rate": 0.00040860000885229944,
      "loss": 0.371,
      "step": 61300
    },
    {
      "epoch": 2.496594628662045,
      "grad_norm": 0.1997290849685669,
      "learning_rate": 0.00040837870136768023,
      "loss": 0.3705,
      "step": 61400
    },
    {
      "epoch": 2.500660743692439,
      "grad_norm": 0.22131262719631195,
      "learning_rate": 0.0004081573938830611,
      "loss": 0.3695,
      "step": 61500
    },
    {
      "epoch": 2.504726858722833,
      "grad_norm": 0.21782435476779938,
      "learning_rate": 0.00040793608639844197,
      "loss": 0.3706,
      "step": 61600
    },
    {
      "epoch": 2.5087929737532275,
      "grad_norm": 0.18692100048065186,
      "learning_rate": 0.00040771477891382287,
      "loss": 0.3694,
      "step": 61700
    },
    {
      "epoch": 2.512859088783622,
      "grad_norm": 0.18249529600143433,
      "learning_rate": 0.0004074934714292037,
      "loss": 0.3695,
      "step": 61800
    },
    {
      "epoch": 2.516925203814016,
      "grad_norm": 0.20240356028079987,
      "learning_rate": 0.0004072721639445846,
      "loss": 0.3689,
      "step": 61900
    },
    {
      "epoch": 2.52099131884441,
      "grad_norm": 0.1936977207660675,
      "learning_rate": 0.0004070508564599655,
      "loss": 0.3696,
      "step": 62000
    },
    {
      "epoch": 2.52099131884441,
      "eval_loss": 0.37894466519355774,
      "eval_runtime": 117.1548,
      "eval_samples_per_second": 1492.914,
      "eval_steps_per_second": 46.656,
      "step": 62000
    },
    {
      "epoch": 2.5250574338748044,
      "grad_norm": 0.18226367235183716,
      "learning_rate": 0.00040682954897534635,
      "loss": 0.3701,
      "step": 62100
    },
    {
      "epoch": 2.5291235489051984,
      "grad_norm": 0.19640180468559265,
      "learning_rate": 0.00040660824149072724,
      "loss": 0.3694,
      "step": 62200
    },
    {
      "epoch": 2.533189663935593,
      "grad_norm": 0.2157801389694214,
      "learning_rate": 0.0004063869340061081,
      "loss": 0.3703,
      "step": 62300
    },
    {
      "epoch": 2.537255778965987,
      "grad_norm": 0.18834124505519867,
      "learning_rate": 0.000406165626521489,
      "loss": 0.372,
      "step": 62400
    },
    {
      "epoch": 2.5413218939963813,
      "grad_norm": 0.19414009153842926,
      "learning_rate": 0.00040594431903686983,
      "loss": 0.3693,
      "step": 62500
    },
    {
      "epoch": 2.5453880090267753,
      "grad_norm": 0.17962373793125153,
      "learning_rate": 0.0004057230115522507,
      "loss": 0.3691,
      "step": 62600
    },
    {
      "epoch": 2.5494541240571698,
      "grad_norm": 0.20338621735572815,
      "learning_rate": 0.00040550170406763157,
      "loss": 0.3696,
      "step": 62700
    },
    {
      "epoch": 2.5535202390875638,
      "grad_norm": 0.18933641910552979,
      "learning_rate": 0.00040528039658301246,
      "loss": 0.3699,
      "step": 62800
    },
    {
      "epoch": 2.5575863541179578,
      "grad_norm": 0.20267707109451294,
      "learning_rate": 0.00040505908909839336,
      "loss": 0.3694,
      "step": 62900
    },
    {
      "epoch": 2.561652469148352,
      "grad_norm": 0.19867993891239166,
      "learning_rate": 0.00040483778161377415,
      "loss": 0.3705,
      "step": 63000
    },
    {
      "epoch": 2.5657185841787467,
      "grad_norm": 0.20445328950881958,
      "learning_rate": 0.00040461647412915505,
      "loss": 0.3683,
      "step": 63100
    },
    {
      "epoch": 2.5697846992091407,
      "grad_norm": 0.19494488835334778,
      "learning_rate": 0.0004043951666445359,
      "loss": 0.3695,
      "step": 63200
    },
    {
      "epoch": 2.5738508142395347,
      "grad_norm": 0.20513731241226196,
      "learning_rate": 0.0004041738591599168,
      "loss": 0.3683,
      "step": 63300
    },
    {
      "epoch": 2.577916929269929,
      "grad_norm": 0.21065889298915863,
      "learning_rate": 0.00040395255167529763,
      "loss": 0.3704,
      "step": 63400
    },
    {
      "epoch": 2.581983044300323,
      "grad_norm": 0.18412359058856964,
      "learning_rate": 0.00040373124419067853,
      "loss": 0.369,
      "step": 63500
    },
    {
      "epoch": 2.5860491593307176,
      "grad_norm": 0.227369025349617,
      "learning_rate": 0.00040350993670605937,
      "loss": 0.3699,
      "step": 63600
    },
    {
      "epoch": 2.5901152743611116,
      "grad_norm": 0.21155354380607605,
      "learning_rate": 0.00040328862922144027,
      "loss": 0.3681,
      "step": 63700
    },
    {
      "epoch": 2.594181389391506,
      "grad_norm": 0.1915680170059204,
      "learning_rate": 0.00040306732173682117,
      "loss": 0.3714,
      "step": 63800
    },
    {
      "epoch": 2.5982475044219,
      "grad_norm": 0.2009933888912201,
      "learning_rate": 0.000402846014252202,
      "loss": 0.3708,
      "step": 63900
    },
    {
      "epoch": 2.6023136194522944,
      "grad_norm": 0.17729924619197845,
      "learning_rate": 0.0004026247067675829,
      "loss": 0.3681,
      "step": 64000
    },
    {
      "epoch": 2.6023136194522944,
      "eval_loss": 0.3793582022190094,
      "eval_runtime": 116.3417,
      "eval_samples_per_second": 1503.348,
      "eval_steps_per_second": 46.982,
      "step": 64000
    },
    {
      "epoch": 2.6063797344826884,
      "grad_norm": 0.23639117181301117,
      "learning_rate": 0.00040240339928296375,
      "loss": 0.3694,
      "step": 64100
    },
    {
      "epoch": 2.6104458495130825,
      "grad_norm": 0.21790945529937744,
      "learning_rate": 0.00040218209179834465,
      "loss": 0.3696,
      "step": 64200
    },
    {
      "epoch": 2.614511964543477,
      "grad_norm": 0.20299620926380157,
      "learning_rate": 0.0004019607843137255,
      "loss": 0.3699,
      "step": 64300
    },
    {
      "epoch": 2.6185780795738713,
      "grad_norm": 0.20292270183563232,
      "learning_rate": 0.0004017394768291064,
      "loss": 0.3694,
      "step": 64400
    },
    {
      "epoch": 2.6226441946042653,
      "grad_norm": 0.19002565741539001,
      "learning_rate": 0.0004015181693444873,
      "loss": 0.3699,
      "step": 64500
    },
    {
      "epoch": 2.6267103096346593,
      "grad_norm": 0.21369057893753052,
      "learning_rate": 0.00040129686185986813,
      "loss": 0.3693,
      "step": 64600
    },
    {
      "epoch": 2.630776424665054,
      "grad_norm": 0.19949452579021454,
      "learning_rate": 0.00040107555437524897,
      "loss": 0.3707,
      "step": 64700
    },
    {
      "epoch": 2.6348425396954482,
      "grad_norm": 0.22355559468269348,
      "learning_rate": 0.0004008542468906298,
      "loss": 0.3664,
      "step": 64800
    },
    {
      "epoch": 2.6389086547258422,
      "grad_norm": 0.1925669014453888,
      "learning_rate": 0.0004006329394060107,
      "loss": 0.3669,
      "step": 64900
    },
    {
      "epoch": 2.6429747697562362,
      "grad_norm": 0.20634174346923828,
      "learning_rate": 0.00040041163192139156,
      "loss": 0.3697,
      "step": 65000
    },
    {
      "epoch": 2.6470408847866307,
      "grad_norm": 0.221556156873703,
      "learning_rate": 0.00040019032443677245,
      "loss": 0.3694,
      "step": 65100
    },
    {
      "epoch": 2.6511069998170247,
      "grad_norm": 0.22784298658370972,
      "learning_rate": 0.0003999690169521533,
      "loss": 0.3698,
      "step": 65200
    },
    {
      "epoch": 2.655173114847419,
      "grad_norm": 0.18352743983268738,
      "learning_rate": 0.0003997477094675342,
      "loss": 0.3702,
      "step": 65300
    },
    {
      "epoch": 2.659239229877813,
      "grad_norm": 0.19139008224010468,
      "learning_rate": 0.0003995264019829151,
      "loss": 0.3696,
      "step": 65400
    },
    {
      "epoch": 2.6633053449082076,
      "grad_norm": 0.18683625757694244,
      "learning_rate": 0.00039930509449829593,
      "loss": 0.3707,
      "step": 65500
    },
    {
      "epoch": 2.6673714599386016,
      "grad_norm": 0.1951764076948166,
      "learning_rate": 0.00039908378701367683,
      "loss": 0.3679,
      "step": 65600
    },
    {
      "epoch": 2.671437574968996,
      "grad_norm": 0.21829824149608612,
      "learning_rate": 0.0003988624795290577,
      "loss": 0.3681,
      "step": 65700
    },
    {
      "epoch": 2.67550368999939,
      "grad_norm": 0.2202359139919281,
      "learning_rate": 0.00039864117204443857,
      "loss": 0.3704,
      "step": 65800
    },
    {
      "epoch": 2.679569805029784,
      "grad_norm": 0.19334614276885986,
      "learning_rate": 0.0003984198645598194,
      "loss": 0.3677,
      "step": 65900
    },
    {
      "epoch": 2.6836359200601785,
      "grad_norm": 0.21996021270751953,
      "learning_rate": 0.0003981985570752003,
      "loss": 0.3703,
      "step": 66000
    },
    {
      "epoch": 2.6836359200601785,
      "eval_loss": 0.3792106509208679,
      "eval_runtime": 115.3814,
      "eval_samples_per_second": 1515.859,
      "eval_steps_per_second": 47.373,
      "step": 66000
    },
    {
      "epoch": 2.687702035090573,
      "grad_norm": 0.19560229778289795,
      "learning_rate": 0.00039797724959058116,
      "loss": 0.3686,
      "step": 66100
    },
    {
      "epoch": 2.691768150120967,
      "grad_norm": 0.2137993723154068,
      "learning_rate": 0.00039775594210596205,
      "loss": 0.3695,
      "step": 66200
    },
    {
      "epoch": 2.695834265151361,
      "grad_norm": 0.1941618174314499,
      "learning_rate": 0.00039753463462134295,
      "loss": 0.3668,
      "step": 66300
    },
    {
      "epoch": 2.6999003801817554,
      "grad_norm": 0.21549175679683685,
      "learning_rate": 0.00039731332713672374,
      "loss": 0.3688,
      "step": 66400
    },
    {
      "epoch": 2.70396649521215,
      "grad_norm": 0.23605020344257355,
      "learning_rate": 0.00039709201965210464,
      "loss": 0.3695,
      "step": 66500
    },
    {
      "epoch": 2.708032610242544,
      "grad_norm": 0.2101733684539795,
      "learning_rate": 0.0003968707121674855,
      "loss": 0.3683,
      "step": 66600
    },
    {
      "epoch": 2.712098725272938,
      "grad_norm": 0.19749921560287476,
      "learning_rate": 0.0003966494046828664,
      "loss": 0.3689,
      "step": 66700
    },
    {
      "epoch": 2.7161648403033323,
      "grad_norm": 0.21601995825767517,
      "learning_rate": 0.0003964280971982472,
      "loss": 0.3688,
      "step": 66800
    },
    {
      "epoch": 2.7202309553337263,
      "grad_norm": 0.20567281544208527,
      "learning_rate": 0.0003962067897136281,
      "loss": 0.3696,
      "step": 66900
    },
    {
      "epoch": 2.7242970703641207,
      "grad_norm": 0.20086652040481567,
      "learning_rate": 0.00039598548222900896,
      "loss": 0.3691,
      "step": 67000
    },
    {
      "epoch": 2.7283631853945147,
      "grad_norm": 0.22205357253551483,
      "learning_rate": 0.00039576417474438986,
      "loss": 0.3675,
      "step": 67100
    },
    {
      "epoch": 2.732429300424909,
      "grad_norm": 0.20810580253601074,
      "learning_rate": 0.00039554286725977075,
      "loss": 0.3684,
      "step": 67200
    },
    {
      "epoch": 2.736495415455303,
      "grad_norm": 0.23333917558193207,
      "learning_rate": 0.0003953215597751516,
      "loss": 0.369,
      "step": 67300
    },
    {
      "epoch": 2.7405615304856976,
      "grad_norm": 0.2241942286491394,
      "learning_rate": 0.0003951002522905325,
      "loss": 0.3686,
      "step": 67400
    },
    {
      "epoch": 2.7446276455160916,
      "grad_norm": 0.22532504796981812,
      "learning_rate": 0.00039487894480591334,
      "loss": 0.3702,
      "step": 67500
    },
    {
      "epoch": 2.7486937605464856,
      "grad_norm": 0.20530574023723602,
      "learning_rate": 0.00039465763732129424,
      "loss": 0.3705,
      "step": 67600
    },
    {
      "epoch": 2.75275987557688,
      "grad_norm": 0.20896703004837036,
      "learning_rate": 0.0003944363298366751,
      "loss": 0.3684,
      "step": 67700
    },
    {
      "epoch": 2.7568259906072745,
      "grad_norm": 0.22776050865650177,
      "learning_rate": 0.000394215022352056,
      "loss": 0.3689,
      "step": 67800
    },
    {
      "epoch": 2.7608921056376685,
      "grad_norm": 0.23754911124706268,
      "learning_rate": 0.0003939937148674369,
      "loss": 0.3682,
      "step": 67900
    },
    {
      "epoch": 2.7649582206680625,
      "grad_norm": 0.22158680856227875,
      "learning_rate": 0.0003937724073828177,
      "loss": 0.3697,
      "step": 68000
    },
    {
      "epoch": 2.7649582206680625,
      "eval_loss": 0.3786788582801819,
      "eval_runtime": 115.2993,
      "eval_samples_per_second": 1516.94,
      "eval_steps_per_second": 47.407,
      "step": 68000
    },
    {
      "epoch": 2.769024335698457,
      "grad_norm": 0.19412320852279663,
      "learning_rate": 0.00039355109989819856,
      "loss": 0.3682,
      "step": 68100
    },
    {
      "epoch": 2.773090450728851,
      "grad_norm": 0.2263018786907196,
      "learning_rate": 0.0003933297924135794,
      "loss": 0.3693,
      "step": 68200
    },
    {
      "epoch": 2.7771565657592454,
      "grad_norm": 0.1939777135848999,
      "learning_rate": 0.0003931084849289603,
      "loss": 0.3656,
      "step": 68300
    },
    {
      "epoch": 2.7812226807896394,
      "grad_norm": 0.18165342509746552,
      "learning_rate": 0.00039288717744434114,
      "loss": 0.3675,
      "step": 68400
    },
    {
      "epoch": 2.785288795820034,
      "grad_norm": 0.20854954421520233,
      "learning_rate": 0.00039266586995972204,
      "loss": 0.3684,
      "step": 68500
    },
    {
      "epoch": 2.789354910850428,
      "grad_norm": 0.21920309960842133,
      "learning_rate": 0.0003924445624751029,
      "loss": 0.3703,
      "step": 68600
    },
    {
      "epoch": 2.7934210258808223,
      "grad_norm": 0.2302401214838028,
      "learning_rate": 0.0003922232549904838,
      "loss": 0.3683,
      "step": 68700
    },
    {
      "epoch": 2.7974871409112163,
      "grad_norm": 0.20075523853302002,
      "learning_rate": 0.0003920019475058647,
      "loss": 0.3691,
      "step": 68800
    },
    {
      "epoch": 2.8015532559416108,
      "grad_norm": 0.2218591868877411,
      "learning_rate": 0.0003917806400212455,
      "loss": 0.3699,
      "step": 68900
    },
    {
      "epoch": 2.8056193709720048,
      "grad_norm": 0.2516324818134308,
      "learning_rate": 0.0003915593325366264,
      "loss": 0.3688,
      "step": 69000
    },
    {
      "epoch": 2.809685486002399,
      "grad_norm": 0.20564153790473938,
      "learning_rate": 0.00039133802505200726,
      "loss": 0.3681,
      "step": 69100
    },
    {
      "epoch": 2.813751601032793,
      "grad_norm": 0.20714633166790009,
      "learning_rate": 0.00039111671756738816,
      "loss": 0.3692,
      "step": 69200
    },
    {
      "epoch": 2.817817716063187,
      "grad_norm": 0.2017376869916916,
      "learning_rate": 0.000390895410082769,
      "loss": 0.3692,
      "step": 69300
    },
    {
      "epoch": 2.8218838310935817,
      "grad_norm": 0.22718343138694763,
      "learning_rate": 0.0003906741025981499,
      "loss": 0.3674,
      "step": 69400
    },
    {
      "epoch": 2.825949946123976,
      "grad_norm": 0.23389090597629547,
      "learning_rate": 0.00039045279511353074,
      "loss": 0.3676,
      "step": 69500
    },
    {
      "epoch": 2.83001606115437,
      "grad_norm": 0.20807534456253052,
      "learning_rate": 0.00039023148762891164,
      "loss": 0.3668,
      "step": 69600
    },
    {
      "epoch": 2.834082176184764,
      "grad_norm": 0.2323312908411026,
      "learning_rate": 0.00039001018014429254,
      "loss": 0.3693,
      "step": 69700
    },
    {
      "epoch": 2.8381482912151585,
      "grad_norm": 0.2182055562734604,
      "learning_rate": 0.0003897888726596733,
      "loss": 0.3682,
      "step": 69800
    },
    {
      "epoch": 2.8422144062455525,
      "grad_norm": 0.21454787254333496,
      "learning_rate": 0.0003895675651750542,
      "loss": 0.3685,
      "step": 69900
    },
    {
      "epoch": 2.846280521275947,
      "grad_norm": 0.2051391899585724,
      "learning_rate": 0.00038934625769043507,
      "loss": 0.3667,
      "step": 70000
    },
    {
      "epoch": 2.846280521275947,
      "eval_loss": 0.3773743212223053,
      "eval_runtime": 115.588,
      "eval_samples_per_second": 1513.15,
      "eval_steps_per_second": 47.289,
      "step": 70000
    },
    {
      "epoch": 2.850346636306341,
      "grad_norm": 0.23753397166728973,
      "learning_rate": 0.00038912495020581596,
      "loss": 0.3701,
      "step": 70100
    },
    {
      "epoch": 2.8544127513367354,
      "grad_norm": 0.22602517902851105,
      "learning_rate": 0.0003889036427211968,
      "loss": 0.3674,
      "step": 70200
    },
    {
      "epoch": 2.8584788663671294,
      "grad_norm": 0.21134711802005768,
      "learning_rate": 0.0003886823352365777,
      "loss": 0.3676,
      "step": 70300
    },
    {
      "epoch": 2.862544981397524,
      "grad_norm": 0.2312232106924057,
      "learning_rate": 0.00038846102775195855,
      "loss": 0.3671,
      "step": 70400
    },
    {
      "epoch": 2.866611096427918,
      "grad_norm": 0.20754879713058472,
      "learning_rate": 0.00038823972026733944,
      "loss": 0.3682,
      "step": 70500
    },
    {
      "epoch": 2.870677211458312,
      "grad_norm": 0.20936334133148193,
      "learning_rate": 0.00038801841278272034,
      "loss": 0.3709,
      "step": 70600
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 0.2240649163722992,
      "learning_rate": 0.0003877971052981012,
      "loss": 0.3681,
      "step": 70700
    },
    {
      "epoch": 2.878809441519101,
      "grad_norm": 0.23152369260787964,
      "learning_rate": 0.0003875757978134821,
      "loss": 0.3698,
      "step": 70800
    },
    {
      "epoch": 2.882875556549495,
      "grad_norm": 0.20951929688453674,
      "learning_rate": 0.0003873544903288629,
      "loss": 0.3674,
      "step": 70900
    },
    {
      "epoch": 2.886941671579889,
      "grad_norm": 0.21040776371955872,
      "learning_rate": 0.0003871331828442438,
      "loss": 0.3698,
      "step": 71000
    },
    {
      "epoch": 2.8910077866102832,
      "grad_norm": 0.2353573441505432,
      "learning_rate": 0.00038691187535962467,
      "loss": 0.3666,
      "step": 71100
    },
    {
      "epoch": 2.8950739016406777,
      "grad_norm": 0.22904591262340546,
      "learning_rate": 0.00038669056787500556,
      "loss": 0.3679,
      "step": 71200
    },
    {
      "epoch": 2.8991400166710717,
      "grad_norm": 0.1956089437007904,
      "learning_rate": 0.00038646926039038646,
      "loss": 0.3684,
      "step": 71300
    },
    {
      "epoch": 2.9032061317014657,
      "grad_norm": 0.234422966837883,
      "learning_rate": 0.0003862479529057673,
      "loss": 0.367,
      "step": 71400
    },
    {
      "epoch": 2.90727224673186,
      "grad_norm": 0.23497574031352997,
      "learning_rate": 0.00038602664542114815,
      "loss": 0.3696,
      "step": 71500
    },
    {
      "epoch": 2.911338361762254,
      "grad_norm": 0.22717759013175964,
      "learning_rate": 0.000385805337936529,
      "loss": 0.3694,
      "step": 71600
    },
    {
      "epoch": 2.9154044767926486,
      "grad_norm": 0.19220443069934845,
      "learning_rate": 0.0003855840304519099,
      "loss": 0.3663,
      "step": 71700
    },
    {
      "epoch": 2.9194705918230426,
      "grad_norm": 0.2186766117811203,
      "learning_rate": 0.00038536272296729073,
      "loss": 0.3677,
      "step": 71800
    },
    {
      "epoch": 2.923536706853437,
      "grad_norm": 0.232340469956398,
      "learning_rate": 0.00038514141548267163,
      "loss": 0.3673,
      "step": 71900
    },
    {
      "epoch": 2.927602821883831,
      "grad_norm": 0.2152978479862213,
      "learning_rate": 0.00038492010799805247,
      "loss": 0.3675,
      "step": 72000
    },
    {
      "epoch": 2.927602821883831,
      "eval_loss": 0.3761478364467621,
      "eval_runtime": 116.4335,
      "eval_samples_per_second": 1502.162,
      "eval_steps_per_second": 46.945,
      "step": 72000
    },
    {
      "epoch": 2.9316689369142255,
      "grad_norm": 0.25035524368286133,
      "learning_rate": 0.00038469880051343337,
      "loss": 0.3659,
      "step": 72100
    },
    {
      "epoch": 2.9357350519446195,
      "grad_norm": 0.21018366515636444,
      "learning_rate": 0.00038447749302881427,
      "loss": 0.3675,
      "step": 72200
    },
    {
      "epoch": 2.9398011669750135,
      "grad_norm": 0.21848076581954956,
      "learning_rate": 0.0003842561855441951,
      "loss": 0.3666,
      "step": 72300
    },
    {
      "epoch": 2.943867282005408,
      "grad_norm": 0.2341652661561966,
      "learning_rate": 0.000384034878059576,
      "loss": 0.3682,
      "step": 72400
    },
    {
      "epoch": 2.9479333970358024,
      "grad_norm": 0.25077664852142334,
      "learning_rate": 0.00038381357057495685,
      "loss": 0.3655,
      "step": 72500
    },
    {
      "epoch": 2.9519995120661964,
      "grad_norm": 0.20561876893043518,
      "learning_rate": 0.00038359226309033775,
      "loss": 0.3671,
      "step": 72600
    },
    {
      "epoch": 2.9560656270965904,
      "grad_norm": 0.22928544878959656,
      "learning_rate": 0.0003833709556057186,
      "loss": 0.3673,
      "step": 72700
    },
    {
      "epoch": 2.960131742126985,
      "grad_norm": 0.2610863745212555,
      "learning_rate": 0.0003831496481210995,
      "loss": 0.3678,
      "step": 72800
    },
    {
      "epoch": 2.964197857157379,
      "grad_norm": 0.2151983082294464,
      "learning_rate": 0.00038292834063648033,
      "loss": 0.3668,
      "step": 72900
    },
    {
      "epoch": 2.9682639721877733,
      "grad_norm": 0.24378426373004913,
      "learning_rate": 0.00038270703315186123,
      "loss": 0.368,
      "step": 73000
    },
    {
      "epoch": 2.9723300872181673,
      "grad_norm": 0.24988776445388794,
      "learning_rate": 0.0003824857256672421,
      "loss": 0.3671,
      "step": 73100
    },
    {
      "epoch": 2.9763962022485617,
      "grad_norm": 0.2058624029159546,
      "learning_rate": 0.0003822644181826229,
      "loss": 0.3663,
      "step": 73200
    },
    {
      "epoch": 2.9804623172789557,
      "grad_norm": 0.2088053822517395,
      "learning_rate": 0.0003820431106980038,
      "loss": 0.3665,
      "step": 73300
    },
    {
      "epoch": 2.98452843230935,
      "grad_norm": 0.21878419816493988,
      "learning_rate": 0.00038182180321338465,
      "loss": 0.3677,
      "step": 73400
    },
    {
      "epoch": 2.988594547339744,
      "grad_norm": 0.23516879975795746,
      "learning_rate": 0.00038160049572876555,
      "loss": 0.3668,
      "step": 73500
    },
    {
      "epoch": 2.9926606623701386,
      "grad_norm": 0.24865388870239258,
      "learning_rate": 0.0003813791882441464,
      "loss": 0.3668,
      "step": 73600
    },
    {
      "epoch": 2.9967267774005326,
      "grad_norm": 0.2186514139175415,
      "learning_rate": 0.0003811578807595273,
      "loss": 0.3657,
      "step": 73700
    },
    {
      "epoch": 3.000792892430927,
      "grad_norm": 0.21599556505680084,
      "learning_rate": 0.00038093657327490813,
      "loss": 0.3677,
      "step": 73800
    },
    {
      "epoch": 3.004859007461321,
      "grad_norm": 0.20407642424106598,
      "learning_rate": 0.00038071526579028903,
      "loss": 0.3631,
      "step": 73900
    },
    {
      "epoch": 3.0089251224917155,
      "grad_norm": 0.21059106290340424,
      "learning_rate": 0.00038049395830566993,
      "loss": 0.362,
      "step": 74000
    },
    {
      "epoch": 3.0089251224917155,
      "eval_loss": 0.3779156804084778,
      "eval_runtime": 116.7654,
      "eval_samples_per_second": 1497.893,
      "eval_steps_per_second": 46.812,
      "step": 74000
    },
    {
      "epoch": 3.0129912375221095,
      "grad_norm": 0.2189810872077942,
      "learning_rate": 0.00038027265082105077,
      "loss": 0.3637,
      "step": 74100
    },
    {
      "epoch": 3.0170573525525035,
      "grad_norm": 0.2339489609003067,
      "learning_rate": 0.00038005134333643167,
      "loss": 0.3649,
      "step": 74200
    },
    {
      "epoch": 3.021123467582898,
      "grad_norm": 0.2155628502368927,
      "learning_rate": 0.0003798300358518125,
      "loss": 0.3633,
      "step": 74300
    },
    {
      "epoch": 3.025189582613292,
      "grad_norm": 0.2021600306034088,
      "learning_rate": 0.0003796087283671934,
      "loss": 0.3634,
      "step": 74400
    },
    {
      "epoch": 3.0292556976436864,
      "grad_norm": 0.2047766000032425,
      "learning_rate": 0.00037938742088257425,
      "loss": 0.3626,
      "step": 74500
    },
    {
      "epoch": 3.0333218126740804,
      "grad_norm": 0.24624934792518616,
      "learning_rate": 0.00037916611339795515,
      "loss": 0.3629,
      "step": 74600
    },
    {
      "epoch": 3.037387927704475,
      "grad_norm": 0.26001110672950745,
      "learning_rate": 0.00037894480591333605,
      "loss": 0.3634,
      "step": 74700
    },
    {
      "epoch": 3.041454042734869,
      "grad_norm": 0.25005680322647095,
      "learning_rate": 0.00037872349842871684,
      "loss": 0.3617,
      "step": 74800
    },
    {
      "epoch": 3.0455201577652633,
      "grad_norm": 0.22054673731327057,
      "learning_rate": 0.00037850219094409773,
      "loss": 0.3649,
      "step": 74900
    },
    {
      "epoch": 3.0495862727956573,
      "grad_norm": 0.22092166543006897,
      "learning_rate": 0.0003782808834594786,
      "loss": 0.3628,
      "step": 75000
    },
    {
      "epoch": 3.0536523878260518,
      "grad_norm": 0.24600031971931458,
      "learning_rate": 0.0003780595759748595,
      "loss": 0.3623,
      "step": 75100
    },
    {
      "epoch": 3.0577185028564458,
      "grad_norm": 0.21824340522289276,
      "learning_rate": 0.0003778382684902403,
      "loss": 0.3638,
      "step": 75200
    },
    {
      "epoch": 3.06178461788684,
      "grad_norm": 0.24908170104026794,
      "learning_rate": 0.0003776169610056212,
      "loss": 0.3647,
      "step": 75300
    },
    {
      "epoch": 3.065850732917234,
      "grad_norm": 0.22387398779392242,
      "learning_rate": 0.00037739565352100206,
      "loss": 0.3625,
      "step": 75400
    },
    {
      "epoch": 3.0699168479476286,
      "grad_norm": 0.20845714211463928,
      "learning_rate": 0.00037717434603638296,
      "loss": 0.3638,
      "step": 75500
    },
    {
      "epoch": 3.0739829629780226,
      "grad_norm": 0.2448919713497162,
      "learning_rate": 0.00037695303855176385,
      "loss": 0.3627,
      "step": 75600
    },
    {
      "epoch": 3.0780490780084167,
      "grad_norm": 0.24125951528549194,
      "learning_rate": 0.0003767317310671447,
      "loss": 0.3638,
      "step": 75700
    },
    {
      "epoch": 3.082115193038811,
      "grad_norm": 0.24140208959579468,
      "learning_rate": 0.0003765104235825256,
      "loss": 0.3629,
      "step": 75800
    },
    {
      "epoch": 3.086181308069205,
      "grad_norm": 0.2174530178308487,
      "learning_rate": 0.00037628911609790644,
      "loss": 0.3636,
      "step": 75900
    },
    {
      "epoch": 3.0902474230995995,
      "grad_norm": 0.22373943030834198,
      "learning_rate": 0.00037606780861328733,
      "loss": 0.3654,
      "step": 76000
    },
    {
      "epoch": 3.0902474230995995,
      "eval_loss": 0.37577828764915466,
      "eval_runtime": 115.4664,
      "eval_samples_per_second": 1514.744,
      "eval_steps_per_second": 47.338,
      "step": 76000
    },
    {
      "epoch": 3.0943135381299935,
      "grad_norm": 0.23820911347866058,
      "learning_rate": 0.0003758465011286682,
      "loss": 0.3615,
      "step": 76100
    },
    {
      "epoch": 3.098379653160388,
      "grad_norm": 0.22827669978141785,
      "learning_rate": 0.0003756251936440491,
      "loss": 0.364,
      "step": 76200
    },
    {
      "epoch": 3.102445768190782,
      "grad_norm": 0.24431395530700684,
      "learning_rate": 0.0003754038861594299,
      "loss": 0.363,
      "step": 76300
    },
    {
      "epoch": 3.1065118832211764,
      "grad_norm": 0.22085820138454437,
      "learning_rate": 0.0003751825786748108,
      "loss": 0.3651,
      "step": 76400
    },
    {
      "epoch": 3.1105779982515704,
      "grad_norm": 0.24812744557857513,
      "learning_rate": 0.00037496127119019166,
      "loss": 0.3635,
      "step": 76500
    },
    {
      "epoch": 3.114644113281965,
      "grad_norm": 0.2321995496749878,
      "learning_rate": 0.0003747399637055725,
      "loss": 0.3649,
      "step": 76600
    },
    {
      "epoch": 3.118710228312359,
      "grad_norm": 0.24146905541419983,
      "learning_rate": 0.0003745186562209534,
      "loss": 0.3628,
      "step": 76700
    },
    {
      "epoch": 3.1227763433427533,
      "grad_norm": 0.2555285394191742,
      "learning_rate": 0.00037429734873633424,
      "loss": 0.365,
      "step": 76800
    },
    {
      "epoch": 3.1268424583731473,
      "grad_norm": 0.2245778739452362,
      "learning_rate": 0.00037407604125171514,
      "loss": 0.3648,
      "step": 76900
    },
    {
      "epoch": 3.130908573403542,
      "grad_norm": 0.2143036425113678,
      "learning_rate": 0.000373854733767096,
      "loss": 0.3661,
      "step": 77000
    },
    {
      "epoch": 3.134974688433936,
      "grad_norm": 0.219170942902565,
      "learning_rate": 0.0003736334262824769,
      "loss": 0.3637,
      "step": 77100
    },
    {
      "epoch": 3.1390408034643302,
      "grad_norm": 0.23818852007389069,
      "learning_rate": 0.0003734121187978577,
      "loss": 0.3661,
      "step": 77200
    },
    {
      "epoch": 3.1431069184947242,
      "grad_norm": 0.206028550863266,
      "learning_rate": 0.0003731908113132386,
      "loss": 0.3633,
      "step": 77300
    },
    {
      "epoch": 3.1471730335251182,
      "grad_norm": 0.24242419004440308,
      "learning_rate": 0.0003729695038286195,
      "loss": 0.364,
      "step": 77400
    },
    {
      "epoch": 3.1512391485555127,
      "grad_norm": 0.2440076619386673,
      "learning_rate": 0.00037274819634400036,
      "loss": 0.3642,
      "step": 77500
    },
    {
      "epoch": 3.1553052635859067,
      "grad_norm": 0.2161184400320053,
      "learning_rate": 0.00037252688885938126,
      "loss": 0.3631,
      "step": 77600
    },
    {
      "epoch": 3.159371378616301,
      "grad_norm": 0.2234247922897339,
      "learning_rate": 0.0003723055813747621,
      "loss": 0.3648,
      "step": 77700
    },
    {
      "epoch": 3.163437493646695,
      "grad_norm": 0.21488463878631592,
      "learning_rate": 0.000372084273890143,
      "loss": 0.3635,
      "step": 77800
    },
    {
      "epoch": 3.1675036086770896,
      "grad_norm": 0.25293856859207153,
      "learning_rate": 0.00037186296640552384,
      "loss": 0.3664,
      "step": 77900
    },
    {
      "epoch": 3.1715697237074836,
      "grad_norm": 0.20989114046096802,
      "learning_rate": 0.00037164165892090474,
      "loss": 0.3646,
      "step": 78000
    },
    {
      "epoch": 3.1715697237074836,
      "eval_loss": 0.3752896189689636,
      "eval_runtime": 114.8668,
      "eval_samples_per_second": 1522.65,
      "eval_steps_per_second": 47.586,
      "step": 78000
    },
    {
      "epoch": 3.175635838737878,
      "grad_norm": 0.23580186069011688,
      "learning_rate": 0.0003714203514362856,
      "loss": 0.3656,
      "step": 78100
    },
    {
      "epoch": 3.179701953768272,
      "grad_norm": 0.24966932833194733,
      "learning_rate": 0.0003711990439516664,
      "loss": 0.3652,
      "step": 78200
    },
    {
      "epoch": 3.1837680687986665,
      "grad_norm": 0.20836769044399261,
      "learning_rate": 0.0003709777364670473,
      "loss": 0.365,
      "step": 78300
    },
    {
      "epoch": 3.1878341838290605,
      "grad_norm": 0.23464500904083252,
      "learning_rate": 0.00037075642898242817,
      "loss": 0.3651,
      "step": 78400
    },
    {
      "epoch": 3.191900298859455,
      "grad_norm": 0.22681671380996704,
      "learning_rate": 0.00037053512149780906,
      "loss": 0.3623,
      "step": 78500
    },
    {
      "epoch": 3.195966413889849,
      "grad_norm": 0.24183514714241028,
      "learning_rate": 0.0003703138140131899,
      "loss": 0.3652,
      "step": 78600
    },
    {
      "epoch": 3.200032528920243,
      "grad_norm": 0.23503676056861877,
      "learning_rate": 0.0003700925065285708,
      "loss": 0.3631,
      "step": 78700
    },
    {
      "epoch": 3.2040986439506374,
      "grad_norm": 0.22397662699222565,
      "learning_rate": 0.00036987119904395165,
      "loss": 0.3625,
      "step": 78800
    },
    {
      "epoch": 3.2081647589810314,
      "grad_norm": 0.223880335688591,
      "learning_rate": 0.00036964989155933254,
      "loss": 0.365,
      "step": 78900
    },
    {
      "epoch": 3.212230874011426,
      "grad_norm": 0.26159030199050903,
      "learning_rate": 0.00036942858407471344,
      "loss": 0.3651,
      "step": 79000
    },
    {
      "epoch": 3.21629698904182,
      "grad_norm": 0.2598991096019745,
      "learning_rate": 0.0003692072765900943,
      "loss": 0.3642,
      "step": 79100
    },
    {
      "epoch": 3.2203631040722143,
      "grad_norm": 0.24468645453453064,
      "learning_rate": 0.0003689859691054752,
      "loss": 0.3632,
      "step": 79200
    },
    {
      "epoch": 3.2244292191026083,
      "grad_norm": 0.23547929525375366,
      "learning_rate": 0.000368764661620856,
      "loss": 0.3633,
      "step": 79300
    },
    {
      "epoch": 3.2284953341330027,
      "grad_norm": 0.21568308770656586,
      "learning_rate": 0.0003685433541362369,
      "loss": 0.3632,
      "step": 79400
    },
    {
      "epoch": 3.2325614491633967,
      "grad_norm": 0.23659756779670715,
      "learning_rate": 0.00036832204665161776,
      "loss": 0.3639,
      "step": 79500
    },
    {
      "epoch": 3.236627564193791,
      "grad_norm": 0.20488876104354858,
      "learning_rate": 0.00036810073916699866,
      "loss": 0.3642,
      "step": 79600
    },
    {
      "epoch": 3.240693679224185,
      "grad_norm": 0.20615799725055695,
      "learning_rate": 0.0003678794316823795,
      "loss": 0.3631,
      "step": 79700
    },
    {
      "epoch": 3.2447597942545796,
      "grad_norm": 0.20958787202835083,
      "learning_rate": 0.0003676581241977604,
      "loss": 0.363,
      "step": 79800
    },
    {
      "epoch": 3.2488259092849736,
      "grad_norm": 0.24075020849704742,
      "learning_rate": 0.00036743681671314125,
      "loss": 0.3647,
      "step": 79900
    },
    {
      "epoch": 3.252892024315368,
      "grad_norm": 0.22352047264575958,
      "learning_rate": 0.0003672155092285221,
      "loss": 0.3633,
      "step": 80000
    },
    {
      "epoch": 3.252892024315368,
      "eval_loss": 0.3752223253250122,
      "eval_runtime": 114.993,
      "eval_samples_per_second": 1520.979,
      "eval_steps_per_second": 47.533,
      "step": 80000
    },
    {
      "epoch": 3.256958139345762,
      "grad_norm": 0.2220444232225418,
      "learning_rate": 0.000366994201743903,
      "loss": 0.3625,
      "step": 80100
    },
    {
      "epoch": 3.2610242543761565,
      "grad_norm": 0.22224019467830658,
      "learning_rate": 0.00036677289425928383,
      "loss": 0.3637,
      "step": 80200
    },
    {
      "epoch": 3.2650903694065505,
      "grad_norm": 0.22569015622138977,
      "learning_rate": 0.0003665515867746647,
      "loss": 0.3625,
      "step": 80300
    },
    {
      "epoch": 3.2691564844369445,
      "grad_norm": 0.24142229557037354,
      "learning_rate": 0.00036633027929004557,
      "loss": 0.3659,
      "step": 80400
    },
    {
      "epoch": 3.273222599467339,
      "grad_norm": 0.2682609558105469,
      "learning_rate": 0.00036610897180542647,
      "loss": 0.3645,
      "step": 80500
    },
    {
      "epoch": 3.277288714497733,
      "grad_norm": 0.2500695586204529,
      "learning_rate": 0.0003658876643208073,
      "loss": 0.364,
      "step": 80600
    },
    {
      "epoch": 3.2813548295281274,
      "grad_norm": 0.28427132964134216,
      "learning_rate": 0.0003656663568361882,
      "loss": 0.3648,
      "step": 80700
    },
    {
      "epoch": 3.2854209445585214,
      "grad_norm": 0.2112388014793396,
      "learning_rate": 0.0003654450493515691,
      "loss": 0.365,
      "step": 80800
    },
    {
      "epoch": 3.289487059588916,
      "grad_norm": 0.20184428989887238,
      "learning_rate": 0.00036522374186694995,
      "loss": 0.364,
      "step": 80900
    },
    {
      "epoch": 3.29355317461931,
      "grad_norm": 0.22183246910572052,
      "learning_rate": 0.00036500243438233085,
      "loss": 0.3661,
      "step": 81000
    },
    {
      "epoch": 3.2976192896497043,
      "grad_norm": 0.22923140227794647,
      "learning_rate": 0.0003647811268977117,
      "loss": 0.3641,
      "step": 81100
    },
    {
      "epoch": 3.3016854046800983,
      "grad_norm": 0.25027748942375183,
      "learning_rate": 0.0003645598194130926,
      "loss": 0.3666,
      "step": 81200
    },
    {
      "epoch": 3.3057515197104927,
      "grad_norm": 0.22288687527179718,
      "learning_rate": 0.00036433851192847343,
      "loss": 0.3627,
      "step": 81300
    },
    {
      "epoch": 3.3098176347408867,
      "grad_norm": 0.23782004415988922,
      "learning_rate": 0.0003641172044438543,
      "loss": 0.3664,
      "step": 81400
    },
    {
      "epoch": 3.313883749771281,
      "grad_norm": 0.21985149383544922,
      "learning_rate": 0.00036389589695923517,
      "loss": 0.3632,
      "step": 81500
    },
    {
      "epoch": 3.317949864801675,
      "grad_norm": 0.2960411310195923,
      "learning_rate": 0.000363674589474616,
      "loss": 0.3641,
      "step": 81600
    },
    {
      "epoch": 3.3220159798320696,
      "grad_norm": 0.30064085125923157,
      "learning_rate": 0.0003634532819899969,
      "loss": 0.3635,
      "step": 81700
    },
    {
      "epoch": 3.3260820948624636,
      "grad_norm": 0.23093043267726898,
      "learning_rate": 0.00036323197450537775,
      "loss": 0.3641,
      "step": 81800
    },
    {
      "epoch": 3.330148209892858,
      "grad_norm": 0.22782744467258453,
      "learning_rate": 0.00036301066702075865,
      "loss": 0.3644,
      "step": 81900
    },
    {
      "epoch": 3.334214324923252,
      "grad_norm": 0.21797162294387817,
      "learning_rate": 0.0003627893595361395,
      "loss": 0.3627,
      "step": 82000
    },
    {
      "epoch": 3.334214324923252,
      "eval_loss": 0.3747650980949402,
      "eval_runtime": 114.9966,
      "eval_samples_per_second": 1520.932,
      "eval_steps_per_second": 47.532,
      "step": 82000
    },
    {
      "epoch": 3.338280439953646,
      "grad_norm": 0.2336089164018631,
      "learning_rate": 0.0003625680520515204,
      "loss": 0.3651,
      "step": 82100
    },
    {
      "epoch": 3.3423465549840405,
      "grad_norm": 0.23668882250785828,
      "learning_rate": 0.00036234674456690123,
      "loss": 0.362,
      "step": 82200
    },
    {
      "epoch": 3.3464126700144345,
      "grad_norm": 0.25698843598365784,
      "learning_rate": 0.00036212543708228213,
      "loss": 0.363,
      "step": 82300
    },
    {
      "epoch": 3.350478785044829,
      "grad_norm": 0.22416013479232788,
      "learning_rate": 0.000361904129597663,
      "loss": 0.3656,
      "step": 82400
    },
    {
      "epoch": 3.354544900075223,
      "grad_norm": 0.2474612593650818,
      "learning_rate": 0.00036168282211304387,
      "loss": 0.363,
      "step": 82500
    },
    {
      "epoch": 3.3586110151056174,
      "grad_norm": 0.2556630074977875,
      "learning_rate": 0.00036146151462842477,
      "loss": 0.3638,
      "step": 82600
    },
    {
      "epoch": 3.3626771301360114,
      "grad_norm": 0.23630954325199127,
      "learning_rate": 0.0003612402071438056,
      "loss": 0.3655,
      "step": 82700
    },
    {
      "epoch": 3.366743245166406,
      "grad_norm": 0.25329717993736267,
      "learning_rate": 0.0003610188996591865,
      "loss": 0.3632,
      "step": 82800
    },
    {
      "epoch": 3.3708093601968,
      "grad_norm": 0.24891747534275055,
      "learning_rate": 0.00036079759217456735,
      "loss": 0.365,
      "step": 82900
    },
    {
      "epoch": 3.3748754752271943,
      "grad_norm": 0.26364415884017944,
      "learning_rate": 0.00036057628468994825,
      "loss": 0.3652,
      "step": 83000
    },
    {
      "epoch": 3.3789415902575883,
      "grad_norm": 0.19596603512763977,
      "learning_rate": 0.0003603549772053291,
      "loss": 0.3636,
      "step": 83100
    },
    {
      "epoch": 3.383007705287983,
      "grad_norm": 0.21141186356544495,
      "learning_rate": 0.00036013366972071,
      "loss": 0.3616,
      "step": 83200
    },
    {
      "epoch": 3.387073820318377,
      "grad_norm": 0.24079737067222595,
      "learning_rate": 0.00035991236223609083,
      "loss": 0.3635,
      "step": 83300
    },
    {
      "epoch": 3.391139935348771,
      "grad_norm": 0.20597931742668152,
      "learning_rate": 0.0003596910547514717,
      "loss": 0.3625,
      "step": 83400
    },
    {
      "epoch": 3.3952060503791652,
      "grad_norm": 0.2668294608592987,
      "learning_rate": 0.0003594697472668526,
      "loss": 0.3639,
      "step": 83500
    },
    {
      "epoch": 3.3992721654095597,
      "grad_norm": 0.2094055414199829,
      "learning_rate": 0.0003592484397822334,
      "loss": 0.3619,
      "step": 83600
    },
    {
      "epoch": 3.4033382804399537,
      "grad_norm": 0.24036918580532074,
      "learning_rate": 0.0003590271322976143,
      "loss": 0.3631,
      "step": 83700
    },
    {
      "epoch": 3.4074043954703477,
      "grad_norm": 0.23177731037139893,
      "learning_rate": 0.00035880582481299516,
      "loss": 0.3648,
      "step": 83800
    },
    {
      "epoch": 3.411470510500742,
      "grad_norm": 0.22337040305137634,
      "learning_rate": 0.00035858451732837605,
      "loss": 0.3623,
      "step": 83900
    },
    {
      "epoch": 3.415536625531136,
      "grad_norm": 0.2531636953353882,
      "learning_rate": 0.0003583632098437569,
      "loss": 0.3646,
      "step": 84000
    },
    {
      "epoch": 3.415536625531136,
      "eval_loss": 0.37500181794166565,
      "eval_runtime": 115.7883,
      "eval_samples_per_second": 1510.533,
      "eval_steps_per_second": 47.207,
      "step": 84000
    },
    {
      "epoch": 3.4196027405615306,
      "grad_norm": 0.23853425681591034,
      "learning_rate": 0.0003581419023591378,
      "loss": 0.3628,
      "step": 84100
    },
    {
      "epoch": 3.4236688555919246,
      "grad_norm": 0.24075156450271606,
      "learning_rate": 0.0003579205948745187,
      "loss": 0.3621,
      "step": 84200
    },
    {
      "epoch": 3.427734970622319,
      "grad_norm": 0.2508106529712677,
      "learning_rate": 0.00035769928738989954,
      "loss": 0.3634,
      "step": 84300
    },
    {
      "epoch": 3.431801085652713,
      "grad_norm": 0.26360711455345154,
      "learning_rate": 0.00035747797990528043,
      "loss": 0.362,
      "step": 84400
    },
    {
      "epoch": 3.4358672006831075,
      "grad_norm": 0.22268176078796387,
      "learning_rate": 0.0003572566724206613,
      "loss": 0.3619,
      "step": 84500
    },
    {
      "epoch": 3.4399333157135015,
      "grad_norm": 0.2275162637233734,
      "learning_rate": 0.0003570353649360422,
      "loss": 0.3635,
      "step": 84600
    },
    {
      "epoch": 3.443999430743896,
      "grad_norm": 0.24552001059055328,
      "learning_rate": 0.000356814057451423,
      "loss": 0.3629,
      "step": 84700
    },
    {
      "epoch": 3.44806554577429,
      "grad_norm": 0.25573599338531494,
      "learning_rate": 0.0003565927499668039,
      "loss": 0.3632,
      "step": 84800
    },
    {
      "epoch": 3.4521316608046844,
      "grad_norm": 0.22875165939331055,
      "learning_rate": 0.00035637144248218476,
      "loss": 0.3612,
      "step": 84900
    },
    {
      "epoch": 3.4561977758350784,
      "grad_norm": 0.2407064288854599,
      "learning_rate": 0.0003561501349975656,
      "loss": 0.3651,
      "step": 85000
    },
    {
      "epoch": 3.4602638908654724,
      "grad_norm": 0.2183394432067871,
      "learning_rate": 0.0003559288275129465,
      "loss": 0.3628,
      "step": 85100
    },
    {
      "epoch": 3.464330005895867,
      "grad_norm": 0.24623450636863708,
      "learning_rate": 0.00035570752002832734,
      "loss": 0.3638,
      "step": 85200
    },
    {
      "epoch": 3.468396120926261,
      "grad_norm": 0.23011355102062225,
      "learning_rate": 0.00035548621254370824,
      "loss": 0.363,
      "step": 85300
    },
    {
      "epoch": 3.4724622359566553,
      "grad_norm": 0.21279962360858917,
      "learning_rate": 0.0003552649050590891,
      "loss": 0.3623,
      "step": 85400
    },
    {
      "epoch": 3.4765283509870493,
      "grad_norm": 0.2381698489189148,
      "learning_rate": 0.00035504359757447,
      "loss": 0.3641,
      "step": 85500
    },
    {
      "epoch": 3.4805944660174437,
      "grad_norm": 0.2402961105108261,
      "learning_rate": 0.0003548222900898508,
      "loss": 0.3665,
      "step": 85600
    },
    {
      "epoch": 3.4846605810478377,
      "grad_norm": 0.22125539183616638,
      "learning_rate": 0.0003546009826052317,
      "loss": 0.3639,
      "step": 85700
    },
    {
      "epoch": 3.488726696078232,
      "grad_norm": 0.2710060775279999,
      "learning_rate": 0.00035437967512061256,
      "loss": 0.3614,
      "step": 85800
    },
    {
      "epoch": 3.492792811108626,
      "grad_norm": 0.21199671924114227,
      "learning_rate": 0.00035415836763599346,
      "loss": 0.3644,
      "step": 85900
    },
    {
      "epoch": 3.4968589261390206,
      "grad_norm": 0.2617241442203522,
      "learning_rate": 0.00035393706015137436,
      "loss": 0.3619,
      "step": 86000
    },
    {
      "epoch": 3.4968589261390206,
      "eval_loss": 0.3736768364906311,
      "eval_runtime": 115.9601,
      "eval_samples_per_second": 1508.294,
      "eval_steps_per_second": 47.137,
      "step": 86000
    },
    {
      "epoch": 3.5009250411694146,
      "grad_norm": 0.26243409514427185,
      "learning_rate": 0.0003537157526667552,
      "loss": 0.3638,
      "step": 86100
    },
    {
      "epoch": 3.504991156199809,
      "grad_norm": 0.22250230610370636,
      "learning_rate": 0.0003534944451821361,
      "loss": 0.3631,
      "step": 86200
    },
    {
      "epoch": 3.509057271230203,
      "grad_norm": 0.24155095219612122,
      "learning_rate": 0.00035327313769751694,
      "loss": 0.3628,
      "step": 86300
    },
    {
      "epoch": 3.513123386260597,
      "grad_norm": 0.23075063526630402,
      "learning_rate": 0.00035305183021289784,
      "loss": 0.3663,
      "step": 86400
    },
    {
      "epoch": 3.5171895012909915,
      "grad_norm": 0.254827618598938,
      "learning_rate": 0.0003528305227282787,
      "loss": 0.3645,
      "step": 86500
    },
    {
      "epoch": 3.521255616321386,
      "grad_norm": 0.22953581809997559,
      "learning_rate": 0.0003526092152436595,
      "loss": 0.3649,
      "step": 86600
    },
    {
      "epoch": 3.52532173135178,
      "grad_norm": 0.28188514709472656,
      "learning_rate": 0.0003523879077590404,
      "loss": 0.3658,
      "step": 86700
    },
    {
      "epoch": 3.529387846382174,
      "grad_norm": 0.21613071858882904,
      "learning_rate": 0.00035216660027442126,
      "loss": 0.3651,
      "step": 86800
    },
    {
      "epoch": 3.5334539614125684,
      "grad_norm": 0.22548462450504303,
      "learning_rate": 0.00035194529278980216,
      "loss": 0.3603,
      "step": 86900
    },
    {
      "epoch": 3.537520076442963,
      "grad_norm": 0.22642236948013306,
      "learning_rate": 0.000351723985305183,
      "loss": 0.3635,
      "step": 87000
    },
    {
      "epoch": 3.541586191473357,
      "grad_norm": 0.22865638136863708,
      "learning_rate": 0.0003515026778205639,
      "loss": 0.3631,
      "step": 87100
    },
    {
      "epoch": 3.545652306503751,
      "grad_norm": 0.24210935831069946,
      "learning_rate": 0.00035128137033594474,
      "loss": 0.3633,
      "step": 87200
    },
    {
      "epoch": 3.5497184215341453,
      "grad_norm": 0.2714163064956665,
      "learning_rate": 0.00035106006285132564,
      "loss": 0.3622,
      "step": 87300
    },
    {
      "epoch": 3.5537845365645393,
      "grad_norm": 0.25203704833984375,
      "learning_rate": 0.0003508387553667065,
      "loss": 0.3626,
      "step": 87400
    },
    {
      "epoch": 3.5578506515949337,
      "grad_norm": 0.24538926780223846,
      "learning_rate": 0.0003506174478820874,
      "loss": 0.3631,
      "step": 87500
    },
    {
      "epoch": 3.5619167666253277,
      "grad_norm": 0.21922285854816437,
      "learning_rate": 0.0003503961403974683,
      "loss": 0.3637,
      "step": 87600
    },
    {
      "epoch": 3.565982881655722,
      "grad_norm": 0.24018844962120056,
      "learning_rate": 0.0003501748329128491,
      "loss": 0.3639,
      "step": 87700
    },
    {
      "epoch": 3.570048996686116,
      "grad_norm": 0.23703785240650177,
      "learning_rate": 0.00034995352542823,
      "loss": 0.3626,
      "step": 87800
    },
    {
      "epoch": 3.5741151117165106,
      "grad_norm": 0.24432924389839172,
      "learning_rate": 0.00034973221794361086,
      "loss": 0.3637,
      "step": 87900
    },
    {
      "epoch": 3.5781812267469046,
      "grad_norm": 0.22209672629833221,
      "learning_rate": 0.00034951091045899176,
      "loss": 0.3629,
      "step": 88000
    },
    {
      "epoch": 3.5781812267469046,
      "eval_loss": 0.3730475902557373,
      "eval_runtime": 116.1734,
      "eval_samples_per_second": 1505.525,
      "eval_steps_per_second": 47.05,
      "step": 88000
    },
    {
      "epoch": 3.5822473417772986,
      "grad_norm": 0.26407691836357117,
      "learning_rate": 0.0003492896029743726,
      "loss": 0.364,
      "step": 88100
    },
    {
      "epoch": 3.586313456807693,
      "grad_norm": 0.2272215038537979,
      "learning_rate": 0.0003490682954897535,
      "loss": 0.3625,
      "step": 88200
    },
    {
      "epoch": 3.5903795718380875,
      "grad_norm": 0.2570808529853821,
      "learning_rate": 0.0003488469880051343,
      "loss": 0.3645,
      "step": 88300
    },
    {
      "epoch": 3.5944456868684815,
      "grad_norm": 0.2583867013454437,
      "learning_rate": 0.0003486256805205152,
      "loss": 0.3651,
      "step": 88400
    },
    {
      "epoch": 3.5985118018988755,
      "grad_norm": 0.22019270062446594,
      "learning_rate": 0.0003484043730358961,
      "loss": 0.3627,
      "step": 88500
    },
    {
      "epoch": 3.60257791692927,
      "grad_norm": 0.2550962567329407,
      "learning_rate": 0.00034818306555127693,
      "loss": 0.3648,
      "step": 88600
    },
    {
      "epoch": 3.606644031959664,
      "grad_norm": 0.2614721655845642,
      "learning_rate": 0.0003479617580666578,
      "loss": 0.3647,
      "step": 88700
    },
    {
      "epoch": 3.6107101469900584,
      "grad_norm": 0.22315962612628937,
      "learning_rate": 0.00034774045058203867,
      "loss": 0.3635,
      "step": 88800
    },
    {
      "epoch": 3.6147762620204524,
      "grad_norm": 0.20765574276447296,
      "learning_rate": 0.00034751914309741957,
      "loss": 0.3612,
      "step": 88900
    },
    {
      "epoch": 3.618842377050847,
      "grad_norm": 0.23083126544952393,
      "learning_rate": 0.0003472978356128004,
      "loss": 0.3638,
      "step": 89000
    },
    {
      "epoch": 3.622908492081241,
      "grad_norm": 0.2571653723716736,
      "learning_rate": 0.0003470765281281813,
      "loss": 0.3651,
      "step": 89100
    },
    {
      "epoch": 3.6269746071116353,
      "grad_norm": 0.2650904357433319,
      "learning_rate": 0.00034685522064356215,
      "loss": 0.3619,
      "step": 89200
    },
    {
      "epoch": 3.6310407221420293,
      "grad_norm": 0.22158272564411163,
      "learning_rate": 0.00034663391315894305,
      "loss": 0.3628,
      "step": 89300
    },
    {
      "epoch": 3.6351068371724233,
      "grad_norm": 0.2522256374359131,
      "learning_rate": 0.00034641260567432394,
      "loss": 0.3631,
      "step": 89400
    },
    {
      "epoch": 3.639172952202818,
      "grad_norm": 0.21248342096805573,
      "learning_rate": 0.0003461912981897048,
      "loss": 0.3641,
      "step": 89500
    },
    {
      "epoch": 3.6432390672332122,
      "grad_norm": 0.2236194759607315,
      "learning_rate": 0.0003459699907050857,
      "loss": 0.3618,
      "step": 89600
    },
    {
      "epoch": 3.6473051822636062,
      "grad_norm": 0.23543792963027954,
      "learning_rate": 0.00034574868322046653,
      "loss": 0.3605,
      "step": 89700
    },
    {
      "epoch": 3.6513712972940002,
      "grad_norm": 0.2577477693557739,
      "learning_rate": 0.0003455273757358474,
      "loss": 0.3637,
      "step": 89800
    },
    {
      "epoch": 3.6554374123243947,
      "grad_norm": 0.24511434137821198,
      "learning_rate": 0.00034530606825122827,
      "loss": 0.3632,
      "step": 89900
    },
    {
      "epoch": 3.659503527354789,
      "grad_norm": 0.23829592764377594,
      "learning_rate": 0.0003450847607666091,
      "loss": 0.3615,
      "step": 90000
    },
    {
      "epoch": 3.659503527354789,
      "eval_loss": 0.3728627860546112,
      "eval_runtime": 115.4445,
      "eval_samples_per_second": 1515.031,
      "eval_steps_per_second": 47.347,
      "step": 90000
    },
    {
      "epoch": 3.663630634110639,
      "grad_norm": 0.25440552830696106,
      "learning_rate": 0.00034486345328198995,
      "loss": 0.3615,
      "step": 90100
    },
    {
      "epoch": 3.667696749141033,
      "grad_norm": 0.23964956402778625,
      "learning_rate": 0.00034464214579737085,
      "loss": 0.3667,
      "step": 90200
    },
    {
      "epoch": 3.6717628641714275,
      "grad_norm": 0.2247934192419052,
      "learning_rate": 0.00034442083831275175,
      "loss": 0.3621,
      "step": 90300
    },
    {
      "epoch": 3.6758289792018215,
      "grad_norm": 0.23652979731559753,
      "learning_rate": 0.0003441995308281326,
      "loss": 0.3619,
      "step": 90400
    },
    {
      "epoch": 3.679895094232216,
      "grad_norm": 0.25192365050315857,
      "learning_rate": 0.0003439782233435135,
      "loss": 0.3626,
      "step": 90500
    },
    {
      "epoch": 3.68396120926261,
      "grad_norm": 0.24516300857067108,
      "learning_rate": 0.00034375691585889433,
      "loss": 0.3632,
      "step": 90600
    },
    {
      "epoch": 3.6880273242930044,
      "grad_norm": 0.2283257693052292,
      "learning_rate": 0.00034353560837427523,
      "loss": 0.3628,
      "step": 90700
    },
    {
      "epoch": 3.6920934393233984,
      "grad_norm": 0.2647687494754791,
      "learning_rate": 0.00034331430088965607,
      "loss": 0.3623,
      "step": 90800
    },
    {
      "epoch": 3.696159554353793,
      "grad_norm": 0.2267238050699234,
      "learning_rate": 0.00034309299340503697,
      "loss": 0.3645,
      "step": 90900
    },
    {
      "epoch": 3.700225669384187,
      "grad_norm": 0.23433123528957367,
      "learning_rate": 0.00034287168592041787,
      "loss": 0.362,
      "step": 91000
    },
    {
      "epoch": 3.704291784414581,
      "grad_norm": 0.2557937502861023,
      "learning_rate": 0.0003426503784357987,
      "loss": 0.3614,
      "step": 91100
    },
    {
      "epoch": 3.7083578994449753,
      "grad_norm": 0.23286104202270508,
      "learning_rate": 0.0003424290709511796,
      "loss": 0.3607,
      "step": 91200
    },
    {
      "epoch": 3.7124240144753697,
      "grad_norm": 0.2704237103462219,
      "learning_rate": 0.00034220776346656045,
      "loss": 0.3623,
      "step": 91300
    },
    {
      "epoch": 3.7164901295057637,
      "grad_norm": 0.2594166696071625,
      "learning_rate": 0.00034198645598194135,
      "loss": 0.3648,
      "step": 91400
    },
    {
      "epoch": 3.7205562445361577,
      "grad_norm": 0.25090235471725464,
      "learning_rate": 0.0003417651484973222,
      "loss": 0.3619,
      "step": 91500
    },
    {
      "epoch": 3.724622359566552,
      "grad_norm": 0.284684419631958,
      "learning_rate": 0.0003415438410127031,
      "loss": 0.3645,
      "step": 91600
    },
    {
      "epoch": 3.728688474596946,
      "grad_norm": 0.2753116190433502,
      "learning_rate": 0.0003413225335280839,
      "loss": 0.3613,
      "step": 91700
    },
    {
      "epoch": 3.7327545896273406,
      "grad_norm": 0.23643016815185547,
      "learning_rate": 0.0003411012260434648,
      "loss": 0.3635,
      "step": 91800
    },
    {
      "epoch": 3.7368207046577346,
      "grad_norm": 0.2916189730167389,
      "learning_rate": 0.00034087991855884567,
      "loss": 0.3623,
      "step": 91900
    },
    {
      "epoch": 3.740886819688129,
      "grad_norm": 0.2415168732404709,
      "learning_rate": 0.0003406586110742265,
      "loss": 0.364,
      "step": 92000
    },
    {
      "epoch": 3.740886819688129,
      "eval_loss": 0.3730940520763397,
      "eval_runtime": 115.5204,
      "eval_samples_per_second": 1514.036,
      "eval_steps_per_second": 47.316,
      "step": 92000
    },
    {
      "epoch": 3.744952934718523,
      "grad_norm": 0.24754789471626282,
      "learning_rate": 0.0003404373035896074,
      "loss": 0.3625,
      "step": 92100
    },
    {
      "epoch": 3.7490190497489175,
      "grad_norm": 0.2343144565820694,
      "learning_rate": 0.00034021599610498826,
      "loss": 0.3617,
      "step": 92200
    },
    {
      "epoch": 3.7530851647793115,
      "grad_norm": 0.25318166613578796,
      "learning_rate": 0.00033999468862036915,
      "loss": 0.3625,
      "step": 92300
    },
    {
      "epoch": 3.757151279809706,
      "grad_norm": 0.22876198589801788,
      "learning_rate": 0.00033977338113575,
      "loss": 0.3635,
      "step": 92400
    },
    {
      "epoch": 3.7612173948401,
      "grad_norm": 0.24721401929855347,
      "learning_rate": 0.0003395520736511309,
      "loss": 0.3621,
      "step": 92500
    },
    {
      "epoch": 3.7652835098704944,
      "grad_norm": 0.2577635645866394,
      "learning_rate": 0.00033933076616651174,
      "loss": 0.3611,
      "step": 92600
    },
    {
      "epoch": 3.7693496249008884,
      "grad_norm": 0.2312488704919815,
      "learning_rate": 0.00033910945868189263,
      "loss": 0.3636,
      "step": 92700
    },
    {
      "epoch": 3.7734157399312824,
      "grad_norm": 0.24156083166599274,
      "learning_rate": 0.00033888815119727353,
      "loss": 0.3637,
      "step": 92800
    },
    {
      "epoch": 3.777481854961677,
      "grad_norm": 0.27245768904685974,
      "learning_rate": 0.0003386668437126544,
      "loss": 0.3627,
      "step": 92900
    },
    {
      "epoch": 3.7815479699920713,
      "grad_norm": 0.2440057098865509,
      "learning_rate": 0.00033844553622803527,
      "loss": 0.3623,
      "step": 93000
    },
    {
      "epoch": 3.7856140850224653,
      "grad_norm": 0.22321274876594543,
      "learning_rate": 0.0003382242287434161,
      "loss": 0.3619,
      "step": 93100
    },
    {
      "epoch": 3.7896802000528593,
      "grad_norm": 0.25200870633125305,
      "learning_rate": 0.000338002921258797,
      "loss": 0.3647,
      "step": 93200
    },
    {
      "epoch": 3.7937463150832538,
      "grad_norm": 0.27525046467781067,
      "learning_rate": 0.00033778161377417786,
      "loss": 0.3628,
      "step": 93300
    },
    {
      "epoch": 3.7978124301136478,
      "grad_norm": 0.2570669949054718,
      "learning_rate": 0.0003375603062895587,
      "loss": 0.3619,
      "step": 93400
    },
    {
      "epoch": 3.801878545144042,
      "grad_norm": 0.24909226596355438,
      "learning_rate": 0.00033733899880493954,
      "loss": 0.3626,
      "step": 93500
    },
    {
      "epoch": 3.8059446601744362,
      "grad_norm": 0.26444193720817566,
      "learning_rate": 0.00033711769132032044,
      "loss": 0.363,
      "step": 93600
    },
    {
      "epoch": 3.8100107752048307,
      "grad_norm": 0.23503614962100983,
      "learning_rate": 0.00033689638383570134,
      "loss": 0.3604,
      "step": 93700
    },
    {
      "epoch": 3.8140768902352247,
      "grad_norm": 0.25844210386276245,
      "learning_rate": 0.0003366750763510822,
      "loss": 0.363,
      "step": 93800
    },
    {
      "epoch": 3.818143005265619,
      "grad_norm": 0.25504735112190247,
      "learning_rate": 0.0003364537688664631,
      "loss": 0.364,
      "step": 93900
    },
    {
      "epoch": 3.822209120296013,
      "grad_norm": 0.2309333086013794,
      "learning_rate": 0.0003362324613818439,
      "loss": 0.3608,
      "step": 94000
    },
    {
      "epoch": 3.822209120296013,
      "eval_loss": 0.37123724818229675,
      "eval_runtime": 114.1862,
      "eval_samples_per_second": 1531.726,
      "eval_steps_per_second": 47.869,
      "step": 94000
    },
    {
      "epoch": 3.826275235326407,
      "grad_norm": 0.2387581169605255,
      "learning_rate": 0.0003360111538972248,
      "loss": 0.3633,
      "step": 94100
    },
    {
      "epoch": 3.8303413503568016,
      "grad_norm": 0.25124862790107727,
      "learning_rate": 0.00033578984641260566,
      "loss": 0.3624,
      "step": 94200
    },
    {
      "epoch": 3.834407465387196,
      "grad_norm": 0.23913340270519257,
      "learning_rate": 0.00033556853892798656,
      "loss": 0.3607,
      "step": 94300
    },
    {
      "epoch": 3.83847358041759,
      "grad_norm": 0.22458985447883606,
      "learning_rate": 0.00033534723144336745,
      "loss": 0.3593,
      "step": 94400
    },
    {
      "epoch": 3.842539695447984,
      "grad_norm": 0.3043128550052643,
      "learning_rate": 0.0003351259239587483,
      "loss": 0.363,
      "step": 94500
    },
    {
      "epoch": 3.8466058104783785,
      "grad_norm": 0.27271342277526855,
      "learning_rate": 0.0003349046164741292,
      "loss": 0.3607,
      "step": 94600
    },
    {
      "epoch": 3.850671925508773,
      "grad_norm": 0.2593793570995331,
      "learning_rate": 0.00033468330898951004,
      "loss": 0.3652,
      "step": 94700
    },
    {
      "epoch": 3.854738040539167,
      "grad_norm": 0.24720881879329681,
      "learning_rate": 0.00033446200150489094,
      "loss": 0.3602,
      "step": 94800
    },
    {
      "epoch": 3.858804155569561,
      "grad_norm": 0.23420573770999908,
      "learning_rate": 0.0003342406940202718,
      "loss": 0.3609,
      "step": 94900
    },
    {
      "epoch": 3.8628702705999554,
      "grad_norm": 0.27465441823005676,
      "learning_rate": 0.0003340193865356527,
      "loss": 0.3622,
      "step": 95000
    },
    {
      "epoch": 3.8669363856303494,
      "grad_norm": 0.2868003249168396,
      "learning_rate": 0.00033379807905103346,
      "loss": 0.3632,
      "step": 95100
    },
    {
      "epoch": 3.871002500660744,
      "grad_norm": 0.28601402044296265,
      "learning_rate": 0.00033357677156641436,
      "loss": 0.3598,
      "step": 95200
    },
    {
      "epoch": 3.875068615691138,
      "grad_norm": 0.2572382986545563,
      "learning_rate": 0.00033335546408179526,
      "loss": 0.36,
      "step": 95300
    },
    {
      "epoch": 3.8791347307215323,
      "grad_norm": 0.26052236557006836,
      "learning_rate": 0.0003331341565971761,
      "loss": 0.3597,
      "step": 95400
    },
    {
      "epoch": 3.8832008457519263,
      "grad_norm": 0.2371402084827423,
      "learning_rate": 0.000332912849112557,
      "loss": 0.3621,
      "step": 95500
    },
    {
      "epoch": 3.8872669607823207,
      "grad_norm": 0.24390317499637604,
      "learning_rate": 0.00033269154162793784,
      "loss": 0.3621,
      "step": 95600
    },
    {
      "epoch": 3.8913330758127147,
      "grad_norm": 0.2204296886920929,
      "learning_rate": 0.00033247023414331874,
      "loss": 0.361,
      "step": 95700
    },
    {
      "epoch": 3.8953991908431087,
      "grad_norm": 0.2612071931362152,
      "learning_rate": 0.0003322489266586996,
      "loss": 0.3619,
      "step": 95800
    },
    {
      "epoch": 3.899465305873503,
      "grad_norm": 0.2566361427307129,
      "learning_rate": 0.0003320276191740805,
      "loss": 0.3601,
      "step": 95900
    },
    {
      "epoch": 3.9035314209038976,
      "grad_norm": 0.24025918543338776,
      "learning_rate": 0.0003318063116894613,
      "loss": 0.361,
      "step": 96000
    },
    {
      "epoch": 3.9035314209038976,
      "eval_loss": 0.37112337350845337,
      "eval_runtime": 115.0202,
      "eval_samples_per_second": 1520.62,
      "eval_steps_per_second": 47.522,
      "step": 96000
    },
    {
      "epoch": 3.9075975359342916,
      "grad_norm": 0.255736768245697,
      "learning_rate": 0.0003315850042048422,
      "loss": 0.3611,
      "step": 96100
    },
    {
      "epoch": 3.9116636509646856,
      "grad_norm": 0.27144816517829895,
      "learning_rate": 0.0003313636967202231,
      "loss": 0.3619,
      "step": 96200
    },
    {
      "epoch": 3.91572976599508,
      "grad_norm": 0.2606707513332367,
      "learning_rate": 0.00033114238923560396,
      "loss": 0.3585,
      "step": 96300
    },
    {
      "epoch": 3.919795881025474,
      "grad_norm": 0.22564835846424103,
      "learning_rate": 0.00033092108175098486,
      "loss": 0.3613,
      "step": 96400
    },
    {
      "epoch": 3.9238619960558685,
      "grad_norm": 0.2774542272090912,
      "learning_rate": 0.0003306997742663657,
      "loss": 0.3629,
      "step": 96500
    },
    {
      "epoch": 3.9279281110862625,
      "grad_norm": 0.2408619225025177,
      "learning_rate": 0.0003304784667817466,
      "loss": 0.3608,
      "step": 96600
    },
    {
      "epoch": 3.931994226116657,
      "grad_norm": 0.230648472905159,
      "learning_rate": 0.00033025715929712744,
      "loss": 0.3611,
      "step": 96700
    },
    {
      "epoch": 3.936060341147051,
      "grad_norm": 0.26358726620674133,
      "learning_rate": 0.0003300358518125083,
      "loss": 0.3612,
      "step": 96800
    },
    {
      "epoch": 3.9401264561774454,
      "grad_norm": 0.24244248867034912,
      "learning_rate": 0.00032981454432788913,
      "loss": 0.3612,
      "step": 96900
    },
    {
      "epoch": 3.9441925712078394,
      "grad_norm": 0.2220418006181717,
      "learning_rate": 0.00032959323684327,
      "loss": 0.3591,
      "step": 97000
    },
    {
      "epoch": 3.948258686238234,
      "grad_norm": 0.2833726108074188,
      "learning_rate": 0.0003293719293586509,
      "loss": 0.3629,
      "step": 97100
    },
    {
      "epoch": 3.952324801268628,
      "grad_norm": 0.26155954599380493,
      "learning_rate": 0.00032915062187403177,
      "loss": 0.3633,
      "step": 97200
    },
    {
      "epoch": 3.9563909162990223,
      "grad_norm": 0.2599785327911377,
      "learning_rate": 0.00032892931438941266,
      "loss": 0.3636,
      "step": 97300
    },
    {
      "epoch": 3.9604570313294163,
      "grad_norm": 0.25020697712898254,
      "learning_rate": 0.0003287080069047935,
      "loss": 0.3616,
      "step": 97400
    },
    {
      "epoch": 3.9645231463598103,
      "grad_norm": 0.25178825855255127,
      "learning_rate": 0.0003284866994201744,
      "loss": 0.3608,
      "step": 97500
    },
    {
      "epoch": 3.9685892613902047,
      "grad_norm": 0.22037966549396515,
      "learning_rate": 0.00032826539193555525,
      "loss": 0.3623,
      "step": 97600
    },
    {
      "epoch": 3.972655376420599,
      "grad_norm": 0.25113606452941895,
      "learning_rate": 0.00032804408445093614,
      "loss": 0.3631,
      "step": 97700
    },
    {
      "epoch": 3.976721491450993,
      "grad_norm": 0.2818368077278137,
      "learning_rate": 0.00032782277696631704,
      "loss": 0.3609,
      "step": 97800
    },
    {
      "epoch": 3.980787606481387,
      "grad_norm": 0.254155695438385,
      "learning_rate": 0.0003276014694816979,
      "loss": 0.3603,
      "step": 97900
    },
    {
      "epoch": 3.9848537215117816,
      "grad_norm": 0.2560500204563141,
      "learning_rate": 0.0003273801619970788,
      "loss": 0.3622,
      "step": 98000
    },
    {
      "epoch": 3.9848537215117816,
      "eval_loss": 0.37146463990211487,
      "eval_runtime": 115.7622,
      "eval_samples_per_second": 1510.874,
      "eval_steps_per_second": 47.217,
      "step": 98000
    },
    {
      "epoch": 3.9889198365421756,
      "grad_norm": 0.26766374707221985,
      "learning_rate": 0.0003271588545124596,
      "loss": 0.362,
      "step": 98100
    },
    {
      "epoch": 3.99298595157257,
      "grad_norm": 0.2704111933708191,
      "learning_rate": 0.0003269375470278405,
      "loss": 0.3612,
      "step": 98200
    },
    {
      "epoch": 3.997052066602964,
      "grad_norm": 0.24995678663253784,
      "learning_rate": 0.00032671623954322137,
      "loss": 0.3607,
      "step": 98300
    },
    {
      "epoch": 4.001118181633358,
      "grad_norm": 0.2668578624725342,
      "learning_rate": 0.00032649493205860226,
      "loss": 0.3608,
      "step": 98400
    },
    {
      "epoch": 4.005184296663753,
      "grad_norm": 0.2367238849401474,
      "learning_rate": 0.00032627362457398305,
      "loss": 0.3583,
      "step": 98500
    },
    {
      "epoch": 4.009250411694147,
      "grad_norm": 0.280033677816391,
      "learning_rate": 0.00032605231708936395,
      "loss": 0.3568,
      "step": 98600
    },
    {
      "epoch": 4.013316526724541,
      "grad_norm": 0.26187118887901306,
      "learning_rate": 0.00032583100960474485,
      "loss": 0.3562,
      "step": 98700
    },
    {
      "epoch": 4.017382641754935,
      "grad_norm": 0.2580893635749817,
      "learning_rate": 0.0003256097021201257,
      "loss": 0.3612,
      "step": 98800
    },
    {
      "epoch": 4.02144875678533,
      "grad_norm": 0.24781548976898193,
      "learning_rate": 0.0003253883946355066,
      "loss": 0.3569,
      "step": 98900
    },
    {
      "epoch": 4.025514871815724,
      "grad_norm": 0.2675013840198517,
      "learning_rate": 0.00032516708715088743,
      "loss": 0.3559,
      "step": 99000
    },
    {
      "epoch": 4.029580986846118,
      "grad_norm": 0.24672703444957733,
      "learning_rate": 0.00032494577966626833,
      "loss": 0.3596,
      "step": 99100
    },
    {
      "epoch": 4.033647101876512,
      "grad_norm": 0.27099135518074036,
      "learning_rate": 0.00032472447218164917,
      "loss": 0.3576,
      "step": 99200
    },
    {
      "epoch": 4.037713216906906,
      "grad_norm": 0.295620858669281,
      "learning_rate": 0.00032450316469703007,
      "loss": 0.356,
      "step": 99300
    },
    {
      "epoch": 4.041779331937301,
      "grad_norm": 0.23460298776626587,
      "learning_rate": 0.0003242818572124109,
      "loss": 0.361,
      "step": 99400
    },
    {
      "epoch": 4.045845446967695,
      "grad_norm": 0.27200666069984436,
      "learning_rate": 0.0003240605497277918,
      "loss": 0.3591,
      "step": 99500
    },
    {
      "epoch": 4.049911561998089,
      "grad_norm": 0.24311840534210205,
      "learning_rate": 0.0003238392422431727,
      "loss": 0.3566,
      "step": 99600
    },
    {
      "epoch": 4.053977677028483,
      "grad_norm": 0.2396254688501358,
      "learning_rate": 0.00032361793475855355,
      "loss": 0.3601,
      "step": 99700
    },
    {
      "epoch": 4.058043792058878,
      "grad_norm": 0.299503892660141,
      "learning_rate": 0.00032339662727393445,
      "loss": 0.3576,
      "step": 99800
    },
    {
      "epoch": 4.062109907089272,
      "grad_norm": 0.27441948652267456,
      "learning_rate": 0.0003231753197893153,
      "loss": 0.3597,
      "step": 99900
    },
    {
      "epoch": 4.066176022119666,
      "grad_norm": 0.2862662374973297,
      "learning_rate": 0.0003229540123046962,
      "loss": 0.3594,
      "step": 100000
    },
    {
      "epoch": 4.066176022119666,
      "eval_loss": 0.37090393900871277,
      "eval_runtime": 116.923,
      "eval_samples_per_second": 1495.873,
      "eval_steps_per_second": 46.749,
      "step": 100000
    },
    {
      "epoch": 4.070262467725212,
      "grad_norm": 0.2532333433628082,
      "learning_rate": 0.000322732704820077,
      "loss": 0.3575,
      "step": 100100
    },
    {
      "epoch": 4.074328582755606,
      "grad_norm": 0.27281084656715393,
      "learning_rate": 0.0003225113973354579,
      "loss": 0.3568,
      "step": 100200
    },
    {
      "epoch": 4.078394697786,
      "grad_norm": 0.28112515807151794,
      "learning_rate": 0.0003222900898508387,
      "loss": 0.3593,
      "step": 100300
    },
    {
      "epoch": 4.082460812816395,
      "grad_norm": 0.25681519508361816,
      "learning_rate": 0.0003220687823662196,
      "loss": 0.3609,
      "step": 100400
    },
    {
      "epoch": 4.086526927846789,
      "grad_norm": 0.2792091369628906,
      "learning_rate": 0.0003218474748816005,
      "loss": 0.3583,
      "step": 100500
    },
    {
      "epoch": 4.090593042877183,
      "grad_norm": 0.2656234800815582,
      "learning_rate": 0.00032162616739698135,
      "loss": 0.3582,
      "step": 100600
    },
    {
      "epoch": 4.094659157907577,
      "grad_norm": 0.2629627287387848,
      "learning_rate": 0.00032140485991236225,
      "loss": 0.3592,
      "step": 100700
    },
    {
      "epoch": 4.098725272937972,
      "grad_norm": 0.23087191581726074,
      "learning_rate": 0.0003211835524277431,
      "loss": 0.3572,
      "step": 100800
    },
    {
      "epoch": 4.102791387968366,
      "grad_norm": 0.2609163522720337,
      "learning_rate": 0.000320962244943124,
      "loss": 0.357,
      "step": 100900
    },
    {
      "epoch": 4.10685750299876,
      "grad_norm": 0.2649787366390228,
      "learning_rate": 0.00032074093745850484,
      "loss": 0.359,
      "step": 101000
    },
    {
      "epoch": 4.110923618029154,
      "grad_norm": 0.3060908615589142,
      "learning_rate": 0.00032051962997388573,
      "loss": 0.3606,
      "step": 101100
    },
    {
      "epoch": 4.114989733059549,
      "grad_norm": 0.30594122409820557,
      "learning_rate": 0.0003202983224892666,
      "loss": 0.3568,
      "step": 101200
    },
    {
      "epoch": 4.119055848089943,
      "grad_norm": 0.25136980414390564,
      "learning_rate": 0.00032007701500464747,
      "loss": 0.3574,
      "step": 101300
    },
    {
      "epoch": 4.123121963120337,
      "grad_norm": 0.22435685992240906,
      "learning_rate": 0.00031985570752002837,
      "loss": 0.3582,
      "step": 101400
    },
    {
      "epoch": 4.127188078150731,
      "grad_norm": 0.26855039596557617,
      "learning_rate": 0.0003196344000354092,
      "loss": 0.359,
      "step": 101500
    },
    {
      "epoch": 4.1312541931811255,
      "grad_norm": 0.2890253961086273,
      "learning_rate": 0.0003194130925507901,
      "loss": 0.3586,
      "step": 101600
    },
    {
      "epoch": 4.1353203082115195,
      "grad_norm": 0.269561767578125,
      "learning_rate": 0.00031919178506617095,
      "loss": 0.3568,
      "step": 101700
    },
    {
      "epoch": 4.1393864232419135,
      "grad_norm": 0.2463853806257248,
      "learning_rate": 0.0003189704775815518,
      "loss": 0.3607,
      "step": 101800
    },
    {
      "epoch": 4.1434525382723075,
      "grad_norm": 0.26957353949546814,
      "learning_rate": 0.00031874917009693264,
      "loss": 0.3587,
      "step": 101900
    },
    {
      "epoch": 4.1475186533027015,
      "grad_norm": 0.2671247720718384,
      "learning_rate": 0.00031852786261231354,
      "loss": 0.3567,
      "step": 102000
    },
    {
      "epoch": 4.1475186533027015,
      "eval_loss": 0.3704474866390228,
      "eval_runtime": 116.487,
      "eval_samples_per_second": 1501.472,
      "eval_steps_per_second": 46.924,
      "step": 102000
    },
    {
      "epoch": 4.151584768333096,
      "grad_norm": 0.2904741168022156,
      "learning_rate": 0.00031830655512769443,
      "loss": 0.3588,
      "step": 102100
    },
    {
      "epoch": 4.15565088336349,
      "grad_norm": 0.25275176763534546,
      "learning_rate": 0.0003180852476430753,
      "loss": 0.359,
      "step": 102200
    },
    {
      "epoch": 4.159716998393884,
      "grad_norm": 0.3077912926673889,
      "learning_rate": 0.0003178639401584562,
      "loss": 0.3581,
      "step": 102300
    },
    {
      "epoch": 4.163783113424278,
      "grad_norm": 0.23807701468467712,
      "learning_rate": 0.000317642632673837,
      "loss": 0.3563,
      "step": 102400
    },
    {
      "epoch": 4.167849228454673,
      "grad_norm": 0.24502216279506683,
      "learning_rate": 0.0003174213251892179,
      "loss": 0.3579,
      "step": 102500
    },
    {
      "epoch": 4.171915343485067,
      "grad_norm": 0.2766995131969452,
      "learning_rate": 0.00031720001770459876,
      "loss": 0.3566,
      "step": 102600
    },
    {
      "epoch": 4.175981458515461,
      "grad_norm": 0.2987053394317627,
      "learning_rate": 0.00031697871021997966,
      "loss": 0.3573,
      "step": 102700
    },
    {
      "epoch": 4.180047573545855,
      "grad_norm": 0.24557285010814667,
      "learning_rate": 0.0003167574027353605,
      "loss": 0.3577,
      "step": 102800
    },
    {
      "epoch": 4.18411368857625,
      "grad_norm": 0.23898857831954956,
      "learning_rate": 0.0003165360952507414,
      "loss": 0.3597,
      "step": 102900
    },
    {
      "epoch": 4.188179803606644,
      "grad_norm": 0.26010239124298096,
      "learning_rate": 0.0003163147877661223,
      "loss": 0.3573,
      "step": 103000
    },
    {
      "epoch": 4.192245918637038,
      "grad_norm": 0.25355347990989685,
      "learning_rate": 0.00031609348028150314,
      "loss": 0.3601,
      "step": 103100
    },
    {
      "epoch": 4.196312033667432,
      "grad_norm": 0.2906467318534851,
      "learning_rate": 0.00031587217279688403,
      "loss": 0.3595,
      "step": 103200
    },
    {
      "epoch": 4.200378148697826,
      "grad_norm": 0.25691255927085876,
      "learning_rate": 0.0003156508653122649,
      "loss": 0.3556,
      "step": 103300
    },
    {
      "epoch": 4.204444263728221,
      "grad_norm": 0.30386143922805786,
      "learning_rate": 0.0003154295578276458,
      "loss": 0.3577,
      "step": 103400
    },
    {
      "epoch": 4.208510378758615,
      "grad_norm": 0.24902543425559998,
      "learning_rate": 0.00031520825034302656,
      "loss": 0.3578,
      "step": 103500
    },
    {
      "epoch": 4.212576493789009,
      "grad_norm": 0.2598992586135864,
      "learning_rate": 0.00031498694285840746,
      "loss": 0.3576,
      "step": 103600
    },
    {
      "epoch": 4.216642608819403,
      "grad_norm": 0.2924422323703766,
      "learning_rate": 0.0003147656353737883,
      "loss": 0.3567,
      "step": 103700
    },
    {
      "epoch": 4.220708723849798,
      "grad_norm": 0.28371161222457886,
      "learning_rate": 0.0003145443278891692,
      "loss": 0.3577,
      "step": 103800
    },
    {
      "epoch": 4.224774838880192,
      "grad_norm": 0.25981923937797546,
      "learning_rate": 0.0003143230204045501,
      "loss": 0.3594,
      "step": 103900
    },
    {
      "epoch": 4.228840953910586,
      "grad_norm": 0.24146971106529236,
      "learning_rate": 0.00031410171291993094,
      "loss": 0.3601,
      "step": 104000
    },
    {
      "epoch": 4.228840953910586,
      "eval_loss": 0.3693286180496216,
      "eval_runtime": 115.9503,
      "eval_samples_per_second": 1508.422,
      "eval_steps_per_second": 47.141,
      "step": 104000
    },
    {
      "epoch": 4.23290706894098,
      "grad_norm": 0.27417492866516113,
      "learning_rate": 0.00031388040543531184,
      "loss": 0.3589,
      "step": 104100
    },
    {
      "epoch": 4.236973183971375,
      "grad_norm": 0.2724056541919708,
      "learning_rate": 0.0003136590979506927,
      "loss": 0.3598,
      "step": 104200
    },
    {
      "epoch": 4.241039299001769,
      "grad_norm": 0.2509074807167053,
      "learning_rate": 0.0003134377904660736,
      "loss": 0.3596,
      "step": 104300
    },
    {
      "epoch": 4.245105414032163,
      "grad_norm": 0.28360095620155334,
      "learning_rate": 0.0003132164829814544,
      "loss": 0.3591,
      "step": 104400
    },
    {
      "epoch": 4.249171529062557,
      "grad_norm": 0.2887994349002838,
      "learning_rate": 0.0003129951754968353,
      "loss": 0.3572,
      "step": 104500
    },
    {
      "epoch": 4.253237644092952,
      "grad_norm": 0.2507530450820923,
      "learning_rate": 0.00031277386801221616,
      "loss": 0.3597,
      "step": 104600
    },
    {
      "epoch": 4.257303759123346,
      "grad_norm": 0.28395316004753113,
      "learning_rate": 0.00031255256052759706,
      "loss": 0.359,
      "step": 104700
    },
    {
      "epoch": 4.26136987415374,
      "grad_norm": 0.3371581435203552,
      "learning_rate": 0.00031233125304297796,
      "loss": 0.357,
      "step": 104800
    },
    {
      "epoch": 4.265435989184134,
      "grad_norm": 0.2789885103702545,
      "learning_rate": 0.0003121099455583588,
      "loss": 0.3578,
      "step": 104900
    },
    {
      "epoch": 4.269502104214528,
      "grad_norm": 0.2895076274871826,
      "learning_rate": 0.0003118886380737397,
      "loss": 0.3594,
      "step": 105000
    },
    {
      "epoch": 4.273568219244923,
      "grad_norm": 0.24918130040168762,
      "learning_rate": 0.00031166733058912054,
      "loss": 0.3592,
      "step": 105100
    },
    {
      "epoch": 4.277634334275317,
      "grad_norm": 0.27098914980888367,
      "learning_rate": 0.0003114460231045014,
      "loss": 0.3589,
      "step": 105200
    },
    {
      "epoch": 4.281700449305711,
      "grad_norm": 0.2558654248714447,
      "learning_rate": 0.00031122471561988223,
      "loss": 0.3576,
      "step": 105300
    },
    {
      "epoch": 4.285766564336105,
      "grad_norm": 0.2516871690750122,
      "learning_rate": 0.0003110034081352631,
      "loss": 0.3569,
      "step": 105400
    },
    {
      "epoch": 4.2898326793665,
      "grad_norm": 0.2584571838378906,
      "learning_rate": 0.000310782100650644,
      "loss": 0.3557,
      "step": 105500
    },
    {
      "epoch": 4.293898794396894,
      "grad_norm": 0.26188865303993225,
      "learning_rate": 0.00031056079316602487,
      "loss": 0.3574,
      "step": 105600
    },
    {
      "epoch": 4.297964909427288,
      "grad_norm": 0.29503482580184937,
      "learning_rate": 0.00031033948568140576,
      "loss": 0.3581,
      "step": 105700
    },
    {
      "epoch": 4.302031024457682,
      "grad_norm": 0.27723851799964905,
      "learning_rate": 0.0003101181781967866,
      "loss": 0.3582,
      "step": 105800
    },
    {
      "epoch": 4.3060971394880765,
      "grad_norm": 0.27084898948669434,
      "learning_rate": 0.0003098968707121675,
      "loss": 0.3595,
      "step": 105900
    },
    {
      "epoch": 4.3101632545184705,
      "grad_norm": 0.26206377148628235,
      "learning_rate": 0.00030967556322754835,
      "loss": 0.3599,
      "step": 106000
    },
    {
      "epoch": 4.3101632545184705,
      "eval_loss": 0.3692241311073303,
      "eval_runtime": 116.2211,
      "eval_samples_per_second": 1504.908,
      "eval_steps_per_second": 47.031,
      "step": 106000
    },
    {
      "epoch": 4.3142293695488645,
      "grad_norm": 0.26975217461586,
      "learning_rate": 0.00030945425574292924,
      "loss": 0.3593,
      "step": 106100
    },
    {
      "epoch": 4.3182954845792585,
      "grad_norm": 0.2730872929096222,
      "learning_rate": 0.0003092329482583101,
      "loss": 0.359,
      "step": 106200
    },
    {
      "epoch": 4.322361599609653,
      "grad_norm": 0.24615992605686188,
      "learning_rate": 0.000309011640773691,
      "loss": 0.3559,
      "step": 106300
    },
    {
      "epoch": 4.326427714640047,
      "grad_norm": 0.2620074152946472,
      "learning_rate": 0.0003087903332890719,
      "loss": 0.3555,
      "step": 106400
    },
    {
      "epoch": 4.330493829670441,
      "grad_norm": 0.27660447359085083,
      "learning_rate": 0.0003085690258044527,
      "loss": 0.3578,
      "step": 106500
    },
    {
      "epoch": 4.334559944700835,
      "grad_norm": 0.3013085126876831,
      "learning_rate": 0.0003083477183198336,
      "loss": 0.3559,
      "step": 106600
    },
    {
      "epoch": 4.338626059731229,
      "grad_norm": 0.22916434705257416,
      "learning_rate": 0.00030812641083521446,
      "loss": 0.3597,
      "step": 106700
    },
    {
      "epoch": 4.342692174761624,
      "grad_norm": 0.28834161162376404,
      "learning_rate": 0.00030790510335059536,
      "loss": 0.3599,
      "step": 106800
    },
    {
      "epoch": 4.346758289792018,
      "grad_norm": 0.27654942870140076,
      "learning_rate": 0.00030768379586597615,
      "loss": 0.3601,
      "step": 106900
    },
    {
      "epoch": 4.350824404822412,
      "grad_norm": 0.24498209357261658,
      "learning_rate": 0.00030746248838135705,
      "loss": 0.3593,
      "step": 107000
    },
    {
      "epoch": 4.354890519852806,
      "grad_norm": 0.2888379991054535,
      "learning_rate": 0.0003072411808967379,
      "loss": 0.3603,
      "step": 107100
    },
    {
      "epoch": 4.358956634883201,
      "grad_norm": 0.28645339608192444,
      "learning_rate": 0.0003070198734121188,
      "loss": 0.3595,
      "step": 107200
    },
    {
      "epoch": 4.363022749913595,
      "grad_norm": 0.255849152803421,
      "learning_rate": 0.0003067985659274997,
      "loss": 0.3584,
      "step": 107300
    },
    {
      "epoch": 4.367088864943989,
      "grad_norm": 0.24786415696144104,
      "learning_rate": 0.00030657725844288053,
      "loss": 0.3601,
      "step": 107400
    },
    {
      "epoch": 4.371154979974383,
      "grad_norm": 0.23530377447605133,
      "learning_rate": 0.0003063559509582614,
      "loss": 0.3612,
      "step": 107500
    },
    {
      "epoch": 4.375221095004778,
      "grad_norm": 0.266171395778656,
      "learning_rate": 0.00030613464347364227,
      "loss": 0.3581,
      "step": 107600
    },
    {
      "epoch": 4.379287210035172,
      "grad_norm": 0.28116023540496826,
      "learning_rate": 0.00030591333598902317,
      "loss": 0.357,
      "step": 107700
    },
    {
      "epoch": 4.383353325065566,
      "grad_norm": 0.2588450610637665,
      "learning_rate": 0.000305692028504404,
      "loss": 0.3575,
      "step": 107800
    },
    {
      "epoch": 4.38741944009596,
      "grad_norm": 0.2551751732826233,
      "learning_rate": 0.0003054707210197849,
      "loss": 0.359,
      "step": 107900
    },
    {
      "epoch": 4.391485555126355,
      "grad_norm": 0.27018091082572937,
      "learning_rate": 0.00030524941353516575,
      "loss": 0.3578,
      "step": 108000
    },
    {
      "epoch": 4.391485555126355,
      "eval_loss": 0.3688269257545471,
      "eval_runtime": 117.1802,
      "eval_samples_per_second": 1492.59,
      "eval_steps_per_second": 46.646,
      "step": 108000
    },
    {
      "epoch": 4.395551670156749,
      "grad_norm": 0.28061598539352417,
      "learning_rate": 0.00030502810605054665,
      "loss": 0.3579,
      "step": 108100
    },
    {
      "epoch": 4.399617785187143,
      "grad_norm": 0.27247536182403564,
      "learning_rate": 0.00030480679856592755,
      "loss": 0.3585,
      "step": 108200
    },
    {
      "epoch": 4.403683900217537,
      "grad_norm": 0.2930395305156708,
      "learning_rate": 0.0003045854910813084,
      "loss": 0.3586,
      "step": 108300
    },
    {
      "epoch": 4.407750015247931,
      "grad_norm": 0.2857935428619385,
      "learning_rate": 0.0003043641835966893,
      "loss": 0.358,
      "step": 108400
    },
    {
      "epoch": 4.411816130278326,
      "grad_norm": 0.24348685145378113,
      "learning_rate": 0.00030414287611207013,
      "loss": 0.359,
      "step": 108500
    },
    {
      "epoch": 4.41588224530872,
      "grad_norm": 0.26699018478393555,
      "learning_rate": 0.00030392156862745097,
      "loss": 0.3573,
      "step": 108600
    },
    {
      "epoch": 4.419948360339114,
      "grad_norm": 0.2899777591228485,
      "learning_rate": 0.0003037002611428318,
      "loss": 0.3578,
      "step": 108700
    },
    {
      "epoch": 4.424014475369508,
      "grad_norm": 0.2570410966873169,
      "learning_rate": 0.0003034789536582127,
      "loss": 0.3592,
      "step": 108800
    },
    {
      "epoch": 4.428080590399903,
      "grad_norm": 0.27908700704574585,
      "learning_rate": 0.00030325764617359356,
      "loss": 0.3585,
      "step": 108900
    },
    {
      "epoch": 4.432146705430297,
      "grad_norm": 0.28319111466407776,
      "learning_rate": 0.00030303633868897445,
      "loss": 0.3586,
      "step": 109000
    },
    {
      "epoch": 4.436212820460691,
      "grad_norm": 0.27293655276298523,
      "learning_rate": 0.00030281503120435535,
      "loss": 0.3609,
      "step": 109100
    },
    {
      "epoch": 4.440278935491085,
      "grad_norm": 0.25153565406799316,
      "learning_rate": 0.0003025937237197362,
      "loss": 0.3577,
      "step": 109200
    },
    {
      "epoch": 4.44434505052148,
      "grad_norm": 0.26654085516929626,
      "learning_rate": 0.0003023724162351171,
      "loss": 0.3591,
      "step": 109300
    },
    {
      "epoch": 4.448411165551874,
      "grad_norm": 0.2817992866039276,
      "learning_rate": 0.00030215110875049793,
      "loss": 0.3568,
      "step": 109400
    },
    {
      "epoch": 4.452477280582268,
      "grad_norm": 0.24807152152061462,
      "learning_rate": 0.00030192980126587883,
      "loss": 0.357,
      "step": 109500
    },
    {
      "epoch": 4.456543395612662,
      "grad_norm": 0.32465726137161255,
      "learning_rate": 0.0003017084937812597,
      "loss": 0.3582,
      "step": 109600
    },
    {
      "epoch": 4.4606095106430566,
      "grad_norm": 0.28908899426460266,
      "learning_rate": 0.00030148718629664057,
      "loss": 0.3568,
      "step": 109700
    },
    {
      "epoch": 4.4646756256734506,
      "grad_norm": 0.2828015387058258,
      "learning_rate": 0.00030126587881202147,
      "loss": 0.3569,
      "step": 109800
    },
    {
      "epoch": 4.468741740703845,
      "grad_norm": 0.3073457181453705,
      "learning_rate": 0.0003010445713274023,
      "loss": 0.3579,
      "step": 109900
    },
    {
      "epoch": 4.472807855734239,
      "grad_norm": 0.28168201446533203,
      "learning_rate": 0.0003008232638427832,
      "loss": 0.3578,
      "step": 110000
    },
    {
      "epoch": 4.472807855734239,
      "eval_loss": 0.36887529492378235,
      "eval_runtime": 117.4731,
      "eval_samples_per_second": 1488.869,
      "eval_steps_per_second": 46.53,
      "step": 110000
    },
    {
      "epoch": 4.476873970764633,
      "grad_norm": 0.3444388806819916,
      "learning_rate": 0.00030060195635816405,
      "loss": 0.3571,
      "step": 110100
    },
    {
      "epoch": 4.4809400857950274,
      "grad_norm": 0.27032947540283203,
      "learning_rate": 0.00030038064887354495,
      "loss": 0.361,
      "step": 110200
    },
    {
      "epoch": 4.4850062008254215,
      "grad_norm": 0.24029526114463806,
      "learning_rate": 0.00030015934138892574,
      "loss": 0.3581,
      "step": 110300
    },
    {
      "epoch": 4.4890723158558155,
      "grad_norm": 0.2936967611312866,
      "learning_rate": 0.00029993803390430664,
      "loss": 0.3581,
      "step": 110400
    },
    {
      "epoch": 4.4931384308862095,
      "grad_norm": 0.31872087717056274,
      "learning_rate": 0.0002997167264196875,
      "loss": 0.3586,
      "step": 110500
    },
    {
      "epoch": 4.497204545916604,
      "grad_norm": 0.2689506709575653,
      "learning_rate": 0.0002994954189350684,
      "loss": 0.3584,
      "step": 110600
    },
    {
      "epoch": 4.501270660946998,
      "grad_norm": 0.273901104927063,
      "learning_rate": 0.0002992741114504493,
      "loss": 0.3594,
      "step": 110700
    },
    {
      "epoch": 4.505336775977392,
      "grad_norm": 0.2766086757183075,
      "learning_rate": 0.0002990528039658301,
      "loss": 0.3554,
      "step": 110800
    },
    {
      "epoch": 4.509402891007786,
      "grad_norm": 0.28789621591567993,
      "learning_rate": 0.000298831496481211,
      "loss": 0.3571,
      "step": 110900
    },
    {
      "epoch": 4.51346900603818,
      "grad_norm": 0.2729949355125427,
      "learning_rate": 0.00029861018899659186,
      "loss": 0.3584,
      "step": 111000
    },
    {
      "epoch": 4.517535121068575,
      "grad_norm": 0.25367629528045654,
      "learning_rate": 0.00029838888151197275,
      "loss": 0.3589,
      "step": 111100
    },
    {
      "epoch": 4.521601236098969,
      "grad_norm": 0.28930914402008057,
      "learning_rate": 0.0002981675740273536,
      "loss": 0.3564,
      "step": 111200
    },
    {
      "epoch": 4.525667351129363,
      "grad_norm": 0.2740263342857361,
      "learning_rate": 0.0002979462665427345,
      "loss": 0.3581,
      "step": 111300
    },
    {
      "epoch": 4.529733466159758,
      "grad_norm": 0.2694101333618164,
      "learning_rate": 0.00029772495905811534,
      "loss": 0.3562,
      "step": 111400
    },
    {
      "epoch": 4.533799581190152,
      "grad_norm": 0.2556382119655609,
      "learning_rate": 0.00029750365157349624,
      "loss": 0.3582,
      "step": 111500
    },
    {
      "epoch": 4.537865696220546,
      "grad_norm": 0.24627703428268433,
      "learning_rate": 0.00029728234408887713,
      "loss": 0.3574,
      "step": 111600
    },
    {
      "epoch": 4.54193181125094,
      "grad_norm": 0.261541485786438,
      "learning_rate": 0.000297061036604258,
      "loss": 0.359,
      "step": 111700
    },
    {
      "epoch": 4.545997926281334,
      "grad_norm": 0.24563010036945343,
      "learning_rate": 0.0002968397291196389,
      "loss": 0.3567,
      "step": 111800
    },
    {
      "epoch": 4.550064041311729,
      "grad_norm": 0.23121106624603271,
      "learning_rate": 0.00029661842163501966,
      "loss": 0.357,
      "step": 111900
    },
    {
      "epoch": 4.554130156342123,
      "grad_norm": 0.24834208190441132,
      "learning_rate": 0.00029639711415040056,
      "loss": 0.3566,
      "step": 112000
    },
    {
      "epoch": 4.554130156342123,
      "eval_loss": 0.36848488450050354,
      "eval_runtime": 116.951,
      "eval_samples_per_second": 1495.515,
      "eval_steps_per_second": 46.738,
      "step": 112000
    },
    {
      "epoch": 4.558196271372517,
      "grad_norm": 0.29902374744415283,
      "learning_rate": 0.0002961758066657814,
      "loss": 0.3585,
      "step": 112100
    },
    {
      "epoch": 4.562262386402911,
      "grad_norm": 0.27944910526275635,
      "learning_rate": 0.0002959544991811623,
      "loss": 0.3582,
      "step": 112200
    },
    {
      "epoch": 4.566328501433306,
      "grad_norm": 0.23425783216953278,
      "learning_rate": 0.00029573319169654314,
      "loss": 0.3589,
      "step": 112300
    },
    {
      "epoch": 4.5703946164637,
      "grad_norm": 0.3153141736984253,
      "learning_rate": 0.00029551188421192404,
      "loss": 0.3544,
      "step": 112400
    },
    {
      "epoch": 4.574460731494094,
      "grad_norm": 0.28744637966156006,
      "learning_rate": 0.00029529057672730494,
      "loss": 0.3547,
      "step": 112500
    },
    {
      "epoch": 4.578526846524488,
      "grad_norm": 0.2591085135936737,
      "learning_rate": 0.0002950692692426858,
      "loss": 0.3577,
      "step": 112600
    },
    {
      "epoch": 4.582592961554882,
      "grad_norm": 0.2794036865234375,
      "learning_rate": 0.0002948479617580667,
      "loss": 0.359,
      "step": 112700
    },
    {
      "epoch": 4.586659076585277,
      "grad_norm": 0.2856372594833374,
      "learning_rate": 0.0002946266542734475,
      "loss": 0.3583,
      "step": 112800
    },
    {
      "epoch": 4.590725191615671,
      "grad_norm": 0.2860550880432129,
      "learning_rate": 0.0002944053467888284,
      "loss": 0.3578,
      "step": 112900
    },
    {
      "epoch": 4.594791306646065,
      "grad_norm": 0.2592354416847229,
      "learning_rate": 0.00029418403930420926,
      "loss": 0.3583,
      "step": 113000
    },
    {
      "epoch": 4.59885742167646,
      "grad_norm": 0.2842757999897003,
      "learning_rate": 0.00029396273181959016,
      "loss": 0.3565,
      "step": 113100
    },
    {
      "epoch": 4.602923536706854,
      "grad_norm": 0.2643418610095978,
      "learning_rate": 0.00029374142433497106,
      "loss": 0.3579,
      "step": 113200
    },
    {
      "epoch": 4.606989651737248,
      "grad_norm": 0.28781071305274963,
      "learning_rate": 0.0002935201168503519,
      "loss": 0.3567,
      "step": 113300
    },
    {
      "epoch": 4.611055766767642,
      "grad_norm": 0.32965072989463806,
      "learning_rate": 0.0002932988093657328,
      "loss": 0.3568,
      "step": 113400
    },
    {
      "epoch": 4.615121881798036,
      "grad_norm": 0.2587466537952423,
      "learning_rate": 0.00029307750188111364,
      "loss": 0.3577,
      "step": 113500
    },
    {
      "epoch": 4.619187996828431,
      "grad_norm": 0.2939145267009735,
      "learning_rate": 0.0002928561943964945,
      "loss": 0.3594,
      "step": 113600
    },
    {
      "epoch": 4.623254111858825,
      "grad_norm": 0.2674688994884491,
      "learning_rate": 0.0002926348869118753,
      "loss": 0.3583,
      "step": 113700
    },
    {
      "epoch": 4.627320226889219,
      "grad_norm": 0.28060096502304077,
      "learning_rate": 0.0002924135794272562,
      "loss": 0.3567,
      "step": 113800
    },
    {
      "epoch": 4.631386341919613,
      "grad_norm": 0.24140238761901855,
      "learning_rate": 0.00029219227194263707,
      "loss": 0.3572,
      "step": 113900
    },
    {
      "epoch": 4.6354524569500075,
      "grad_norm": 0.2790883779525757,
      "learning_rate": 0.00029197096445801796,
      "loss": 0.3585,
      "step": 114000
    },
    {
      "epoch": 4.6354524569500075,
      "eval_loss": 0.36827194690704346,
      "eval_runtime": 116.4846,
      "eval_samples_per_second": 1501.503,
      "eval_steps_per_second": 46.925,
      "step": 114000
    },
    {
      "epoch": 4.6395185719804015,
      "grad_norm": 0.263286292552948,
      "learning_rate": 0.00029174965697339886,
      "loss": 0.3568,
      "step": 114100
    },
    {
      "epoch": 4.6435846870107955,
      "grad_norm": 0.24922612309455872,
      "learning_rate": 0.0002915283494887797,
      "loss": 0.3588,
      "step": 114200
    },
    {
      "epoch": 4.6476508020411895,
      "grad_norm": 0.29953035712242126,
      "learning_rate": 0.0002913070420041606,
      "loss": 0.3584,
      "step": 114300
    },
    {
      "epoch": 4.6517169170715835,
      "grad_norm": 0.29062098264694214,
      "learning_rate": 0.00029108573451954144,
      "loss": 0.3583,
      "step": 114400
    },
    {
      "epoch": 4.655783032101978,
      "grad_norm": 0.28556114435195923,
      "learning_rate": 0.00029086442703492234,
      "loss": 0.3562,
      "step": 114500
    },
    {
      "epoch": 4.659849147132372,
      "grad_norm": 0.3156438171863556,
      "learning_rate": 0.0002906431195503032,
      "loss": 0.3576,
      "step": 114600
    },
    {
      "epoch": 4.663915262162766,
      "grad_norm": 0.2899743914604187,
      "learning_rate": 0.0002904218120656841,
      "loss": 0.3549,
      "step": 114700
    },
    {
      "epoch": 4.66798137719316,
      "grad_norm": 0.28668999671936035,
      "learning_rate": 0.0002902005045810649,
      "loss": 0.3591,
      "step": 114800
    },
    {
      "epoch": 4.672047492223555,
      "grad_norm": 0.32084065675735474,
      "learning_rate": 0.0002899791970964458,
      "loss": 0.3566,
      "step": 114900
    },
    {
      "epoch": 4.676113607253949,
      "grad_norm": 0.24315908551216125,
      "learning_rate": 0.0002897578896118267,
      "loss": 0.3559,
      "step": 115000
    },
    {
      "epoch": 4.680179722284343,
      "grad_norm": 0.2875431180000305,
      "learning_rate": 0.00028953658212720756,
      "loss": 0.3542,
      "step": 115100
    },
    {
      "epoch": 4.684245837314737,
      "grad_norm": 0.2865435779094696,
      "learning_rate": 0.00028931527464258846,
      "loss": 0.3571,
      "step": 115200
    },
    {
      "epoch": 4.688311952345132,
      "grad_norm": 0.28427669405937195,
      "learning_rate": 0.00028909396715796925,
      "loss": 0.3566,
      "step": 115300
    },
    {
      "epoch": 4.692378067375526,
      "grad_norm": 0.2903275787830353,
      "learning_rate": 0.00028887265967335015,
      "loss": 0.3584,
      "step": 115400
    },
    {
      "epoch": 4.69644418240592,
      "grad_norm": 0.2609390914440155,
      "learning_rate": 0.000288651352188731,
      "loss": 0.3573,
      "step": 115500
    },
    {
      "epoch": 4.700510297436314,
      "grad_norm": 0.29631248116493225,
      "learning_rate": 0.0002884300447041119,
      "loss": 0.3579,
      "step": 115600
    },
    {
      "epoch": 4.704576412466709,
      "grad_norm": 0.29335033893585205,
      "learning_rate": 0.00028820873721949273,
      "loss": 0.3561,
      "step": 115700
    },
    {
      "epoch": 4.708642527497103,
      "grad_norm": 0.26945996284484863,
      "learning_rate": 0.00028798742973487363,
      "loss": 0.3562,
      "step": 115800
    },
    {
      "epoch": 4.712708642527497,
      "grad_norm": 0.2658182680606842,
      "learning_rate": 0.0002877661222502545,
      "loss": 0.3572,
      "step": 115900
    },
    {
      "epoch": 4.716774757557891,
      "grad_norm": 0.2612001299858093,
      "learning_rate": 0.00028754481476563537,
      "loss": 0.3583,
      "step": 116000
    },
    {
      "epoch": 4.716774757557891,
      "eval_loss": 0.368123322725296,
      "eval_runtime": 116.417,
      "eval_samples_per_second": 1502.375,
      "eval_steps_per_second": 46.952,
      "step": 116000
    },
    {
      "epoch": 4.720840872588285,
      "grad_norm": 0.2340208888053894,
      "learning_rate": 0.00028732350728101627,
      "loss": 0.3572,
      "step": 116100
    },
    {
      "epoch": 4.72490698761868,
      "grad_norm": 0.2663814127445221,
      "learning_rate": 0.0002871021997963971,
      "loss": 0.3555,
      "step": 116200
    },
    {
      "epoch": 4.728973102649074,
      "grad_norm": 0.27265459299087524,
      "learning_rate": 0.000286880892311778,
      "loss": 0.3563,
      "step": 116300
    },
    {
      "epoch": 4.733039217679468,
      "grad_norm": 0.301035612821579,
      "learning_rate": 0.00028665958482715885,
      "loss": 0.3589,
      "step": 116400
    },
    {
      "epoch": 4.737105332709862,
      "grad_norm": 0.26960045099258423,
      "learning_rate": 0.00028643827734253975,
      "loss": 0.3562,
      "step": 116500
    },
    {
      "epoch": 4.741171447740257,
      "grad_norm": 0.27077779173851013,
      "learning_rate": 0.00028621696985792064,
      "loss": 0.3571,
      "step": 116600
    },
    {
      "epoch": 4.745237562770651,
      "grad_norm": 0.2710956931114197,
      "learning_rate": 0.0002859956623733015,
      "loss": 0.3574,
      "step": 116700
    },
    {
      "epoch": 4.749303677801045,
      "grad_norm": 0.2615862786769867,
      "learning_rate": 0.0002857743548886824,
      "loss": 0.3591,
      "step": 116800
    },
    {
      "epoch": 4.753369792831439,
      "grad_norm": 0.28391745686531067,
      "learning_rate": 0.00028555304740406323,
      "loss": 0.3558,
      "step": 116900
    },
    {
      "epoch": 4.757435907861834,
      "grad_norm": 0.2872748374938965,
      "learning_rate": 0.00028533173991944407,
      "loss": 0.358,
      "step": 117000
    },
    {
      "epoch": 4.761502022892228,
      "grad_norm": 0.30368244647979736,
      "learning_rate": 0.0002851104324348249,
      "loss": 0.3581,
      "step": 117100
    },
    {
      "epoch": 4.765568137922622,
      "grad_norm": 0.293703556060791,
      "learning_rate": 0.0002848891249502058,
      "loss": 0.3569,
      "step": 117200
    },
    {
      "epoch": 4.769634252953016,
      "grad_norm": 0.29198548197746277,
      "learning_rate": 0.00028466781746558665,
      "loss": 0.3563,
      "step": 117300
    },
    {
      "epoch": 4.773700367983411,
      "grad_norm": 0.2839723825454712,
      "learning_rate": 0.00028444650998096755,
      "loss": 0.3576,
      "step": 117400
    },
    {
      "epoch": 4.777766483013805,
      "grad_norm": 0.2446531355381012,
      "learning_rate": 0.00028422520249634845,
      "loss": 0.3562,
      "step": 117500
    },
    {
      "epoch": 4.781832598044199,
      "grad_norm": 0.26990434527397156,
      "learning_rate": 0.0002840038950117293,
      "loss": 0.3571,
      "step": 117600
    },
    {
      "epoch": 4.785898713074593,
      "grad_norm": 0.2612258493900299,
      "learning_rate": 0.0002837825875271102,
      "loss": 0.3571,
      "step": 117700
    },
    {
      "epoch": 4.789964828104987,
      "grad_norm": 0.3155441880226135,
      "learning_rate": 0.00028356128004249103,
      "loss": 0.3562,
      "step": 117800
    },
    {
      "epoch": 4.794030943135382,
      "grad_norm": 0.2950551211833954,
      "learning_rate": 0.00028333997255787193,
      "loss": 0.3565,
      "step": 117900
    },
    {
      "epoch": 4.798097058165776,
      "grad_norm": 0.2743789553642273,
      "learning_rate": 0.00028311866507325277,
      "loss": 0.3588,
      "step": 118000
    },
    {
      "epoch": 4.798097058165776,
      "eval_loss": 0.3675958216190338,
      "eval_runtime": 116.6742,
      "eval_samples_per_second": 1499.063,
      "eval_steps_per_second": 46.848,
      "step": 118000
    },
    {
      "epoch": 4.80216317319617,
      "grad_norm": 0.248197540640831,
      "learning_rate": 0.00028289735758863367,
      "loss": 0.3595,
      "step": 118100
    },
    {
      "epoch": 4.806229288226564,
      "grad_norm": 0.2920874059200287,
      "learning_rate": 0.0002826760501040145,
      "loss": 0.3574,
      "step": 118200
    },
    {
      "epoch": 4.8102954032569585,
      "grad_norm": 0.3004226088523865,
      "learning_rate": 0.0002824547426193954,
      "loss": 0.3562,
      "step": 118300
    },
    {
      "epoch": 4.8143615182873525,
      "grad_norm": 0.24559558928012848,
      "learning_rate": 0.0002822334351347763,
      "loss": 0.3568,
      "step": 118400
    },
    {
      "epoch": 4.8184276333177465,
      "grad_norm": 0.3028608560562134,
      "learning_rate": 0.00028201212765015715,
      "loss": 0.3548,
      "step": 118500
    },
    {
      "epoch": 4.8224937483481405,
      "grad_norm": 0.3079078495502472,
      "learning_rate": 0.00028179082016553805,
      "loss": 0.3555,
      "step": 118600
    },
    {
      "epoch": 4.8265598633785345,
      "grad_norm": 0.3004281222820282,
      "learning_rate": 0.00028156951268091884,
      "loss": 0.3571,
      "step": 118700
    },
    {
      "epoch": 4.830625978408929,
      "grad_norm": 0.3055688738822937,
      "learning_rate": 0.00028134820519629973,
      "loss": 0.3564,
      "step": 118800
    },
    {
      "epoch": 4.834692093439323,
      "grad_norm": 0.34212973713874817,
      "learning_rate": 0.0002811268977116806,
      "loss": 0.3576,
      "step": 118900
    },
    {
      "epoch": 4.838758208469717,
      "grad_norm": 0.29814469814300537,
      "learning_rate": 0.0002809055902270615,
      "loss": 0.3565,
      "step": 119000
    },
    {
      "epoch": 4.842824323500112,
      "grad_norm": 0.3025364875793457,
      "learning_rate": 0.0002806842827424423,
      "loss": 0.3555,
      "step": 119100
    },
    {
      "epoch": 4.846890438530506,
      "grad_norm": 0.29624009132385254,
      "learning_rate": 0.0002804629752578232,
      "loss": 0.3569,
      "step": 119200
    },
    {
      "epoch": 4.8509565535609,
      "grad_norm": 0.24851849675178528,
      "learning_rate": 0.0002802416677732041,
      "loss": 0.355,
      "step": 119300
    },
    {
      "epoch": 4.855022668591294,
      "grad_norm": 0.32020246982574463,
      "learning_rate": 0.00028002036028858496,
      "loss": 0.3557,
      "step": 119400
    },
    {
      "epoch": 4.859088783621688,
      "grad_norm": 0.2885248363018036,
      "learning_rate": 0.00027979905280396585,
      "loss": 0.3565,
      "step": 119500
    },
    {
      "epoch": 4.863154898652083,
      "grad_norm": 0.3218400180339813,
      "learning_rate": 0.0002795777453193467,
      "loss": 0.3586,
      "step": 119600
    },
    {
      "epoch": 4.867221013682477,
      "grad_norm": 0.28282850980758667,
      "learning_rate": 0.0002793564378347276,
      "loss": 0.355,
      "step": 119700
    },
    {
      "epoch": 4.871287128712871,
      "grad_norm": 0.317060649394989,
      "learning_rate": 0.00027913513035010844,
      "loss": 0.3565,
      "step": 119800
    },
    {
      "epoch": 4.875353243743265,
      "grad_norm": 0.2764195501804352,
      "learning_rate": 0.00027891382286548933,
      "loss": 0.3574,
      "step": 119900
    },
    {
      "epoch": 4.87941935877366,
      "grad_norm": 0.34879305958747864,
      "learning_rate": 0.0002786925153808702,
      "loss": 0.3555,
      "step": 120000
    },
    {
      "epoch": 4.87941935877366,
      "eval_loss": 0.36635759472846985,
      "eval_runtime": 117.4505,
      "eval_samples_per_second": 1489.155,
      "eval_steps_per_second": 46.539,
      "step": 120000
    },
    {
      "epoch": 4.883485473804054,
      "grad_norm": 0.26008155941963196,
      "learning_rate": 0.0002784712078962511,
      "loss": 0.3579,
      "step": 120100
    },
    {
      "epoch": 4.887551588834448,
      "grad_norm": 0.28850486874580383,
      "learning_rate": 0.00027824990041163197,
      "loss": 0.3554,
      "step": 120200
    },
    {
      "epoch": 4.891617703864842,
      "grad_norm": 0.2855483889579773,
      "learning_rate": 0.0002780285929270128,
      "loss": 0.3565,
      "step": 120300
    },
    {
      "epoch": 4.895683818895236,
      "grad_norm": 0.27360013127326965,
      "learning_rate": 0.00027780728544239366,
      "loss": 0.3559,
      "step": 120400
    },
    {
      "epoch": 4.899749933925631,
      "grad_norm": 0.30378279089927673,
      "learning_rate": 0.0002775859779577745,
      "loss": 0.3574,
      "step": 120500
    },
    {
      "epoch": 4.903816048956025,
      "grad_norm": 0.2791111469268799,
      "learning_rate": 0.0002773646704731554,
      "loss": 0.356,
      "step": 120600
    },
    {
      "epoch": 4.907882163986419,
      "grad_norm": 0.2692723274230957,
      "learning_rate": 0.00027714336298853624,
      "loss": 0.3571,
      "step": 120700
    },
    {
      "epoch": 4.911948279016814,
      "grad_norm": 0.2754718065261841,
      "learning_rate": 0.00027692205550391714,
      "loss": 0.3579,
      "step": 120800
    },
    {
      "epoch": 4.916014394047208,
      "grad_norm": 0.22334668040275574,
      "learning_rate": 0.00027670074801929804,
      "loss": 0.3576,
      "step": 120900
    },
    {
      "epoch": 4.920080509077602,
      "grad_norm": 0.25870564579963684,
      "learning_rate": 0.0002764794405346789,
      "loss": 0.3554,
      "step": 121000
    },
    {
      "epoch": 4.924146624107996,
      "grad_norm": 0.29140421748161316,
      "learning_rate": 0.0002762581330500598,
      "loss": 0.358,
      "step": 121100
    },
    {
      "epoch": 4.92821273913839,
      "grad_norm": 0.3528808355331421,
      "learning_rate": 0.0002760368255654406,
      "loss": 0.3543,
      "step": 121200
    },
    {
      "epoch": 4.932278854168785,
      "grad_norm": 0.2726130783557892,
      "learning_rate": 0.0002758155180808215,
      "loss": 0.3591,
      "step": 121300
    },
    {
      "epoch": 4.936344969199179,
      "grad_norm": 0.2802547514438629,
      "learning_rate": 0.00027559421059620236,
      "loss": 0.3561,
      "step": 121400
    },
    {
      "epoch": 4.940411084229573,
      "grad_norm": 0.2754310965538025,
      "learning_rate": 0.00027537290311158326,
      "loss": 0.3559,
      "step": 121500
    },
    {
      "epoch": 4.944477199259967,
      "grad_norm": 0.2896747589111328,
      "learning_rate": 0.0002751515956269641,
      "loss": 0.3569,
      "step": 121600
    },
    {
      "epoch": 4.948543314290362,
      "grad_norm": 0.3324406147003174,
      "learning_rate": 0.000274930288142345,
      "loss": 0.356,
      "step": 121700
    },
    {
      "epoch": 4.952609429320756,
      "grad_norm": 0.25929054617881775,
      "learning_rate": 0.0002747089806577259,
      "loss": 0.3537,
      "step": 121800
    },
    {
      "epoch": 4.95667554435115,
      "grad_norm": 0.28786394000053406,
      "learning_rate": 0.00027448767317310674,
      "loss": 0.3557,
      "step": 121900
    },
    {
      "epoch": 4.960741659381544,
      "grad_norm": 0.3187359571456909,
      "learning_rate": 0.00027426636568848764,
      "loss": 0.3569,
      "step": 122000
    },
    {
      "epoch": 4.960741659381544,
      "eval_loss": 0.3661154508590698,
      "eval_runtime": 117.296,
      "eval_samples_per_second": 1491.116,
      "eval_steps_per_second": 46.6,
      "step": 122000
    },
    {
      "epoch": 4.964807774411938,
      "grad_norm": 0.2897428274154663,
      "learning_rate": 0.0002740450582038684,
      "loss": 0.3571,
      "step": 122100
    },
    {
      "epoch": 4.9688738894423325,
      "grad_norm": 0.2559417188167572,
      "learning_rate": 0.0002738237507192493,
      "loss": 0.3582,
      "step": 122200
    },
    {
      "epoch": 4.9729400044727265,
      "grad_norm": 0.2970070540904999,
      "learning_rate": 0.00027360244323463016,
      "loss": 0.3569,
      "step": 122300
    },
    {
      "epoch": 4.9770061195031206,
      "grad_norm": 0.3009655475616455,
      "learning_rate": 0.00027338113575001106,
      "loss": 0.3563,
      "step": 122400
    },
    {
      "epoch": 4.981072234533515,
      "grad_norm": 0.32153627276420593,
      "learning_rate": 0.0002731598282653919,
      "loss": 0.357,
      "step": 122500
    },
    {
      "epoch": 4.985138349563909,
      "grad_norm": 0.2967435121536255,
      "learning_rate": 0.0002729385207807728,
      "loss": 0.3566,
      "step": 122600
    },
    {
      "epoch": 4.9892044645943034,
      "grad_norm": 0.3037301003932953,
      "learning_rate": 0.0002727172132961537,
      "loss": 0.3567,
      "step": 122700
    },
    {
      "epoch": 4.9932705796246974,
      "grad_norm": 0.2740233540534973,
      "learning_rate": 0.00027249590581153454,
      "loss": 0.3569,
      "step": 122800
    },
    {
      "epoch": 4.9973366946550914,
      "grad_norm": 0.26466670632362366,
      "learning_rate": 0.00027227459832691544,
      "loss": 0.3563,
      "step": 122900
    },
    {
      "epoch": 5.001402809685486,
      "grad_norm": 0.30951470136642456,
      "learning_rate": 0.0002720532908422963,
      "loss": 0.3553,
      "step": 123000
    },
    {
      "epoch": 5.00546892471588,
      "grad_norm": 0.2686529755592346,
      "learning_rate": 0.0002718319833576772,
      "loss": 0.353,
      "step": 123100
    },
    {
      "epoch": 5.009535039746274,
      "grad_norm": 0.2794654071331024,
      "learning_rate": 0.000271610675873058,
      "loss": 0.3503,
      "step": 123200
    },
    {
      "epoch": 5.013601154776668,
      "grad_norm": 0.27293524146080017,
      "learning_rate": 0.0002713893683884389,
      "loss": 0.3522,
      "step": 123300
    },
    {
      "epoch": 5.017667269807063,
      "grad_norm": 0.3002837598323822,
      "learning_rate": 0.00027116806090381976,
      "loss": 0.3538,
      "step": 123400
    },
    {
      "epoch": 5.021733384837457,
      "grad_norm": 0.274250328540802,
      "learning_rate": 0.00027094675341920066,
      "loss": 0.3515,
      "step": 123500
    },
    {
      "epoch": 5.025799499867851,
      "grad_norm": 0.2672753930091858,
      "learning_rate": 0.00027072544593458156,
      "loss": 0.3523,
      "step": 123600
    },
    {
      "epoch": 5.029865614898245,
      "grad_norm": 0.2908139228820801,
      "learning_rate": 0.00027050413844996235,
      "loss": 0.3504,
      "step": 123700
    },
    {
      "epoch": 5.033931729928639,
      "grad_norm": 0.23546364903450012,
      "learning_rate": 0.00027028283096534325,
      "loss": 0.353,
      "step": 123800
    },
    {
      "epoch": 5.037997844959034,
      "grad_norm": 0.2792588472366333,
      "learning_rate": 0.0002700615234807241,
      "loss": 0.3518,
      "step": 123900
    },
    {
      "epoch": 5.042063959989428,
      "grad_norm": 0.2783741056919098,
      "learning_rate": 0.000269840215996105,
      "loss": 0.3514,
      "step": 124000
    },
    {
      "epoch": 5.042063959989428,
      "eval_loss": 0.3671838641166687,
      "eval_runtime": 117.0713,
      "eval_samples_per_second": 1493.978,
      "eval_steps_per_second": 46.689,
      "step": 124000
    },
    {
      "epoch": 5.046150405594974,
      "grad_norm": 0.27867716550827026,
      "learning_rate": 0.00026961890851148583,
      "loss": 0.3537,
      "step": 124100
    },
    {
      "epoch": 5.050216520625368,
      "grad_norm": 0.3469078838825226,
      "learning_rate": 0.0002693976010268667,
      "loss": 0.3507,
      "step": 124200
    },
    {
      "epoch": 5.054282635655762,
      "grad_norm": 0.3111548125743866,
      "learning_rate": 0.0002691762935422476,
      "loss": 0.3512,
      "step": 124300
    },
    {
      "epoch": 5.058348750686157,
      "grad_norm": 0.25634852051734924,
      "learning_rate": 0.00026895498605762847,
      "loss": 0.3529,
      "step": 124400
    },
    {
      "epoch": 5.062414865716551,
      "grad_norm": 0.2844146192073822,
      "learning_rate": 0.00026873367857300936,
      "loss": 0.3515,
      "step": 124500
    },
    {
      "epoch": 5.066480980746945,
      "grad_norm": 0.2609381079673767,
      "learning_rate": 0.0002685123710883902,
      "loss": 0.3524,
      "step": 124600
    },
    {
      "epoch": 5.070547095777339,
      "grad_norm": 0.267598032951355,
      "learning_rate": 0.0002682910636037711,
      "loss": 0.3546,
      "step": 124700
    },
    {
      "epoch": 5.074613210807733,
      "grad_norm": 0.2818945348262787,
      "learning_rate": 0.00026806975611915195,
      "loss": 0.3519,
      "step": 124800
    },
    {
      "epoch": 5.078679325838128,
      "grad_norm": 0.31482866406440735,
      "learning_rate": 0.00026784844863453284,
      "loss": 0.3533,
      "step": 124900
    },
    {
      "epoch": 5.082745440868522,
      "grad_norm": 0.2726970613002777,
      "learning_rate": 0.0002676271411499137,
      "loss": 0.3524,
      "step": 125000
    },
    {
      "epoch": 5.086811555898916,
      "grad_norm": 0.3153945505619049,
      "learning_rate": 0.0002674058336652946,
      "loss": 0.3542,
      "step": 125100
    },
    {
      "epoch": 5.09087767092931,
      "grad_norm": 0.29931312799453735,
      "learning_rate": 0.0002671845261806755,
      "loss": 0.3511,
      "step": 125200
    },
    {
      "epoch": 5.094943785959705,
      "grad_norm": 0.2819404602050781,
      "learning_rate": 0.0002669632186960563,
      "loss": 0.3525,
      "step": 125300
    },
    {
      "epoch": 5.099009900990099,
      "grad_norm": 0.34401893615722656,
      "learning_rate": 0.00026674191121143717,
      "loss": 0.3518,
      "step": 125400
    },
    {
      "epoch": 5.103076016020493,
      "grad_norm": 0.30086496472358704,
      "learning_rate": 0.000266520603726818,
      "loss": 0.3523,
      "step": 125500
    },
    {
      "epoch": 5.107142131050887,
      "grad_norm": 0.3061933219432831,
      "learning_rate": 0.0002662992962421989,
      "loss": 0.3526,
      "step": 125600
    },
    {
      "epoch": 5.111208246081282,
      "grad_norm": 0.33713674545288086,
      "learning_rate": 0.00026607798875757975,
      "loss": 0.3501,
      "step": 125700
    },
    {
      "epoch": 5.115274361111676,
      "grad_norm": 0.27995365858078003,
      "learning_rate": 0.00026585668127296065,
      "loss": 0.3529,
      "step": 125800
    },
    {
      "epoch": 5.11934047614207,
      "grad_norm": 0.3239816427230835,
      "learning_rate": 0.0002656353737883415,
      "loss": 0.3522,
      "step": 125900
    },
    {
      "epoch": 5.123406591172464,
      "grad_norm": 0.294953316450119,
      "learning_rate": 0.0002654140663037224,
      "loss": 0.3548,
      "step": 126000
    },
    {
      "epoch": 5.123406591172464,
      "eval_loss": 0.36545994877815247,
      "eval_runtime": 115.4989,
      "eval_samples_per_second": 1514.318,
      "eval_steps_per_second": 47.325,
      "step": 126000
    },
    {
      "epoch": 5.127472706202859,
      "grad_norm": 0.25915417075157166,
      "learning_rate": 0.0002651927588191033,
      "loss": 0.3518,
      "step": 126100
    },
    {
      "epoch": 5.131538821233253,
      "grad_norm": 0.2957768738269806,
      "learning_rate": 0.00026497145133448413,
      "loss": 0.3518,
      "step": 126200
    },
    {
      "epoch": 5.135604936263647,
      "grad_norm": 0.3115253150463104,
      "learning_rate": 0.00026475014384986503,
      "loss": 0.353,
      "step": 126300
    },
    {
      "epoch": 5.139671051294041,
      "grad_norm": 0.295622855424881,
      "learning_rate": 0.00026452883636524587,
      "loss": 0.3539,
      "step": 126400
    },
    {
      "epoch": 5.143737166324435,
      "grad_norm": 0.31827157735824585,
      "learning_rate": 0.00026430752888062677,
      "loss": 0.3558,
      "step": 126500
    },
    {
      "epoch": 5.14780328135483,
      "grad_norm": 0.28080716729164124,
      "learning_rate": 0.0002640862213960076,
      "loss": 0.3526,
      "step": 126600
    },
    {
      "epoch": 5.151869396385224,
      "grad_norm": 0.27738457918167114,
      "learning_rate": 0.0002638649139113885,
      "loss": 0.3532,
      "step": 126700
    },
    {
      "epoch": 5.155935511415618,
      "grad_norm": 0.28002381324768066,
      "learning_rate": 0.00026364360642676935,
      "loss": 0.3519,
      "step": 126800
    },
    {
      "epoch": 5.160001626446012,
      "grad_norm": 0.2908804416656494,
      "learning_rate": 0.00026342229894215025,
      "loss": 0.354,
      "step": 126900
    },
    {
      "epoch": 5.164067741476407,
      "grad_norm": 0.26412859559059143,
      "learning_rate": 0.00026320099145753115,
      "loss": 0.3537,
      "step": 127000
    },
    {
      "epoch": 5.168133856506801,
      "grad_norm": 0.2992713749408722,
      "learning_rate": 0.00026297968397291194,
      "loss": 0.3533,
      "step": 127100
    },
    {
      "epoch": 5.172199971537195,
      "grad_norm": 0.2818242609500885,
      "learning_rate": 0.00026275837648829283,
      "loss": 0.3526,
      "step": 127200
    },
    {
      "epoch": 5.176266086567589,
      "grad_norm": 0.31422868371009827,
      "learning_rate": 0.0002625370690036737,
      "loss": 0.3534,
      "step": 127300
    },
    {
      "epoch": 5.180332201597984,
      "grad_norm": 0.3573342561721802,
      "learning_rate": 0.0002623157615190546,
      "loss": 0.3523,
      "step": 127400
    },
    {
      "epoch": 5.184398316628378,
      "grad_norm": 0.29662197828292847,
      "learning_rate": 0.0002620944540344354,
      "loss": 0.3517,
      "step": 127500
    },
    {
      "epoch": 5.188464431658772,
      "grad_norm": 0.2439090460538864,
      "learning_rate": 0.0002618731465498163,
      "loss": 0.3527,
      "step": 127600
    },
    {
      "epoch": 5.192530546689166,
      "grad_norm": 0.28905782103538513,
      "learning_rate": 0.00026165183906519716,
      "loss": 0.3504,
      "step": 127700
    },
    {
      "epoch": 5.1965966617195605,
      "grad_norm": 0.36273816227912903,
      "learning_rate": 0.00026143053158057805,
      "loss": 0.3536,
      "step": 127800
    },
    {
      "epoch": 5.2006627767499545,
      "grad_norm": 0.2842322885990143,
      "learning_rate": 0.00026120922409595895,
      "loss": 0.3543,
      "step": 127900
    },
    {
      "epoch": 5.2047288917803485,
      "grad_norm": 0.2965638041496277,
      "learning_rate": 0.0002609879166113398,
      "loss": 0.3534,
      "step": 128000
    },
    {
      "epoch": 5.2047288917803485,
      "eval_loss": 0.3647823631763458,
      "eval_runtime": 114.346,
      "eval_samples_per_second": 1529.586,
      "eval_steps_per_second": 47.802,
      "step": 128000
    },
    {
      "epoch": 5.2087950068107425,
      "grad_norm": 0.279989093542099,
      "learning_rate": 0.0002607666091267207,
      "loss": 0.354,
      "step": 128100
    },
    {
      "epoch": 5.2128611218411365,
      "grad_norm": 0.290288507938385,
      "learning_rate": 0.00026054530164210154,
      "loss": 0.3508,
      "step": 128200
    },
    {
      "epoch": 5.216927236871531,
      "grad_norm": 0.30814820528030396,
      "learning_rate": 0.00026032399415748243,
      "loss": 0.3515,
      "step": 128300
    },
    {
      "epoch": 5.220993351901925,
      "grad_norm": 0.2810158133506775,
      "learning_rate": 0.0002601026866728633,
      "loss": 0.3547,
      "step": 128400
    },
    {
      "epoch": 5.225059466932319,
      "grad_norm": 0.3229469060897827,
      "learning_rate": 0.00025988137918824417,
      "loss": 0.352,
      "step": 128500
    },
    {
      "epoch": 5.229125581962713,
      "grad_norm": 0.3000977039337158,
      "learning_rate": 0.00025966007170362507,
      "loss": 0.3522,
      "step": 128600
    },
    {
      "epoch": 5.233191696993108,
      "grad_norm": 0.2781185507774353,
      "learning_rate": 0.0002594387642190059,
      "loss": 0.3518,
      "step": 128700
    },
    {
      "epoch": 5.237257812023502,
      "grad_norm": 0.2801065742969513,
      "learning_rate": 0.00025921745673438676,
      "loss": 0.3531,
      "step": 128800
    },
    {
      "epoch": 5.241323927053896,
      "grad_norm": 0.25754329562187195,
      "learning_rate": 0.0002589961492497676,
      "loss": 0.3528,
      "step": 128900
    },
    {
      "epoch": 5.24539004208429,
      "grad_norm": 0.3077823221683502,
      "learning_rate": 0.0002587748417651485,
      "loss": 0.3513,
      "step": 129000
    },
    {
      "epoch": 5.249456157114685,
      "grad_norm": 0.3115164041519165,
      "learning_rate": 0.00025855353428052934,
      "loss": 0.3562,
      "step": 129100
    },
    {
      "epoch": 5.253522272145079,
      "grad_norm": 0.2532423436641693,
      "learning_rate": 0.00025833222679591024,
      "loss": 0.3516,
      "step": 129200
    },
    {
      "epoch": 5.257588387175473,
      "grad_norm": 0.28937679529190063,
      "learning_rate": 0.0002581109193112911,
      "loss": 0.3512,
      "step": 129300
    },
    {
      "epoch": 5.261654502205867,
      "grad_norm": 0.2723083794116974,
      "learning_rate": 0.000257889611826672,
      "loss": 0.3534,
      "step": 129400
    },
    {
      "epoch": 5.265720617236262,
      "grad_norm": 0.27026915550231934,
      "learning_rate": 0.0002576683043420529,
      "loss": 0.3526,
      "step": 129500
    },
    {
      "epoch": 5.269786732266656,
      "grad_norm": 0.2807725965976715,
      "learning_rate": 0.0002574469968574337,
      "loss": 0.3538,
      "step": 129600
    },
    {
      "epoch": 5.27385284729705,
      "grad_norm": 0.2949509024620056,
      "learning_rate": 0.0002572256893728146,
      "loss": 0.3529,
      "step": 129700
    },
    {
      "epoch": 5.277918962327444,
      "grad_norm": 0.2529938817024231,
      "learning_rate": 0.00025700438188819546,
      "loss": 0.3529,
      "step": 129800
    },
    {
      "epoch": 5.281985077357838,
      "grad_norm": 0.29820138216018677,
      "learning_rate": 0.00025678307440357636,
      "loss": 0.3502,
      "step": 129900
    },
    {
      "epoch": 5.286051192388233,
      "grad_norm": 0.3020201623439789,
      "learning_rate": 0.0002565617669189572,
      "loss": 0.3527,
      "step": 130000
    },
    {
      "epoch": 5.286051192388233,
      "eval_loss": 0.3648805320262909,
      "eval_runtime": 114.1784,
      "eval_samples_per_second": 1531.831,
      "eval_steps_per_second": 47.872,
      "step": 130000
    },
    {
      "epoch": 5.290117307418627,
      "grad_norm": 0.2947584390640259,
      "learning_rate": 0.0002563404594343381,
      "loss": 0.3556,
      "step": 130100
    },
    {
      "epoch": 5.294183422449021,
      "grad_norm": 0.29428020119667053,
      "learning_rate": 0.00025611915194971894,
      "loss": 0.3533,
      "step": 130200
    },
    {
      "epoch": 5.298249537479415,
      "grad_norm": 0.28967294096946716,
      "learning_rate": 0.00025589784446509984,
      "loss": 0.3527,
      "step": 130300
    },
    {
      "epoch": 5.30231565250981,
      "grad_norm": 0.2821199297904968,
      "learning_rate": 0.00025567653698048073,
      "loss": 0.3532,
      "step": 130400
    },
    {
      "epoch": 5.306381767540204,
      "grad_norm": 0.3105047643184662,
      "learning_rate": 0.0002554552294958615,
      "loss": 0.3527,
      "step": 130500
    },
    {
      "epoch": 5.310447882570598,
      "grad_norm": 0.328704833984375,
      "learning_rate": 0.0002552339220112424,
      "loss": 0.3555,
      "step": 130600
    },
    {
      "epoch": 5.314513997600992,
      "grad_norm": 0.2833884358406067,
      "learning_rate": 0.00025501261452662326,
      "loss": 0.3525,
      "step": 130700
    },
    {
      "epoch": 5.318580112631387,
      "grad_norm": 0.2809497117996216,
      "learning_rate": 0.00025479130704200416,
      "loss": 0.3506,
      "step": 130800
    },
    {
      "epoch": 5.322646227661781,
      "grad_norm": 0.28789910674095154,
      "learning_rate": 0.000254569999557385,
      "loss": 0.3551,
      "step": 130900
    },
    {
      "epoch": 5.326712342692175,
      "grad_norm": 0.30402871966362,
      "learning_rate": 0.0002543486920727659,
      "loss": 0.3528,
      "step": 131000
    },
    {
      "epoch": 5.330778457722569,
      "grad_norm": 0.2714962363243103,
      "learning_rate": 0.00025412738458814674,
      "loss": 0.3515,
      "step": 131100
    },
    {
      "epoch": 5.334844572752964,
      "grad_norm": 0.2743654251098633,
      "learning_rate": 0.00025390607710352764,
      "loss": 0.352,
      "step": 131200
    },
    {
      "epoch": 5.338910687783358,
      "grad_norm": 0.31444302201271057,
      "learning_rate": 0.00025368476961890854,
      "loss": 0.3532,
      "step": 131300
    },
    {
      "epoch": 5.342976802813752,
      "grad_norm": 0.29817190766334534,
      "learning_rate": 0.0002534634621342894,
      "loss": 0.3532,
      "step": 131400
    },
    {
      "epoch": 5.347042917844146,
      "grad_norm": 0.2732975482940674,
      "learning_rate": 0.0002532421546496703,
      "loss": 0.3534,
      "step": 131500
    },
    {
      "epoch": 5.35110903287454,
      "grad_norm": 0.2607930898666382,
      "learning_rate": 0.0002530208471650511,
      "loss": 0.3537,
      "step": 131600
    },
    {
      "epoch": 5.3551751479049345,
      "grad_norm": 0.2779424488544464,
      "learning_rate": 0.000252799539680432,
      "loss": 0.3511,
      "step": 131700
    },
    {
      "epoch": 5.3592412629353285,
      "grad_norm": 0.28274670243263245,
      "learning_rate": 0.00025257823219581286,
      "loss": 0.352,
      "step": 131800
    },
    {
      "epoch": 5.3633073779657225,
      "grad_norm": 0.2836078405380249,
      "learning_rate": 0.00025235692471119376,
      "loss": 0.3554,
      "step": 131900
    },
    {
      "epoch": 5.3673734929961165,
      "grad_norm": 0.3166389465332031,
      "learning_rate": 0.00025213561722657466,
      "loss": 0.3528,
      "step": 132000
    },
    {
      "epoch": 5.3673734929961165,
      "eval_loss": 0.364551305770874,
      "eval_runtime": 113.4589,
      "eval_samples_per_second": 1541.545,
      "eval_steps_per_second": 48.176,
      "step": 132000
    },
    {
      "epoch": 5.371439608026511,
      "grad_norm": 0.31564122438430786,
      "learning_rate": 0.0002519143097419555,
      "loss": 0.3528,
      "step": 132100
    },
    {
      "epoch": 5.375505723056905,
      "grad_norm": 0.29470163583755493,
      "learning_rate": 0.00025169300225733634,
      "loss": 0.3529,
      "step": 132200
    },
    {
      "epoch": 5.379571838087299,
      "grad_norm": 0.24600546061992645,
      "learning_rate": 0.0002514716947727172,
      "loss": 0.3506,
      "step": 132300
    },
    {
      "epoch": 5.383637953117693,
      "grad_norm": 0.2768210172653198,
      "learning_rate": 0.0002512503872880981,
      "loss": 0.353,
      "step": 132400
    },
    {
      "epoch": 5.387704068148087,
      "grad_norm": 0.3038325011730194,
      "learning_rate": 0.00025102907980347893,
      "loss": 0.3514,
      "step": 132500
    },
    {
      "epoch": 5.391770183178482,
      "grad_norm": 0.2883547842502594,
      "learning_rate": 0.0002508077723188598,
      "loss": 0.3549,
      "step": 132600
    },
    {
      "epoch": 5.395836298208876,
      "grad_norm": 0.33139553666114807,
      "learning_rate": 0.00025058646483424067,
      "loss": 0.3554,
      "step": 132700
    },
    {
      "epoch": 5.39990241323927,
      "grad_norm": 0.31150031089782715,
      "learning_rate": 0.00025036515734962157,
      "loss": 0.3501,
      "step": 132800
    },
    {
      "epoch": 5.403968528269664,
      "grad_norm": 0.30937397480010986,
      "learning_rate": 0.00025014384986500246,
      "loss": 0.3523,
      "step": 132900
    },
    {
      "epoch": 5.408034643300059,
      "grad_norm": 0.30924075841903687,
      "learning_rate": 0.0002499225423803833,
      "loss": 0.3541,
      "step": 133000
    },
    {
      "epoch": 5.412100758330453,
      "grad_norm": 0.2832221984863281,
      "learning_rate": 0.0002497012348957642,
      "loss": 0.352,
      "step": 133100
    },
    {
      "epoch": 5.416166873360847,
      "grad_norm": 0.32737988233566284,
      "learning_rate": 0.00024947992741114505,
      "loss": 0.3539,
      "step": 133200
    },
    {
      "epoch": 5.420232988391241,
      "grad_norm": 0.323930561542511,
      "learning_rate": 0.00024925861992652594,
      "loss": 0.3553,
      "step": 133300
    },
    {
      "epoch": 5.424299103421636,
      "grad_norm": 0.3282323181629181,
      "learning_rate": 0.0002490373124419068,
      "loss": 0.3531,
      "step": 133400
    },
    {
      "epoch": 5.42836521845203,
      "grad_norm": 0.31787726283073425,
      "learning_rate": 0.00024881600495728763,
      "loss": 0.3525,
      "step": 133500
    },
    {
      "epoch": 5.432431333482424,
      "grad_norm": 0.28429117798805237,
      "learning_rate": 0.0002485946974726685,
      "loss": 0.3542,
      "step": 133600
    },
    {
      "epoch": 5.436497448512818,
      "grad_norm": 0.33360928297042847,
      "learning_rate": 0.0002483733899880494,
      "loss": 0.353,
      "step": 133700
    },
    {
      "epoch": 5.440563563543213,
      "grad_norm": 0.3407765030860901,
      "learning_rate": 0.00024815208250343027,
      "loss": 0.3529,
      "step": 133800
    },
    {
      "epoch": 5.444629678573607,
      "grad_norm": 0.340603232383728,
      "learning_rate": 0.00024793077501881116,
      "loss": 0.3537,
      "step": 133900
    },
    {
      "epoch": 5.448695793604001,
      "grad_norm": 0.28453993797302246,
      "learning_rate": 0.000247709467534192,
      "loss": 0.3504,
      "step": 134000
    },
    {
      "epoch": 5.448695793604001,
      "eval_loss": 0.36423200368881226,
      "eval_runtime": 113.2073,
      "eval_samples_per_second": 1544.971,
      "eval_steps_per_second": 48.283,
      "step": 134000
    },
    {
      "epoch": 5.452761908634395,
      "grad_norm": 0.31811824440956116,
      "learning_rate": 0.0002474881600495729,
      "loss": 0.3526,
      "step": 134100
    },
    {
      "epoch": 5.456828023664789,
      "grad_norm": 0.3047696352005005,
      "learning_rate": 0.00024726685256495375,
      "loss": 0.3523,
      "step": 134200
    },
    {
      "epoch": 5.460894138695184,
      "grad_norm": 0.29863792657852173,
      "learning_rate": 0.0002470455450803346,
      "loss": 0.3505,
      "step": 134300
    },
    {
      "epoch": 5.464960253725578,
      "grad_norm": 0.2732101082801819,
      "learning_rate": 0.0002468242375957155,
      "loss": 0.3519,
      "step": 134400
    },
    {
      "epoch": 5.469026368755972,
      "grad_norm": 0.2902623414993286,
      "learning_rate": 0.00024660293011109633,
      "loss": 0.3525,
      "step": 134500
    },
    {
      "epoch": 5.473092483786366,
      "grad_norm": 0.3175256550312042,
      "learning_rate": 0.00024638162262647723,
      "loss": 0.352,
      "step": 134600
    },
    {
      "epoch": 5.477158598816761,
      "grad_norm": 0.30670851469039917,
      "learning_rate": 0.0002461603151418581,
      "loss": 0.3522,
      "step": 134700
    },
    {
      "epoch": 5.481224713847155,
      "grad_norm": 0.2997579574584961,
      "learning_rate": 0.00024593900765723897,
      "loss": 0.3533,
      "step": 134800
    },
    {
      "epoch": 5.485290828877549,
      "grad_norm": 0.29294925928115845,
      "learning_rate": 0.00024571770017261987,
      "loss": 0.3493,
      "step": 134900
    },
    {
      "epoch": 5.489356943907943,
      "grad_norm": 0.3255826234817505,
      "learning_rate": 0.0002454963926880007,
      "loss": 0.3512,
      "step": 135000
    },
    {
      "epoch": 5.493423058938338,
      "grad_norm": 0.276257187128067,
      "learning_rate": 0.00024527508520338155,
      "loss": 0.3523,
      "step": 135100
    },
    {
      "epoch": 5.497489173968732,
      "grad_norm": 0.27685415744781494,
      "learning_rate": 0.00024505377771876245,
      "loss": 0.3525,
      "step": 135200
    },
    {
      "epoch": 5.501555288999126,
      "grad_norm": 0.28273212909698486,
      "learning_rate": 0.0002448324702341433,
      "loss": 0.3519,
      "step": 135300
    },
    {
      "epoch": 5.50562140402952,
      "grad_norm": 0.3469690680503845,
      "learning_rate": 0.0002446111627495242,
      "loss": 0.3529,
      "step": 135400
    },
    {
      "epoch": 5.509687519059915,
      "grad_norm": 0.34913602471351624,
      "learning_rate": 0.0002443898552649051,
      "loss": 0.3518,
      "step": 135500
    },
    {
      "epoch": 5.513753634090309,
      "grad_norm": 0.32144635915756226,
      "learning_rate": 0.00024416854778028593,
      "loss": 0.3545,
      "step": 135600
    },
    {
      "epoch": 5.517819749120703,
      "grad_norm": 0.3061386048793793,
      "learning_rate": 0.0002439472402956668,
      "loss": 0.3529,
      "step": 135700
    },
    {
      "epoch": 5.521885864151097,
      "grad_norm": 0.2787937819957733,
      "learning_rate": 0.00024372593281104767,
      "loss": 0.3495,
      "step": 135800
    },
    {
      "epoch": 5.525951979181491,
      "grad_norm": 0.3739701211452484,
      "learning_rate": 0.00024350462532642857,
      "loss": 0.3513,
      "step": 135900
    },
    {
      "epoch": 5.5300180942118855,
      "grad_norm": 0.27814117074012756,
      "learning_rate": 0.0002432833178418094,
      "loss": 0.3506,
      "step": 136000
    },
    {
      "epoch": 5.5300180942118855,
      "eval_loss": 0.36366337537765503,
      "eval_runtime": 113.8917,
      "eval_samples_per_second": 1535.686,
      "eval_steps_per_second": 47.993,
      "step": 136000
    },
    {
      "epoch": 5.5340842092422795,
      "grad_norm": 0.33203646540641785,
      "learning_rate": 0.00024306201035719028,
      "loss": 0.3522,
      "step": 136100
    },
    {
      "epoch": 5.5381503242726735,
      "grad_norm": 0.281596302986145,
      "learning_rate": 0.00024284070287257115,
      "loss": 0.3512,
      "step": 136200
    },
    {
      "epoch": 5.5422164393030675,
      "grad_norm": 0.3047196865081787,
      "learning_rate": 0.00024261939538795202,
      "loss": 0.353,
      "step": 136300
    },
    {
      "epoch": 5.546282554333462,
      "grad_norm": 0.29137763381004333,
      "learning_rate": 0.0002423980879033329,
      "loss": 0.3539,
      "step": 136400
    },
    {
      "epoch": 5.550348669363856,
      "grad_norm": 0.26254498958587646,
      "learning_rate": 0.00024217678041871376,
      "loss": 0.3529,
      "step": 136500
    },
    {
      "epoch": 5.55441478439425,
      "grad_norm": 0.27273672819137573,
      "learning_rate": 0.00024195547293409463,
      "loss": 0.3527,
      "step": 136600
    },
    {
      "epoch": 5.558480899424644,
      "grad_norm": 0.3254949152469635,
      "learning_rate": 0.00024173416544947553,
      "loss": 0.3517,
      "step": 136700
    },
    {
      "epoch": 5.562547014455039,
      "grad_norm": 0.30844762921333313,
      "learning_rate": 0.00024151285796485637,
      "loss": 0.3503,
      "step": 136800
    },
    {
      "epoch": 5.566613129485433,
      "grad_norm": 0.2858195900917053,
      "learning_rate": 0.00024129155048023724,
      "loss": 0.3511,
      "step": 136900
    },
    {
      "epoch": 5.570679244515827,
      "grad_norm": 0.26084834337234497,
      "learning_rate": 0.00024107024299561811,
      "loss": 0.3539,
      "step": 137000
    },
    {
      "epoch": 5.574745359546221,
      "grad_norm": 0.349037766456604,
      "learning_rate": 0.00024084893551099898,
      "loss": 0.3533,
      "step": 137100
    },
    {
      "epoch": 5.578811474576616,
      "grad_norm": 0.30123522877693176,
      "learning_rate": 0.00024062762802637985,
      "loss": 0.3529,
      "step": 137200
    },
    {
      "epoch": 5.58287758960701,
      "grad_norm": 0.3022671937942505,
      "learning_rate": 0.00024040632054176073,
      "loss": 0.3519,
      "step": 137300
    },
    {
      "epoch": 5.586943704637404,
      "grad_norm": 0.2806626856327057,
      "learning_rate": 0.0002401850130571416,
      "loss": 0.3494,
      "step": 137400
    },
    {
      "epoch": 5.591009819667798,
      "grad_norm": 0.32088667154312134,
      "learning_rate": 0.00023996370557252247,
      "loss": 0.3504,
      "step": 137500
    },
    {
      "epoch": 5.595075934698192,
      "grad_norm": 0.2776072919368744,
      "learning_rate": 0.00023974239808790336,
      "loss": 0.3531,
      "step": 137600
    },
    {
      "epoch": 5.599142049728587,
      "grad_norm": 0.34420982003211975,
      "learning_rate": 0.0002395210906032842,
      "loss": 0.3514,
      "step": 137700
    },
    {
      "epoch": 5.603208164758981,
      "grad_norm": 0.29755714535713196,
      "learning_rate": 0.00023929978311866508,
      "loss": 0.3534,
      "step": 137800
    },
    {
      "epoch": 5.607274279789375,
      "grad_norm": 0.2966611683368683,
      "learning_rate": 0.00023907847563404595,
      "loss": 0.3518,
      "step": 137900
    },
    {
      "epoch": 5.611340394819769,
      "grad_norm": 0.31135788559913635,
      "learning_rate": 0.00023885716814942682,
      "loss": 0.3536,
      "step": 138000
    },
    {
      "epoch": 5.611340394819769,
      "eval_loss": 0.3632051944732666,
      "eval_runtime": 113.8063,
      "eval_samples_per_second": 1536.839,
      "eval_steps_per_second": 48.029,
      "step": 138000
    },
    {
      "epoch": 5.615406509850164,
      "grad_norm": 0.27287557721138,
      "learning_rate": 0.0002386358606648077,
      "loss": 0.3498,
      "step": 138100
    },
    {
      "epoch": 5.619472624880558,
      "grad_norm": 0.27923792600631714,
      "learning_rate": 0.00023841455318018856,
      "loss": 0.3529,
      "step": 138200
    },
    {
      "epoch": 5.623538739910952,
      "grad_norm": 0.28264686465263367,
      "learning_rate": 0.00023819324569556943,
      "loss": 0.3514,
      "step": 138300
    },
    {
      "epoch": 5.627604854941346,
      "grad_norm": 0.3322109878063202,
      "learning_rate": 0.00023797193821095032,
      "loss": 0.3526,
      "step": 138400
    },
    {
      "epoch": 5.631670969971741,
      "grad_norm": 0.3026346266269684,
      "learning_rate": 0.00023775063072633117,
      "loss": 0.3531,
      "step": 138500
    },
    {
      "epoch": 5.635737085002135,
      "grad_norm": 0.2935118079185486,
      "learning_rate": 0.00023752932324171204,
      "loss": 0.3535,
      "step": 138600
    },
    {
      "epoch": 5.639803200032529,
      "grad_norm": 0.34555336833000183,
      "learning_rate": 0.0002373080157570929,
      "loss": 0.3526,
      "step": 138700
    },
    {
      "epoch": 5.643869315062923,
      "grad_norm": 0.26759353280067444,
      "learning_rate": 0.00023708670827247378,
      "loss": 0.3504,
      "step": 138800
    },
    {
      "epoch": 5.647935430093318,
      "grad_norm": 0.298136442899704,
      "learning_rate": 0.00023686540078785465,
      "loss": 0.3531,
      "step": 138900
    },
    {
      "epoch": 5.652001545123712,
      "grad_norm": 0.27464497089385986,
      "learning_rate": 0.00023664409330323552,
      "loss": 0.3511,
      "step": 139000
    },
    {
      "epoch": 5.656067660154106,
      "grad_norm": 0.29813167452812195,
      "learning_rate": 0.0002364227858186164,
      "loss": 0.3515,
      "step": 139100
    },
    {
      "epoch": 5.6601337751845,
      "grad_norm": 0.26700666546821594,
      "learning_rate": 0.00023620147833399726,
      "loss": 0.3532,
      "step": 139200
    },
    {
      "epoch": 5.664199890214894,
      "grad_norm": 0.2805536985397339,
      "learning_rate": 0.00023598017084937813,
      "loss": 0.3526,
      "step": 139300
    },
    {
      "epoch": 5.668266005245289,
      "grad_norm": 0.31418612599372864,
      "learning_rate": 0.000235758863364759,
      "loss": 0.3531,
      "step": 139400
    },
    {
      "epoch": 5.672332120275683,
      "grad_norm": 0.30685797333717346,
      "learning_rate": 0.00023553755588013987,
      "loss": 0.3526,
      "step": 139500
    },
    {
      "epoch": 5.676398235306077,
      "grad_norm": 0.29965445399284363,
      "learning_rate": 0.00023531624839552074,
      "loss": 0.3511,
      "step": 139600
    },
    {
      "epoch": 5.680464350336471,
      "grad_norm": 0.28359517455101013,
      "learning_rate": 0.0002350949409109016,
      "loss": 0.3512,
      "step": 139700
    },
    {
      "epoch": 5.684530465366866,
      "grad_norm": 0.3351280093193054,
      "learning_rate": 0.00023487363342628248,
      "loss": 0.352,
      "step": 139800
    },
    {
      "epoch": 5.68859658039726,
      "grad_norm": 0.295398086309433,
      "learning_rate": 0.00023465232594166335,
      "loss": 0.3506,
      "step": 139900
    },
    {
      "epoch": 5.692662695427654,
      "grad_norm": 0.27045029401779175,
      "learning_rate": 0.00023443101845704422,
      "loss": 0.3507,
      "step": 140000
    },
    {
      "epoch": 5.692662695427654,
      "eval_loss": 0.36222216486930847,
      "eval_runtime": 113.5961,
      "eval_samples_per_second": 1539.683,
      "eval_steps_per_second": 48.118,
      "step": 140000
    },
    {
      "epoch": 5.696728810458048,
      "grad_norm": 0.3212493360042572,
      "learning_rate": 0.00023420971097242512,
      "loss": 0.3523,
      "step": 140100
    },
    {
      "epoch": 5.700794925488442,
      "grad_norm": 0.28041040897369385,
      "learning_rate": 0.00023398840348780596,
      "loss": 0.3501,
      "step": 140200
    },
    {
      "epoch": 5.7048610405188365,
      "grad_norm": 0.2875918745994568,
      "learning_rate": 0.00023376709600318683,
      "loss": 0.3488,
      "step": 140300
    },
    {
      "epoch": 5.7089271555492305,
      "grad_norm": 0.27989962697029114,
      "learning_rate": 0.0002335457885185677,
      "loss": 0.3511,
      "step": 140400
    },
    {
      "epoch": 5.7129932705796245,
      "grad_norm": 0.269423246383667,
      "learning_rate": 0.00023332448103394857,
      "loss": 0.3529,
      "step": 140500
    },
    {
      "epoch": 5.717059385610019,
      "grad_norm": 0.28224799036979675,
      "learning_rate": 0.00023310317354932944,
      "loss": 0.3513,
      "step": 140600
    },
    {
      "epoch": 5.721125500640413,
      "grad_norm": 0.33719009160995483,
      "learning_rate": 0.0002328818660647103,
      "loss": 0.3533,
      "step": 140700
    },
    {
      "epoch": 5.725191615670807,
      "grad_norm": 0.3427017033100128,
      "learning_rate": 0.00023266055858009118,
      "loss": 0.3521,
      "step": 140800
    },
    {
      "epoch": 5.729257730701201,
      "grad_norm": 0.28034061193466187,
      "learning_rate": 0.00023243925109547205,
      "loss": 0.3508,
      "step": 140900
    },
    {
      "epoch": 5.733323845731595,
      "grad_norm": 0.33365464210510254,
      "learning_rate": 0.00023221794361085292,
      "loss": 0.3524,
      "step": 141000
    },
    {
      "epoch": 5.73738996076199,
      "grad_norm": 0.32241126894950867,
      "learning_rate": 0.0002319966361262338,
      "loss": 0.3498,
      "step": 141100
    },
    {
      "epoch": 5.741456075792384,
      "grad_norm": 0.30426260828971863,
      "learning_rate": 0.00023177532864161466,
      "loss": 0.352,
      "step": 141200
    },
    {
      "epoch": 5.745522190822778,
      "grad_norm": 0.29734742641448975,
      "learning_rate": 0.00023155402115699553,
      "loss": 0.3544,
      "step": 141300
    },
    {
      "epoch": 5.749588305853172,
      "grad_norm": 0.3271358907222748,
      "learning_rate": 0.0002313327136723764,
      "loss": 0.3531,
      "step": 141400
    },
    {
      "epoch": 5.753654420883567,
      "grad_norm": 0.3282318711280823,
      "learning_rate": 0.00023111140618775727,
      "loss": 0.3533,
      "step": 141500
    },
    {
      "epoch": 5.757720535913961,
      "grad_norm": 0.37629738450050354,
      "learning_rate": 0.00023089009870313814,
      "loss": 0.3505,
      "step": 141600
    },
    {
      "epoch": 5.761786650944355,
      "grad_norm": 0.29877570271492004,
      "learning_rate": 0.00023066879121851901,
      "loss": 0.3551,
      "step": 141700
    },
    {
      "epoch": 5.765852765974749,
      "grad_norm": 0.2989180088043213,
      "learning_rate": 0.00023044748373389989,
      "loss": 0.3528,
      "step": 141800
    },
    {
      "epoch": 5.769918881005143,
      "grad_norm": 0.3290403485298157,
      "learning_rate": 0.00023022617624928076,
      "loss": 0.3515,
      "step": 141900
    },
    {
      "epoch": 5.773984996035538,
      "grad_norm": 0.28014281392097473,
      "learning_rate": 0.00023000486876466163,
      "loss": 0.3521,
      "step": 142000
    },
    {
      "epoch": 5.773984996035538,
      "eval_loss": 0.36244523525238037,
      "eval_runtime": 113.7334,
      "eval_samples_per_second": 1537.825,
      "eval_steps_per_second": 48.06,
      "step": 142000
    },
    {
      "epoch": 5.778051111065932,
      "grad_norm": 0.2926499843597412,
      "learning_rate": 0.0002297835612800425,
      "loss": 0.3507,
      "step": 142100
    },
    {
      "epoch": 5.782117226096326,
      "grad_norm": 0.3121868968009949,
      "learning_rate": 0.00022956225379542337,
      "loss": 0.3526,
      "step": 142200
    },
    {
      "epoch": 5.786183341126721,
      "grad_norm": 0.29105710983276367,
      "learning_rate": 0.00022934094631080424,
      "loss": 0.3541,
      "step": 142300
    },
    {
      "epoch": 5.790249456157115,
      "grad_norm": 0.31526491045951843,
      "learning_rate": 0.0002291196388261851,
      "loss": 0.3512,
      "step": 142400
    },
    {
      "epoch": 5.794315571187509,
      "grad_norm": 0.2969339191913605,
      "learning_rate": 0.00022889833134156598,
      "loss": 0.3503,
      "step": 142500
    },
    {
      "epoch": 5.798381686217903,
      "grad_norm": 0.2518361508846283,
      "learning_rate": 0.00022867702385694685,
      "loss": 0.3516,
      "step": 142600
    },
    {
      "epoch": 5.802447801248297,
      "grad_norm": 0.34262344241142273,
      "learning_rate": 0.00022845571637232772,
      "loss": 0.3525,
      "step": 142700
    },
    {
      "epoch": 5.806513916278692,
      "grad_norm": 0.32183852791786194,
      "learning_rate": 0.0002282344088877086,
      "loss": 0.3508,
      "step": 142800
    },
    {
      "epoch": 5.810580031309086,
      "grad_norm": 0.2861384153366089,
      "learning_rate": 0.00022801310140308946,
      "loss": 0.3535,
      "step": 142900
    },
    {
      "epoch": 5.81464614633948,
      "grad_norm": 0.2893296182155609,
      "learning_rate": 0.00022779179391847033,
      "loss": 0.3517,
      "step": 143000
    },
    {
      "epoch": 5.818712261369874,
      "grad_norm": 0.32398107647895813,
      "learning_rate": 0.0002275704864338512,
      "loss": 0.3517,
      "step": 143100
    },
    {
      "epoch": 5.822778376400269,
      "grad_norm": 0.2863541543483734,
      "learning_rate": 0.00022734917894923207,
      "loss": 0.3519,
      "step": 143200
    },
    {
      "epoch": 5.826844491430663,
      "grad_norm": 0.38314077258110046,
      "learning_rate": 0.00022712787146461294,
      "loss": 0.3507,
      "step": 143300
    },
    {
      "epoch": 5.830910606461057,
      "grad_norm": 0.3447906970977783,
      "learning_rate": 0.0002269065639799938,
      "loss": 0.3513,
      "step": 143400
    },
    {
      "epoch": 5.834976721491451,
      "grad_norm": 0.3003023564815521,
      "learning_rate": 0.00022668525649537468,
      "loss": 0.351,
      "step": 143500
    },
    {
      "epoch": 5.839042836521845,
      "grad_norm": 0.2954615652561188,
      "learning_rate": 0.00022646394901075555,
      "loss": 0.3514,
      "step": 143600
    },
    {
      "epoch": 5.84310895155224,
      "grad_norm": 0.2997654974460602,
      "learning_rate": 0.00022624264152613642,
      "loss": 0.353,
      "step": 143700
    },
    {
      "epoch": 5.847175066582634,
      "grad_norm": 0.32318630814552307,
      "learning_rate": 0.0002260213340415173,
      "loss": 0.3497,
      "step": 143800
    },
    {
      "epoch": 5.851241181613028,
      "grad_norm": 0.31375852227211,
      "learning_rate": 0.00022580002655689816,
      "loss": 0.3523,
      "step": 143900
    },
    {
      "epoch": 5.8553072966434225,
      "grad_norm": 0.32992640137672424,
      "learning_rate": 0.00022557871907227903,
      "loss": 0.3524,
      "step": 144000
    },
    {
      "epoch": 5.8553072966434225,
      "eval_loss": 0.3619591295719147,
      "eval_runtime": 113.4377,
      "eval_samples_per_second": 1541.833,
      "eval_steps_per_second": 48.185,
      "step": 144000
    },
    {
      "epoch": 5.8593734116738165,
      "grad_norm": 0.3050118684768677,
      "learning_rate": 0.0002253574115876599,
      "loss": 0.3493,
      "step": 144100
    },
    {
      "epoch": 5.8634395267042105,
      "grad_norm": 0.32240691781044006,
      "learning_rate": 0.00022513610410304077,
      "loss": 0.3517,
      "step": 144200
    },
    {
      "epoch": 5.8675056417346045,
      "grad_norm": 0.30151915550231934,
      "learning_rate": 0.00022491479661842164,
      "loss": 0.3532,
      "step": 144300
    },
    {
      "epoch": 5.8715717567649985,
      "grad_norm": 0.24594523012638092,
      "learning_rate": 0.0002246934891338025,
      "loss": 0.3507,
      "step": 144400
    },
    {
      "epoch": 5.875637871795393,
      "grad_norm": 0.38448360562324524,
      "learning_rate": 0.00022447218164918338,
      "loss": 0.3502,
      "step": 144500
    },
    {
      "epoch": 5.879703986825787,
      "grad_norm": 0.3493848443031311,
      "learning_rate": 0.00022425087416456425,
      "loss": 0.3518,
      "step": 144600
    },
    {
      "epoch": 5.883770101856181,
      "grad_norm": 0.30085593461990356,
      "learning_rate": 0.00022402956667994512,
      "loss": 0.3499,
      "step": 144700
    },
    {
      "epoch": 5.887836216886575,
      "grad_norm": 0.34642329812049866,
      "learning_rate": 0.000223808259195326,
      "loss": 0.3505,
      "step": 144800
    },
    {
      "epoch": 5.89190233191697,
      "grad_norm": 0.3035936653614044,
      "learning_rate": 0.00022358695171070686,
      "loss": 0.3495,
      "step": 144900
    },
    {
      "epoch": 5.895968446947364,
      "grad_norm": 0.3068265914916992,
      "learning_rate": 0.00022336564422608773,
      "loss": 0.3529,
      "step": 145000
    },
    {
      "epoch": 5.900034561977758,
      "grad_norm": 0.32165345549583435,
      "learning_rate": 0.0002231443367414686,
      "loss": 0.351,
      "step": 145100
    },
    {
      "epoch": 5.904100677008152,
      "grad_norm": 0.33077654242515564,
      "learning_rate": 0.00022292302925684945,
      "loss": 0.352,
      "step": 145200
    },
    {
      "epoch": 5.908166792038546,
      "grad_norm": 0.3429205119609833,
      "learning_rate": 0.00022270172177223034,
      "loss": 0.3521,
      "step": 145300
    },
    {
      "epoch": 5.912232907068941,
      "grad_norm": 0.308961421251297,
      "learning_rate": 0.0002224804142876112,
      "loss": 0.3516,
      "step": 145400
    },
    {
      "epoch": 5.916299022099335,
      "grad_norm": 0.3297097086906433,
      "learning_rate": 0.00022225910680299208,
      "loss": 0.3504,
      "step": 145500
    },
    {
      "epoch": 5.920365137129729,
      "grad_norm": 0.3153701722621918,
      "learning_rate": 0.00022203779931837295,
      "loss": 0.3525,
      "step": 145600
    },
    {
      "epoch": 5.924431252160123,
      "grad_norm": 0.35592707991600037,
      "learning_rate": 0.00022181649183375382,
      "loss": 0.3516,
      "step": 145700
    },
    {
      "epoch": 5.928497367190518,
      "grad_norm": 0.29888027906417847,
      "learning_rate": 0.0002215951843491347,
      "loss": 0.3513,
      "step": 145800
    },
    {
      "epoch": 5.932563482220912,
      "grad_norm": 0.3267459273338318,
      "learning_rate": 0.00022137387686451556,
      "loss": 0.3517,
      "step": 145900
    },
    {
      "epoch": 5.936629597251306,
      "grad_norm": 0.28127235174179077,
      "learning_rate": 0.00022115256937989643,
      "loss": 0.3519,
      "step": 146000
    },
    {
      "epoch": 5.936629597251306,
      "eval_loss": 0.3612525463104248,
      "eval_runtime": 113.532,
      "eval_samples_per_second": 1540.553,
      "eval_steps_per_second": 48.145,
      "step": 146000
    },
    {
      "epoch": 5.9406957122817,
      "grad_norm": 0.29353392124176025,
      "learning_rate": 0.0002209312618952773,
      "loss": 0.3507,
      "step": 146100
    },
    {
      "epoch": 5.944761827312095,
      "grad_norm": 0.32089948654174805,
      "learning_rate": 0.00022070995441065817,
      "loss": 0.3508,
      "step": 146200
    },
    {
      "epoch": 5.948827942342489,
      "grad_norm": 0.326321005821228,
      "learning_rate": 0.00022048864692603905,
      "loss": 0.3524,
      "step": 146300
    },
    {
      "epoch": 5.952894057372883,
      "grad_norm": 0.3076014220714569,
      "learning_rate": 0.00022026733944141992,
      "loss": 0.3519,
      "step": 146400
    },
    {
      "epoch": 5.956960172403277,
      "grad_norm": 0.33187150955200195,
      "learning_rate": 0.00022004603195680079,
      "loss": 0.35,
      "step": 146500
    },
    {
      "epoch": 5.961026287433672,
      "grad_norm": 0.29856669902801514,
      "learning_rate": 0.00021982472447218166,
      "loss": 0.3514,
      "step": 146600
    },
    {
      "epoch": 5.965092402464066,
      "grad_norm": 0.3037317395210266,
      "learning_rate": 0.00021960341698756253,
      "loss": 0.3517,
      "step": 146700
    },
    {
      "epoch": 5.96915851749446,
      "grad_norm": 0.2887791097164154,
      "learning_rate": 0.0002193821095029434,
      "loss": 0.3517,
      "step": 146800
    },
    {
      "epoch": 5.973224632524854,
      "grad_norm": 0.31699681282043457,
      "learning_rate": 0.00021916080201832424,
      "loss": 0.3519,
      "step": 146900
    },
    {
      "epoch": 5.977290747555248,
      "grad_norm": 0.29039764404296875,
      "learning_rate": 0.00021893949453370514,
      "loss": 0.3522,
      "step": 147000
    },
    {
      "epoch": 5.981356862585643,
      "grad_norm": 0.29190486669540405,
      "learning_rate": 0.000218718187049086,
      "loss": 0.3512,
      "step": 147100
    },
    {
      "epoch": 5.985422977616037,
      "grad_norm": 0.3456207811832428,
      "learning_rate": 0.00021849687956446688,
      "loss": 0.3522,
      "step": 147200
    },
    {
      "epoch": 5.989489092646431,
      "grad_norm": 0.3054628372192383,
      "learning_rate": 0.00021827557207984775,
      "loss": 0.3509,
      "step": 147300
    },
    {
      "epoch": 5.993555207676825,
      "grad_norm": 0.2824403941631317,
      "learning_rate": 0.00021805426459522862,
      "loss": 0.3517,
      "step": 147400
    },
    {
      "epoch": 5.99762132270722,
      "grad_norm": 0.32462388277053833,
      "learning_rate": 0.0002178329571106095,
      "loss": 0.3527,
      "step": 147500
    },
    {
      "epoch": 6.001687437737614,
      "grad_norm": 0.30307045578956604,
      "learning_rate": 0.00021761164962599036,
      "loss": 0.3476,
      "step": 147600
    },
    {
      "epoch": 6.005753552768008,
      "grad_norm": 0.30522650480270386,
      "learning_rate": 0.00021739034214137123,
      "loss": 0.3455,
      "step": 147700
    },
    {
      "epoch": 6.009819667798402,
      "grad_norm": 0.3172396719455719,
      "learning_rate": 0.00021716903465675207,
      "loss": 0.3471,
      "step": 147800
    },
    {
      "epoch": 6.013885782828797,
      "grad_norm": 0.2782834470272064,
      "learning_rate": 0.00021694772717213297,
      "loss": 0.3451,
      "step": 147900
    },
    {
      "epoch": 6.017951897859191,
      "grad_norm": 0.30834510922431946,
      "learning_rate": 0.00021672641968751384,
      "loss": 0.3452,
      "step": 148000
    },
    {
      "epoch": 6.017951897859191,
      "eval_loss": 0.3613130450248718,
      "eval_runtime": 113.6735,
      "eval_samples_per_second": 1538.634,
      "eval_steps_per_second": 48.085,
      "step": 148000
    },
    {
      "epoch": 6.022018012889585,
      "grad_norm": 0.2753838002681732,
      "learning_rate": 0.0002165051122028947,
      "loss": 0.346,
      "step": 148100
    },
    {
      "epoch": 6.026084127919979,
      "grad_norm": 0.3062976002693176,
      "learning_rate": 0.00021628380471827558,
      "loss": 0.3461,
      "step": 148200
    },
    {
      "epoch": 6.0301502429503735,
      "grad_norm": 0.38755476474761963,
      "learning_rate": 0.00021606249723365645,
      "loss": 0.3475,
      "step": 148300
    },
    {
      "epoch": 6.0342163579807675,
      "grad_norm": 0.3244189918041229,
      "learning_rate": 0.00021584118974903732,
      "loss": 0.3462,
      "step": 148400
    },
    {
      "epoch": 6.0382824730111615,
      "grad_norm": 0.3486388623714447,
      "learning_rate": 0.0002156198822644182,
      "loss": 0.3449,
      "step": 148500
    },
    {
      "epoch": 6.0423485880415555,
      "grad_norm": 0.33706292510032654,
      "learning_rate": 0.00021539857477979903,
      "loss": 0.3465,
      "step": 148600
    },
    {
      "epoch": 6.0464147030719495,
      "grad_norm": 0.3089725077152252,
      "learning_rate": 0.00021517726729517993,
      "loss": 0.3471,
      "step": 148700
    },
    {
      "epoch": 6.050480818102344,
      "grad_norm": 0.35269463062286377,
      "learning_rate": 0.0002149559598105608,
      "loss": 0.345,
      "step": 148800
    },
    {
      "epoch": 6.054546933132738,
      "grad_norm": 0.29384326934814453,
      "learning_rate": 0.00021473465232594167,
      "loss": 0.3466,
      "step": 148900
    },
    {
      "epoch": 6.058613048163132,
      "grad_norm": 0.34196794033050537,
      "learning_rate": 0.00021451334484132254,
      "loss": 0.3481,
      "step": 149000
    },
    {
      "epoch": 6.062679163193526,
      "grad_norm": 0.3240191340446472,
      "learning_rate": 0.0002142920373567034,
      "loss": 0.3475,
      "step": 149100
    },
    {
      "epoch": 6.066745278223921,
      "grad_norm": 0.31915730237960815,
      "learning_rate": 0.00021407072987208428,
      "loss": 0.3472,
      "step": 149200
    },
    {
      "epoch": 6.070811393254315,
      "grad_norm": 0.2963625490665436,
      "learning_rate": 0.00021384942238746515,
      "loss": 0.3469,
      "step": 149300
    },
    {
      "epoch": 6.074877508284709,
      "grad_norm": 0.34742969274520874,
      "learning_rate": 0.00021362811490284602,
      "loss": 0.3498,
      "step": 149400
    },
    {
      "epoch": 6.078943623315103,
      "grad_norm": 0.32883572578430176,
      "learning_rate": 0.00021340680741822687,
      "loss": 0.3467,
      "step": 149500
    },
    {
      "epoch": 6.083009738345498,
      "grad_norm": 0.3794333040714264,
      "learning_rate": 0.00021318549993360776,
      "loss": 0.3451,
      "step": 149600
    },
    {
      "epoch": 6.087075853375892,
      "grad_norm": 0.30214235186576843,
      "learning_rate": 0.00021296419244898863,
      "loss": 0.3461,
      "step": 149700
    },
    {
      "epoch": 6.091141968406286,
      "grad_norm": 0.32861238718032837,
      "learning_rate": 0.0002127428849643695,
      "loss": 0.346,
      "step": 149800
    },
    {
      "epoch": 6.09520808343668,
      "grad_norm": 0.367269903421402,
      "learning_rate": 0.00021252157747975037,
      "loss": 0.3456,
      "step": 149900
    },
    {
      "epoch": 6.099274198467075,
      "grad_norm": 0.36057403683662415,
      "learning_rate": 0.00021230026999513124,
      "loss": 0.3479,
      "step": 150000
    },
    {
      "epoch": 6.099274198467075,
      "eval_loss": 0.3613682687282562,
      "eval_runtime": 113.5959,
      "eval_samples_per_second": 1539.685,
      "eval_steps_per_second": 48.118,
      "step": 150000
    },
    {
      "epoch": 6.103340313497469,
      "grad_norm": 0.31610459089279175,
      "learning_rate": 0.0002120789625105121,
      "loss": 0.3489,
      "step": 150100
    },
    {
      "epoch": 6.107406428527863,
      "grad_norm": 0.34851962327957153,
      "learning_rate": 0.00021185765502589298,
      "loss": 0.347,
      "step": 150200
    },
    {
      "epoch": 6.111472543558257,
      "grad_norm": 0.35955825448036194,
      "learning_rate": 0.00021163634754127383,
      "loss": 0.3473,
      "step": 150300
    },
    {
      "epoch": 6.115538658588651,
      "grad_norm": 0.33312955498695374,
      "learning_rate": 0.00021141504005665472,
      "loss": 0.3476,
      "step": 150400
    },
    {
      "epoch": 6.119604773619046,
      "grad_norm": 0.2990591824054718,
      "learning_rate": 0.0002111937325720356,
      "loss": 0.3449,
      "step": 150500
    },
    {
      "epoch": 6.12367088864944,
      "grad_norm": 0.29552292823791504,
      "learning_rate": 0.00021097242508741646,
      "loss": 0.347,
      "step": 150600
    },
    {
      "epoch": 6.127737003679834,
      "grad_norm": 0.3791888952255249,
      "learning_rate": 0.00021075111760279733,
      "loss": 0.3478,
      "step": 150700
    },
    {
      "epoch": 6.131803118710228,
      "grad_norm": 0.32020968198776245,
      "learning_rate": 0.0002105298101181782,
      "loss": 0.3454,
      "step": 150800
    },
    {
      "epoch": 6.135869233740623,
      "grad_norm": 0.31899574398994446,
      "learning_rate": 0.00021030850263355908,
      "loss": 0.3468,
      "step": 150900
    },
    {
      "epoch": 6.139935348771017,
      "grad_norm": 0.3224790096282959,
      "learning_rate": 0.00021008719514893995,
      "loss": 0.3459,
      "step": 151000
    },
    {
      "epoch": 6.144001463801411,
      "grad_norm": 0.3037399351596832,
      "learning_rate": 0.0002098658876643208,
      "loss": 0.3468,
      "step": 151100
    },
    {
      "epoch": 6.148067578831805,
      "grad_norm": 0.39149338006973267,
      "learning_rate": 0.00020964458017970166,
      "loss": 0.3455,
      "step": 151200
    },
    {
      "epoch": 6.1521336938622,
      "grad_norm": 0.3556250035762787,
      "learning_rate": 0.00020942327269508256,
      "loss": 0.3489,
      "step": 151300
    },
    {
      "epoch": 6.156199808892594,
      "grad_norm": 0.3199218809604645,
      "learning_rate": 0.00020920196521046343,
      "loss": 0.3487,
      "step": 151400
    },
    {
      "epoch": 6.160265923922988,
      "grad_norm": 0.31116074323654175,
      "learning_rate": 0.0002089806577258443,
      "loss": 0.3475,
      "step": 151500
    },
    {
      "epoch": 6.164332038953382,
      "grad_norm": 0.324081152677536,
      "learning_rate": 0.00020875935024122517,
      "loss": 0.3469,
      "step": 151600
    },
    {
      "epoch": 6.168398153983776,
      "grad_norm": 0.31518372893333435,
      "learning_rate": 0.00020853804275660604,
      "loss": 0.3463,
      "step": 151700
    },
    {
      "epoch": 6.172464269014171,
      "grad_norm": 0.31835484504699707,
      "learning_rate": 0.0002083167352719869,
      "loss": 0.3464,
      "step": 151800
    },
    {
      "epoch": 6.176530384044565,
      "grad_norm": 0.364100843667984,
      "learning_rate": 0.00020809542778736778,
      "loss": 0.3456,
      "step": 151900
    },
    {
      "epoch": 6.180596499074959,
      "grad_norm": 0.343336820602417,
      "learning_rate": 0.00020787412030274862,
      "loss": 0.3477,
      "step": 152000
    },
    {
      "epoch": 6.180596499074959,
      "eval_loss": 0.3602360486984253,
      "eval_runtime": 113.6705,
      "eval_samples_per_second": 1538.676,
      "eval_steps_per_second": 48.086,
      "step": 152000
    },
    {
      "epoch": 6.184662614105353,
      "grad_norm": 0.3055262267589569,
      "learning_rate": 0.00020765281281812952,
      "loss": 0.3491,
      "step": 152100
    },
    {
      "epoch": 6.188728729135748,
      "grad_norm": 0.3648899793624878,
      "learning_rate": 0.0002074315053335104,
      "loss": 0.3474,
      "step": 152200
    },
    {
      "epoch": 6.192794844166142,
      "grad_norm": 0.3336252272129059,
      "learning_rate": 0.00020721019784889126,
      "loss": 0.3469,
      "step": 152300
    },
    {
      "epoch": 6.196860959196536,
      "grad_norm": 0.3726203441619873,
      "learning_rate": 0.00020698889036427213,
      "loss": 0.3477,
      "step": 152400
    },
    {
      "epoch": 6.20092707422693,
      "grad_norm": 0.32303953170776367,
      "learning_rate": 0.000206767582879653,
      "loss": 0.3488,
      "step": 152500
    },
    {
      "epoch": 6.2049931892573245,
      "grad_norm": 0.31977441906929016,
      "learning_rate": 0.00020654627539503387,
      "loss": 0.3465,
      "step": 152600
    },
    {
      "epoch": 6.2090593042877185,
      "grad_norm": 0.34532567858695984,
      "learning_rate": 0.00020632496791041474,
      "loss": 0.3477,
      "step": 152700
    },
    {
      "epoch": 6.2131254193181125,
      "grad_norm": 0.343341201543808,
      "learning_rate": 0.00020610366042579558,
      "loss": 0.348,
      "step": 152800
    },
    {
      "epoch": 6.2171915343485065,
      "grad_norm": 0.3301019072532654,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.3475,
      "step": 152900
    },
    {
      "epoch": 6.221257649378901,
      "grad_norm": 0.38154780864715576,
      "learning_rate": 0.00020566104545655735,
      "loss": 0.348,
      "step": 153000
    },
    {
      "epoch": 6.225323764409295,
      "grad_norm": 0.3068700134754181,
      "learning_rate": 0.00020543973797193822,
      "loss": 0.3485,
      "step": 153100
    },
    {
      "epoch": 6.229389879439689,
      "grad_norm": 0.30659225583076477,
      "learning_rate": 0.0002052184304873191,
      "loss": 0.3461,
      "step": 153200
    },
    {
      "epoch": 6.233455994470083,
      "grad_norm": 0.305145263671875,
      "learning_rate": 0.00020499712300269996,
      "loss": 0.3451,
      "step": 153300
    },
    {
      "epoch": 6.237522109500477,
      "grad_norm": 0.34074077010154724,
      "learning_rate": 0.00020477581551808083,
      "loss": 0.3485,
      "step": 153400
    },
    {
      "epoch": 6.241588224530872,
      "grad_norm": 0.3412782847881317,
      "learning_rate": 0.0002045545080334617,
      "loss": 0.347,
      "step": 153500
    },
    {
      "epoch": 6.245654339561266,
      "grad_norm": 0.3462347686290741,
      "learning_rate": 0.00020433320054884257,
      "loss": 0.3483,
      "step": 153600
    },
    {
      "epoch": 6.24972045459166,
      "grad_norm": 0.3583519160747528,
      "learning_rate": 0.00020411189306422341,
      "loss": 0.3471,
      "step": 153700
    },
    {
      "epoch": 6.253786569622054,
      "grad_norm": 0.3386973738670349,
      "learning_rate": 0.0002038905855796043,
      "loss": 0.3486,
      "step": 153800
    },
    {
      "epoch": 6.257852684652449,
      "grad_norm": 0.3399618864059448,
      "learning_rate": 0.00020366927809498518,
      "loss": 0.3484,
      "step": 153900
    },
    {
      "epoch": 6.261918799682843,
      "grad_norm": 0.29606807231903076,
      "learning_rate": 0.00020344797061036605,
      "loss": 0.3468,
      "step": 154000
    },
    {
      "epoch": 6.261918799682843,
      "eval_loss": 0.3603365123271942,
      "eval_runtime": 113.6657,
      "eval_samples_per_second": 1538.74,
      "eval_steps_per_second": 48.088,
      "step": 154000
    },
    {
      "epoch": 6.265984914713237,
      "grad_norm": 0.3172640800476074,
      "learning_rate": 0.00020322666312574692,
      "loss": 0.3437,
      "step": 154100
    },
    {
      "epoch": 6.270051029743631,
      "grad_norm": 0.33801060914993286,
      "learning_rate": 0.0002030053556411278,
      "loss": 0.3462,
      "step": 154200
    },
    {
      "epoch": 6.274117144774026,
      "grad_norm": 0.33077067136764526,
      "learning_rate": 0.00020278404815650866,
      "loss": 0.347,
      "step": 154300
    },
    {
      "epoch": 6.27818325980442,
      "grad_norm": 0.32241058349609375,
      "learning_rate": 0.00020256274067188953,
      "loss": 0.3473,
      "step": 154400
    },
    {
      "epoch": 6.282249374834814,
      "grad_norm": 0.34030914306640625,
      "learning_rate": 0.00020234143318727038,
      "loss": 0.3465,
      "step": 154500
    },
    {
      "epoch": 6.286315489865208,
      "grad_norm": 0.35403943061828613,
      "learning_rate": 0.00020212012570265125,
      "loss": 0.347,
      "step": 154600
    },
    {
      "epoch": 6.290381604895602,
      "grad_norm": 0.3257502317428589,
      "learning_rate": 0.00020189881821803214,
      "loss": 0.348,
      "step": 154700
    },
    {
      "epoch": 6.294447719925997,
      "grad_norm": 0.3256388306617737,
      "learning_rate": 0.00020167751073341301,
      "loss": 0.3444,
      "step": 154800
    },
    {
      "epoch": 6.298513834956391,
      "grad_norm": 0.377200722694397,
      "learning_rate": 0.00020145620324879388,
      "loss": 0.3447,
      "step": 154900
    },
    {
      "epoch": 6.302579949986785,
      "grad_norm": 0.3701755702495575,
      "learning_rate": 0.00020123489576417475,
      "loss": 0.3476,
      "step": 155000
    },
    {
      "epoch": 6.306646065017179,
      "grad_norm": 0.31371957063674927,
      "learning_rate": 0.00020101358827955562,
      "loss": 0.3482,
      "step": 155100
    },
    {
      "epoch": 6.310712180047574,
      "grad_norm": 0.36126434803009033,
      "learning_rate": 0.0002007922807949365,
      "loss": 0.3478,
      "step": 155200
    },
    {
      "epoch": 6.314778295077968,
      "grad_norm": 0.32176539301872253,
      "learning_rate": 0.00020057097331031736,
      "loss": 0.3472,
      "step": 155300
    },
    {
      "epoch": 6.318844410108362,
      "grad_norm": 0.3495958745479584,
      "learning_rate": 0.0002003496658256982,
      "loss": 0.3489,
      "step": 155400
    },
    {
      "epoch": 6.322910525138756,
      "grad_norm": 0.2873014211654663,
      "learning_rate": 0.0002001283583410791,
      "loss": 0.348,
      "step": 155500
    },
    {
      "epoch": 6.326976640169151,
      "grad_norm": 0.2897264361381531,
      "learning_rate": 0.00019990705085645998,
      "loss": 0.3483,
      "step": 155600
    },
    {
      "epoch": 6.331042755199545,
      "grad_norm": 0.34929925203323364,
      "learning_rate": 0.00019968574337184085,
      "loss": 0.3454,
      "step": 155700
    },
    {
      "epoch": 6.335108870229939,
      "grad_norm": 0.3021230399608612,
      "learning_rate": 0.00019946443588722172,
      "loss": 0.3475,
      "step": 155800
    },
    {
      "epoch": 6.339174985260333,
      "grad_norm": 0.3095329701900482,
      "learning_rate": 0.00019924312840260259,
      "loss": 0.346,
      "step": 155900
    },
    {
      "epoch": 6.343241100290728,
      "grad_norm": 0.30551737546920776,
      "learning_rate": 0.00019902182091798346,
      "loss": 0.346,
      "step": 156000
    },
    {
      "epoch": 6.343241100290728,
      "eval_loss": 0.3597036302089691,
      "eval_runtime": 114.1606,
      "eval_samples_per_second": 1532.07,
      "eval_steps_per_second": 47.88,
      "step": 156000
    },
    {
      "epoch": 6.347307215321122,
      "grad_norm": 0.3633415102958679,
      "learning_rate": 0.00019880051343336433,
      "loss": 0.3469,
      "step": 156100
    },
    {
      "epoch": 6.351373330351516,
      "grad_norm": 0.3642215132713318,
      "learning_rate": 0.00019857920594874517,
      "loss": 0.347,
      "step": 156200
    },
    {
      "epoch": 6.35543944538191,
      "grad_norm": 0.3868046998977661,
      "learning_rate": 0.00019835789846412604,
      "loss": 0.3451,
      "step": 156300
    },
    {
      "epoch": 6.359505560412304,
      "grad_norm": 0.3494359254837036,
      "learning_rate": 0.00019813659097950694,
      "loss": 0.347,
      "step": 156400
    },
    {
      "epoch": 6.3635716754426985,
      "grad_norm": 0.31757688522338867,
      "learning_rate": 0.0001979152834948878,
      "loss": 0.348,
      "step": 156500
    },
    {
      "epoch": 6.3676377904730925,
      "grad_norm": 0.30101802945137024,
      "learning_rate": 0.00019769397601026868,
      "loss": 0.3463,
      "step": 156600
    },
    {
      "epoch": 6.3717039055034865,
      "grad_norm": 0.33802729845046997,
      "learning_rate": 0.00019747266852564955,
      "loss": 0.3476,
      "step": 156700
    },
    {
      "epoch": 6.3757700205338805,
      "grad_norm": 0.3425021767616272,
      "learning_rate": 0.00019725136104103042,
      "loss": 0.3479,
      "step": 156800
    },
    {
      "epoch": 6.379836135564275,
      "grad_norm": 0.3081623315811157,
      "learning_rate": 0.0001970300535564113,
      "loss": 0.3471,
      "step": 156900
    },
    {
      "epoch": 6.383902250594669,
      "grad_norm": 0.3249785006046295,
      "learning_rate": 0.00019680874607179213,
      "loss": 0.3449,
      "step": 157000
    },
    {
      "epoch": 6.387968365625063,
      "grad_norm": 0.35365936160087585,
      "learning_rate": 0.000196587438587173,
      "loss": 0.3476,
      "step": 157100
    },
    {
      "epoch": 6.392034480655457,
      "grad_norm": 0.3161327540874481,
      "learning_rate": 0.00019636613110255387,
      "loss": 0.3443,
      "step": 157200
    },
    {
      "epoch": 6.396100595685852,
      "grad_norm": 0.31863537430763245,
      "learning_rate": 0.00019614482361793477,
      "loss": 0.3465,
      "step": 157300
    },
    {
      "epoch": 6.400166710716246,
      "grad_norm": 0.2803141176700592,
      "learning_rate": 0.00019592351613331564,
      "loss": 0.347,
      "step": 157400
    },
    {
      "epoch": 6.40423282574664,
      "grad_norm": 0.333375483751297,
      "learning_rate": 0.0001957022086486965,
      "loss": 0.3482,
      "step": 157500
    },
    {
      "epoch": 6.408298940777034,
      "grad_norm": 0.3598981201648712,
      "learning_rate": 0.00019548090116407738,
      "loss": 0.3462,
      "step": 157600
    },
    {
      "epoch": 6.412365055807429,
      "grad_norm": 0.2889775037765503,
      "learning_rate": 0.00019525959367945825,
      "loss": 0.3461,
      "step": 157700
    },
    {
      "epoch": 6.416431170837823,
      "grad_norm": 0.3328687846660614,
      "learning_rate": 0.00019503828619483912,
      "loss": 0.3491,
      "step": 157800
    },
    {
      "epoch": 6.420497285868217,
      "grad_norm": 0.34583139419555664,
      "learning_rate": 0.00019481697871021996,
      "loss": 0.3463,
      "step": 157900
    },
    {
      "epoch": 6.424563400898611,
      "grad_norm": 0.3464168310165405,
      "learning_rate": 0.00019459567122560083,
      "loss": 0.3462,
      "step": 158000
    },
    {
      "epoch": 6.424563400898611,
      "eval_loss": 0.359407514333725,
      "eval_runtime": 113.7344,
      "eval_samples_per_second": 1537.811,
      "eval_steps_per_second": 48.059,
      "step": 158000
    },
    {
      "epoch": 6.428629515929005,
      "grad_norm": 0.37099337577819824,
      "learning_rate": 0.00019437436374098173,
      "loss": 0.3494,
      "step": 158100
    },
    {
      "epoch": 6.4326956309594,
      "grad_norm": 0.32502493262290955,
      "learning_rate": 0.0001941530562563626,
      "loss": 0.347,
      "step": 158200
    },
    {
      "epoch": 6.436761745989794,
      "grad_norm": 0.3438078761100769,
      "learning_rate": 0.00019393174877174347,
      "loss": 0.3468,
      "step": 158300
    },
    {
      "epoch": 6.440827861020188,
      "grad_norm": 0.34245631098747253,
      "learning_rate": 0.00019371044128712434,
      "loss": 0.3488,
      "step": 158400
    },
    {
      "epoch": 6.444893976050582,
      "grad_norm": 0.33713996410369873,
      "learning_rate": 0.0001934891338025052,
      "loss": 0.3467,
      "step": 158500
    },
    {
      "epoch": 6.448960091080977,
      "grad_norm": 0.32232239842414856,
      "learning_rate": 0.00019326782631788608,
      "loss": 0.3467,
      "step": 158600
    },
    {
      "epoch": 6.453026206111371,
      "grad_norm": 0.3650343120098114,
      "learning_rate": 0.00019304651883326693,
      "loss": 0.3457,
      "step": 158700
    },
    {
      "epoch": 6.457092321141765,
      "grad_norm": 0.3699491024017334,
      "learning_rate": 0.0001928252113486478,
      "loss": 0.3482,
      "step": 158800
    },
    {
      "epoch": 6.461158436172159,
      "grad_norm": 0.2973133623600006,
      "learning_rate": 0.00019260390386402867,
      "loss": 0.3452,
      "step": 158900
    },
    {
      "epoch": 6.465224551202554,
      "grad_norm": 0.35352823138237,
      "learning_rate": 0.00019238259637940956,
      "loss": 0.3464,
      "step": 159000
    },
    {
      "epoch": 6.469290666232948,
      "grad_norm": 0.3593660593032837,
      "learning_rate": 0.00019216128889479043,
      "loss": 0.3492,
      "step": 159100
    },
    {
      "epoch": 6.473356781263342,
      "grad_norm": 0.34818798303604126,
      "learning_rate": 0.0001919399814101713,
      "loss": 0.3466,
      "step": 159200
    },
    {
      "epoch": 6.477422896293736,
      "grad_norm": 0.3376648724079132,
      "learning_rate": 0.00019171867392555217,
      "loss": 0.3477,
      "step": 159300
    },
    {
      "epoch": 6.481489011324131,
      "grad_norm": 0.3743976950645447,
      "learning_rate": 0.00019149736644093304,
      "loss": 0.3446,
      "step": 159400
    },
    {
      "epoch": 6.485555126354525,
      "grad_norm": 0.3848102390766144,
      "learning_rate": 0.00019127605895631391,
      "loss": 0.3476,
      "step": 159500
    },
    {
      "epoch": 6.489621241384919,
      "grad_norm": 0.2948320209980011,
      "learning_rate": 0.00019105475147169476,
      "loss": 0.3484,
      "step": 159600
    },
    {
      "epoch": 6.493687356415313,
      "grad_norm": 0.30939745903015137,
      "learning_rate": 0.00019083344398707563,
      "loss": 0.3481,
      "step": 159700
    },
    {
      "epoch": 6.497753471445707,
      "grad_norm": 0.453080415725708,
      "learning_rate": 0.00019061213650245652,
      "loss": 0.3439,
      "step": 159800
    },
    {
      "epoch": 6.501819586476102,
      "grad_norm": 0.30890122056007385,
      "learning_rate": 0.0001903908290178374,
      "loss": 0.3466,
      "step": 159900
    },
    {
      "epoch": 6.505885701506496,
      "grad_norm": 0.3224636912345886,
      "learning_rate": 0.00019016952153321827,
      "loss": 0.3483,
      "step": 160000
    },
    {
      "epoch": 6.505885701506496,
      "eval_loss": 0.358492910861969,
      "eval_runtime": 113.6078,
      "eval_samples_per_second": 1539.525,
      "eval_steps_per_second": 48.113,
      "step": 160000
    },
    {
      "epoch": 6.50995181653689,
      "grad_norm": 0.34503182768821716,
      "learning_rate": 0.00018994821404859914,
      "loss": 0.3479,
      "step": 160100
    },
    {
      "epoch": 6.514017931567284,
      "grad_norm": 0.3298255503177643,
      "learning_rate": 0.00018972690656398,
      "loss": 0.3462,
      "step": 160200
    },
    {
      "epoch": 6.518084046597679,
      "grad_norm": 0.3847154676914215,
      "learning_rate": 0.00018950559907936088,
      "loss": 0.3469,
      "step": 160300
    },
    {
      "epoch": 6.522150161628073,
      "grad_norm": 0.3110109269618988,
      "learning_rate": 0.00018928429159474172,
      "loss": 0.3467,
      "step": 160400
    },
    {
      "epoch": 6.526216276658467,
      "grad_norm": 0.35010308027267456,
      "learning_rate": 0.0001890629841101226,
      "loss": 0.3461,
      "step": 160500
    },
    {
      "epoch": 6.530282391688861,
      "grad_norm": 0.3546449542045593,
      "learning_rate": 0.00018884167662550346,
      "loss": 0.3479,
      "step": 160600
    },
    {
      "epoch": 6.534348506719255,
      "grad_norm": 0.38751932978630066,
      "learning_rate": 0.00018862036914088436,
      "loss": 0.3455,
      "step": 160700
    },
    {
      "epoch": 6.5384146217496495,
      "grad_norm": 0.3599039912223816,
      "learning_rate": 0.00018839906165626523,
      "loss": 0.3494,
      "step": 160800
    },
    {
      "epoch": 6.5424807367800435,
      "grad_norm": 0.4221345782279968,
      "learning_rate": 0.0001881777541716461,
      "loss": 0.346,
      "step": 160900
    },
    {
      "epoch": 6.5465468518104375,
      "grad_norm": 0.35920825600624084,
      "learning_rate": 0.00018795644668702697,
      "loss": 0.3462,
      "step": 161000
    },
    {
      "epoch": 6.550612966840832,
      "grad_norm": 0.31380361318588257,
      "learning_rate": 0.00018773513920240784,
      "loss": 0.3462,
      "step": 161100
    },
    {
      "epoch": 6.554679081871226,
      "grad_norm": 0.30022722482681274,
      "learning_rate": 0.0001875138317177887,
      "loss": 0.3446,
      "step": 161200
    },
    {
      "epoch": 6.55874519690162,
      "grad_norm": 0.31585636734962463,
      "learning_rate": 0.00018729252423316955,
      "loss": 0.3478,
      "step": 161300
    },
    {
      "epoch": 6.562811311932014,
      "grad_norm": 0.32074281573295593,
      "learning_rate": 0.00018707121674855042,
      "loss": 0.3464,
      "step": 161400
    },
    {
      "epoch": 6.566877426962408,
      "grad_norm": 0.36609962582588196,
      "learning_rate": 0.00018684990926393132,
      "loss": 0.3461,
      "step": 161500
    },
    {
      "epoch": 6.570943541992803,
      "grad_norm": 0.32333114743232727,
      "learning_rate": 0.0001866286017793122,
      "loss": 0.3468,
      "step": 161600
    },
    {
      "epoch": 6.575009657023197,
      "grad_norm": 0.3281107544898987,
      "learning_rate": 0.00018640729429469306,
      "loss": 0.3464,
      "step": 161700
    },
    {
      "epoch": 6.579075772053591,
      "grad_norm": 0.3099961578845978,
      "learning_rate": 0.00018618598681007393,
      "loss": 0.3473,
      "step": 161800
    },
    {
      "epoch": 6.583141887083985,
      "grad_norm": 0.36928364634513855,
      "learning_rate": 0.0001859646793254548,
      "loss": 0.3476,
      "step": 161900
    },
    {
      "epoch": 6.58720800211438,
      "grad_norm": 0.2870802879333496,
      "learning_rate": 0.00018574337184083567,
      "loss": 0.3472,
      "step": 162000
    },
    {
      "epoch": 6.58720800211438,
      "eval_loss": 0.35815757513046265,
      "eval_runtime": 113.5153,
      "eval_samples_per_second": 1540.78,
      "eval_steps_per_second": 48.152,
      "step": 162000
    },
    {
      "epoch": 6.591274117144774,
      "grad_norm": 0.3839239180088043,
      "learning_rate": 0.0001855220643562165,
      "loss": 0.3467,
      "step": 162100
    },
    {
      "epoch": 6.595340232175168,
      "grad_norm": 0.34975913166999817,
      "learning_rate": 0.00018530075687159738,
      "loss": 0.3471,
      "step": 162200
    },
    {
      "epoch": 6.599406347205562,
      "grad_norm": 0.33200082182884216,
      "learning_rate": 0.00018507944938697825,
      "loss": 0.3455,
      "step": 162300
    },
    {
      "epoch": 6.603472462235956,
      "grad_norm": 0.34010207653045654,
      "learning_rate": 0.00018485814190235915,
      "loss": 0.3463,
      "step": 162400
    },
    {
      "epoch": 6.607538577266351,
      "grad_norm": 0.3522595167160034,
      "learning_rate": 0.00018463683441774002,
      "loss": 0.3442,
      "step": 162500
    },
    {
      "epoch": 6.611604692296745,
      "grad_norm": 0.3192879557609558,
      "learning_rate": 0.0001844155269331209,
      "loss": 0.3486,
      "step": 162600
    },
    {
      "epoch": 6.615670807327139,
      "grad_norm": 0.32353517413139343,
      "learning_rate": 0.00018419421944850176,
      "loss": 0.343,
      "step": 162700
    },
    {
      "epoch": 6.619736922357534,
      "grad_norm": 0.37103304266929626,
      "learning_rate": 0.00018397291196388263,
      "loss": 0.3477,
      "step": 162800
    },
    {
      "epoch": 6.623803037387928,
      "grad_norm": 0.3946087956428528,
      "learning_rate": 0.00018375160447926347,
      "loss": 0.3493,
      "step": 162900
    },
    {
      "epoch": 6.627869152418322,
      "grad_norm": 0.3158467411994934,
      "learning_rate": 0.00018353029699464434,
      "loss": 0.3456,
      "step": 163000
    },
    {
      "epoch": 6.631935267448716,
      "grad_norm": 0.3252919316291809,
      "learning_rate": 0.00018330898951002522,
      "loss": 0.3464,
      "step": 163100
    },
    {
      "epoch": 6.63600138247911,
      "grad_norm": 0.3259567320346832,
      "learning_rate": 0.0001830876820254061,
      "loss": 0.3464,
      "step": 163200
    },
    {
      "epoch": 6.640067497509505,
      "grad_norm": 0.3809758126735687,
      "learning_rate": 0.00018286637454078698,
      "loss": 0.3449,
      "step": 163300
    },
    {
      "epoch": 6.644133612539899,
      "grad_norm": 0.34954243898391724,
      "learning_rate": 0.00018264506705616785,
      "loss": 0.345,
      "step": 163400
    },
    {
      "epoch": 6.648199727570293,
      "grad_norm": 0.34529411792755127,
      "learning_rate": 0.00018242375957154872,
      "loss": 0.3467,
      "step": 163500
    },
    {
      "epoch": 6.652265842600687,
      "grad_norm": 0.35837307572364807,
      "learning_rate": 0.0001822024520869296,
      "loss": 0.3472,
      "step": 163600
    },
    {
      "epoch": 6.656331957631082,
      "grad_norm": 0.37582284212112427,
      "learning_rate": 0.00018198114460231046,
      "loss": 0.3463,
      "step": 163700
    },
    {
      "epoch": 6.660398072661476,
      "grad_norm": 0.31324177980422974,
      "learning_rate": 0.0001817598371176913,
      "loss": 0.3448,
      "step": 163800
    },
    {
      "epoch": 6.66446418769187,
      "grad_norm": 0.3795190751552582,
      "learning_rate": 0.00018153852963307218,
      "loss": 0.3464,
      "step": 163900
    },
    {
      "epoch": 6.668530302722264,
      "grad_norm": 0.4141450524330139,
      "learning_rate": 0.00018131722214845305,
      "loss": 0.3451,
      "step": 164000
    },
    {
      "epoch": 6.668530302722264,
      "eval_loss": 0.35791251063346863,
      "eval_runtime": 113.9899,
      "eval_samples_per_second": 1534.365,
      "eval_steps_per_second": 47.952,
      "step": 164000
    },
    {
      "epoch": 6.672596417752658,
      "grad_norm": 0.32356399297714233,
      "learning_rate": 0.00018109591466383394,
      "loss": 0.3475,
      "step": 164100
    },
    {
      "epoch": 6.676662532783053,
      "grad_norm": 0.31302276253700256,
      "learning_rate": 0.00018087460717921481,
      "loss": 0.3464,
      "step": 164200
    },
    {
      "epoch": 6.680728647813447,
      "grad_norm": 0.33957982063293457,
      "learning_rate": 0.00018065329969459568,
      "loss": 0.3477,
      "step": 164300
    },
    {
      "epoch": 6.684794762843841,
      "grad_norm": 0.36321550607681274,
      "learning_rate": 0.00018043199220997656,
      "loss": 0.3465,
      "step": 164400
    },
    {
      "epoch": 6.6888608778742356,
      "grad_norm": 0.3992597460746765,
      "learning_rate": 0.00018021068472535743,
      "loss": 0.3449,
      "step": 164500
    },
    {
      "epoch": 6.69292699290463,
      "grad_norm": 0.3232088088989258,
      "learning_rate": 0.00017998937724073827,
      "loss": 0.3483,
      "step": 164600
    },
    {
      "epoch": 6.696993107935024,
      "grad_norm": 0.37262827157974243,
      "learning_rate": 0.00017976806975611914,
      "loss": 0.3467,
      "step": 164700
    },
    {
      "epoch": 6.701059222965418,
      "grad_norm": 0.342072993516922,
      "learning_rate": 0.0001795467622715,
      "loss": 0.3468,
      "step": 164800
    },
    {
      "epoch": 6.705125337995812,
      "grad_norm": 0.4003768265247345,
      "learning_rate": 0.0001793254547868809,
      "loss": 0.3448,
      "step": 164900
    },
    {
      "epoch": 6.7091914530262065,
      "grad_norm": 0.3659486472606659,
      "learning_rate": 0.00017910414730226178,
      "loss": 0.3463,
      "step": 165000
    },
    {
      "epoch": 6.7132575680566005,
      "grad_norm": 0.3430371582508087,
      "learning_rate": 0.00017888283981764265,
      "loss": 0.3456,
      "step": 165100
    },
    {
      "epoch": 6.7173236830869945,
      "grad_norm": 0.4597843885421753,
      "learning_rate": 0.00017866153233302352,
      "loss": 0.3477,
      "step": 165200
    },
    {
      "epoch": 6.7213897981173885,
      "grad_norm": 0.3453525900840759,
      "learning_rate": 0.0001784402248484044,
      "loss": 0.3444,
      "step": 165300
    },
    {
      "epoch": 6.725455913147783,
      "grad_norm": 0.435634583234787,
      "learning_rate": 0.00017821891736378526,
      "loss": 0.3475,
      "step": 165400
    },
    {
      "epoch": 6.729522028178177,
      "grad_norm": 0.31593599915504456,
      "learning_rate": 0.0001779976098791661,
      "loss": 0.3464,
      "step": 165500
    },
    {
      "epoch": 6.733588143208571,
      "grad_norm": 0.3679751455783844,
      "learning_rate": 0.00017777630239454697,
      "loss": 0.3459,
      "step": 165600
    },
    {
      "epoch": 6.737654258238965,
      "grad_norm": 0.3711942732334137,
      "learning_rate": 0.00017755499490992784,
      "loss": 0.3443,
      "step": 165700
    },
    {
      "epoch": 6.741720373269359,
      "grad_norm": 0.35359445214271545,
      "learning_rate": 0.00017733368742530874,
      "loss": 0.345,
      "step": 165800
    },
    {
      "epoch": 6.745786488299754,
      "grad_norm": 0.3594095706939697,
      "learning_rate": 0.0001771123799406896,
      "loss": 0.3452,
      "step": 165900
    },
    {
      "epoch": 6.749852603330148,
      "grad_norm": 0.3381999731063843,
      "learning_rate": 0.00017689107245607048,
      "loss": 0.3453,
      "step": 166000
    },
    {
      "epoch": 6.749852603330148,
      "eval_loss": 0.3574453294277191,
      "eval_runtime": 114.2133,
      "eval_samples_per_second": 1531.363,
      "eval_steps_per_second": 47.858,
      "step": 166000
    },
    {
      "epoch": 6.753918718360542,
      "grad_norm": 0.34745121002197266,
      "learning_rate": 0.00017666976497145135,
      "loss": 0.3469,
      "step": 166100
    },
    {
      "epoch": 6.757984833390936,
      "grad_norm": 0.32619890570640564,
      "learning_rate": 0.00017644845748683222,
      "loss": 0.3459,
      "step": 166200
    },
    {
      "epoch": 6.762050948421331,
      "grad_norm": 0.3292045295238495,
      "learning_rate": 0.00017622715000221306,
      "loss": 0.347,
      "step": 166300
    },
    {
      "epoch": 6.766117063451725,
      "grad_norm": 0.3707817494869232,
      "learning_rate": 0.00017600584251759393,
      "loss": 0.3464,
      "step": 166400
    },
    {
      "epoch": 6.770183178482119,
      "grad_norm": 0.35101544857025146,
      "learning_rate": 0.0001757845350329748,
      "loss": 0.3463,
      "step": 166500
    },
    {
      "epoch": 6.774249293512513,
      "grad_norm": 0.34058740735054016,
      "learning_rate": 0.00017556322754835567,
      "loss": 0.3467,
      "step": 166600
    },
    {
      "epoch": 6.778315408542908,
      "grad_norm": 0.3645447790622711,
      "learning_rate": 0.00017534192006373657,
      "loss": 0.3468,
      "step": 166700
    },
    {
      "epoch": 6.782381523573302,
      "grad_norm": 0.3248041272163391,
      "learning_rate": 0.00017512061257911744,
      "loss": 0.3469,
      "step": 166800
    },
    {
      "epoch": 6.786447638603696,
      "grad_norm": 0.31727635860443115,
      "learning_rate": 0.0001748993050944983,
      "loss": 0.347,
      "step": 166900
    },
    {
      "epoch": 6.79051375363409,
      "grad_norm": 0.31467607617378235,
      "learning_rate": 0.00017467799760987918,
      "loss": 0.3428,
      "step": 167000
    },
    {
      "epoch": 6.794579868664485,
      "grad_norm": 0.328641414642334,
      "learning_rate": 0.00017445669012526005,
      "loss": 0.3454,
      "step": 167100
    },
    {
      "epoch": 6.798645983694879,
      "grad_norm": 0.3282223045825958,
      "learning_rate": 0.0001742353826406409,
      "loss": 0.345,
      "step": 167200
    },
    {
      "epoch": 6.802712098725273,
      "grad_norm": 0.3814666271209717,
      "learning_rate": 0.00017401407515602176,
      "loss": 0.3439,
      "step": 167300
    },
    {
      "epoch": 6.806778213755667,
      "grad_norm": 0.33226266503334045,
      "learning_rate": 0.00017379276767140263,
      "loss": 0.3463,
      "step": 167400
    },
    {
      "epoch": 6.810844328786061,
      "grad_norm": 0.33759358525276184,
      "learning_rate": 0.00017357146018678353,
      "loss": 0.3454,
      "step": 167500
    },
    {
      "epoch": 6.814910443816456,
      "grad_norm": 0.37770652770996094,
      "learning_rate": 0.0001733501527021644,
      "loss": 0.3451,
      "step": 167600
    },
    {
      "epoch": 6.81897655884685,
      "grad_norm": 0.3655847907066345,
      "learning_rate": 0.00017312884521754527,
      "loss": 0.3482,
      "step": 167700
    },
    {
      "epoch": 6.823042673877244,
      "grad_norm": 0.35593709349632263,
      "learning_rate": 0.00017290753773292614,
      "loss": 0.346,
      "step": 167800
    },
    {
      "epoch": 6.827108788907638,
      "grad_norm": 0.3672143220901489,
      "learning_rate": 0.000172686230248307,
      "loss": 0.345,
      "step": 167900
    },
    {
      "epoch": 6.831174903938033,
      "grad_norm": 0.3588738739490509,
      "learning_rate": 0.00017246492276368786,
      "loss": 0.346,
      "step": 168000
    },
    {
      "epoch": 6.831174903938033,
      "eval_loss": 0.35689499974250793,
      "eval_runtime": 113.7081,
      "eval_samples_per_second": 1538.166,
      "eval_steps_per_second": 48.07,
      "step": 168000
    },
    {
      "epoch": 6.835241018968427,
      "grad_norm": 0.31316375732421875,
      "learning_rate": 0.00017224361527906873,
      "loss": 0.3469,
      "step": 168100
    },
    {
      "epoch": 6.839307133998821,
      "grad_norm": 0.34371453523635864,
      "learning_rate": 0.0001720223077944496,
      "loss": 0.3473,
      "step": 168200
    },
    {
      "epoch": 6.843373249029215,
      "grad_norm": 0.37286248803138733,
      "learning_rate": 0.00017180100030983047,
      "loss": 0.3443,
      "step": 168300
    },
    {
      "epoch": 6.84743936405961,
      "grad_norm": 0.3948984146118164,
      "learning_rate": 0.00017157969282521136,
      "loss": 0.3453,
      "step": 168400
    },
    {
      "epoch": 6.851505479090004,
      "grad_norm": 0.3369975984096527,
      "learning_rate": 0.00017135838534059223,
      "loss": 0.3454,
      "step": 168500
    },
    {
      "epoch": 6.855571594120398,
      "grad_norm": 0.353772908449173,
      "learning_rate": 0.0001711370778559731,
      "loss": 0.3455,
      "step": 168600
    },
    {
      "epoch": 6.859637709150792,
      "grad_norm": 0.3175913095474243,
      "learning_rate": 0.00017091577037135397,
      "loss": 0.3457,
      "step": 168700
    },
    {
      "epoch": 6.8637038241811865,
      "grad_norm": 0.35150790214538574,
      "learning_rate": 0.00017069446288673482,
      "loss": 0.3439,
      "step": 168800
    },
    {
      "epoch": 6.8677699392115805,
      "grad_norm": 0.3103400766849518,
      "learning_rate": 0.0001704731554021157,
      "loss": 0.3458,
      "step": 168900
    },
    {
      "epoch": 6.8718360542419745,
      "grad_norm": 0.3325151801109314,
      "learning_rate": 0.00017025184791749656,
      "loss": 0.345,
      "step": 169000
    },
    {
      "epoch": 6.8759021692723685,
      "grad_norm": 0.3739124536514282,
      "learning_rate": 0.00017003054043287743,
      "loss": 0.3479,
      "step": 169100
    },
    {
      "epoch": 6.8799682843027625,
      "grad_norm": 0.3368436396121979,
      "learning_rate": 0.00016980923294825833,
      "loss": 0.3442,
      "step": 169200
    },
    {
      "epoch": 6.884034399333157,
      "grad_norm": 0.3507189154624939,
      "learning_rate": 0.0001695879254636392,
      "loss": 0.3463,
      "step": 169300
    },
    {
      "epoch": 6.888100514363551,
      "grad_norm": 0.30569857358932495,
      "learning_rate": 0.00016936661797902007,
      "loss": 0.346,
      "step": 169400
    },
    {
      "epoch": 6.892166629393945,
      "grad_norm": 0.3411688804626465,
      "learning_rate": 0.00016914531049440094,
      "loss": 0.3435,
      "step": 169500
    },
    {
      "epoch": 6.896232744424339,
      "grad_norm": 0.3238009810447693,
      "learning_rate": 0.0001689240030097818,
      "loss": 0.3478,
      "step": 169600
    },
    {
      "epoch": 6.900298859454734,
      "grad_norm": 0.3265722990036011,
      "learning_rate": 0.00016870269552516265,
      "loss": 0.3459,
      "step": 169700
    },
    {
      "epoch": 6.904364974485128,
      "grad_norm": 0.3183280825614929,
      "learning_rate": 0.00016848138804054352,
      "loss": 0.3448,
      "step": 169800
    },
    {
      "epoch": 6.908431089515522,
      "grad_norm": 0.3815837502479553,
      "learning_rate": 0.0001682600805559244,
      "loss": 0.3454,
      "step": 169900
    },
    {
      "epoch": 6.912497204545916,
      "grad_norm": 0.3603766858577728,
      "learning_rate": 0.00016803877307130526,
      "loss": 0.3474,
      "step": 170000
    },
    {
      "epoch": 6.912497204545916,
      "eval_loss": 0.3567661643028259,
      "eval_runtime": 113.9921,
      "eval_samples_per_second": 1534.335,
      "eval_steps_per_second": 47.951,
      "step": 170000
    },
    {
      "epoch": 6.91656331957631,
      "grad_norm": 0.3287934958934784,
      "learning_rate": 0.00016781746558668616,
      "loss": 0.3467,
      "step": 170100
    },
    {
      "epoch": 6.920629434606705,
      "grad_norm": 0.36777517199516296,
      "learning_rate": 0.00016759615810206703,
      "loss": 0.346,
      "step": 170200
    },
    {
      "epoch": 6.924695549637099,
      "grad_norm": 0.3695332407951355,
      "learning_rate": 0.0001673748506174479,
      "loss": 0.3458,
      "step": 170300
    },
    {
      "epoch": 6.928761664667493,
      "grad_norm": 0.3327680230140686,
      "learning_rate": 0.00016715354313282877,
      "loss": 0.3473,
      "step": 170400
    },
    {
      "epoch": 6.932827779697888,
      "grad_norm": 0.33352112770080566,
      "learning_rate": 0.0001669322356482096,
      "loss": 0.3439,
      "step": 170500
    },
    {
      "epoch": 6.936893894728282,
      "grad_norm": 0.32450082898139954,
      "learning_rate": 0.00016671092816359048,
      "loss": 0.3452,
      "step": 170600
    },
    {
      "epoch": 6.940960009758676,
      "grad_norm": 0.3365597426891327,
      "learning_rate": 0.00016648962067897135,
      "loss": 0.3454,
      "step": 170700
    },
    {
      "epoch": 6.94502612478907,
      "grad_norm": 0.3773866891860962,
      "learning_rate": 0.00016626831319435222,
      "loss": 0.3434,
      "step": 170800
    },
    {
      "epoch": 6.949092239819464,
      "grad_norm": 0.33795538544654846,
      "learning_rate": 0.00016604700570973312,
      "loss": 0.3465,
      "step": 170900
    },
    {
      "epoch": 6.953158354849859,
      "grad_norm": 0.3964235484600067,
      "learning_rate": 0.000165825698225114,
      "loss": 0.3436,
      "step": 171000
    },
    {
      "epoch": 6.957224469880253,
      "grad_norm": 0.34601396322250366,
      "learning_rate": 0.00016560439074049486,
      "loss": 0.3452,
      "step": 171100
    },
    {
      "epoch": 6.961290584910647,
      "grad_norm": 0.3738211393356323,
      "learning_rate": 0.00016538308325587573,
      "loss": 0.3432,
      "step": 171200
    },
    {
      "epoch": 6.965356699941041,
      "grad_norm": 0.35893189907073975,
      "learning_rate": 0.0001651617757712566,
      "loss": 0.3453,
      "step": 171300
    },
    {
      "epoch": 6.969422814971436,
      "grad_norm": 0.3466692864894867,
      "learning_rate": 0.00016494046828663744,
      "loss": 0.3457,
      "step": 171400
    },
    {
      "epoch": 6.97348893000183,
      "grad_norm": 0.3253740966320038,
      "learning_rate": 0.00016471916080201831,
      "loss": 0.3475,
      "step": 171500
    },
    {
      "epoch": 6.977555045032224,
      "grad_norm": 0.34294164180755615,
      "learning_rate": 0.00016449785331739918,
      "loss": 0.3454,
      "step": 171600
    },
    {
      "epoch": 6.981621160062618,
      "grad_norm": 0.3510618805885315,
      "learning_rate": 0.00016427654583278005,
      "loss": 0.3452,
      "step": 171700
    },
    {
      "epoch": 6.985687275093012,
      "grad_norm": 0.40700623393058777,
      "learning_rate": 0.00016405523834816095,
      "loss": 0.3459,
      "step": 171800
    },
    {
      "epoch": 6.989753390123407,
      "grad_norm": 0.348921000957489,
      "learning_rate": 0.00016383393086354182,
      "loss": 0.3457,
      "step": 171900
    },
    {
      "epoch": 6.993819505153801,
      "grad_norm": 0.39158836007118225,
      "learning_rate": 0.0001636126233789227,
      "loss": 0.3458,
      "step": 172000
    },
    {
      "epoch": 6.993819505153801,
      "eval_loss": 0.35662195086479187,
      "eval_runtime": 113.5036,
      "eval_samples_per_second": 1540.938,
      "eval_steps_per_second": 48.157,
      "step": 172000
    },
    {
      "epoch": 6.997885620184195,
      "grad_norm": 0.3360098600387573,
      "learning_rate": 0.00016339131589430356,
      "loss": 0.3447,
      "step": 172100
    },
    {
      "epoch": 7.001951735214589,
      "grad_norm": 0.3390447497367859,
      "learning_rate": 0.0001631700084096844,
      "loss": 0.3436,
      "step": 172200
    },
    {
      "epoch": 7.006017850244984,
      "grad_norm": 0.38567304611206055,
      "learning_rate": 0.00016294870092506528,
      "loss": 0.3407,
      "step": 172300
    },
    {
      "epoch": 7.010083965275378,
      "grad_norm": 0.36632946133613586,
      "learning_rate": 0.00016272739344044615,
      "loss": 0.3396,
      "step": 172400
    },
    {
      "epoch": 7.014150080305772,
      "grad_norm": 0.3681555688381195,
      "learning_rate": 0.00016250608595582702,
      "loss": 0.3409,
      "step": 172500
    },
    {
      "epoch": 7.018216195336166,
      "grad_norm": 0.3625243902206421,
      "learning_rate": 0.0001622847784712079,
      "loss": 0.3397,
      "step": 172600
    },
    {
      "epoch": 7.022282310366561,
      "grad_norm": 0.36614376306533813,
      "learning_rate": 0.00016206347098658878,
      "loss": 0.3406,
      "step": 172700
    },
    {
      "epoch": 7.026348425396955,
      "grad_norm": 0.3710143566131592,
      "learning_rate": 0.00016184216350196965,
      "loss": 0.3405,
      "step": 172800
    },
    {
      "epoch": 7.030414540427349,
      "grad_norm": 0.37251120805740356,
      "learning_rate": 0.00016162085601735052,
      "loss": 0.3408,
      "step": 172900
    },
    {
      "epoch": 7.034480655457743,
      "grad_norm": 0.3722868263721466,
      "learning_rate": 0.0001613995485327314,
      "loss": 0.3399,
      "step": 173000
    },
    {
      "epoch": 7.0385467704881375,
      "grad_norm": 0.34248724579811096,
      "learning_rate": 0.00016117824104811224,
      "loss": 0.3397,
      "step": 173100
    },
    {
      "epoch": 7.0426128855185315,
      "grad_norm": 0.32273513078689575,
      "learning_rate": 0.0001609569335634931,
      "loss": 0.3394,
      "step": 173200
    },
    {
      "epoch": 7.0466790005489255,
      "grad_norm": 0.3167512118816376,
      "learning_rate": 0.00016073562607887398,
      "loss": 0.3395,
      "step": 173300
    },
    {
      "epoch": 7.0507451155793195,
      "grad_norm": 0.372496634721756,
      "learning_rate": 0.00016051431859425485,
      "loss": 0.3388,
      "step": 173400
    },
    {
      "epoch": 7.054811230609714,
      "grad_norm": 0.39073729515075684,
      "learning_rate": 0.00016029301110963575,
      "loss": 0.3417,
      "step": 173500
    },
    {
      "epoch": 7.058877345640108,
      "grad_norm": 0.40094271302223206,
      "learning_rate": 0.00016007170362501662,
      "loss": 0.3398,
      "step": 173600
    },
    {
      "epoch": 7.062943460670502,
      "grad_norm": 0.3628004491329193,
      "learning_rate": 0.00015985039614039749,
      "loss": 0.3392,
      "step": 173700
    },
    {
      "epoch": 7.067009575700896,
      "grad_norm": 0.3797649145126343,
      "learning_rate": 0.00015962908865577836,
      "loss": 0.3407,
      "step": 173800
    },
    {
      "epoch": 7.07107569073129,
      "grad_norm": 0.40062999725341797,
      "learning_rate": 0.0001594077811711592,
      "loss": 0.3402,
      "step": 173900
    },
    {
      "epoch": 7.075141805761685,
      "grad_norm": 0.36081916093826294,
      "learning_rate": 0.00015918647368654007,
      "loss": 0.3398,
      "step": 174000
    },
    {
      "epoch": 7.075141805761685,
      "eval_loss": 0.3564632833003998,
      "eval_runtime": 113.5824,
      "eval_samples_per_second": 1539.869,
      "eval_steps_per_second": 48.124,
      "step": 174000
    },
    {
      "epoch": 7.079207920792079,
      "grad_norm": 0.46556076407432556,
      "learning_rate": 0.00015896516620192094,
      "loss": 0.3396,
      "step": 174100
    },
    {
      "epoch": 7.083274035822473,
      "grad_norm": 0.38443723320961,
      "learning_rate": 0.0001587438587173018,
      "loss": 0.3401,
      "step": 174200
    },
    {
      "epoch": 7.087340150852867,
      "grad_norm": 0.3875542879104614,
      "learning_rate": 0.0001585225512326827,
      "loss": 0.3407,
      "step": 174300
    },
    {
      "epoch": 7.091406265883262,
      "grad_norm": 0.3417659103870392,
      "learning_rate": 0.00015830124374806358,
      "loss": 0.3404,
      "step": 174400
    },
    {
      "epoch": 7.095472380913656,
      "grad_norm": 0.3436785638332367,
      "learning_rate": 0.00015807993626344445,
      "loss": 0.3396,
      "step": 174500
    },
    {
      "epoch": 7.09953849594405,
      "grad_norm": 0.39295873045921326,
      "learning_rate": 0.00015785862877882532,
      "loss": 0.342,
      "step": 174600
    },
    {
      "epoch": 7.103604610974444,
      "grad_norm": 0.334565669298172,
      "learning_rate": 0.00015763732129420616,
      "loss": 0.3419,
      "step": 174700
    },
    {
      "epoch": 7.107670726004839,
      "grad_norm": 0.3531554043292999,
      "learning_rate": 0.00015741601380958703,
      "loss": 0.3423,
      "step": 174800
    },
    {
      "epoch": 7.111736841035233,
      "grad_norm": 0.3973170518875122,
      "learning_rate": 0.0001571947063249679,
      "loss": 0.3402,
      "step": 174900
    },
    {
      "epoch": 7.115802956065627,
      "grad_norm": 0.4142465889453888,
      "learning_rate": 0.00015697339884034877,
      "loss": 0.3413,
      "step": 175000
    },
    {
      "epoch": 7.119869071096021,
      "grad_norm": 0.39090362191200256,
      "learning_rate": 0.00015675209135572964,
      "loss": 0.3397,
      "step": 175100
    },
    {
      "epoch": 7.123935186126415,
      "grad_norm": 0.3894548714160919,
      "learning_rate": 0.00015653078387111054,
      "loss": 0.3411,
      "step": 175200
    },
    {
      "epoch": 7.12800130115681,
      "grad_norm": 0.3748234212398529,
      "learning_rate": 0.0001563094763864914,
      "loss": 0.3414,
      "step": 175300
    },
    {
      "epoch": 7.132067416187204,
      "grad_norm": 0.3787679970264435,
      "learning_rate": 0.00015608816890187228,
      "loss": 0.3405,
      "step": 175400
    },
    {
      "epoch": 7.136133531217598,
      "grad_norm": 0.39676737785339355,
      "learning_rate": 0.00015586686141725315,
      "loss": 0.3408,
      "step": 175500
    },
    {
      "epoch": 7.140199646247992,
      "grad_norm": 0.4688648581504822,
      "learning_rate": 0.000155645553932634,
      "loss": 0.3404,
      "step": 175600
    },
    {
      "epoch": 7.144265761278387,
      "grad_norm": 0.3873578608036041,
      "learning_rate": 0.00015542424644801486,
      "loss": 0.3374,
      "step": 175700
    },
    {
      "epoch": 7.148331876308781,
      "grad_norm": 0.4326271414756775,
      "learning_rate": 0.00015520293896339573,
      "loss": 0.3408,
      "step": 175800
    },
    {
      "epoch": 7.152397991339175,
      "grad_norm": 0.3852561414241791,
      "learning_rate": 0.0001549816314787766,
      "loss": 0.3404,
      "step": 175900
    },
    {
      "epoch": 7.156464106369569,
      "grad_norm": 0.37779948115348816,
      "learning_rate": 0.00015476032399415747,
      "loss": 0.3423,
      "step": 176000
    },
    {
      "epoch": 7.156464106369569,
      "eval_loss": 0.35539138317108154,
      "eval_runtime": 113.6343,
      "eval_samples_per_second": 1539.166,
      "eval_steps_per_second": 48.102,
      "step": 176000
    },
    {
      "epoch": 7.160530221399964,
      "grad_norm": 0.3556787371635437,
      "learning_rate": 0.00015453901650953837,
      "loss": 0.3423,
      "step": 176100
    },
    {
      "epoch": 7.164596336430358,
      "grad_norm": 0.3950326144695282,
      "learning_rate": 0.00015431770902491924,
      "loss": 0.3412,
      "step": 176200
    },
    {
      "epoch": 7.168662451460752,
      "grad_norm": 0.38741782307624817,
      "learning_rate": 0.0001540964015403001,
      "loss": 0.3406,
      "step": 176300
    },
    {
      "epoch": 7.172728566491146,
      "grad_norm": 0.31944236159324646,
      "learning_rate": 0.00015387509405568095,
      "loss": 0.3414,
      "step": 176400
    },
    {
      "epoch": 7.176794681521541,
      "grad_norm": 0.38870176672935486,
      "learning_rate": 0.00015365378657106182,
      "loss": 0.3414,
      "step": 176500
    },
    {
      "epoch": 7.180860796551935,
      "grad_norm": 0.4028627574443817,
      "learning_rate": 0.0001534324790864427,
      "loss": 0.3385,
      "step": 176600
    },
    {
      "epoch": 7.184926911582329,
      "grad_norm": 0.3978463411331177,
      "learning_rate": 0.00015321117160182357,
      "loss": 0.339,
      "step": 176700
    },
    {
      "epoch": 7.188993026612723,
      "grad_norm": 0.3970734179019928,
      "learning_rate": 0.00015298986411720444,
      "loss": 0.3412,
      "step": 176800
    },
    {
      "epoch": 7.193059141643117,
      "grad_norm": 0.34890031814575195,
      "learning_rate": 0.00015276855663258533,
      "loss": 0.3399,
      "step": 176900
    },
    {
      "epoch": 7.1971252566735116,
      "grad_norm": 0.370919793844223,
      "learning_rate": 0.0001525472491479662,
      "loss": 0.3408,
      "step": 177000
    },
    {
      "epoch": 7.2011913717039056,
      "grad_norm": 0.3616369664669037,
      "learning_rate": 0.00015232594166334707,
      "loss": 0.3415,
      "step": 177100
    },
    {
      "epoch": 7.2052574867342996,
      "grad_norm": 0.3569144606590271,
      "learning_rate": 0.00015210463417872794,
      "loss": 0.3401,
      "step": 177200
    },
    {
      "epoch": 7.209323601764694,
      "grad_norm": 0.3870229125022888,
      "learning_rate": 0.00015188332669410879,
      "loss": 0.3402,
      "step": 177300
    },
    {
      "epoch": 7.2133897167950884,
      "grad_norm": 0.3905895948410034,
      "learning_rate": 0.00015166201920948966,
      "loss": 0.341,
      "step": 177400
    },
    {
      "epoch": 7.2174558318254824,
      "grad_norm": 0.3844307065010071,
      "learning_rate": 0.00015144071172487053,
      "loss": 0.3414,
      "step": 177500
    },
    {
      "epoch": 7.2215219468558765,
      "grad_norm": 0.34137389063835144,
      "learning_rate": 0.0001512194042402514,
      "loss": 0.3404,
      "step": 177600
    },
    {
      "epoch": 7.2255880618862705,
      "grad_norm": 0.34559962153434753,
      "learning_rate": 0.00015099809675563227,
      "loss": 0.3396,
      "step": 177700
    },
    {
      "epoch": 7.229654176916665,
      "grad_norm": 0.3581583499908447,
      "learning_rate": 0.00015077678927101316,
      "loss": 0.342,
      "step": 177800
    },
    {
      "epoch": 7.233720291947059,
      "grad_norm": 0.37543827295303345,
      "learning_rate": 0.00015055548178639403,
      "loss": 0.3415,
      "step": 177900
    },
    {
      "epoch": 7.237786406977453,
      "grad_norm": 0.38658010959625244,
      "learning_rate": 0.0001503341743017749,
      "loss": 0.338,
      "step": 178000
    },
    {
      "epoch": 7.237786406977453,
      "eval_loss": 0.35508957505226135,
      "eval_runtime": 114.123,
      "eval_samples_per_second": 1532.574,
      "eval_steps_per_second": 47.896,
      "step": 178000
    },
    {
      "epoch": 7.241893183158152,
      "grad_norm": 0.4003206789493561,
      "learning_rate": 0.00015011286681715575,
      "loss": 0.3404,
      "step": 178100
    },
    {
      "epoch": 7.245959298188546,
      "grad_norm": 0.3832121193408966,
      "learning_rate": 0.00014989155933253662,
      "loss": 0.3402,
      "step": 178200
    },
    {
      "epoch": 7.25002541321894,
      "grad_norm": 0.34100615978240967,
      "learning_rate": 0.0001496702518479175,
      "loss": 0.3407,
      "step": 178300
    },
    {
      "epoch": 7.254091528249334,
      "grad_norm": 0.3585923910140991,
      "learning_rate": 0.00014944894436329836,
      "loss": 0.3404,
      "step": 178400
    },
    {
      "epoch": 7.258157643279729,
      "grad_norm": 0.3685937821865082,
      "learning_rate": 0.00014922763687867923,
      "loss": 0.3406,
      "step": 178500
    },
    {
      "epoch": 7.262223758310123,
      "grad_norm": 0.34468942880630493,
      "learning_rate": 0.00014900632939406013,
      "loss": 0.3405,
      "step": 178600
    },
    {
      "epoch": 7.266289873340517,
      "grad_norm": 0.3363487124443054,
      "learning_rate": 0.000148785021909441,
      "loss": 0.3397,
      "step": 178700
    },
    {
      "epoch": 7.270355988370911,
      "grad_norm": 0.38203248381614685,
      "learning_rate": 0.00014856371442482187,
      "loss": 0.3402,
      "step": 178800
    },
    {
      "epoch": 7.274422103401305,
      "grad_norm": 0.35949304699897766,
      "learning_rate": 0.00014834240694020274,
      "loss": 0.3408,
      "step": 178900
    },
    {
      "epoch": 7.2784882184317,
      "grad_norm": 0.39605987071990967,
      "learning_rate": 0.00014812109945558358,
      "loss": 0.3389,
      "step": 179000
    },
    {
      "epoch": 7.282554333462094,
      "grad_norm": 0.3444439172744751,
      "learning_rate": 0.00014789979197096445,
      "loss": 0.3404,
      "step": 179100
    },
    {
      "epoch": 7.286620448492488,
      "grad_norm": 0.3887416422367096,
      "learning_rate": 0.00014767848448634532,
      "loss": 0.3396,
      "step": 179200
    },
    {
      "epoch": 7.290686563522882,
      "grad_norm": 0.37012338638305664,
      "learning_rate": 0.0001474571770017262,
      "loss": 0.3392,
      "step": 179300
    },
    {
      "epoch": 7.294752678553277,
      "grad_norm": 0.40466028451919556,
      "learning_rate": 0.00014723586951710706,
      "loss": 0.3403,
      "step": 179400
    },
    {
      "epoch": 7.298818793583671,
      "grad_norm": 0.38240164518356323,
      "learning_rate": 0.00014701456203248796,
      "loss": 0.3416,
      "step": 179500
    },
    {
      "epoch": 7.302884908614065,
      "grad_norm": 0.4268046021461487,
      "learning_rate": 0.00014679325454786883,
      "loss": 0.3417,
      "step": 179600
    },
    {
      "epoch": 7.306951023644459,
      "grad_norm": 0.4276479482650757,
      "learning_rate": 0.0001465719470632497,
      "loss": 0.3399,
      "step": 179700
    },
    {
      "epoch": 7.3110171386748535,
      "grad_norm": 0.3662428557872772,
      "learning_rate": 0.00014635063957863054,
      "loss": 0.34,
      "step": 179800
    },
    {
      "epoch": 7.3150832537052475,
      "grad_norm": 0.4309961795806885,
      "learning_rate": 0.0001461293320940114,
      "loss": 0.3405,
      "step": 179900
    },
    {
      "epoch": 7.3191493687356415,
      "grad_norm": 0.408142626285553,
      "learning_rate": 0.00014590802460939228,
      "loss": 0.3404,
      "step": 180000
    },
    {
      "epoch": 7.3191493687356415,
      "eval_loss": 0.35470864176750183,
      "eval_runtime": 114.0798,
      "eval_samples_per_second": 1533.155,
      "eval_steps_per_second": 47.914,
      "step": 180000
    },
    {
      "epoch": 7.3232154837660355,
      "grad_norm": 0.36828336119651794,
      "learning_rate": 0.00014568671712477315,
      "loss": 0.3408,
      "step": 180100
    },
    {
      "epoch": 7.32728159879643,
      "grad_norm": 0.37053611874580383,
      "learning_rate": 0.00014546540964015402,
      "loss": 0.339,
      "step": 180200
    },
    {
      "epoch": 7.331347713826824,
      "grad_norm": 0.4222056567668915,
      "learning_rate": 0.00014524410215553492,
      "loss": 0.3394,
      "step": 180300
    },
    {
      "epoch": 7.335413828857218,
      "grad_norm": 0.3261723816394806,
      "learning_rate": 0.0001450227946709158,
      "loss": 0.3399,
      "step": 180400
    },
    {
      "epoch": 7.339479943887612,
      "grad_norm": 0.372773140668869,
      "learning_rate": 0.00014480148718629666,
      "loss": 0.3401,
      "step": 180500
    },
    {
      "epoch": 7.343546058918006,
      "grad_norm": 0.39829400181770325,
      "learning_rate": 0.0001445801797016775,
      "loss": 0.339,
      "step": 180600
    },
    {
      "epoch": 7.347612173948401,
      "grad_norm": 0.3549538254737854,
      "learning_rate": 0.00014435887221705837,
      "loss": 0.3413,
      "step": 180700
    },
    {
      "epoch": 7.351678288978795,
      "grad_norm": 0.36280569434165955,
      "learning_rate": 0.00014413756473243924,
      "loss": 0.3392,
      "step": 180800
    },
    {
      "epoch": 7.355744404009189,
      "grad_norm": 0.4232325255870819,
      "learning_rate": 0.00014391625724782011,
      "loss": 0.3398,
      "step": 180900
    },
    {
      "epoch": 7.359810519039583,
      "grad_norm": 0.3527020514011383,
      "learning_rate": 0.00014369494976320098,
      "loss": 0.3401,
      "step": 181000
    },
    {
      "epoch": 7.363876634069978,
      "grad_norm": 0.5433390140533447,
      "learning_rate": 0.00014347364227858185,
      "loss": 0.3413,
      "step": 181100
    },
    {
      "epoch": 7.367942749100372,
      "grad_norm": 0.408213347196579,
      "learning_rate": 0.00014325233479396275,
      "loss": 0.3407,
      "step": 181200
    },
    {
      "epoch": 7.372008864130766,
      "grad_norm": 0.3143787980079651,
      "learning_rate": 0.00014303102730934362,
      "loss": 0.3405,
      "step": 181300
    },
    {
      "epoch": 7.37607497916116,
      "grad_norm": 0.38657546043395996,
      "learning_rate": 0.0001428097198247245,
      "loss": 0.3401,
      "step": 181400
    },
    {
      "epoch": 7.380141094191555,
      "grad_norm": 0.430431067943573,
      "learning_rate": 0.00014258841234010534,
      "loss": 0.3396,
      "step": 181500
    },
    {
      "epoch": 7.384207209221949,
      "grad_norm": 0.430375337600708,
      "learning_rate": 0.0001423671048554862,
      "loss": 0.3397,
      "step": 181600
    },
    {
      "epoch": 7.388273324252343,
      "grad_norm": 0.41358116269111633,
      "learning_rate": 0.00014214579737086708,
      "loss": 0.3391,
      "step": 181700
    },
    {
      "epoch": 7.392339439282737,
      "grad_norm": 0.4361914396286011,
      "learning_rate": 0.00014192448988624795,
      "loss": 0.3416,
      "step": 181800
    },
    {
      "epoch": 7.396405554313132,
      "grad_norm": 0.3923317492008209,
      "learning_rate": 0.00014170318240162882,
      "loss": 0.3402,
      "step": 181900
    },
    {
      "epoch": 7.400471669343526,
      "grad_norm": 0.3875589668750763,
      "learning_rate": 0.00014148187491700971,
      "loss": 0.3399,
      "step": 182000
    },
    {
      "epoch": 7.400471669343526,
      "eval_loss": 0.3544296324253082,
      "eval_runtime": 113.3581,
      "eval_samples_per_second": 1542.915,
      "eval_steps_per_second": 48.219,
      "step": 182000
    },
    {
      "epoch": 7.40453778437392,
      "grad_norm": 0.378627747297287,
      "learning_rate": 0.00014126056743239058,
      "loss": 0.3398,
      "step": 182100
    },
    {
      "epoch": 7.408603899404314,
      "grad_norm": 0.40280604362487793,
      "learning_rate": 0.00014103925994777145,
      "loss": 0.3408,
      "step": 182200
    },
    {
      "epoch": 7.412670014434708,
      "grad_norm": 0.4343639314174652,
      "learning_rate": 0.0001408179524631523,
      "loss": 0.34,
      "step": 182300
    },
    {
      "epoch": 7.416736129465103,
      "grad_norm": 0.41363462805747986,
      "learning_rate": 0.00014059664497853317,
      "loss": 0.3423,
      "step": 182400
    },
    {
      "epoch": 7.420802244495497,
      "grad_norm": 0.37895554304122925,
      "learning_rate": 0.00014037533749391404,
      "loss": 0.3432,
      "step": 182500
    },
    {
      "epoch": 7.424868359525891,
      "grad_norm": 0.3556329905986786,
      "learning_rate": 0.0001401540300092949,
      "loss": 0.3391,
      "step": 182600
    },
    {
      "epoch": 7.428934474556285,
      "grad_norm": 0.3918808698654175,
      "learning_rate": 0.00013993272252467578,
      "loss": 0.3427,
      "step": 182700
    },
    {
      "epoch": 7.43300058958668,
      "grad_norm": 0.40892136096954346,
      "learning_rate": 0.00013971141504005665,
      "loss": 0.3412,
      "step": 182800
    },
    {
      "epoch": 7.437066704617074,
      "grad_norm": 0.37967783212661743,
      "learning_rate": 0.00013949010755543755,
      "loss": 0.3401,
      "step": 182900
    },
    {
      "epoch": 7.441132819647468,
      "grad_norm": 0.4008391201496124,
      "learning_rate": 0.00013926880007081842,
      "loss": 0.3403,
      "step": 183000
    },
    {
      "epoch": 7.445198934677862,
      "grad_norm": 0.417808473110199,
      "learning_rate": 0.00013904749258619929,
      "loss": 0.3403,
      "step": 183100
    },
    {
      "epoch": 7.449265049708257,
      "grad_norm": 0.3679591119289398,
      "learning_rate": 0.00013882618510158013,
      "loss": 0.3391,
      "step": 183200
    },
    {
      "epoch": 7.453331164738651,
      "grad_norm": 0.3569779396057129,
      "learning_rate": 0.000138604877616961,
      "loss": 0.341,
      "step": 183300
    },
    {
      "epoch": 7.457397279769045,
      "grad_norm": 0.34710630774497986,
      "learning_rate": 0.00013838357013234187,
      "loss": 0.3392,
      "step": 183400
    },
    {
      "epoch": 7.461463394799439,
      "grad_norm": 0.46489641070365906,
      "learning_rate": 0.00013816226264772274,
      "loss": 0.3405,
      "step": 183500
    },
    {
      "epoch": 7.4655295098298335,
      "grad_norm": 0.40209174156188965,
      "learning_rate": 0.0001379409551631036,
      "loss": 0.3404,
      "step": 183600
    },
    {
      "epoch": 7.4695956248602275,
      "grad_norm": 0.46248024702072144,
      "learning_rate": 0.0001377196476784845,
      "loss": 0.3398,
      "step": 183700
    },
    {
      "epoch": 7.4736617398906215,
      "grad_norm": 0.3634487986564636,
      "learning_rate": 0.00013749834019386538,
      "loss": 0.3409,
      "step": 183800
    },
    {
      "epoch": 7.4777278549210155,
      "grad_norm": 0.43510034680366516,
      "learning_rate": 0.00013727703270924625,
      "loss": 0.3386,
      "step": 183900
    },
    {
      "epoch": 7.4817939699514096,
      "grad_norm": 0.42082443833351135,
      "learning_rate": 0.0001370557252246271,
      "loss": 0.3415,
      "step": 184000
    },
    {
      "epoch": 7.4817939699514096,
      "eval_loss": 0.35377466678619385,
      "eval_runtime": 113.9103,
      "eval_samples_per_second": 1535.436,
      "eval_steps_per_second": 47.985,
      "step": 184000
    },
    {
      "epoch": 7.485860084981804,
      "grad_norm": 0.3981691002845764,
      "learning_rate": 0.00013683441774000796,
      "loss": 0.3407,
      "step": 184100
    },
    {
      "epoch": 7.489926200012198,
      "grad_norm": 0.39590728282928467,
      "learning_rate": 0.00013661311025538883,
      "loss": 0.3415,
      "step": 184200
    },
    {
      "epoch": 7.4939923150425924,
      "grad_norm": 0.3963281512260437,
      "learning_rate": 0.0001363918027707697,
      "loss": 0.3405,
      "step": 184300
    },
    {
      "epoch": 7.4980584300729864,
      "grad_norm": 0.3465215563774109,
      "learning_rate": 0.00013617049528615057,
      "loss": 0.3398,
      "step": 184400
    },
    {
      "epoch": 7.502124545103381,
      "grad_norm": 0.43405476212501526,
      "learning_rate": 0.00013594918780153144,
      "loss": 0.3406,
      "step": 184500
    },
    {
      "epoch": 7.506190660133775,
      "grad_norm": 0.3846878707408905,
      "learning_rate": 0.00013572788031691234,
      "loss": 0.339,
      "step": 184600
    },
    {
      "epoch": 7.510256775164169,
      "grad_norm": 0.4229898154735565,
      "learning_rate": 0.0001355065728322932,
      "loss": 0.3402,
      "step": 184700
    },
    {
      "epoch": 7.514322890194563,
      "grad_norm": 0.4331040382385254,
      "learning_rate": 0.00013528526534767408,
      "loss": 0.3385,
      "step": 184800
    },
    {
      "epoch": 7.518389005224957,
      "grad_norm": 0.39637646079063416,
      "learning_rate": 0.00013506395786305492,
      "loss": 0.3415,
      "step": 184900
    },
    {
      "epoch": 7.522455120255352,
      "grad_norm": 0.3934740126132965,
      "learning_rate": 0.0001348426503784358,
      "loss": 0.3404,
      "step": 185000
    },
    {
      "epoch": 7.526521235285746,
      "grad_norm": 0.3603454828262329,
      "learning_rate": 0.00013462134289381666,
      "loss": 0.3393,
      "step": 185100
    },
    {
      "epoch": 7.53058735031614,
      "grad_norm": 0.35798877477645874,
      "learning_rate": 0.00013440003540919753,
      "loss": 0.3405,
      "step": 185200
    },
    {
      "epoch": 7.534653465346535,
      "grad_norm": 0.36887049674987793,
      "learning_rate": 0.0001341787279245784,
      "loss": 0.3397,
      "step": 185300
    },
    {
      "epoch": 7.538719580376929,
      "grad_norm": 0.3591001033782959,
      "learning_rate": 0.00013395742043995927,
      "loss": 0.341,
      "step": 185400
    },
    {
      "epoch": 7.542785695407323,
      "grad_norm": 0.38883915543556213,
      "learning_rate": 0.00013373611295534017,
      "loss": 0.3384,
      "step": 185500
    },
    {
      "epoch": 7.546851810437717,
      "grad_norm": 0.4661332368850708,
      "learning_rate": 0.00013351480547072104,
      "loss": 0.3407,
      "step": 185600
    },
    {
      "epoch": 7.550917925468111,
      "grad_norm": 0.3886455297470093,
      "learning_rate": 0.00013329349798610188,
      "loss": 0.3405,
      "step": 185700
    },
    {
      "epoch": 7.554984040498506,
      "grad_norm": 0.3954237997531891,
      "learning_rate": 0.00013307219050148276,
      "loss": 0.3392,
      "step": 185800
    },
    {
      "epoch": 7.5590501555289,
      "grad_norm": 0.3876384496688843,
      "learning_rate": 0.00013285088301686363,
      "loss": 0.339,
      "step": 185900
    },
    {
      "epoch": 7.563116270559294,
      "grad_norm": 0.37267249822616577,
      "learning_rate": 0.0001326295755322445,
      "loss": 0.3408,
      "step": 186000
    },
    {
      "epoch": 7.563116270559294,
      "eval_loss": 0.3529749810695648,
      "eval_runtime": 113.3818,
      "eval_samples_per_second": 1542.593,
      "eval_steps_per_second": 48.209,
      "step": 186000
    },
    {
      "epoch": 7.567182385589688,
      "grad_norm": 0.380446195602417,
      "learning_rate": 0.00013240826804762537,
      "loss": 0.3404,
      "step": 186100
    },
    {
      "epoch": 7.571248500620083,
      "grad_norm": 0.3523031175136566,
      "learning_rate": 0.00013218696056300624,
      "loss": 0.3405,
      "step": 186200
    },
    {
      "epoch": 7.575314615650477,
      "grad_norm": 0.4931383728981018,
      "learning_rate": 0.00013196565307838713,
      "loss": 0.3401,
      "step": 186300
    },
    {
      "epoch": 7.579380730680871,
      "grad_norm": 0.4063531756401062,
      "learning_rate": 0.000131744345593768,
      "loss": 0.3396,
      "step": 186400
    },
    {
      "epoch": 7.583446845711265,
      "grad_norm": 0.44154632091522217,
      "learning_rate": 0.00013152303810914885,
      "loss": 0.3381,
      "step": 186500
    },
    {
      "epoch": 7.587512960741659,
      "grad_norm": 0.41817668080329895,
      "learning_rate": 0.00013130173062452972,
      "loss": 0.3395,
      "step": 186600
    },
    {
      "epoch": 7.591579075772054,
      "grad_norm": 0.49331653118133545,
      "learning_rate": 0.0001310804231399106,
      "loss": 0.3404,
      "step": 186700
    },
    {
      "epoch": 7.595645190802448,
      "grad_norm": 0.42164623737335205,
      "learning_rate": 0.00013085911565529146,
      "loss": 0.3388,
      "step": 186800
    },
    {
      "epoch": 7.599711305832842,
      "grad_norm": 0.41977086663246155,
      "learning_rate": 0.00013063780817067233,
      "loss": 0.341,
      "step": 186900
    },
    {
      "epoch": 7.603777420863237,
      "grad_norm": 0.41529566049575806,
      "learning_rate": 0.0001304165006860532,
      "loss": 0.3397,
      "step": 187000
    },
    {
      "epoch": 7.607843535893631,
      "grad_norm": 0.4089634120464325,
      "learning_rate": 0.00013019519320143407,
      "loss": 0.3394,
      "step": 187100
    },
    {
      "epoch": 7.611909650924025,
      "grad_norm": 0.43384698033332825,
      "learning_rate": 0.00012997388571681497,
      "loss": 0.3398,
      "step": 187200
    },
    {
      "epoch": 7.615975765954419,
      "grad_norm": 0.38508790731430054,
      "learning_rate": 0.00012975257823219584,
      "loss": 0.339,
      "step": 187300
    },
    {
      "epoch": 7.620041880984813,
      "grad_norm": 0.4070599377155304,
      "learning_rate": 0.00012953127074757668,
      "loss": 0.3408,
      "step": 187400
    },
    {
      "epoch": 7.624107996015208,
      "grad_norm": 0.46203291416168213,
      "learning_rate": 0.00012930996326295755,
      "loss": 0.3403,
      "step": 187500
    },
    {
      "epoch": 7.628174111045602,
      "grad_norm": 0.3998284339904785,
      "learning_rate": 0.00012908865577833842,
      "loss": 0.339,
      "step": 187600
    },
    {
      "epoch": 7.632240226075996,
      "grad_norm": 0.39638155698776245,
      "learning_rate": 0.0001288673482937193,
      "loss": 0.3381,
      "step": 187700
    },
    {
      "epoch": 7.63630634110639,
      "grad_norm": 0.4156073331832886,
      "learning_rate": 0.00012864604080910016,
      "loss": 0.3403,
      "step": 187800
    },
    {
      "epoch": 7.6403724561367845,
      "grad_norm": 0.40782395005226135,
      "learning_rate": 0.00012842473332448103,
      "loss": 0.3382,
      "step": 187900
    },
    {
      "epoch": 7.6444385711671785,
      "grad_norm": 0.3809567987918854,
      "learning_rate": 0.00012820342583986193,
      "loss": 0.3393,
      "step": 188000
    },
    {
      "epoch": 7.6444385711671785,
      "eval_loss": 0.35272353887557983,
      "eval_runtime": 113.81,
      "eval_samples_per_second": 1536.789,
      "eval_steps_per_second": 48.027,
      "step": 188000
    },
    {
      "epoch": 7.6485046861975725,
      "grad_norm": 0.4388989806175232,
      "learning_rate": 0.0001279821183552428,
      "loss": 0.3381,
      "step": 188100
    },
    {
      "epoch": 7.6525708012279665,
      "grad_norm": 0.34756702184677124,
      "learning_rate": 0.00012776081087062364,
      "loss": 0.3387,
      "step": 188200
    },
    {
      "epoch": 7.6566369162583605,
      "grad_norm": 0.43929365277290344,
      "learning_rate": 0.0001275395033860045,
      "loss": 0.3392,
      "step": 188300
    },
    {
      "epoch": 7.660703031288755,
      "grad_norm": 0.36654725670814514,
      "learning_rate": 0.00012731819590138538,
      "loss": 0.3391,
      "step": 188400
    },
    {
      "epoch": 7.664769146319149,
      "grad_norm": 0.39774999022483826,
      "learning_rate": 0.00012709688841676625,
      "loss": 0.3416,
      "step": 188500
    },
    {
      "epoch": 7.668835261349543,
      "grad_norm": 0.406978577375412,
      "learning_rate": 0.00012687558093214712,
      "loss": 0.3401,
      "step": 188600
    },
    {
      "epoch": 7.672901376379937,
      "grad_norm": 0.38809236884117126,
      "learning_rate": 0.000126654273447528,
      "loss": 0.3376,
      "step": 188700
    },
    {
      "epoch": 7.676967491410332,
      "grad_norm": 0.4430091977119446,
      "learning_rate": 0.00012643296596290886,
      "loss": 0.3417,
      "step": 188800
    },
    {
      "epoch": 7.681033606440726,
      "grad_norm": 0.4504791498184204,
      "learning_rate": 0.00012621165847828976,
      "loss": 0.3387,
      "step": 188900
    },
    {
      "epoch": 7.68509972147112,
      "grad_norm": 0.4304887056350708,
      "learning_rate": 0.00012599035099367063,
      "loss": 0.3396,
      "step": 189000
    },
    {
      "epoch": 7.689165836501514,
      "grad_norm": 0.45704033970832825,
      "learning_rate": 0.00012576904350905147,
      "loss": 0.3399,
      "step": 189100
    },
    {
      "epoch": 7.693231951531909,
      "grad_norm": 0.42968031764030457,
      "learning_rate": 0.00012554773602443234,
      "loss": 0.3376,
      "step": 189200
    },
    {
      "epoch": 7.697298066562303,
      "grad_norm": 0.4186645448207855,
      "learning_rate": 0.0001253264285398132,
      "loss": 0.3397,
      "step": 189300
    },
    {
      "epoch": 7.701364181592697,
      "grad_norm": 0.3936024010181427,
      "learning_rate": 0.00012510512105519408,
      "loss": 0.3395,
      "step": 189400
    },
    {
      "epoch": 7.705430296623091,
      "grad_norm": 0.41757267713546753,
      "learning_rate": 0.00012488381357057495,
      "loss": 0.3393,
      "step": 189500
    },
    {
      "epoch": 7.709496411653486,
      "grad_norm": 0.3978797495365143,
      "learning_rate": 0.00012466250608595582,
      "loss": 0.3413,
      "step": 189600
    },
    {
      "epoch": 7.71356252668388,
      "grad_norm": 0.42664551734924316,
      "learning_rate": 0.0001244411986013367,
      "loss": 0.3389,
      "step": 189700
    },
    {
      "epoch": 7.717628641714274,
      "grad_norm": 0.4020361602306366,
      "learning_rate": 0.00012421989111671756,
      "loss": 0.3387,
      "step": 189800
    },
    {
      "epoch": 7.721694756744668,
      "grad_norm": 0.36141079664230347,
      "learning_rate": 0.00012399858363209843,
      "loss": 0.3412,
      "step": 189900
    },
    {
      "epoch": 7.725760871775062,
      "grad_norm": 0.3986142575740814,
      "learning_rate": 0.0001237772761474793,
      "loss": 0.34,
      "step": 190000
    },
    {
      "epoch": 7.725760871775062,
      "eval_loss": 0.35214656591415405,
      "eval_runtime": 113.6689,
      "eval_samples_per_second": 1538.698,
      "eval_steps_per_second": 48.087,
      "step": 190000
    },
    {
      "epoch": 7.729826986805457,
      "grad_norm": 0.46676766872406006,
      "learning_rate": 0.00012355596866286017,
      "loss": 0.3393,
      "step": 190100
    },
    {
      "epoch": 7.733893101835851,
      "grad_norm": 0.4550146460533142,
      "learning_rate": 0.00012333466117824104,
      "loss": 0.3399,
      "step": 190200
    },
    {
      "epoch": 7.737959216866245,
      "grad_norm": 0.45873168110847473,
      "learning_rate": 0.00012311335369362192,
      "loss": 0.3397,
      "step": 190300
    },
    {
      "epoch": 7.742025331896639,
      "grad_norm": 0.4141022264957428,
      "learning_rate": 0.00012289204620900279,
      "loss": 0.3384,
      "step": 190400
    },
    {
      "epoch": 7.746091446927034,
      "grad_norm": 0.4385048449039459,
      "learning_rate": 0.00012267073872438366,
      "loss": 0.3394,
      "step": 190500
    },
    {
      "epoch": 7.750157561957428,
      "grad_norm": 0.37647852301597595,
      "learning_rate": 0.00012244943123976453,
      "loss": 0.3396,
      "step": 190600
    },
    {
      "epoch": 7.754223676987822,
      "grad_norm": 0.42570367455482483,
      "learning_rate": 0.0001222281237551454,
      "loss": 0.3378,
      "step": 190700
    },
    {
      "epoch": 7.758289792018216,
      "grad_norm": 0.416450560092926,
      "learning_rate": 0.00012200681627052628,
      "loss": 0.3381,
      "step": 190800
    },
    {
      "epoch": 7.762355907048611,
      "grad_norm": 0.4369352459907532,
      "learning_rate": 0.00012178550878590715,
      "loss": 0.3408,
      "step": 190900
    },
    {
      "epoch": 7.766422022079005,
      "grad_norm": 0.399799108505249,
      "learning_rate": 0.000121564201301288,
      "loss": 0.3371,
      "step": 191000
    },
    {
      "epoch": 7.770488137109399,
      "grad_norm": 0.4042545258998871,
      "learning_rate": 0.00012134289381666888,
      "loss": 0.3383,
      "step": 191100
    },
    {
      "epoch": 7.774554252139793,
      "grad_norm": 0.39921051263809204,
      "learning_rate": 0.00012112158633204976,
      "loss": 0.3392,
      "step": 191200
    },
    {
      "epoch": 7.778620367170188,
      "grad_norm": 0.4551786482334137,
      "learning_rate": 0.00012090027884743063,
      "loss": 0.3393,
      "step": 191300
    },
    {
      "epoch": 7.782686482200582,
      "grad_norm": 0.4466094970703125,
      "learning_rate": 0.00012067897136281149,
      "loss": 0.3399,
      "step": 191400
    },
    {
      "epoch": 7.786752597230976,
      "grad_norm": 0.45737984776496887,
      "learning_rate": 0.00012045766387819236,
      "loss": 0.3402,
      "step": 191500
    },
    {
      "epoch": 7.79081871226137,
      "grad_norm": 0.35038867592811584,
      "learning_rate": 0.00012023635639357323,
      "loss": 0.3393,
      "step": 191600
    },
    {
      "epoch": 7.794884827291764,
      "grad_norm": 0.41196703910827637,
      "learning_rate": 0.00012001504890895411,
      "loss": 0.3377,
      "step": 191700
    },
    {
      "epoch": 7.798950942322159,
      "grad_norm": 0.41588032245635986,
      "learning_rate": 0.00011979374142433497,
      "loss": 0.3387,
      "step": 191800
    },
    {
      "epoch": 7.803017057352553,
      "grad_norm": 0.44174307584762573,
      "learning_rate": 0.00011957243393971584,
      "loss": 0.3383,
      "step": 191900
    },
    {
      "epoch": 7.807083172382947,
      "grad_norm": 0.40104618668556213,
      "learning_rate": 0.00011935112645509671,
      "loss": 0.3387,
      "step": 192000
    },
    {
      "epoch": 7.807083172382947,
      "eval_loss": 0.3513599634170532,
      "eval_runtime": 113.2977,
      "eval_samples_per_second": 1543.739,
      "eval_steps_per_second": 48.245,
      "step": 192000
    },
    {
      "epoch": 7.811149287413341,
      "grad_norm": 0.43392813205718994,
      "learning_rate": 0.00011912981897047759,
      "loss": 0.3413,
      "step": 192100
    },
    {
      "epoch": 7.8152154024437355,
      "grad_norm": 0.3804505467414856,
      "learning_rate": 0.00011890851148585845,
      "loss": 0.3391,
      "step": 192200
    },
    {
      "epoch": 7.8192815174741295,
      "grad_norm": 0.448086142539978,
      "learning_rate": 0.00011868720400123932,
      "loss": 0.3375,
      "step": 192300
    },
    {
      "epoch": 7.8233476325045235,
      "grad_norm": 0.39343997836112976,
      "learning_rate": 0.00011846589651662019,
      "loss": 0.337,
      "step": 192400
    },
    {
      "epoch": 7.8274137475349175,
      "grad_norm": 0.3928893506526947,
      "learning_rate": 0.00011824458903200107,
      "loss": 0.3377,
      "step": 192500
    },
    {
      "epoch": 7.8314798625653115,
      "grad_norm": 0.38450905680656433,
      "learning_rate": 0.00011802328154738194,
      "loss": 0.3397,
      "step": 192600
    },
    {
      "epoch": 7.835545977595706,
      "grad_norm": 0.4218480885028839,
      "learning_rate": 0.0001178019740627628,
      "loss": 0.3397,
      "step": 192700
    },
    {
      "epoch": 7.8396120926261,
      "grad_norm": 0.3850468695163727,
      "learning_rate": 0.00011758066657814367,
      "loss": 0.3381,
      "step": 192800
    },
    {
      "epoch": 7.843678207656494,
      "grad_norm": 0.3921409249305725,
      "learning_rate": 0.00011735935909352455,
      "loss": 0.3376,
      "step": 192900
    },
    {
      "epoch": 7.847744322686889,
      "grad_norm": 0.5114637613296509,
      "learning_rate": 0.00011713805160890542,
      "loss": 0.3377,
      "step": 193000
    },
    {
      "epoch": 7.851810437717283,
      "grad_norm": 0.39709508419036865,
      "learning_rate": 0.00011691674412428628,
      "loss": 0.3395,
      "step": 193100
    },
    {
      "epoch": 7.855876552747677,
      "grad_norm": 0.39751505851745605,
      "learning_rate": 0.00011669543663966715,
      "loss": 0.3394,
      "step": 193200
    },
    {
      "epoch": 7.859942667778071,
      "grad_norm": 0.4127240478992462,
      "learning_rate": 0.00011647412915504802,
      "loss": 0.3389,
      "step": 193300
    },
    {
      "epoch": 7.864008782808465,
      "grad_norm": 0.36452364921569824,
      "learning_rate": 0.0001162528216704289,
      "loss": 0.338,
      "step": 193400
    },
    {
      "epoch": 7.86807489783886,
      "grad_norm": 0.3288072943687439,
      "learning_rate": 0.00011603151418580976,
      "loss": 0.3395,
      "step": 193500
    },
    {
      "epoch": 7.872141012869254,
      "grad_norm": 0.3811570703983307,
      "learning_rate": 0.00011581020670119063,
      "loss": 0.3382,
      "step": 193600
    },
    {
      "epoch": 7.876207127899648,
      "grad_norm": 0.4194466471672058,
      "learning_rate": 0.0001155888992165715,
      "loss": 0.3372,
      "step": 193700
    },
    {
      "epoch": 7.880273242930042,
      "grad_norm": 0.4245879650115967,
      "learning_rate": 0.00011536759173195239,
      "loss": 0.3399,
      "step": 193800
    },
    {
      "epoch": 7.884339357960437,
      "grad_norm": 0.4105278253555298,
      "learning_rate": 0.00011514628424733324,
      "loss": 0.3382,
      "step": 193900
    },
    {
      "epoch": 7.888405472990831,
      "grad_norm": 0.39360830187797546,
      "learning_rate": 0.00011492497676271411,
      "loss": 0.3385,
      "step": 194000
    },
    {
      "epoch": 7.888405472990831,
      "eval_loss": 0.350801944732666,
      "eval_runtime": 113.8904,
      "eval_samples_per_second": 1535.705,
      "eval_steps_per_second": 47.994,
      "step": 194000
    },
    {
      "epoch": 7.892471588021225,
      "grad_norm": 0.39868617057800293,
      "learning_rate": 0.00011470366927809498,
      "loss": 0.3392,
      "step": 194100
    },
    {
      "epoch": 7.896537703051619,
      "grad_norm": 0.37551066279411316,
      "learning_rate": 0.00011448236179347587,
      "loss": 0.337,
      "step": 194200
    },
    {
      "epoch": 7.900603818082013,
      "grad_norm": 0.3816207945346832,
      "learning_rate": 0.00011426105430885672,
      "loss": 0.3361,
      "step": 194300
    },
    {
      "epoch": 7.904669933112408,
      "grad_norm": 0.3804980516433716,
      "learning_rate": 0.0001140397468242376,
      "loss": 0.3398,
      "step": 194400
    },
    {
      "epoch": 7.908736048142802,
      "grad_norm": 0.45475730299949646,
      "learning_rate": 0.00011381843933961846,
      "loss": 0.3382,
      "step": 194500
    },
    {
      "epoch": 7.912802163173196,
      "grad_norm": 0.49900102615356445,
      "learning_rate": 0.00011359713185499935,
      "loss": 0.3386,
      "step": 194600
    },
    {
      "epoch": 7.916868278203591,
      "grad_norm": 0.38936904072761536,
      "learning_rate": 0.00011337582437038022,
      "loss": 0.3376,
      "step": 194700
    },
    {
      "epoch": 7.920934393233985,
      "grad_norm": 0.44865652918815613,
      "learning_rate": 0.00011315451688576108,
      "loss": 0.3395,
      "step": 194800
    },
    {
      "epoch": 7.925000508264379,
      "grad_norm": 0.41168075799942017,
      "learning_rate": 0.00011293320940114195,
      "loss": 0.3387,
      "step": 194900
    },
    {
      "epoch": 7.929066623294773,
      "grad_norm": 0.417739599943161,
      "learning_rate": 0.00011271190191652282,
      "loss": 0.3409,
      "step": 195000
    },
    {
      "epoch": 7.933132738325167,
      "grad_norm": 0.38863950967788696,
      "learning_rate": 0.0001124905944319037,
      "loss": 0.337,
      "step": 195100
    },
    {
      "epoch": 7.937198853355562,
      "grad_norm": 0.41704726219177246,
      "learning_rate": 0.00011226928694728456,
      "loss": 0.3384,
      "step": 195200
    },
    {
      "epoch": 7.941264968385956,
      "grad_norm": 0.45104020833969116,
      "learning_rate": 0.00011204797946266543,
      "loss": 0.3363,
      "step": 195300
    },
    {
      "epoch": 7.94533108341635,
      "grad_norm": 0.4488080143928528,
      "learning_rate": 0.0001118266719780463,
      "loss": 0.3382,
      "step": 195400
    },
    {
      "epoch": 7.949397198446744,
      "grad_norm": 0.4232679009437561,
      "learning_rate": 0.00011160536449342718,
      "loss": 0.3396,
      "step": 195500
    },
    {
      "epoch": 7.953463313477139,
      "grad_norm": 0.4439776837825775,
      "learning_rate": 0.00011138405700880804,
      "loss": 0.34,
      "step": 195600
    },
    {
      "epoch": 7.957529428507533,
      "grad_norm": 0.514523983001709,
      "learning_rate": 0.00011116274952418891,
      "loss": 0.3367,
      "step": 195700
    },
    {
      "epoch": 7.961595543537927,
      "grad_norm": 0.4789126515388489,
      "learning_rate": 0.00011094144203956978,
      "loss": 0.3371,
      "step": 195800
    },
    {
      "epoch": 7.965661658568321,
      "grad_norm": 0.4154759645462036,
      "learning_rate": 0.00011072013455495066,
      "loss": 0.3374,
      "step": 195900
    },
    {
      "epoch": 7.969727773598715,
      "grad_norm": 0.5310204029083252,
      "learning_rate": 0.00011049882707033152,
      "loss": 0.3403,
      "step": 196000
    },
    {
      "epoch": 7.969727773598715,
      "eval_loss": 0.3503013551235199,
      "eval_runtime": 114.47,
      "eval_samples_per_second": 1527.929,
      "eval_steps_per_second": 47.751,
      "step": 196000
    },
    {
      "epoch": 7.9737938886291095,
      "grad_norm": 0.3849300146102905,
      "learning_rate": 0.00011027751958571239,
      "loss": 0.3376,
      "step": 196100
    },
    {
      "epoch": 7.9778600036595035,
      "grad_norm": 0.4328179955482483,
      "learning_rate": 0.00011005621210109326,
      "loss": 0.3386,
      "step": 196200
    },
    {
      "epoch": 7.9819261186898975,
      "grad_norm": 0.40846186876296997,
      "learning_rate": 0.00010983490461647413,
      "loss": 0.3379,
      "step": 196300
    },
    {
      "epoch": 7.985992233720292,
      "grad_norm": 0.4074135720729828,
      "learning_rate": 0.00010961359713185501,
      "loss": 0.3383,
      "step": 196400
    },
    {
      "epoch": 7.990058348750686,
      "grad_norm": 0.3829115927219391,
      "learning_rate": 0.00010939228964723587,
      "loss": 0.3396,
      "step": 196500
    },
    {
      "epoch": 7.99412446378108,
      "grad_norm": 0.43403226137161255,
      "learning_rate": 0.00010917098216261674,
      "loss": 0.3386,
      "step": 196600
    },
    {
      "epoch": 7.998190578811474,
      "grad_norm": 0.45347851514816284,
      "learning_rate": 0.00010894967467799761,
      "loss": 0.3354,
      "step": 196700
    },
    {
      "epoch": 8.002256693841868,
      "grad_norm": 0.44626936316490173,
      "learning_rate": 0.00010872836719337849,
      "loss": 0.3351,
      "step": 196800
    },
    {
      "epoch": 8.006322808872262,
      "grad_norm": 0.4368092119693756,
      "learning_rate": 0.00010850705970875935,
      "loss": 0.3306,
      "step": 196900
    },
    {
      "epoch": 8.010388923902656,
      "grad_norm": 0.425666868686676,
      "learning_rate": 0.00010828575222414022,
      "loss": 0.3317,
      "step": 197000
    },
    {
      "epoch": 8.014455038933052,
      "grad_norm": 0.44438764452934265,
      "learning_rate": 0.00010806444473952109,
      "loss": 0.3305,
      "step": 197100
    },
    {
      "epoch": 8.018521153963446,
      "grad_norm": 0.5055786967277527,
      "learning_rate": 0.00010784313725490197,
      "loss": 0.331,
      "step": 197200
    },
    {
      "epoch": 8.02258726899384,
      "grad_norm": 0.4287346303462982,
      "learning_rate": 0.00010762182977028283,
      "loss": 0.3326,
      "step": 197300
    },
    {
      "epoch": 8.026653384024234,
      "grad_norm": 0.4232304096221924,
      "learning_rate": 0.0001074005222856637,
      "loss": 0.3323,
      "step": 197400
    },
    {
      "epoch": 8.030719499054628,
      "grad_norm": 0.4346705377101898,
      "learning_rate": 0.00010717921480104457,
      "loss": 0.3334,
      "step": 197500
    },
    {
      "epoch": 8.034785614085022,
      "grad_norm": 0.463225781917572,
      "learning_rate": 0.00010695790731642545,
      "loss": 0.3304,
      "step": 197600
    },
    {
      "epoch": 8.038851729115416,
      "grad_norm": 0.4667437970638275,
      "learning_rate": 0.00010673659983180631,
      "loss": 0.3342,
      "step": 197700
    },
    {
      "epoch": 8.04291784414581,
      "grad_norm": 0.4733387529850006,
      "learning_rate": 0.00010651529234718718,
      "loss": 0.3324,
      "step": 197800
    },
    {
      "epoch": 8.046983959176204,
      "grad_norm": 0.500067949295044,
      "learning_rate": 0.00010629398486256805,
      "loss": 0.3323,
      "step": 197900
    },
    {
      "epoch": 8.0510500742066,
      "grad_norm": 0.4519632160663605,
      "learning_rate": 0.00010607267737794892,
      "loss": 0.3324,
      "step": 198000
    },
    {
      "epoch": 8.0510500742066,
      "eval_loss": 0.35052525997161865,
      "eval_runtime": 114.8633,
      "eval_samples_per_second": 1522.696,
      "eval_steps_per_second": 47.587,
      "step": 198000
    },
    {
      "epoch": 8.055116189236994,
      "grad_norm": 0.43176114559173584,
      "learning_rate": 0.00010585136989332979,
      "loss": 0.3324,
      "step": 198100
    },
    {
      "epoch": 8.059182304267388,
      "grad_norm": 0.47420328855514526,
      "learning_rate": 0.00010563006240871066,
      "loss": 0.3305,
      "step": 198200
    },
    {
      "epoch": 8.063248419297782,
      "grad_norm": 0.3996661305427551,
      "learning_rate": 0.00010540875492409153,
      "loss": 0.332,
      "step": 198300
    },
    {
      "epoch": 8.067314534328176,
      "grad_norm": 0.4435218274593353,
      "learning_rate": 0.0001051874474394724,
      "loss": 0.3312,
      "step": 198400
    },
    {
      "epoch": 8.07138064935857,
      "grad_norm": 0.4440837502479553,
      "learning_rate": 0.00010496613995485329,
      "loss": 0.3326,
      "step": 198500
    },
    {
      "epoch": 8.075446764388964,
      "grad_norm": 0.41544362902641296,
      "learning_rate": 0.00010474483247023414,
      "loss": 0.3302,
      "step": 198600
    },
    {
      "epoch": 8.079512879419358,
      "grad_norm": 0.42395445704460144,
      "learning_rate": 0.00010452352498561501,
      "loss": 0.3317,
      "step": 198700
    },
    {
      "epoch": 8.083578994449754,
      "grad_norm": 0.40649721026420593,
      "learning_rate": 0.00010430221750099588,
      "loss": 0.3342,
      "step": 198800
    },
    {
      "epoch": 8.087645109480148,
      "grad_norm": 0.4820978045463562,
      "learning_rate": 0.00010408091001637677,
      "loss": 0.3323,
      "step": 198900
    },
    {
      "epoch": 8.091711224510542,
      "grad_norm": 0.44817426800727844,
      "learning_rate": 0.00010385960253175762,
      "loss": 0.3319,
      "step": 199000
    },
    {
      "epoch": 8.095777339540936,
      "grad_norm": 0.44758230447769165,
      "learning_rate": 0.0001036382950471385,
      "loss": 0.3337,
      "step": 199100
    },
    {
      "epoch": 8.09984345457133,
      "grad_norm": 0.43648603558540344,
      "learning_rate": 0.00010341698756251936,
      "loss": 0.333,
      "step": 199200
    },
    {
      "epoch": 8.103909569601724,
      "grad_norm": 0.4062255918979645,
      "learning_rate": 0.00010319568007790025,
      "loss": 0.3328,
      "step": 199300
    },
    {
      "epoch": 8.107975684632118,
      "grad_norm": 0.44130825996398926,
      "learning_rate": 0.0001029743725932811,
      "loss": 0.3322,
      "step": 199400
    },
    {
      "epoch": 8.112041799662512,
      "grad_norm": 0.4393887221813202,
      "learning_rate": 0.00010275306510866198,
      "loss": 0.3327,
      "step": 199500
    },
    {
      "epoch": 8.116107914692906,
      "grad_norm": 0.45154228806495667,
      "learning_rate": 0.00010253175762404285,
      "loss": 0.3333,
      "step": 199600
    },
    {
      "epoch": 8.120174029723302,
      "grad_norm": 0.44698190689086914,
      "learning_rate": 0.00010231045013942372,
      "loss": 0.3325,
      "step": 199700
    },
    {
      "epoch": 8.124240144753696,
      "grad_norm": 0.4447499215602875,
      "learning_rate": 0.00010208914265480459,
      "loss": 0.3304,
      "step": 199800
    },
    {
      "epoch": 8.12830625978409,
      "grad_norm": 0.4050416350364685,
      "learning_rate": 0.00010186783517018546,
      "loss": 0.3338,
      "step": 199900
    },
    {
      "epoch": 8.132372374814484,
      "grad_norm": 0.44197699427604675,
      "learning_rate": 0.00010164652768556633,
      "loss": 0.3328,
      "step": 200000
    },
    {
      "epoch": 8.132372374814484,
      "eval_loss": 0.350136399269104,
      "eval_runtime": 114.4254,
      "eval_samples_per_second": 1528.525,
      "eval_steps_per_second": 47.769,
      "step": 200000
    },
    {
      "epoch": 8.136438489844878,
      "grad_norm": 0.43101775646209717,
      "learning_rate": 0.0001014252202009472,
      "loss": 0.3325,
      "step": 200100
    },
    {
      "epoch": 8.140504604875272,
      "grad_norm": 0.47205477952957153,
      "learning_rate": 0.00010120391271632807,
      "loss": 0.333,
      "step": 200200
    },
    {
      "epoch": 8.144570719905666,
      "grad_norm": 0.3937542736530304,
      "learning_rate": 0.00010098260523170894,
      "loss": 0.3324,
      "step": 200300
    },
    {
      "epoch": 8.14863683493606,
      "grad_norm": 0.4580889940261841,
      "learning_rate": 0.00010076129774708981,
      "loss": 0.334,
      "step": 200400
    },
    {
      "epoch": 8.152702949966455,
      "grad_norm": 0.47757411003112793,
      "learning_rate": 0.00010053999026247068,
      "loss": 0.3334,
      "step": 200500
    },
    {
      "epoch": 8.15676906499685,
      "grad_norm": 0.3840838074684143,
      "learning_rate": 0.00010031868277785156,
      "loss": 0.3328,
      "step": 200600
    },
    {
      "epoch": 8.160835180027243,
      "grad_norm": 0.45445066690444946,
      "learning_rate": 0.00010009737529323242,
      "loss": 0.3316,
      "step": 200700
    },
    {
      "epoch": 8.164901295057637,
      "grad_norm": 0.38352325558662415,
      "learning_rate": 9.987606780861329e-05,
      "loss": 0.3324,
      "step": 200800
    },
    {
      "epoch": 8.168967410088031,
      "grad_norm": 0.45400771498680115,
      "learning_rate": 9.965476032399416e-05,
      "loss": 0.3318,
      "step": 200900
    },
    {
      "epoch": 8.173033525118425,
      "grad_norm": 0.5084940791130066,
      "learning_rate": 9.943345283937503e-05,
      "loss": 0.3338,
      "step": 201000
    },
    {
      "epoch": 8.17709964014882,
      "grad_norm": 0.4427659213542938,
      "learning_rate": 9.92121453547559e-05,
      "loss": 0.3331,
      "step": 201100
    },
    {
      "epoch": 8.181165755179213,
      "grad_norm": 0.4168813228607178,
      "learning_rate": 9.899083787013677e-05,
      "loss": 0.3296,
      "step": 201200
    },
    {
      "epoch": 8.185231870209607,
      "grad_norm": 0.4358823299407959,
      "learning_rate": 9.876953038551764e-05,
      "loss": 0.3321,
      "step": 201300
    },
    {
      "epoch": 8.189297985240003,
      "grad_norm": 0.43689244985580444,
      "learning_rate": 9.854822290089851e-05,
      "loss": 0.3316,
      "step": 201400
    },
    {
      "epoch": 8.193364100270397,
      "grad_norm": 0.46038028597831726,
      "learning_rate": 9.832691541627938e-05,
      "loss": 0.3345,
      "step": 201500
    },
    {
      "epoch": 8.197430215300791,
      "grad_norm": 0.4478287398815155,
      "learning_rate": 9.810560793166025e-05,
      "loss": 0.3341,
      "step": 201600
    },
    {
      "epoch": 8.201496330331185,
      "grad_norm": 0.43594321608543396,
      "learning_rate": 9.788430044704112e-05,
      "loss": 0.3321,
      "step": 201700
    },
    {
      "epoch": 8.20556244536158,
      "grad_norm": 0.44080591201782227,
      "learning_rate": 9.766299296242199e-05,
      "loss": 0.3338,
      "step": 201800
    },
    {
      "epoch": 8.209628560391973,
      "grad_norm": 0.4337176978588104,
      "learning_rate": 9.744168547780286e-05,
      "loss": 0.3333,
      "step": 201900
    },
    {
      "epoch": 8.213694675422367,
      "grad_norm": 0.3943593204021454,
      "learning_rate": 9.722037799318373e-05,
      "loss": 0.3327,
      "step": 202000
    },
    {
      "epoch": 8.213694675422367,
      "eval_loss": 0.3498360514640808,
      "eval_runtime": 114.5505,
      "eval_samples_per_second": 1526.854,
      "eval_steps_per_second": 47.717,
      "step": 202000
    },
    {
      "epoch": 8.217760790452761,
      "grad_norm": 0.5314409136772156,
      "learning_rate": 9.69990705085646e-05,
      "loss": 0.3317,
      "step": 202100
    },
    {
      "epoch": 8.221826905483157,
      "grad_norm": 0.4616177976131439,
      "learning_rate": 9.677776302394547e-05,
      "loss": 0.3328,
      "step": 202200
    },
    {
      "epoch": 8.225893020513551,
      "grad_norm": 0.46015051007270813,
      "learning_rate": 9.655645553932636e-05,
      "loss": 0.3326,
      "step": 202300
    },
    {
      "epoch": 8.229959135543945,
      "grad_norm": 0.4665873050689697,
      "learning_rate": 9.633514805470721e-05,
      "loss": 0.333,
      "step": 202400
    },
    {
      "epoch": 8.234025250574339,
      "grad_norm": 0.4624031186103821,
      "learning_rate": 9.611384057008808e-05,
      "loss": 0.3333,
      "step": 202500
    },
    {
      "epoch": 8.238091365604733,
      "grad_norm": 0.4268178343772888,
      "learning_rate": 9.589253308546895e-05,
      "loss": 0.3329,
      "step": 202600
    },
    {
      "epoch": 8.242157480635127,
      "grad_norm": 0.42120161652565,
      "learning_rate": 9.567122560084982e-05,
      "loss": 0.333,
      "step": 202700
    },
    {
      "epoch": 8.246223595665521,
      "grad_norm": 0.4608185291290283,
      "learning_rate": 9.544991811623069e-05,
      "loss": 0.3322,
      "step": 202800
    },
    {
      "epoch": 8.250289710695915,
      "grad_norm": 0.5300644040107727,
      "learning_rate": 9.522861063161156e-05,
      "loss": 0.3346,
      "step": 202900
    },
    {
      "epoch": 8.254355825726309,
      "grad_norm": 0.4546145498752594,
      "learning_rate": 9.500730314699243e-05,
      "loss": 0.3333,
      "step": 203000
    },
    {
      "epoch": 8.258421940756705,
      "grad_norm": 0.4155733287334442,
      "learning_rate": 9.47859956623733e-05,
      "loss": 0.3322,
      "step": 203100
    },
    {
      "epoch": 8.262488055787099,
      "grad_norm": 0.41301703453063965,
      "learning_rate": 9.456468817775417e-05,
      "loss": 0.3315,
      "step": 203200
    },
    {
      "epoch": 8.266554170817493,
      "grad_norm": 0.46367013454437256,
      "learning_rate": 9.434338069313504e-05,
      "loss": 0.3341,
      "step": 203300
    },
    {
      "epoch": 8.270620285847887,
      "grad_norm": 0.49886175990104675,
      "learning_rate": 9.412207320851591e-05,
      "loss": 0.3323,
      "step": 203400
    },
    {
      "epoch": 8.27468640087828,
      "grad_norm": 0.4474438428878784,
      "learning_rate": 9.390076572389678e-05,
      "loss": 0.3344,
      "step": 203500
    },
    {
      "epoch": 8.278752515908675,
      "grad_norm": 0.5216431617736816,
      "learning_rate": 9.367945823927765e-05,
      "loss": 0.3332,
      "step": 203600
    },
    {
      "epoch": 8.282818630939069,
      "grad_norm": 0.5447733998298645,
      "learning_rate": 9.345815075465852e-05,
      "loss": 0.3313,
      "step": 203700
    },
    {
      "epoch": 8.286884745969463,
      "grad_norm": 0.4453809857368469,
      "learning_rate": 9.32368432700394e-05,
      "loss": 0.3326,
      "step": 203800
    },
    {
      "epoch": 8.290950860999857,
      "grad_norm": 0.4196682274341583,
      "learning_rate": 9.301553578542027e-05,
      "loss": 0.3318,
      "step": 203900
    },
    {
      "epoch": 8.295016976030253,
      "grad_norm": 0.45294129848480225,
      "learning_rate": 9.279422830080112e-05,
      "loss": 0.3318,
      "step": 204000
    },
    {
      "epoch": 8.295016976030253,
      "eval_loss": 0.3490455746650696,
      "eval_runtime": 114.3341,
      "eval_samples_per_second": 1529.744,
      "eval_steps_per_second": 47.807,
      "step": 204000
    },
    {
      "epoch": 8.299083091060647,
      "grad_norm": 0.4837310016155243,
      "learning_rate": 9.2572920816182e-05,
      "loss": 0.3334,
      "step": 204100
    },
    {
      "epoch": 8.30314920609104,
      "grad_norm": 0.43817228078842163,
      "learning_rate": 9.235161333156288e-05,
      "loss": 0.3325,
      "step": 204200
    },
    {
      "epoch": 8.307215321121435,
      "grad_norm": 0.4425993859767914,
      "learning_rate": 9.213030584694375e-05,
      "loss": 0.3328,
      "step": 204300
    },
    {
      "epoch": 8.311281436151829,
      "grad_norm": 0.46717971563339233,
      "learning_rate": 9.190899836232462e-05,
      "loss": 0.3341,
      "step": 204400
    },
    {
      "epoch": 8.315347551182223,
      "grad_norm": 0.46433568000793457,
      "learning_rate": 9.168769087770549e-05,
      "loss": 0.332,
      "step": 204500
    },
    {
      "epoch": 8.319413666212617,
      "grad_norm": 0.4632318615913391,
      "learning_rate": 9.146638339308636e-05,
      "loss": 0.3335,
      "step": 204600
    },
    {
      "epoch": 8.32347978124301,
      "grad_norm": 0.47236189246177673,
      "learning_rate": 9.124507590846723e-05,
      "loss": 0.3336,
      "step": 204700
    },
    {
      "epoch": 8.327545896273406,
      "grad_norm": 0.4440281093120575,
      "learning_rate": 9.10237684238481e-05,
      "loss": 0.3313,
      "step": 204800
    },
    {
      "epoch": 8.3316120113038,
      "grad_norm": 0.42044252157211304,
      "learning_rate": 9.080246093922897e-05,
      "loss": 0.3319,
      "step": 204900
    },
    {
      "epoch": 8.335678126334194,
      "grad_norm": 0.41408848762512207,
      "learning_rate": 9.058115345460984e-05,
      "loss": 0.3315,
      "step": 205000
    },
    {
      "epoch": 8.339744241364588,
      "grad_norm": 0.4749205410480499,
      "learning_rate": 9.035984596999071e-05,
      "loss": 0.333,
      "step": 205100
    },
    {
      "epoch": 8.343810356394982,
      "grad_norm": 0.4391273558139801,
      "learning_rate": 9.013853848537158e-05,
      "loss": 0.332,
      "step": 205200
    },
    {
      "epoch": 8.347876471425376,
      "grad_norm": 0.5123189091682434,
      "learning_rate": 8.991723100075245e-05,
      "loss": 0.3321,
      "step": 205300
    },
    {
      "epoch": 8.35194258645577,
      "grad_norm": 0.47600993514060974,
      "learning_rate": 8.969592351613332e-05,
      "loss": 0.3323,
      "step": 205400
    },
    {
      "epoch": 8.356008701486164,
      "grad_norm": 0.4870377480983734,
      "learning_rate": 8.947461603151419e-05,
      "loss": 0.3323,
      "step": 205500
    },
    {
      "epoch": 8.360074816516558,
      "grad_norm": 0.43006470799446106,
      "learning_rate": 8.925330854689506e-05,
      "loss": 0.3335,
      "step": 205600
    },
    {
      "epoch": 8.364140931546954,
      "grad_norm": 0.4554872214794159,
      "learning_rate": 8.903200106227592e-05,
      "loss": 0.3319,
      "step": 205700
    },
    {
      "epoch": 8.368207046577348,
      "grad_norm": 0.4889041483402252,
      "learning_rate": 8.88106935776568e-05,
      "loss": 0.3329,
      "step": 205800
    },
    {
      "epoch": 8.372273161607742,
      "grad_norm": 0.4414113759994507,
      "learning_rate": 8.858938609303767e-05,
      "loss": 0.3321,
      "step": 205900
    },
    {
      "epoch": 8.376339276638136,
      "grad_norm": 0.39764800667762756,
      "learning_rate": 8.836807860841854e-05,
      "loss": 0.3331,
      "step": 206000
    },
    {
      "epoch": 8.376339276638136,
      "eval_loss": 0.34842437505722046,
      "eval_runtime": 114.8858,
      "eval_samples_per_second": 1522.398,
      "eval_steps_per_second": 47.578,
      "step": 206000
    },
    {
      "epoch": 8.38040539166853,
      "grad_norm": 0.47803789377212524,
      "learning_rate": 8.81467711237994e-05,
      "loss": 0.3332,
      "step": 206100
    },
    {
      "epoch": 8.384471506698924,
      "grad_norm": 0.5088308453559875,
      "learning_rate": 8.792546363918028e-05,
      "loss": 0.3332,
      "step": 206200
    },
    {
      "epoch": 8.388537621729318,
      "grad_norm": 0.4298187792301178,
      "learning_rate": 8.770415615456115e-05,
      "loss": 0.3324,
      "step": 206300
    },
    {
      "epoch": 8.392603736759712,
      "grad_norm": 0.41452428698539734,
      "learning_rate": 8.748284866994202e-05,
      "loss": 0.3354,
      "step": 206400
    },
    {
      "epoch": 8.396669851790108,
      "grad_norm": 0.43571722507476807,
      "learning_rate": 8.726154118532289e-05,
      "loss": 0.3327,
      "step": 206500
    },
    {
      "epoch": 8.400735966820502,
      "grad_norm": 0.47044801712036133,
      "learning_rate": 8.704023370070376e-05,
      "loss": 0.3322,
      "step": 206600
    },
    {
      "epoch": 8.404802081850896,
      "grad_norm": 0.4334047734737396,
      "learning_rate": 8.681892621608463e-05,
      "loss": 0.334,
      "step": 206700
    },
    {
      "epoch": 8.40886819688129,
      "grad_norm": 0.5201693773269653,
      "learning_rate": 8.65976187314655e-05,
      "loss": 0.3324,
      "step": 206800
    },
    {
      "epoch": 8.412934311911684,
      "grad_norm": 0.4373643100261688,
      "learning_rate": 8.637631124684637e-05,
      "loss": 0.3328,
      "step": 206900
    },
    {
      "epoch": 8.417000426942078,
      "grad_norm": 0.45613226294517517,
      "learning_rate": 8.615500376222724e-05,
      "loss": 0.3325,
      "step": 207000
    },
    {
      "epoch": 8.421066541972472,
      "grad_norm": 0.4165651798248291,
      "learning_rate": 8.593369627760811e-05,
      "loss": 0.3295,
      "step": 207100
    },
    {
      "epoch": 8.425132657002866,
      "grad_norm": 0.42296016216278076,
      "learning_rate": 8.571238879298898e-05,
      "loss": 0.3317,
      "step": 207200
    },
    {
      "epoch": 8.42919877203326,
      "grad_norm": 0.4653589725494385,
      "learning_rate": 8.549108130836985e-05,
      "loss": 0.3325,
      "step": 207300
    },
    {
      "epoch": 8.433264887063656,
      "grad_norm": 0.42224353551864624,
      "learning_rate": 8.526977382375071e-05,
      "loss": 0.3331,
      "step": 207400
    },
    {
      "epoch": 8.43733100209405,
      "grad_norm": 0.45321160554885864,
      "learning_rate": 8.504846633913159e-05,
      "loss": 0.3319,
      "step": 207500
    },
    {
      "epoch": 8.441397117124444,
      "grad_norm": 0.46834883093833923,
      "learning_rate": 8.482715885451246e-05,
      "loss": 0.3307,
      "step": 207600
    },
    {
      "epoch": 8.445463232154838,
      "grad_norm": 0.4462485909461975,
      "learning_rate": 8.460585136989333e-05,
      "loss": 0.3322,
      "step": 207700
    },
    {
      "epoch": 8.449529347185232,
      "grad_norm": 0.4625745713710785,
      "learning_rate": 8.438454388527419e-05,
      "loss": 0.3296,
      "step": 207800
    },
    {
      "epoch": 8.453595462215626,
      "grad_norm": 0.4504599869251251,
      "learning_rate": 8.416323640065507e-05,
      "loss": 0.3306,
      "step": 207900
    },
    {
      "epoch": 8.45766157724602,
      "grad_norm": 0.47711044549942017,
      "learning_rate": 8.394192891603594e-05,
      "loss": 0.3325,
      "step": 208000
    },
    {
      "epoch": 8.45766157724602,
      "eval_loss": 0.3478941321372986,
      "eval_runtime": 113.8684,
      "eval_samples_per_second": 1536.001,
      "eval_steps_per_second": 48.003,
      "step": 208000
    },
    {
      "epoch": 8.461727692276414,
      "grad_norm": 0.47198405861854553,
      "learning_rate": 8.372062143141681e-05,
      "loss": 0.332,
      "step": 208100
    },
    {
      "epoch": 8.46579380730681,
      "grad_norm": 0.5079105496406555,
      "learning_rate": 8.349931394679768e-05,
      "loss": 0.3316,
      "step": 208200
    },
    {
      "epoch": 8.469859922337204,
      "grad_norm": 0.4234296977519989,
      "learning_rate": 8.327800646217855e-05,
      "loss": 0.3307,
      "step": 208300
    },
    {
      "epoch": 8.473926037367598,
      "grad_norm": 0.47133564949035645,
      "learning_rate": 8.305669897755943e-05,
      "loss": 0.3325,
      "step": 208400
    },
    {
      "epoch": 8.477992152397992,
      "grad_norm": 0.44322487711906433,
      "learning_rate": 8.28353914929403e-05,
      "loss": 0.3324,
      "step": 208500
    },
    {
      "epoch": 8.482058267428386,
      "grad_norm": 0.4424481689929962,
      "learning_rate": 8.261408400832117e-05,
      "loss": 0.332,
      "step": 208600
    },
    {
      "epoch": 8.48612438245878,
      "grad_norm": 0.46383267641067505,
      "learning_rate": 8.239277652370202e-05,
      "loss": 0.3314,
      "step": 208700
    },
    {
      "epoch": 8.490190497489174,
      "grad_norm": 0.42706015706062317,
      "learning_rate": 8.21714690390829e-05,
      "loss": 0.3316,
      "step": 208800
    },
    {
      "epoch": 8.494256612519568,
      "grad_norm": 0.5286641120910645,
      "learning_rate": 8.195016155446378e-05,
      "loss": 0.3317,
      "step": 208900
    },
    {
      "epoch": 8.498322727549962,
      "grad_norm": 0.4600279629230499,
      "learning_rate": 8.172885406984465e-05,
      "loss": 0.3298,
      "step": 209000
    },
    {
      "epoch": 8.502388842580357,
      "grad_norm": 0.460407555103302,
      "learning_rate": 8.15075465852255e-05,
      "loss": 0.3307,
      "step": 209100
    },
    {
      "epoch": 8.506454957610751,
      "grad_norm": 0.4397556483745575,
      "learning_rate": 8.128623910060639e-05,
      "loss": 0.333,
      "step": 209200
    },
    {
      "epoch": 8.510521072641145,
      "grad_norm": 0.4570247232913971,
      "learning_rate": 8.106493161598726e-05,
      "loss": 0.3319,
      "step": 209300
    },
    {
      "epoch": 8.51458718767154,
      "grad_norm": 0.4815148711204529,
      "learning_rate": 8.084362413136813e-05,
      "loss": 0.3318,
      "step": 209400
    },
    {
      "epoch": 8.518653302701933,
      "grad_norm": 0.4599582552909851,
      "learning_rate": 8.062231664674898e-05,
      "loss": 0.3332,
      "step": 209500
    },
    {
      "epoch": 8.522719417732327,
      "grad_norm": 0.5078366994857788,
      "learning_rate": 8.040100916212987e-05,
      "loss": 0.3307,
      "step": 209600
    },
    {
      "epoch": 8.526785532762721,
      "grad_norm": 0.47295936942100525,
      "learning_rate": 8.017970167751074e-05,
      "loss": 0.3312,
      "step": 209700
    },
    {
      "epoch": 8.530851647793115,
      "grad_norm": 0.47821685671806335,
      "learning_rate": 7.995839419289161e-05,
      "loss": 0.3314,
      "step": 209800
    },
    {
      "epoch": 8.534917762823511,
      "grad_norm": 0.41847625374794006,
      "learning_rate": 7.973708670827246e-05,
      "loss": 0.3305,
      "step": 209900
    },
    {
      "epoch": 8.538983877853905,
      "grad_norm": 0.43771645426750183,
      "learning_rate": 7.951577922365335e-05,
      "loss": 0.3325,
      "step": 210000
    },
    {
      "epoch": 8.538983877853905,
      "eval_loss": 0.34754273295402527,
      "eval_runtime": 113.5663,
      "eval_samples_per_second": 1540.087,
      "eval_steps_per_second": 48.13,
      "step": 210000
    },
    {
      "epoch": 8.5430499928843,
      "grad_norm": 0.5875128507614136,
      "learning_rate": 7.929447173903422e-05,
      "loss": 0.333,
      "step": 210100
    },
    {
      "epoch": 8.547116107914693,
      "grad_norm": 0.4762771427631378,
      "learning_rate": 7.907316425441509e-05,
      "loss": 0.3335,
      "step": 210200
    },
    {
      "epoch": 8.551182222945087,
      "grad_norm": 0.42494919896125793,
      "learning_rate": 7.885185676979596e-05,
      "loss": 0.3322,
      "step": 210300
    },
    {
      "epoch": 8.555248337975481,
      "grad_norm": 0.46881750226020813,
      "learning_rate": 7.863054928517682e-05,
      "loss": 0.3329,
      "step": 210400
    },
    {
      "epoch": 8.559314453005875,
      "grad_norm": 0.4897269904613495,
      "learning_rate": 7.84092418005577e-05,
      "loss": 0.3309,
      "step": 210500
    },
    {
      "epoch": 8.56338056803627,
      "grad_norm": 0.4622875154018402,
      "learning_rate": 7.818793431593857e-05,
      "loss": 0.3323,
      "step": 210600
    },
    {
      "epoch": 8.567446683066663,
      "grad_norm": 0.5130023956298828,
      "learning_rate": 7.796662683131944e-05,
      "loss": 0.3322,
      "step": 210700
    },
    {
      "epoch": 8.571512798097059,
      "grad_norm": 0.5736634135246277,
      "learning_rate": 7.77453193467003e-05,
      "loss": 0.3318,
      "step": 210800
    },
    {
      "epoch": 8.575578913127453,
      "grad_norm": 0.4920400083065033,
      "learning_rate": 7.752401186208118e-05,
      "loss": 0.3325,
      "step": 210900
    },
    {
      "epoch": 8.579645028157847,
      "grad_norm": 0.5604576468467712,
      "learning_rate": 7.730270437746205e-05,
      "loss": 0.333,
      "step": 211000
    },
    {
      "epoch": 8.583711143188241,
      "grad_norm": 0.4834870398044586,
      "learning_rate": 7.708139689284292e-05,
      "loss": 0.3323,
      "step": 211100
    },
    {
      "epoch": 8.587777258218635,
      "grad_norm": 0.5892523527145386,
      "learning_rate": 7.686008940822378e-05,
      "loss": 0.3299,
      "step": 211200
    },
    {
      "epoch": 8.591843373249029,
      "grad_norm": 0.4862620234489441,
      "learning_rate": 7.663878192360466e-05,
      "loss": 0.3306,
      "step": 211300
    },
    {
      "epoch": 8.595909488279423,
      "grad_norm": 0.46236446499824524,
      "learning_rate": 7.641747443898553e-05,
      "loss": 0.3323,
      "step": 211400
    },
    {
      "epoch": 8.599975603309817,
      "grad_norm": 0.4774887263774872,
      "learning_rate": 7.61961669543664e-05,
      "loss": 0.3325,
      "step": 211500
    },
    {
      "epoch": 8.604041718340213,
      "grad_norm": 0.6245965361595154,
      "learning_rate": 7.597485946974726e-05,
      "loss": 0.333,
      "step": 211600
    },
    {
      "epoch": 8.608107833370607,
      "grad_norm": 0.48872989416122437,
      "learning_rate": 7.575355198512814e-05,
      "loss": 0.3321,
      "step": 211700
    },
    {
      "epoch": 8.612173948401,
      "grad_norm": 0.4844626188278198,
      "learning_rate": 7.553224450050901e-05,
      "loss": 0.3307,
      "step": 211800
    },
    {
      "epoch": 8.616240063431395,
      "grad_norm": 0.4800538122653961,
      "learning_rate": 7.531093701588988e-05,
      "loss": 0.3297,
      "step": 211900
    },
    {
      "epoch": 8.620306178461789,
      "grad_norm": 0.4963747560977936,
      "learning_rate": 7.508962953127074e-05,
      "loss": 0.3302,
      "step": 212000
    },
    {
      "epoch": 8.620306178461789,
      "eval_loss": 0.34658172726631165,
      "eval_runtime": 113.717,
      "eval_samples_per_second": 1538.046,
      "eval_steps_per_second": 48.067,
      "step": 212000
    },
    {
      "epoch": 8.624372293492183,
      "grad_norm": 0.4769459664821625,
      "learning_rate": 7.486832204665161e-05,
      "loss": 0.3317,
      "step": 212100
    },
    {
      "epoch": 8.628438408522577,
      "grad_norm": 0.47912073135375977,
      "learning_rate": 7.46470145620325e-05,
      "loss": 0.3296,
      "step": 212200
    },
    {
      "epoch": 8.63250452355297,
      "grad_norm": 0.4546780586242676,
      "learning_rate": 7.442570707741336e-05,
      "loss": 0.3305,
      "step": 212300
    },
    {
      "epoch": 8.636570638583365,
      "grad_norm": 0.5071712732315063,
      "learning_rate": 7.420439959279423e-05,
      "loss": 0.3318,
      "step": 212400
    },
    {
      "epoch": 8.64063675361376,
      "grad_norm": 0.5401533246040344,
      "learning_rate": 7.398309210817509e-05,
      "loss": 0.3333,
      "step": 212500
    },
    {
      "epoch": 8.644702868644154,
      "grad_norm": 0.46905073523521423,
      "learning_rate": 7.376178462355597e-05,
      "loss": 0.3304,
      "step": 212600
    },
    {
      "epoch": 8.648768983674548,
      "grad_norm": 0.5431610345840454,
      "learning_rate": 7.354047713893684e-05,
      "loss": 0.3313,
      "step": 212700
    },
    {
      "epoch": 8.652835098704942,
      "grad_norm": 0.41588273644447327,
      "learning_rate": 7.331916965431771e-05,
      "loss": 0.3314,
      "step": 212800
    },
    {
      "epoch": 8.656901213735336,
      "grad_norm": 0.48443928360939026,
      "learning_rate": 7.309786216969857e-05,
      "loss": 0.3311,
      "step": 212900
    },
    {
      "epoch": 8.66096732876573,
      "grad_norm": 0.5397329330444336,
      "learning_rate": 7.287655468507946e-05,
      "loss": 0.3302,
      "step": 213000
    },
    {
      "epoch": 8.665033443796125,
      "grad_norm": 0.47253331542015076,
      "learning_rate": 7.265524720046033e-05,
      "loss": 0.3289,
      "step": 213100
    },
    {
      "epoch": 8.669099558826519,
      "grad_norm": 0.48264607787132263,
      "learning_rate": 7.24339397158412e-05,
      "loss": 0.3305,
      "step": 213200
    },
    {
      "epoch": 8.673165673856914,
      "grad_norm": 0.4476125240325928,
      "learning_rate": 7.221263223122205e-05,
      "loss": 0.3296,
      "step": 213300
    },
    {
      "epoch": 8.677231788887308,
      "grad_norm": 0.5078252553939819,
      "learning_rate": 7.199132474660292e-05,
      "loss": 0.331,
      "step": 213400
    },
    {
      "epoch": 8.681297903917702,
      "grad_norm": 0.47529417276382446,
      "learning_rate": 7.17700172619838e-05,
      "loss": 0.3305,
      "step": 213500
    },
    {
      "epoch": 8.685364018948096,
      "grad_norm": 0.5254806280136108,
      "learning_rate": 7.154870977736468e-05,
      "loss": 0.3332,
      "step": 213600
    },
    {
      "epoch": 8.68943013397849,
      "grad_norm": 0.5164546370506287,
      "learning_rate": 7.132740229274553e-05,
      "loss": 0.3283,
      "step": 213700
    },
    {
      "epoch": 8.693496249008884,
      "grad_norm": 0.5053397417068481,
      "learning_rate": 7.11060948081264e-05,
      "loss": 0.3294,
      "step": 213800
    },
    {
      "epoch": 8.697562364039278,
      "grad_norm": 0.5191360116004944,
      "learning_rate": 7.088478732350729e-05,
      "loss": 0.3307,
      "step": 213900
    },
    {
      "epoch": 8.701628479069672,
      "grad_norm": 0.4525315761566162,
      "learning_rate": 7.066347983888816e-05,
      "loss": 0.3301,
      "step": 214000
    },
    {
      "epoch": 8.701628479069672,
      "eval_loss": 0.3460606336593628,
      "eval_runtime": 114.7907,
      "eval_samples_per_second": 1523.661,
      "eval_steps_per_second": 47.617,
      "step": 214000
    },
    {
      "epoch": 8.705694594100066,
      "grad_norm": 0.39787527918815613,
      "learning_rate": 7.044217235426903e-05,
      "loss": 0.3293,
      "step": 214100
    },
    {
      "epoch": 8.709760709130462,
      "grad_norm": 0.5149434208869934,
      "learning_rate": 7.022086486964988e-05,
      "loss": 0.33,
      "step": 214200
    },
    {
      "epoch": 8.713826824160856,
      "grad_norm": 0.4480800926685333,
      "learning_rate": 6.999955738503077e-05,
      "loss": 0.3299,
      "step": 214300
    },
    {
      "epoch": 8.71789293919125,
      "grad_norm": 0.4480264484882355,
      "learning_rate": 6.977824990041164e-05,
      "loss": 0.3309,
      "step": 214400
    },
    {
      "epoch": 8.721959054221644,
      "grad_norm": 0.4824668765068054,
      "learning_rate": 6.955694241579251e-05,
      "loss": 0.3298,
      "step": 214500
    },
    {
      "epoch": 8.726025169252038,
      "grad_norm": 0.491759330034256,
      "learning_rate": 6.933563493117337e-05,
      "loss": 0.3307,
      "step": 214600
    },
    {
      "epoch": 8.730091284282432,
      "grad_norm": 0.49007514119148254,
      "learning_rate": 6.911432744655425e-05,
      "loss": 0.3297,
      "step": 214700
    },
    {
      "epoch": 8.734157399312826,
      "grad_norm": 0.4782603681087494,
      "learning_rate": 6.889301996193512e-05,
      "loss": 0.3316,
      "step": 214800
    },
    {
      "epoch": 8.73822351434322,
      "grad_norm": 0.4564664959907532,
      "learning_rate": 6.867171247731599e-05,
      "loss": 0.3314,
      "step": 214900
    },
    {
      "epoch": 8.742289629373616,
      "grad_norm": 0.5244478583335876,
      "learning_rate": 6.845040499269685e-05,
      "loss": 0.3316,
      "step": 215000
    },
    {
      "epoch": 8.74635574440401,
      "grad_norm": 0.4451081454753876,
      "learning_rate": 6.822909750807772e-05,
      "loss": 0.331,
      "step": 215100
    },
    {
      "epoch": 8.750421859434404,
      "grad_norm": 0.46913596987724304,
      "learning_rate": 6.80077900234586e-05,
      "loss": 0.333,
      "step": 215200
    },
    {
      "epoch": 8.754487974464798,
      "grad_norm": 0.4463059604167938,
      "learning_rate": 6.778648253883947e-05,
      "loss": 0.3295,
      "step": 215300
    },
    {
      "epoch": 8.758554089495192,
      "grad_norm": 0.4161628484725952,
      "learning_rate": 6.756517505422033e-05,
      "loss": 0.3317,
      "step": 215400
    },
    {
      "epoch": 8.762620204525586,
      "grad_norm": 0.4941028654575348,
      "learning_rate": 6.73438675696012e-05,
      "loss": 0.3291,
      "step": 215500
    },
    {
      "epoch": 8.76668631955598,
      "grad_norm": 0.5147081613540649,
      "learning_rate": 6.712256008498208e-05,
      "loss": 0.331,
      "step": 215600
    },
    {
      "epoch": 8.770752434586374,
      "grad_norm": 0.5110629796981812,
      "learning_rate": 6.690125260036295e-05,
      "loss": 0.3302,
      "step": 215700
    },
    {
      "epoch": 8.774818549616768,
      "grad_norm": 0.5002039074897766,
      "learning_rate": 6.667994511574381e-05,
      "loss": 0.3309,
      "step": 215800
    },
    {
      "epoch": 8.778884664647164,
      "grad_norm": 0.46053120493888855,
      "learning_rate": 6.645863763112468e-05,
      "loss": 0.3309,
      "step": 215900
    },
    {
      "epoch": 8.782950779677558,
      "grad_norm": 0.48951563239097595,
      "learning_rate": 6.623733014650556e-05,
      "loss": 0.3297,
      "step": 216000
    },
    {
      "epoch": 8.782950779677558,
      "eval_loss": 0.34552180767059326,
      "eval_runtime": 115.3637,
      "eval_samples_per_second": 1516.092,
      "eval_steps_per_second": 47.381,
      "step": 216000
    },
    {
      "epoch": 8.787016894707952,
      "grad_norm": 0.49616485834121704,
      "learning_rate": 6.601602266188643e-05,
      "loss": 0.3296,
      "step": 216100
    },
    {
      "epoch": 8.791083009738346,
      "grad_norm": 0.47129765152931213,
      "learning_rate": 6.57947151772673e-05,
      "loss": 0.3299,
      "step": 216200
    },
    {
      "epoch": 8.79514912476874,
      "grad_norm": 0.5985330939292908,
      "learning_rate": 6.557340769264816e-05,
      "loss": 0.3305,
      "step": 216300
    },
    {
      "epoch": 8.799215239799134,
      "grad_norm": 0.6023905873298645,
      "learning_rate": 6.535210020802904e-05,
      "loss": 0.3287,
      "step": 216400
    },
    {
      "epoch": 8.803281354829528,
      "grad_norm": 0.5155487060546875,
      "learning_rate": 6.513079272340991e-05,
      "loss": 0.3314,
      "step": 216500
    },
    {
      "epoch": 8.807347469859922,
      "grad_norm": 0.4736543595790863,
      "learning_rate": 6.490948523879078e-05,
      "loss": 0.3297,
      "step": 216600
    },
    {
      "epoch": 8.811413584890317,
      "grad_norm": 0.4867953956127167,
      "learning_rate": 6.468817775417164e-05,
      "loss": 0.3308,
      "step": 216700
    },
    {
      "epoch": 8.815479699920711,
      "grad_norm": 0.48850977420806885,
      "learning_rate": 6.446687026955251e-05,
      "loss": 0.3285,
      "step": 216800
    },
    {
      "epoch": 8.819545814951105,
      "grad_norm": 0.5199918746948242,
      "learning_rate": 6.42455627849334e-05,
      "loss": 0.3312,
      "step": 216900
    },
    {
      "epoch": 8.8236119299815,
      "grad_norm": 0.4638539254665375,
      "learning_rate": 6.402425530031426e-05,
      "loss": 0.3311,
      "step": 217000
    },
    {
      "epoch": 8.827678045011893,
      "grad_norm": 0.565899133682251,
      "learning_rate": 6.380294781569512e-05,
      "loss": 0.3312,
      "step": 217100
    },
    {
      "epoch": 8.831744160042287,
      "grad_norm": 0.4967825412750244,
      "learning_rate": 6.358164033107599e-05,
      "loss": 0.3291,
      "step": 217200
    },
    {
      "epoch": 8.835810275072681,
      "grad_norm": 0.4888254702091217,
      "learning_rate": 6.336033284645687e-05,
      "loss": 0.3306,
      "step": 217300
    },
    {
      "epoch": 8.839876390103075,
      "grad_norm": 0.4854496419429779,
      "learning_rate": 6.313902536183774e-05,
      "loss": 0.3312,
      "step": 217400
    },
    {
      "epoch": 8.84394250513347,
      "grad_norm": 0.48269420862197876,
      "learning_rate": 6.29177178772186e-05,
      "loss": 0.3293,
      "step": 217500
    },
    {
      "epoch": 8.848008620163865,
      "grad_norm": 0.5093843936920166,
      "learning_rate": 6.269641039259947e-05,
      "loss": 0.3291,
      "step": 217600
    },
    {
      "epoch": 8.85207473519426,
      "grad_norm": 0.5139695405960083,
      "learning_rate": 6.247510290798036e-05,
      "loss": 0.3308,
      "step": 217700
    },
    {
      "epoch": 8.856140850224653,
      "grad_norm": 0.499968945980072,
      "learning_rate": 6.225379542336121e-05,
      "loss": 0.3291,
      "step": 217800
    },
    {
      "epoch": 8.860206965255047,
      "grad_norm": 0.5079591274261475,
      "learning_rate": 6.20324879387421e-05,
      "loss": 0.3298,
      "step": 217900
    },
    {
      "epoch": 8.864273080285441,
      "grad_norm": 0.4484997093677521,
      "learning_rate": 6.181118045412297e-05,
      "loss": 0.3293,
      "step": 218000
    },
    {
      "epoch": 8.864273080285441,
      "eval_loss": 0.3447074890136719,
      "eval_runtime": 114.8194,
      "eval_samples_per_second": 1523.279,
      "eval_steps_per_second": 47.605,
      "step": 218000
    },
    {
      "epoch": 8.868339195315835,
      "grad_norm": 0.5049223303794861,
      "learning_rate": 6.158987296950382e-05,
      "loss": 0.3289,
      "step": 218100
    },
    {
      "epoch": 8.87240531034623,
      "grad_norm": 0.5625244379043579,
      "learning_rate": 6.13685654848847e-05,
      "loss": 0.33,
      "step": 218200
    },
    {
      "epoch": 8.876471425376623,
      "grad_norm": 0.543362557888031,
      "learning_rate": 6.114725800026556e-05,
      "loss": 0.3293,
      "step": 218300
    },
    {
      "epoch": 8.880537540407019,
      "grad_norm": 0.46938568353652954,
      "learning_rate": 6.092595051564644e-05,
      "loss": 0.3306,
      "step": 218400
    },
    {
      "epoch": 8.884603655437413,
      "grad_norm": 0.5053285360336304,
      "learning_rate": 6.070464303102731e-05,
      "loss": 0.33,
      "step": 218500
    },
    {
      "epoch": 8.888669770467807,
      "grad_norm": 0.49140751361846924,
      "learning_rate": 6.048333554640818e-05,
      "loss": 0.3293,
      "step": 218600
    },
    {
      "epoch": 8.892735885498201,
      "grad_norm": 0.4790773093700409,
      "learning_rate": 6.026202806178905e-05,
      "loss": 0.3294,
      "step": 218700
    },
    {
      "epoch": 8.896802000528595,
      "grad_norm": 0.5215588808059692,
      "learning_rate": 6.004072057716992e-05,
      "loss": 0.3295,
      "step": 218800
    },
    {
      "epoch": 8.900868115558989,
      "grad_norm": 0.4884876608848572,
      "learning_rate": 5.981941309255079e-05,
      "loss": 0.3273,
      "step": 218900
    },
    {
      "epoch": 8.904934230589383,
      "grad_norm": 0.4670581519603729,
      "learning_rate": 5.959810560793166e-05,
      "loss": 0.3289,
      "step": 219000
    },
    {
      "epoch": 8.909000345619777,
      "grad_norm": 0.5015098452568054,
      "learning_rate": 5.937679812331253e-05,
      "loss": 0.3295,
      "step": 219100
    },
    {
      "epoch": 8.913066460650171,
      "grad_norm": 0.46096232533454895,
      "learning_rate": 5.91554906386934e-05,
      "loss": 0.3294,
      "step": 219200
    },
    {
      "epoch": 8.917132575680567,
      "grad_norm": 0.55767422914505,
      "learning_rate": 5.893418315407427e-05,
      "loss": 0.3308,
      "step": 219300
    },
    {
      "epoch": 8.92119869071096,
      "grad_norm": 0.48656487464904785,
      "learning_rate": 5.871287566945514e-05,
      "loss": 0.3278,
      "step": 219400
    },
    {
      "epoch": 8.925264805741355,
      "grad_norm": 0.522264301776886,
      "learning_rate": 5.849156818483601e-05,
      "loss": 0.3298,
      "step": 219500
    },
    {
      "epoch": 8.929330920771749,
      "grad_norm": 0.4908585548400879,
      "learning_rate": 5.827026070021688e-05,
      "loss": 0.3291,
      "step": 219600
    },
    {
      "epoch": 8.933397035802143,
      "grad_norm": 0.5198734998703003,
      "learning_rate": 5.8048953215597747e-05,
      "loss": 0.3285,
      "step": 219700
    },
    {
      "epoch": 8.937463150832537,
      "grad_norm": 0.5797748565673828,
      "learning_rate": 5.7827645730978623e-05,
      "loss": 0.3292,
      "step": 219800
    },
    {
      "epoch": 8.94152926586293,
      "grad_norm": 0.5013983249664307,
      "learning_rate": 5.7606338246359494e-05,
      "loss": 0.3296,
      "step": 219900
    },
    {
      "epoch": 8.945595380893325,
      "grad_norm": 0.5310184955596924,
      "learning_rate": 5.7385030761740364e-05,
      "loss": 0.329,
      "step": 220000
    },
    {
      "epoch": 8.945595380893325,
      "eval_loss": 0.34425589442253113,
      "eval_runtime": 115.1702,
      "eval_samples_per_second": 1518.639,
      "eval_steps_per_second": 47.46,
      "step": 220000
    },
    {
      "epoch": 8.94966149592372,
      "grad_norm": 0.4478617012500763,
      "learning_rate": 5.7163723277121234e-05,
      "loss": 0.3297,
      "step": 220100
    },
    {
      "epoch": 8.953727610954115,
      "grad_norm": 0.5342764258384705,
      "learning_rate": 5.6942415792502104e-05,
      "loss": 0.3293,
      "step": 220200
    },
    {
      "epoch": 8.957793725984509,
      "grad_norm": 0.4424700140953064,
      "learning_rate": 5.6721108307882975e-05,
      "loss": 0.3296,
      "step": 220300
    },
    {
      "epoch": 8.961859841014903,
      "grad_norm": 0.5079405307769775,
      "learning_rate": 5.6499800823263845e-05,
      "loss": 0.3272,
      "step": 220400
    },
    {
      "epoch": 8.965925956045297,
      "grad_norm": 0.5136367678642273,
      "learning_rate": 5.6278493338644715e-05,
      "loss": 0.329,
      "step": 220500
    },
    {
      "epoch": 8.96999207107569,
      "grad_norm": 0.46083763241767883,
      "learning_rate": 5.6057185854025585e-05,
      "loss": 0.329,
      "step": 220600
    },
    {
      "epoch": 8.974058186106085,
      "grad_norm": 0.5490012168884277,
      "learning_rate": 5.5835878369406455e-05,
      "loss": 0.3285,
      "step": 220700
    },
    {
      "epoch": 8.978124301136479,
      "grad_norm": 0.49010318517684937,
      "learning_rate": 5.5614570884787326e-05,
      "loss": 0.3288,
      "step": 220800
    },
    {
      "epoch": 8.982190416166873,
      "grad_norm": 0.44290250539779663,
      "learning_rate": 5.5393263400168196e-05,
      "loss": 0.3292,
      "step": 220900
    },
    {
      "epoch": 8.986256531197267,
      "grad_norm": 0.5219035148620605,
      "learning_rate": 5.5171955915549066e-05,
      "loss": 0.3274,
      "step": 221000
    },
    {
      "epoch": 8.990322646227662,
      "grad_norm": 0.5165494084358215,
      "learning_rate": 5.4950648430929936e-05,
      "loss": 0.3292,
      "step": 221100
    },
    {
      "epoch": 8.994388761258056,
      "grad_norm": 0.6138957142829895,
      "learning_rate": 5.47293409463108e-05,
      "loss": 0.3309,
      "step": 221200
    },
    {
      "epoch": 8.99845487628845,
      "grad_norm": 0.5683607459068298,
      "learning_rate": 5.450803346169168e-05,
      "loss": 0.3285,
      "step": 221300
    },
    {
      "epoch": 9.002520991318844,
      "grad_norm": 0.4647732079029083,
      "learning_rate": 5.428672597707254e-05,
      "loss": 0.3239,
      "step": 221400
    },
    {
      "epoch": 9.006587106349238,
      "grad_norm": 0.5976124405860901,
      "learning_rate": 5.406541849245342e-05,
      "loss": 0.324,
      "step": 221500
    },
    {
      "epoch": 9.010653221379632,
      "grad_norm": 0.5002411603927612,
      "learning_rate": 5.384411100783428e-05,
      "loss": 0.3213,
      "step": 221600
    },
    {
      "epoch": 9.014719336410026,
      "grad_norm": 0.5222567915916443,
      "learning_rate": 5.362280352321516e-05,
      "loss": 0.3213,
      "step": 221700
    },
    {
      "epoch": 9.01878545144042,
      "grad_norm": 0.5842715501785278,
      "learning_rate": 5.340149603859602e-05,
      "loss": 0.3225,
      "step": 221800
    },
    {
      "epoch": 9.022851566470816,
      "grad_norm": 0.5231634378433228,
      "learning_rate": 5.31801885539769e-05,
      "loss": 0.3211,
      "step": 221900
    },
    {
      "epoch": 9.02691768150121,
      "grad_norm": 0.5213747620582581,
      "learning_rate": 5.295888106935777e-05,
      "loss": 0.3228,
      "step": 222000
    },
    {
      "epoch": 9.02691768150121,
      "eval_loss": 0.3443205952644348,
      "eval_runtime": 115.5479,
      "eval_samples_per_second": 1513.675,
      "eval_steps_per_second": 47.305,
      "step": 222000
    },
    {
      "epoch": 9.030983796531604,
      "grad_norm": 0.5165215730667114,
      "learning_rate": 5.273757358473864e-05,
      "loss": 0.3231,
      "step": 222100
    },
    {
      "epoch": 9.035049911561998,
      "grad_norm": 0.536141574382782,
      "learning_rate": 5.251626610011951e-05,
      "loss": 0.3237,
      "step": 222200
    },
    {
      "epoch": 9.039116026592392,
      "grad_norm": 0.5391598343849182,
      "learning_rate": 5.229495861550038e-05,
      "loss": 0.3227,
      "step": 222300
    },
    {
      "epoch": 9.043182141622786,
      "grad_norm": 0.512612521648407,
      "learning_rate": 5.207365113088125e-05,
      "loss": 0.3227,
      "step": 222400
    },
    {
      "epoch": 9.04724825665318,
      "grad_norm": 0.5639604330062866,
      "learning_rate": 5.185234364626212e-05,
      "loss": 0.3216,
      "step": 222500
    },
    {
      "epoch": 9.051314371683574,
      "grad_norm": 0.5115975737571716,
      "learning_rate": 5.163103616164299e-05,
      "loss": 0.3216,
      "step": 222600
    },
    {
      "epoch": 9.05538048671397,
      "grad_norm": 0.5718313455581665,
      "learning_rate": 5.140972867702385e-05,
      "loss": 0.3216,
      "step": 222700
    },
    {
      "epoch": 9.059446601744364,
      "grad_norm": 0.501792311668396,
      "learning_rate": 5.118842119240473e-05,
      "loss": 0.3215,
      "step": 222800
    },
    {
      "epoch": 9.063512716774758,
      "grad_norm": 0.5331548452377319,
      "learning_rate": 5.0967113707785594e-05,
      "loss": 0.3218,
      "step": 222900
    },
    {
      "epoch": 9.067578831805152,
      "grad_norm": 0.5041155815124512,
      "learning_rate": 5.074580622316647e-05,
      "loss": 0.3215,
      "step": 223000
    },
    {
      "epoch": 9.071644946835546,
      "grad_norm": 0.47525888681411743,
      "learning_rate": 5.0524498738547334e-05,
      "loss": 0.3231,
      "step": 223100
    },
    {
      "epoch": 9.07571106186594,
      "grad_norm": 0.4934643805027008,
      "learning_rate": 5.030319125392821e-05,
      "loss": 0.3211,
      "step": 223200
    },
    {
      "epoch": 9.079777176896334,
      "grad_norm": 0.5176284909248352,
      "learning_rate": 5.0081883769309074e-05,
      "loss": 0.321,
      "step": 223300
    },
    {
      "epoch": 9.083843291926728,
      "grad_norm": 0.5362722277641296,
      "learning_rate": 4.986057628468995e-05,
      "loss": 0.3222,
      "step": 223400
    },
    {
      "epoch": 9.087909406957122,
      "grad_norm": 0.5401734113693237,
      "learning_rate": 4.9639268800070815e-05,
      "loss": 0.3229,
      "step": 223500
    },
    {
      "epoch": 9.091975521987518,
      "grad_norm": 0.5547678470611572,
      "learning_rate": 4.941796131545169e-05,
      "loss": 0.323,
      "step": 223600
    },
    {
      "epoch": 9.096041637017912,
      "grad_norm": 0.5584995150566101,
      "learning_rate": 4.9196653830832555e-05,
      "loss": 0.3229,
      "step": 223700
    },
    {
      "epoch": 9.100107752048306,
      "grad_norm": 0.5385524034500122,
      "learning_rate": 4.897534634621343e-05,
      "loss": 0.3223,
      "step": 223800
    },
    {
      "epoch": 9.1041738670787,
      "grad_norm": 0.5719937682151794,
      "learning_rate": 4.87540388615943e-05,
      "loss": 0.323,
      "step": 223900
    },
    {
      "epoch": 9.108239982109094,
      "grad_norm": 0.5000250339508057,
      "learning_rate": 4.853273137697517e-05,
      "loss": 0.32,
      "step": 224000
    },
    {
      "epoch": 9.108239982109094,
      "eval_loss": 0.34406599402427673,
      "eval_runtime": 115.3968,
      "eval_samples_per_second": 1515.657,
      "eval_steps_per_second": 47.367,
      "step": 224000
    },
    {
      "epoch": 9.112306097139488,
      "grad_norm": 0.5019373893737793,
      "learning_rate": 4.831142389235604e-05,
      "loss": 0.3237,
      "step": 224100
    },
    {
      "epoch": 9.116372212169882,
      "grad_norm": 0.6004074215888977,
      "learning_rate": 4.809011640773691e-05,
      "loss": 0.322,
      "step": 224200
    },
    {
      "epoch": 9.120438327200276,
      "grad_norm": 0.5791239142417908,
      "learning_rate": 4.7868808923117783e-05,
      "loss": 0.3223,
      "step": 224300
    },
    {
      "epoch": 9.124504442230672,
      "grad_norm": 0.5277771353721619,
      "learning_rate": 4.764750143849865e-05,
      "loss": 0.3247,
      "step": 224400
    },
    {
      "epoch": 9.128570557261066,
      "grad_norm": 0.5411479473114014,
      "learning_rate": 4.7426193953879524e-05,
      "loss": 0.3208,
      "step": 224500
    },
    {
      "epoch": 9.13263667229146,
      "grad_norm": 0.5216279029846191,
      "learning_rate": 4.720488646926039e-05,
      "loss": 0.3215,
      "step": 224600
    },
    {
      "epoch": 9.136702787321854,
      "grad_norm": 0.48500728607177734,
      "learning_rate": 4.6983578984641264e-05,
      "loss": 0.3248,
      "step": 224700
    },
    {
      "epoch": 9.140768902352248,
      "grad_norm": 0.5746868252754211,
      "learning_rate": 4.676227150002213e-05,
      "loss": 0.3215,
      "step": 224800
    },
    {
      "epoch": 9.144835017382642,
      "grad_norm": 0.5466157793998718,
      "learning_rate": 4.6540964015403005e-05,
      "loss": 0.3216,
      "step": 224900
    },
    {
      "epoch": 9.148901132413036,
      "grad_norm": 0.6133995056152344,
      "learning_rate": 4.631965653078387e-05,
      "loss": 0.3229,
      "step": 225000
    },
    {
      "epoch": 9.15296724744343,
      "grad_norm": 0.5187009572982788,
      "learning_rate": 4.6098349046164745e-05,
      "loss": 0.3213,
      "step": 225100
    },
    {
      "epoch": 9.157033362473824,
      "grad_norm": 0.6049615740776062,
      "learning_rate": 4.587704156154561e-05,
      "loss": 0.3241,
      "step": 225200
    },
    {
      "epoch": 9.16109947750422,
      "grad_norm": 0.6618739366531372,
      "learning_rate": 4.5655734076926486e-05,
      "loss": 0.3222,
      "step": 225300
    },
    {
      "epoch": 9.165165592534613,
      "grad_norm": 0.5995904803276062,
      "learning_rate": 4.543442659230735e-05,
      "loss": 0.3237,
      "step": 225400
    },
    {
      "epoch": 9.169231707565007,
      "grad_norm": 0.5969778895378113,
      "learning_rate": 4.5213119107688226e-05,
      "loss": 0.3222,
      "step": 225500
    },
    {
      "epoch": 9.173297822595401,
      "grad_norm": 0.5301324725151062,
      "learning_rate": 4.499181162306909e-05,
      "loss": 0.3227,
      "step": 225600
    },
    {
      "epoch": 9.177363937625795,
      "grad_norm": 0.5480829477310181,
      "learning_rate": 4.4770504138449967e-05,
      "loss": 0.3228,
      "step": 225700
    },
    {
      "epoch": 9.18143005265619,
      "grad_norm": 0.5423291325569153,
      "learning_rate": 4.454919665383084e-05,
      "loss": 0.3218,
      "step": 225800
    },
    {
      "epoch": 9.185496167686583,
      "grad_norm": 0.563721776008606,
      "learning_rate": 4.43278891692117e-05,
      "loss": 0.3218,
      "step": 225900
    },
    {
      "epoch": 9.189562282716977,
      "grad_norm": 0.5657629370689392,
      "learning_rate": 4.410658168459258e-05,
      "loss": 0.3218,
      "step": 226000
    },
    {
      "epoch": 9.189562282716977,
      "eval_loss": 0.34340959787368774,
      "eval_runtime": 114.5987,
      "eval_samples_per_second": 1526.212,
      "eval_steps_per_second": 47.697,
      "step": 226000
    },
    {
      "epoch": 9.193628397747371,
      "grad_norm": 0.49949193000793457,
      "learning_rate": 4.388527419997344e-05,
      "loss": 0.322,
      "step": 226100
    },
    {
      "epoch": 9.197694512777767,
      "grad_norm": 0.6053012013435364,
      "learning_rate": 4.366396671535432e-05,
      "loss": 0.3215,
      "step": 226200
    },
    {
      "epoch": 9.201760627808161,
      "grad_norm": 0.5992075204849243,
      "learning_rate": 4.344265923073518e-05,
      "loss": 0.3229,
      "step": 226300
    },
    {
      "epoch": 9.205826742838555,
      "grad_norm": 0.5006710886955261,
      "learning_rate": 4.322135174611606e-05,
      "loss": 0.3227,
      "step": 226400
    },
    {
      "epoch": 9.20989285786895,
      "grad_norm": 0.5153858661651611,
      "learning_rate": 4.300004426149692e-05,
      "loss": 0.3232,
      "step": 226500
    },
    {
      "epoch": 9.213958972899343,
      "grad_norm": 0.5179495811462402,
      "learning_rate": 4.27787367768778e-05,
      "loss": 0.3238,
      "step": 226600
    },
    {
      "epoch": 9.218025087929737,
      "grad_norm": 0.5174803733825684,
      "learning_rate": 4.255742929225866e-05,
      "loss": 0.3234,
      "step": 226700
    },
    {
      "epoch": 9.222091202960131,
      "grad_norm": 0.5017304420471191,
      "learning_rate": 4.233612180763954e-05,
      "loss": 0.3225,
      "step": 226800
    },
    {
      "epoch": 9.226157317990525,
      "grad_norm": 0.5692875385284424,
      "learning_rate": 4.21148143230204e-05,
      "loss": 0.3214,
      "step": 226900
    },
    {
      "epoch": 9.230223433020921,
      "grad_norm": 0.5119971632957458,
      "learning_rate": 4.189350683840128e-05,
      "loss": 0.3214,
      "step": 227000
    },
    {
      "epoch": 9.234289548051315,
      "grad_norm": 0.5350836515426636,
      "learning_rate": 4.167219935378214e-05,
      "loss": 0.3227,
      "step": 227100
    },
    {
      "epoch": 9.238355663081709,
      "grad_norm": 0.559723973274231,
      "learning_rate": 4.145089186916302e-05,
      "loss": 0.3207,
      "step": 227200
    },
    {
      "epoch": 9.242421778112103,
      "grad_norm": 0.6291691660881042,
      "learning_rate": 4.122958438454388e-05,
      "loss": 0.3218,
      "step": 227300
    },
    {
      "epoch": 9.246487893142497,
      "grad_norm": 0.6304813623428345,
      "learning_rate": 4.1008276899924754e-05,
      "loss": 0.3222,
      "step": 227400
    },
    {
      "epoch": 9.250554008172891,
      "grad_norm": 0.5607988834381104,
      "learning_rate": 4.0786969415305624e-05,
      "loss": 0.3202,
      "step": 227500
    },
    {
      "epoch": 9.254620123203285,
      "grad_norm": 0.5859555602073669,
      "learning_rate": 4.0565661930686494e-05,
      "loss": 0.3202,
      "step": 227600
    },
    {
      "epoch": 9.258686238233679,
      "grad_norm": 0.595224142074585,
      "learning_rate": 4.0344354446067364e-05,
      "loss": 0.3204,
      "step": 227700
    },
    {
      "epoch": 9.262752353264073,
      "grad_norm": 0.6209589242935181,
      "learning_rate": 4.0123046961448234e-05,
      "loss": 0.3218,
      "step": 227800
    },
    {
      "epoch": 9.266818468294469,
      "grad_norm": 0.5387998223304749,
      "learning_rate": 3.990173947682911e-05,
      "loss": 0.3219,
      "step": 227900
    },
    {
      "epoch": 9.270884583324863,
      "grad_norm": 0.48028188943862915,
      "learning_rate": 3.9680431992209975e-05,
      "loss": 0.3213,
      "step": 228000
    },
    {
      "epoch": 9.270884583324863,
      "eval_loss": 0.34275442361831665,
      "eval_runtime": 113.1725,
      "eval_samples_per_second": 1545.446,
      "eval_steps_per_second": 48.298,
      "step": 228000
    },
    {
      "epoch": 9.274950698355257,
      "grad_norm": 0.5160180926322937,
      "learning_rate": 3.945912450759085e-05,
      "loss": 0.3209,
      "step": 228100
    },
    {
      "epoch": 9.27901681338565,
      "grad_norm": 0.6373993754386902,
      "learning_rate": 3.9237817022971715e-05,
      "loss": 0.3209,
      "step": 228200
    },
    {
      "epoch": 9.283082928416045,
      "grad_norm": 0.5872462391853333,
      "learning_rate": 3.901650953835259e-05,
      "loss": 0.3216,
      "step": 228300
    },
    {
      "epoch": 9.287149043446439,
      "grad_norm": 0.6098607182502747,
      "learning_rate": 3.8795202053733456e-05,
      "loss": 0.3218,
      "step": 228400
    },
    {
      "epoch": 9.291215158476833,
      "grad_norm": 0.5990544557571411,
      "learning_rate": 3.857389456911433e-05,
      "loss": 0.3229,
      "step": 228500
    },
    {
      "epoch": 9.295281273507227,
      "grad_norm": 0.5799218416213989,
      "learning_rate": 3.8352587084495196e-05,
      "loss": 0.323,
      "step": 228600
    },
    {
      "epoch": 9.299347388537623,
      "grad_norm": 0.681605339050293,
      "learning_rate": 3.813127959987607e-05,
      "loss": 0.3214,
      "step": 228700
    },
    {
      "epoch": 9.303413503568017,
      "grad_norm": 0.5808181166648865,
      "learning_rate": 3.7909972115256937e-05,
      "loss": 0.3209,
      "step": 228800
    },
    {
      "epoch": 9.30747961859841,
      "grad_norm": 0.5768256187438965,
      "learning_rate": 3.7688664630637814e-05,
      "loss": 0.3216,
      "step": 228900
    },
    {
      "epoch": 9.311545733628805,
      "grad_norm": 0.5543337464332581,
      "learning_rate": 3.746735714601868e-05,
      "loss": 0.3205,
      "step": 229000
    },
    {
      "epoch": 9.315611848659199,
      "grad_norm": 0.5622882843017578,
      "learning_rate": 3.724604966139955e-05,
      "loss": 0.322,
      "step": 229100
    },
    {
      "epoch": 9.319677963689593,
      "grad_norm": 0.5312137007713318,
      "learning_rate": 3.702474217678042e-05,
      "loss": 0.3214,
      "step": 229200
    },
    {
      "epoch": 9.323744078719987,
      "grad_norm": 0.4963032305240631,
      "learning_rate": 3.680343469216129e-05,
      "loss": 0.3209,
      "step": 229300
    },
    {
      "epoch": 9.32781019375038,
      "grad_norm": 0.5520665049552917,
      "learning_rate": 3.658212720754216e-05,
      "loss": 0.3212,
      "step": 229400
    },
    {
      "epoch": 9.331876308780775,
      "grad_norm": 0.561984121799469,
      "learning_rate": 3.636081972292303e-05,
      "loss": 0.3216,
      "step": 229500
    },
    {
      "epoch": 9.33594242381117,
      "grad_norm": 0.5393698215484619,
      "learning_rate": 3.61395122383039e-05,
      "loss": 0.3216,
      "step": 229600
    },
    {
      "epoch": 9.340008538841564,
      "grad_norm": 0.5577148795127869,
      "learning_rate": 3.591820475368477e-05,
      "loss": 0.3213,
      "step": 229700
    },
    {
      "epoch": 9.344074653871958,
      "grad_norm": 0.5867210030555725,
      "learning_rate": 3.5696897269065646e-05,
      "loss": 0.3225,
      "step": 229800
    },
    {
      "epoch": 9.348140768902352,
      "grad_norm": 0.5538598895072937,
      "learning_rate": 3.547558978444651e-05,
      "loss": 0.3222,
      "step": 229900
    },
    {
      "epoch": 9.352206883932746,
      "grad_norm": 0.6257975697517395,
      "learning_rate": 3.5254282299827386e-05,
      "loss": 0.3211,
      "step": 230000
    },
    {
      "epoch": 9.352206883932746,
      "eval_loss": 0.342229425907135,
      "eval_runtime": 112.7637,
      "eval_samples_per_second": 1551.049,
      "eval_steps_per_second": 48.473,
      "step": 230000
    },
    {
      "epoch": 9.35627299896314,
      "grad_norm": 0.5900530815124512,
      "learning_rate": 3.503297481520825e-05,
      "loss": 0.3214,
      "step": 230100
    },
    {
      "epoch": 9.360339113993534,
      "grad_norm": 0.587054967880249,
      "learning_rate": 3.4811667330589126e-05,
      "loss": 0.3238,
      "step": 230200
    },
    {
      "epoch": 9.364405229023928,
      "grad_norm": 0.5402547121047974,
      "learning_rate": 3.459035984596999e-05,
      "loss": 0.322,
      "step": 230300
    },
    {
      "epoch": 9.368471344054324,
      "grad_norm": 0.5851655602455139,
      "learning_rate": 3.436905236135087e-05,
      "loss": 0.3207,
      "step": 230400
    },
    {
      "epoch": 9.372537459084718,
      "grad_norm": 0.5725268125534058,
      "learning_rate": 3.414774487673173e-05,
      "loss": 0.3215,
      "step": 230500
    },
    {
      "epoch": 9.376603574115112,
      "grad_norm": 0.5488226413726807,
      "learning_rate": 3.39264373921126e-05,
      "loss": 0.3209,
      "step": 230600
    },
    {
      "epoch": 9.380669689145506,
      "grad_norm": 0.6002330183982849,
      "learning_rate": 3.370512990749347e-05,
      "loss": 0.3243,
      "step": 230700
    },
    {
      "epoch": 9.3847358041759,
      "grad_norm": 0.5580825209617615,
      "learning_rate": 3.348382242287434e-05,
      "loss": 0.3228,
      "step": 230800
    },
    {
      "epoch": 9.388801919206294,
      "grad_norm": 0.544996440410614,
      "learning_rate": 3.326251493825521e-05,
      "loss": 0.3214,
      "step": 230900
    },
    {
      "epoch": 9.392868034236688,
      "grad_norm": 0.5649847388267517,
      "learning_rate": 3.304120745363608e-05,
      "loss": 0.3211,
      "step": 231000
    },
    {
      "epoch": 9.396934149267082,
      "grad_norm": 0.6663061380386353,
      "learning_rate": 3.281989996901695e-05,
      "loss": 0.3225,
      "step": 231100
    },
    {
      "epoch": 9.401000264297476,
      "grad_norm": 0.66552734375,
      "learning_rate": 3.259859248439782e-05,
      "loss": 0.3199,
      "step": 231200
    },
    {
      "epoch": 9.405066379327872,
      "grad_norm": 0.5507941842079163,
      "learning_rate": 3.237728499977869e-05,
      "loss": 0.3235,
      "step": 231300
    },
    {
      "epoch": 9.409132494358266,
      "grad_norm": 0.6210348010063171,
      "learning_rate": 3.215597751515956e-05,
      "loss": 0.3242,
      "step": 231400
    },
    {
      "epoch": 9.41319860938866,
      "grad_norm": 0.5429226160049438,
      "learning_rate": 3.193467003054043e-05,
      "loss": 0.3216,
      "step": 231500
    },
    {
      "epoch": 9.417264724419054,
      "grad_norm": 0.5891621112823486,
      "learning_rate": 3.17133625459213e-05,
      "loss": 0.3223,
      "step": 231600
    },
    {
      "epoch": 9.421330839449448,
      "grad_norm": 0.6180939674377441,
      "learning_rate": 3.149205506130218e-05,
      "loss": 0.322,
      "step": 231700
    },
    {
      "epoch": 9.425396954479842,
      "grad_norm": 0.5902212262153625,
      "learning_rate": 3.127074757668304e-05,
      "loss": 0.3223,
      "step": 231800
    },
    {
      "epoch": 9.429463069510236,
      "grad_norm": 0.6314866542816162,
      "learning_rate": 3.1049440092063913e-05,
      "loss": 0.3213,
      "step": 231900
    },
    {
      "epoch": 9.43352918454063,
      "grad_norm": 0.5923019647598267,
      "learning_rate": 3.0828132607444784e-05,
      "loss": 0.3219,
      "step": 232000
    },
    {
      "epoch": 9.43352918454063,
      "eval_loss": 0.341636061668396,
      "eval_runtime": 112.9615,
      "eval_samples_per_second": 1548.333,
      "eval_steps_per_second": 48.388,
      "step": 232000
    },
    {
      "epoch": 9.437595299571026,
      "grad_norm": 0.5820648670196533,
      "learning_rate": 3.0606825122825654e-05,
      "loss": 0.3222,
      "step": 232100
    },
    {
      "epoch": 9.44166141460142,
      "grad_norm": 0.5740501880645752,
      "learning_rate": 3.0385517638206524e-05,
      "loss": 0.3198,
      "step": 232200
    },
    {
      "epoch": 9.445727529631814,
      "grad_norm": 0.6457056403160095,
      "learning_rate": 3.0164210153587394e-05,
      "loss": 0.3217,
      "step": 232300
    },
    {
      "epoch": 9.449793644662208,
      "grad_norm": 0.5711623430252075,
      "learning_rate": 2.9942902668968265e-05,
      "loss": 0.3202,
      "step": 232400
    },
    {
      "epoch": 9.453859759692602,
      "grad_norm": 0.5051748752593994,
      "learning_rate": 2.9721595184349135e-05,
      "loss": 0.3206,
      "step": 232500
    },
    {
      "epoch": 9.457925874722996,
      "grad_norm": 0.6338320374488831,
      "learning_rate": 2.9500287699730005e-05,
      "loss": 0.3209,
      "step": 232600
    },
    {
      "epoch": 9.46199198975339,
      "grad_norm": 0.585936963558197,
      "learning_rate": 2.927898021511088e-05,
      "loss": 0.3206,
      "step": 232700
    },
    {
      "epoch": 9.466058104783784,
      "grad_norm": 0.6332675814628601,
      "learning_rate": 2.905767273049175e-05,
      "loss": 0.3208,
      "step": 232800
    },
    {
      "epoch": 9.470124219814178,
      "grad_norm": 0.5672056674957275,
      "learning_rate": 2.8836365245872616e-05,
      "loss": 0.3213,
      "step": 232900
    },
    {
      "epoch": 9.474190334844574,
      "grad_norm": 0.5406581163406372,
      "learning_rate": 2.8615057761253486e-05,
      "loss": 0.3208,
      "step": 233000
    },
    {
      "epoch": 9.478256449874968,
      "grad_norm": 0.5773170590400696,
      "learning_rate": 2.8393750276634356e-05,
      "loss": 0.3215,
      "step": 233100
    },
    {
      "epoch": 9.482322564905362,
      "grad_norm": 0.6012770533561707,
      "learning_rate": 2.8172442792015226e-05,
      "loss": 0.3214,
      "step": 233200
    },
    {
      "epoch": 9.486388679935756,
      "grad_norm": 0.6037606596946716,
      "learning_rate": 2.7951135307396097e-05,
      "loss": 0.3202,
      "step": 233300
    },
    {
      "epoch": 9.49045479496615,
      "grad_norm": 0.577410876750946,
      "learning_rate": 2.7729827822776967e-05,
      "loss": 0.3209,
      "step": 233400
    },
    {
      "epoch": 9.494520909996544,
      "grad_norm": 0.6866926550865173,
      "learning_rate": 2.7508520338157837e-05,
      "loss": 0.3204,
      "step": 233500
    },
    {
      "epoch": 9.498587025026938,
      "grad_norm": 0.6949816346168518,
      "learning_rate": 2.7287212853538707e-05,
      "loss": 0.3211,
      "step": 233600
    },
    {
      "epoch": 9.502653140057332,
      "grad_norm": 0.5943641066551208,
      "learning_rate": 2.7065905368919577e-05,
      "loss": 0.3211,
      "step": 233700
    },
    {
      "epoch": 9.506719255087727,
      "grad_norm": 0.5703333616256714,
      "learning_rate": 2.6844597884300448e-05,
      "loss": 0.3205,
      "step": 233800
    },
    {
      "epoch": 9.510785370118121,
      "grad_norm": 0.580806314945221,
      "learning_rate": 2.6623290399681318e-05,
      "loss": 0.3216,
      "step": 233900
    },
    {
      "epoch": 9.514851485148515,
      "grad_norm": 0.5542572736740112,
      "learning_rate": 2.6401982915062188e-05,
      "loss": 0.3196,
      "step": 234000
    },
    {
      "epoch": 9.514851485148515,
      "eval_loss": 0.3408661186695099,
      "eval_runtime": 112.5796,
      "eval_samples_per_second": 1553.585,
      "eval_steps_per_second": 48.552,
      "step": 234000
    },
    {
      "epoch": 9.51891760017891,
      "grad_norm": 0.5491925477981567,
      "learning_rate": 2.6180675430443058e-05,
      "loss": 0.3196,
      "step": 234100
    },
    {
      "epoch": 9.522983715209303,
      "grad_norm": 0.6628844141960144,
      "learning_rate": 2.595936794582393e-05,
      "loss": 0.3211,
      "step": 234200
    },
    {
      "epoch": 9.527049830239697,
      "grad_norm": 0.5578463673591614,
      "learning_rate": 2.57380604612048e-05,
      "loss": 0.3197,
      "step": 234300
    },
    {
      "epoch": 9.531115945270091,
      "grad_norm": 0.5820043683052063,
      "learning_rate": 2.5516752976585666e-05,
      "loss": 0.3198,
      "step": 234400
    },
    {
      "epoch": 9.535182060300485,
      "grad_norm": 0.5573136210441589,
      "learning_rate": 2.5295445491966536e-05,
      "loss": 0.3219,
      "step": 234500
    },
    {
      "epoch": 9.53924817533088,
      "grad_norm": 0.6036468148231506,
      "learning_rate": 2.507413800734741e-05,
      "loss": 0.3225,
      "step": 234600
    },
    {
      "epoch": 9.543314290361275,
      "grad_norm": 0.6187048554420471,
      "learning_rate": 2.485283052272828e-05,
      "loss": 0.3222,
      "step": 234700
    },
    {
      "epoch": 9.547380405391669,
      "grad_norm": 0.5425005555152893,
      "learning_rate": 2.463152303810915e-05,
      "loss": 0.3181,
      "step": 234800
    },
    {
      "epoch": 9.551446520422063,
      "grad_norm": 0.623319149017334,
      "learning_rate": 2.441021555349002e-05,
      "loss": 0.3225,
      "step": 234900
    },
    {
      "epoch": 9.555512635452457,
      "grad_norm": 0.5500656366348267,
      "learning_rate": 2.418890806887089e-05,
      "loss": 0.32,
      "step": 235000
    },
    {
      "epoch": 9.559578750482851,
      "grad_norm": 0.5417319536209106,
      "learning_rate": 2.396760058425176e-05,
      "loss": 0.3181,
      "step": 235100
    },
    {
      "epoch": 9.563644865513245,
      "grad_norm": 0.6087383031845093,
      "learning_rate": 2.374629309963263e-05,
      "loss": 0.3202,
      "step": 235200
    },
    {
      "epoch": 9.567710980543639,
      "grad_norm": 0.6893118619918823,
      "learning_rate": 2.35249856150135e-05,
      "loss": 0.3207,
      "step": 235300
    },
    {
      "epoch": 9.571777095574033,
      "grad_norm": 0.5717345476150513,
      "learning_rate": 2.330367813039437e-05,
      "loss": 0.3218,
      "step": 235400
    },
    {
      "epoch": 9.575843210604429,
      "grad_norm": 0.6018801927566528,
      "learning_rate": 2.308237064577524e-05,
      "loss": 0.3208,
      "step": 235500
    },
    {
      "epoch": 9.579909325634823,
      "grad_norm": 0.5748759508132935,
      "learning_rate": 2.286106316115611e-05,
      "loss": 0.3213,
      "step": 235600
    },
    {
      "epoch": 9.583975440665217,
      "grad_norm": 0.5503509640693665,
      "learning_rate": 2.2639755676536982e-05,
      "loss": 0.3209,
      "step": 235700
    },
    {
      "epoch": 9.588041555695611,
      "grad_norm": 0.6338069438934326,
      "learning_rate": 2.2418448191917852e-05,
      "loss": 0.3217,
      "step": 235800
    },
    {
      "epoch": 9.592107670726005,
      "grad_norm": 0.5826733708381653,
      "learning_rate": 2.2197140707298722e-05,
      "loss": 0.3195,
      "step": 235900
    },
    {
      "epoch": 9.596173785756399,
      "grad_norm": 0.6387643218040466,
      "learning_rate": 2.197583322267959e-05,
      "loss": 0.3198,
      "step": 236000
    },
    {
      "epoch": 9.596173785756399,
      "eval_loss": 0.3400886356830597,
      "eval_runtime": 112.672,
      "eval_samples_per_second": 1552.311,
      "eval_steps_per_second": 48.513,
      "step": 236000
    },
    {
      "epoch": 9.600239900786793,
      "grad_norm": 0.57936692237854,
      "learning_rate": 2.175452573806046e-05,
      "loss": 0.3209,
      "step": 236100
    },
    {
      "epoch": 9.604306015817187,
      "grad_norm": 0.5738024711608887,
      "learning_rate": 2.153321825344133e-05,
      "loss": 0.3188,
      "step": 236200
    },
    {
      "epoch": 9.608372130847581,
      "grad_norm": 0.5960617661476135,
      "learning_rate": 2.13119107688222e-05,
      "loss": 0.3196,
      "step": 236300
    },
    {
      "epoch": 9.612438245877977,
      "grad_norm": 0.6076608896255493,
      "learning_rate": 2.109060328420307e-05,
      "loss": 0.3218,
      "step": 236400
    },
    {
      "epoch": 9.61650436090837,
      "grad_norm": 0.5317469835281372,
      "learning_rate": 2.086929579958394e-05,
      "loss": 0.3198,
      "step": 236500
    },
    {
      "epoch": 9.620570475938765,
      "grad_norm": 0.5798606872558594,
      "learning_rate": 2.0647988314964814e-05,
      "loss": 0.3193,
      "step": 236600
    },
    {
      "epoch": 9.624636590969159,
      "grad_norm": 0.5511528253555298,
      "learning_rate": 2.0426680830345684e-05,
      "loss": 0.3198,
      "step": 236700
    },
    {
      "epoch": 9.628702705999553,
      "grad_norm": 0.5599926710128784,
      "learning_rate": 2.0205373345726554e-05,
      "loss": 0.3181,
      "step": 236800
    },
    {
      "epoch": 9.632768821029947,
      "grad_norm": 0.5880968570709229,
      "learning_rate": 1.9984065861107424e-05,
      "loss": 0.3196,
      "step": 236900
    },
    {
      "epoch": 9.63683493606034,
      "grad_norm": 0.5873876810073853,
      "learning_rate": 1.9762758376488295e-05,
      "loss": 0.3206,
      "step": 237000
    },
    {
      "epoch": 9.640901051090735,
      "grad_norm": 0.6401693820953369,
      "learning_rate": 1.9541450891869165e-05,
      "loss": 0.3199,
      "step": 237100
    },
    {
      "epoch": 9.64496716612113,
      "grad_norm": 0.5913081169128418,
      "learning_rate": 1.9320143407250035e-05,
      "loss": 0.3188,
      "step": 237200
    },
    {
      "epoch": 9.649033281151524,
      "grad_norm": 0.5889933705329895,
      "learning_rate": 1.9098835922630905e-05,
      "loss": 0.3197,
      "step": 237300
    },
    {
      "epoch": 9.653099396181918,
      "grad_norm": 0.6497000455856323,
      "learning_rate": 1.8877528438011776e-05,
      "loss": 0.3206,
      "step": 237400
    },
    {
      "epoch": 9.657165511212312,
      "grad_norm": 0.6908433437347412,
      "learning_rate": 1.8656220953392646e-05,
      "loss": 0.3204,
      "step": 237500
    },
    {
      "epoch": 9.661231626242706,
      "grad_norm": 0.6075339913368225,
      "learning_rate": 1.8434913468773513e-05,
      "loss": 0.3218,
      "step": 237600
    },
    {
      "epoch": 9.6652977412731,
      "grad_norm": 0.6097578406333923,
      "learning_rate": 1.8213605984154383e-05,
      "loss": 0.3208,
      "step": 237700
    },
    {
      "epoch": 9.669363856303494,
      "grad_norm": 0.6664062738418579,
      "learning_rate": 1.7992298499535253e-05,
      "loss": 0.321,
      "step": 237800
    },
    {
      "epoch": 9.673429971333888,
      "grad_norm": 0.5746066570281982,
      "learning_rate": 1.7770991014916123e-05,
      "loss": 0.3209,
      "step": 237900
    },
    {
      "epoch": 9.677496086364282,
      "grad_norm": 0.594237208366394,
      "learning_rate": 1.7549683530296994e-05,
      "loss": 0.3196,
      "step": 238000
    },
    {
      "epoch": 9.677496086364282,
      "eval_loss": 0.3397737443447113,
      "eval_runtime": 112.9332,
      "eval_samples_per_second": 1548.721,
      "eval_steps_per_second": 48.4,
      "step": 238000
    },
    {
      "epoch": 9.681562201394678,
      "grad_norm": 0.5910089015960693,
      "learning_rate": 1.7328376045677864e-05,
      "loss": 0.3202,
      "step": 238100
    },
    {
      "epoch": 9.685628316425072,
      "grad_norm": 0.5571303367614746,
      "learning_rate": 1.7107068561058734e-05,
      "loss": 0.3184,
      "step": 238200
    },
    {
      "epoch": 9.689694431455466,
      "grad_norm": 0.604725182056427,
      "learning_rate": 1.6885761076439604e-05,
      "loss": 0.3184,
      "step": 238300
    },
    {
      "epoch": 9.69376054648586,
      "grad_norm": 0.6115219593048096,
      "learning_rate": 1.6664453591820474e-05,
      "loss": 0.3208,
      "step": 238400
    },
    {
      "epoch": 9.697826661516254,
      "grad_norm": 0.6287631988525391,
      "learning_rate": 1.6443146107201348e-05,
      "loss": 0.3189,
      "step": 238500
    },
    {
      "epoch": 9.701892776546648,
      "grad_norm": 0.6569950580596924,
      "learning_rate": 1.6221838622582218e-05,
      "loss": 0.3199,
      "step": 238600
    },
    {
      "epoch": 9.705958891577042,
      "grad_norm": 0.5677297711372375,
      "learning_rate": 1.600053113796309e-05,
      "loss": 0.3194,
      "step": 238700
    },
    {
      "epoch": 9.710025006607436,
      "grad_norm": 0.5367802977561951,
      "learning_rate": 1.577922365334396e-05,
      "loss": 0.3187,
      "step": 238800
    },
    {
      "epoch": 9.714091121637832,
      "grad_norm": 0.6505126357078552,
      "learning_rate": 1.5557916168724826e-05,
      "loss": 0.3178,
      "step": 238900
    },
    {
      "epoch": 9.718157236668226,
      "grad_norm": 0.6013728976249695,
      "learning_rate": 1.53366086841057e-05,
      "loss": 0.3187,
      "step": 239000
    },
    {
      "epoch": 9.72222335169862,
      "grad_norm": 0.5936048030853271,
      "learning_rate": 1.5115301199486568e-05,
      "loss": 0.3191,
      "step": 239100
    },
    {
      "epoch": 9.726289466729014,
      "grad_norm": 0.6167245507240295,
      "learning_rate": 1.4893993714867438e-05,
      "loss": 0.3172,
      "step": 239200
    },
    {
      "epoch": 9.730355581759408,
      "grad_norm": 0.6216642260551453,
      "learning_rate": 1.4672686230248308e-05,
      "loss": 0.3189,
      "step": 239300
    },
    {
      "epoch": 9.734421696789802,
      "grad_norm": 0.5091118812561035,
      "learning_rate": 1.4451378745629178e-05,
      "loss": 0.32,
      "step": 239400
    },
    {
      "epoch": 9.738487811820196,
      "grad_norm": 0.6572582721710205,
      "learning_rate": 1.4230071261010047e-05,
      "loss": 0.3195,
      "step": 239500
    },
    {
      "epoch": 9.74255392685059,
      "grad_norm": 0.6341210007667542,
      "learning_rate": 1.4008763776390917e-05,
      "loss": 0.3202,
      "step": 239600
    },
    {
      "epoch": 9.746620041880984,
      "grad_norm": 0.6038832664489746,
      "learning_rate": 1.3787456291771787e-05,
      "loss": 0.3187,
      "step": 239700
    },
    {
      "epoch": 9.75068615691138,
      "grad_norm": 0.6553649306297302,
      "learning_rate": 1.3566148807152657e-05,
      "loss": 0.3201,
      "step": 239800
    },
    {
      "epoch": 9.754752271941774,
      "grad_norm": 0.6020246744155884,
      "learning_rate": 1.3344841322533528e-05,
      "loss": 0.317,
      "step": 239900
    },
    {
      "epoch": 9.758818386972168,
      "grad_norm": 0.5625,
      "learning_rate": 1.31235338379144e-05,
      "loss": 0.3193,
      "step": 240000
    },
    {
      "epoch": 9.758818386972168,
      "eval_loss": 0.33910682797431946,
      "eval_runtime": 112.7711,
      "eval_samples_per_second": 1550.946,
      "eval_steps_per_second": 48.47,
      "step": 240000
    },
    {
      "epoch": 9.762884502002562,
      "grad_norm": 0.6806621551513672,
      "learning_rate": 1.290222635329527e-05,
      "loss": 0.32,
      "step": 240100
    },
    {
      "epoch": 9.766950617032956,
      "grad_norm": 0.7398905158042908,
      "learning_rate": 1.268091886867614e-05,
      "loss": 0.3201,
      "step": 240200
    },
    {
      "epoch": 9.77101673206335,
      "grad_norm": 0.5454760789871216,
      "learning_rate": 1.2459611384057009e-05,
      "loss": 0.321,
      "step": 240300
    },
    {
      "epoch": 9.775082847093744,
      "grad_norm": 0.5750144720077515,
      "learning_rate": 1.2238303899437879e-05,
      "loss": 0.3179,
      "step": 240400
    },
    {
      "epoch": 9.779148962124138,
      "grad_norm": 0.6507167816162109,
      "learning_rate": 1.2016996414818749e-05,
      "loss": 0.3177,
      "step": 240500
    },
    {
      "epoch": 9.783215077154534,
      "grad_norm": 0.595252513885498,
      "learning_rate": 1.179568893019962e-05,
      "loss": 0.3189,
      "step": 240600
    },
    {
      "epoch": 9.787281192184928,
      "grad_norm": 0.639225423336029,
      "learning_rate": 1.157438144558049e-05,
      "loss": 0.3191,
      "step": 240700
    },
    {
      "epoch": 9.791347307215322,
      "grad_norm": 0.529520571231842,
      "learning_rate": 1.135307396096136e-05,
      "loss": 0.3202,
      "step": 240800
    },
    {
      "epoch": 9.795413422245716,
      "grad_norm": 0.6394244432449341,
      "learning_rate": 1.113176647634223e-05,
      "loss": 0.318,
      "step": 240900
    },
    {
      "epoch": 9.79947953727611,
      "grad_norm": 0.611487090587616,
      "learning_rate": 1.0910458991723102e-05,
      "loss": 0.3189,
      "step": 241000
    },
    {
      "epoch": 9.803545652306504,
      "grad_norm": 0.6400057673454285,
      "learning_rate": 1.068915150710397e-05,
      "loss": 0.3202,
      "step": 241100
    },
    {
      "epoch": 9.807611767336898,
      "grad_norm": 0.5455589294433594,
      "learning_rate": 1.046784402248484e-05,
      "loss": 0.3187,
      "step": 241200
    },
    {
      "epoch": 9.811677882367292,
      "grad_norm": 0.6323734521865845,
      "learning_rate": 1.024653653786571e-05,
      "loss": 0.3215,
      "step": 241300
    },
    {
      "epoch": 9.815743997397686,
      "grad_norm": 0.6609461307525635,
      "learning_rate": 1.0025229053246581e-05,
      "loss": 0.3203,
      "step": 241400
    },
    {
      "epoch": 9.81981011242808,
      "grad_norm": 0.6356253623962402,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.3179,
      "step": 241500
    },
    {
      "epoch": 9.823876227458475,
      "grad_norm": 0.5681877136230469,
      "learning_rate": 9.582614084008321e-06,
      "loss": 0.32,
      "step": 241600
    },
    {
      "epoch": 9.82794234248887,
      "grad_norm": 0.6044402718544006,
      "learning_rate": 9.361306599389192e-06,
      "loss": 0.3184,
      "step": 241700
    },
    {
      "epoch": 9.832008457519263,
      "grad_norm": 0.6302270889282227,
      "learning_rate": 9.13999911477006e-06,
      "loss": 0.3171,
      "step": 241800
    },
    {
      "epoch": 9.836074572549657,
      "grad_norm": 0.5964558124542236,
      "learning_rate": 8.91869163015093e-06,
      "loss": 0.317,
      "step": 241900
    },
    {
      "epoch": 9.840140687580051,
      "grad_norm": 0.6394781470298767,
      "learning_rate": 8.697384145531802e-06,
      "loss": 0.3166,
      "step": 242000
    },
    {
      "epoch": 9.840140687580051,
      "eval_loss": 0.3385038673877716,
      "eval_runtime": 113.2681,
      "eval_samples_per_second": 1544.141,
      "eval_steps_per_second": 48.257,
      "step": 242000
    },
    {
      "epoch": 9.844206802610445,
      "grad_norm": 0.6370998024940491,
      "learning_rate": 8.476076660912673e-06,
      "loss": 0.3171,
      "step": 242100
    },
    {
      "epoch": 9.84827291764084,
      "grad_norm": 0.6237854957580566,
      "learning_rate": 8.254769176293543e-06,
      "loss": 0.3203,
      "step": 242200
    },
    {
      "epoch": 9.852339032671233,
      "grad_norm": 0.610331654548645,
      "learning_rate": 8.033461691674413e-06,
      "loss": 0.319,
      "step": 242300
    },
    {
      "epoch": 9.85640514770163,
      "grad_norm": 0.5562739968299866,
      "learning_rate": 7.812154207055283e-06,
      "loss": 0.318,
      "step": 242400
    },
    {
      "epoch": 9.860471262732023,
      "grad_norm": 0.6267716288566589,
      "learning_rate": 7.590846722436153e-06,
      "loss": 0.3186,
      "step": 242500
    },
    {
      "epoch": 9.864537377762417,
      "grad_norm": 0.5883303880691528,
      "learning_rate": 7.369539237817023e-06,
      "loss": 0.3183,
      "step": 242600
    },
    {
      "epoch": 9.868603492792811,
      "grad_norm": 0.6322078108787537,
      "learning_rate": 7.148231753197894e-06,
      "loss": 0.3176,
      "step": 242700
    },
    {
      "epoch": 9.872669607823205,
      "grad_norm": 0.5818657279014587,
      "learning_rate": 6.926924268578763e-06,
      "loss": 0.3191,
      "step": 242800
    },
    {
      "epoch": 9.8767357228536,
      "grad_norm": 0.6191835403442383,
      "learning_rate": 6.7056167839596335e-06,
      "loss": 0.317,
      "step": 242900
    },
    {
      "epoch": 9.880801837883993,
      "grad_norm": 0.6491280198097229,
      "learning_rate": 6.484309299340504e-06,
      "loss": 0.3175,
      "step": 243000
    },
    {
      "epoch": 9.884867952914387,
      "grad_norm": 0.6134216785430908,
      "learning_rate": 6.263001814721374e-06,
      "loss": 0.3172,
      "step": 243100
    },
    {
      "epoch": 9.888934067944781,
      "grad_norm": 0.5821706056594849,
      "learning_rate": 6.041694330102244e-06,
      "loss": 0.3181,
      "step": 243200
    },
    {
      "epoch": 9.893000182975177,
      "grad_norm": 0.6223289370536804,
      "learning_rate": 5.820386845483114e-06,
      "loss": 0.3196,
      "step": 243300
    },
    {
      "epoch": 9.897066298005571,
      "grad_norm": 0.6239637136459351,
      "learning_rate": 5.599079360863985e-06,
      "loss": 0.3177,
      "step": 243400
    },
    {
      "epoch": 9.901132413035965,
      "grad_norm": 0.572573721408844,
      "learning_rate": 5.377771876244855e-06,
      "loss": 0.3175,
      "step": 243500
    },
    {
      "epoch": 9.905198528066359,
      "grad_norm": 0.6437477469444275,
      "learning_rate": 5.156464391625724e-06,
      "loss": 0.3178,
      "step": 243600
    },
    {
      "epoch": 9.909264643096753,
      "grad_norm": 0.5993471145629883,
      "learning_rate": 4.935156907006595e-06,
      "loss": 0.3174,
      "step": 243700
    },
    {
      "epoch": 9.913330758127147,
      "grad_norm": 0.6017647385597229,
      "learning_rate": 4.7138494223874655e-06,
      "loss": 0.3177,
      "step": 243800
    },
    {
      "epoch": 9.917396873157541,
      "grad_norm": 0.5941608548164368,
      "learning_rate": 4.492541937768336e-06,
      "loss": 0.3167,
      "step": 243900
    },
    {
      "epoch": 9.921462988187935,
      "grad_norm": 0.628546953201294,
      "learning_rate": 4.271234453149205e-06,
      "loss": 0.3166,
      "step": 244000
    },
    {
      "epoch": 9.921462988187935,
      "eval_loss": 0.33809950947761536,
      "eval_runtime": 114.043,
      "eval_samples_per_second": 1533.65,
      "eval_steps_per_second": 47.929,
      "step": 244000
    },
    {
      "epoch": 9.92552910321833,
      "grad_norm": 0.6519865989685059,
      "learning_rate": 4.049926968530075e-06,
      "loss": 0.3181,
      "step": 244100
    },
    {
      "epoch": 9.929595218248725,
      "grad_norm": 0.5563254952430725,
      "learning_rate": 3.8286194839109455e-06,
      "loss": 0.3186,
      "step": 244200
    },
    {
      "epoch": 9.933661333279119,
      "grad_norm": 0.6078489422798157,
      "learning_rate": 3.607311999291816e-06,
      "loss": 0.3171,
      "step": 244300
    },
    {
      "epoch": 9.937727448309513,
      "grad_norm": 0.6722143292427063,
      "learning_rate": 3.3860045146726864e-06,
      "loss": 0.3193,
      "step": 244400
    },
    {
      "epoch": 9.941793563339907,
      "grad_norm": 0.58777916431427,
      "learning_rate": 3.1646970300535566e-06,
      "loss": 0.319,
      "step": 244500
    },
    {
      "epoch": 9.9458596783703,
      "grad_norm": 0.6737107038497925,
      "learning_rate": 2.943389545434427e-06,
      "loss": 0.3168,
      "step": 244600
    },
    {
      "epoch": 9.949925793400695,
      "grad_norm": 0.5841479897499084,
      "learning_rate": 2.7220820608152966e-06,
      "loss": 0.317,
      "step": 244700
    },
    {
      "epoch": 9.953991908431089,
      "grad_norm": 0.5809665322303772,
      "learning_rate": 2.5007745761961673e-06,
      "loss": 0.3189,
      "step": 244800
    },
    {
      "epoch": 9.958058023461483,
      "grad_norm": 0.6154278516769409,
      "learning_rate": 2.279467091577037e-06,
      "loss": 0.3177,
      "step": 244900
    },
    {
      "epoch": 9.962124138491879,
      "grad_norm": 0.5853445529937744,
      "learning_rate": 2.0581596069579077e-06,
      "loss": 0.3175,
      "step": 245000
    },
    {
      "epoch": 9.966190253522273,
      "grad_norm": 0.651337206363678,
      "learning_rate": 1.8368521223387775e-06,
      "loss": 0.3179,
      "step": 245100
    },
    {
      "epoch": 9.970256368552667,
      "grad_norm": 0.6305847764015198,
      "learning_rate": 1.6155446377196477e-06,
      "loss": 0.3183,
      "step": 245200
    },
    {
      "epoch": 9.97432248358306,
      "grad_norm": 0.5797362923622131,
      "learning_rate": 1.394237153100518e-06,
      "loss": 0.3187,
      "step": 245300
    },
    {
      "epoch": 9.978388598613455,
      "grad_norm": 0.6768087148666382,
      "learning_rate": 1.172929668481388e-06,
      "loss": 0.3187,
      "step": 245400
    },
    {
      "epoch": 9.982454713643849,
      "grad_norm": 0.6229487061500549,
      "learning_rate": 9.516221838622583e-07,
      "loss": 0.3152,
      "step": 245500
    },
    {
      "epoch": 9.986520828674243,
      "grad_norm": 0.5880612730979919,
      "learning_rate": 7.303146992431284e-07,
      "loss": 0.3183,
      "step": 245600
    },
    {
      "epoch": 9.990586943704637,
      "grad_norm": 0.5969985127449036,
      "learning_rate": 5.090072146239986e-07,
      "loss": 0.3171,
      "step": 245700
    },
    {
      "epoch": 9.994653058735032,
      "grad_norm": 0.5846843719482422,
      "learning_rate": 2.876997300048688e-07,
      "loss": 0.3165,
      "step": 245800
    },
    {
      "epoch": 9.998719173765426,
      "grad_norm": 0.6212279200553894,
      "learning_rate": 6.639224538573895e-08,
      "loss": 0.3192,
      "step": 245900
    },
    {
      "epoch": 9.999939008274545,
      "step": 245930,
      "total_flos": 0.0,
      "train_loss": 0.06621546175841206,
      "train_runtime": 8156.4931,
      "train_samples_per_second": 1929.73,
      "train_steps_per_second": 30.151
    }
  ],
  "logging_steps": 100,
  "max_steps": 245930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
